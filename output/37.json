[
  {
    "title": "The worst-case execution-time problem—overview of methods and survey of tools",
    "doi": "https://doi.org/10.1145/1347375.1347389",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Reinhard Wilhelm; Jakob Engblom; Andreas Ermedahl; Niklas Holsti; Stephan Thesing; David Whalley; Guillem Bernat; Christian Ferdinand; Reinhold Heckmann; Tulika Mitra; Frank Mueller; Isabelle Puaut; Peter Puschner; Jan Staschulat; Per Stenström",
    "corresponding_authors": "",
    "abstract": "The determination of upper bounds on execution times, commonly called worst-case execution times (WCETs), is a necessary step in the development and validation process for hard real-time systems. This problem is hard if the underlying processor architecture has components, such as caches, pipelines, branch prediction, and other speculative components. This article describes different approaches to this problem and surveys several commercially available tools 1 and research prototypes.",
    "cited_by_count": 1794,
    "openalex_id": "https://openalex.org/W2076285066",
    "type": "article"
  },
  {
    "title": "Power management in energy harvesting sensor networks",
    "doi": "https://doi.org/10.1145/1274858.1274870",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Aman Kansal; Jason C. Hsu; Sadaf Zahedi; Mani Srivastava",
    "corresponding_authors": "",
    "abstract": "Power management is an important concern in sensor networks, because a tethered energy infrastructure is usually not available and an obvious concern is to use the available battery energy efficiently. However, in some of the sensor networking applications, an additional facility is available to ameliorate the energy problem: harvesting energy from the environment. Certain considerations in using an energy harvesting source are fundamentally different from that in using a battery, because, rather than a limit on the maximum energy, it has a limit on the maximum rate at which the energy can be used. Further, the harvested energy availability typically varies with time in a nondeterministic manner. While a deterministic metric, such as residual battery, suffices to characterize the energy availability in the case of batteries, a more sophisticated characterization may be required for a harvesting source. Another issue that becomes important in networked systems with multiple harvesting nodes is that different nodes may have different harvesting opportunity. In a distributed application, the same end-user performance may be achieved using different workload allocations, and resultant energy consumptions at multiple nodes. In this case, it is important to align the workload allocation with the energy availability at the harvesting nodes. We consider the above issues in power management for energy-harvesting sensor networks. We develop abstractions to characterize the complex time varying nature of such sources with analytically tractable models and use them to address key design issues. We also develop distributed methods to efficiently use harvested energy and test these both in simulation and experimentally on an energy-harvesting sensor network, prototyped for this work.",
    "cited_by_count": 1524,
    "openalex_id": "https://openalex.org/W1991781995",
    "type": "article"
  },
  {
    "title": "A log buffer-based flash translation layer using fully-associative sector translation",
    "doi": "https://doi.org/10.1145/1275986.1275990",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Sang-Won Lee; Dong-Joo Park; Tae‐Sun Chung; Dong‐Ho Lee; Sangwon Park; Ha-Joo Song",
    "corresponding_authors": "",
    "abstract": "Flash memory is being rapidly deployed as data storage for mobile devices such as PDAs, MP3 players, mobile phones, and digital cameras, mainly because of its low electronic power, nonvolatile storage, high performance, physical stability, and portability. One disadvantage of flash memory is that prewritten data cannot be dynamically overwritten. Before overwriting prewritten data, a time-consuming erase operation on the used blocks must precede, which significantly degrades the overall write performance of flash memory. In order to solve this “erase-before-write” problem, the flash memory controller can be integrated with a software module, called “flash translation layer (FTL).” Among many FTL schemes available, the log block buffer scheme is considered to be optimum. With this scheme, a small number of log blocks, a kind of write buffer, can improve the performance of write operations by reducing the number of erase operations. However, this scheme can suffer from low space utilization of log blocks. In this paper, we show that there is much room for performance improvement in the log buffer block scheme, and propose an enhanced log block buffer scheme, called FAST (full associative sector translation). Our FAST scheme improves the space utilization of log blocks using fully-associative sector translations for the log block sectors. We also show empirically that our FAST scheme outperforms the pure log block buffer scheme.",
    "cited_by_count": 656,
    "openalex_id": "https://openalex.org/W2018763861",
    "type": "article"
  },
  {
    "title": "Survey of Stochastic Computing",
    "doi": "https://doi.org/10.1145/2465787.2465794",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Armin Alaghi; John P. Hayes",
    "corresponding_authors": "",
    "abstract": "Stochastic computing (SC) was proposed in the 1960s as a low-cost alternative to conventional binary computing. It is unique in that it represents and processes information in the form of digitized probabilities. SC employs very low-complexity arithmetic units which was a primary design concern in the past. Despite this advantage and also its inherent error tolerance, SC was seen as impractical because of very long computation times and relatively low accuracy. However, current technology trends tend to increase uncertainty in circuit behavior and imply a need to better understand, and perhaps exploit, probability in computation. This article surveys SC from a modern perspective where the small size, error resilience, and probabilistic features of SC may compete successfully with conventional methodologies in certain applications. First, we survey the literature and review the key concepts of stochastic number representation and circuit structure. We then describe the design of SC-based circuits and evaluate their advantages and disadvantages. Finally, we give examples of the potential applications of SC and discuss some practical problems that are yet to be solved.",
    "cited_by_count": 549,
    "openalex_id": "https://openalex.org/W2003056114",
    "type": "article"
  },
  {
    "title": "Sensor deployment and target localization in distributed sensor networks",
    "doi": "https://doi.org/10.1145/972627.972631",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Yi Zou; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "The effectiveness of cluster-based distributed sensor networks depends to a large extent on the coverage provided by the sensor deployment. We propose a virtual force algorithm (VFA) as a sensor deployment strategy to enhance the coverage after an initial random placement of sensors. For a given number of sensors, the VFA algorithm attempts to maximize the sensor field coverage. A judicious combination of attractive and repulsive forces is used to determine the new sensor locations that improve the coverage. Once the effective sensor positions are identified, a one-time movement with energy consideration incorporated is carried out, that is, the sensors are redeployed, to these positions. We also propose a novel probabilistic target localization algorithm that is executed by the cluster head. The localization results are used by the cluster head to query only a few sensors (out of those that report the presence of a target) for more detailed information. Simulation results are presented to demonstrate the effectiveness of the proposed approach.",
    "cited_by_count": 514,
    "openalex_id": "https://openalex.org/W2105847861",
    "type": "article"
  },
  {
    "title": "Security in embedded systems",
    "doi": "https://doi.org/10.1145/1015047.1015049",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "Srivaths Ravi; Anand Raghunathan; Paul Kocher; S. V. Hattangady",
    "corresponding_authors": "",
    "abstract": "Many modern electronic systems---including personal computers, PDAs, cell phones, network routers, smart cards, and networked sensors to name a few---need to access, store, manipulate, or communicate sensitive information, making security a serious concern in their design. Embedded systems, which account for a wide range of products from the electronics, semiconductor, telecommunications, and networking industries, face some of the most demanding security concerns---on the one hand, they are often highly resource constrained, while on the other hand, they frequently need to operate in physically insecure environments.Security has been the subject of intensive research in the context of general-purpose computing and communications systems. However, security is often misconstrued by embedded system designers as the addition of features, such as specific cryptographic algorithms and security protocols, to the system. In reality, it is a new dimension that designers should consider throughout the design process, along with other metrics such as cost, performance, and power.The challenges unique to embedded systems require new approaches to security covering all aspects of embedded system design from architecture to implementation. Security processing, which refers to the computations that must be performed in a system for the purpose of security, can easily overwhelm the computational capabilities of processors in both low- and high-end embedded systems. This challenge, which we refer to as the \"security processing gap,\" is compounded by increases in the amounts of data manipulated and the data rates that need to be achieved. Equally daunting is the \"battery gap\" in battery-powered embedded systems, which is caused by the disparity between rapidly increasing energy requirements for secure operation and slow improvements in battery technology. The final challenge is the \"assurance gap,\" which relates to the gap between functional security measures (e.g., security services, protocols, and their constituent cryptographic algorithms) and actual secure implementations. This paper provides an introduction to the challenges involved in secure embedded system design, discusses recent advances in addressing them, and identifies opportunities for future research.",
    "cited_by_count": 460,
    "openalex_id": "https://openalex.org/W2120562931",
    "type": "article"
  },
  {
    "title": "LegUp",
    "doi": "https://doi.org/10.1145/2514740",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Andrew Canis; Jongsok Choi; Mark Aldham; Victor Zhang; Ahmed Kammoona; Tomasz Czajkowski; Stephen D. Brown; Jason H. Anderson",
    "corresponding_authors": "",
    "abstract": "It is generally accepted that a custom hardware implementation of a set of computations will provide superior speed and energy efficiency relative to a software implementation. However, the cost and difficulty of hardware design is often prohibitive, and consequently, a software approach is used for most applications. In this article, we introduce a new high-level synthesis tool called LegUp that allows software techniques to be used for hardware design. LegUp accepts a standard C program as input and automatically compiles the program to a hybrid architecture containing an FPGA-based MIPS soft processor and custom hardware accelerators that communicate through a standard bus interface. In the hybrid processor/accelerator architecture, program segments that are unsuitable for hardware implementation can execute in software on the processor. LegUp can synthesize most of the C language to hardware, including fixed-sized multidimensional arrays, structs, global variables, and pointer arithmetic. Results show that the tool produces hardware solutions of comparable quality to a commercial high-level synthesis tool. We also give results demonstrating the ability of the tool to explore the hardware/software codesign space by varying the amount of a program that runs in software versus hardware. LegUp, along with a set of benchmark C programs, is open source and freely downloadable, providing a powerful platform that can be leveraged for new research on a wide range of high-level synthesis topics.",
    "cited_by_count": 294,
    "openalex_id": "https://openalex.org/W1970032753",
    "type": "article"
  },
  {
    "title": "A PUF-Based Secure Communication Protocol for IoT",
    "doi": "https://doi.org/10.1145/3005715",
    "publication_date": "2017-04-28",
    "publication_year": 2017,
    "authors": "Urbi Chatterjee; Rajat Subhra Chakraborty; Debdeep Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "Security features are of paramount importance for the Internet of Things (IoT), and implementations are challenging given the resource-constrained IoT setup. We have developed a lightweight identity-based cryptosystem suitable for IoT to enable secure authentication and message exchange among the devices. Our scheme employs a Physically Unclonable Function (PUF) to generate the public identity of each device, which is used as the public key for each device for message encryption. We have provided formal proofs of security in the Session Key Security and Universally Composable Framework of the proposed protocol, which demonstrates the resilience of the scheme against passive and active attacks. We have demonstrated the setup required for the protocol implementation and shown that the proposed protocol implementation incurs low hardware and software overhead.",
    "cited_by_count": 183,
    "openalex_id": "https://openalex.org/W2609047018",
    "type": "article"
  },
  {
    "title": "Multilevel μTESLA",
    "doi": "https://doi.org/10.1145/1027794.1027800",
    "publication_date": "2004-11-01",
    "publication_year": 2004,
    "authors": "Donggang Liu; Peng Ning",
    "corresponding_authors": "",
    "abstract": "Broadcast authentication is a fundamental security service in distributed sensor networks. This paper presents the development of a scalable broadcast authentication scheme named &lt;i&gt;multilevel μTESLA&lt;/i&gt; based on μTESLA, a broadcast authentication protocol whose scalability is limited by its unicast-based initial parameter distribution. Multilevel μTESLA satisfies several nice properties, including low overhead, tolerance of message loss, scalability to large networks, and resistance to replay attacks as well as denial-of-service attacks. This paper also presents the experimental results obtained through simulation, which demonstrate the performance of the proposed scheme under severe denial-of-service attacks and poor channel quality.",
    "cited_by_count": 353,
    "openalex_id": "https://openalex.org/W2061285874",
    "type": "article"
  },
  {
    "title": "An optimal memory allocation scheme for scratch-pad-based embedded systems",
    "doi": "https://doi.org/10.1145/581888.581891",
    "publication_date": "2002-11-01",
    "publication_year": 2002,
    "authors": "Oren Avissar; Rajeev Barua; Dave Stewart",
    "corresponding_authors": "",
    "abstract": "This article presents a technique for the efficient compiler management of software-exposed heterogeneous memory. In many lower-end embedded chips, often used in microcontrollers and DSP processors, heterogeneous memory units such as scratch-pad SRAM, internal DRAM, external DRAM, and ROM are visible directly to the software, without automatic management by a hardware caching mechanism. Instead, the memory units are mapped to different portions of the address space. Caches are avoided due to their cost and power consumption, and because they make it difficult to guarantee real-time performance. For this important class of embedded chips, the allocation of data to different memory units to maximize performance is the responsibility of the software.Current practice typically leaves it to the programmer to partition the data among different memory units. We present a compiler strategy that automatically partitions the data among the memory units. We show that this strategy is optimal, relative to the profile run, among all static partitions for global and stack data. For the first time, our allocation scheme for stacks distributes the stack among multiple memory units. For global and stack data, the scheme is provably equal to or better than any other compiler scheme or set of programmer annotations. Results from our benchmarks show a 44.2% reduction in runtime from using our distributed stack strategy vs. using a unified stack, and a further 11.8% reduction in runtime from using a linear optimization strategy for allocation vs. a simpler greedy strategy; both in the case of the SRAM size being 20% of the total data size. For some programs, less than 5% of data in SRAM achieves a similar speedup.",
    "cited_by_count": 338,
    "openalex_id": "https://openalex.org/W2163270257",
    "type": "article"
  },
  {
    "title": "Energy management for battery-powered embedded systems",
    "doi": "https://doi.org/10.1145/860176.860179",
    "publication_date": "2003-08-01",
    "publication_year": 2003,
    "authors": "Daler Rakhmatov; Sarma Vrudhula",
    "corresponding_authors": "",
    "abstract": "Portable embedded computing systems require energy autonomy. This is achieved by batteries serving as a dedicated energy source. The requirement of portability places severe restrictions on size and weight, which in turn limits the amount of energy that is continuously available to maintain system operability. For these reasons, efficient energy utilization has become one of the key challenges to the designer of battery-powered embedded computing systems.In this paper, we first present a novel analytical battery model, which can be used for the battery lifetime estimation. The high quality of the proposed model is demonstrated with measurements and simulations. Using this battery model, we introduce a new \"battery-aware\" cost function, which will be used for optimizing the lifetime of the battery. This cost function generalizes the traditional minimization metric, namely the energy consumption of the system. We formulate the problem of battery-aware task scheduling on a single processor with multiple voltages. Then, we prove several important mathematical properties of the cost function. Based on these properties, we propose several algorithms for task ordering and voltage assignment, including optimal idle period insertion to exercise charge recovery.This paper presents the first effort toward a formal treatment of battery-aware task scheduling and voltage scaling, based on an accurate analytical model of the battery behavior.",
    "cited_by_count": 261,
    "openalex_id": "https://openalex.org/W2054775380",
    "type": "article"
  },
  {
    "title": "Range-free localization and its impact on large scale sensor networks",
    "doi": "https://doi.org/10.1145/1113830.1113837",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "Tian He; Chengdu Huang; Brian Blum; John A. Stankovic; Tarek Abdelzaher",
    "corresponding_authors": "",
    "abstract": "With the proliferation of location dependent applications in sensor networks, location awareness becomes an essential capability of sensor nodes. Because coarse accuracy is sufficient for most sensor network applications, solutions in range-free localization are being pursued as a cost-effective alternative to more expensive range-based approaches. In this paper, we present APIT, a novel localization algorithm that is range-free. We show that our APIT scheme performs best when an irregular radio pattern and random node placement are considered, and low communication overhead is desired. We compare our work, via extensive simulation, with three state-of-the-art range-free localization schemes to identify the preferable system configurations of each. In addition, we provide insight into the impact of localization accuracy on various location dependent applications and suggestions on improving their performance in the presence of such inaccuracy.",
    "cited_by_count": 244,
    "openalex_id": "https://openalex.org/W2076752550",
    "type": "article"
  },
  {
    "title": "MEDiSN",
    "doi": "https://doi.org/10.1145/1814539.1814550",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "JeongGil Ko; Jong Hyun Lim; Yin Chen; Rvăzvan Musvaloiu-E; Andreas Terzis; Gerald M. Masson; Tia Gao; Walt Destler; Leo Selavo; Richard P. Dutton",
    "corresponding_authors": "",
    "abstract": "Staff shortages and an increasingly aging population are straining the ability of emergency departments to provide high quality care. At the same time, there is a growing concern about hospitals' ability to provide effective care during disaster events. For these reasons, tools that automate patient monitoring have the potential to greatly improve efficiency and quality of health care. Towards this goal, we have developed MEDiSN , a wireless sensor network for monitoring patients' physiological data in hospitals and during disaster events. MEDiSN comprises Physiological Monitors (PMs), which are custom-built, patient-worn motes that sample, encrypt, and sign physiological data and Relay Points (RPs) that self-organize into a multi-hop wireless backbone for carrying physiological data. Moreover, MEDiSN includes a back-end server that persistently stores medical data and presents them to authenticated GUI clients. The combination of MEDiSN's two-tier architecture and optimized rate control protocols allows it to address the compound challenge of reliably delivering large volumes of data while meeting the application's QoS requirements. Results from extensive simulations, testbed experiments, and multiple pilot hospital deployments show that MEDiSN can scale from tens to at least five hundred PMs, effectively protect application packets from congestive and corruptive losses, and deliver medically actionable data.",
    "cited_by_count": 233,
    "openalex_id": "https://openalex.org/W1975347960",
    "type": "article"
  },
  {
    "title": "Real-time garbage collection for flash-memory storage systems of real-time embedded systems",
    "doi": "https://doi.org/10.1145/1027794.1027801",
    "publication_date": "2004-11-01",
    "publication_year": 2004,
    "authors": "Li-Pin Chang; Tei‐Wei Kuo; Shi-Wu Lo",
    "corresponding_authors": "",
    "abstract": "Flash-memory technology is becoming critical in building embedded systems applications because of its shock-resistant, power economic, and nonvolatile nature. With the recent technology breakthroughs in both capacity and reliability, flash-memory storage systems are now very popular in many types of embedded systems. However, because flash memory is a write-once and bulk-erase medium, we need a translation layer and a garbage-collection mechanism to provide applications a transparent storage service. In the past work, various techniques were introduced to improve the garbage-collection mechanism. These techniques aimed at both performance and endurance issues, but they all failed in providing applications a guaranteed performance. In this paper, we propose a real-time garbage-collection mechanism, which provides a guaranteed performance, for hard real-time systems. On the other hand, the proposed mechanism supports non-real-time tasks so that the potential bandwidth of the storage system can be fully utilized. A wear-leveling method, which is executed as a non-real-time service, is presented to resolve the endurance problem of flash memory. The capability of the proposed mechanism is demonstrated by a series of experiments over our system prototype.",
    "cited_by_count": 228,
    "openalex_id": "https://openalex.org/W2036382651",
    "type": "article"
  },
  {
    "title": "Self-configuring localization systems",
    "doi": "https://doi.org/10.1145/972627.972630",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Nirupama Bulusu; John Heidemann; Deborah Estrin; Tommy Tran",
    "corresponding_authors": "",
    "abstract": "Embedded networked sensors promise to revolutionize the way we interact with our physical environment and require scalable, ad hoc deployable and energy-efficient node localization/positioning.This paper describes the motivation, design, implementation, and experimental evaluation (on sharply resource-constrained devices) of a self-configuring localization system using radio beacons. We identify beacon density as an important parameter in determining localization quality, which saturates at a transition density. We develop algorithms to improve localization quality by (i) automating placement of new beacons at low densities (HEAP) and (ii) rotating functionality among redundant beacons while increasing system lifetime at high densities (STROBE).",
    "cited_by_count": 227,
    "openalex_id": "https://openalex.org/W2030175957",
    "type": "article"
  },
  {
    "title": "Dynamic allocation for scratch-pad memory using compile-time decisions",
    "doi": "https://doi.org/10.1145/1151074.1151085",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Sumesh Udayakumaran; Ángel Manuel Gamaza Domínguez; Rajeev Barua",
    "corresponding_authors": "",
    "abstract": "In this research, we propose a highly predictable, low overhead, and, yet, dynamic, memory-allocation strategy for embedded systems with scratch pad memory. A scratch pad is a fast compiler-managed SRAM memory that replaces the hardware-managed cache. It is motivated by its better real-time guarantees versus cache and by its significantly lower overheads in energy consumption, area, and overall runtime, even with a simple allocation scheme. Primarily scratch pad allocation methods are of two types. First, software-caching schemes emulate the workings of a hardware cache in software. Instructions are inserted before each load/store to check the software-maintained cache tags. Such methods incur large overheads in runtime, code size, energy consumption, and SRAM space for tags and deliver poor real-time guarantees just like hardware caches. A second category of algorithms partitions variables at compile-time into the two banks. However, a drawback of such static allocation schemes is that they do not account for dynamic program behavior. It is easy to see why a data allocation that never changes at runtime cannot achieve the full locality benefits of a cache. We propose a dynamic allocation methodology for global and stack data and program code that; (i) accounts for changing program requirements at runtime, (ii) has no software-caching tags, (iii) requires no runtime checks, (iv) has extremely low overheads, and (v) yields 100% predictable memory access times. In this method, data that is about to be accessed frequently is copied into the scratch pad using compiler-inserted code at fixed and infrequent points in the program. Earlier data is evicted if necessary. When compared to a provably optimal static allocation, results show that our scheme reduces runtime by up to 39.8% and energy by up to 31.3%, on average, for our benchmarks, depending on the SRAM size used. The actual gain depends on the SRAM size, but our results show that close to the maximum benefit in runtime and energy is achieved for a substantial range of small SRAM sizes commonly found in embedded systems. Our comparison with a direct mapped cache shows that our method performs roughly as well as a cached architecture.",
    "cited_by_count": 227,
    "openalex_id": "https://openalex.org/W2162528816",
    "type": "article"
  },
  {
    "title": "AIDA",
    "doi": "https://doi.org/10.1145/993396.993406",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Tian He; Brian Blum; John A. Stankovic; Tarek Abdelzaher",
    "corresponding_authors": "",
    "abstract": "Sensor networks, a novel paradigm in distributed wireless communication technology, have been proposed for various applications including military surveillance and environmental monitoring. These systems deploy heterogeneous collections of sensors capable of observing and reporting on various dynamic properties of their surroundings in a time sensitive manner. Such systems suffer bandwidth, energy, and throughput constraints that limit the quantity of information transferred from end-to-end. These factors coupled with unpredictable traffic patterns and dynamic network topologies make the task of designing optimal protocols for such networks difficult. Mechanisms to perform data-centric aggregation utilizing application-specific knowledge provide a means to augmenting throughput, but have limitations due to their lack of adaptation and reliance on application-specific decisions. We, therefore, propose a novel aggregation scheme that adaptively performs application-independent data aggregation in a time sensitive manner. Our work isolates aggregation decisions into a module that resides between the network and the data-link layer and does not require any modifications to the currently existing MAC and network layer protocols. We take advantage of queuing delay and the broadcast nature of wireless communication to concatenate network units into an aggregate using a novel adaptive feedback scheme to schedule the delivery of this aggregate to the MAC layer for transmission. In our evaluation we show that end-to-end transmission delay is reduced by as much as 80% under heavy traffic loads. Additionally, we show as much as a 50% reduction in transmission energy consumption with an overall reduction in header overhead. Theoretical analysis, simulation, and a test-bed implementation on Berkeley's MICA motes are provided to validate our claims.",
    "cited_by_count": 218,
    "openalex_id": "https://openalex.org/W2001965201",
    "type": "article"
  },
  {
    "title": "Compositional real-time scheduling framework with periodic model",
    "doi": "https://doi.org/10.1145/1347375.1347383",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Insik Shin; Insup Lee",
    "corresponding_authors": "",
    "abstract": "It is desirable to develop large complex systems using components based on systematic abstraction and composition. Our goal is to develop a compositional real-time scheduling framework to support abstraction and composition techniques for real-time aspects of components. In this paper, we present a formal description of compositional real-time scheduling problems, which are the component abstraction and composition problems. We identify issues that need be addressed by solutions and provide our framework for the solutions, which is based on the periodic interface . Specifically, we introduce the periodic resource model to characterize resource allocations provided to a single component. We present exact schedulability conditions for the standard Liu and Layland periodic task model and the proposed periodic resource model under EDF and RM scheduling, and we show that the component abstraction and composition problems can be addressed with periodic interfaces through the exact schedulability conditions. We also provide the utilization bounds of a periodic task set over the periodic resource model and the abstraction bounds of periodic interfaces for a periodic task set under EDF and RM scheduling. We finally present the analytical bounds of overheads that our solution incurs in terms of resource utilization increase and evaluate the overheads through simulations.",
    "cited_by_count": 202,
    "openalex_id": "https://openalex.org/W2170600460",
    "type": "article"
  },
  {
    "title": "Safety verification of hybrid systems by constraint propagation-based abstraction refinement",
    "doi": "https://doi.org/10.1145/1210268.1210276",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Stefan Ratschan; Zhikun She",
    "corresponding_authors": "",
    "abstract": "This paper deals with the problem of safety verification of nonlinear hybrid systems. We start from a classical method that uses interval arithmetic to check whether trajectories can move over the boundaries in a rectangular grid. We put this method into an abstraction refinement framework and improve it by developing an additional refinement step that employs interval-constraint propagation to add information to the abstraction without introducing new grid elements. Moreover, the resulting method allows switching conditions, initial states, and unsafe states to be described by complex constraints, instead of sets that correspond to grid elements. Nevertheless, the method can be easily implemented, since it is based on a well-defined set of constraints, on which one can run any constraint propagation-based solver. Tests of such an implementation are promising.",
    "cited_by_count": 184,
    "openalex_id": "https://openalex.org/W1999629321",
    "type": "article"
  },
  {
    "title": "Security on FPGAs",
    "doi": "https://doi.org/10.1145/1015047.1015052",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "Thomas Wollinger; Jorge Guajardo; Christof Paar",
    "corresponding_authors": "",
    "abstract": "In the last decade, it has become apparent that embedded systems are integral parts of our every day lives. The wireless nature of many embedded applications as well as their omnipresence has made the need for security and privacy preserving mechanisms particularly important. Thus, as field programmable gate arrays (FPGAs) become integral parts of embedded systems, it is imperative to consider their security as a whole. This contribution provides a state-of-the-art description of security issues on FPGAs, both from the system and implementation perspectives. We discuss the advantages of reconfigurable hardware for cryptographic applications, show potential security problems of FPGAs, and provide a list of open research problems. Moreover, we summarize both public and symmetric-key algorithm implementations on FPGAs.",
    "cited_by_count": 176,
    "openalex_id": "https://openalex.org/W2012478492",
    "type": "article"
  },
  {
    "title": "An efficient B-tree layer implementation for flash-memory storage systems",
    "doi": "https://doi.org/10.1145/1275986.1275991",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Chin-Hsien Wu; Tei‐Wei Kuo; Li Ping Chang",
    "corresponding_authors": "",
    "abstract": "With the significant growth of the markets for consumer electronics and various embedded systems, flash memory is now an economic solution for storage systems design. Because index structures require intensively fine-grained updates/modifications, block-oriented access over flash memory could introduce a significant number of redundant writes. This might not only severely degrade the overall performance, but also damage the reliability of flash memory. In this paper, we propose a very different approach, which can efficiently handle fine-grained updates/modifications caused by B-tree index access over flash memory. The implementation is done directly over the flash translation layer (FTL); hence, no modifications to existing application systems are needed. We demonstrate that when index structures are adopted over flash memory, the proposed methodology can significantly improve the system performance and, at the same time, reduce both the overhead of flash-memory management and the energy dissipation. The average response time of record insertions and deletions was also significantly reduced.",
    "cited_by_count": 174,
    "openalex_id": "https://openalex.org/W2020930775",
    "type": "article"
  },
  {
    "title": "RapidIO for radar processing in advanced space systems",
    "doi": "https://doi.org/10.1145/1324969.1324970",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "D. Remondo Bueno; Chris Conger; Alan D. George; Ian A. Troxel; Adam Leko",
    "corresponding_authors": "",
    "abstract": "Space-based radar is a suite of applications that presents many unique system design challenges. In this paper, we investigate use of RapidIO, a new high-performance embedded systems interconnect, in addressing issues associated with the high network bandwidth requirements of real-time ground moving target indicator (GMTI), and synthetic aperture Radar (SAR) applications in satellite systems. Using validated simulation, we study several critical issues related to the RapidIO network and algorithms under study. The results show that RapidIO is a promising platform for space-based radar using emerging technology, providing network bandwidth to enable parallel computation previously unattainable in an embedded satellite system.",
    "cited_by_count": 172,
    "openalex_id": "https://openalex.org/W2026029858",
    "type": "article"
  },
  {
    "title": "Optimal voltage allocation techniques for dynamically variable voltage processors",
    "doi": "https://doi.org/10.1145/1053271.1053280",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Woo-Cheol Kwon; Taewhan Kim",
    "corresponding_authors": "",
    "abstract": "This paper presents important, new results of a study on the problem of task scheduling and voltage allocation in dynamically variable voltage processors, the purpose of which was minimization of processor energy consumption. The contributions are twofold: (1) For given multiple discrete supply voltages and tasks with arbitrary arrival-time/deadline constraints, we propose a voltage allocation technique that produces a feasible task schedule with optimal processor energy consumption. (2) We then extend the problem to include the case in which tasks have nonuniform loads (i.e.; switched) capacitances and solve it optimally . The proposed technique, called Alloc-vt, in (1) is based on the prior results in [Yao, Demers and Shenker. 1995. In Proceedings of IEEE Symposium on Foundations of Computer Science . 374--382] (which is optimal for dynamically continuously variable voltages, but not for discrete ones) and [Ishihara and Yasuura. 1998. In Proceedings of International Symposium on Low Power Electronics and Design . 197--202] (which is optimal for a single task, but not for multiple tasks), whereas the proposed technique, called Alloc-vt cap , in (2) is based on an efficient linear programming (LP) formulation. Both techniques solve the allocation problems optimally in polynomial time.",
    "cited_by_count": 169,
    "openalex_id": "https://openalex.org/W2131060015",
    "type": "article"
  },
  {
    "title": "Delite",
    "doi": "https://doi.org/10.1145/2584665",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Arvind K. Sujeeth; Kevin J. Brown; HyoukJoong Lee; Tiark Rompf; Hassan Chafi; Martin Odersky; Kunle Olukotun",
    "corresponding_authors": "",
    "abstract": "Developing high-performance software is a difficult task that requires the use of low-level, architecture-specific programming models (e.g., OpenMP for CMPs, CUDA for GPUs, MPI for clusters). It is typically not possible to write a single application that can run efficiently in different environments, leading to multiple versions and increased complexity. Domain-Specific Languages (DSLs) are a promising avenue to enable programmers to use high-level abstractions and still achieve good performance on a variety of hardware. This is possible because DSLs have higher-level semantics and restrictions than general-purpose languages, so DSL compilers can perform higher-level optimization and translation. However, the cost of developing performance-oriented DSLs is a substantial roadblock to their development and adoption. In this article, we present an overview of the Delite compiler framework and the DSLs that have been developed with it. Delite simplifies the process of DSL development by providing common components, like parallel patterns, optimizations, and code generators, that can be reused in DSL implementations. Delite DSLs are embedded in Scala, a general-purpose programming language, but use metaprogramming to construct an Intermediate Representation (IR) of user programs and compile to multiple languages (including C++, CUDA, and OpenCL). DSL programs are automatically parallelized and different parts of the application can run simultaneously on CPUs and GPUs. We present Delite DSLs for machine learning, data querying, graph analysis, and scientific computing and show that they all achieve performance competitive to or exceeding C++ code.",
    "cited_by_count": 168,
    "openalex_id": "https://openalex.org/W2143609451",
    "type": "article"
  },
  {
    "title": "A reconfigurable FTL (flash translation layer) architecture for NAND flash-based applications",
    "doi": "https://doi.org/10.1145/1376804.1376806",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Chanik Park; Wonmoon Cheon; Jeong‐Uk Kang; Kangho Roh; Wonhee Cho; Jin‐Soo Kim",
    "corresponding_authors": "",
    "abstract": "In this article, a novel FTL (flash translation layer) architecture is proposed for NAND flash-based applications such as MP3 players, DSCs (digital still cameras) and SSDs (solid-state drives). Although the basic function of an FTL is to translate a logical sector address to a physical sector address in flash memory, efficient algorithms of an FTL have a significant impact on performance as well as the lifetime. After the dominant parameters that affect the performance and endurance are categorized, the design space of the FTL architecture is explored based on a diverse workload analysis. With the proposed FTL architectural framework, it is possible to decide which configuration of FTL mapping parameters yields the best performance, depending on the differing characteristics of various NAND flash-based applications.",
    "cited_by_count": 167,
    "openalex_id": "https://openalex.org/W2079623992",
    "type": "article"
  },
  {
    "title": "Energy-Aware Scheduling for Real-Time Systems",
    "doi": "https://doi.org/10.1145/2808231",
    "publication_date": "2016-01-13",
    "publication_year": 2016,
    "authors": "Mario Bambagini; Mauro Marinoni; Hakan Aydın; Giorgio Buttazzo",
    "corresponding_authors": "",
    "abstract": "This article presents a survey of energy-aware scheduling algorithms proposed for real-time systems. The analysis presents the main results starting from the middle 1990s until today, showing how the proposed solutions evolved to address the evolution of the platform's features and needs. The survey first presents a taxonomy to classify the existing approaches for uniprocessor systems, distinguishing them according to the technology exploited for reducing energy consumption, that is, Dynamic Voltage and Frequency Scaling (DVFS), Dynamic Power Management (DPM), or both. Then, the survey discusses the approaches proposed in the literature to deal with the additional problems related to the evolution of computing platforms toward multicore architectures.",
    "cited_by_count": 164,
    "openalex_id": "https://openalex.org/W2233909155",
    "type": "article"
  },
  {
    "title": "HiCH",
    "doi": "https://doi.org/10.1145/3126501",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Iman Azimi; Arman Anzanpour; Amir M. Rahmani; Tapio Pahikkala; Marco Levorato; Pasi Liljeberg; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) paradigm holds significant promises for remote health monitoring systems. Due to their life- or mission-critical nature, these systems need to provide a high level of availability and accuracy. On the one hand, centralized cloud-based IoT systems lack reliability, punctuality and availability (e.g., in case of slow or unreliable Internet connection), and on the other hand, fully outsourcing data analytics to the edge of the network can result in diminished level of accuracy and adaptability due to the limited computational capacity in edge nodes. In this paper, we tackle these issues by proposing a hierarchical computing architecture, HiCH, for IoT-based health monitoring systems. The core components of the proposed system are 1) a novel computing architecture suitable for hierarchical partitioning and execution of machine learning based data analytics, 2) a closed-loop management technique capable of autonomous system adjustments with respect to patient’s condition. HiCH benefits from the features offered by both fog and cloud computing and introduces a tailored management methodology for healthcare IoT systems. We demonstrate the efficacy of HiCH via a comprehensive performance assessment and evaluation on a continuous remote health monitoring case study focusing on arrhythmia detection for patients suffering from CardioVascular Diseases (CVDs).",
    "cited_by_count": 162,
    "openalex_id": "https://openalex.org/W2757855038",
    "type": "article"
  },
  {
    "title": "Probabilistic Temporal Logic Falsification of Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/2465787.2465797",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Houssam Abbas; Georgios Fainekos; Sriram Sankaranarayanan; Franjo Ivančić; Aarti Gupta",
    "corresponding_authors": "",
    "abstract": "We present a Monte-Carlo optimization technique for finding system behaviors that falsify a metric temporal logic (MTL) property. Our approach performs a random walk over the space of system inputs guided by a robustness metric defined by the MTL property. Robustness is guiding the search for a falsifying behavior by exploring trajectories with smaller robustness values. The resulting testing framework can be applied to a wide class of cyber-physical systems (CPS). We show through experiments on complex system models that using our framework can help automatically falsify properties with more consistency as compared to other means, such as uniform sampling.",
    "cited_by_count": 159,
    "openalex_id": "https://openalex.org/W2172184261",
    "type": "article"
  },
  {
    "title": "Spin transfer torque (STT)-MRAM--based runtime reconfiguration FPGA circuit",
    "doi": "https://doi.org/10.1145/1596543.1596548",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Weisheng Zhao; Eric Belhaire; Claude Chappert; P. Mazoyer",
    "corresponding_authors": "",
    "abstract": "As the minimum fabrication technology of CMOS transistor shrink down to 90nm or below, the high standby power has become one of the major critical issues for the SRAM-based FPGA circuit due to the increasing leakage currents in the configuration memory. The integration of MRAM in FPGA instead of SRAM is one of the most promising solutions to overcome this issue, because its nonvolatility and high write/read speed allow to power down completely the logic blocks in “idle” states in the FPGA circuit. MRAM-based FPGA promises as well as some advanced reconfiguration methods such as runtime reconfiguration and multicontext configuration. However, the conventional MRAM technology based on field-induced magnetic switching (FIMS) writing approach consumes very high power, large circuit surface and produces high disturbance between memory cells. These drawbacks prevent FIMS-MRAM's further development in memory and logic circuit. Spin transfer torque (STT)-based MRAM is then evaluated to address these issues, some design techniques and novel computing architecture for FPGA logic circuits based on STT-MRAM technology are presented in this article. By using STMicroelectronics CMOS 90nm technology and a STT-MTJ spice model, some chip characteristic results as the programming latency and power have been calculated and simulated to demonstrate the expected performance of STT-MRAM based FPGA logic circuits.",
    "cited_by_count": 151,
    "openalex_id": "https://openalex.org/W2031539925",
    "type": "article"
  },
  {
    "title": "Throughput maximization for periodic real-time systems under the maximal temperature constraint",
    "doi": "https://doi.org/10.1145/2544375.2544390",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Huang Huang; Vivek Chaturvedi; Gang Quan; Jeffrey Fan; Meikang Qiu",
    "corresponding_authors": "",
    "abstract": "In this article, we study the problem of how to maximize the throughput of a periodic real-time system under a given peak temperature constraint. We assume that different tasks in our system may have different power and thermal characteristics. Two scheduling approaches are presented. The first is built upon processors that can be in either active or sleep mode. By judiciously selecting tasks with different thermal characteristics as well as alternating the processor's active / sleep mode, the sleep period required to cool down the processor is kept at a minimum level, and, as the result, the throughput is maximized. We further extend this approach for processors with dynamic voltage/frequency scaling (DVFS) capability. Our experiments on a large number of synthetic test cases as well as real benchmark programs show that the proposed methods not only consistently outperform the existing approaches in terms of throughput maximization, but also significantly improve the feasibility of tasks when a more stringent temperature constraint is imposed.",
    "cited_by_count": 145,
    "openalex_id": "https://openalex.org/W2208896226",
    "type": "article"
  },
  {
    "title": "ReconOS",
    "doi": "https://doi.org/10.1145/1596532.1596540",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Enno Lübbers; Marco Platzner",
    "corresponding_authors": "",
    "abstract": "Rising logic densities together with the inclusion of dedicated processor cores push reconfigurable devices from being applied for glue logic and prototyping towards implementing complete reconfigurable systems-on-chip. The mix of fast CPU cores and fine-grained reconfigurable logic allows to map both sequential, control-dominated code and highly parallel data-centric computations onto one platform. However, traditional design techniques that view specialized hardware circuits as passive coprocessors are ill-suited for programming these reconfigurable computers. In particular, the programming models for software—running on an embedded operating system—and digital hardware—synthesized to an FPGA—lack commonalities, which hinders design space exploration and severely impairs the potential for code reuse. In this article, we present ReconOS, an execution environment based on existing embedded operating systems that extends the multithreaded programming model established in the software domain to reconfigurable hardware. Using threads and common synchronization and communication services as an abstraction layer, ReconOS allows for the creation of portable and flexible multithreaded applications targeting CPU/FPGA systems. This article discusses the ReconOS programming model and its execution environment, presents implementations based on modern platform FPGAs and the operating systems eCos and Linux, evaluates time and area overheads of the proposed mechanisms and, finally, demonstrates the feasibility of the multithreading design approach on several case studies.",
    "cited_by_count": 137,
    "openalex_id": "https://openalex.org/W1990079240",
    "type": "article"
  },
  {
    "title": "Energy optimization for real-time multiprocessor system-on-chip with optimal DVFS and DPM combination",
    "doi": "https://doi.org/10.1145/2567935",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Gang Chen; Kai Huang; Alois Knoll",
    "corresponding_authors": "",
    "abstract": "Energy optimization is a critical design concern for embedded systems. Combining D VFS +D PM is considered as one preferable technique to reduce energy consumption. There have been optimal D VFS +D PM algorithms for periodic independent tasks running on uniprocessor in the literature. Optimal combination of D VFS and D PM for periodic dependent tasks on multicore systems is however not yet reported. The challenge of this problem is that the idle intervals of cores are not easy to model. In this article, a novel technique is proposed to directly model the idle intervals of individual cores such that both D VFS and D PM can be optimized at the same time. Based on this technique, the energy optimization problem is formulated by means of mixed integrated linear programming. We also present techniques to prune the exploration space of the formulation. Experimental results using real-world benchmarks demonstrate the effectiveness of our approach compared to existing approaches.",
    "cited_by_count": 135,
    "openalex_id": "https://openalex.org/W2056370048",
    "type": "article"
  },
  {
    "title": "ReachNN",
    "doi": "https://doi.org/10.1145/3358228",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Chao Huang; Jiameng Fan; Wenchao Li; Xin Chen; Qi Zhu",
    "corresponding_authors": "",
    "abstract": "Applying neural networks as controllers in dynamical systems has shown great promises. However, it is critical yet challenging to verify the safety of such control systems with neural-network controllers in the loop. Previous methods for verifying neural network controlled systems are limited to a few specific activation functions. In this work, we propose a new reachability analysis approach based on Bernstein polynomials that can verify neural-network controlled systems with a more general form of activation functions, i.e., as long as they ensure that the neural networks are Lipschitz continuous. Specifically, we consider abstracting feedforward neural networks with Bernstein polynomials for a small subset of inputs. To quantify the error introduced by abstraction, we provide both theoretical error bound estimation based on the theory of Bernstein polynomials and more practical sampling based error bound estimation, following a tight Lipschitz constant estimation approach based on forward reachability analysis. Compared with previous methods, our approach addresses a much broader set of neural networks, including heterogeneous neural networks that contain multiple types of activation functions. Experiment results on a variety of benchmarks show the effectiveness of our approach.",
    "cited_by_count": 135,
    "openalex_id": "https://openalex.org/W2980176926",
    "type": "article"
  },
  {
    "title": "Building timing predictable embedded systems",
    "doi": "https://doi.org/10.1145/2560033",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Philip Axer; Rolf Ernst; Heiko Falk; Alain Girault; Daniel Grund; Nan Guan; Bengt Jönsson; Peter Marwedel; Jan Reineke; Christine Rochange; Maurice Sebastian; Reinhard von Hanxleden; Reinhard Wilhelm; Wang Yi",
    "corresponding_authors": "",
    "abstract": "A large class of embedded systems is distinguished from general-purpose computing systems by the need to satisfy strict requirements on timing, often under constraints on available resources. Predictable system design is concerned with the challenge of building systems for which timing requirements can be guaranteed a priori . Perhaps paradoxically, this problem has become more difficult by the introduction of performance-enhancing architectural elements, such as caches, pipelines, and multithreading, which introduce a large degree of uncertainty and make guarantees harder to provide. The intention of this article is to summarize the current state of the art in research concerning how to build predictable yet performant systems. We suggest precise definitions for the concept of “predictability”, and present predictability concerns at different abstraction levels in embedded system design. First, we consider timing predictability of processor instruction sets. Thereafter, we consider how programming languages can be equipped with predictable timing semantics, covering both a language-based approach using the synchronous programming paradigm, as well as an environment that provides timing semantics for a mainstream programming language (in this case C). We present techniques for achieving timing predictability on multicores. Finally, we discuss how to handle predictability at the level of networked embedded systems where randomly occurring errors must be considered.",
    "cited_by_count": 127,
    "openalex_id": "https://openalex.org/W2102481384",
    "type": "article"
  },
  {
    "title": "Optimization of task allocation and priority assignment in hard real-time distributed systems",
    "doi": "https://doi.org/10.1145/2362336.2362352",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Qi Zhu; Haibo Zeng; Wei Zheng; Marco Di Natale; Alberto Sangiovanni‐Vincentelli",
    "corresponding_authors": "",
    "abstract": "The complexity and physical distribution of modern active safety, chassis, and powertrain automotive applications requires the use of distributed architectures. Complex functions designed as networks of function blocks exchanging signal information are deployed onto the physical HW and implemented in a SW architecture consisting of a set of tasks and messages. The typical configuration features priority-based scheduling of tasks and messages and imposes end-to-end deadlines. In this work, we present and compare formulations and procedures for the optimization of the task allocation, the signal to message mapping, and the assignment of priorities to tasks and messages in order to meet end-to-end deadline constraints and minimize latencies. Our formulations leverage worst-case response time analysis within a mixed integer linear optimization framework and are compared for performance against a simulated annealing implementation. The methods are applied for evaluation to an automotive case study of complexity comparable to industrial design problems.",
    "cited_by_count": 125,
    "openalex_id": "https://openalex.org/W2041045065",
    "type": "article"
  },
  {
    "title": "Safety Verification of Cyber-Physical Systems with Reinforcement Learning Control",
    "doi": "https://doi.org/10.1145/3358230",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Hoang-Dung Tran; Feiyang Cai; Manzanas Lopez Diego; Patrick Musau; Taylor T. Johnson; Xenofon Koutsoukos",
    "corresponding_authors": "",
    "abstract": "This paper proposes a new forward reachability analysis approach to verify safety of cyber-physical systems (CPS) with reinforcement learning controllers. The foundation of our approach lies on two efficient, exact and over-approximate reachability algorithms for neural network control systems using star sets, which is an efficient representation of polyhedra. Using these algorithms, we determine the initial conditions for which a safety-critical system with a neural network controller is safe by incrementally searching a critical initial condition where the safety of the system cannot be established. Our approach produces tight over-approximation error and it is computationally efficient, which allows the application to practical CPS with learning enable components (LECs). We implement our approach in NNV, a recent verification tool for neural networks and neural network control systems, and evaluate its advantages and applicability by verifying safety of a practical Advanced Emergency Braking System (AEBS) with a reinforcement learning (RL) controller trained using the deep deterministic policy gradient (DDPG) method. The experimental results show that our new reachability algorithms are much less conservative than existing polyhedra-based approaches. We successfully determine the entire region of the initial conditions of the AEBS with the RL controller such that the safety of the system is guaranteed, while a polyhedra-based approach cannot prove the safety properties of the system.",
    "cited_by_count": 111,
    "openalex_id": "https://openalex.org/W2980176594",
    "type": "article"
  },
  {
    "title": "PROARTIS",
    "doi": "https://doi.org/10.1145/2465787.2465796",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Francisco J. Cazorla; Eduardo Quiñones; Tullio Vardanega; Liliana Cucu; Benoît Triquet; Guillem Bernat; Emery D. Berger; Jaume Abella; Franck Wartel; Michael Houston; Luca Santinelli; Leonidas Kosmidis; Codé Lo; Dorin Maxim",
    "corresponding_authors": "",
    "abstract": "Static timing analysis is the state-of-the-art practice of ascertaining the timing behavior of current-generation real-time embedded systems. The adoption of more complex hardware to respond to the increasing demand for computing power in next-generation systems exacerbates some of the limitations of static timing analysis. In particular, the effort of acquiring (1) detailed information on the hardware to develop an accurate model of its execution latency as well as (2) knowledge of the timing behavior of the program in the presence of varying hardware conditions, such as those dependent on the history of previously executed instructions. We call these problems the timing analysis walls. In this vision-statement article, we present probabilistic timing analysis , a novel approach to the analysis of the timing behavior of next-generation real-time embedded systems. We show how probabilistic timing analysis attacks the timing analysis walls; we then illustrate the mathematical foundations on which this method is based and the challenges we face in the effort of efficiently implementing it. We also present experimental evidence that shows how probabilistic timing analysis reduces the extent of knowledge about the execution platform required to produce probabilistically accurate WCET estimations.",
    "cited_by_count": 110,
    "openalex_id": "https://openalex.org/W2003192087",
    "type": "article"
  },
  {
    "title": "SA-EAST",
    "doi": "https://doi.org/10.1145/2979677",
    "publication_date": "2017-01-02",
    "publication_year": 2017,
    "authors": "Keke Gai; Longfei Qiu; Min Chen; Hui Zhao; Meikang Qiu",
    "corresponding_authors": "",
    "abstract": "The expected advanced network explorations and the growing demand for mobile data sharing and transferring have driven numerous novel applications in Cyber-Physical Systems (CPSs), such as Intelligent Transportation Systems (ITSs). However, current ITS implementations are restricted by the conflicts between security and communication efficiency. Focusing on this issue, this article proposes a Security-Aware Efficient Data Sharing and Transferring (SA-EAST) model, which is designed for securing cloud-based ITS implementations. In applying this approach, we aim to obtain secure real-time multimedia data sharing and transferring. Our experimental evaluation has shown that our proposed model provides an effective performance in securing communications for ITS.",
    "cited_by_count": 94,
    "openalex_id": "https://openalex.org/W2563851203",
    "type": "article"
  },
  {
    "title": "Structural Test Coverage Criteria for Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3358233",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Youcheng Sun; Xiaowei Huang; Daniel Kroening; James J. Sharp; Matthew Q. Hill; Rob Ashmore",
    "corresponding_authors": "",
    "abstract": "Deep neural networks (DNNs) have a wide range of applications, and software employing them must be thoroughly tested, especially in safety-critical domains. However, traditional software test coverage metrics cannot be applied directly to DNNs. In this paper, inspired by the MC/DC coverage criterion, we propose a family of four novel test coverage criteria that are tailored to structural features of DNNs and their semantics. We validate the criteria by demonstrating that test inputs that are generated with guidance by our proposed coverage criteria are able to capture undesired behaviours in a DNN. Test cases are generated using a symbolic approach and a gradient-based heuristic search. By comparing them with existing methods, we show that our criteria achieve a balance between their ability to find bugs (proxied using adversarial examples and correlation with functional coverage) and the computational cost of test input generation. Our experiments are conducted on state-of-the-art DNNs obtained using popular open source datasets, including MNIST, CIFAR-10 and ImageNet.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W2979485058",
    "type": "article"
  },
  {
    "title": "Toward a Lingua Franca for Deterministic Concurrent Systems",
    "doi": "https://doi.org/10.1145/3448128",
    "publication_date": "2021-05-18",
    "publication_year": 2021,
    "authors": "Marten Lohstroh; Christian Menard; Soroush Bateni; Edward A. Lee",
    "corresponding_authors": "",
    "abstract": "Many programming languages and programming frameworks focus on parallel and distributed computing. Several frameworks are based on actors, which provide a more disciplined model for concurrency than threads. The interactions between actors, however, if not constrained, admit nondeterminism. As a consequence, actor programs may exhibit unintended behaviors and are less amenable to rigorous testing. We show that nondeterminism can be handled in a number of ways, surveying dataflow dialects, process networks, synchronous-reactive models, and discrete-event models. These existing approaches, however, tend to require centralized control, pose challenges to modular system design, or introduce a single point of failure. We describe “reactors,” a new coordination model that combines ideas from several of these approaches to enable determinism while preserving much of the style of actors. Reactors promote modularity and allow for distributed execution. By using a logical model of time that can be associated with physical time, reactors also provide control over timing. Reactors also expose parallelism that can be exploited on multicore machines and in distributed configurations without compromising determinacy.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W3160830781",
    "type": "article"
  },
  {
    "title": "TensorRT-Based Framework and Optimization Methodology for Deep Learning Inference on Jetson Boards",
    "doi": "https://doi.org/10.1145/3508391",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Eunjin Jeong; Jangryul Kim; Soonhoi Ha",
    "corresponding_authors": "",
    "abstract": "As deep learning inference applications are increasing in embedded devices, an embedded device tends to equip neural processing units (NPUs) in addition to a multi-core CPU and a GPU. NVIDIA Jetson AGX Xavier is an example. For fast and efficient development of deep learning applications, TensorRT is provided as the SDK for high-performance inference, including an optimizer and runtime that delivers low latency and high throughput for deep learning inference applications. Like most deep learning frameworks, TensorRT assumes that the inference is executed on a single processing element, GPU or NPU, not both. In this article, we present a TensorRT-based framework supporting various optimization parameters to accelerate a deep learning application targeted on an NVIDIA Jetson embedded platform with heterogeneous processors, including multi-threading, pipelining, buffer assignment, and network duplication. Since the design space of allocating layers to diverse processing elements and optimizing other parameters is huge, we devise a parameter optimization methodology that consists of a heuristic for balancing pipeline stages among heterogeneous processors and fine-tuning the process for optimizing parameters. With nine real-life benchmarks, we could achieve 101%~680% performance improvement and up to 55% energy reduction over the baseline inference using a GPU only.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W4210338699",
    "type": "article"
  },
  {
    "title": "Edge-SLAM: Edge-Assisted Visual Simultaneous Localization and Mapping",
    "doi": "https://doi.org/10.1145/3561972",
    "publication_date": "2022-09-12",
    "publication_year": 2022,
    "authors": "Ali J. Ben Ali; Marziye Kouroshli; Sofiya Semenova; Zakieh Sadat Hashemifar; Steven Y. Ko; Karthik Dantu",
    "corresponding_authors": "",
    "abstract": "Localization in urban environments is becoming increasingly important and used in tools such as ARCore [ 18 ], ARKit [ 34 ] and others. One popular mechanism to achieve accurate indoor localization and a map of the space is using Visual Simultaneous Localization and Mapping (Visual-SLAM). However, Visual-SLAM is known to be resource-intensive in memory and processing time. Furthermore, some of the operations grow in complexity over time, making it challenging to run on mobile devices continuously. Edge computing provides additional compute and memory resources to mobile devices to allow offloading tasks without the large latencies seen when offloading to the cloud. In this article, we present Edge-SLAM, a system that uses edge computing resources to offload parts of Visual-SLAM. We use ORB-SLAM2 [ 50 ] as a prototypical Visual-SLAM system and modify it to a split architecture between the edge and the mobile device. We keep the tracking computation on the mobile device and move the rest of the computation, i.e., local mapping and loop closing, to the edge. We describe the design choices in this effort and implement them in our prototype. Our results show that our split architecture can allow the functioning of the Visual-SLAM system long-term with limited resources without affecting the accuracy of operation. It also keeps the computation and memory cost on the mobile device constant, which would allow for the deployment of other end applications that use Visual-SLAM. We perform a detailed performance and resources use (CPU, memory, network, and power) analysis to fully understand the effect of our proposed split architecture.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W4295886237",
    "type": "article"
  },
  {
    "title": "Side-channel Analysis of Lattice-based Post-quantum Cryptography: Exploiting Polynomial Multiplication",
    "doi": "https://doi.org/10.1145/3569420",
    "publication_date": "2022-11-04",
    "publication_year": 2022,
    "authors": "Catinca Mujdei; Lennert Wouters; Angshuman Karmakar; Arthur Beckers; Jose Maria Bermudo Mera; Ingrid Verbauwhede",
    "corresponding_authors": "",
    "abstract": "Polynomial multiplication algorithms such as Toom-Cook and the Number Theoretic Transform are fundamental building blocks for lattice-based post-quantum cryptography. In this work we present correlation power-analysis-based side-channel analysis methodologies targeting every polynomial multiplication strategy for all lattice-based post-quantum key encapsulation mechanisms in the final round of the NIST post-quantum standardization procedure. We perform practical experiments on real side-channel measurements, demonstrating that our method allows to extract the secret key from all lattice-based post-quantum key encapsulation mechanisms. Our analysis shows that the used polynomial multiplication strategy can significantly impact the time complexity of the attack.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W4308198585",
    "type": "article"
  },
  {
    "title": "Cryptographic Engineering a Fast and Efficient SIKE in FPGA",
    "doi": "https://doi.org/10.1145/3584919",
    "publication_date": "2023-02-23",
    "publication_year": 2023,
    "authors": "Rami Elkhatib; Brian Koziel; Reza Azarderakhsh; Mehran Mozaffari Kermani",
    "corresponding_authors": "",
    "abstract": "Recent attacks have shown that SIKE is not secure and should not be used in its current state. However, this work was completed before these attacks were discovered and might be beneficial to other cryptosystems such as SQISign. The primary downside of SIKE is its performance. However, this work achieves new SIKE speed records even using less resources than the state-of-the-art. Our approach entails designing and optimizing a new field multiplier, SIKE-optimized Keccak unit, and high-level controller. On a Xilinx Virtex-7 FPGA, this architecture performs the NIST Level 1 SIKE scheme key encapsulation and key decapsulation functions in 2.23 and 2.39 ms, respectively. The combined key encapsulation and decapsulation time is 4.62 ms, which outperforms the next best Virtex-7 implementation by nearly 2 ms. Our implementation achieves speed records for the NIST Level 1, 2, and 3 parameter sets. Only our NIST Level 5 parameter set was beat by an all-out performance implementation. Our implementations also efficiently utilize the FPGA resources, achieving new records in area-time product metrics for all parameter sets. Overall, this work continues to push the bar for accelerating SIKE computations to make a stronger case for SIKE standardization.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W4321595467",
    "type": "article"
  },
  {
    "title": "Edge-AI-Driven Framework with Efficient Mobile Network Design for Facial Expression Recognition",
    "doi": "https://doi.org/10.1145/3587038",
    "publication_date": "2023-03-06",
    "publication_year": 2023,
    "authors": "Yirui Wu; Lilai Zhang; Zonghua Gu; Hu Lu; Shaohua Wan",
    "corresponding_authors": "",
    "abstract": "Facial Expression Recognition (FER) in the wild poses significant challenges due to realistic occlusions, illumination, scale, and head pose variations of the facial images. In this article, we propose an Edge-AI-driven framework for FER. On the algorithms aspect, we propose two attention modules, Arbitrary-oriented Spatial Pooling (ASP) and Scalable Frequency Pooling (SFP), for effective feature extraction to improve classification accuracy. On the systems aspect, we propose an edge-cloud joint inference architecture for FER to achieve low-latency inference, consisting of a lightweight backbone network running on the edge device, and two optional attention modules partially offloaded to the cloud. Performance evaluation demonstrates that our approach achieves a good balance between classification accuracy and inference latency.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W4323312436",
    "type": "article"
  },
  {
    "title": "Edge Intelligence: Concepts, Architectures, Applications, and Future Directions",
    "doi": "https://doi.org/10.1145/3486674",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Javier Mendez; Kay Bierzynski; Manuel Pegalájar Cuéllar; Diego P. Morales",
    "corresponding_authors": "",
    "abstract": "The name edge intelligence , also known as Edge AI , is a recent term used in the past few years to refer to the confluence of machine learning, or broadly speaking artificial intelligence, with edge computing. In this article, we revise the concepts regarding edge intelligence, such as cloud, edge, and fog computing, the motivation to use edge intelligence, and compare current approaches and analyze application scenarios. To provide a complete review of this technology, previous frameworks and platforms for edge computing have been discussed in this work to provide the general view of the basis for Edge AI. Similarly, the emerging techniques to deploy deep learning models at the network edge, as well as specialized platforms and frameworks to do so, are review in this article. These devices, techniques, and frameworks are analyzed based on relevant criteria at the network edge, such as latency, energy consumption, and accuracy of the models, to determine the current state of the art as well as current limitations of the proposed technologies. Because of this, it is possible to understand the current possibilities to efficiently deploy state-of-the-art deep learning models at the network edge based on technologies such as artificial intelligence accelerators, tensor processing units, and techniques that include federated learning and gossip training. Finally, the challenges of Edge AI are discussed in the work, as well as the future directions that can be extracted from the evolution of the edge computing and Internet of Things approaches.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W4210529452",
    "type": "article"
  },
  {
    "title": "A Survey of Blockchain Data Management Systems",
    "doi": "https://doi.org/10.1145/3502741",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Qian Wei; Bingzhe Li; Wanli Chang; Zhiping Jia; Zhaoyan Shen; Zili Shao",
    "corresponding_authors": "",
    "abstract": "Blockchain has been widely deployed in various fields, such as finance, education, and public services. Blockchain has decentralized mechanisms with persistency and auditability and runs as an immutable distributed ledger, where transactions are jointly performed through cryptocurrency-based consensus algorithms by worldwide distributed nodes. There have been many survey papers reviewing the blockchain technologies from different perspectives, e.g., digital currencies, consensus algorithms, and smart contracts. However, none of them have focused on the blockchain data management systems. To fill in this gap, we have conducted a comprehensive survey on the data management systems, based on three typical types of blockchain, i.e., standard blockchain, hybrid blockchain, and DAG ( Directed Acyclic Graph )-based blockchain. We categorize their data management mechanisms into three layers: blockchain architecture, blockchain data structure, and blockchain storage engine, where block architecture indicates how to record transactions on a distributed ledger, blockchain data structure refers to the internal structure of each block, and blockchain storage engine specifies the storage form of data on the blockchain system. For each layer, the works advancing the state-of-the-art are discussed together with technical challenges. Furthermore, we lay out several possible future research directions for the blockchain data management systems.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W4210763765",
    "type": "article"
  },
  {
    "title": "Side-channel and Fault-injection attacks over Lattice-based Post-quantum Schemes (Kyber, Dilithium): Survey and New Results",
    "doi": "https://doi.org/10.1145/3603170",
    "publication_date": "2023-06-05",
    "publication_year": 2023,
    "authors": "Prasanna Ravi; Anupam Chattopadhyay; Jan-Pieter D’Anvers; Anubhab Baksi",
    "corresponding_authors": "",
    "abstract": "In this work, we present a systematic study of Side-Channel Attacks (SCA) and Fault Injection Attacks (FIA) on structured lattice-based schemes, with main focus on Kyber Key Encapsulation Mechanism (KEM) and Dilithium signature scheme, which are leading candidates in the NIST standardization process for Post-Quantum Cryptography (PQC). Through our study, we attempt to understand the underlying similarities and differences between the existing attacks while classifying them into different categories. Given the wide variety of reported attacks, simultaneous protection against all the attacks requires to implement customized protections/countermeasures for both Kyber and Dilithium. We therefore present a range of customized countermeasures, capable of providing defenses/mitigations against existing SCA/FIA, and incorporate several SCA and FIA countermeasures within a single design of Kyber and Dilithium. Among the several countermeasures discussed in this work, we present novel countermeasures that offer simultaneous protection against several SCA- and FIA-based chosen-ciphertext attacks for Kyber KEM. We implement the presented countermeasures within two well-known public software libraries for PQC: (1) pqm4 library for the ARM Cortex-M4-based microcontroller and (2) liboqs library for the Raspberry Pi 3 Model B Plus based on the ARM Cortex-A53 processor. Our performance evaluation reveals that the presented custom countermeasures incur reasonable performance overheads on both the evaluated embedded platforms. We therefore believe our work argues for usage of custom countermeasures within real-world implementations of lattice-based schemes, either in a standalone manner or as reinforcements to generic countermeasures such as masking.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W4379384493",
    "type": "article"
  },
  {
    "title": "Distributed Task Offloading and Resource Purchasing in NOMA-Enabled Mobile Edge Computing: Hierarchical Game Theoretical Approaches",
    "doi": "https://doi.org/10.1145/3597023",
    "publication_date": "2023-05-16",
    "publication_year": 2023,
    "authors": "Ying Chen; Jie Zhao; Jintao Hu; Shaohua Wan; Jiwei Huang",
    "corresponding_authors": "",
    "abstract": "As the computing resources and the battery capacity of mobile devices are usually limited, it is a feasible solution to offload the computation-intensive tasks generated by mobile devices to edge servers (ESs) in mobile edge computing (MEC) . In this article, we study the multi-user multi-server task offloading problem in MEC systems, where all users compete for the limited communication resources and computing resources. We formulate the offloading problem with the goal of minimizing the cost of the users and maximizing the profits of the ESs. We propose a hierarchical EETORP (Economic and Efficient Task Offloading and Resource Purchasing) framework that includes a two-stage joint optimization process. Then we prove that the problem is NP-complete. For the first stage, we formulate the offloading problem as a multi-channel access game (MCA-Game) and prove theoretically the existence of at least one Nash equilibrium strategy in MCA-Game. Next, we propose a game-based multi-channel access (GMCA) algorithm to obtain the Nash equilibrium strategy and analyze the performance guarantee of the obtained offloading strategy in the worst case. For the second stage, we model the computing resource allocation between the users and ESs by Stackelberg game theory, and reformulate the problem as a resource pricing and purchasing game (PAP-Game). We prove theoretically the property of incentive compatibility and the existence of Stackelberg equilibrium. A game-based pricing and purchasing (GPAP) algorithm is proposed. Finally, a series of both parameter analysis and comparison experiments are carried out, which validate the convergence and effectiveness of the GMCA algorithm and GPAP algorithm.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W4376643890",
    "type": "article"
  },
  {
    "title": "Post-Quantum Signatures on RISC-V with Hardware Acceleration",
    "doi": "https://doi.org/10.1145/3579092",
    "publication_date": "2023-01-06",
    "publication_year": 2023,
    "authors": "Patrick Karl; Jonas Schupp; Tim Fritzmann; Georg Sigl",
    "corresponding_authors": "",
    "abstract": "CRYSTALS-Dilithium and Falcon are digital signature algorithms based on cryptographic lattices, which are considered secure even if large-scale quantum computers will be able to break conventional public-key cryptography. Both schemes have been selected for standardization in the NIST Post-Quantum competition. In this work, we present a RISC-V HW/SW codesign that aims to combine the advantages of software and hardware implementations, i.e., flexibility and performance. It shows the use of flexible hardware accelerators, which have been previously used for Public-Key Encryption (PKE) and Key-Encapsulation Mechanism (KEM), for Post-Quantum signatures. It is optimized for Dilithium as a generic signature scheme but also accelerates applications that require fast verification of Falcon’s compact signatures. We provide a comparison with previous works showing that for Dilithium and Falcon, cycle counts are significantly reduced, such that our design is faster than previous software implementations or other HW/SW codesigns. In addition to that, we present a compact Globalfoundries 22nm ASIC design that runs at 800 MHz. By using hardware acceleration, energy consumption for Dilithium is reduced by up to 92.2%, and up to 67.5% for Falcon’s signature verification.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W4313645570",
    "type": "article"
  },
  {
    "title": "Hardware Trojan Detection Using Machine Learning: A Tutorial",
    "doi": "https://doi.org/10.1145/3579823",
    "publication_date": "2023-01-18",
    "publication_year": 2023,
    "authors": "Kevin Immanuel Gubbi; Banafsheh Saber Latibari; Anirudh Srikanth; Tyler Sheaves; Sayed Arash Beheshti-Shirazi; Sai Manoj PD; Satareh Rafatirad; Avesta Sasan; Houman Homayoun; Soheil Salehi",
    "corresponding_authors": "",
    "abstract": "With the growth and globalization of IC design and development, there is an increase in the number of Designers and Design houses. As setting up a fabrication facility may easily cost upwards of $20 billion, costs for advanced nodes may be even greater. IC design houses that cannot produce their chips in-house have no option but to use external foundries that are often in other countries. Establishing trust with these external foundries can be a challenge, and these foundries are assumed to be untrusted. The use of these untrusted foundries in the global semiconductor supply chain has raised concerns about the security of the fabricated ICs targeted for sensitive applications. One of these security threats is the adversarial infestation of fabricated ICs with a Hardware Trojan (HT) . An HT can be broadly described as a malicious modification to a circuit to control, modify, disable, or monitor its logic. Conventional VLSI manufacturing tests and verification methods fail to detect HT due to the different and un-modeled nature of these malicious modifications. Current state-of-the-art HT detection methods utilize statistical analysis of various side-channel information collected from ICs, such as power analysis, power supply transient analysis, regional supply current analysis, temperature analysis, wireless transmission power analysis, and delay analysis. To detect HTs, most methods require a Trojan-free reference golden IC. A signature from these golden ICs is extracted and used to detect ICs with HTs. However, access to a golden IC is not always feasible. Thus, a mechanism for HT detection is sought that does not require the golden IC. Machine Learning (ML) approaches have emerged to be extremely useful in helping eliminate the need for a golden IC. Recent works on utilizing ML for HT detection have been shown to be promising in achieving this goal. Thus, in this tutorial, we will explain utilizing ML as a solution to the challenge of HT detection. Additionally, we will describe the Electronic Design Automation (EDA) tool flow for automating ML-assisted HT detection. Moreover, to further discuss the benefits of ML-assisted HT detection solutions, we will demonstrate a Neural Network (NN) -assisted timing profiling method for HT detection. Finally, we will discuss the shortcomings and open challenges of ML-assisted HT detection methods.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W4317209778",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Partitioned-RM Scheduling for Shared Resources Imprecise Mixed-Criticality Tasks",
    "doi": "https://doi.org/10.1145/3728641",
    "publication_date": "2025-04-05",
    "publication_year": 2025,
    "authors": "Yi-Wen Zhang; Rong-Kun Chen",
    "corresponding_authors": "",
    "abstract": "Shared resources and energy consumption are important factors to consider in the design of mixed-criticality systems. Existing works have studied these two factors separately. In this article, we simultaneously focus on shared resources and energy consumption on multiprocessor platforms. Firstly, we address the problem of energy-aware scheduling for the fixed-priority imprecise mixed-criticality tasks with shared resources and propose a schedulability test based on the Multiprocessor Priority Ceiling Protocol for a given task-to-processor mapping. Secondly, we calculate the energy-efficient speed of each processor based on the schedulability test and propose the corresponding task-to-processor mapping algorithm, called IMCPA. Finally, we conduct experiments on a real-world case and synthetic tasksets. The experimental results show that IMCPA can improve the schedulability ratio by about 13.76% and save energy consumption by about 34.89% compared to the existing algorithms.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4409182011",
    "type": "article"
  },
  {
    "title": "A Comprehensive Survey on Deep Learning-based Predictive Maintenance",
    "doi": "https://doi.org/10.1145/3732287",
    "publication_date": "2025-04-24",
    "publication_year": 2025,
    "authors": "Uzair Farooq Khan; Dong Seon Cheng; Francesco Setti; Franco Fummi; Marco Cristani; Luigi Capogrosso",
    "corresponding_authors": "",
    "abstract": "With the advent of Industrial 4.0 and the push towards Industry 5.0, the data generated by the industries have become surprisingly large. This abundance of data significantly boosts machine and deep learning models for Predictive Maintenance (PdM). The PdM plays a vital role in extending the lifespan of industrial equipment and machines while also helping to reduce the risk of unscheduled downtime. Given its multidisciplinary nature, the field of PdM has been approached from many different angles: this comprehensive survey aims to provide an up-to-date overview focused on all the learning-based industrial PdM strategies, discussing weaknesses and strengths. The survey is based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodological flow, allowing a systematic and complete review of the literature. In particular, firstly, we explore the main learning models used for PdM, mainly Convolutional Neural Networks (ConvNets), Autoencoders (AEs), Generative Adversarial Networks (GANs), and Transformers, also giving an overview of the newest models such as diffusion models and foundation models. Then, we discuss the main learning paradigms applied to PdM, i.e. , supervised, unsupervised, ensemble, transfer, federated, and reinforcement learning. Furthermore, this work discusses the pipeline of the data-driven PdM and its benefits, practical applications, datasets, and benchmarks. In addition, the evaluation metrics for each PdM stage and the state-of-the-art hardware devices used are discussed. Finally, the challenges and future work are presented.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4409771013",
    "type": "article"
  },
  {
    "title": "Online strategies for dynamic power management in systems with multiple power-saving states",
    "doi": "https://doi.org/10.1145/860176.860180",
    "publication_date": "2003-08-01",
    "publication_year": 2003,
    "authors": "Sandy Irani; Sandeep K. Shukla; Rajesh K. Gupta",
    "corresponding_authors": "",
    "abstract": "Online dynamic power management (DPM) strategies refer to strategies that attempt to make power-mode-related decisions based on information available at runtime. In making such decisions, these strategies do not depend upon information of future behavior of the system, or any a priori knowledge of the input characteristics. In this paper, we present online strategies, and evaluate them based on a measure called the competitive ratio that enables a quantitative analysis of the performance of online strategies. All earlier approaches (online or predictive) have been limited to systems with two power-saving states (e.g., idle and shutdown). The only earlier approaches that handled multiple power-saving states were based on stochastic optimization. This paper provides a theoretical basis for the analysis of DPM strategies for systems with multiple power-down states, without resorting to such complex approaches. We show how a relatively simple \"online learning\" scheme can be used to improve the competitive ratio over deterministic strategies using the notion of \"probability-based\" online DPM strategies. Experimental results show that the algorithm presented here attains the best competitive ratio in comparison with other known predictive DPM algorithms. The other algorithms that come close to matching its performance in power suffer at least an additional 40% wake-up latency on average. Meanwhile, the algorithms that have comparable latency to our methods use at least 25% more power on average.",
    "cited_by_count": 181,
    "openalex_id": "https://openalex.org/W2156886733",
    "type": "article"
  },
  {
    "title": "Translating discrete-time simulink to lustre",
    "doi": "https://doi.org/10.1145/1113830.1113834",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "Stavros Tripakis; Christos Sofronis; Paul Caspi; Adrian Curic",
    "corresponding_authors": "",
    "abstract": "We present a method of translating discrete-time Simulink models to Lustre programs. Our method consists of three steps: type inference, clock inference, and hierarchical bottom-up translation. In the process, we explain and formalize the typing and timing mechanisms of Simulink. The method has been implemented in a prototype tool called S2L, which has been used in the context of a European research project to translate two automotive controller models provided by Audi.",
    "cited_by_count": 156,
    "openalex_id": "https://openalex.org/W2115803389",
    "type": "article"
  },
  {
    "title": "UML-based multiprocessor SoC design framework",
    "doi": "https://doi.org/10.1145/1151074.1151077",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Tero Kangas; Petri Kukkala; Heikki Orsila; Erno Salminen; Marko Hännikäinen; Timo D. Hämäläinen; Jouni Riihimäki; Kimmo Kuusilinna",
    "corresponding_authors": "",
    "abstract": "This paper describes a complete design flow for multiprocessor systems-on-chips (SoCs) covering the design phases from system-level modeling to FPGA prototyping. The design of complex heterogeneous systems is enabled by raising the abstraction level and providing several system-level design automation tools. The system is modeled in a UML design environment following a new UML profile that specifies the practices for orthogonal application and architecture modeling. The design flow tools are governed in a single framework that combines the subtools into a seamless flow and visualizes the design process. Novel features also include an automated architecture exploration based on the system models in UML, as well as the automatic back and forward annotation of information in the design flow. The architecture exploration is based on the global optimization of systems that are composed of subsystems, which are then locally optimized for their particular purposes. As a result, the design flow produces an optimized component allocation, task mapping, and scheduling for the described application. In addition, it implements the entire system for FPGA prototyping board. As a case study, the design flow is utilized in the integration of state-of-the-art technology approaches, including a wireless terminal architecture, a network-on-chip, and multiprocessing utilizing RTOS in a SoC. In this study, a central part of a WLAN terminal is modeled, verified, optimized, and prototyped with the presented framework.",
    "cited_by_count": 150,
    "openalex_id": "https://openalex.org/W2031699358",
    "type": "article"
  },
  {
    "title": "A unified hardware/software runtime environment for FPGA-based reconfigurable computers using BORPH",
    "doi": "https://doi.org/10.1145/1331331.1331338",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Hayden Kwok‐Hay So; R.W. Brodersen",
    "corresponding_authors": "",
    "abstract": "This paper explores the design and implementation of BORPH, an operating system designed for FPGA-based reconfigurable computers. Hardware designs execute as normal UNIX processes under BORPH, having access to standard OS services, such as file system support. Hardware and software components of user designs may, therefore, run as communicating processes within BORPH's runtime environment. The familiar language independent UNIX kernel interface facilitates easy design reuse and rapid application development. To develop hardware designs, a Simulink-based design flow that integrates with BORPH is employed. Performances of BORPH on two on-chip systems implemented on a BEE2 platform are compared.",
    "cited_by_count": 138,
    "openalex_id": "https://openalex.org/W2041958163",
    "type": "article"
  },
  {
    "title": "LiSP",
    "doi": "https://doi.org/10.1145/1015047.1015056",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "Taejoon Park; Kang G. Shin",
    "corresponding_authors": "",
    "abstract": "Small low-cost sensor devices with limited resources are being used widely to build a self-organizing wireless network for various applications, such as situation monitoring and asset surveillance. Making such a sensor network secure is crucial to their intended applications, yet challenging due to the severe resource constraints in each sensor device. We present a lightweight security protocol (LiSP) that makes a tradeoff between security and resource consumption via efficient rekeying. The heart of the protocol is the novel rekeying mechanism that offers (1) efficient key broadcast without requiring retransmission/ACKs, (2) authentication for each key-disclosure without incurring additional overhead, (3) the ability of detecting/recovering lost keys, (4) seamless key refreshment without disrupting ongoing data encryption/decryption, and (5) robustness to inter-node clock skews. Furthermore, these benefits are preserved in conventional contention-based medium access control protocols that do not support reliable broadcast. Our performance evaluation shows that LiSP reduces resource consumption significantly, while requiring only three hash computations, on average, and a storage space for eight keys.",
    "cited_by_count": 128,
    "openalex_id": "https://openalex.org/W2123117681",
    "type": "article"
  },
  {
    "title": "Predicate abstraction for reachability analysis of hybrid systems",
    "doi": "https://doi.org/10.1145/1132357.1132363",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "Rajeev Alur; Thao Dang; Franjo Ivančić",
    "corresponding_authors": "",
    "abstract": "Embedded systems are increasingly finding their way into a growing range of physical devices. These embedded systems often consist of a collection of software threads interacting concurrently with each other and with a physical, continuous environment. While continuous dynamics have been well studied in control theory, and discrete and distributed systems have been investigated in computer science, the combination of the two complexities leads us to the recent research on hybrid systems . This paper addresses the formal analysis of such hybrid systems. Predicate abstraction has emerged to be a powerful technique for extracting finite-state models from infinite-state discrete programs. This paper presents algorithms and tools for reachability analysis of hybrid systems by combining the notion of predicate abstraction with recent techniques for approximating the set of reachable states of linear systems using polyhedra. Given a hybrid system and a set of predicates, we consider the finite discrete quotient whose states correspond to all possible truth assignments to the input predicates. The tool performs an on-the-fly exploration of the abstract system. We present the basic techniques for guided search in the abstract state-space, optimizations of these techniques, implementation of these in our verifier, and case studies demonstrating the promise of the approach. We also address the completeness of our abstraction-based verification strategy by showing that predicate abstraction of hybrid systems can be used to prove bounded safety.",
    "cited_by_count": 116,
    "openalex_id": "https://openalex.org/W1967091946",
    "type": "article"
  },
  {
    "title": "From the prototype to the final embedded system using the Ocarina AADL tool suite",
    "doi": "https://doi.org/10.1145/1376804.1376810",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Jérôme Hugues; Bechir Zalila; Laurent Pautet; Fabrice Kordon",
    "corresponding_authors": "",
    "abstract": "Building distributed deal-time embedded systems requires a stringent methodology, from early requirement capture to full implementation. However, there is a strong link between the requirements and the final implementation (e.g., scheduling and resource dimensioning). Therefore, a rapid prototyping process based on automation of tedious and error-prone tasks (analysis and code generation) is required to speed up the development cycle. In this article, we show how the AADL ( Architecture Analysis and Design Language ), which appeared in late 2004, helps solve these issues thanks to a dedicated tool suite. We then detail the prototyping process and its current implementation: Ocarina.",
    "cited_by_count": 112,
    "openalex_id": "https://openalex.org/W2059902621",
    "type": "article"
  },
  {
    "title": "A Model-Driven Design Framework for Massively Parallel Embedded Systems",
    "doi": "https://doi.org/10.1145/2043662.2043663",
    "publication_date": "2011-11-01",
    "publication_year": 2011,
    "authors": "Abdoulaye Gamatié; Sébastien Le Beux; Éric Piel; Rabie Ben Atitallah; Anne Etien; Philippe Marquet; Jean‐Luc Dekeyser",
    "corresponding_authors": "",
    "abstract": "Modern embedded systems integrate more and more complex functionalities. At the same time, the semiconductor technology advances enable to increase the amount of hardware resources on a chip for the execution. Massively parallel embedded systems specifically deal with the optimized usage of such hardware resources to efficiently execute their functionalities. The design of these systems mainly relies on the following challenging issues: first, how to deal with the parallelism in order to increase the performance; second, how to abstract their implementation details in order to manage their complexity; third, how to refine these abstract representations in order to produce efficient implementations. This article presents the Gaspard design framework for massively parallel embedded systems as a solution to the preceding issues. Gaspard uses the repetitive Model of Computation (MoC), which offers a powerful expression of the regular parallelism available in both system functionality and architecture. Embedded systems are designed at a high abstraction level with the MARTE (Modeling and Analysis of Real-time and Embedded systems) standard profile, in which our repetitive MoC is described by the so-called Repetitive Structure Modeling (RSM) package. Based on the Model-Driven Engineering (MDE) paradigm, MARTE models are refined towards lower abstraction levels, which make possible the design space exploration. By combining all these capabilities, Gaspard allows the designers to automatically generate code for formal verification, simulation and hardware synthesis from high-level specifications of high-performance embedded systems. Its effectiveness is demonstrated with the design of an embedded system for a multimedia application.",
    "cited_by_count": 104,
    "openalex_id": "https://openalex.org/W2000336625",
    "type": "article"
  },
  {
    "title": "Energy-efficient dynamic task scheduling algorithms for DVS systems",
    "doi": "https://doi.org/10.1145/1331331.1331341",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Jianli Zhuo; Chaitali Chakrabarti",
    "corresponding_authors": "",
    "abstract": "Dynamic voltage scaling (DVS) is a well-known low-power design technique that reduces the processor energy by slowing down the DVS processor and stretching the task execution time. However, in a DVS system consisting of a DVS processor and multiple devices, slowing down the processor increases the device energy consumption and thereby the system-level energy consumption. In this paper, we first use system-level energy consideration to derive the “optimal ” scaling factor by which a task should be scaled if there are no deadline constraints. Next, we develop dynamic task-scheduling algorithms that make use of dynamic processor utilization and optimal scaling factor to determine the speed setting of a task. We present algorithm duEDF , which reduces the CPU energy consumption and algorithm duSYS and its reduced preemption version, duSYS_PC , which reduce the system-level energy. Experimental results on the video-phone task set show that when the CPU power is dominant, algorithm duEDF results in up to 45% energy savings compared to the non-DVS case. When the CPU power and device power are comparable, algorithms duSYS and duSYS_PC achieve up to 25% energy saving compared to CPU energy-efficient algorithm duEDF , and up to 12% energy saving over the non-DVS scheduling algorithm. However, if the device power is large compared to the CPU power, then we show that a DVS scheme does not result in lowest energy. Finally, a comparison of the performance of algorithms duSYS and duSYS_PC show that preemption control has minimal effect on system-level energy reduction.",
    "cited_by_count": 104,
    "openalex_id": "https://openalex.org/W2014887248",
    "type": "article"
  },
  {
    "title": "A real-time Java virtual machine with applications in avionics",
    "doi": "https://doi.org/10.1145/1324969.1324974",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Austin Armbruster; Jason D. Baker; Antonio Cunei; Chapman Flack; David Holmes; Filip Pizlo; Edward Pla; Marek Procházka; Jan Vítek",
    "corresponding_authors": "",
    "abstract": "This paper reports on our experience with the implementation of the Real-time Specification for Java on the Ovm open source Java virtual machine. We describe the architecture and main design decisions involved in implementing real-time Java on Ovm. We present the first use of Real-time Java in avionics in the context of control software for a ScanEagle Unmanned Aerial Vehicle.",
    "cited_by_count": 104,
    "openalex_id": "https://openalex.org/W2021682354",
    "type": "article"
  },
  {
    "title": "Sea depth measurement with restricted floating sensors",
    "doi": "https://doi.org/10.1145/2512448",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Mo Li; Zheng Yang; Yunhao Liu",
    "corresponding_authors": "",
    "abstract": "Sea depth monitoring is a critical task for ensuring safe operation of harbors. Traditional schemes largely rely on labor-intensive work and expensive hardware. This study explores the possibility of deploying networked sensors on the surface of the sea, measuring and reporting the sea depth of given areas. We propose a Restricted Floating Sensors (RFS) model in which sensor nodes are anchored to the sea bottom, floating within a restricted area. Distinguished from traditional stationary or mobile sensor networks, the RFS network consists of sensor nodes with restricted mobility. We construct the network model and elaborate the corresponding localization problem. We show that by locating such RFS sensors, the sea depth can be estimated without the help of any extra ranging devices. A prototype system with 25 Telos sensor nodes is deployed to validate this design. We also examine the efficiency and scalability of this design through large-scale simulations.",
    "cited_by_count": 100,
    "openalex_id": "https://openalex.org/W2027867549",
    "type": "article"
  },
  {
    "title": "Thermal-aware task scheduling in 3D chip multiprocessor with real-time constrained workloads",
    "doi": "https://doi.org/10.1145/2423636.2423642",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Jiayin Li; Meikang Qiu; Jianwei Niu; Laurence T. Yang; Yongxin Zhu; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "Chip multiprocessor (CMP) techniques have been implemented in embedded systems due to tremendous computation requirements. Three-dimension (3D) CMP architecture has been studied recently for integrating more functionalities and providing higher performance. The high temperature on chip is a critical issue for the 3D architecture. In this article, we propose an online thermal prediction model for 3D chips. Using this model, we propose novel task scheduling algorithms based on rotation scheduling to reduce the peak temperature on chip. We consider data dependencies, especially inter-iteration dependencies that are not well considered in most of the current thermal-aware task scheduling algorithms. Our simulation results show that our algorithms can efficiently reduce the peak temperature up to 8.1 ˆ C.",
    "cited_by_count": 97,
    "openalex_id": "https://openalex.org/W2073600756",
    "type": "article"
  },
  {
    "title": "Ten Years of Building Broken Chips",
    "doi": "https://doi.org/10.1145/2465787.2465789",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Krishna V. Palem; Avinash Lingamneni",
    "corresponding_authors": "",
    "abstract": "Well over a decade ago, many believed that an engine of growth driving the semiconductor and computing industries---captured nicely by Gordon Moore’s remarkable prophecy (Moore’s law)---was speeding towards a dangerous cliff-edge. Ranging from expressions of concern to doomsday scenarios, the exact time when serious hurdles would beset us varied quite a bit---some of the more optimistic warnings giving Moore’s law until. Needless to say, a lot of people have spent time and effort with great success to find ways for substantially extending the time when we would encounter the dreaded cliff-edge, if not avoiding it altogether. Faced with this issue, we started approaching this in a decidedly different manner---one which suggested falling off the metaphorical cliff as a design choice, but in a controlled way. This resulted in devices that could switch and produce bits that are correct, namely of having the intended value, only with a probabilistic guarantee. As a result, the results could in fact be incorrect. Such devices and associated circuits and computing structures are now broadly referred to as inexact designs, circuits, and architectures. In this article, we will crystallize the essence of inexactness dating back to 2002 through two key principles that we developed: (i) that of admitting error in a design in return for resource savings, and subsequently (ii) making resource investments in the elements of a hardware platform proportional to the value of information they compute. We will also give a broad overview of a range of inexact designs and hardware concepts that our group and other groups around the world have been developing since, based on these two principles. Despite not being deterministically precise, inexact designs can be significantly more efficient in the energy they consume, their speed of execution, and their area needs, which makes them attractive in application contexts that are resilient to error. Significantly, our development of inexactness will be contrasted against the rich backdrop of traditional approaches aimed at realizing reliable computing from unreliable elements, starting with von Neumann’s influential lectures and further developed by Shannon-Weaver and others.",
    "cited_by_count": 93,
    "openalex_id": "https://openalex.org/W2072122809",
    "type": "article"
  },
  {
    "title": "Model checking of software for microcontrollers",
    "doi": "https://doi.org/10.1145/1721695.1721702",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Bastian Schlich",
    "corresponding_authors": "Bastian Schlich",
    "abstract": "The interest of industries in model checking software for microcontrollers is increasing. However, there are currently no appropriate tools that can be applied by embedded systems developers for the direct verification of software for microcontrollers without the need for manual modeling. This article describes a new approach to model checking software for microcontrollers, which verifies the assembly code of the software. The state space is built using a tailored simulator, which abstracts from time, handles nondeterminism, and creates an overapproximation of the behavior shown by the real microcontroller. Within this simulator, we apply abstraction techniques to tackle the state-explosion problem. In our approach, we combine different formal methods, namely, model checking, static analysis, and abstract interpretation. We also combine explicit and symbolic model checking techniques. This article presents a case study using several programs to demonstrate the efficiency of the applied abstraction techniques and to show the applicability of this approach.",
    "cited_by_count": 91,
    "openalex_id": "https://openalex.org/W2126301692",
    "type": "article"
  },
  {
    "title": "On the use of greedy shapers in real-time embedded systems",
    "doi": "https://doi.org/10.1145/2146417.2146418",
    "publication_date": "2012-03-01",
    "publication_year": 2012,
    "authors": "Ernesto Wandeler; A. Maxiaguine; Lothar Thiele",
    "corresponding_authors": "",
    "abstract": "Traffic shaping is a well-known technique in the area of networking and is proven to reduce global buffer requirements and end-to-end delays in networked systems. Due to these properties, shapers also play an increasingly important role in the design of multiprocessor embedded systems that exhibit a considerable amount of on-chip traffic. Despite the growing importance of traffic shapping in this area, no methods exist for analyzing shapers in distributed embedded systems and for incorporating them into a system-level performance analysis. Until now it was not possible to determine the effect of shapers on end-to-end delay guarantees or buffer requirements in such systems. In this work, we present a method for analyzing greedy shapers, and we embed this analysis method into a well-established modular performance analysis framework for real-time embedded systems. The presented approach enables system-level performance analysis of complete systems with greedy shapers, and we prove its applicability by analyzing three case study systems.",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W2007206096",
    "type": "article"
  },
  {
    "title": "Enabling Contactless Detection of Moving Humans with Dynamic Speeds Using CSI",
    "doi": "https://doi.org/10.1145/3157677",
    "publication_date": "2018-01-23",
    "publication_year": 2018,
    "authors": "Kun Qian; Chenshu Wu; Zheng Yang; Yunhao Liu; Fugui He; Tianzhang Xing",
    "corresponding_authors": "",
    "abstract": "Device-free passive detection is an emerging technology to detect whether there exist any moving entities in the areas of interest without attaching any device to them. It is an essential primitive for a broad range of applications including intrusion detection for safety precautions, patient monitoring in hospitals, child and elder care at home, and so forth. Despite the prevalent signal feature Received Signal Strength (RSS), most robust and reliable solutions resort to a finer-grained channel descriptor at the physical layer, e.g., the Channel State Information (CSI) in the 802.11n standard. Among a large body of emerging techniques, however, few of them have explored the full potential of CSI for human detection. Moreover, space diversity supported by nowadays popular multiantenna systems are not investigated to a comparable extent as frequency diversity. In this article, we propose a novel scheme for device-free PAssive Detection of moving humans with dynamic Speed (PADS). Both full information (amplitude and phase) of CSI and space diversity across multiantennas in MIMO systems are exploited to extract and shape sensitive metrics for accuracy and robust target detection. We prototype PADS on commercial WiFi devices, and experiment results in different scenarios demonstrate that PADS achieves great performance improvement in spite of dynamic human movements.",
    "cited_by_count": 86,
    "openalex_id": "https://openalex.org/W2786484969",
    "type": "article"
  },
  {
    "title": "Parallelizing Sequential Programs with Statistical Accuracy Tests",
    "doi": "https://doi.org/10.1145/2465787.2465790",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Saša Misailovíc; Deokhwan Kim; Martin Rinard",
    "corresponding_authors": "",
    "abstract": "We present QuickStep, a novel system for parallelizing sequential programs. Unlike standard parallelizing compilers (which are designed to preserve the semantics of the original sequential computation), QuickStep is instead designed to generate (potentially nondeterministic) parallel programs that produce acceptably accurate results acceptably often. The freedom to generate parallel programs whose output may differ (within statistical accuracy bounds) from the output of the sequential program enables a dramatic simplification of the compiler, a dramatic increase in the range of applications that it can parallelize, and a significant expansion in the range of parallel programs that it can legally generate. Results from our benchmark set of applications show that QuickStep can automatically generate acceptably accurate and efficient parallel programs---the automatically generated parallel versions of five of our six benchmark applications run between 5.0 and 7.8 times faster on eight cores than the original sequential versions. These applications and parallelizations contain features (such as the use of modern object-oriented programming constructs or desirable parallelizations with infrequent but acceptable data races) that place them inherently beyond the reach of standard approaches.",
    "cited_by_count": 83,
    "openalex_id": "https://openalex.org/W2081942292",
    "type": "article"
  },
  {
    "title": "Toward Smart Embedded Systems",
    "doi": "https://doi.org/10.1145/2872936",
    "publication_date": "2016-02-17",
    "publication_year": 2016,
    "authors": "Nikil Dutt; Axel Jantsch; Santanu Sarma",
    "corresponding_authors": "",
    "abstract": "Embedded systems must address a multitude of potentially conflicting design constraints such as resiliency, energy, heat, cost, performance, security, etc., all in the face of highly dynamic operational behaviors and environmental conditions. By incorporating elements of intelligence, the hope is that the resulting “smart” embedded systems will function correctly and within desired constraints in spite of highly dynamic changes in the applications and the environment, as well as in the underlying software/hardware platforms. Since terms related to “smartness” (e.g., self-awareness, self-adaptivity, and autonomy) have been used loosely in many software and hardware computing contexts, we first present a taxonomy of “self-x” terms and use this taxonomy to relate major “smart” software and hardware computing efforts. A major attribute for smart embedded systems is the notion of self-awareness that enables an embedded system to monitor its own state and behavior, as well as the external environment, so as to adapt intelligently. Toward this end, we use a System-on-Chip perspective to show how the CyberPhysical System-on-Chip (CPSoC) exemplar platform achieves self-awareness through a combination of cross-layer sensing, actuation, self-aware adaptations, and online learning. We conclude with some thoughts on open challenges and research directions.",
    "cited_by_count": 83,
    "openalex_id": "https://openalex.org/W2317748259",
    "type": "article"
  },
  {
    "title": "Game-Theory-Based Active Defense for Intrusion Detection in Cyber-Physical Embedded Systems",
    "doi": "https://doi.org/10.1145/2886100",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Kun Wang; Miao Du; Dejun Yang; Chunsheng Zhu; Jian Shen; Yan Zhang",
    "corresponding_authors": "",
    "abstract": "Cyber-Physical Embedded Systems (CPESs) are distributed embedded systems integrated with various actuators and sensors. When it comes to the issue of CPES security, the most significant problem is the security of Embedded Sensor Networks (ESNs). With the continuous growth of ESNs, the security of transferring data from sensors to their destinations has become an important research area. Due to the limitations in power, storage, and processing capabilities, existing security mechanisms for wired or wireless networks cannot apply directly to ESNs. Meanwhile, ESNs are likely to be attacked by different kinds of attacks in industrial scenarios. Therefore, there is a need to develop new techniques or modify the current security mechanisms to overcome these problems. In this article, we focus on Intrusion Detection (ID) techniques and propose a new attack-defense game model to detect malicious nodes using a repeated game approach. As a direct consequence of the game model, attackers and defenders make different strategies to achieve optimal payoffs. Importantly, error detection and missing detection are taken into consideration in Intrusion Detection Systems (IDSs), where a game tree model is introduced to solve this problem. In addition, we analyze and prove the existence of pure Nash equilibrium and mixed Nash equilibrium. Simulations show that the proposed model can both reduce energy consumption by up to 50% compared with the existing All Monitor (AM) model and improve the detection rate by up to 10% to 15% compared with the existing Cluster Head (CH) monitor model.",
    "cited_by_count": 83,
    "openalex_id": "https://openalex.org/W2529866846",
    "type": "article"
  },
  {
    "title": "Trapezius muscle EMG as predictor of mental stress",
    "doi": "https://doi.org/10.1145/2485984.2485987",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Jacqueline Wijsman; Bernard Grundlehner; Julien Penders; Hermie Hermens",
    "corresponding_authors": "",
    "abstract": "Stress is a growing problem in society and can cause musculoskeletal complaints. It would be useful to measure stress for prevention of stress-related health problems. An experiment is described in which EMG signals of the upper trapezius muscle were measured with a wireless system during three different stressful conditions: a calculation task (the Norinder test), a logical puzzle task and a memory task. The latter two tests were newly designed and aimed at creating circumstances that are similar to work stress. Amplitudes of the EMG signals were significantly higher during stress compared to rest (+2.6% of reference contraction level) and relative time with EMG gaps was lower during stress (−14.3% of time). Also, mean and median frequencies were significantly lower during stress than during rest (−8.6 and −8.8 Hz, respectively). EMG amplitude increased not only from rest to stress conditions, but also during stressful conditions and decreased during relaxation periods. EMG features correlated with subjectively indicated stress levels (correlations of 0.32 with RMS and −0.32 with relative gaptime). The results indicate that EMG is a useful parameter to detect stress. Together with other physiological sensors, EMG sensors can be included in a wireless system for ambulatory monitoring of stress levels.",
    "cited_by_count": 81,
    "openalex_id": "https://openalex.org/W1969050256",
    "type": "article"
  },
  {
    "title": "Parallel Reconfigurable Computing-Based Mapping Algorithm for Motion Estimation in Advanced Video Coding",
    "doi": "https://doi.org/10.1145/2331147.2331149",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Anand Paul; Yung-Chuan Jiang; Jhing-Fa Wang; Jar‐Ferr Yang",
    "corresponding_authors": "",
    "abstract": "Computational load of motion estimation in advanced video coding (AVC) standard is significantly high and even worse for HDTV and super-resolution sequences. In this article, a video processing algorithm is dynamically mapped onto a new parallel reconfigurable computing (PRC) architecture which consists of multiple dynamic reconfigurable computing (DRC) units. First, we construct a directed acyclic graph (DAG) to represent video coding algorithms in which motion estimation is the focus. A novel parallel partition approach is then proposed to map motion estimation DAG onto the multiple DRC units in a PRC system. This partitioning algorithm is capable of design optimization of parallel processing reconfigurable systems for a given number of processing elements in different search ranges. This speeds up the video processing with minimum sacrifice.",
    "cited_by_count": 78,
    "openalex_id": "https://openalex.org/W2015398052",
    "type": "article"
  },
  {
    "title": "dMazeRunner",
    "doi": "https://doi.org/10.1145/3358198",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Shail Dave; Youngbin Kim; Sasikanth Avancha; Kyoungwoo Lee; Aviral Shrivastava",
    "corresponding_authors": "",
    "abstract": "Dataflow accelerators feature simplicity, programmability, and energy-efficiency and are visualized as a promising architecture for accelerating perfectly nested loops that dominate several important applications, including image and media processing and deep learning. Although numerous accelerator designs are being proposed, how to discover the most efficient way to execute the perfectly nested loop of an application onto computational and memory resources of a given dataflow accelerator ( execution method ) remains an essential and yet unsolved challenge. In this paper, we propose dMazeRunner -- to efficiently and accurately explore the vast space of the different ways to spatiotemporally execute a perfectly nested loop on dataflow accelerators (execution methods). The novelty of dMazeRunner framework is in: i) a holistic representation of the loop nests, that can succinctly capture the various execution methods, ii) accurate energy and performance models that explicitly capture the computation and communication patterns, data movement, and data buffering of the different execution methods, and iii) drastic pruning of the vast search space by discarding invalid solutions and the solutions that lead to the same cost. Our experiments on various convolution layers (perfectly nested loops) of popular deep learning applications demonstrate that the solutions discovered by dMazeRunner are on average 9.16× better in Energy-Delay-Product (EDP) and 5.83× better in execution time, as compared to prior approaches. With additional pruning heuristics, dMazeRunner reduces the search time from days to seconds with a mere 2.56% increase in EDP, as compared to the optimal solution.",
    "cited_by_count": 77,
    "openalex_id": "https://openalex.org/W2979644612",
    "type": "article"
  },
  {
    "title": "DLSeF",
    "doi": "https://doi.org/10.1145/2937755",
    "publication_date": "2016-12-19",
    "publication_year": 2016,
    "authors": "Deepak Puthal; ‪Surya Nepal‬; Rajiv Ranjan; Jinjun Chen",
    "corresponding_authors": "",
    "abstract": "Applications in risk-critical domains such as emergency management and industrial control systems need near-real-time stream data processing in large-scale sensing networks. The key problem is how to ensure online end-to-end security (e.g., confidentiality, integrity, and authenticity) of data streams for such applications. We refer to this as an online security verification problem. Existing data security solutions cannot be applied in such applications as they cannot deal with data streams with high-volume and high-velocity data in real time. They introduce a significant buffering delay during security verification, resulting in a requirement for a large buffer size for the stream processing server. To address this problem, we propose a Dynamic Key-Length-Based Security Framework (DLSeF) based on a shared key derived from synchronized prime numbers; the key is dynamically updated at short intervals to thwart potential attacks to ensure end-to-end security. Theoretical analyses and experimental results of the DLSeF framework show that it can significantly improve the efficiency of processing stream data by reducing the security verification time and buffer usage without compromising security.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2561357874",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Modeling and Verification of Discrete Event Systems",
    "doi": "https://doi.org/10.1145/2406336.2406337",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Mohamed Khalgui; Zhiwu Li",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 73,
    "openalex_id": "https://openalex.org/W2017196860",
    "type": "article"
  },
  {
    "title": "CUDA Leaks",
    "doi": "https://doi.org/10.1145/2801153",
    "publication_date": "2016-01-13",
    "publication_year": 2016,
    "authors": "Roberto Di Pietro; Flavio Lombardi; Antonio Villani",
    "corresponding_authors": "",
    "abstract": "Graphics Processing Units (GPUs) are deployed on most present server, desktop, and even mobile platforms. Nowadays, a growing number of applications leverage the high parallelism offered by this architecture to speed-up general purpose computation. This phenomenon is called GPGPU computing (General Purpose GPU computing). The aim of this work is to discover and highlight security issues related to CUDA, the most widespread platform for GPGPU computing. In particular, we provide details and proofs-of-concept about a novel set of vulnerabilities CUDA architectures are subject to, that could be exploited to cause severe information leak. Following (detailed) intuitions rooted on sound engineering security, we performed several experiments targeting the last two generations of CUDA devices: Fermi and Kepler. We discovered that these two families do suffer from information leakage vulnerabilities. In particular, some vulnerabilities are shared between the two architectures, while others are idiosyncratic of the Kepler architecture. As a case study, we report the impact of one of these vulnerabilities on a GPU implementation of the AES encryption algorithm. We also suggest software patches and alternative approaches to tackle the presented vulnerabilities. To the best of our knowledge this is the first work showing that information leakage in CUDA is possible using just standard CUDA instructions. We expect our work to pave the way for further research in the field.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W3102569685",
    "type": "article"
  },
  {
    "title": "A Hybrid Task Mapping Algorithm for Heterogeneous MPSoCs",
    "doi": "https://doi.org/10.1145/2680542",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Wei Quan; Andy D. Pimentel",
    "corresponding_authors": "",
    "abstract": "The application workloads in modern MPSoC-based embedded systems are becoming increasingly dynamic. Different applications concurrently execute and contend for resources in such systems, which could cause serious changes in the intensity and nature of the workload demands over time. To cope with the dynamism of application workloads at runtime and improve the efficiency of the underlying system architecture, this article presents a hybrid task mapping algorithm that combines a static mapping exploration and a dynamic mapping optimization to achieve an overall improvement of system efficiency. We evaluate our algorithm using a heterogeneous MPSoC system with three real applications. Experimental results reveal the effectiveness of our proposed algorithm by comparing derived solutions to the ones obtained from several other runtime mapping algorithms. In test cases with three simultaneously active applications, the mapping solutions derived by our approach have average performance improvements ranging from 45.9% to 105.9% and average energy savings ranging from 14.6% to 23.5%.",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W2081166696",
    "type": "article"
  },
  {
    "title": "Persistent Clocks for Batteryless Sensing Devices",
    "doi": "https://doi.org/10.1145/2903140",
    "publication_date": "2016-08-02",
    "publication_year": 2016,
    "authors": "Josiah Hester; Nicole Tobias; Amir Rahmati; Lanny Sitanayah; Daniel Holcomb; Kevin Fu; Wayne Burleson; Jacob Sorber",
    "corresponding_authors": "",
    "abstract": "Sensing platforms are becoming batteryless to enable the vision of the Internet of Things, where trillions of devices collect data, interact with each other, and interact with people. However, these batteryless sensing platforms—that rely purely on energy harvesting—are rarely able to maintain a sense of time after a power failure. This makes working with sensor data that is time sensitive especially difficult. We propose two novel, zero-power timekeepers that use remanence decay to measure the time elapsed between power failures. Our approaches compute the elapsed time from the amount of decay of a capacitive device, either on-chip Static Random-Access Memory (SRAM) or a dedicated capacitor. This enables hourglass-like timers that give intermittently powered sensing devices a persistent sense of time. Our evaluation shows that applications using either timekeeper can keep time accurately through power failures as long as 45s with low overhead.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W2482690451",
    "type": "article"
  },
  {
    "title": "NQA",
    "doi": "https://doi.org/10.1145/3330139",
    "publication_date": "2019-07-02",
    "publication_year": 2019,
    "authors": "Xiaokang Wang; Laurence T. Yang; Hong-Guo Li; Man Lin; Jian-Jun Han; Bernady O. Apduhan",
    "corresponding_authors": "",
    "abstract": "Radio frequency identification (RFID) systems, as one of the key components in the Internet of Things (IoT), have attracted much attention in the domains of industry and academia. In practice, the performance of RFID systems rather relies on the effectiveness and efficiency of anti-collision algorithms. A large body of studies have recently focused on the anti-collision algorithms, such as the Q-algorithm ( QA ), which has been successfully utilized in EPCglobal Class-1 Generation-2 protocol. However, the performance of those anti-collision algorithms needs to be further improved. Observe that fully exploiting the pre-processing time can improve the efficiency of the QA algorithm. With an objective of improving the performance for anti-collision, we propose a Nested Q-algorithm ( NQA ), which makes full use of such pre-processing time and incorporates the advantages of both Binary Tree ( BT ) algorithm and QA algorithm. Specifically, based on the expected number of collision tags, the NQA algorithm can adaptively select either BT or QA to identify collision tags. Extensive simulation results validate the efficiency and effectiveness of our proposed NQA (i.e., less running time for processing the same number of active tags) when compared to the existing algorithms.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W2954613285",
    "type": "article"
  },
  {
    "title": "Invasive Tightly-Coupled Processor Arrays",
    "doi": "https://doi.org/10.1145/2584660",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Frank Hannig; Vahid Lari; Srinivas Boppu; Alexandru Tanase; Oliver Reiche",
    "corresponding_authors": "",
    "abstract": "We introduce a novel class of massively parallel processor architectures called invasive Tightly-Coupled Processor Arrays (TCPAs). The presented processor class is a highly parameterizable template which can be tailored before runtime to fulfill costumers' requirements such as performance, area cost, and energy efficiency. These programmable accelerators are well suited for domain-specific computing from the areas of signal, image, and video processing as well as other streaming processing applications. To overcome future scaling issues (e.g., power consumption, reliability, resource management, as well as application parallelization and mapping), TCPAs are inherently designed in way that they support self-adaptivity and resource awareness at hardware level. Here, we follow a recently introduced resource-aware parallel computing paradigm called invasive computing where an application can dynamically claim, execute, and release the resources. Furthermore, we show how invasive computing can be used as an enabler for power management. For the first time, we present a seamless mapping flow for TCPAs, based on a domain-specific language. Moreover, we outline a complete symbolic mapping approach. Finally, we support our claims by comparing a TCPA against an ARM Mali-T604 GPU in terms of performance and energy efficiency.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W1970340536",
    "type": "article"
  },
  {
    "title": "Attack-Resilient Sensor Fusion for Safety-Critical Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/2847418",
    "publication_date": "2016-02-20",
    "publication_year": 2016,
    "authors": "Radoslav Ivanov; Miroslav Pajić; Insup Lee",
    "corresponding_authors": "",
    "abstract": "This article focuses on the design of safe and attack-resilient Cyber-Physical Systems (CPS) equipped with multiple sensors measuring the same physical variable. A malicious attacker may be able to disrupt system performance through compromising a subset of these sensors. Consequently, we develop a precise and resilient sensor fusion algorithm that combines the data received from all sensors by taking into account their specified precisions. In particular, we note that in the presence of a shared bus, in which messages are broadcast to all nodes in the network, the attacker’s impact depends on what sensors he has seen before sending the corrupted measurements. Therefore, we explore the effects of communication schedules on the performance of sensor fusion and provide theoretical and experimental results advocating for the use of the Ascending schedule, which orders sensor transmissions according to their precision starting from the most precise. In addition, to improve the accuracy of the sensor fusion algorithm, we consider the dynamics of the system in order to incorporate past measurements at the current time. Possible ways of mapping sensor measurement history are investigated in the article and are compared in terms of the confidence in the final output of the sensor fusion. We show that the precision of the algorithm using history is never worse than the no-history one, while the benefits may be significant. Furthermore, we utilize the complementary properties of the two methods and show that their combination results in a more precise and resilient algorithm. Finally, we validate our approach in simulation and experiments on a real unmanned ground robot.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W2207856858",
    "type": "article"
  },
  {
    "title": "Optimizing Deep Learning Inference on Embedded Systems Through Adaptive Model Selection",
    "doi": "https://doi.org/10.1145/3371154",
    "publication_date": "2020-01-31",
    "publication_year": 2020,
    "authors": "Vicent Sanz Marco; Ben Taylor; Zheng Wang; Yehia Elkhatib",
    "corresponding_authors": "",
    "abstract": "Deep neural networks (DNNs) are becoming a key enabling technique for many application domains. However, on-device inference on battery-powered, resource-constrained embedding systems is often infeasible due to prohibitively long inferencing time and resource requirements of many DNNs. Offloading computation into the cloud is often unacceptable due to privacy concerns, high latency, or the lack of connectivity. Although compression algorithms often succeed in reducing inferencing times, they come at the cost of reduced accuracy. This article presents a new, alternative approach to enable efficient execution of DNNs on embedded devices. Our approach dynamically determines which DNN to use for a given input by considering the desired accuracy and inference time. It employs machine learning to develop a low-cost predictive model to quickly select a pre-trained DNN to use for a given input and the optimization constraint. We achieve this first by offline training a predictive model and then using the learned model to select a DNN model to use for new, unseen inputs. We apply our approach to two representative DNN domains: image classification and machine translation. We evaluate our approach on a Jetson TX2 embedded deep learning platform and consider a range of influential DNN models including convolutional and recurrent neural networks. For image classification, we achieve a 1.8x reduction in inference time with a 7.52% improvement in accuracy over the most capable single DNN model. For machine translation, we achieve a 1.34x reduction in inference time over the most capable single model with little impact on the quality of translation.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W3004633656",
    "type": "article"
  },
  {
    "title": "MARS: mmWave-based Assistive Rehabilitation System for Smart Healthcare",
    "doi": "https://doi.org/10.1145/3477003",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Sizhe An; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "Rehabilitation is a crucial process for patients suffering from motor disorders. The current practice is performing rehabilitation exercises under clinical expert supervision. New approaches are needed to allow patients to perform prescribed exercises at their homes and alleviate commuting requirements, expert shortages, and healthcare costs. Human joint estimation is a substantial component of these programs since it offers valuable visualization and feedback based on body movements. Camera-based systems have been popular for capturing joint motion. However, they have high-cost, raise serious privacy concerns, and require strict lighting and placement settings. We propose a millimeter-wave (mmWave)-based assistive rehabilitation system (MARS) for motor disorders to address these challenges. MARS provides a low-cost solution with a competitive object localization and detection accuracy. It first maps the 5D time-series point cloud from mmWave to a lower dimension. Then, it uses a convolution neural network (CNN) to estimate the accurate location of human joints. MARS can reconstruct 19 human joints and their skeleton from the point cloud generated by mmWave radar. We evaluate MARS using ten specific rehabilitation movements performed by four human subjects involving all body parts and obtain an average mean absolute error of 5.87 cm for all joint positions. To the best of our knowledge, this is the first rehabilitation movements dataset using mmWave point cloud. MARS is evaluated on the Nvidia Jetson Xavier-NX board. Model inference takes only 64 <?TeX $\\mu$?> s and consumes 442 <?TeX $\\mu$?> J energy. These results demonstrate the practicality of MARS on low-power edge devices.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W3201387271",
    "type": "article"
  },
  {
    "title": "MHDeep: Mental Health Disorder Detection System Based on Wearable Sensors and Artificial Neural Networks",
    "doi": "https://doi.org/10.1145/3527170",
    "publication_date": "2022-03-26",
    "publication_year": 2022,
    "authors": "Shayan Hassantabar; Joe Zhang; Hongxu Yin; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Mental health problems impact the quality of life of millions of people around the world. However, diagnosis of mental health disorders is a challenging problem that often relies on self-reporting by patients about their behavioral patterns and social interactions. Therefore, there is a need for new strategies for diagnosis and daily monitoring of mental health conditions. The recent introduction of body-area networks consisting of a plethora of accurate sensors embedded in smartwatches and smartphones and edge-compatible deep neural networks (DNNs) points toward a possible solution. Such wearable medical sensors (WMSs) enable continuous monitoring of physiological signals in a passive and non-invasive manner. However, disease diagnosis based on WMSs and DNNs, and their deployment on edge devices, such as smartphones, remains a challenging problem. These challenges stem from the difficulty of feature engineering and knowledge distillation from the raw sensor data, as well as the computational and memory constraints of battery-operated edge devices. To this end, we propose a framework called MHDeep that utilizes commercially available WMSs and efficient DNN models to diagnose three important mental health disorders: schizoaffective, major depressive, and bipolar. MHDeep uses eight different categories of data obtained from sensors integrated in a smartwatch and smartphone. These categories include various physiological signals and additional information on motion patterns and environmental variables related to the wearer. MHDeep eliminates the need for manual feature engineering by directly operating on the data streams obtained from participants. Because the amount of data is limited, MHDeep uses a synthetic data generation module to augment real data with synthetic data drawn from the same probability distribution. We use the synthetic dataset to pre-train the weights of the DNN models, thus imposing a prior on the weights. We use a grow-and-prune DNN synthesis approach to learn both architecture and weights during the training process. We use three different data partitions to evaluate the MHDeep models trained with data collected from 74 individuals. We conduct two types of evaluations: at the data instance level and at the patient level. MHDeep achieves an average test accuracy, across the three data partitions, of 90.4%, 87.3%, and 82.4%, respectively, for classifications between healthy and schizoaffective disorder instances, healthy and major depressive disorder instances, and healthy and bipolar disorder instances. At the patient level, MHDeep DNN models achieve an accuracy of 100%, 100%, and 90.0% for the three mental health disorders, respectively, based on inference that uses 40, 16, and 22 minutes of sensor data collection from each patient.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W4220822781",
    "type": "article"
  },
  {
    "title": "CAN Bus Intrusion Detection Based on Auxiliary Classifier GAN and Out-of-distribution Detection",
    "doi": "https://doi.org/10.1145/3540198",
    "publication_date": "2022-06-03",
    "publication_year": 2022,
    "authors": "Qingling Zhao; Mingqiang Chen; Zonghua Gu; Siyu Luan; Haibo Zeng; Samarjit Chakrabory",
    "corresponding_authors": "",
    "abstract": "The Controller Area Network (CAN) is a ubiquitous bus protocol present in the Electrical/Electronic (E/E) systems of almost all vehicles. It is vulnerable to a range of attacks once the attacker gains access to the bus through the vehicle’s attack surface. We address the problem of Intrusion Detection on the CAN bus and present a series of methods based on two classifiers trained with Auxiliary Classifier Generative Adversarial Network (ACGAN) to detect and assign fine-grained labels to Known Attacks and also detect the Unknown Attack class in a dataset containing a mixture of (Normal + Known Attacks + Unknown Attack) messages. The most effective method is a cascaded two-stage classification architecture, with the multi-class Auxiliary Classifier in the first stage for classification of Normal and Known Attacks, passing Out-of-Distribution (OOD) samples to the binary Real-Fake Classifier in the second stage for detection of the Unknown Attack class. Performance evaluation demonstrates that our method achieves both high classification accuracy and low runtime overhead, making it suitable for deployment in the resource-constrained in-vehicle environment.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W4281702766",
    "type": "article"
  },
  {
    "title": "Deep Ensemble Learning for Human Activity Recognition Using Wearable Sensors via Filter Activation",
    "doi": "https://doi.org/10.1145/3551486",
    "publication_date": "2022-07-26",
    "publication_year": 2022,
    "authors": "Wenbo Huang; Lei Zhang; Shuoyuan Wang; Hao Wu; Aiguo Song",
    "corresponding_authors": "",
    "abstract": "During the past decade, human activity recognition ( HAR ) using wearable sensors has become a new research hot spot due to its extensive use in various application domains such as healthcare, fitness, smart homes, and eldercare. Deep neural networks, especially convolutional neural networks ( CNNs ), have gained a lot of attention in HAR scenario. Despite exceptional performance, CNNs with heavy overhead is not the best option for HAR task due to the limitation of computing resource on embedded devices. As far as we know, there are many invalid filters in CNN that contribute very little to output. Simply pruning these invalid filters could effectively accelerate CNNs , but it inevitably hurts performance. In this article, we first propose a novel CNN for HAR that uses filter activation. In comparison with filter pruning that is motivated for efficient consideration, filter activation aims to activate these invalid filters from an accuracy boosting perspective. We perform extensive experiments on several public HAR datasets, namely, UCI-HAR ( UCI ), OPPORTUNITY ( OPPO ), UniMiB-SHAR ( Uni ), PAMAP2 ( PAM2 ), WISDM ( WIS ), and USC-HAD ( USC ), which show the superiority of the proposed method against existing state-of-the-art ( SOTA ) approaches. Ablation studies are conducted to analyze its internal mechanism. Finally, the inference speed and power consumption are evaluated on an embedded Raspberry Pi Model 3 B plus platform.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W4287982304",
    "type": "article"
  },
  {
    "title": "A Configurable CRYSTALS-Kyber Hardware Implementation with Side-Channel Protection",
    "doi": "https://doi.org/10.1145/3587037",
    "publication_date": "2023-03-06",
    "publication_year": 2023,
    "authors": "Arpan Jati; Naina Gupta; Anupam Chattopadhyay; Somitra Kumar Sanadhya",
    "corresponding_authors": "",
    "abstract": "In this work, we present a configurable and side channel resistant implementation of the post-quantum key-exchange algorithm CRYSTALS-Kyber . The implemented design can be configured for different performance and area requirements leading to different trade-offs for different applications. A low area implementation can be achieved in 5,269 LUTs and 2,422 FFs, whereas a high performance implementation required 7,151 LUTs and 3,730 FFs. Due to a deeply pipelined architecture, a high operating speed of more than 250 MHz could be achieved on 28nm Xilinx FPGAs. The side channel resistance is implemented using a carefully chosen set of novel and known techniques such as Fault Detection Hashes, Instruction Randomization, FSM Protection and so on. resulting in a low overhead of less than 5% while being highly configurable. To the best of our knowledge, this work presents the first side-channel and fault attack protected configurable accelerator for CRYSTALS-Kyber . Using TVLA (test vector leakage assessment), we validate the implemented protection techniques and demonstrate that the design does not leak information even after 200 K traces. Furthermore, one of the configuration choices results in the smallest hardware implementation of CRYSTALS-Kyber known in the literature.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3201868317",
    "type": "article"
  },
  {
    "title": "DNN Inference Acceleration Based on Adaptive Task Partitioning and Offloading in Embedded VEC",
    "doi": "https://doi.org/10.1145/3725734",
    "publication_date": "2025-03-21",
    "publication_year": 2025,
    "authors": "Chunlin Li; Sen Liu; Kun Jiang; Mengjie Yang; Zihao Zhang; Bingxin Wang; Liang Zhao; Chen Chen; Shaohua Wan",
    "corresponding_authors": "",
    "abstract": "As a distributed embedded system, vehicular edge computing (VEC) completes various complex Deep neural network (DNN) tasks through network collaboration and communication. However,due to the limited computing power of vehicle processors, vehicles cannot handle increasingly complex DNN tasks. To accurately estimate the execution latency of each layer across different DNN models on heterogeneous devices, we proposed the Extreme Gradient Boosting Tree (XGBoost) algorithm to predict DNN task inference latency. Furthermore, we proposed partitioning and offloading algorithms for both chained DNN tasks and Directed Acyclic Graph (DAG)-type DNN tasks, addressing their unique computational characteristics. For chained DNN tasks, we employ a linear search to determine optimal partitioning points based on predictions from the DNN latency prediction model. For the partitioning and offloading of DAG-type DNN tasks, we construct it as a minimum cut problem under the network flow graph and propose a DNN task partitioning and offloading algorithm based on the highest label pre-stream push (HLPP) algorithm to effectively reduce the cost of task partitioning and offloading. Finally, we used an experimental vehicle equipped with Raspberry and a RSU equipped with Jetson Nano to verify the results. The experiment shows that the DNN latency prediction model based on the XGBoost we proposed can effectively improve the latency prediction accuracy of DNN layer-by-layer execution. At the same time, the division and offloading algorithms for different types of DNN inference tasks can achieve higher task completion rate, lower latency, and lower energy consumption.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4408719512",
    "type": "article"
  },
  {
    "title": "On energy-optimal voltage scheduling for fixed-priority hard real-time systems",
    "doi": "https://doi.org/10.1145/860176.860183",
    "publication_date": "2003-08-01",
    "publication_year": 2003,
    "authors": "Han-Saem Yun; Jihong Kim",
    "corresponding_authors": "",
    "abstract": "We address the problem of energy-optimal voltage scheduling for fixed-priority hard real-time systems, on which we present a complete treatment both theoretically and practically. Although most practical real-time systems are based on fixed-priority scheduling, there have been few research results known on the energy-optimal fixed-priority scheduling problem. First, we prove that the problem is NP-hard. Then, we present a fully polynomial time approximation scheme (FPTAS) for the problem. For any ε &gt; 0, the proposed approximation scheme computes a voltage schedule whose energy consumption is at most (1 + ε) times that of the optimal voltage schedule. Furthermore, the running time of the proposed approximation scheme is bounded by a polynomial function of the number of input jobs and 1/ε. Given the NP-hardness of the problem, the proposed approximation scheme is practically the best solution because it can compute a near-optimal voltage schedule (i.e., provably arbitrarily close to the optimal schedule) in polynomial time. Experimental results show that the approximation scheme finds more efficient (almost optimal) voltage schedules faster than the best existing heuristic.",
    "cited_by_count": 108,
    "openalex_id": "https://openalex.org/W2001861238",
    "type": "article"
  },
  {
    "title": "Energy savings and speedups from partitioning critical software loops to hardware in embedded systems",
    "doi": "https://doi.org/10.1145/972627.972637",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Greg Stitt; Frank Vahid; Shawn Nematbakhsh",
    "corresponding_authors": "",
    "abstract": "We present results of extensive hardware/software partitioning experiments on numerous benchmarks. We describe our loop-oriented partitioning methodology for moving critical code from hardware to software. Our benchmarks included programs from PowerStone, MediaBench, and NetBench. Our experiments included estimated results for partitioning using an 8051 8-bit microcontroller or a 32-bit MIPS microprocessor for the software, and using on-chip configurable logic or custom application-specific integrated circuit hardware for the hardware. Additional experiments involved actual measurements taken from several physical implementations of hardware/software partitionings on real single-chip microprocessor/configurable-logic devices. We also estimated results assuming voltage scalable processors. We provide performance, energy, and size data for all of the experiments. We found that the benchmarks spent an average of 80% of their execution time in only 3% of their code, amounting to only about 200 bytes of critical code. For various experiments, we found that moving critical code to hardware resulted in average speedups of 3 to 5 and average energy savings of 35% to 70%, with average hardware requirements of only 5000 to 10,000 gates. To our knowledge, these experiments represent the most comprehensive hardware/software partitioning study published to date.",
    "cited_by_count": 107,
    "openalex_id": "https://openalex.org/W2071576608",
    "type": "article"
  },
  {
    "title": "A design methodology for application-specific networks-on-chip",
    "doi": "https://doi.org/10.1145/1151074.1151076",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Jiang Xu; Wayne Wolf; Joerg Henkel; Srimat Chakradhar",
    "corresponding_authors": "",
    "abstract": "With the help of HW/SW codesign, system-on-chip (SoC) can effectively reduce cost, improve reliability, and produce versatile products. The growing complexity of SoC designs makes on-chip communication subsystem design as important as computation subsystem design. While a number of codesign methodologies have been proposed for on-chip computation subsystems, many works are needed for on-chip communication subsystems. This paper proposes application-specific networks-on-chip (ASNoC) and its design methodology. ASNoC is used for two high-performance SoC applications. The methodology (1) can automatically generate optimized ASNoC for different applications, (2) can generate a corresponding distributed shared memory along with an ASNoC, (3) can use both recorded and statistical communication traces for cycle-accurate performance analysis, (4) is based on standardized network component library and floorplan to estimate power and area, (5) adapts an industrial-grade network modeling and simulation environment, OPNET, which makes the methodology ready to use, and (6) can be easily integrated into current HW/SW codesign flow. Using the methodology, ASNoC is generated for a H.264 HDTV decoder SoC and Smart Camera SoC. ASNoC and 2D mesh networks-on-chip are compared in performance, power, and area in detail. The comparison results show that ASNoC provide substantial improvements in power, performance, and cost compared to 2D mesh networks-on-chip. In the H.264 HDTV decoder SoC, ASNoC uses 39% less power, 59% less silicon area, 74% less metal area, 63% less switch capacity, and 69% less interconnection capacity to achieve 2X performance compared to 2D mesh networks-on-chip.",
    "cited_by_count": 103,
    "openalex_id": "https://openalex.org/W2088512458",
    "type": "article"
  },
  {
    "title": "Statistics and secret leakage",
    "doi": "https://doi.org/10.1145/1015047.1015050",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "Jean-Sébastien Coron; David Naccache; Paul Kocher",
    "corresponding_authors": "",
    "abstract": "In addition to its usual complexity assumptions, cryptography silently assumes that information can be physically protected in a single location. As one can easily imagine, real-life devices are not ideal and information may leak through different physical channels.This paper gives a rigorous definition of leakage immunity and presents several leakage detection tests. In these tests, failure confirms the probable existence of secret-correlated emanations and indicates how likely the leakage is. Success does not refute the existence of emanations but indicates that significant emanations were not detected on the strength of the evidence presented , which of course, leaves the door open to reconsider the situation if further evidence comes to hand at a later date.",
    "cited_by_count": 102,
    "openalex_id": "https://openalex.org/W2156817460",
    "type": "article"
  },
  {
    "title": "Adaptive scheduling server for power-aware real-time tasks",
    "doi": "https://doi.org/10.1145/993396.993400",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Pedro Mejía-Álvarez; Eugene Levner; Daniel Mossé",
    "corresponding_authors": "",
    "abstract": "In this paper, we propose a novel scheduling framework for a dynamic real-time environment with energy constraints. This framework dynamically adjusts the CPU voltage/frequency so that no task in the system misses its deadline and the total energy savings of the system are maximized. In this paper, we consider only realistic, discrete-level speeds.Each task in the system consumes a certain amount of energy, which depends on a speed chosen for execution. The process of selecting speeds for execution while maximizing the energy savings of the system requires the exploration of a large number of combinations, which is too time consuming to be computed online. Thus, we propose an integrated heuristic methodology, which executes an optimization procedure in a low computation time. This scheme allows the scheduler to handle power-aware real-time tasks with low cost while maximizing the use of the available resources and without jeopardizing the temporal constraints of the system. Simulation results show that our heuristic methodology is able to generate power-aware scheduling solutions with near-optimal performance.",
    "cited_by_count": 101,
    "openalex_id": "https://openalex.org/W2167285292",
    "type": "article"
  },
  {
    "title": "A fast string-matching algorithm for network processor-based intrusion detection system",
    "doi": "https://doi.org/10.1145/1015047.1015055",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "Rong-Tai Liu; Nen-Fu Huang; Chih‐Hao Chen; Chia-Nan Kao",
    "corresponding_authors": "",
    "abstract": "Network intrusion detection systems (NIDSs) are one of the latest developments in security. The matching of packet strings against collected signatures dominates signature-based NIDS performance. Network processors are also one of the fastest growing segments of the semiconductor market, because they are designed to provide scalable and flexible solutions that can accommodate change quickly and economically. This work presents a fast string-matching algorithm (called FNP) over the network processor platform that conducts matching sets of patterns in parallel. This design also supports numerous practical features such as case-sensitive string matching, signature prioritization, and multiple-content signatures. This efficient multiple-pattern matching algorithm utilizes the hardware facilities provided by typical network processors instead of employing the external lookup co-processors. To verify the efficiency and practicability of the proposed algorithm, it was implemented on the Vitesse IQ2000 network processor platform. The searching patterns used in the present experiments are derived from the well-known Snort ruleset cited by most open-source and commercial NIDSs. This work shows that combining our string-matching methodology, hashing engine supported by most network processors, and characteristics of current Snort signatures frequently improves performance and reduces number of memory accesses compared to conventional string-matching algorithms. Another contribution of this work is to highlight that, besides total number of searching patterns, shortest pattern length is also a major influence on NIDS multipattern matching algorithm performance.",
    "cited_by_count": 100,
    "openalex_id": "https://openalex.org/W2003648673",
    "type": "article"
  },
  {
    "title": "EnviroSuite",
    "doi": "https://doi.org/10.1145/1165780.1165782",
    "publication_date": "2006-08-01",
    "publication_year": 2006,
    "authors": "Liqian Luo; Tarek Abdelzaher; Tian He; John A. Stankovic",
    "corresponding_authors": "",
    "abstract": "Sensor networks open a new frontier for embedded-distributed computing. Paradigms for sensor network programming-in-the-large have been identified as a significant challenge toward developing large-scale applications. Classical programming languages are too low-level. This paper presents the design, implementation, and evaluation of EnviroSuite , a programming framework that introduces a new paradigm, called environmentally immersive programming , to abstract distributed interactions with the environment. Environmentally immersive programming refers to an object-based programming model in which individual objects represent physical elements in the external environment. It allows the programmer to think directly in terms of environmental abstractions. EnviroSuite provides language primitives for environmentally immersive programming that map transparently into a support library of distributed algorithms for tracking and environmental monitoring. We show how nesC code of realistic applications is significantly simplified using EnviroSuite and demonstrate the resulting system performance on Mica2 and XSM platforms.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W2153841912",
    "type": "article"
  },
  {
    "title": "A highly configurable cache for low energy embedded systems",
    "doi": "https://doi.org/10.1145/1067915.1067921",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "Chuanjun Zhang; Frank Vahid; Walid Najjar",
    "corresponding_authors": "",
    "abstract": "Energy consumption is a major concern in many embedded computing systems. Several studies have shown that cache memories account for about 50% of the total energy consumed in these systems. The performance of a given cache architecture is determined, to a large degree, by the behavior of the application executing on the architecture. Desktop systems have to accommodate a very wide range of applications and therefore the cache architecture is usually set by the manufacturer as a best compromise given current applications, technology, and cost. Unlike desktop systems, embedded systems are designed to run a small range of well-defined applications. In this context, a cache architecture that is tuned for that narrow range of applications can have both increased performance as well as lower energy consumption. We introduce a novel cache architecture intended for embedded microprocessor platforms. The cache has three software-configurable parameters that can be tuned to particular applications. First, the cache's associativity can be configured to be direct-mapped, two-way, or four-way set-associative, using a novel technique we call way concatenation . Second, the cache's total size can be configured by shutting down ways. Finally, the cache's line size can be configured to have 16, 32, or 64 bytes. A study of 23 programs drawn from Powerstone, MediaBench, and Spec2000 benchmark suites shows that the configurable cache tuned to each program saved energy for every program compared to a conventional four-way set-associative cache as well as compared to a conventional direct-mapped cache, with an average savings of energy related to memory access of over 40%.",
    "cited_by_count": 97,
    "openalex_id": "https://openalex.org/W2039914356",
    "type": "article"
  },
  {
    "title": "Improving security for periodic tasks in embedded systems through scheduling",
    "doi": "https://doi.org/10.1145/1275986.1275992",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Tao Xie; Xiao Qin",
    "corresponding_authors": "",
    "abstract": "While many scheduling algorithms for periodic tasks ignore security requirements posed by sensitive applications and are, consequently, unable to perform properly in embedded systems with security constraints, in this paper, we present an approach to scheduling periodic tasks in embedded systems subject to security and timing constraints. We design a necessary and sufficient feasibility check for a set of periodic tasks with security requirements. With the feasibility test in place, we propose a scheduling algorithm, or SASES (security-aware scheduling for embedded systems), which accounts for both security and timing requirements. SASES judiciously distributes slack times among a variety of security services for a set of periodic tasks, thereby optimizing security for embedded systems without sacrificing schedulability. To demonstrate the effectiveness of SASES, we apply the proposed SASES to real-world embedded systems such as an automated flight control system. We show, through extensive simulations, that SASES is able to maximize security for embedded systems while guaranteeing timeliness. In particular, SASES significantly improves security over three baseline algorithms by up to 107%.",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W2103707436",
    "type": "article"
  },
  {
    "title": "Superblock FTL",
    "doi": "https://doi.org/10.1145/1721695.1721706",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Dawoon Jung; Jeong‐Uk Kang; Heeseung Jo; Jin‐Soo Kim; Joonwon Lee",
    "corresponding_authors": "",
    "abstract": "In NAND flash-based storage systems, an intermediate software layer called a Flash Translation Layer (FTL) is usually employed to hide the erase-before-write characteristics of NAND flash memory. We propose a novel superblock-based FTL scheme, which combines a set of adjacent logical blocks into a superblock. In the proposed Superblock FTL, superblocks are mapped at coarse granularity, while pages inside the superblock are mapped freely at fine granularity to any location in several physical blocks. To reduce extra storage and flash memory operations, the fine-grain mapping information is stored in the spare area of NAND flash memory. This hybrid address translation scheme has the flexibility provided by fine-grain address translation, while reducing the memory overhead to the level of coarse-grain address translation. Our experimental results show that the proposed FTL scheme significantly outperforms previous block-mapped FTL schemes with roughly the same memory overhead.",
    "cited_by_count": 78,
    "openalex_id": "https://openalex.org/W1984275681",
    "type": "article"
  },
  {
    "title": "Minimizing CPU energy in real-time systems with discrete speed management",
    "doi": "https://doi.org/10.1145/1550987.1550994",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Enrico Bini; Giorgio Buttazzo; Giuseppe Lipari",
    "corresponding_authors": "",
    "abstract": "This article presents a general framework to analyze and design embedded systems minimizing the energy consumption without violating timing requirements. A set of realistic assumptions is considered in the model in order to apply the results in practical real-time applications. The processor is assumed to have as a set of discrete operating modes, each characterized by speed and power consumption. The energy overhead and the transition delay incurred during mode switches are considered. Task computation times are modeled with a part that scales with the speed and a part having a fixed duration, to take I/O operations into account. The proposed method allows to compute the optimal sequence of voltage/speed changes that approximates the minimum continuous speed, which guarantees the feasibility of a given set of real-time tasks, without violating the deadline constraints. The analysis is performed both under fixed and dynamic priority assignments.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W2004220906",
    "type": "article"
  },
  {
    "title": "BeepBeep",
    "doi": "https://doi.org/10.1145/2146417.2146421",
    "publication_date": "2012-03-01",
    "publication_year": 2012,
    "authors": "Chunyi Peng; Guobin Shen; Yongguang Zhang",
    "corresponding_authors": "",
    "abstract": "We present the design and implementation of BeepBeep, a high-accuracy acoustic-based system for ranging and localization. It is a pure software-based solution and uses the most basic set of commodity hardware -- a speaker, a microphone, and some form of interdevice communication. The ranging scheme works without any infrastructure and is applicable to sensor platforms and commercial-off-the-shelf mobile devices. It achieves high accuracy through three techniques: two-way sensing , self-recording , and sample counting . We further devise a scalable and fast localization scheme. Our experiments show that up to one-centimeter ranging accuracy and three-centimeter localization accuracy can be achieved.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W2111165378",
    "type": "article"
  },
  {
    "title": "Miniaturized wireless ECG monitor for real-time detection of epileptic seizures",
    "doi": "https://doi.org/10.1145/2485984.2485990",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Fabien Massé; Martien van Bussel; Aline Serteyn; Johan Arends; Julien Penders",
    "corresponding_authors": "",
    "abstract": "Recent advances in miniaturization of ultra-low power components allow for more intelligent wearable health monitors. The development and evaluation of a wireless wearable electrocardiogram (ECG) monitor to detect epileptic seizures from changes in the cardiac rhythm is described. The ECG data are analyzed by embedded algorithms: a robust beat-detection algorithm combined with a real-time epileptic seizure detector. In its current implementation, the proposed prototype is 52× 36× 15mm 3 , and has an autonomy of one day. Based on data collected on the first three epilepsy patients, preliminary clinical results are provided. Wireless, miniaturized and comfortable, this prototype opens new perspectives for health monitoring.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W1976321635",
    "type": "article"
  },
  {
    "title": "A real-time Java chip-multiprocessor",
    "doi": "https://doi.org/10.1145/1814539.1814548",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Christof Pitter; Martin Schoeberl",
    "corresponding_authors": "",
    "abstract": "Chip-multiprocessors are an emerging trend for embedded systems. In this article, we introduce a real-time Java multiprocessor called JopCMP. It is a symmetric shared-memory multiprocessor, and consists of up to eight Java Optimized Processor (JOP) cores, an arbitration control device, and a shared memory. All components are interconnected via a system on chip bus. The arbiter synchronizes the access of multiple CPUs to the shared main memory. In this article, three different arbitration policies are presented, evaluated, and compared with respect to their real-time and average-case performance: a fixed priority, a fair-based, and a time-sliced arbiter. Tasks running on different CPUs of a chip-multiprocessor (CMP) influence each others' execution times when accessing a shared memory. Therefore, the system needs an arbiter that is able to limit the worst-case execution time of a task running on a CPU, even though tasks executing simultaneously on other CPUs access the main memory. Our research shows that timing analysis is in fact possible for homogeneous multiprocessor systems with a shared memory. The timing analysis of tasks, executing on the CMP using time-sliced memory arbitration, leads to viable worst-case execution time bounds. The time-sliced arbiter divides the memory access time into equal time slots, one time slot for each CPU. This memory arbitration scheme allows for a calculation of upper bounds of Java application worst-case execution times, depending on the number of CPUs, the time slot size, and the memory access time. Examples of worst-case execution time calculation are presented, and the analyzed results of a real-world application task are compared to measured execution time results. Finally, we evaluate the tradeoffs when using a time-predictable solution compared to using average-case optimized chip-multiprocessors, applying three different benchmarks. These experiments are carried out by executing the programs on the CMP prototype.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W2057433895",
    "type": "article"
  },
  {
    "title": "Synchronous dataflow scenarios",
    "doi": "https://doi.org/10.1145/1880050.1880052",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Marc Geilen",
    "corresponding_authors": "Marc Geilen",
    "abstract": "The Synchronous Dataflow (SDF) model of computation by Lee and Messerschmitt has become popular for modeling concurrent applications on a multiprocessor platform. It is used to obtain a guaranteed, predictable performance. The model, on the other hand, is quite restrictive in its expressivity, making it less applicable to many modern, more dynamic applications. A common technique to deal with dynamic behavior is to consider different scenarios in separation. This analysis is, however, currently limited mainly to sequential applications. In this article, we present a new analysis approach that allows analysis of synchronous dataflow models across different scenarios of operation. The dataflow graphs corresponding to the different scenarios can be completely different. Execution times, consumption and production rates and the structure of the SDF may change. Our technique allows to derive or prove worst-case performance guarantees of the resulting model and as such extends the model-driven approach to designing predictable systems to significantly more dynamic applications and platforms. The approach is illustrated with three MP3 and MPEG-4 related case studies.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W2104150063",
    "type": "article"
  },
  {
    "title": "<scp>metro</scp> II",
    "doi": "https://doi.org/10.1145/2435227.2435245",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Abhijit Davare; Douglas Densmore; Liangpeng Guo; Roberto Passerone; Alberto Sangiovanni‐Vincentelli; Alena Simalatsar; Qi Zhu",
    "corresponding_authors": "",
    "abstract": "Cyber-Physical Systems are integrations of computation and physical processes and as such, will be increasingly relevant to industry and people. The complexity of designing CPS resides in their heterogeneity. Heterogeneity manifest itself in modeling their functionality as well as in the implementation platforms that include a multiplicity of components such as microprocessors, signal processors, peripherals, memories, sensors and actuators often integrated on a single chip or on a small package such as a multi-chip module. We need a methodology, tools and environments where heterogeneity can be dealt with at all levels of abstraction and where different tools can be integrated. We present here Platform-Based Design as the CPS methodology of choice and metro II, a design environment that supports it. We present the metamodeling approach followed in metro II, how to couple the functionality and implementation platforms of CPS, and the simulation technology that supports the analysis of CPS and of their implementation. We also present examples of use and the integration of metro II with another popular design environment developed at Verimag, BIP.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W1992160941",
    "type": "article"
  },
  {
    "title": "Design Optimization of Mixed-Criticality Real-Time Embedded Systems",
    "doi": "https://doi.org/10.1145/2700103",
    "publication_date": "2015-04-30",
    "publication_year": 2015,
    "authors": "Domiţian Tămaş–Selicean; Paul Pop",
    "corresponding_authors": "",
    "abstract": "In this article, we are interested in implementing mixed-criticality real-time embedded applications on a given heterogeneous distributed architecture. Applications have different criticality levels, captured by their Safety-Integrity Level (SIL), and are scheduled using static-cyclic scheduling. According to certification standards, mixed-criticality tasks can be integrated onto the same architecture only if there is enough spatial and temporal separation among them. We consider that the separation is provided by partitioning, such that applications run in separate partitions, and each partition is allocated several time slots on a processor. Tasks of different SILs can share a partition only if they are all elevated to the highest SIL among them. Such elevation leads to increased development costs, which increase dramatically with each SIL. Tasks of higher SILs can be decomposed into redundant structures of lower SIL tasks. We are interested to determine (i) the mapping of tasks to processors, (ii) the assignment of tasks to partitions, (iii) the decomposition of tasks into redundant lower SIL tasks, (iv) the sequence and size of the partition time slots on each processor, and (v) the schedule tables, such that all the applications are schedulable and the development costs are minimized. We have proposed a Tabu Search-based approach to solve this optimization problem. The proposed algorithm has been evaluated using several synthetic and real-life benchmarks.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W2055433515",
    "type": "article"
  },
  {
    "title": "Near optimal rate selection for wireless control systems",
    "doi": "https://doi.org/10.1145/2584652",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Abusayeed Saifullah; Chengjie Wu; Paras Babu Tiwari; You Xu; Yongqing Fu; Chenyang Lu; Yixin Chen",
    "corresponding_authors": "",
    "abstract": "With the advent of industrial standards such as WirelessHART, process industries are now gravitating towards wireless control systems. Due to limited bandwidth in a wireless network shared by multiple control loops, it is critical to optimize the overall control performance. In this article, we address the scheduling-control co-design problem of determining the optimal sampling rates of feedback control loops sharing a WirelessHART network. The objective is to minimize the overall control cost while ensuring that all data flows meet their end-to-end deadlines. The resulting constrained optimization based on existing delay bounds for WirelessHART networks is challenging since it is nondifferentiable, nonlinear, and not in closed-form. We propose four methods to solve this problem. First, we present a subgradient method for rate selection. Second, we propose a greedy heuristic that usually achieves low control cost while significantly reducing the execution time. Third, we propose a global constrained optimization algorithm using a simulated annealing (SA) based penalty method. We study SA method under both constant factor penalty and adaptive penalty. Finally, we formulate rate selection as a differentiable convex optimization problem that provides a quick solution through a convex optimization technique. This is based on a new delay bound that is convex and differentiable, and hence simplifies the optimization problem. We study both the gradient descent method and the interior point method to solve it. We evaluate all methods through simulations based on topologies of a 74-node wireless sensor network testbed. The subgradient method is disposed to incur the longest execution time as well as the highest control cost among all methods. Among the SA-based constant penalty method, the greedy heuristic, and the gradient descent method, the first two represent the opposite ends of the tradeoff between control cost and execution time, while the third one hits the balance between the two. We further observe that the SA based adaptive penalty method is superior to the constant penalty method, and that the interior point method is superior to the gradient method. Thus, the interior point method and the SA-based adaptive penalty method are the two most effective approaches for rate selection. While both methods are competitive against each other in terms of control cost, the interior point method is significantly faster than the penalty method. As a result, the interior point method upon convex relaxation is more suitable for online rate adaptation than the SA based adaptive penalty method due to their significant difference in run-time efficiency.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W1976184177",
    "type": "article"
  },
  {
    "title": "Adaptive Power Management in Solar Energy Harvesting Sensor Node Using Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3126495",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Shaswot Shresthamali; Masaaki Kondo; Hiroshi Nakamura",
    "corresponding_authors": "",
    "abstract": "In this paper, we present an adaptive power manager for solar energy harvesting sensor nodes. We use a simplified model consisting of a solar panel, an ideal battery and a general sensor node with variable duty cycle. Our power manager uses Reinforcement Learning (RL), specifically SARSA(λ) learning, to train itself from historical data. Once trained, we show that our power manager is capable of adapting to changes in weather, climate, device parameters and battery degradation while ensuring near-optimal performance without depleting or overcharging its battery. Our approach uses a simple but novel general reward function and leverages the use of weather forecast data to enhance performance. We show that our method achieves near perfect energy neutral operation (ENO) with less than 6% root mean square deviation from ENO as compared to more than 23% deviation that occur when using other approaches.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W2756881949",
    "type": "article"
  },
  {
    "title": "Modeling and Analysis of Fault Detection and Fault Tolerance in Wireless Sensor Networks",
    "doi": "https://doi.org/10.1145/2680538",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Arslan Munir; Joseph Antoon; Ross Gordon",
    "corresponding_authors": "",
    "abstract": "Technological advancements in communications and embedded systems have led to the proliferation of Wireless Sensor Networks (WSNs) in a wide variety of application domains. These application domains include but are not limited to mission-critical (e.g., security, defense, space, satellite) or safety-related (e.g., health care, active volcano monitoring) systems. One commonality across all WSN application domains is the need to meet application requirements (e.g., lifetime, reliability). Many application domains require that sensor nodes be deployed in harsh environments, such as on the ocean floor or in an active volcano, making these nodes more prone to failures. Sensor node failures can be catastrophic for critical or safety-related systems. This article models and analyzes fault detection and fault tolerance in WSNs. To determine the effectiveness and accuracy of fault detection algorithms, we simulate these algorithms using ns-2. We investigate the synergy between fault detection and fault tolerance and use the fault detection algorithms’ accuracies in our modeling of Fault-Tolerant (FT) WSNs. We develop Markov models for characterizing WSN reliability and Mean Time to Failure (MTTF) to facilitate WSN application-specific design. Results obtained from our FT modeling reveal that an FT WSN composed of duplex sensor nodes can result in as high as a 100% MTTF increase and approximately a 350% improvement in reliability over a Non-Fault-Tolerant (NFT) WSN. The article also highlights future research directions for the design and deployment of reliable and trustworthy WSNs.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W1986841165",
    "type": "article"
  },
  {
    "title": "Testing Cyber-Physical Systems through Bayesian Optimization",
    "doi": "https://doi.org/10.1145/3126521",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Jyotirmoy V. Deshmukh; Marko Horvat; Xiaoqing Jin; Rupak Majumdar; Vinayak S. Prabhu",
    "corresponding_authors": "",
    "abstract": "Many problems in the design and analysis of cyber-physical systems (CPS) reduce to the following optimization problem: given a CPS which transforms continuous-time input traces in R m to continuous-time output traces in R n and a cost function over output traces, find an input trace which minimizes the cost. Cyber-physical systems are typically so complex that solving the optimization problem analytically by examining the system dynamics is not feasible. We consider a black-box approach, where the optimization is performed by testing the input-output behaviour of the CPS. We provide a unified, tool-supported methodology for CPS testing and optimization. Our tool is the first CPS testing tool that supports Bayesian optimization. It is also the first to employ fully automated dimensionality reduction techniques. We demonstrate the potential of our tool by running experiments on multiple industrial case studies. We compare the effectiveness of Bayesian optimization to state-of-the-art testing techniques based on CMA-ES and Simulated Annealing.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2759950027",
    "type": "article"
  },
  {
    "title": "METEOR",
    "doi": "https://doi.org/10.1145/2567940",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Shirish Bahirat; Sudeep Pasricha",
    "corresponding_authors": "",
    "abstract": "With increasing application complexity and improvements in process technology, Chip MultiProcessors (CMPs) with tens to hundreds of cores on a chip are becoming a reality. Networks-on-Chip (NoCs) have emerged as scalable communication fabrics that can support high bandwidths for these massively parallel multicore systems. However, traditional electrical NoC implementations still need to overcome the challenges of high data transfer latencies and large power consumption. On-chip photonic interconnects with high performance-per-watt characteristics have recently been proposed as an alternative to address these challenges for intra-chip communication. In this article, we explore using low-cost photonic interconnects on a chip to enhance traditional electrical NoCs. Our proposed hybrid photonic ring-mesh NoC (METEOR) utilizes a configurable photonic ring waveguide coupled to a traditional 2D electrical mesh NoC. Experimental results indicate a strong motivation to consider the proposed architecture for future CMPs, as it can provide about 5× reduction in power consumption and improved throughput and access latencies, compared to traditional electrical 2D mesh and torus NoC architectures. Compared to other previously proposed hybrid photonic NoC fabrics such as the hybrid photonic torus, Corona, and Firefly, our proposed fabric is also shown to have lower photonic area overhead, power consumption, and energy-delay product, while maintaining competitive throughput and latency.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W1997342630",
    "type": "article"
  },
  {
    "title": "Reinforcement Learning-Assisted Garbage Collection to Mitigate Long-Tail Latency in SSD",
    "doi": "https://doi.org/10.1145/3126537",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Wonkyung Kang; Dongkun Shin; Sungjoo Yoo",
    "corresponding_authors": "",
    "abstract": "NAND flash memory is widely used in various systems, ranging from real-time embedded systems to enterprise server systems. Because the flash memory has erase-before-write characteristics, we need flash-memory management methods, i.e., address translation and garbage collection. In particular, garbage collection (GC) incurs long-tail latency, e.g., 100 times higher latency than the average latency at the 99 th percentile. Thus, real-time and quality-critical systems fail to meet the given requirements such as deadline and QoS constraints. In this study, we propose a novel method of GC based on reinforcement learning. The objective is to reduce the long-tail latency by exploiting the idle time in the storage system. To improve the efficiency of the reinforcement learning-assisted GC scheme, we present new optimization methods that exploit fine-grained GC to further reduce the long-tail latency. The experimental results with real workloads show that our technique significantly reduces the long-tail latency by 29--36% at the 99.99 th percentile compared to state-of-the-art schemes.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2759513358",
    "type": "article"
  },
  {
    "title": "Probabilistic Safety Verification of Stochastic Hybrid Systems Using Barrier Certificates",
    "doi": "https://doi.org/10.1145/3126508",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Chao Huang; Xin Chen; Lin Wang; Zhengfeng Yang; Xuandong Li",
    "corresponding_authors": "",
    "abstract": "The problem of probabilistic safety verification of stochastic hybrid systems is to check whether the probability that a given system will reach an unsafe region from certain initial states can be bounded by some given probability threshold. The paper considers stochastic hybrid systems where the behavior is governed by polynomial equalities and inequalities, as for usual hybrid systems, but the initial states follow some stochastic distributions. It proposes a new barrier certificate based method for probabilistic safety verification which guarantees the absolute safety in a infinite time horizon that is beyond the reach of existing techniques using either statistical model checking or probabilistic reachable set computation. It also gives a novel computational approach, by building and solving a constrained optimization problem coming from verification conditions of barrier certificates, to compute the lower bound on safety probabilities which can be compared with the given threshold. Experimental evidence is provided demonstrating the applicability of our approach on several benchmarks.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2759834774",
    "type": "article"
  },
  {
    "title": "CxDNN",
    "doi": "https://doi.org/10.1145/3362035",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Shubham Jain; Anand Raghunathan",
    "corresponding_authors": "",
    "abstract": "Resistive crossbars have shown strong potential as the building blocks of future neural fabrics, due to their ability to natively execute vector-matrix multiplication (the dominant computational kernel in DNNs). However, a key challenge that arises in resistive crossbars is that non-idealities in the synaptic devices, interconnects, and peripheral circuits of resistive crossbars lead to errors in the computations performed. When large-scale DNNs are executed on resistive crossbar systems, these errors compound and result in unacceptable degradation in application-level accuracy. We propose CxDNN, a hardware-software methodology that enables the realization of large-scale DNNs on crossbar systems by compensating for errors due to non-idealities, greatly mitigating the degradation in accuracy. CxDNN is composed of (i) an optimized mapping technique to convert floating-point weights and activations to crossbar conductances and input voltages, (ii) a fast one-time re-training method to recover accuracy loss due to this conversion, and (iii) low-overhead compensation hardware to mitigate dynamic and hardware-instance-specific errors. Unlike previous efforts that are limited to small networks and require the training and deployment of hardware-instance-specific models, CxDNN presents a scalable compensation methodology that can address large DNNs (e.g., ResNet-50 on ImageNet) and maintains the train-once-deploy-anywhere tenet of current DNN application. We evaluated CxDNN on six top DNNs on the ImageNet dataset with 0.5--13.8 million neurons and 0.5--15.5 billion connections. CxDNN achieves 16.9%--49% improvement in the top-1 classification accuracy, effectively mitigating a key challenge to the use of resistive crossbar--based neural fabrics.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2983353765",
    "type": "article"
  },
  {
    "title": "Bluetooth aided mobile phone localization",
    "doi": "https://doi.org/10.1145/2560018",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Shuai Li; Yuesheng Lou; Бо Лю",
    "corresponding_authors": "",
    "abstract": "It is meaningful to design a strategy to roughly localize mobile phones without a GPS by exploiting existing conditions and devices especially in environments without GPS availability (e.g., tunnels, subway stations, etc.). The availability of Bluetooth devices for most phones and the existence of a number of GPS equipped phones in a crowd of phone users enable us to design a Bluetooth aided mobile phone localization strategy. With the position of GPS equipped phones as beacons, and with the Bluetooth connection between neighbor phones as proximity constraints, we formulate the problem into an inequality problem defined on the Bluetooth network. A recurrent neural network is developed to solve the problem distributively in real time. The convergence of the neural network and the solution feasibility to the defined problem are both theoretically proven. The hardware implementation architecture of the proposed neural network is also given in this article. As applications, rough localizations of drivers in a tunnel and localization of customers in a supermarket are explored and simulated. Simulations demonstrate the effectiveness of the proposed method.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2004790933",
    "type": "article"
  },
  {
    "title": "DyPO",
    "doi": "https://doi.org/10.1145/3126530",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Ujjwal Gupta; Chetan Arvind Patil; Ganapati Bhat; Prabhat Mishra; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "Modern multiprocessor systems-on-chip (MpSoCs) offer tremendous power and performance optimization opportunities by tuning thousands of potential voltage, frequency and core configurations. As the workload phases change at runtime, different configurations may become optimal with respect to power, performance or other metrics. Identifying the optimal configuration at runtime is infeasible due to the large number of workloads and configurations. This paper proposes a novel methodology that can find the Pareto-optimal configurations at runtime as a function of the workload. To achieve this, we perform an extensive offline characterization to find classifiers that map performance counters to optimal configurations. Then, we use these classifiers and performance counters at runtime to choose Pareto-optimal configurations. We evaluate the proposed methodology by maximizing the performance per watt for 18 single- and multi-threaded applications. Our experiments demonstrate an average increase of 93%, 81% and 6% in performance per watt compared to the interactive, ondemand and powersave governors, respectively.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2759387091",
    "type": "article"
  },
  {
    "title": "End-to-End Timing Analysis of Sporadic Cause-Effect Chains in Distributed Systems",
    "doi": "https://doi.org/10.1145/3358181",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Marco Dürr; Georg von der Brüggen; Kuan-Hsun Chen; Jian-Jia Chen",
    "corresponding_authors": "",
    "abstract": "A cause-effect chain is used to define the logical order of data dependent tasks, which is independent from the execution order of the jobs of the (periodic/sporadic) tasks. Analyzing the worst-case End-to-End timing behavior, associated to a cause-effect chain, is an important problem in embedded control systems. For example, the detailed timing properties of modern automotive systems are specified in the AUTOSAR Timing Extensions. In this paper, we present a formal End-to-End timing analysis for distributed systems. We consider the two most important End-to-End timing semantics, i.e., the button-to-action delay (termed as the maximum reaction time ) and the worst-case data freshness (termed as the maximum data age ). Our contribution is significant due to the consideration of the sporadic behavior of job activations, whilst the results in the literature have been mostly limited to periodic activations. The proof strategy shows the (previously unexplored) connection between the reaction time (data age, respectively) and immediate forward (backward, respectively) job chains. Our analytical results dominate the state of the art for sporadic task activations in distributed systems and the evaluations show a clear improvement for synthesized task systems as well as for a real world automotive benchmark setting.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2979569264",
    "type": "article"
  },
  {
    "title": "Designing Trusted Embedded Systems from Finite State Machines",
    "doi": "https://doi.org/10.1145/2638555",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Carson Dunbar; Gang Qu",
    "corresponding_authors": "",
    "abstract": "Sequential components are crucial for a real-time embedded system as they control the system based on the system's current state and real life input. In this article, we explore the security and trust issues of sequential system design from the perspective of a finite state machine (FSM), which is the most popular model used to describe sequential systems. Specifically, we find that the traditional FSM synthesis procedure will introduce security risks and cannot guarantee trustworthiness in the implemented circuits. Indeed, we show that not only do there exist simple and effective ways to attack a sequential system, it is also possible to insert a hardware Trojan Horse into the design without introducing any significant design overhead. We then formally define the notion of trust in FSM and propose a novel approach to designing trusted circuits from the FSM specification. We demonstrate both our findings on the security threats and the effectiveness of our proposed method on Microelectronics Center of North Carolina (MCNC) sequential circuit benchmarks.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2068085802",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Real-Time Scheduling of DAG Tasks",
    "doi": "https://doi.org/10.1145/3241049",
    "publication_date": "2018-09-17",
    "publication_year": 2018,
    "authors": "Ashikahmed Bhuiyan; Zhishan Guo; Abusayeed Saifullah; Nan Guan; Haoyi Xiong",
    "corresponding_authors": "",
    "abstract": "This work studies energy-aware real-time scheduling of a set of sporadic Directed Acyclic Graph (DAG) tasks with implicit deadlines. While meeting all real-time constraints, we try to identify the best task allocation and execution pattern such that the average power consumption of the whole platform is minimized. To our knowledge, this is the first work that addresses the power consumption issue in scheduling multiple DAG tasks on multi-cores and allows intra-task processor sharing. First, we adapt the decomposition-based framework for federated scheduling and propose an energy-sub-optimal scheduler. Then, we derive an approximation algorithm to identify processors to be merged together for further improvements in energy-efficiency. The effectiveness of the proposed approach is evaluated both theoretically via approximation ratio bounds and also experimentally through simulation study. Experimental results on randomly generated workloads show that our algorithms achieve an energy saving of 60% to 68% compared to existing DAG task schedulers.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2890277969",
    "type": "article"
  },
  {
    "title": "An Efficient UAV Hijacking Detection Method Using Onboard Inertial Measurement Unit",
    "doi": "https://doi.org/10.1145/3289390",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Zhiwei Feng; Nan Guan; Mingsong Lv; Weichen Liu; Qingxu Deng; Xue Liu; Wang Yi",
    "corresponding_authors": "",
    "abstract": "With the fast growth of civil drones, their security problems meet significant challenges. A commercial drone may be hijacked by a GPS-spoofing attack for illegal activities, such as terrorist attacks. The target of this article is to develop a technique that only uses onboard gyroscopes to determine whether a drone has been hijacked. Ideally, GPS data and the angular velocities measured by gyroscopes can be used to estimate the acceleration of a drone, which can be further compared with the measurement of the accelerometer to detect whether a drone has been hijacked. However, the detection results may not always be accurate due to some calculation and measurement errors, especially when no hijacking occurs in curve trajectory situations. To overcome this, in this article, we propose a novel and simple method to detect hijacking only based on gyroscopes’ measurements and GPS data, without using any accelerometer in the detection procedure. The computational complexity of our method is very low, which is suitable to be implemented in the drones with micro-controllers. On the other hand, the proposed method does not rely on any accelerometer to detect attacks, which means it receives less information in the detection procedure and may reduce the results accuracy in some special situations. While the previous method can compensate for this flaw, the high detection results also can be guaranteed by using the above two methods. Experiments with a quad-rotor drone are conducted to show the effectiveness of the proposed method and the combination method.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2904976413",
    "type": "article"
  },
  {
    "title": "XOR-Based Low-Cost Reconfigurable PUFs for IoT Security",
    "doi": "https://doi.org/10.1145/3274666",
    "publication_date": "2019-04-02",
    "publication_year": 2019,
    "authors": "Weiqiang Liu; Lei Zhang; Zhengran Zhang; Chongyan Gu; Chenghua Wang; Máire O’Neill; Fabrizio Lombardi",
    "corresponding_authors": "",
    "abstract": "With the rapid development of the Internet of Things (IoT), security has attracted considerable interest. Conventional security solutions that have been proposed for the Internet based on classical cryptography cannot be applied to IoT nodes as they are typically resource-constrained. A physical unclonable function (PUF) is a hardware-based security primitive and can be used to generate a key online or uniquely identify an integrated circuit (IC) by extracting its internal random differences using so-called challenge-response pairs (CRPs). It is regarded as a promising low-cost solution for IoT security. A logic reconfigurable PUF (RPUF) is highly efficient in terms of hardware cost. This article first presents a new classification for RPUFs, namely circuit-based RPUF (C-RPUF) and algorithm-based RPUF (A-RPUF); two Exclusive OR (XOR)-based RPUF circuits (an XOR-based reconfigurable bistable ring PUF (XRBR PUF) and an XOR-based reconfigurable ring oscillator PUF (XRRO PUF)) are proposed. Both the XRBR and XRRO PUFs are implemented on Xilinx Spartan-6 field-programmable gate arrays (FPGAs). The implementation results are compared with previous PUF designs and show good uniqueness and reliability. Compared to conventional PUF designs, the most significant advantage of the proposed designs is that they are highly efficient in terms of hardware cost. Moreover, the XRRO PUF is the most efficient design when compared with previous RPUFs. Also, both the proposed XRRO and XRBR PUFs require only 12.5% of the hardware resources of previous bitstable ring PUFs and reconfigurable RO PUFs, respectively, to generate a 1-bit response. This confirms that the proposed XRBR and XRRO PUFs are very efficient designs with good uniqueness and reliability.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2931380630",
    "type": "article"
  },
  {
    "title": "Adaptive and Hierarchical Runtime Manager for Energy-Aware Thermal Management of Embedded Systems",
    "doi": "https://doi.org/10.1145/2834120",
    "publication_date": "2016-01-29",
    "publication_year": 2016,
    "authors": "Anup Das; Bashir M. Al‐Hashimi; Geoff V. Merrett",
    "corresponding_authors": "",
    "abstract": "Modern embedded systems execute applications, which interact with the operating system and hardware differently depending on the type of workload. These cross-layer interactions result in wide variations of the chip-wide thermal profile. In this article, a reinforcement learning-based runtime manager is proposed that guarantees application-specific performance requirements and controls the POSIX thread allocation and voltage/frequency scaling for energy-efficient thermal management. This controls three thermal aspects: peak temperature, average temperature, and thermal cycling. Contrary to existing learning-based runtime approaches that optimize energy and temperature individually, the proposed runtime manager is the first approach to combine the two objectives, simultaneously addressing all three thermal aspects. However, determining thread allocation and core frequencies to optimize energy and temperature is an NP-hard problem. This leads to exponential growth in the learning table (significant memory overhead) and a corresponding increase in the exploration time to learn the most appropriate thread allocation and core frequency for a particular application workload. To confine the learning space and to minimize the learning cost, the proposed runtime manager is implemented in a two-stage hierarchy: a heuristic-based thread allocation at a longer time interval to improve thermal cycling, followed by a learning-based hardware frequency selection at a much finer interval to improve average temperature, peak temperature, and energy consumption. This enables finer control on temperature in an energy-efficient manner while simultaneously addressing scalability, which is a crucial aspect for multi-/many-core embedded systems. The proposed hierarchical runtime manager is implemented for Linux running on nVidia’s Tegra SoC, featuring four ARM Cortex-A15 cores. Experiments conducted with a range of embedded and cpu-intensive applications demonstrate that the proposed runtime manager not only reduces energy consumption by an average 15% with respect to Linux but also improves all the thermal aspects—average temperature by 14°C, peak temperature by 16°C, and thermal cycling by 54%.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2117382847",
    "type": "article"
  },
  {
    "title": "Design and Implementation of Warbler Family of Lightweight Pseudorandom Number Generators for Smart Devices",
    "doi": "https://doi.org/10.1145/2808230",
    "publication_date": "2016-02-20",
    "publication_year": 2016,
    "authors": "Kalikinkar Mandal; Xinxin Fan; Guang Gong",
    "corresponding_authors": "",
    "abstract": "With the advent of ubiquitous computing and the Internet of Things (IoT), the security and privacy issues for various smart devices such as radio-frequency identification (RFID) tags and wireless sensor nodes are receiving increased attention from academia and industry. A number of lightweight cryptographic primitives have been proposed to provide security services for resource-constrained smart devices. As one of the core primitives, a cryptographically secure pseudorandom number generator (PRNG) plays an important role for lightweight embedded applications. The most existing PRNGs proposed for smart devices employ true random number generators as a component, which generally incur significant power consumption and gate count in hardware. In this article, we present Warbler family, a new pseudorandom number generator family based on nonlinear feedback shift registers (NLFSRs) with desirable randomness properties. The design of the Warbler family is based on the combination of modified de Bruijn blocks together with a nonlinear feedback Welch-Gong (WG) sequence generator, which enables us to precisely characterize the randomness properties and to flexibly adjust the security level of the resulting PRNG. Some criteria for selecting parameters of the Warbler family are proposed to offer the maximum level of security. Two instances of the Warbler family are also described, which feature two different security levels and are dedicated to EPC C1 Gen2 RFID tags and wireless sensor nodes, respectively. The security analysis shows that the proposed instances not only can pass the cryptographic statistical tests recommended by the EPC C1 Gen2 standard and NIST but also are resistant to the cryptanalytic attacks such as algebraic attacks, cube attacks, time-memory-data tradeoff attacks, Mihaljević et al.’s attacks, and weak internal state and fault injection attacks. Our ASIC implementations using a 65nm CMOS process demonstrate that the proposed two lightweight instances of the Warbler family can achieve good performance in terms of speed and area and provide ideal solutions for securing low-cost smart devices.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2295169600",
    "type": "article"
  },
  {
    "title": "Memory- and Communication-Aware Model Compression for Distributed Deep Learning Inference on IoT",
    "doi": "https://doi.org/10.1145/3358205",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Kartikeya Bhardwaj; Ching‐Yi Lin; Anderson L. Sartor; Radu Mărculescu",
    "corresponding_authors": "",
    "abstract": "Model compression has emerged as an important area of research for deploying deep learning models on Internet-of-Things (IoT). However, for extremely memory-constrained scenarios, even the compressed models cannot fit within the memory of a single device and, as a result, must be distributed across multiple devices. This leads to a distributed inference paradigm in which memory and communication costs represent a major bottleneck. Yet, existing model compression techniques are not communication-aware. Therefore, we propose Network of Neural Networks (NoNN), a new distributed IoT learning paradigm that compresses a large pretrained ‘teacher’ deep network into several disjoint and highly-compressed ‘student’ modules, without loss of accuracy. Moreover, we propose a network science-based knowledge partitioning algorithm for the teacher model, and then train individual students on the resulting disjoint partitions. Extensive experimentation on five image classification datasets, for user-defined memory/performance budgets, show that NoNN achieves higher accuracy than several baselines and similar accuracy as the teacher model, while using minimal communication among students. Finally, as a case study, we deploy the proposed model for CIFAR-10 dataset on edge devices and demonstrate significant improvements in memory footprint (up to 24×), performance (up to 12×), and energy per node (up to 14×) compared to the large teacher model. We further show that for distributed inference on multiple edge devices, our proposed NoNN model results in up to 33× reduction in total latency w.r.t. a state-of-the-art model compression baseline.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2979562621",
    "type": "article"
  },
  {
    "title": "Achieving Super-Linear Speedup across Multi-FPGA for Real-Time DNN Inference",
    "doi": "https://doi.org/10.1145/3358192",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Weiwen Jiang; Edwin H.‐M. Sha; Xinyi Zhang; Lei Yang; Qingfeng Zhuge; Yiyu Shi; Jingtong Hu",
    "corresponding_authors": "",
    "abstract": "Real-time Deep Neural Network (DNN) inference with low-latency requirement has become increasingly important for numerous applications in both cloud computing (e.g., Apple's Siri) and edge computing (e.g., Google/Waymo's driverless car). FPGA-based DNN accelerators have demonstrated both superior flexibility and performance; in addition, for real-time inference with low batch size, FPGA is expected to achieve further performance improvement. However, the performance gain from the single-FPGA design is obstructed by the limited on-chip resource. In this paper, we employ multiple FPGAs to cooperatively run DNNs with the objective of achieving super-linear speed-up against single-FPGA design. In implementing such systems, we found two barriers that hinder us from achieving the design goal: (1) the lack of a clear partition scheme for each DNN layer to fully exploit parallelism, and (2) the insufficient bandwidth between the off-chip memory and the accelerator due to the growing size of DNNs. To tackle these issues, we propose a general framework, \"Super-LIP\", which can support different kinds of DNNs. In this paper, we take Convolutional Neural Network (CNN) as a vehicle to illustrate Super-LIP. We first formulate an accurate system-level model to support the exploration of best partition schemes. Then, we develop a novel design methodology to effectively alleviate the heavy loads on memory bandwidth by moving traffic from memory bus to inter-FPGA links. We implement Super-LIP based on ZCU102 FPGA boards. Results demonstrate that Super-LIP with 2 FPGAs can achieve 3.48x speedup, compared to the state-of-the-art single-FPGA design. What is more, as the number of FPGAs scales up, the system latency can be further reduced while maintaining high energy efficiency.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2962953210",
    "type": "article"
  },
  {
    "title": "Statistical Verification of Hyperproperties for Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3358232",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Yu Wang; Mojtaba Zarei; Borzoo Bonakdarpour; Miroslav Pajić",
    "corresponding_authors": "",
    "abstract": "Many important properties of cyber-physical systems (CPS) are defined upon the relationship between multiple executions simultaneously in continuous time. Examples include probabilistic fairness and sensitivity to modeling errors (i.e., parameters changes) for real-valued signals. These requirements can only be specified by hyperproperties . In this article, we focus on verifying probabilistic hyperproperties for CPS. To cover a wide range of modeling formalisms, we first propose a general model of probabilistic uncertain systems (PUSs) that unify commonly studied CPS models such as continuous-time Markov chains (CTMCs) and probabilistically parametrized Hybrid I/O Automata (P 2 HIOA). To formally specify hyperproperties, we propose a new temporal logic, hyper probabilistic signal temporal logic (HyperPSTL) that serves as a hyper and probabilistic version of the conventional signal temporal logic (STL). Considering the complexity of real-world systems that can be captured as PUSs, we adopt a statistical model checking (SMC) approach for their verification. We develop a new SMC technique based on the direct computation of significance levels of statistical assertions for HyperPSTL specifications, which requires no a priori knowledge on the indifference margin. Then, we introduce SMC algorithms for HyperPSTL specifications on the joint probabilistic distribution of multiple paths, as well as specifications with nested probabilistic operators quantifying different paths, which cannot be handled by existing SMC algorithms. Finally, we show the effectiveness of our SMC algorithms on CPS benchmarks with varying levels of complexity, including the Toyota Powertrain Control System.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2980274526",
    "type": "article"
  },
  {
    "title": "SIAM: Chiplet-based Scalable In-Memory Acceleration with Mesh for Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3476999",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Gokul Krishnan; Sumit K. Mandal; Manvitha Pannala; Chaitali Chakrabarti; Jae-sun Seo; Ümit Y. Ogras; Yu Cao",
    "corresponding_authors": "",
    "abstract": "In-memory computing (IMC) on a monolithic chip for deep learning faces dramatic challenges on area, yield, and on-chip interconnection cost due to the ever-increasing model sizes. 2.5D integration or chiplet-based architectures interconnect multiple small chips (i.e., chiplets) to form a large computing system, presenting a feasible solution beyond a monolithic IMC architecture to accelerate large deep learning models. This paper presents a new benchmarking simulator, SIAM, to evaluate the performance of chiplet-based IMC architectures and explore the potential of such a paradigm shift in IMC architecture design. SIAM integrates device, circuit, architecture, network-on-chip (NoC), network-on-package (NoP), and DRAM access models to realize an end-to-end system. SIAM is scalable in its support of a wide range of deep neural networks (DNNs), customizable to various network structures and configurations, and capable of efficient design space exploration. We demonstrate the flexibility, scalability, and simulation speed of SIAM by benchmarking different state-of-the-art DNNs with CIFAR-10, CIFAR-100, and ImageNet datasets. We further calibrate the simulation results with a published silicon result, SIMBA. The chiplet-based IMC architecture obtained through SIAM shows 130 and 72 improvement in energy-efficiency for ResNet-50 on the ImageNet dataset compared to Nvidia V100 and T4 GPUs.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W3201613041",
    "type": "article"
  },
  {
    "title": "Heuristic Computation Offloading Algorithms for Mobile Users in Fog Computing",
    "doi": "https://doi.org/10.1145/3426852",
    "publication_date": "2021-01-04",
    "publication_year": 2021,
    "authors": "Keqin Li",
    "corresponding_authors": "Keqin Li",
    "abstract": "The investigation in this article makes the following important contributions to combinatorial optimization of computation offloading in fog computing. First, we rigorously define the two problems of optimal computation offloading with energy constraint and optimal computation offloading with time constraint. We do this in such a way that between execution time and energy consumption, we can fix one and minimize the other. We prove that our optimization problems are NP-hard, even for very special cases. Second, we develop a unique and effective approach for solving the proposed combinatorial optimization problems, namely, a two-stage method. In the first stage, we generate a computation offloading strategy. In the second stage, we decide the computation speed and the communication speeds. This method is applicable to both optimization problems. Third, we use a simple yet efficient greedy method to produce a computation offloading strategy by taking all aspects into consideration, including the properties of the communication channels, the power consumption models of computation and communication, the tasks already assigned and allocated, and the characteristics of the current task being considered. Fourth, we experimentally evaluate the performance of our heuristic algorithms. We observe that while various heuristics do exhibit noticeably different performance, there can be a single and simple heuristic that can perform very well. Furthermore, the method of compound algorithm can be applied to obtain slightly improved performance. Fifth, we emphasize that our problems and algorithms can be easily extended to study combined performance and cost optimization (such as cost–performance ratio and weighted cost-performance sum optimization) and to accommodate more realistic and complicated fog computing environments (such as preloaded mobile edge servers and multiple users) with little extra effort. To the best of our knowledge, there has been no similar study in the existing fog computing literature.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W3118359622",
    "type": "article"
  },
  {
    "title": "PhiNets: A Scalable Backbone for Low-power AI at the Edge",
    "doi": "https://doi.org/10.1145/3510832",
    "publication_date": "2022-02-03",
    "publication_year": 2022,
    "authors": "Francesco Paissan; Alberto Ancilotto; Elisabetta Farella",
    "corresponding_authors": "",
    "abstract": "In the Internet of Things era, where we see many interconnected and heterogeneous mobile and fixed smart devices, distributing the intelligence from the cloud to the edge has become a necessity. Due to limited computational and communication capabilities, low memory and limited energy budget, bringing artificial intelligence algorithms to peripheral devices, such as end-nodes of a sensor network, is a challenging task and requires the design of innovative solutions. In this work, we present PhiNets , a new scalable backbone optimized for deep-learning-based image processing on resource-constrained platforms. PhiNets are based on inverted residual blocks specifically designed to decouple the computational cost, working memory, and parameter memory, thus exploiting all available resources for a given platform. With a YoloV2 detection head and Simple Online and Realtime Tracking (SORT), the proposed architecture achieves state-of-the-art results in (i) detection on the COCO and VOC2012 benchmarks, and (ii) tracking on the MOT15 benchmark. PhiNets obtain a reduction in parameter count of around 90% with respect to previous state-of-the-art models (EfficientNetv1, MobileNetv2) and achieve better performance with lower computational cost. Moreover, we demonstrate our approach on a prototype node based on an STM32H743 microcontroller (MCU) with 2 MB of internal Flash and 1MB of RAM and achieve power requirements in the order of 10 mW. The code for the PhiNets is publicly available on GitHub. 1",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W4210269029",
    "type": "article"
  },
  {
    "title": "Camaroptera: A Long-range Image Sensor with Local Inference for Remote Sensing Applications",
    "doi": "https://doi.org/10.1145/3510850",
    "publication_date": "2022-02-21",
    "publication_year": 2022,
    "authors": "Harsh Desai; Matteo Nardello; Davide Brunelli; Brandon Lucia",
    "corresponding_authors": "",
    "abstract": "Batteryless image sensors present an opportunity for long-life, long-range sensor deployments that require zero maintenance, and have low cost. Such deployments are critical for enabling remote sensing applications, e.g., instrumenting national highways, where individual devices are deployed far (kms away) from supporting infrastructure. In this work, we develop and characterize Camaroptera, the first batteryless image-sensing platform to combine energy-harvesting with active, long-range (LoRa) communication. We also equip Camaroptera with a Machine Learning-based processing pipeline to mitigate costly, long-distance communication of image data. This processing pipeline filters out uninteresting images and only transmits the images interesting to the application. We show that compared to running a traditional Sense-and-Send workload, Camaroptera’s Local Inference pipeline captures and sends upto \\( 12\\times \\) more images of interest to an application. By performing Local Inference , Camaroptera also sends upto \\( 6.5\\times \\) fewer uninteresting images, instead using that energy to capture upto \\( 14.7\\times \\) more new images, increasing its sensing effectiveness and availability. We fully prototype the Camaroptera hardware platform in a compact, 2 cm \\( \\times \\) 3 cm \\( \\times \\) 5 cm volume. Our evaluation demonstrates the viability of a batteryless, remote, visual-sensing platform in a small package that collects and usefully processes acquired data and transmits it over long distances (kms), while being deployed for multiple decades with zero maintenance.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W4212769148",
    "type": "article"
  },
  {
    "title": "DynO: Dynamic Onloading of Deep Neural Networks from Cloud to Device",
    "doi": "https://doi.org/10.1145/3510831",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Mário Almeida; Stefanos Laskaridis; Stylianos I. Venieris; Ilias Leontiadis; Nicholas D. Lane",
    "corresponding_authors": "",
    "abstract": "Recently, there has been an explosive growth of mobile and embedded applications using convolutional neural networks(CNNs). To alleviate their excessive computational demands, developers have traditionally resorted to cloud offloading, inducing high infrastructure costs and a strong dependence on networking conditions. On the other end, the emergence of powerful SoCs is gradually enabling on-device execution. Nonetheless, low- and mid-tier platforms still struggle to run state-of-the-art CNNs sufficiently. In this paper, we present DynO, a distributed inference framework that combines the best of both worlds to address several challenges, such as device heterogeneity, varying bandwidth and multi-objective requirements. Key components that enable this are its novel CNN-specific data packing method, which exploits the variability of precision needs in different parts of the CNN when onloading computation, and its novel scheduler that jointly tunes the partition point and transferred data precision at run time to adapt inference to its execution environment. Quantitative evaluation shows that DynO outperforms the current state-of-the-art, improving throughput by over an order of magnitude over device-only execution and up to 7.9x over competing CNN offloading systems, with up to 60x less data transferred.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3156189202",
    "type": "article"
  },
  {
    "title": "LL-GNN: Low Latency Graph Neural Networks on FPGAs for High Energy Physics",
    "doi": "https://doi.org/10.1145/3640464",
    "publication_date": "2024-01-15",
    "publication_year": 2024,
    "authors": "Zhiqiang Que; Hongxiang Fan; Marcus H. Loo; He Li; Michaela Blott; M. Pierini; A. Tapper; Wayne Luk",
    "corresponding_authors": "",
    "abstract": "This work presents a novel reconfigurable architecture for Low Latency Graph Neural Network (LL-GNN) designs for particle detectors, delivering unprecedented low latency performance. Incorporating FPGA-based GNNs into particle detectors presents a unique challenge since it requires sub-microsecond latency to deploy the networks for online event selection with a data rate of hundreds of terabytes per second in the Level-1 triggers at the CERN Large Hadron Collider experiments. This article proposes a novel outer-product based matrix multiplication approach, which is enhanced by exploiting the structured adjacency matrix and a column-major data layout. In addition, we propose a custom code transformation for the matrix multiplication operations, which leverages the structured sparsity patterns and binary features of adjacency matrices to reduce latency and improve hardware efficiency. Moreover, a fusion step is introduced to further reduce the end-to-end design latency by eliminating unnecessary boundaries. Furthermore, a GNN-specific algorithm-hardware co-design approach is presented which not only finds a design with a much better latency but also finds a high accuracy design under given latency constraints. To facilitate this, a customizable template for this low latency GNN hardware architecture has been designed and open-sourced, which enables the generation of low-latency FPGA designs with efficient resource utilization using a high-level synthesis tool. Evaluation results show that our FPGA implementation is up to 9.0 times faster and achieves up to 13.1 times higher power efficiency than a GPU implementation. Compared to the previous FPGA implementations, this work achieves 6.51 to 16.7 times lower latency. Moreover, the latency of our FPGA design is sufficiently low to enable deployment of GNNs in a sub-microsecond, real-time collider trigger system, enabling it to benefit from improved accuracy. The proposed LL-GNN design advances the next generation of trigger systems by enabling sophisticated algorithms to process experimental data efficiently.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4390880528",
    "type": "article"
  },
  {
    "title": "Diwall: A Lightweight Host Intrusion Detection System Against Jamming and Packet Injection Attacks",
    "doi": "https://doi.org/10.1145/3711833",
    "publication_date": "2025-01-14",
    "publication_year": 2025,
    "authors": "Mohamed El Bouazzati; Philippe A. Tanguy; Guy Gogniat; Russell Tessier",
    "corresponding_authors": "",
    "abstract": "The rapid growth of Internet of Things (IoT) applications in various sectors has led to a significant increase in the number of IoT devices. This has led to the deployment of numerous IoT protocols to provide greater connectivity. However, this extensive adoption has also left them vulnerable to attack. In particular, attacks targeting wireless communication capabilities represent a significant threat. Such attacks exploit various vulnerabilities in the wireless connectivity unit, compromising its security. To counter this threat, this article proposes a Host Intrusion Detection System (HIDS) for detecting wireless attacks. Its components are customized to support IoT end-devices using low-GHz and sub-GHz data rate protocols. The HIDS deploys a hardware tracer to monitor microarchitecture and network metrics using hardware performance counters (HPCs). It performs monitoring of network and microarchitecture metrics for a 32-bit RISC-V-based wireless connectivity unit. The HIDS uses analysis and classification of monitored data for detecting memory corruption and jamming attacks. We evaluate the effectiveness of the HIDS in detecting packet injection and jamming attacks. Our Field?Programmable Gate Array (FPGA) implementation of HIDS has a logic overhead of about 14.30% and 22.89% of flip flops (FFs) and lookup tables (LUTs), respectively, compared to the CV32E40P baseline on an Arty A7 100T board. The design frequency and code size penalties are less than 1% for a RISC-V processor with a LoRaWAN protocol stack.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4406371865",
    "type": "article"
  },
  {
    "title": "A Hybrid Target Selection Model of Functional Safety Compliance for Autonomous Driving System",
    "doi": "https://doi.org/10.1145/3716631",
    "publication_date": "2025-02-08",
    "publication_year": 2025,
    "authors": "Yang Liu; Z. Wang; Mengchi Cai; Qing Xu; Keqiang Li",
    "corresponding_authors": "",
    "abstract": "The autonomous driving system faces challenges in selecting critical targets under dense environments with limited computation resources. Existing rule-based methods struggle with complex scenarios, while learning-based approaches lack interpretability and safety. This paper proposes a hybrid target selection model combining a lightweight long short-term memory (LSTM) based deep learning classifier and rule-based methods. Key input features are identified and processed to enhance training. The LSTM model is validated for accuracy and efficiency against bidirectional LSTM (Bi-LSTM) variations. Compared to the single approach, the hybrid model integrates the LSTM classifier and rule-based methods with a synthesizer, demonstrating improved accuracy, better interpretability, and a potentially higher functional safety level. Integrated into TDA4VM, the hybrid model shows timely and complementary target selection performance in actual urban and highway tests with low computation costs, proving its theoretical value and engineering prospects.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4407276926",
    "type": "article"
  },
  {
    "title": "SPHINCSLET: An Area-Efficient Accelerator for the Full SPHINCS+ Digital Signature Algorithm",
    "doi": "https://doi.org/10.1145/3728469",
    "publication_date": "2025-04-07",
    "publication_year": 2025,
    "authors": "Sanjay Deshpande; Yong-Seok Lee; Cansu Karakuzu; Jakub Szefer; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "This work presents SPHINCSLET, the first fully standard-compliant and area-efficient hardware implementation of the SLH-DSA algorithm, formerly known as SPHINCS+, a post-quantum digital signature scheme. SPHINCSLET is designed to be parameterizable across different security levels and hash functions, offering a balanced trade-off between area efficiency and performance. Existing hardware implementations either feature a large area footprint to achieve fast signing and verification or adopt a coprocessor-based approach that significantly slows down these operations. SPHINCSLET addresses this gap by delivering a 4.7 × reduction in area compared to high-speed designs while achieving a 2.5 × to 5 × improvement in signing time over the most efficient coprocessor-based designs for a SHAKE256-based SPHINCS+ implementation. The SHAKE256-based SPHINCS+ FPGA implementation targeting the AMD Artix-7 requires fewer than 10.8K LUTs for any security level of SLH-DSA. Furthermore, the SHA-2-based SPHINCS+ implementation achieves a 2 × to 4 × speedup in signature generation across various security levels compared to existing SLH-DSA hardware, all while maintaining a compact area footprint of 6K to 15K LUTs. This makes it the fastest SHA-2-based SLH-DSA implementation to date. With an optimized balance of area and performance, SPHINCSLET can assist resource-constrained devices in transitioning to post-quantum cryptography.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4409212896",
    "type": "article"
  },
  {
    "title": "Power management for energy-aware communication systems",
    "doi": "https://doi.org/10.1145/860176.860184",
    "publication_date": "2003-08-01",
    "publication_year": 2003,
    "authors": "Curt Schurgers; Vijay Raghunathan; Mani Srivastava",
    "corresponding_authors": "",
    "abstract": "System-level power management has become a key technique to render modern wireless communication devices economically viable. Despite their relatively large impact on the system energy consumption, power management for radios has been limited to shutdown-based schemes, while processors have benefited from superior techniques based on dynamic voltage scaling (DVS). However, similar scaling approaches that trade-off energy versus performance are also available for radios. To utilize these in radio power management, existing packet scheduling policies have to be thoroughly rethought to make them energy-aware, essentially opening a whole new set of challenges the same way the introduction of DVS did to CPU task scheduling. We use one specific scaling technique, dynamic modulation scaling (DMS), as a vehicle to outline these challenges, and to introduce the intricacies caused by the nonpreemptive nature of packet scheduling and the time-varying wireless channel.",
    "cited_by_count": 93,
    "openalex_id": "https://openalex.org/W1967049959",
    "type": "article"
  },
  {
    "title": "Frequent value locality and its applications",
    "doi": "https://doi.org/10.1145/581888.581894",
    "publication_date": "2002-11-01",
    "publication_year": 2002,
    "authors": "Jun Yang; Rajiv Gupta",
    "corresponding_authors": "",
    "abstract": "By analyzing the behavior of a set of benchmarks, we demonstrate that a small number of distinct values tend to occur very frequently in memory. On an average, only eight of these frequent values were found to occupy 48% of memory locations for the benchmarks studied. In addition, we demonstrate that the identity of frequent values remains stable over the entire execution of the program and these values are scattered fairly uniformly across the allocated memory. We present three different algorithms for finding frequent values and experimentally demonstrate their effectiveness. Each of these algorithms is designed to suit a different application scenario. Since the contents of memory exhibit frequent value locality, it is expected that frequent values will be observed in data streams that flow across different points in the memory hierarchy. We exploit this observation for developing two low-power designs: a low-power level-one data cache and a low-power external data bus. In each of these applications a different form of encoding of frequent values is employed to obtain a low-power design. We also experimentally demonstrate the effectiveness of these designs.",
    "cited_by_count": 93,
    "openalex_id": "https://openalex.org/W2037635237",
    "type": "article"
  },
  {
    "title": "A self-tuning cache architecture for embedded systems",
    "doi": "https://doi.org/10.1145/993396.993405",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Chuanjun Zhang; Frank Vahid; Roman Lysecky",
    "corresponding_authors": "",
    "abstract": "Memory accesses often account for about half of a microprocessor system's power consumption. Customizing a microprocessor cache's total size, line size, and associativity to a particular program is well known to have tremendous benefits for performance and power. Customizing caches has until recently been restricted to core-based flows, in which a new chip will be fabricated. However, several configurable cache architectures have been proposed recently for use in prefabricated microprocessor platforms. Tuning those caches to a program is still, however, a cumbersome task left for designers, assisted in part by recent computer-aided design (CAD) tuning aids. We propose to move that CAD on-chip, which can greatly increase the acceptance of tunable caches. We introduce on-chip hardware implementing an efficient cache tuning heuristic that can automatically, transparently, and dynamically tune the cache to an executing program. Our heuristic seeks not only to reduce the number of configurations that must be examined, but also traverses the search space in a way that minimizes costly cache flushes. By simulating numerous Powerstone and MediaBench benchmarks, we show that such a dynamic self-tuning cache saves on average 40% of total memory access energy over a standard nontuned reference cache.",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W2070553643",
    "type": "article"
  },
  {
    "title": "Eliminating stack overflow by abstract interpretation",
    "doi": "https://doi.org/10.1145/1113830.1113833",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "John Regehr; Alastair Reid; Kirk Webb",
    "corresponding_authors": "",
    "abstract": "An important correctness criterion for software running on embedded microcontrollers is stack safety : a guarantee that the call stack does not overflow. Our first contribution is a method for statically guaranteeing stack safety of interrupt-driven embedded software using an approach based on context-sensitive dataflow analysis of object code. We have implemented a prototype stack analysis tool that targets software for Atmel AVR microcontrollers and tested it on embedded applications compiled from up to 30,000 lines of C. We experimentally validate the accuracy of the tool, which runs in under 10 sec on the largest programs that we tested. The second contribution of this paper is the development of two novel ways to reduce stack memory requirements of embedded software.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W2025806161",
    "type": "article"
  },
  {
    "title": "Maximizing rewards for real-time applications with energy constraints",
    "doi": "https://doi.org/10.1145/950162.950166",
    "publication_date": "2003-11-01",
    "publication_year": 2003,
    "authors": "Cosmin Rusu; Rami Melhem; Daniel Mossé",
    "corresponding_authors": "",
    "abstract": "New technologies have brought about a proliferation of embedded systems, which vary from control systems to sensor networks to personal digital assistants. Many of the portable embedded devices run several applications, which typically have three constraints that need to be addressed: energy , deadline , and reward . However, many of these portable devices do not have powerful enough CPUs and batteries to run all applications within their deadlines. An optimal scheme would allow the device to run the most applications, each using the most amount of CPU cycles possible, without depleting the energy source while still meeting all deadlines. In this paper we propose a solution to this problem; to our knowledge, this is the first solution that combines the three constraints mentioned above. We devise two algorithms, an optimal algorithm for homogeneous applications (with respect to power consumption) and a heuristic iterative algorithm that can also accommodate heterogeneous applications (i.e., those with different power consumption functions). We show by simulation that our iterative algorithm is fast and within 1% of the optimal.",
    "cited_by_count": 86,
    "openalex_id": "https://openalex.org/W2146949338",
    "type": "article"
  },
  {
    "title": "Timing analysis for preemptive multitasking real-time systems with caches",
    "doi": "https://doi.org/10.1145/1210268.1210275",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Yudong Tan; Vincent J. Mooney",
    "corresponding_authors": "",
    "abstract": "In this paper, we propose an approach to estimate the worst-case response time (WCRT) of each task in a preemptive multitasking single-processor real-time system utilizing an L1 cache. The approach combines intertask cache-eviction analysis and intratask cache-access analysis to estimate the number of cache lines that can possibly be evicted by the preempting task and also be accessed again by the preempted task after preemptions (thus requiring the preempted task to reload the cache line(s)). This cache-reload delay caused by preempting task(s) is then incorporated into WCRT analysis. Three sets of applications with up to six concurrent tasks running are used to test our approach. The experimental results show that our approach can tighten the WCRT estimate by up to 32% (1.4X) over prior state-of-the-art.",
    "cited_by_count": 77,
    "openalex_id": "https://openalex.org/W2011874983",
    "type": "article"
  },
  {
    "title": "Undergraduate embedded system education at Carnegie Mellon",
    "doi": "https://doi.org/10.1145/1086519.1086522",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Philip Koopman; Howie Choset; Rajeev Gandhi; Bruce H. Krogh; Diana Marculescu; Priya Narasimhan; JoAnn M. Paul; Ragunathan Rajkumar; Daniel P. Siewiorek; Asim﻿ Smailagic; Peter Steenkiste; Donald E. Thomas; Chenxi Wang",
    "corresponding_authors": "",
    "abstract": "Embedded systems encompass a wide range of applications, technologies, and disciplines, necessitating a broad approach to education. We describe embedded system coursework during the first 4 years of university education (the U.S. undergraduate level). Embedded application curriculum areas include: small and single-microcontroller applications, control systems, distributed embedded control, system-on-chip, networking, embedded PCs, critical systems, robotics, computer peripherals, wireless data systems, signal processing, and command and control. Additional cross-cutting skills that are important to embedded system designers include: security, dependability, energy-aware computing, software/systems engineering, real-time computing, and human--computer interaction. We describe lessons learned from teaching courses in many of these areas, as well as general skills taught and approaches used, including a heavy emphasis on course projects to teach system skills.",
    "cited_by_count": 73,
    "openalex_id": "https://openalex.org/W1997625806",
    "type": "article"
  },
  {
    "title": "Data cache locking for tight timing calculations",
    "doi": "https://doi.org/10.1145/1324969.1324973",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Xavier Vera; Björn Lisper; Jingling Xue",
    "corresponding_authors": "",
    "abstract": "Caches have become increasingly important with the widening gap between main memory and processor speeds. Small and fast cache memories are designed to bridge this discrepancy. However, they are only effective when programs exhibit sufficient data locality. In addition, caches are a source of unpredictability, resulting in programs sometimes behaving in a different way than expected. Detailed information about the number of cache misses and their causes allows us to predict cache behavior and to detect bottlenecks. Small modifications in the source code may change memory patterns, thereby altering the cache behavior. Code transformations, which take the cache behavior into account, might result in a high cache performance improvement. However, cache memory behavior is very hard to predict, thus making the task of optimizing and timing cache behavior very difficult. This article proposes and evaluates a new compiler framework that times cache behavior for multitasking systems. Our method explores the use of cache partitioning and dynamic cache locking to provide worst-case performance estimates in a safe and tight way for multitasking systems. We use cache partitioning, which divides the cache among tasks to eliminate intertask cache interferences. We combine static cache analysis and cache-locking mechanisms to ensure that all intratask conflicts, and consequently, memory access times, are exactly predictable. The results of our experiments demonstrate the capability of our framework to describe cache behavior at compile time. We compare our timing approach with a system equipped with a nonpartitioned, but statically, locked data cache. Our method outperforms static cache locking for all analyzed task sets under various cache architectures, demonstrating that our fully predictable scheme does not compromise the performance of the transformed programs.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2094162955",
    "type": "article"
  },
  {
    "title": "Microsearch",
    "doi": "https://doi.org/10.1145/1721695.1721709",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Chiu C. Tan; Bo Sheng; Haodong Wang; Qun Li",
    "corresponding_authors": "",
    "abstract": "In this article, we present Microsearch, a search system suitable for embedded devices used in ubiquitous computing environments. Akin to a desktop search engine, Microsearch indexes the information inside a small device, and accurately resolves a user's queries. Given the limited hardware, conventional search engine design and algorithms cannot be used. We adopt Information Retrieval (IR) techniques for query resolution, and proposed a new space-efficient top- k query resolution algorithm. A theoretical model of Microsearch is given to better understand the trade-offs in design parameters. Evaluation is done via actual implementation on off-the-shelf hardware.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W2104525643",
    "type": "article"
  },
  {
    "title": "REDEFINE",
    "doi": "https://doi.org/10.1145/1596543.1596545",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Mythri Alle; Keshavan Varadarajan; Alexander Fell; Ramesh Reddy C.; Nimmy Joseph; Saptarsi Das; Prasenjit Biswas; Jugantor Chetia; A. R. Rao; S. K. Nandy; Ranjani Narayan",
    "corresponding_authors": "",
    "abstract": "Emerging embedded applications are based on evolving standards (e.g., MPEG2/4, H.264/265, IEEE802.11a/b/g/n). Since most of these applications run on handheld devices, there is an increasing need for a single chip solution that can dynamically interoperate between different standards and their derivatives. In order to achieve high resource utilization and low power dissipation, we propose REDEFINE, a polymorphic ASIC in which specialized hardware units are replaced with basic hardware units that can create the same functionality by runtime re -composition. It is a “future-proof” custom hardware solution for multiple applications and their derivatives in a domain. In this article, we describe a compiler framework and supporting hardware comprising compute, storage, and communication resources. Applications described in high-level language (e.g., C) are compiled into application substructures. For each application substructure, a set of compute elements on the hardware are interconnected during runtime to form a pattern that closely matches the communication pattern of that particular application. The advantage is that the bounded CEs are neither processor cores nor logic elements as in FPGAs. Hence, REDEFINE offers the power and performance advantage of an ASIC and the hardware reconfigurability and programmability of that of an FPGA/instruction set processor. In addition, the hardware supports custom instruction pipelining. Existing instruction-set extensible processors determine a sequence of instructions that repeatedly occur within the application to create custom instructions at design time to speed up the execution of this sequence. We extend this scheme further, where a kernel is compiled into custom instructions that bear strong producer-consumer relationship (and not limited to frequently occurring sequences of instructions). Custom instructions, realized as hardware compositions effected at runtime, allow several instances of the same to be active in parallel. A key distinguishing factor in majority of the emerging embedded applications is stream processing. To reduce the overheads of data transfer between custom instructions, direct communication paths are employed among custom instructions. In this article, we present the overview of the hardware-aware compiler framework, which determines the NoC-aware schedule of transports of the data exchanged between the custom instructions on the interconnect. The results for the FFT kernel indicate a 25% reduction in the number of loads/stores, and throughput improves by log(n) for n-point FFT when compared to sequential implementation. Overall, REDEFINE offers flexibility and a runtime reconfigurability at the expense of 1.16× in power and 8× in area when compared to an ASIC. REDEFINE implementation consumes 0.1× the power of an FPGA implementation. In addition, the configuration overhead of the FPGA implementation is 1,000× more than that of REDEFINE.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W1968238550",
    "type": "article"
  },
  {
    "title": "A multifrequency MAC specially designed for wireless sensor network applications",
    "doi": "https://doi.org/10.1145/1721695.1721705",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Gang Zhou; Yafeng Wu; Ting Yan; Tian He; Chengdu Huang; John A. Stankovic; Tarek Abdelzaher",
    "corresponding_authors": "",
    "abstract": "Multifrequency media access control has been well understood in general wireless ad hoc networks, while in wireless sensor networks, researchers still focus on single frequency solutions. In wireless sensor networks, each device is typically equipped with a single radio transceiver and applications adopt much smaller packet sizes compared to those in general wireless ad hoc networks. Hence, the multifrequency MAC protocols proposed for general wireless ad hoc networks are not suitable for wireless sensor network applications, which we further demonstrate through our simulation experiments. In this article, we propose MMSN, which takes advantage of multifrequency availability while, at the same time, takes into consideration the restrictions of wireless sensor networks. In MMSN, four frequency assignment options are provided to meet different application requirements. A scalable media access is designed with efficient broadcast support. Also, an optimal nonuniform back-off algorithm is derived and its lightweight approximation is implemented in MMSN, which significantly reduces congestion in the time synchronized media access design. Through extensive experiments, MMSN exhibits the prominent ability to utilize parallel transmissions among neighboring nodes. When multiple physical frequencies are available, it also achieves increased energy efficiency, demonstrating the ability to work against radio interference and the tolerance to a wide range of measured time synchronization errors.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2125678429",
    "type": "article"
  },
  {
    "title": "Compositionality in synchronous data flow",
    "doi": "https://doi.org/10.1145/2442116.2442133",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Stavros Tripakis; Dai Bui; Marc Geilen; Bert Rodiers; Edward A. Lee",
    "corresponding_authors": "",
    "abstract": "Hierarchical SDF models are not compositional: a composite SDF actor cannot be represented as an atomic SDF actor without loss of information that can lead to rate inconsistency or deadlock. Motivated by the need for incremental and modular code generation from hierarchical SDF models, we introduce in this paper DSSF profiles. DSSF (Deterministic SDF with Shared FIFOs) forms a compositional abstraction of composite actors that can be used for modular compilation. We provide algorithms for automatic synthesis of non-monolithic DSSF profiles of composite actors given DSSF profiles of their sub-actors. We show how different trade-offs can be explored when synthesizing such profiles, in terms of compactness (keeping the size of the generated DSSF profile small) versus reusability (maintaining necessary information to preserve rate consistency and deadlock-absence) as well as algorithmic complexity. We show that our method guarantees maximal reusability and report on a prototype implementation.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2153894526",
    "type": "article"
  },
  {
    "title": "Synthesizing Parsimonious Inexact Circuits through Probabilistic Design Techniques",
    "doi": "https://doi.org/10.1145/2465787.2465795",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Avinash Lingamneni; Christian Enz; Krishna V. Palem; Christian Piguet",
    "corresponding_authors": "",
    "abstract": "The domain of inexact circuit design, in which accuracy of the circuit can be exchanged for substantial cost (energy, delay, and/or area) savings, has been gathering increasing prominence of late owing to a growing desire for reducing energy consumption of the systems, particularly in the domain of embedded and (portable) multimedia applications. Most of the previous approaches to realizing inexact circuits relied on scaling of circuit parameters (such as supply voltage) taking advantage of an application’s error tolerance to achieve the cost and accuracy trade-offs, thus suffering from acute drawbacks of considerable implementation overheads that significantly reduced the gains. In this article, two novel design approaches called Probabilistic Pruning and Probabilistic Logic Minimization are proposed to realize inexact circuits with zero hardware overhead.Extensive simulations on various architectures of critical datapath elements demonstrate that each of the techniques can independently achieve normalized gains as large as 2x--9.5x in energy-delay-area product for relative error magnitude as low as 10 − 4% --8% compared to corresponding conventional correct circuits.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2044694954",
    "type": "article"
  },
  {
    "title": "Write activity reduction on non-volatile main memories for embedded chip multiprocessors",
    "doi": "https://doi.org/10.1145/2442116.2442127",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Jingtong Hu; Chun Jason Xue; Qingfeng Zhuge; Wei-Che Tseng; Edwin H.‐M. Sha",
    "corresponding_authors": "",
    "abstract": "Recent advances in circuit and semiconductor technologies have pushed Non-Volatile Memory (NVM) technologies into a new era. These technologies exhibit appealing properties such as low power consumption, non-volatility, shock-resistivity, and high density. However, there are challenges to which we need answers in the road of applying non-volatile memories as main memory in embedded computer systems. First, when compared with DRAM, NVMs have a limited number of write/erase cycles. Second, write activities on NVM are more expensive than DRAM memory in terms of energy consumption and access latency. Both challenges will benefit from the reduction of the write activities on the NVMs. In this paper, we target embedded Chip Multiprocessors (CMPs) with Scratch Pad Memory (SPM) and non-volatile main memory. We introduce scheduling, data migration, and recomputation techniques to reduce the number of write activities on NVMs. Experimental results show that the proposed methods can reduce the number of writes by 58.46% on average, which means that the NVM can last 2.8 times as long as before. For Phase Change Memory (PCM), the lifetime is extended from 2.5 years to about 7 years on average and 15 years at the most. Also, the finish time of the tested programs is reduced by an average of 38.07%, and the energy consumption is reduced by an average of 51.23%.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2086804599",
    "type": "article"
  },
  {
    "title": "Energy-aware task mapping and scheduling for reliable embedded computing systems",
    "doi": "https://doi.org/10.1145/2544375.2544392",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Anup Das; Akash Kumar; Bharadwaj Veeravalli",
    "corresponding_authors": "",
    "abstract": "Task mapping and scheduling are critical in minimizing energy consumption while satisfying the performance requirement of applications enabled on heterogeneous multiprocessor systems. An area of growing concern for modern multiprocessor systems is the increase in the failure probability of one or more component processors. This is especially critical for applications where performance degradation (e.g., throughput) directly impacts the quality of service requirement. This article proposes a design-time (offline) multi-criterion optimization technique for application mapping on embedded multiprocessor systems to minimize energy consumption for all processor fault-scenarios. A scheduling technique is then proposed based on self-timed execution to minimize the schedule storage and construction overhead at runtime. Experiments conducted with synthetic and real applications from streaming and nonstreaming domains on heterogeneous MPSoCs demonstrate that the proposed technique minimizes energy consumption by 22% and design space exploration time by 100x, while satisfying the throughput requirement for all processor fault-scenarios. For scalable throughput applications, the proposed technique achieves 30% better throughput per unit energy, compared to the existing techniques. Additionally, the self-timed execution-based scheduling technique minimizes schedule construction time by 95% and storage overhead by 92%.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2065865627",
    "type": "article"
  },
  {
    "title": "Energy-Aware Memory Mapping for Hybrid FRAM-SRAM MCUs in Intermittently-Powered IoT Devices",
    "doi": "https://doi.org/10.1145/2983628",
    "publication_date": "2017-04-28",
    "publication_year": 2017,
    "authors": "Hrishikesh Jayakumar; Arnab Raha; Jacob R. Stevens; Vijay Raghunathan",
    "corresponding_authors": "",
    "abstract": "Forecasts project that by 2020, there will be around 50 billion devices connected to the Internet of Things (IoT), most of which will operate untethered and unplugged. While environmental energy harvesting is a promising solution to power these IoT edge devices, it introduces new complexities due to the unreliable nature of ambient energy sources. In the presence of an unreliable power supply, frequent checkpointing of the system state becomes imperative, and recent research has proposed the concept of in-situ checkpointing by using ferroelectric RAM (FRAM), an emerging non-volatile memory technology, as unified memory in these systems. Even though an entirely FRAM-based solution provides reliability, it is energy inefficient compared to SRAM due to the higher access latency of FRAM. On the other hand, an entirely SRAM-based solution is highly energy efficient but is unreliable in the face of power loss. This paper advocates an intermediate approach in hybrid FRAM-SRAM microcontrollers that involves judicious memory mapping of program sections to retain the reliability benefits provided by FRAM while performing almost as efficiently as an SRAM-based system. We propose an energy-aware memory mapping technique that maps different program sections to the hybrid FRAM-SRAM microcontroller such that energy consumption is minimized without sacrificing reliability. Our technique consists of eM-map , which performs a one-time characterization to find the optimal memory map for the functions that constitute a program and energy-align , a novel hardware-software technique that aligns the system’s powered-on time intervals to function execution boundaries, which results in further improvements in energy efficiency and performance. Experimental results obtained using the MSP430FR5739 microcontroller demonstrate a significant performance improvement of up to 2x and energy reduction of up to 20% over a state-of-the-art FRAM-based solution. Finally, we present a case study that shows the implementation of our techniques in the context of a real IoT application.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2609357516",
    "type": "article"
  },
  {
    "title": "FlashKV",
    "doi": "https://doi.org/10.1145/3126545",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Jiacheng Zhang; Youyou Lu; Jiwu Shu; Xiongjun Qin",
    "corresponding_authors": "",
    "abstract": "As the cost-per-bit of solid state disks is decreasing quickly, SSDs are supplanting HDDs in many cases, including the primary storage of key-value stores. However, simply deploying LSM-tree-based key-value stores on commercial SSDs is inefficient and induces heavy write amplification and severe garbage collection overhead under write-intensive conditions. The main cause of these critical issues comes from the triple redundant management functionalities lying in the LSM-tree, file system and flash translation layer, which block the awareness between key-value stores and flash devices. Furthermore, we observe that the performance of LSM-tree-based key-value stores is improved little by only eliminating these redundant layers, as the I/O stacks, including the cache and scheduler, are not optimized for LSM-tree’s unique I/O patterns. To address the issues above, we propose FlashKV, an LSM-tree based key-value store running on open-channel SSDs. FlashKV eliminates the redundant management and semantic isolation by directly managing the raw flash devices in the application layer. With the domain knowledge of LSM-tree and the open-channel information, FlashKV employs a parallel data layout to exploit the internal parallelism of the flash device, and optimizes the compaction, caching and I/O scheduling mechanisms specifically. Evaluations show that FlashKV effectively improves system performance by 1.5× to 4.5× and decreases up to 50% write traffic under heavy write conditions, compared to LevelDB.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2759027646",
    "type": "article"
  },
  {
    "title": "Security challenges in embedded systems",
    "doi": "https://doi.org/10.1145/2435227.2435262",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Dimitrios Serpanos; Artemios G. Voyiatzis",
    "corresponding_authors": "",
    "abstract": "Embedded systems security is a significant requirement in emerging environments, considering the increasing deployment of embedded systems in several application domains. The large number of deployed embedded systems, their limited resources and their increasing complexity render systems vulnerable to an increasing number of threats. Additionally, the involvement of sensitive, often private, information and the expectation for safe and dependable embedded platforms lead to strong security requirements, even legal ones, which require new technologies for their provision. In this article, we provide an overview of embedded security issues, used methods and technologies, identifying important challenges in this emerging field.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W1994033684",
    "type": "article"
  },
  {
    "title": "Practical Lattice-Based Digital Signature Schemes",
    "doi": "https://doi.org/10.1145/2724713",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "James Howe; Thomas Pöppelmann; Máire O’Neill; Elizabeth O’Sullivan; Tim Güneysu",
    "corresponding_authors": "",
    "abstract": "Digital signatures are an important primitive for building secure systems and are used in most real-world security protocols. However, almost all popular signature schemes are either based on the factoring assumption (RSA) or the hardness of the discrete logarithm problem (DSA/ECDSA). In the case of classical cryptanalytic advances or progress on the development of quantum computers, the hardness of these closely related problems might be seriously weakened. A potential alternative approach is the construction of signature schemes based on the hardness of certain lattice problems that are assumed to be intractable by quantum computers. Due to significant research advancements in recent years, lattice-based schemes have now become practical and appear to be a very viable alternative to number-theoretic cryptography. In this article, we focus on recent developments and the current state of the art in lattice-based digital signatures and provide a comprehensive survey discussing signature schemes with respect to practicality. Additionally, we discuss future research areas that are essential for the continued development of lattice-based cryptography.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2093721992",
    "type": "article"
  },
  {
    "title": "Security-Aware Scheduling of Embedded Control Tasks",
    "doi": "https://doi.org/10.1145/3126518",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Vuk Lesi; Ilija Jovanov; Miroslav Pajić",
    "corresponding_authors": "",
    "abstract": "In this work, we focus on securing cyber-physical systems (CPS) in the presence of network-based attacks, such as Man-in-the-Middle (MitM) attacks, where a stealthy attacker is able to compromise communication between system sensors and controllers. Standard methods for this type of attacks rely on the use of cryptographic mechanisms, such as Message Authentication Codes (MACs) to ensure data integrity. However, this approach incurs significant computation overhead, limiting its use in resource constrained systems. Consequently, we consider the problem of scheduling multiple control tasks on a shared processor while providing a suitable level of security guarantees. Specifically, by security guarantees we refer to control performance, i.e., Quality-of-Control (QoC), in the presence of attacks. We start by mapping requirements for QoC under attack into constraints for security-aware control tasks that, besides standard control operations, intermittently perform data authentication. This allows for the analysis of the impact that security-related computation overhead has on both schedulability of control tasks and QoC. Building on this analysis, we introduce a mixed-integer linear programming-based technique to obtain a schedulable task set with predefined QoC requirements. Also, to facilitate optimal resource allocation, we provide a method to analyze interplay between available computational resources and the overall QoC under attack, and show how to obtain a schedulable task set that maximizes the overall QoC guarantees. Finally, we prove usability of our approach on a case study with multiple automotive control components.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2757117954",
    "type": "article"
  },
  {
    "title": "Timing effects of DDR memory systems in hard real-time multicore architectures",
    "doi": "https://doi.org/10.1145/2435227.2435260",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Marco Paolieri; Eduardo Quiñones; Francisco J. Cazorla",
    "corresponding_authors": "",
    "abstract": "Multicore processors are an effective solution to cope with the performance requirements of real-time embedded systems due to their good performance-per-watt ratio and high performance capabilities. Unfortunately, their use in integrated architectures such as IMA or AUTOSAR is limited by the fact that multicores do not guarantee a time composable behavior for the applications: the WCET of a task depends on inter-task interferences introduced by other tasks running simultaneously. This article focuses on the off-chip memory system: the hardware shared resource with the highest impact on the WCET and hence the main impediment for the use of multicores in integrated architectures. We present an analytical model that computes the worst-case delay, also known as Upper Bound Delay (UBD), that a memory request can suffer due to memory interferences generated by other co-running tasks. By considering the UBD in the WCET analysis, the resulting WCET estimation is independent from the other tasks, hence ensuring the time composability property and enabling the use of multicores in integrated architectures. We propose a memory controller for hard real-time multicores compliant with the analytical model that implements extra hardware features to deal with refresh operations and interferences generated by co-running non hard real-time tasks.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2095712519",
    "type": "article"
  },
  {
    "title": "A Unified WCET analysis framework for multicore platforms",
    "doi": "https://doi.org/10.1145/2584654",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Sudipta Chattopadhyay; Lee Kee Chong; Abhik Roychoudhury; Timon Kelter; Peter Marwedel; Heiko Falk",
    "corresponding_authors": "",
    "abstract": "With the advent of multicore architectures, worst-case execution time (WCET) analysis has become an increasingly difficult problem. In this article, we propose a unified WCET analysis framework for multicore processors featuring both shared cache and shared bus. Compared to other previous works, our work differs by modeling the interaction of shared cache and shared bus with other basic microarchitectural components (e.g., pipeline and branch predictor). In addition, our framework does not assume a timing anomaly free multicore architecture for computing the WCET. A detailed experiment methodology suggests that we can obtain reasonably tight WCET estimates in a wide range of benchmark programs.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2036213524",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Thread Assignment Optimization for Heterogeneous Multicore Systems",
    "doi": "https://doi.org/10.1145/2566618",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Vinícius Petrucci; Orlando Loques; Daniel Mossé; Rami Melhem; Neven Abou Gazala; Sameh Gobriel",
    "corresponding_authors": "",
    "abstract": "The current trend to move from homogeneous to heterogeneous multicore systems provides compelling opportunities for achieving performance and energy efficiency goals. Running multiple threads in multicore systems poses challenges on meeting limited shared resources, such as memory bandwidth. We propose an optimization approach that includes an Integer Linear Programming (ILP) optimization model and a scheme to dynamically determine thread-to-core assignment. We present simulation analysis that shows energy savings and performance gains for a variety of workloads compared to state-of-the-art schemes. We implemented and evaluated a prototype of our thread assignment approach at user level, leveraging Linux scheduling and performance-monitoring capabilities.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2051785559",
    "type": "article"
  },
  {
    "title": "One-Step Look-Ahead Maximally Permissive Deadlock Control of AMS by Using Petri Nets",
    "doi": "https://doi.org/10.1145/2406336.2406346",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Naiqi Wu; MengChu Zhou; Gang Hu",
    "corresponding_authors": "",
    "abstract": "It is desired that a deadlock control policy for automated manufacturing systems (AMS) is maximally permissive. However, its tractability issue remains open, and this work addresses this important issue. It models AMS with a resource-oriented Petri net (ROPN) and presents a necessary and sufficient condition under which there exists a one-step look-ahead maximally permissive control policy for deadlock avoidance in AMS. It further identifies some conditions under which a one-step look-ahead maximally permissive deadlock control policy exists for a single-capacity system. The conditions can be conveniently examined by using the developed ROPN model.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2131815807",
    "type": "article"
  },
  {
    "title": "On Constrained Implementation of Lattice-Based Cryptographic Primitives and Schemes on Smart Cards",
    "doi": "https://doi.org/10.1145/2700078",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Ahmad Boorghany; Siavash Bayat-Sarmadi; Rasool Jalili",
    "corresponding_authors": "",
    "abstract": "Most lattice-based cryptographic schemes with a security proof suffer from large key sizes and heavy computations. This is also true for the simpler case of authentication protocols that are used on smart cards as a very-constrained computing environment. Recent progress on ideal lattices has significantly improved the efficiency and made it possible to implement practical lattice-based cryptography on constrained devices. However, to the best of our knowledge, no previous attempts have been made to implement lattice-based schemes on smart cards. In this article, we provide the results of our implementation of several state-of-the-art lattice-based authentication protocols on smart cards and a microcontroller widely used in smart cards. Our results show that only a few of the proposed lattice-based authentication protocols can be implemented using limited resources of such constrained devices; however, cutting-edge ones are suitably efficient to be used practically on smart cards. Moreover, we have implemented fast Fourier transform (FFT) and discrete Gaussian sampling with different typical parameter sets, as well as versatile lattice-based public-key encryptions. These results have noticeable points that help to design or optimize lattice-based schemes for constrained devices.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2151954684",
    "type": "article"
  },
  {
    "title": "LiBrA-CAN",
    "doi": "https://doi.org/10.1145/3056506",
    "publication_date": "2017-04-06",
    "publication_year": 2017,
    "authors": "Bogdan Groza; Pal-Stefan Murvay; Anthony Van Herrewege; Ingrid Verbauwhede",
    "corresponding_authors": "",
    "abstract": "Despite realistic concerns, security is still absent from vehicular buses such as the widely used Controller Area Network (CAN). We design an efficient protocol based on efficient symmetric primitives, taking advantage of two innovative procedures: splitting keys between nodes and mixing authentication tags. This results in a higher security level when compromised nodes are in the minority, a realistic assumption for automotive networks. Experiments are performed on state-of-the-art Infineon TriCore controllers, contrasted with low-end Freescale S12X cores, while simulations are provided for the recently released CAN-FD standard. To gain compatibility with existent networks, we also discuss a solution based on CAN+.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2604623014",
    "type": "article"
  },
  {
    "title": "Runtime Enforcement of Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3126500",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Srinivas Pinisetty; Partha S. Roop; Steven Smyth; Nathan Allen; Stavros Tripakis; Reinhard von Hanxleden",
    "corresponding_authors": "",
    "abstract": "Many implantable medical devices, such as pacemakers, have been recalled due to failure of their embedded software. This motivates rethinking their design and certification processes. We propose, for the first time, an additional layer of safety by formalising the problem of run-time enforcement of implantable pacemakers. While recent work has formalised run-time enforcement of reactive systems, the proposed framework generalises existing work along the following directions: (1) we develop bi-directional enforcement, where the enforced policies depend not only on the status of the pacemaker (the controller) but also of the heart (the plant), thus formalising the run-time enforcement problem for cyber-physical systems (2) we express policies using a variant of discrete timed automata (DTA), which can cover all regular properties unlike earlier frameworks limited to safety properties, (3) we are able to ensure the timing safety of implantable devices through the proposed enforcement, and (4) we show that the DTA-based approach is efficient relative to its dense time variant while ensuring that the discretisation error is relatively small and bounded. The developed approach is validated through a prototype system implemented using the open source KIELER framework. The experiments show that the framework incurs minimal runtime overhead.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2757214569",
    "type": "article"
  },
  {
    "title": "Weakly Hard Schedulability Analysis for Fixed Priority Scheduling of Periodic Real-Time Tasks",
    "doi": "https://doi.org/10.1145/3126497",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Youcheng Sun; Marco Di Natale",
    "corresponding_authors": "",
    "abstract": "The hard deadline model is very popular in real-time research, but is representative or applicable to a small number of systems. Many applications, including control systems, are capable of tolerating occasional deadline misses, but are seriously compromised by a repeating pattern of late terminations. The weakly hard real-time model tries to capture these requirements by analyzing the conditions that guarantee that a maximum number of deadlines can be possibly missed in any set of consecutive activations. We provide a new weakly hard schedulability analysis method that applies to constrained-deadline periodic real-time systems scheduled with fixed priority and without knowledge of the task activation offsets. The analysis is based on a Mixed Integer Linear Programming (MILP) problem formulation; it is very general and can be adapted to include the consideration of resource sharing and activation jitter. A set of experiments conducted on an automotive engine control application and randomly generated tasksets show the applicability and accuracy of the proposed technique.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2760380815",
    "type": "article"
  },
  {
    "title": "Effective Runtime Resource Management Using Linux Control Groups with the BarbequeRTRM Framework",
    "doi": "https://doi.org/10.1145/2658990",
    "publication_date": "2015-03-09",
    "publication_year": 2015,
    "authors": "Patrick Bellasi; Giuseppe Massari; William Fornaciari",
    "corresponding_authors": "",
    "abstract": "The extremely high technology process reached by silicon manufacturing (smaller than 32nm) has led to production of computational platforms and SoC, featuring a considerable amount of resources. Whereas from one side such multi- and many-core platforms show growing performance capabilities, from the other side they are more and more affected by power, thermal, and reliability issues. Moreover, the increased computational capabilities allows congested usage scenarios with workloads subject to mixed and time-varying requirements. Effective usage of the resources should take into account both the application requirements and resources availability , with an arbiter, namely a resource manager in charge to solve the resource contention among demanding applications. Current operating systems (OS) have only a limited knowledge about application-specific behaviors and their time-varying requirements. Dedicated system interfaces to collect such inputs and forward them to the OS (e.g., its scheduler) are thus an interesting research area that aims at integrating the OS with an ad hoc resource manager. Such a component can exploit efficient low-level OS interfaces and mechanisms to extend its capabilities of controlling tasks and system resources. Because of the specific tasks and timings of a resource manager, this component can be easily and effectively developed as a user-space extension lying in between the OS and the controlled application. This article, which focuses on multicore Linux systems, shows a portable solution to enforce runtime resource management decisions based on the standard control groups framework. A burst and a mixed workload analysis, performed on a multicore-based NUMA platform, have reported some promising results both in terms of performance and power saving.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W1990339909",
    "type": "article"
  },
  {
    "title": "BTMonitor",
    "doi": "https://doi.org/10.1145/3362034",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Jia Zhou; Prachi Joshi; Haibo Zeng; Renfa Li",
    "corresponding_authors": "",
    "abstract": "With the rapid growth of connectivity and autonomy for today’s automobiles, their security vulnerabilities are becoming one of the most urgent concerns in the automotive industry. The lack of message authentication in Controller Area Network (CAN), which is the most popular in-vehicle communication protocol, makes it susceptible to cyber attack. It has been demonstrated that the remote attackers can take over the maneuver of vehicles after getting access to CAN, which poses serious safety threats to the public. To mitigate this issue, we propose a novel intrusion detection system (IDS), called BTMonitor (Bit-time-based CAN Bus Monitor). It utilizes the small but measurable discrepancy of bit time in CAN frames to fingerprint their sender Electronic Control Units (ECUs). To reduce the requirement for high sampling rate, we calculate the bit time of recessive bits and dominant bits, respectively, and extract their statistical features as fingerprint. The generated fingerprint is then used to detect intrusion and pinpoint the attacker. BTMonitor can detect new types of masquerade attack that the state-of-the-art clock-skew-based IDS is unable to identify. We implement a prototype system for BTMonitor using Xilinx Spartan 6 FPGA for data collection. We evaluate our method on both a CAN bus prototype and a real vehicle. The results show that BTMonitor can correctly identify the sender with an average probability of 99.76% on the real vehicle.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2986731541",
    "type": "article"
  },
  {
    "title": "Mobile Computations with Surrounding Devices",
    "doi": "https://doi.org/10.1145/2656214",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Seng W. Loke; Keegan Napier; Abdulaziz Al-Ali; Niroshinie Fernando; Wenny Rahayu",
    "corresponding_authors": "",
    "abstract": "With the proliferation of mobile devices, and their increasingly powerful embedded processors and storage, vast resources increasingly surround users. We have been investigating the concept of on-demand ad hoc forming of groups of nearby mobile devices in the midst of crowds to cooperatively perform computationally intensive tasks as a service to local mobile users, or what we call mobile crowd computing. As devices can vary in processing power and some can leave a group unexpectedly or new devices join in, there is a need for algorithms that can distribute work in a flexible manner and still work with different arrangements of devices that can arise in an ad hoc fashion. In this article, we first argue for the feasibility of such use of crowd-embedded computations using theoretical justifications and reporting on our experiments on Bluetooth-based proximity sensing. We then present a multilayered work-stealing style algorithm for distributing work efficiently among mobile devices and compare speedups attainable for different topologies of devices networked with Bluetooth, justifying a topology-flexible opportunistic approach. While our experiments are with Bluetooth and mobile devices, the approach is applicable to ecosystems of various embedded devices with powerful processors, networking technologies, and storage that will increasingly surround users.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2048231144",
    "type": "article"
  },
  {
    "title": "Fault Detection Architectures for Post-Quantum Cryptographic Stateless Hash-Based Secure Signatures Benchmarked on ASIC",
    "doi": "https://doi.org/10.1145/2930664",
    "publication_date": "2016-12-12",
    "publication_year": 2016,
    "authors": "Mehran Mozaffari Kermani; Reza Azarderakhsh; Anita Aghaie",
    "corresponding_authors": "",
    "abstract": "Symmetric-key cryptography can resist the potential post-quantum attacks expected with the not-so-faraway advent of quantum computing power. Hash-based, code-based, lattice-based, and multivariate-quadratic equations are all other potential candidates, the merit of which is that they are believed to resist both classical and quantum computers, and applying “Shor’s algorithm”—the quantum-computer discrete-logarithm algorithm that breaks classical schemes—to them is infeasible. In this article, we propose, assess, and benchmark reliable constructions for stateless hash-based signatures. Such architectures are believed to be one of the prominent post-quantum schemes, offering security proofs relative to plausible properties of the hash function; however, it is well known that their confidentiality does not guarantee reliable architectures in the presence natural and malicious faults. We propose and benchmark fault diagnosis methods for this post-quantum cryptography variant through case studies for hash functions and present the simulations and implementations results (through application-specific integrated circuit evaluations) to show the applicability of the presented schemes. The proposed approaches make such hash-based constructions more reliable against natural faults and help protecting them against malicious faults and can be tailored based on the resources available and for different reliability objectives.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2565780392",
    "type": "article"
  },
  {
    "title": "Energy Cooperation in Battery-Free Wireless Communications with Radio Frequency Energy Harvesting",
    "doi": "https://doi.org/10.1145/3141249",
    "publication_date": "2018-02-13",
    "publication_year": 2018,
    "authors": "He Li; Kaoru Ota; Mianxiong Dong",
    "corresponding_authors": "",
    "abstract": "Radio frequency (RF) energy harvesting techniques are becoming a potential method to power battery-free wireless networks. In RF energy harvesting communications, energy cooperation enables shaping and optimization of the energy arrivals at the energy-receiving node to improve the overall system performance. In this article, we propose an energy cooperation scheme that enables energy cooperation in battery-free wireless networks with RF harvesting. We first study the battery-free wireless network with RF energy harvesting and then state the problem that optimizing the system performance with limited harvesting energy through new energy cooperation protocol. Finally, from the extensive simulation results, our energy cooperation protocol performs better than the original battery-free wireless network solution.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2792931786",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Multicore Scheduling for Hard Real-Time Systems",
    "doi": "https://doi.org/10.1145/3291387",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Saad Zia Sheikh; Muhammad Adeel Pasha",
    "corresponding_authors": "",
    "abstract": "As real-time embedded systems are evolving in scale and complexity, the demand for a higher performance at a minimum energy consumption has become a necessity. Consequently, many embedded systems are now adopting multicore architectures into their design. However, scheduling on multicores is not a trivial task and scheduling to minimize the energy consumption further increases the complexity of the problem. This problem is especially aggravated for hard real-time systems where failure to meet a deadline can be catastrophic. Such scheduling algorithms yearn for a polynomial time complexity for the task-to-core assignment problem with an objective to minimize the overall energy consumption. There is now a trend toward heterogeneous multicores where cores differ in power, performance, and architectural capabilities. The desired performance and energy consumption is attained by assigning a task to the core that is best suited for it. In this article, we present a survey on energy-efficient multicore scheduling algorithms for hard real-time systems. We summarize various algorithms reported in the literature and classify them based on Partitioned, Semi-Partitioned, and Global scheduling techniques for both homogeneous and heterogeneous multicores. We also present a detailed discussion on various open issues within this domain.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2905931660",
    "type": "article"
  },
  {
    "title": "Flexible PV-cell Modeling for Energy Harvesting in Wearable IoT Applications",
    "doi": "https://doi.org/10.1145/3126568",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Jaehyun Park; Hitesh Joshi; Hyung Gyu Lee; Sayfe Kiaei; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "Wearable devices with sensing, processing and communication capabilities have become feasible with the advances in internet-of-things (IoT) and low power design technologies. Energy harvesting is extremely important for wearable IoT devices due to size and weight limitations of batteries. One of the most widely used energy harvesting sources is photovoltaic cell (PV-cell) owing to its simplicity and high output power. In particular, flexible PV-cells offer great potential for wearable applications. This paper models, for the first time , how bending a PV-cell significantly impacts the harvested energy. Furthermore, we derive an analytical model to quantify the harvested energy as a function of the radius of curvature. We validate the proposed model empirically using a commercial PV-cell under a wide range of bending scenarios, light intensities and elevation angles. Finally, we show that the proposed model can accelerate maximum power point tracking algorithms and increase the harvested energy by up to 25.0%.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2760630439",
    "type": "article"
  },
  {
    "title": "Verifying the Safety of Autonomous Systems with Neural Network Controllers",
    "doi": "https://doi.org/10.1145/3419742",
    "publication_date": "2020-12-07",
    "publication_year": 2020,
    "authors": "Radoslav Ivanov; Taylor J. Carpenter; James Weimer; Rajeev Alur; George J. Pappas; Insup Lee",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of verifying the safety of autonomous systems with neural network (NN) controllers. We focus on NNs with sigmoid/tanh activations and use the fact that the sigmoid/tanh is the solution to a quadratic differential equation. This allows us to convert the NN into an equivalent hybrid system and cast the problem as a hybrid system verification problem, which can be solved by existing tools. Furthermore, we improve the scalability of the proposed method by approximating the sigmoid with a Taylor series with worst-case error bounds. Finally, we provide an evaluation over four benchmarks, including comparisons with alternative approaches based on mixed integer linear programming as well as on star sets.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W3113369941",
    "type": "article"
  },
  {
    "title": "Polar",
    "doi": "https://doi.org/10.1145/3358227",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Zhengxiong Luo; Feilong Zuo; Yu Jiang; Jian Gao; Xun Jiao; Jiaguang Sun",
    "corresponding_authors": "",
    "abstract": "Industrial Control System (ICS) protocols are widely used to build communications among system components. Compared with common internet protocols, ICS protocols have more control over remote devices by carrying a specific field called “function code”, which assigns what the receive end should do. Therefore, it is of vital importance to ensure their correctness. However, traditional vulnerability detection techniques such as fuzz testing are challenged by the increasing complexity of these diverse ICS protocols. In this paper, we present a function code aware fuzzing framework — Polar, which automatically extracts semantic information from the ICS protocol and utilizes this information to accelerate security vulnerability detection. Based on static analysis and dynamic taint analysis, Polar initiates the values of the function code field and identifies some vulnerable operations. Then, novel semantic aware mutation and selection strategies are designed to optimize the fuzzing procedure. For evaluation, we implement Polar on top of two popular fuzzers — AFL and AFLFast, and conduct experiments on several widely used ICS protocols such as Modbus, IEC104, and IEC 61850. Results show that, compared with AFL and AFLFast, Polar achieves the same code coverage and bug detection numbers at the speed of 1.5X-12X. It also gains increase with 0%--91% more paths within 24 hours. Furthermore, Polar has exposed 10 previously unknown vulnerabilities in those protocols, 6 of which have been assigned unique CVE identifiers in the US National Vulnerability Database.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2980096664",
    "type": "article"
  },
  {
    "title": "Learning Nondeterministic Real-Time Automata",
    "doi": "https://doi.org/10.1145/3477030",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Jie An; Bohua Zhan; Naijun Zhan; Miaomiao Zhang",
    "corresponding_authors": "",
    "abstract": "We present an active learning algorithm named NRTALearning for nondeterministic real-time automata (NRTAs). Real-time automata (RTAs) are a subclass of timed automata with only one clock which resets at each transition. First, we prove the corresponding Myhill-Nerode theorem for real-time languages. Then we show that there exists a unique minimal deterministic real-time automaton (DRTA) recognizing a given real-time language, but the same does not hold for NRTAs. We thus define a special kind of NRTAs, named residual real-time automata (RRTAs), and prove that there exists a minimal RRTA to recognize any given real-time language. This transforms the learning problem of NRTAs to the learning problem of RRTAs. After describing the learning algorithm in detail, we prove its correctness and polynomial complexity. In addition, based on the corresponding Myhill-Nerode theorem, we extend the existing active learning algorithm NL* for nondeterministic finite automata to learn RRTAs. We evaluate and compare the two algorithms on two benchmarks consisting of randomly generated NRTAs and rational regular expressions. The results show that NRTALearning generally performs fewer membership queries and more equivalence queries than the extended NL* algorithm, and the learnt NRTAs have much fewer locations than the corresponding minimal DRTAs. We also conduct a case study using a model of scheduling of final testing of integrated circuits.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W3201497886",
    "type": "article"
  },
  {
    "title": "Reliability-aware Scheduling and Routing for Messages in Time-sensitive Networking",
    "doi": "https://doi.org/10.1145/3458768",
    "publication_date": "2021-05-29",
    "publication_year": 2021,
    "authors": "Yuanbin Zhou; Soheil Samii; Petru Eles; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "Time-sensitive Networking (TSN) on Ethernet is a promising communication technology in the automotive and industrial automation industries due to its real-time and high-bandwidth communication capabilities. Time-triggered scheduling and static routing are often adopted in these areas due to high requirements on predictability for safety-critical applications. Deadline-constrained routing and scheduling in TSN have been studied extensively in past research. However, scheduling and routing with reliability requirements in the context of transient faults are not yet studied. In this work, we propose an Satisfiability Modulo Theory-based technique to perform scheduling and routing that takes both reliability constraints and end-to-end deadline constraints into consideration. Heuristics have been applied to improve the scalability of the solution. Extensive experiments have been conducted to demonstrate the efficiency of our proposed technique.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W3170788757",
    "type": "article"
  },
  {
    "title": "Algorithm-hardware Co-design of Attention Mechanism on FPGA Devices",
    "doi": "https://doi.org/10.1145/3477002",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Xinyi Zhang; Yawen Wu; Peipei Zhou; Xulong Tang; Jingtong Hu",
    "corresponding_authors": "",
    "abstract": "Multi-head self-attention (attention mechanism) has been employed in a variety of fields such as machine translation, language modeling, and image processing due to its superiority in feature extraction and sequential data analysis. This is benefited from a large number of parameters and sophisticated model architecture behind the attention mechanism. To efficiently deploy attention mechanism on resource-constrained devices, existing works propose to reduce the model size by building a customized smaller model or compressing a big standard model. A customized smaller model is usually optimized for the specific task and needs effort in model parameters exploration. Model compression reduces model size without hurting the model architecture robustness, which can be efficiently applied to different tasks. The compressed weights in the model are usually regularly shaped (e.g. rectangle) but the dimension sizes vary (e.g. differs in rectangle height and width). Such compressed attention mechanism can be efficiently deployed on CPU/GPU platforms as their memory and computing resources can be flexibly assigned with demand. However, for Field Programmable Gate Arrays (FPGAs), the data buffer allocation and computing kernel are fixed at run time to achieve maximum energy efficiency. After compression, weights are much smaller and different in size, which leads to inefficient utilization of FPGA on-chip buffer. Moreover, the different weight heights and widths may lead to inefficient FPGA computing kernel execution. Due to the large number of weights in the attention mechanism, building a unique buffer and computing kernel for each compressed weight on FPGA is not feasible. In this work, we jointly consider the compression impact on buffer allocation and the required computing kernel during the attention mechanism compressing. A novel structural pruning method with memory footprint awareness is proposed and the associated accelerator on FPGA is designed. The experimental results show that our work can compress Transformer (an attention mechanism based model) by 95x. The developed accelerator can fully utilize the FPGA resource, processing the sparse attention mechanism with the run-time throughput performance of 1.87 Tops in ZCU102 FPGA.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W3199934250",
    "type": "article"
  },
  {
    "title": "Intermittent-Aware Neural Architecture Search",
    "doi": "https://doi.org/10.1145/3476995",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Hashan Roshantha Mendis; Chih-Kai Kang; Pi-Cheng Hsiu",
    "corresponding_authors": "",
    "abstract": "The increasing paradigm shift towards i ntermittent computing has made it possible to intermittently execute d eep neural network (DNN) inference on edge devices powered by ambient energy. Recently, n eural architecture search (NAS) techniques have achieved great success in automatically finding DNNs with high accuracy and low inference latency on the deployed hardware. We make a key observation, where NAS attempts to improve inference latency by primarily maximizing data reuse, but the derived solutions when deployed on intermittently-powered systems may be inefficient, such that the inference may not satisfy an end-to-end latency requirement and, more seriously, they may be unsafe given an insufficient energy budget. This work proposes iNAS, which introduces intermittent execution behavior into NAS to find accurate network architectures with corresponding execution designs, which can safely and efficiently execute under intermittent power. An intermittent-aware execution design explorer is presented, which finds the right balance between data reuse and the costs related to intermittent inference, and incorporates a preservation design search space into NAS, while ensuring the power-cycle energy budget is not exceeded. To assess an intermittent execution design, an intermittent-aware abstract performance model is presented, which formulates the key costs related to progress preservation and recovery during intermittent inference. We implement iNAS on top of an existing NAS framework and evaluate their respective solutions found for various datasets, energy budgets and latency requirements, on a Texas Instruments device. Compared to those NAS solutions that can safely complete the inference, the iNAS solutions reduce the intermittent inference latency by 60% on average while achieving comparable accuracy, with an average 7% increase in search overhead.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W3200382295",
    "type": "article"
  },
  {
    "title": "DFSynthesizer: Dataflow-based Synthesis of Spiking Neural Networks to Neuromorphic Hardware",
    "doi": "https://doi.org/10.1145/3479156",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Shihao Song; Harry Lye Hin Chong; Adarsha Balaji; Anup Das; James Shackleford; Nagarajan Kandasamy",
    "corresponding_authors": "",
    "abstract": "Spiking Neural Networks (SNNs) are an emerging computation model that uses event-driven activation and bio-inspired learning algorithms. SNN-based machine learning programs are typically executed on tile-based neuromorphic hardware platforms, where each tile consists of a computation unit called a crossbar, which maps neurons and synapses of the program. However, synthesizing such programs on an off-the-shelf neuromorphic hardware is challenging. This is because of the inherent resource and latency limitations of the hardware, which impact both model performance, e.g., accuracy, and hardware performance, e.g., throughput. We propose DFSynthesizer, an end-to-end framework for synthesizing SNN-based machine learning programs to neuromorphic hardware. The proposed framework works in four steps. First, it analyzes a machine learning program and generates SNN workload using representative data. Second, it partitions the SNN workload and generates clusters that fit on crossbars of the target neuromorphic hardware. Third, it exploits the rich semantics of the Synchronous Dataflow Graph (SDFG) to represent a clustered SNN program, allowing for performance analysis in terms of key hardware constraints such as number of crossbars, dimension of each crossbar, buffer space on tiles, and tile communication bandwidth. Finally, it uses a novel scheduling algorithm to execute clusters on crossbars of the hardware, guaranteeing hardware performance. We evaluate DFSynthesizer with 10 commonly used machine learning programs. Our results demonstrate that DFSynthesizer provides a much tighter performance guarantee compared to current mapping approaches.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3191283164",
    "type": "article"
  },
  {
    "title": "AHA: An Agile Approach to the Design of Coarse-Grained Reconfigurable Accelerators and Compilers",
    "doi": "https://doi.org/10.1145/3534933",
    "publication_date": "2022-07-07",
    "publication_year": 2022,
    "authors": "Kalhan Koul; Jackson Melchert; Kavya Sreedhar; Leonard Truong; Gedeon Nyengele; Keyi Zhang; Qiaoyi Liu; Jeff Setter; Po‐Han Chen; Yuchen Mei; Maxwell Strange; Ross Daly; Caleb Donovick; Alex Carsello; Taeyoung Kong; Kathleen Feng; Dillon Huff; Ankita Nayak; Rajsekhar Setaluri; James J. Thomas; Nikhil Bhagdikar; David Durst; Zachary Myers; Nestan Tsiskaridze; Stephen Richardson; Rick Bahr; Kayvon Fatahalian; Pat Hanrahan; Clark Barrett; Mark Horowitz; Christopher Torng; Fredrik Kjølstad; Priyanka Raina",
    "corresponding_authors": "",
    "abstract": "With the slowing of Moore’s law, computer architects have turned to domain-specific hardware specialization to continue improving the performance and efficiency of computing systems. However, specialization typically entails significant modifications to the software stack to properly leverage the updated hardware. The lack of a structured approach for updating the compiler and the accelerator in tandem has impeded many attempts to systematize this procedure. We propose a new approach to enable flexible and evolvable domain-specific hardware specialization based on coarse-grained reconfigurable arrays (CGRAs). Our agile methodology employs a combination of new programming languages and formal methods to automatically generate the accelerator hardware and its compiler from a single source of truth. This enables the creation of design-space exploration frameworks that automatically generate accelerator architectures that approach the efficiencies of hand-designed accelerators, with a significantly lower design effort for both hardware and compiler generation. Our current system accelerates dense linear algebra applications but is modular and can be extended to support other domains. Our methodology has the potential to significantly improve the productivity of hardware-software engineering teams and enable quicker customization and deployment of complex accelerator-rich computing systems.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W4284689293",
    "type": "article"
  },
  {
    "title": "Human Activity Recognition on Microcontrollers with Quantized and Adaptive Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3542819",
    "publication_date": "2022-07-31",
    "publication_year": 2022,
    "authors": "Francesco Daghero; Alessio Burrello; Chen Xie; Marco Castellano; Luca Gandolfi; Andrea Calimera; Enrico Macii; Massimo Poncino; Daniele Jahier Pagliari",
    "corresponding_authors": "",
    "abstract": "Human Activity Recognition (HAR) based on inertial data is an increasingly diffused task on embedded devices, from smartphones to ultra low-power sensors. Due to the high computational complexity of deep learning models, most embedded HAR systems are based on simple and not-so-accurate classic machine learning algorithms. This work bridges the gap between on-device HAR and deep learning, proposing a set of efficient one-dimensional Convolutional Neural Networks (CNNs) that can be deployed on general purpose microcontrollers (MCUs). Our CNNs are obtained combining hyper-parameters optimization with sub-byte and mixed-precision quantization, to find good trade-offs between classification results and memory occupation. Moreover, we also leverage adaptive inference as an orthogonal optimization to tune the inference complexity at runtime based on the processed input, hence producing a more flexible HAR system. With experiments on four datasets, and targeting an ultra-low-power RISC-V MCU, we show that (i) we are able to obtain a rich set of Pareto-optimal CNNs for HAR, spanning more than 1 order of magnitude in terms of memory, latency, and energy consumption; (ii) thanks to adaptive inference, we can derive &gt;20 runtime operating modes starting from a single CNN, differing by up to 10% in classification scores and by more than 3× in inference complexity, with a limited memory overhead; (iii) on three of the four benchmarks, we outperform all previous deep learning methods, while reducing the memory occupation by more than 100×. The few methods that obtain better performance (both shallow and deep) are not compatible with MCU deployment; (iv) all our CNNs are compatible with real-time on-device HAR, achieving an inference latency that ranges between 9 μs and 16 ms. Their memory occupation varies in 0.05–23.17 kB, and their energy consumption in 0.05 and 61.59 μJ, allowing years of continuous operation on a small battery supply.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W4292722085",
    "type": "article"
  },
  {
    "title": "DNN Is Not All You Need: Parallelizing Non-neural ML Algorithms on Ultra-low-power IoT Processors",
    "doi": "https://doi.org/10.1145/3571133",
    "publication_date": "2023-04-19",
    "publication_year": 2023,
    "authors": "Enrico Tabanelli; Giuseppe Tagliavini; Luca Benini",
    "corresponding_authors": "",
    "abstract": "Machine Learning (ML) functions are becoming ubiquitous in latency- and privacy-sensitive IoT applications, prompting a shift toward near-sensor processing at the extreme edge and the consequent increasing adoption of Parallel Ultra-low-power (PULP) IoT processors. These compute- and memory-constrained parallel architectures need to run efficiently a wide range of algorithms, including key Non-neural ML kernels that compete favorably with Deep Neural Networks in terms of accuracy under severe resource constraints. In this article, we focus on enabling efficient parallel execution of Non-neural ML algorithms on two RISCV-based PULP platforms, namely, GAP8, a commercial chip, and PULP-OPEN, a research platform running on an FPGA emulator. We optimized the parallel algorithms through a fine-grained analysis and intensive optimization to maximize the speedup, considering two alternative Floating-point (FP) emulation libraries on GAP8 and the native FPU support on PULP-OPEN. Experimental results show that a target-optimized emulation library can lead to an average 1.61× runtime improvement and 37% energy reduction compared to a standard emulation library, while the native FPU support reaches up to 32.09× and 99%, respectively. In terms of parallel speedup, our design improves the sequential execution by 7.04× on average on the targeted octa-core platforms leading to energy and latency decrease up to 87%. Last, we present a comparison with the ARM Cortex-M4 microcontroller, a widely adopted commercial solution for edge deployments, which is 12.87× slower than PULP-OPEN.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3185199394",
    "type": "article"
  },
  {
    "title": "TyBox: An Automatic Design and Code Generation Toolbox for TinyML Incremental On-Device Learning",
    "doi": "https://doi.org/10.1145/3604566",
    "publication_date": "2023-06-17",
    "publication_year": 2023,
    "authors": "Massimo Pavan; Eugeniu Ostrovan; Armando Caltabiano; Manuel Roveri",
    "corresponding_authors": "",
    "abstract": "Incremental on-device learning is one of the most relevant and interesting challenges in the field of Tiny Machine Learning (TinyML). Indeed, differently from traditional TinyML solutions where the training is typically carried out on the Cloud and inference only occurs on the tiny devices (e.g., embedded systems or Internet-of-Things units), incremental on-device TinyML allows both the inference and the training of TinyML models directly on tiny devices. This ability paves the way for TinyML-enabled intelligent devices that can learn directly on the field and adapt to evolving environments, different working conditions, or specific users. The literature in this field is quite limited with very few solutions focusing only on the incremental fine-tuning of machine learning models, whereas a general solution encompassing algorithms and code generation for incremental on-device TinyML is still perceived as missing. The aim of this article is to introduce, to the best of our knowledge for the first time in the literature, a toolbox called TyBox for the automatic design and code generation of incremental on-device TinyML classification models. In more detail, starting from a “static” TinyML model, TyBox is able to (i) automatically design the “incremental” on-device version of the TinyML model that has been suitably designed to take into account the technological constraint on the RAM memory of the target tiny device, and (ii) autonomously provide the C++ codes and libraries to support the inference and learning of the incremental on-device TinyML model directly on the tiny devices. TyBox has been extensively compared with a state-of-the-art incremental learning solution for TinyML and tested on an off-the-shelf tiny device (i.e., the Arduino Nano 33 BLE) in three relevant TinyML application tasks and scenarios: binary image classification, multi-class image classification, and ultra-wide-band human activity recognition. In addition, TyBox is released to the scientific community as a public repository.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4381054159",
    "type": "article"
  },
  {
    "title": "ViT4Mal: Lightweight Vision Transformer for Malware Detection on Edge Devices",
    "doi": "https://doi.org/10.1145/3609112",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Akshara Ravi; Vivek Chaturvedi; Muhammad Shafique",
    "corresponding_authors": "",
    "abstract": "There has been a tremendous growth of edge devices connected to the network in recent years. Although these devices make our life simpler and smarter, they need to perform computations under severe resource and energy constraints, while being vulnerable to malware attacks. Once compromised, these devices are further exploited as attack vectors targeting critical infrastructure. Most existing malware detection solutions are resource and compute-intensive and hence perform poorly in protecting edge devices. In this paper, we propose a novel approach ViT4Mal that utilizes a lightweight vision transformer (ViT) for malware detection on an edge device. ViT4Mal first converts executable byte-code into images to learn malware features and later uses a customized lightweight ViT to detect malware with high accuracy. We have performed extensive experiments to compare our model with state-of-the-art CNNs in the malware detection domain. Experimental results corroborate that ViTs don’t demand deeper networks to achieve comparable accuracy of around 97% corresponding to heavily structured CNN models. We have also performed hardware deployment of our proposed lightweight ViT4Mal model on the Xilinx PYNQ Z1 FPGA board by applying specialized hardware optimizations such as quantization, loop pipelining, and array partitioning. ViT4Mal achieved an accuracy of ~94% and a 41x speedup compared to the original ViT model.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4386568539",
    "type": "article"
  },
  {
    "title": "FedHIL: Heterogeneity Resilient Federated Learning for Robust Indoor Localization with Mobile Devices",
    "doi": "https://doi.org/10.1145/3607919",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Danish Gufran; Sudeep Pasricha",
    "corresponding_authors": "",
    "abstract": "Indoor localization plays a vital role in applications such as emergency response, warehouse management, and augmented reality experiences. By deploying machine learning (ML) based indoor localization frameworks on their mobile devices, users can localize themselves in a variety of indoor and subterranean environments. However, achieving accurate indoor localization can be challenging due to heterogeneity in the hardware and software stacks of mobile devices, which can result in inconsistent and inaccurate location estimates. Traditional ML models also heavily rely on initial training data, making them vulnerable to degradation in performance with dynamic changes across indoor environments. To address the challenges due to device heterogeneity and lack of adaptivity, we propose a novel embedded ML framework called FedHIL . Our framework combines indoor localization and federated learning (FL) to improve indoor localization accuracy in device-heterogeneous environments while also preserving user data privacy. FedHIL integrates a domain-specific selective weight adjustment approach to preserve the ML model's performance for indoor localization during FL, even in the presence of extremely noisy data. Experimental evaluations in diverse real-world indoor environments and with heterogeneous mobile devices show that FedHIL outperforms state-of-the-art FL and non-FL indoor localization frameworks. FedHIL is able to achieve 1.62 × better localization accuracy on average than the best performing FL-based indoor localization framework from prior work.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4386568669",
    "type": "article"
  },
  {
    "title": "A Design Flow based on Docker and Kubernetes for ROS-based Robotic Software Applications",
    "doi": "https://doi.org/10.1145/3594539",
    "publication_date": "2024-08-14",
    "publication_year": 2024,
    "authors": "Francesco Lumpp; Marco Panato; Nicola Bombieri; Franco Fummi",
    "corresponding_authors": "",
    "abstract": "Human-centered robotic applications are becoming pervasive in the context of robotics and smart manufacturing, and such a pervasiveness is even more expected with the shift to Industry 5.0. The always increasing level of autonomy of modern robotic platforms requires the integration of software applications from different domains to implement artificial intelligence, cognition, and human-robot/robot-robot interaction. Developing and (re)configuring such a multi-domain software to meet functional constraints is a challenging task. Even more challenging is customizing the software to satisfy non-functional requirements such as real-time, reliability, and energy efficiency. In this context, the concept of Edge-Cloud continuum is gaining consensus as a solution to address functional and non-functional constraints in a seamless way. Containerization and orchestration are becoming a standard practice, as they allow for better information flow among different network levels as well as increased modularity in the use of multi-domain software components. Nevertheless, the adoption of such a practice along the design flow, from simulation to the deployment of complex robotic applications by addressing the de facto development standards (e.g., ROS - Robotic Operating System) is still an open problem. We present a design methodology based on Docker and Kubernetes that enables containerization and orchestration of ROS-based robotic SW applications for heterogeneous and hierarchical HW architectures. The methodology aims at (i) integrating and verifying multi-domain components since early in the design flow, (ii) mapping software tasks to containers to minimize the performance and memory footprint overhead, (iii) clustering containers to efficiently distribute load across the edge-cloud architecture by minimizing resource utilization, and (iv) enabling multi-domain verification of functional and non-functional constraints before deployment. The article presents the results obtained with a real case of study, in which the design methodology has been applied to program the mission of a Robotnik RB-Kairos mobile robot in an industrial agile production chain. We have obtained reduced load on the robot’s HW with minimal performance and network overhead, thanks to the optimized distributed system.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4366985351",
    "type": "article"
  },
  {
    "title": "Dynamic Cluster Head Selection in WSN",
    "doi": "https://doi.org/10.1145/3665867",
    "publication_date": "2024-05-25",
    "publication_year": 2024,
    "authors": "Rupendra Pratap Singh Hada; Abhishek Srivastava",
    "corresponding_authors": "",
    "abstract": "A Wireless Sensor Network (WSN) comprises an ad-hoc network of nodes laden with sensors that are used to monitor a region mostly in the outdoors and often not easily accessible. Despite exceptions, several deployments of WSN continue to grapple with the limitation of finite energy derived through batteries. Thus, it is imperative that the energy of a WSN be conserved and its life prolonged. An important direction of work to this end is towards the transmission of data between nodes in a manner that minimum energy is expended. One approach to doing this is cluster-based routing, wherein nodes in a WSN are organised into clusters, and transmission of data from the node is through a representative node called a cluster-head. Forming optimal clusters and choosing an optimal cluster-head is an NP-Hard problem. Significant work is done towards devising mechanisms to form clusters and choosing cluster heads to reduce the transmission overhead to a minimum. In this article, an approach is proposed to create clusters and identify cluster heads that are near optimal. The approach involves two-stage clustering, with the clustering algorithm for each stage chosen through an exhaustive search. Furthermore, unlike existing approaches that choose a cluster-head on the basis of the residual energy of nodes, the proposed approach utilises three factors in addition to the residual energy, namely the distance of a node from the cluster centroid, the distance of a node from the final destination (base-station), and the connectivity of the node. The approach is shown to be effective and economical through extensive validation via simulations and through a real-world prototypical implementation.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4399018331",
    "type": "article"
  },
  {
    "title": "DOCTOR: A Multi-Disease Detection Continual Learning Framework Based on Wearable Medical Sensors",
    "doi": "https://doi.org/10.1145/3679050",
    "publication_date": "2024-07-26",
    "publication_year": 2024,
    "authors": "Chia‐Hao Li; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Modern advances in machine learning (ML) and wearable medical sensors (WMSs) in edge devices have enabled ML-driven disease detection for smart healthcare. Conventional ML-driven methods for disease detection rely on customizing individual models for each disease and its corresponding WMS data. However, such methods lack adaptability to distribution shifts and new task classification classes. In addition, they need to be rearchitected and retrained from scratch for each new disease. Moreover, installing multiple ML models in an edge device consumes excessive memory, drains the battery faster, and complicates the detection process. To address these challenges, we propose DOCTOR, a multi-disease detection continual learning (CL) framework based on WMSs. It employs a multi-headed deep neural network (DNN) and a replay-style CL algorithm. The CL algorithm enables the framework to continually learn new missions in which different data distributions, classification classes, and disease detection tasks are introduced sequentially. It counteracts catastrophic forgetting with either a data preservation (DP) method or a synthetic data generation (SDG) module. The DP method preserves the most informative subset of real training data from previous missions for exemplar replay. The SDG module models the probability distribution of the real training data and generates synthetic data for generative replay while retaining data privacy. The multi-headed DNN enables DOCTOR to detect multiple diseases simultaneously based on user WMS data. We demonstrate DOCTOR’s efficacy in maintaining high disease classification accuracy with a single DNN model in various CL experiments. In complex scenarios, DOCTOR achieves 1.43× better average test accuracy, 1.25× better F1-score, and 0.41 higher backward transfer than the naïve fine-tuning framework, with a small model size of less than 350 KB.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4401029999",
    "type": "article"
  },
  {
    "title": "Schedulability analysis of applications with stochastic task execution times",
    "doi": "https://doi.org/10.1145/1027794.1027797",
    "publication_date": "2004-11-01",
    "publication_year": 2004,
    "authors": "Sorin Manolache; Petru Eles; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "In the past decade, the limitations of models considering fixed (worst-case) task execution times have been acknowledged for large application classes within soft real-time systems. A more realistic model considers the tasks having varying execution times with given probability distributions. Considering such a model with specified task execution time probability distribution functions, an important performance indicator of the system is the expected deadline miss ratio of the tasks and of the task graphs. This article presents an approach for obtaining this indicator in an analytic way. Our goal is to keep the analysis cost low, in terms of required analysis time and memory, while considering as general classes of target application models as possible. The following main assumptions have been made on the applications that are modeled as sets of task graphs: the tasks are periodic, the task execution times have given generalized probability distribution functions, the task execution deadlines are given and arbitrary, the scheduling policy can belong to practically any class of non-preemptive scheduling policies, and a designer supplied maximum number of concurrent instantiations of the same task graph is tolerated in the system. Experiments show the efficiency of the proposed technique for monoprocessor systems.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2025875132",
    "type": "article"
  },
  {
    "title": "Guidelines for a graduate curriculum on embedded software and systems",
    "doi": "https://doi.org/10.1145/1086519.1086526",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "P. Caspi; Alberto Sangiovanni‐Vincentelli; Lúıs Almeida; Albert Benveniste; Bruno Bouyssounouse; Giorgio Buttazzo; Ivica Crnković; Werner Damm; Jakob Engblom; G. Folher; Marisol García‐Valls; Hermann Kopetz; Yassine Lakhnech; François Laroussinie; Luciano Lavagno; Giuseppe Lipari; Florence Maraninchi; Ph. Peti; Juan A. de la Puente; Norman Scaife; Joseph Sifakis; Raffaella Simone; Martin Törngren; Paulo Verı́ssimo; Andy Wellings; Robert G. Wilhelm; Tim A. C. Willemse; Wonjun Yi",
    "corresponding_authors": "",
    "abstract": "The design of embedded real-time systems requires skills from multiple specific disciplines, including, but not limited to, control, computer science, and electronics. This often involves experts from differing backgrounds, who do not recognize that they address similar, if not identical, issues from complementary angles. Design methodologies are lacking in rigor and discipline so that demonstrating correctness of an embedded design, if at all possible, is a very expensive proposition that may delay significantly the introduction of a critical product. While the economic importance of embedded systems is widely acknowledged, academia has not paid enough attention to the education of a community of high-quality embedded system designers, an obvious difficulty being the need of interdisciplinarity in a period where specialization has been the target of most education systems. This paper presents the reflections that took place in the European Network of Excellence Artist leading us to propose principles and structured contents for building curricula on embedded software and systems.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W2018010659",
    "type": "article"
  },
  {
    "title": "Multitasking on reconfigurable architectures: microarchitecture support and dynamic scheduling",
    "doi": "https://doi.org/10.1145/993396.993404",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Juanjo Noguera; Rosa M. Badía",
    "corresponding_authors": "",
    "abstract": "Dynamic scheduling for system-on-chip (SoC) platforms has become an important field of research due to the emerging range of applications with dynamic behavior (e.g., MPEG-4). Dynamically reconfigurable architectures are an interesting solution for this type of applications. Scheduling for dynamically reconfigurable architectures might be classified in two major broad categories: (1) static scheduling techniques or (2) use of an operating system (OS) for reconfigurable computing. However, research efforts demonstrate a trend to move tasks traditionally assigned to the OS into hardware (thus increasing performance and reducing power).In this paper, we introduce a methodology for dynamically reconfigurable architectures. The dynamic scheduling of tasks to several reconfigurable units is performed by a hardware-based multitasking support unit. Two different versions of the microarchitecture are possible (with or without a hardware configuration prefetch unit). The dynamic scheduling algorithms are also explained. Both algorithms try to minimize the reconfiguration overhead by overlapping the execution of tasks with device reconfigurations.An exhaustive study (using the developed simulation and performance analysis framework) of this novel proposal is presented, and the effect of the microarchitecture parameters has been studied. Results demonstrate the benefits of our approach (achieving similar performance to a static configuration solution but using half of the resources). The hardware configuration prefetch unit is useful (i.e., minimize the execution time) in applications with low level of parallelism.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W2021477284",
    "type": "article"
  },
  {
    "title": "Dynamic adaptation for fault tolerance and power management in embedded real-time systems",
    "doi": "https://doi.org/10.1145/993396.993402",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Ying Zhang; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Safety-critical embedded systems often operate in harsh environmental conditions that necessitate fault-tolerant computing techniques. In addition, many safety-critical systems execute real-time applications that require strict adherence to task deadlines. These embedded systems are also energy-constrained, since system lifetime is determined largely by the battery lifetime. In this paper, we investigate dynamic adaptation techniques based on checkpointing and dynamic voltage scaling (DVS) for fault tolerance and power management. We first present schedulability tests that provide the criteria under which checkpointing can provide fault tolerance and real-time guarantees. We then present an adaptive checkpointing scheme in which the checkpointing interval for a task is dynamically adjusted during execution, and checkpoints are inserted based not only on the available slack, but also on the occurrences of faults. Next, we combine adaptive checkpointing with DVS to achieve power reduction. Finally, we develop an adaptive checkpointing scheme for a set of multiple tasks in real-time systems. An offline preprocessing based on linear programming is used to determine the parameters that are provided as inputs to the online adaptive checkpointing procedure. Simulation results show that compared to previous methods, the proposed adaptive checkpointing approach increases the likelihood of timely task completion in the presence of faults. When combined with DVS, adaptive checkpointing also leads to considerable energy savings.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W2109315204",
    "type": "article"
  },
  {
    "title": "Adaptive mode control",
    "doi": "https://doi.org/10.1145/860176.860181",
    "publication_date": "2003-08-01",
    "publication_year": 2003,
    "authors": "Huiyang Zhou; Mark C. Toburen; Eric Rotenberg; Thomas M. Conte",
    "corresponding_authors": "",
    "abstract": "Lower threshold voltages in deep submicron technologies cause more leakage current, increasing static power dissipation. This trend, combined with the trend of larger/more cache memories dominating die area, has prompted circuit designers to develop SRAM cells with low-leakage operating modes (e.g., sleep mode). Sleep mode reduces static power dissipation, but data stored in a sleeping cell is unreliable or lost. So, at the architecture level, there is interest in exploiting sleep mode to reduce static power dissipation while maintaining high performance.Current approaches dynamically control the operating mode of large groups of cache lines or even individual cache lines. However, the performance monitoring mechanism that controls the percentage of sleep-mode lines, and identifies particular lines for sleep mode, is somewhat arbitrary. There is no way to know what the performance could be with all cache lines active, so arbitrary miss rate targets are set (perhaps on a per-benchmark basis using profile information), and the control mechanism tracks these targets. We propose applying sleep mode only to the data store and not the tag store. By keeping the entire tag store active the hardware knows what the hypothetical miss rate would be if all data lines were active, and the actual miss rate can be made to precisely track it. Simulations show that an average of 73% of I-cache lines and 54% of D-cache lines are put in sleep mode with an average IPC impact of only 1.7%, for 64 KB caches.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W2075190356",
    "type": "article"
  },
  {
    "title": "Software design patterns for TinyOS",
    "doi": "https://doi.org/10.1145/1274858.1274860",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "David Gay; Philip Levis; David Culler",
    "corresponding_authors": "",
    "abstract": "We present design patterns used by software components in the TinyOS sensor network operating system. They differ significantly from traditional software design patterns because of the constraints of sensor networks and to TinyOS's focus on static allocation and whole-program composition. We describe how nesC has evolved to support these design patterns by including a few simple language primitives and optimizations.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2643482692",
    "type": "article"
  },
  {
    "title": "The Molen compiler for reconfigurable processors",
    "doi": "https://doi.org/10.1145/1210268.1210274",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Elena Moscu Panainte; Koen Bertels; Stamatis Vassiliadis",
    "corresponding_authors": "",
    "abstract": "In this paper, we describe the compiler developed to target the Molen reconfigurable processor and programming paradigm. The compiler automatically generates optimized binary code for C applications, based on pragma annotation of the code executed on the reconfigurable hardware. For the IBM PowerPC 405 processor included in the Virtex II Pro platform FPGA, we implemented code generation, register, and stack frame allocation following the PowerPC EABI (embedded application binary interface). The PowerPC backend has been extended to generate the appropriate instructions for the reconfigurable hardware and data transfer, taking into account the information of the specific hardware implementations and system. Starting with an annotated C application, a complete design flow has been integrated to generate the executable bitstream for the reconfigurable processor. The flexible design of the proposed infrastructure allows to consider the special features of the reconfigurable architectures. In order to hide the reconfiguration latencies, we implemented an instruction-scheduling algorithm for the dynamic hardware configuration instructions. The algorithm schedules, in advance, the hardware configuration instructions, taking into account the conflicts for the reconfigurable hardware resources (FPGA area) between the hardware operations. To verify the Molen compiler, we used the multimedia video frame M-JPEG encoder of which the extended discrete cosine transform (DCT*) function was mapped on the FPGA. We obtained an overall speedup of 2.5 (about 84% efficiency over the maximal theoretical speedup of 2.96). The performance efficiency is achieved using automatically generated nonoptimized DCT* hardware implementation. The instruction-scheduling algorithm has been tested for DCT, quantization, and VLC operations. Based on simulation results, we determine that, while a simple scheduling produces a significant performance decrease, our proposed scheduling contributes for up to 16x M-JPEG encoder speedup.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2042269206",
    "type": "article"
  },
  {
    "title": "Pruning-based, energy-optimal, deterministic I/O device scheduling for hard real-time systems",
    "doi": "https://doi.org/10.1145/1053271.1053277",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Vishnu Swaminathan; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Software-controlled (or dynamic) power management (DPM) in embedded systems has emerged as an attractive alternative to inflexible hardware solutions. However, DPM via I/O device scheduling for hard real-time systems has received relatively little attention. In this paper, we present an offline I/O device scheduling algorithm called energy-optimal device scheduler (EDS). For a given set of jobs, it determines the start time of each job such that the energy consumption of the I/O devices is minimized. EDS also ensures that no real-time constraint is violated. The device schedules are provably energy optimal under hard real-time job deadlines. Temporal and energy-based pruning are used to reduce the search space significantly. Since the I/O device scheduling problem is NP-complete, we also describe a heuristic called maximum device overlap (MDO) to generate near-optimal solutions in polynomial time. We present experimental results to show that EDS and MDO reduce the energy consumption of I/O devices significantly for hard real-time systems.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2142636178",
    "type": "article"
  },
  {
    "title": "Guest editorial CAPA'08 configurable computing",
    "doi": "https://doi.org/10.1145/1596532.1596533",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Toomas P. Plaks; Neil Bergmann; Bernard Pottier",
    "corresponding_authors": "",
    "abstract": "editorial Free AccessGuest editorial CAPA'08 configurable computing: Configuring algorithms, processes, and architecture issue I: Configuring algorithms and processes Editors: Dr. Toomas P. Plaks Reading University, UK Reading University, UKView Profile , Neil Bergmann Queensland University, Australia Queensland University, AustraliaView Profile , Bernard Pottier University of Bretagne, France University of Bretagne, FranceView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 9Issue 1Article No.: 1pp 1–5https://doi.org/10.1145/1596532.1596533Published:29 October 2009Publication History 0citation282DownloadsMetricsTotal Citations0Total Downloads282Last 12 Months2Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2031301693",
    "type": "editorial"
  },
  {
    "title": "Introduction to special issue on Java technologies for real-time and embedded systems",
    "doi": "https://doi.org/10.1145/1814539.1814540",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "M. Teresa Higuera‐Toledano; Doug Locke; Angelo Corsaro",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to special issue on Java technologies for real-time and embedded systems Authors: M. Teresa Higuera-Toledano Universidad Complutense de Madrid, Spain Universidad Complutense de Madrid, SpainView Profile , Doug Locke LC Systems Services Inc., USA LC Systems Services Inc., USAView Profile , Angelo Corsaro PrismTech Corporation, France PrismTech Corporation, FranceView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 10Issue 1August 2010 Article No.: 1pp 1–4https://doi.org/10.1145/1814539.1814540Published:27 August 2010Publication History 0citation446DownloadsMetricsTotal Citations0Total Downloads446Last 12 Months6Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2014519677",
    "type": "article"
  },
  {
    "title": "Analysis and design of a hardware/software trusted platform module for embedded systems",
    "doi": "https://doi.org/10.1145/1457246.1457254",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Najwa Aaraj; Anand Raghunathan; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Trusted platforms have been proposed as a promising approach to enhance the security of general-purpose computing systems. However, for many resource-constrained embedded systems, the size and cost overheads of a separate Trusted Platform Module (TPM) chip are not acceptable. One alternative is to use a software-based TPM, which implements TPM functions using software that executes in a protected execution domain on the embedded processor itself. However, since many embedded systems have limited processing capabilities and are battery-powered, it is also important to ensure that the computational and energy requirements for SW-TPMs are acceptable. In this article, we perform an evaluation of the energy and execution time overheads for a SW-TPM implementation on a handheld appliance (Sharp Zaurus PDA). We characterize the execution time and energy required by each TPM command through actual measurements on the target platform. We observe that for most commands, overheads are primarily due to the use of 2,048-bit RSA operations that are performed within the SW-TPM. In order to alleviate SW-TPM overheads, we evaluate the use of Elliptic Curve Cryptography (ECC) as a replacement for the RSA algorithm specified in the Trusted Computing Group (TCG) standards. In addition, we also evaluate the overheads of using the SW-TPM in the context of various end applications, including trusted boot of the Linux operating system (OS), a secure VoIP client, and a secure Web browser. Furthermore, we analyze the computational workload involved in running SW-TPM commands using ECC. We then present a suite of hardware and software enhancements to accelerate these commands—generic custom instructions and exploitation of parallel processing capabilities in multiprocessor systems-on-chip (SoCs). We report results of evaluating the proposed architectures on a commercial embedded processor (Xtensa from Tensilica). Through uniprocessor and multiprocessor optimizations, we could achieve speed-ups of up to 5.71X for individual TPM commands.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2045604437",
    "type": "article"
  },
  {
    "title": "Scalable FPGA-based architecture for DCT computation using dynamic partial reconfiguration",
    "doi": "https://doi.org/10.1145/1596532.1596541",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Jian Huang; Matthew Parris; Jooheung Lee; Ronald F. DeMara",
    "corresponding_authors": "",
    "abstract": "In this article, we propose field programmable gate array-based scalable architecture for discrete cosine transform (DCT) computation using dynamic partial reconfiguration. Our architecture can achieve quality scalability using dynamic partial reconfiguration. This is important for some critical applications that need continuous hardware servicing. Our scalable architecture has three features. First, the architecture can perform DCT computations for eight different zones, that is, from 1 × 1 DCT to 8× 8 DCT. Second, the architecture can change the configuration of processing elements to trade off the precisions of DCT coefficients with computational complexity. Third, unused PEs for DCT can be used for motion estimation computations. Using dynamic partial reconfiguration with 2.3MB bitstreams, 80 distinct hardware architectures can be implemented. We show the experimental results and comparisons between different configurations using both partial reconfiguration and nonpartial reconfiguration process. The detailed trade-offs among visual quality, power consumption, processing clock cycles, and reconfiguration overhead are analyzed in the article.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2058476306",
    "type": "article"
  },
  {
    "title": "Reliability-aware dynamic energy management in dependable embedded real-time systems",
    "doi": "https://doi.org/10.1145/1880050.1880062",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Dakai Zhu",
    "corresponding_authors": "Dakai Zhu",
    "abstract": "Recent studies show that voltage scaling, which is an efficient energy management technique, has a direct and negative effect on system reliability because of the increased rate of transient faults (e.g., those induced by cosmic particles). In this article, we propose energy management schemes that explicitly take system reliability into consideration. The proposed reliability-aware energy management schemes dynamically schedule recoveries for tasks to be scaled down to recuperate the reliability loss due to energy management. Based on the amount of available slack, the application size, and the fault rate changes, we analyze when it is profitable to reclaim the slack for energy savings without sacrificing system reliability. Checkpoint technique is further explored to efficiently use the slack. Analytical and simulation results show that the proposed schemes can achieve comparable energy savings as ordinary energy management schemes (which are reliability-ignorant) while preserving system reliability. The ordinary energy management schemes that ignore the effects of voltage scaling on fault rate changes could lead to drastically decreased system reliability.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2621879533",
    "type": "article"
  },
  {
    "title": "Design and implementation of a MicroBlaze-based warp processor",
    "doi": "https://doi.org/10.1145/1509288.1509294",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Roman Lysecky; Frank Vahid",
    "corresponding_authors": "",
    "abstract": "While soft processor cores provided by FPGA vendors offer designers with increased flexibility, such processors typically incur penalties in performance and energy consumption compared to hard processor core alternatives. The recently developed technology of warp processing can help reduce those penalties. Warp processing is the dynamic and transparent transformation of critical software regions from microprocessor execution to much faster circuit execution on an FPGA. In this article, we describe an implementation of a warp processor on a Xilinx Virtex-II Pro and Spartan3 FPGAs incorporating one or more MicroBlaze soft processor cores. We further provide a detailed analysis of the energy overhead of dynamically partitioning an application's kernels to hardware executing within an FPGA. Considering an implementation that periodically partitions the executing application once every minute, a MicroBlaze-based warp processor implemented on a Spartan3 FPGA achieves average speedups of 5.8× and energy reductions of 49% compared to the MicroBlaze soft processor core alone—providing competitive performance and energy consumption compared to existing hard processor cores.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W1990771216",
    "type": "article"
  },
  {
    "title": "Real-time performance analysis of multiprocessor systems with shared memory",
    "doi": "https://doi.org/10.1145/1880050.1880058",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Simon Schliecker; Rolf Ernst",
    "corresponding_authors": "",
    "abstract": "Predicting timing behavior is key to reliable real-time system design and verification, but becomes increasingly difficult for current multiprocessor systems on chip. The integration of formerly separate functionality into a single multicore system introduces new intercore timing dependencies resulting from the common use of the now shared resources. This feedback of system timing on local timing makes traditional performance analysis approaches inappropriate. This article presents a general methodology to model the shared resource traffic and consider its effect on the local task execution. The aggregate busy time captures the timing of multiple accesses to a shared memory far better than the traditional models that focus on the timing of individual events. An iterative approach is proposed to tackle the analysis dependencies that exist in systems with event-driven task activation and dynamic resource arbitration.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2007338428",
    "type": "article"
  },
  {
    "title": "Physical activity recognition using multiple sensors embedded in a wearable device",
    "doi": "https://doi.org/10.1145/2423636.2423644",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Yunyoung Nam; Seungmin Rho; Chulung Lee",
    "corresponding_authors": "",
    "abstract": "In this article, we present a wearable intelligence device for activity monitoring applications. We developed and evaluated algorithms to recognize physical activities from data acquired using a 3-axis accelerometer with a single camera worn on a body. The recognition process is performed in two steps: at first the features for defining a human activity are measured by the 3-axis accelerometer sensor and the image sensor embedded in a wearable device. Then, the physical activity corresponding to the measured features is determined by applying the SVM classifier. The 3-axis accelerometer sensor computes the correlation between axes and the magnitude of the FFT for other features of an activity. Acceleration data is classified into nine activity labels. Through the image sensor, multiple optical flow vectors computed on each grid image patch are extracted as features for defining an activity. In the experiments, we showed that an overall accuracy rate of activity recognition based our method was 92.78%.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2028855865",
    "type": "article"
  },
  {
    "title": "Transition-Based Deadlock Detection and Recovery Policy for FMSs Using Graph Technique",
    "doi": "https://doi.org/10.1145/2406336.2406347",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Yi‐Sheng Huang; Yen‐Liang Pan; Pin‐June Su",
    "corresponding_authors": "",
    "abstract": "A transition-controlled deadlock detection and recovery prevention policy is presented for a subclass of Petri nets used to model flexible manufacturing systems. The subclass is called systems of simple sequential processes with resources (S 3 PR). The proposed policy is different from the standard deadlock prevention policies. Instead of adding control places, this policy adds a controlled transition to solve a group of deadlocked markings that have the same graph-based property. Finally, the results of our study indicate that the proposed policy appears to be more permissive than those existing ones that add control places.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2072697401",
    "type": "article"
  },
  {
    "title": "On self-tuning networks-on-chip for dynamic network-flow dominance adaptation",
    "doi": "https://doi.org/10.1145/2544375.2544393",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Xiaohang Wang; Mei Yang; Yingtao Jiang; Peng Liu; Masoud Daneshtalab; Maurizio Palesi; Terrence Mak",
    "corresponding_authors": "",
    "abstract": "Modern network-on-chip (NoC) systems are required to handle complex runtime traffic patterns and unprecedented applications. Data traffics of these applications are difficult to fully comprehend at design time so as to optimize the network design. However, it has been discovered that the majority of dataflows in a network are dominated by less than 10% of the specific pathways. In this article, we introduce a method that is capable of identifying critical pathways in a network at runtime and can then dynamically reconfigure the network to optimize for network performance subject to the identified dominated flows. An online learning and analysis scheme is employed to quickly discover the emerging dominated traffic flows and provides a statistical traffic prediction using regression analysis. The architecture of a self-tuning network is also discussed which can be reconfigured by setting up the identified point-to-point paths for the dominance dataflows in large traffic volumes. The merits of this new approach are experimentally demonstrated using comprehensive NoC simulations. Compared to the conventional network architectures over a range of realistic applications, the proposed self-tuning network approach can effectively reduce the latency and power consumption by as much as 25% and 24%, respectively. We also evaluated the configuration time and additional hardware cost. This new approach demonstrates the capability of an adaptive NoC to handle more complex and dynamic applications.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2022705085",
    "type": "article"
  },
  {
    "title": "Real-Time Power Management for Embedded M2M Using Intelligent Learning Methods",
    "doi": "https://doi.org/10.1145/2632158",
    "publication_date": "2014-07-23",
    "publication_year": 2014,
    "authors": "Anand Paul",
    "corresponding_authors": "Anand Paul",
    "abstract": "In this work, an embedded system working model is designed with one server that receives requests by a requester by a service queue that is monitored by a Power Manager (PM). A novel approach is presented based on reinforcement learning to predict the best policy amidst existing DPM policies and deterministic markovian nonstationary policies (DMNSP). We apply reinforcement learning, namely a computational approach to understanding and automating goal-directed learning that supports different devices according to their DPM. Reinforcement learning uses a formal framework defining the interaction between agent and environment in terms of states, response action, and reward points. The capability of this approach is demonstrated by an event-driven simulator designed using Java with a power-manageable machine-to-machine device. Our experiment result shows that the proposed dynamic power management with timeout policy gives average power saving from 4% to 21% and the novel dynamic power management with DMNSP gives average power saving from 10% to 28% more than already proposed DPM policies.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2007975429",
    "type": "article"
  },
  {
    "title": "Dynamic Cache Reconfiguration for Soft Real-Time Systems",
    "doi": "https://doi.org/10.1145/2220336.2220340",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Weixun Wang; Prabhat Mishra; Ross Gordon",
    "corresponding_authors": "",
    "abstract": "In recent years, efficient dynamic reconfiguration techniques have been widely employed for system optimization. Dynamic cache reconfiguration is a promising approach for reducing energy consumption as well as for improving overall system performance. It is a major challenge to introduce cache reconfiguration into real-time multitasking systems, since dynamic analysis may adversely affect tasks with timing constraints. This article presents a novel approach for implementing cache reconfiguration in soft real-time systems by efficiently leveraging static analysis during runtime to minimize energy while maintaining the same service level. To the best of our knowledge, this is the first attempt to integrate dynamic cache reconfiguration in real-time scheduling techniques. Our experimental results using a wide variety of applications have demonstrated that our approach can significantly reduce the cache energy consumption in soft real-time systems (up to 74%).",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2018328611",
    "type": "article"
  },
  {
    "title": "Implementing QC-MDPC McEliece Encryption",
    "doi": "https://doi.org/10.1145/2700102",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Ingo von Maurich; Tobias Oder; Tim Güneysu",
    "corresponding_authors": "",
    "abstract": "With respect to performance, asymmetric code-based cryptography based on binary Goppa codes has been reported as a highly interesting alternative to RSA and ECC. A major drawback is still the large keys in the range between 50 and 100KB that prevented real-world applications of code-based cryptosystems so far. A recent proposal by Misoczki et al. showed that quasi-cyclic moderate-density parity-check (QC-MDPC) codes can be used in McEliece encryption, reducing the public key to just 0.6KB to achieve an 80-bit security level. In this article, we provide optimized decoding techniques for MDPC codes and survey several efficient implementations of the QC-MDPC McEliece cryptosystem. This includes high-speed and lightweight architectures for reconfigurable hardware, efficient coding styles for ARM’s Cortex-M4 microcontroller, and novel high-performance software implementations that fully employ vector instructions. Finally, we conclude that McEliece encryption in combination with QC-MDPC codes not only enables high-performance implementations but also allows for lightweight designs on a wide range of different platforms.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2020457125",
    "type": "article"
  },
  {
    "title": "Energy Modeling of Software for a Hardware Multithreaded Embedded Microprocessor",
    "doi": "https://doi.org/10.1145/2700104",
    "publication_date": "2015-04-30",
    "publication_year": 2015,
    "authors": "Steve Kerrison; Kerstin Eder",
    "corresponding_authors": "",
    "abstract": "This article examines a hardware multithreaded microprocessor and discusses the impact such an architecture has on existing software energy modeling techniques. A framework is constructed for analyzing the energy behavior of the XMOS XS1-L multithreaded processor and a variation on existing software energy models is proposed, based on analysis of collected energy data. It is shown that by combining execution statistics with sufficient data on the processor’s thread activity and instruction execution costs, a multithreaded software energy model used with Instruction Set Simulation can yield an average error margin of less than 7%.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2053700189",
    "type": "article"
  },
  {
    "title": "Power-aware dynamic mapping heuristics for NoC-based MPSoCs using a unified model-based approach",
    "doi": "https://doi.org/10.1145/2442116.2442125",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Luciano Ost; Marcelo Mandelli; Gabriel Marchesan Almeida; Leandro Möller; Leandro Soares Indrusiak; Gilles Sassatelli; Pascal Benoit; Manfred Glesner; Michel Robert; Fernando Moraes",
    "corresponding_authors": "",
    "abstract": "The mapping of tasks to processing elements of an MPSoC has critical impact on system performance and energy consumption. To cope with complex dynamic behavior of applications, it is common to perform task mapping during runtime so that the utilization of processors and interconnect can be taken into account when deciding the allocation of each task. This paper has two major contributions, one of them targeting the general problem of evaluating dynamic mapping heuristics in NoC-based MPSoCs, and another focusing on the specific problem of finding a task mapping that optimizes energy consumption in those architectures.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2086509560",
    "type": "article"
  },
  {
    "title": "Resource-Aware Task Scheduling",
    "doi": "https://doi.org/10.1145/2638554",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Martin Tillenius; Elisabeth Larsson; Rosa M. Badía; Xavier Martorell",
    "corresponding_authors": "",
    "abstract": "Dependency-aware task-based parallel programming models have proven to be successful for developing efficient application software for multicore-based computer architectures. The programming model is amenable to programmers, thereby supporting productivity, whereas hardware performance is achieved through a runtime system that dynamically schedules tasks onto cores in such a way that all dependencies are respected. However, even if the scheduling is completely successful with respect to load balancing, the scaling with the number of cores may be suboptimal due to resource contention. Here we consider the problem of scheduling tasks not only with respect to their interdependencies but also with respect to their usage of resources, such as memory and bandwidth. At the software level, this is achieved by user annotations of the task resource consumption. In the runtime system, the annotations are translated into scheduling constraints. Experimental results for different hardware, demonstrating performance gains both for model examples and real applications, are presented. Furthermore, we provide a set of tools to detect resource sensitivity and predict the performance improvements that can be achieved by resource-aware scheduling. These tools are solely based on parallel execution traces and require no instrumentation or modification of the application code.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2179783112",
    "type": "article"
  },
  {
    "title": "Tightening Contention Delays While Scheduling Parallel Applications on Multi-core Architectures",
    "doi": "https://doi.org/10.1145/3126496",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Benjamin Rouxel; Steven Derrien; Isabelle Puaut",
    "corresponding_authors": "",
    "abstract": "Multi-core systems are increasingly interesting candidates for executing parallel real-time applications, in avionic, space or automotive industries, as they provide both computing capabilities and power efficiency. However, ensuring that timing constraints are met on such platforms is challenging, because some hardware resources are shared between cores. Assuming worst-case contentions when analyzing the schedulability of applications may result in systems mistakenly declared unschedulable, although the worst-case level of contentions can never occur in practice. In this paper, we present two contention-aware scheduling strategies that produce a time-triggered schedule of the application’s tasks. Based on knowledge of the application’s structure, our scheduling strategies precisely estimate the effective contentions, in order to minimize the overall makespan of the schedule. An Integer Linear Programming (ILP) solution of the scheduling problem is presented, as well as a heuristic solution that generates schedules very close to ones of the ILP (5% longer on average), with a much lower time complexity. Our heuristic improves by 19% the overall makespan of the resulting schedules compared to a worst-case contention baseline.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2758796948",
    "type": "article"
  },
  {
    "title": "Analysis and Design of Adders for Approximate Computing",
    "doi": "https://doi.org/10.1145/3131274",
    "publication_date": "2017-12-07",
    "publication_year": 2017,
    "authors": "Sunil Dutt; Sukumar Nandi; Gaurav Trivedi",
    "corresponding_authors": "",
    "abstract": "The concept of approximate computing, that is, to sacrifice computation quality for computation efforts, has recently emerged as a promising design approach. Over the past decade, several research works have explored approximate computing at both the software level and hardware level of abstraction with encouraging results. At the hardware level of abstraction, adders (being the fundamental and most widely used data operators in digital systems) have attracted a significant attention for approximation. In this article, we first explain briefly the need/significance of approximate adders. We then propose four Approximate Full Adders (AFAs) for high-performance energy-efficient approximate computing. The key design objective behind the proposed AFAs is to curtail the length of carry propagation subjected to minimal error rate. Next, we exploit one of the proposed AFAs (optimal one) to construct an N -bit approximate adder that hereinafter is referred as “ApproxADD.” An emergent property of ApproxADD is that carries do not propagate in it, and, consequently, it provides bit-width-aware constant delay ( O (1)). ApproxADD also provides improvement in dynamic power consumption by 46.31% and in area by 28.57% w.r.t. Ripple Carry Adder (RCA), which exhibits the lowest power and area. Although ApproxADD provides a significant improvement in delay, power, and area, it may not be preferred for some of the error-resilient applications because its: (i) Error Distance (ED) is too high; and (ii) Error Rate (ER) increases rapidly with bit-width ( N ). To improve ED and ER, we exploit the concept of carry-lifetime and Error Detection and Correction logic, respectively. In this way, we introduce two more (improved) versions of ApproxADD--ApproxADD υ 1 and ApproxADD. We call these as ApproxADD υ 1 and ApproxADD υ 2 with existing approximate adders based on conventional design metrics and approximate computing design metrics. Furthermore, to inspect effectiveness of the proposed approach in real-life applications, we demonstrate image compression and decompression by replacing the conventional addition operations in Discrete Cosine Transform (DCT) and Inverse Discrete Cosine Transform (IDCT) modules with ApproxADD υ 2.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2773871951",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Run-Time Mapping and Thread Partitioning of Concurrent OpenCL Applications on CPU-GPU MPSoCs",
    "doi": "https://doi.org/10.1145/3126548",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Amit Kumar Singh; Alok Prakash; Karunakar Reddy Basireddy; Geoff V. Merrett; Bashir M. Al‐Hashimi",
    "corresponding_authors": "",
    "abstract": "Heterogeneous Multi-Processor Systems-on-Chips (MPSoCs) containing CPU and GPU cores are typically required to execute applications concurrently. However, as will be shown in this paper, existing approaches are not well suited for concurrent applications as they are developed either by considering only a single application or they do not exploit both CPU and GPU cores at the same time. In this paper, we propose an energy-efficient run-time mapping and thread partitioning approach for executing concurrent OpenCL applications on both GPU and GPU cores while satisfying performance requirements. Depending upon the performance requirements, for each concurrently executing application, the mapping process finds the appropriate number of CPU cores and operating frequencies of CPU and GPU cores, and the partitioning process identifies an efficient partitioning of the applications’ threads between CPU and GPU cores. We validate the proposed approach experimentally on the Odroid-XU3 hardware platform with various mixes of applications from the Polybench benchmark suite. Additionally, a case-study is performed with a real-world application SLAMBench. Results show an average energy saving of 32% compared to existing approaches while still satisfying the performance requirements.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2756215207",
    "type": "article"
  },
  {
    "title": "Robustness analysis for battery-supported cyber-physical systems",
    "doi": "https://doi.org/10.1145/2442116.2442119",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Fumin Zhang; Zhenwu Shi; S. Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "This article establishes a novel analytical approach to quantify robustness of scheduling and battery management for battery supported cyber-physical systems. A dynamic schedulability test is introduced to determine whether tasks are schedulable within a finite time window. The test is used to measure robustness of a real-time scheduling algorithm by evaluating the strength of computing time perturbations that break schedulability at runtime. Robustness of battery management is quantified analytically by an adaptive threshold on the state of charge. The adaptive threshold significantly reduces the false alarm rate for battery management algorithms to decide when a battery needs to be replaced.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2031427196",
    "type": "article"
  },
  {
    "title": "A Socioecological Model for Advanced Service Discovery in Machine-to-Machine Communication Networks",
    "doi": "https://doi.org/10.1145/2811264",
    "publication_date": "2016-03-11",
    "publication_year": 2016,
    "authors": "Lu Liu; Nick Antonopoulos; Minghui Zheng; Yongzhao Zhan; Zhijun Ding",
    "corresponding_authors": "",
    "abstract": "The new development of embedded systems has the potential to revolutionize our lives and will have a significant impact on future Internet of Thing (IoT) systems if required services can be automatically discovered and accessed at runtime in Machine-to-Machine (M2M) communication networks. It is a crucial task for devices to perform timely service discovery in a dynamic environment of IoTs. In this article, we propose a Socioecological Service Discovery (SESD) model for advanced service discovery in M2M communication networks. In the SESD network, each device can perform advanced service search to dynamically resolve complex enquires and autonomously support and co-operate with each other to quickly discover and self-configure any services available in M2M communication networks to deliver a real-time capability. The proposed model has been systematically evaluated and simulated in a dynamic M2M environment. The experiment results show that SESD can self-adapt and self-organize themselves in real time to generate higher flexibility and adaptability and achieve a better performance than the existing methods in terms of the number of discovered service and a better efficiency in terms of the number of discovered services per message.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2327524664",
    "type": "article"
  },
  {
    "title": "A See-through-Wall System for Device-Free Human Motion Sensing Based on Battery-Free RFID",
    "doi": "https://doi.org/10.1145/3055515",
    "publication_date": "2017-09-20",
    "publication_year": 2017,
    "authors": "Zhongqin Wang; Fu Xiao; Ning Ye; Ruchuan Wang; Panlong Yang",
    "corresponding_authors": "",
    "abstract": "A see-through-wall system can be used in life detection, military fields, elderly people surveillance. and gaming. The existing systems are mainly based on military devices, customized signals or pre-deployed sensors inside the room, which are very expensive and inaccessible for general use. Recently, a low-cost RFID technology has gained a lot of attention in this field. Since phase estimates of a battery-free RFID tag collected by a commercial off-the-shelf (COTS) RFID reader are sensitive to external interference, the RFID tag could be regarded as a battery-free sensor that detects reflections off targeted objects. The existing RFID-based system, however, needs to first learn the environment of the empty room beforehand to separate reflections off the tracked target. Besides, it can only track low-speed metal objects with high-positioning accuracy. Since the human body with its complex surface has a weaker ability to reflect radio frequency (RF) signals than metal objects, a battery-free RFID tag can capture only a subset of the reflections off the human body. To address these challenges, a RFID-based human motion sensing technology, called RF-HMS, is presented to track device-free human motion through walls. At first, we construct transfer functions of multipath channel based on phase and RSSI measurements to eliminate device noise and reflections off static objects like walls and furniture without learning the environment of the empty room before. Then a tag planar array is grouped by many battery-free RFID tags to improve the sensing performance. RF-HMS combines reflections from each RFID tag into a reinforced result. On this basis, we extract phase shifts to detect the absence or presence of any moving persons and further derive the reflections off a single moving person to identify his/her forward or backward motion direction. The results show that RF-HMS can effectively detect the absence or presence of moving persons with 100% accuracy and keep a high accuracy of more than 90% to track human motion directions.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2755724311",
    "type": "article"
  },
  {
    "title": "D-PUF",
    "doi": "https://doi.org/10.1145/3105915",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "Soubhagya Sutar; Arnab Raha; Amey Kulkarni; Rajeev Shorey; Jeffrey D. Tew; Vijay Raghunathan",
    "corresponding_authors": "",
    "abstract": "Physically Unclonable Functions (PUFs) have proved to be an effective and low-cost measure against counterfeiting by providing device authentication and secure key storage services. Memory-based PUF implementations are an attractive option due to the ubiquitous nature of memory in electronic devices and the requirement of minimal (or no) additional circuitry. Dynamic Random Access Memory-- (DRAM) based PUFs are particularly advantageous due to their large address space and multiple controllable parameters during response generation. However, prior works on DRAM PUFs use a static response-generation mechanism making them vulnerable to security attacks. Further, they result in slow device authentication, are not applicable to commercial off-the-shelf devices, or require DRAM power cycling prior to authentication. In this article, we propose D-PUF, an intrinsically reconfigurable DRAM PUF based on the idea of DRAM refresh pausing. A key feature of the proposed DRAM PUF is reconfigurability , that is, by varying the DRAM refresh-pause interval, the challenge-response behavior of the PUF can be altered, making it robust to various attacks. The article is broadly divided into two parts. In the first part, we demonstrate the use of D-PUF in performing device authentication through a secure, low-overhead methodology. In the second part, we show the generation of true random numbers using D-PUF. The design is implemented and validated using an Altera Stratix IV GX FPGA-based Terasic TR4-230 development board and several off-the-shelf 1GB DDR3 DRAM modules. Our experimental results demonstrate a 4.3×-6.4× reduction in authentication time compared to prior work. Using controlled temperature and accelerated aging tests, we also demonstrate the robustness of our authentication mechanism to temperature variations and aging effects. Finally, the ability of the design to generate random numbers is verified using the NIST Statistical Test Suite.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2775542369",
    "type": "article"
  },
  {
    "title": "Real-Time Reachability for Verified Simplex Design",
    "doi": "https://doi.org/10.1145/2723871",
    "publication_date": "2016-02-17",
    "publication_year": 2016,
    "authors": "Taylor T. Johnson; Stanley Bak; Marco Caccamo; Lui Sha",
    "corresponding_authors": "",
    "abstract": "The Simplex architecture ensures the safe use of an unverifiable complex/smart controller by using it in conjunction with a verified safety controller and verified supervisory controller (switching logic). This architecture enables the safe use of smart, high-performance, untrusted, and complex control algorithms to enable autonomy without requiring the smart controllers to be formally verified or certified. Simplex incorporates a supervisory controller that will take over control from the unverified complex/smart controller if it misbehaves and use a safety controller. The supervisory controller should (1) guarantee that the system never enters an unsafe state (safety), but should also (2) use the complex/smart controller as much as possible (minimize conservatism). The problem of precisely and correctly defining the switching logic of the supervisory controller has previously been considered either using a control-theoretic optimization approach or through an offline hybrid-systems reachability computation. In this work, we show that a combined online/offline approach that uses aspects of the two earlier methods, along with a real-time reachability computation, also maintains safety, but with significantly less conservatism, allowing the complex controller to be used more frequently. We demonstrate the advantages of this unified approach on a saturated inverted pendulum system, in which the verifiable region of attraction is over twice as large compared to the earlier approach. Additionally, to validate the claims that the real-time reachability approach may be implemented on embedded platforms, we have ported and conducted embedded hardware studies using both ARM processors and Atmel AVR microcontrollers. This is the first ever demonstration of a hybrid-systems reachability computation in real time on actual embedded platforms, which required addressing significant technical challenges.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2279014940",
    "type": "article"
  },
  {
    "title": "Device-Free Motion &amp; Trajectory Detection via RFID",
    "doi": "https://doi.org/10.1145/3230644",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Xiaoxuan Liang; Zhangqin Huang; Shengqi Yang; Lanxin Qiu",
    "corresponding_authors": "",
    "abstract": "Compared with traditional methods that employ inertial sensors or wireless sensors, device-free approaches do not require that people carry devices, and they are considered a useful technique for indoor navigation and posture recognition. However, few existing methods can detect the trajectory and movements of humans at the same time. In this study, we propose a scheme called PADAR for addressing these two problems simultaneously by using passive radio frequency identification (RFID) tags but without attaching them to the human body. The idea is based on the principle of radio tomographic imaging, where the variance in a tag’s backscattered radio frequency signal strength is influenced by human movement. We integrated a commodity off-the-shelf RFID reader with a two-dimensional phased array antenna and a matrix of passive tags to evaluate the performance of our scheme. We conducted experiments in a simulated indoor environment. The experimental results showed that PADAR achieved an accuracy of over 70%.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2888079598",
    "type": "article"
  },
  {
    "title": "Enabling and Exploiting Partition-Level Parallelism (PALP) in Phase Change Memories",
    "doi": "https://doi.org/10.1145/3358180",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Shihao Song; Anup Das; Onur Mutlu; Nagarajan Kandasamy",
    "corresponding_authors": "",
    "abstract": "Phase-change memory (PCM) devices have multiple banks to serve memory requests in parallel . Unfortunately, if two requests go to the same bank , they have to be served one after another , leading to lower system performance . We observe that a modern PCM bank is implemented as a collection of partitions that operate mostly independently while sharing a few global peripheral structures, which include the sense amplifiers (to read) and the write drivers (to write). Based on this observation, we propose PALP , a new mechanism that enables partition-level parallelism within each PCM bank, and exploits such parallelism by using the memory controller’s access scheduling decisions. PALP consists of three new contributions. First , we introduce new PCM commands to enable parallelism in a bank’s partitions in order to resolve the read-write bank conflicts, with no changes needed to PCM logic or its interface. Second , we propose simple circuit modifications that introduce a new operating mode for the write drivers, in addition to their default mode of serving write requests. When configured in this new mode, the write drivers can resolve the read-read bank conflicts, working jointly with the sense amplifiers. Finally , we propose a new access scheduling mechanism in PCM that improves performance by prioritizing those requests that exploit partition-level parallelism over other requests, including the long outstanding ones. While doing so, the memory controller also guarantees starvation-freedom and the PCM’s running-average-power-limit (RAPL). We evaluate PALP with workloads from the MiBench and SPEC CPU2017 Benchmark suites. Our results show that PALP reduces average PCM access latency by 23%, and improves average system performance by 28% compared to the state-of-the-art approaches.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2979865208",
    "type": "article"
  },
  {
    "title": "Hardware Acceleration for an Accurate Stereo Vision System Using Mini-Census Adaptive Support Region",
    "doi": "https://doi.org/10.1145/2584659",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Yi Shan; Yuchen Hao; Wenqiang Wang; Yu Wang; Xu Chen; Huazhong Yang; Wayne Luk",
    "corresponding_authors": "",
    "abstract": "Domain of stereo vision is highly important in the fields of autonomous cars, video tolling, robotics, and aerial surveys. The specific feature of this domain is that we should handle not only the pixel-by-pixel 2D processing in one image but also the 3D processing for depth estimation by comparing information about a scene from several images with different perspectives. This feature brings challenges to memory resource utilization, because an extra dimension of data has to be buffered. Due to the memory limitation, few of previous stereo vision implementations provide both accurate and high-speed processing for high-resolution images at the same time. To achieve domain-specific acceleration for stereo vision, the memory limitation has to be addressed. This article uses a Mini-Census ADaptive Support Region (MCADSR) stereo matching algorithm as a case study due to its high accuracy and representative operations in this domain. To relieve the memory limitation and achieve high-speed processing, the article proposes several efficient optimization methods including vertical-first cost aggregation, hybrid parallel processing, and hardware-friendly integral image. The article also presents a customizable system which provides both accurate and high-speed stereo matching for high-resolution images. The benefits of applying the optimization methods to the system are highlighted. With the aforesaid optimization and specific customization implemented on FPGA, the demonstrated system can process 47.6 fps (frames per second) and 129 fps for video size of 1920 × 1080 with a large disparity range of 256 and 1024 × 768 with a disparity range of 128, respectively. Our results are up to 1.64 times better than previous work in terms of Million Disparity Estimation per second (MDE/s). For accuracy, the 7.65% overall average error rate outperforms current work which can provide real-time processing with this high-resolution and large disparity range.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2057936902",
    "type": "article"
  },
  {
    "title": "Minimizing Cost of Scheduling Tasks on Heterogeneous Multicore Embedded Systems",
    "doi": "https://doi.org/10.1145/2935749",
    "publication_date": "2016-12-19",
    "publication_year": 2016,
    "authors": "Jing Liu; Kenli Li; Dakai Zhu; Jian-Jun Han; Keqin Li",
    "corresponding_authors": "",
    "abstract": "Cost savings are very critical in modern heterogeneous computing systems, especially in embedded systems. Task scheduling plays an important role in cost savings. In this article, we tackle the problem of scheduling tasks on heterogeneous multicore embedded systems with the constraints of time and resources for minimizing the total cost, while considering the communication overhead. This problem is NP-hard and we propose several heuristic techniques— ISGG , RLD , and RLDG —to address the problem. Experimental results show that the proposed algorithms significantly outperform the existing approaches in terms of cost savings.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2562782724",
    "type": "article"
  },
  {
    "title": "MC-ADAPT",
    "doi": "https://doi.org/10.1145/3126498",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Jaewoo Lee; Hoon Sung Chwa; Linh Thi Xuan Phan; Insik Shin; Insup Lee",
    "corresponding_authors": "",
    "abstract": "Recent embedded systems are becoming integrated systems with components of different criticality. To tackle this, mixed-criticality systems aim to provide different levels of timing assurance to components of different criticality levels while achieving efficient resource utilization. Many approaches have been proposed to execute more lower-criticality tasks without affecting the timeliness of higher-criticality tasks. Those previous approaches however have at least one of the two limitations; i) they penalize all lower-criticality tasks at once upon a certain situation, or ii) they make the decision how to penalize lower-criticality tasks at design time. As a consequence, they under-utilize resources by imposing an excessive penalty on low-criticality tasks. Unlike those existing studies, we present a novel framework, called MC-ADAPT, that aims to minimally penalize lower-criticality tasks by fully reflecting the dynamically changing system behavior into adaptive decision making. Towards this, we propose a new scheduling algorithm and develop its runtime schedulability analysis capable of capturing the dynamic system state. Our proposed algorithm adaptively determines which task to drop based on the runtime analysis. To determine the quality of task dropping solution, we propose the speedup factor for task dropping while the conventional use of the speedup factor only evaluates MC scheduling algorithms in terms of the worst-case schedulability. We apply the speedup factor for a newly-defined task dropping problem that evaluates task dropping solution under different runtime scheduling scenarios. We derive that MC-ADAPT has a speedup factor of 1.619 for task drop. This implies that MC-ADAPT can behave the same as the optimal scheduling algorithm with optimal task dropping strategy does under any runtime scenario if the system is sped up by a factor of 1.619.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2759636500",
    "type": "article"
  },
  {
    "title": "Virtual Platform-Based Design Space Exploration of Power-Efficient Distributed Embedded Applications",
    "doi": "https://doi.org/10.1145/2723161",
    "publication_date": "2015-04-30",
    "publication_year": 2015,
    "authors": "Parinaz Sayyah; Mihai T. Lazarescu; S. Bocchio; Emad Ebeid; Gianluca Palermo; Davide Quaglia; Alberto Rosti; Luciano Lavagno",
    "corresponding_authors": "",
    "abstract": "Networked embedded systems are essential building blocks of a broad variety of distributed applications ranging from agriculture to industrial automation to healthcare and more. These often require specific energy optimizations to increase the battery lifetime or to operate using energy harvested from the environment. Since a dominant portion of power consumption is determined and managed by software, the software development process must have access to the sophisticated power management mechanisms provided by state-of-the-art hardware platforms to achieve the best tradeoff between system availability and reactivity. Furthermore, internode communications must be considered to properly assess the energy consumption. This article describes a design flow based on a SystemC virtual platform including both accurate power models of the hardware components and a fast abstract model of the wireless network. The platform allows both model-driven design of the application and the exploration of power and network management alternatives. These can be evaluated in different network scenarios, allowing one to exploit power optimization strategies without requiring expensive field trials. The effectiveness of the approach is demonstrated via experiments on a wireless body area network application.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2048712301",
    "type": "article"
  },
  {
    "title": "Fault-Tolerant Dynamic Task Mapping and Scheduling for Network-on-Chip-Based Multicore Platform",
    "doi": "https://doi.org/10.1145/3055512",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Navonil Chatterjee; Suraj Paul; Santanu Chattopadhyay",
    "corresponding_authors": "",
    "abstract": "In Network-on-Chip (NoC)-based multicore systems, task allocation and scheduling are known to be important problems, as they affect the performance of applications in terms of energy consumption and timing. Advancement of deep submicron technology has made it possible to scale the transistor feature size to the nanometer range, which has enabled multiple processing elements to be integrated onto a single chip. On the flipside, it has made the integrated entities on the chip more susceptible to different faults. Although a significant amount of work has been done in the domain of fault-tolerant mapping and scheduling, existing algorithms either precompute reconfigured mapping solutions at design time while anticipating fault(s) scenarios or adopt a hybrid approach wherein a part of the fault mitigation strategy relies on the design-time solution. The complexity of the problem rises further for real-time dynamic systems where new applications can arrive in the multicore platform at any time instant. For real-time systems, the validity of computation depends both on the correctness of results and on temporal constraint satisfaction. This article presents an improved fault-tolerant dynamic solution to the integrated problem of application mapping and scheduling for NoC-based multicore platforms. The developed algorithm provides a unified mapping and scheduling method for real-time systems focusing on meeting application deadlines and minimizing communication energy. A predictive model has been used to determine the failure-prone cores in the system for which a fault-tolerant resource allocation with task redundancy has been performed. By selectively using a task replication policy, the reliability of the application, executing on a given NoC platform, is improved. A detailed evaluation of the performance of the proposed algorithm has been conducted for both real and synthetic applications. When compared with other fault-tolerant algorithms reported in the literature, performance of the proposed algorithm shows an average reduction of 56.95% in task re-execution time overhead and an average improvement of 31% in communication energy. Further, for time-constrained tasks, deadline satisfaction has also been achieved for most of the test cases by the developed algorithm, whereas the techniques reported in the literature failed to meet deadline in about 45% test cases.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2617354207",
    "type": "article"
  },
  {
    "title": "Machine Intelligence on Resource-Constrained IoT Devices",
    "doi": "https://doi.org/10.1145/3126555",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Mohammad Motamedi; Daniel Fong; Soheil Ghiasi",
    "corresponding_authors": "",
    "abstract": "Despite their remarkable performance in various machine intelligence tasks, the computational intensity of Convolutional Neural Networks (CNNs) has hindered their widespread utilization in resource-constrained embedded and IoT systems. To address this problem, we present a framework for synthesis of efficient CNN inference software targeting mobile SoC platforms. We argue that thread granularity can substantially impact the performance and energy dissipation of the synthesized inference software, and demonstrate that launching the maximum number of logical threads, often promoted as a guiding principle by GPGPU practitioners, does not result in an efficient implementation for mobile SoCs. We hypothesize that the runtime of a CNN layer on a particular SoC platform can be accurately estimated as a linear function of its computational complexity, which may seem counter-intuitive, as modern mobile SoCs utilize a plethora of heterogeneous architectural features and dynamic resource management policies. Consequently, we develop a principled approach and a data-driven analytical model to optimize granularity of threads during CNN software synthesis. Experimental results with several modern CNNs mapped to a commodity Android smartphone with a Snapdragon SoC show up to 2.37X speedup in application runtime, and up to 1.9X improvement in its energy dissipation compared to existing approaches.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2758475033",
    "type": "article"
  },
  {
    "title": "CASCADE",
    "doi": "https://doi.org/10.1145/3358177",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Dhananjaya Wijerathne; Zhaoying Li; Manupa Karunarathne; Anuj Pathania; Tulika Mitra",
    "corresponding_authors": "",
    "abstract": "A Coarse-Grained Reconfigurable Array (CGRA) is a promising high-performance low-power accelerator for compute-intensive loop kernels. While the mapping of the computations on the CGRA is a well-studied problem, bringing the data into the array at a high throughput remains a challenge. A conventional CGRA design involves on-array computations to generate memory addresses for data access undermining the attainable throughput. A decoupled access-execute architecture, on the other hand, isolates the memory access from the actual computations resulting in a significantly higher throughput. We propose a novel decoupled access-execute CGRA design called CASCADE with full architecture and compiler support for high-throughput data streaming from an on-chip multi-bank memory. CASCADE offloads the address computations for the multi-bank data memory access to a custom designed programmable hardware. An end-to-end fully-automated compiler synchronizes the conflict-free movement of data between the memory banks and the CGRA. Experimental evaluations show on average 3× performance benefit and 2.2× performance per watt improvement for CASCADE compared to an iso-area conventional CGRA with a bigger processing array in lieu of a dedicated hardware memory address generation logic.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2979393958",
    "type": "article"
  },
  {
    "title": "A System-Level Modeling and Design for Cyber-Physical-Social Systems",
    "doi": "https://doi.org/10.1145/2834119",
    "publication_date": "2016-05-10",
    "publication_year": 2016,
    "authors": "Jing Zeng; Laurence T. Yang; Jianhua Ma",
    "corresponding_authors": "",
    "abstract": "The design of cyber-physical-social systems (CPSS) is a novel and challenging research field due that it emphasizes the deep fusion of cyberspace, physical space, and social space. In this article, we extend our previously proposed system-level design framework [Zeng et al. 2015] to tailor it to the needs of social scenario of multiple users. A hierarchical Petri net-based model and social flow are presented to extend the control flow and formally describe the social interactions of multiple users, respectively. By using the extended model, the system-level optimization for CPSS can be achieved by the improved design flow. Specifically, object emplacement and user satisfaction are further extended into the social environment. Also maximal power estimation algorithm is improved, leveraging the extended intermediate representation model. Finally, we use a smart office case to demonstrate the feasibility and effectiveness of our improved design approach for multiple users.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2384636886",
    "type": "article"
  },
  {
    "title": "Game-Based Task Offloading of Multiple Mobile Devices with QoS in Mobile Edge Computing Systems of Limited Computation Capacity",
    "doi": "https://doi.org/10.1145/3398038",
    "publication_date": "2020-07-04",
    "publication_year": 2020,
    "authors": "Junyan Hu; Kenli Li; Chubo Liu; Keqin Li",
    "corresponding_authors": "",
    "abstract": "Mobile edge computing (MEC) is becoming a promising paradigm of providing computing servers, like cloud computing, to Edge node. Compared to cloud servers, MECs are deployed closer to mobile devices (MDs) and can provide high quality-of-service (QoS; including high bandwidth, low latency, etc) for MDs with computation-intensive and delay-sensitive tasks. Faced with many MDs with high QoS requirements, MEC with limited computation capacity should consider how to allocate the computing resources to MDs to maximize the number of served MDs. Besides, for each MD, he/she wants to minimize the energy consumption within an acceptance delay range. To solve these issues, we propose a Game-based Computation Offloading (GCO) algorithm including a task offloading profile of MEC and the transmission power controlling of each MD. Specifically, we propose a Greedy-Pruning algorithm to determine the MDs that can offload the tasks to MEC. Meanwhile, each MD competes the computing resources by using his/her transmission power-controlling strategy. We illustrate the problem of task offloading for multi-MD as a non-cooperative game model, in which the information of each player (MDs) is incomplete for others and each player wishes to maximize his/her own benefit. We prove the existence of the Nash equilibrium solution of our proposed game model. Then, it is proved that the transmission power solution sequence obtained from GCO algorithm converges to the Nash equilibrium solution. Extensive simulated experiments are shown and the comparison experiments with the state-of-the-art and benchmark solutions validate and show the feasibility of the proposed method.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W3042924535",
    "type": "article"
  },
  {
    "title": "Optimal Power Management with Guaranteed Minimum Energy Utilization for Solar Energy Harvesting Systems",
    "doi": "https://doi.org/10.1145/3317679",
    "publication_date": "2019-06-10",
    "publication_year": 2019,
    "authors": "Rehan Ahmed; Bernhard Buchli; Stefan Draskovic; Lukas Sigrist; Pratyush Kumar; Lothar Thiele",
    "corresponding_authors": "",
    "abstract": "In this work, we present a formal study on optimizing the energy consumption of energy harvesting embedded systems. To deal with the uncertainty inherent in solar energy harvesting systems, we propose the Stochastic Power Management (SPM) scheme, which builds statistical models of harvested energy based on historical data. The proposed stochastic scheme maximizes the lowest energy consumption across all time intervals while giving strict probabilistic guarantees on not encountering battery depletion. For situations where historical data is not available, we propose the use of (i) a Finite Horizon Control (FHC) scheme and (ii) a non-uniformly scaled energy estimator based on an astronomical model, which is used by FHC. Under certain realistic assumptions, the FHC scheme can provide guarantees on minimum energy usage that can be supported over all times. We further propose and evaluate a piece-wise linear approximation of FHC for efficient implementation in resource-constrained embedded systems. With extensive experimental evaluation for eight publicly available datasets and two datasets collected with our own deployments, we quantitatively establish that the proposed solutions are highly effective at providing a guaranteed minimum service level and significantly outperform existing solutions.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2950646794",
    "type": "article"
  },
  {
    "title": "An Ultra-Low Energy Human Activity Recognition Accelerator for Wearable Health Applications",
    "doi": "https://doi.org/10.1145/3358175",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Ganapati Bhat; Yiğit Tuncel; Sizhe An; Hyung Gyu Lee; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "Human activity recognition (HAR) has recently received significant attention due to its wide range of applications in health and activity monitoring. The nature of these applications requires mobile or wearable devices with limited battery capacity. User surveys show that charging requirement is one of the leading reasons for abandoning these devices. Hence, practical solutions must offer ultra-low power capabilities that enable operation on harvested energy. To address this need, we present the first fully integrated custom hardware accelerator (HAR engine) that consumes 22.4 μJ per operation using a commercial 65 nm technology. We present a complete solution that integrates all steps of HAR , i.e., reading the raw sensor data, generating features, and activity classification using a deep neural network (DNN). It achieves 95% accuracy in recognizing 8 common human activities while providing three orders of magnitude higher energy efficiency compared to existing solutions.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2980092400",
    "type": "article"
  },
  {
    "title": "Timing-Anomaly Free Dynamic Scheduling of Conditional DAG Tasks on Multi-Core Systems",
    "doi": "https://doi.org/10.1145/3358236",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Peng Chen; Weichen Liu; Xu Jiang; Qingqiang He; Nan Guan",
    "corresponding_authors": "",
    "abstract": "In this paper, we propose a novel approach to schedule conditional DAG parallel tasks, with which we can derive safe response time upper bounds significantly better than the state-of-the-art counterparts. The main idea is to eliminate the notorious timing anomaly in scheduling parallel tasks by enforcing certain order constraints among the vertices, and thus the response time bound can be accurately predicted off-line by somehow “simulating” the runtime scheduling. A key challenge to apply the timing-anomaly free scheduling approach to conditional DAG parallel tasks is that at runtime it may generate exponentially many instances from a conditional DAG structure. To deal with this problem, we develop effective abstractions, based on which a safe response time upper bound is computed in polynomial time. We also develop algorithms to explore the vertex orders to shorten the response time bound. The effectiveness of the proposed approach is evaluated by experiments with randomly generated DAG tasks with different parameter configurations.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W3005001290",
    "type": "article"
  },
  {
    "title": "ROBIN: A Robust Optical Binary Neural Network Accelerator",
    "doi": "https://doi.org/10.1145/3476988",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Febin Sunny; Asif Mirza; Mahdi Nikdast; Sudeep Pasricha",
    "corresponding_authors": "",
    "abstract": "Domain specific neural network accelerators have garnered attention because of their improved energy efficiency and inference performance compared to CPUs and GPUs. Such accelerators are thus well suited for resource-constrained embedded systems. However, mapping sophisticated neural network models on these accelerators still entails significant energy and memory consumption, along with high inference time overhead. Binarized neural networks (BNNs), which utilize single-bit weights, represent an efficient way to implement and deploy neural network models on accelerators. In this paper, we present a novel optical-domain BNN accelerator, named ROBIN , which intelligently integrates heterogeneous microring resonator optical devices with complementary capabilities to efficiently implement the key functionalities in BNNs. We perform detailed fabrication-process variation analyses at the optical device level, explore efficient corrective tuning for these devices, and integrate circuit-level optimization to counter thermal variations. As a result, our proposed ROBIN architecture possesses the desirable traits of being robust, energy-efficient, low latency, and high throughput, when executing BNN models. Our analysis shows that ROBIN can outperform the best-known optical BNN accelerators and many electronic accelerators. Specifically, our energy-efficient ROBIN design exhibits energy-per-bit values that are ∼4 × lower than electronic BNN accelerators and ∼933 × lower than a recently proposed photonic BNN accelerator, while a performance-efficient ROBIN design shows ∼3 × and ∼25 × better performance than electronic and photonic BNN accelerators, respectively.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W3200864435",
    "type": "article"
  },
  {
    "title": "CEDR: A Compiler-integrated, Extensible DSSoC Runtime",
    "doi": "https://doi.org/10.1145/3529257",
    "publication_date": "2022-04-13",
    "publication_year": 2022,
    "authors": "Joshua Mack; Sahil Hassan; Nirmal Kumbhare; Miguel C. Gonzalez; Ali Akoglu",
    "corresponding_authors": "",
    "abstract": "In this work, we present a C ompiler-integrated, E xtensible D omain Specific System on Chip R untime (CEDR) ecosystem to facilitate research toward addressing the challenges of architecture, system software, and application development with distinct plug-and-play integration points in a unified compile time and runtime workflow. We demonstrate the utility of CEDR on the Xilinx Zynq MPSoC-ZCU102 for evaluating performance of pre-silicon hardware in the trade space of SoC configuration, scheduling policy and workload complexity based on dynamically arriving workload scenarios composed of real-life signal processing applications scaling to thousands of application instances with Fast Fourier Transform and matrix multiply accelerators. We provide insights into the tradeoffs present in this design space through a number of distinct case studies. CEDR is portable and has been deployed and validated on Odroid-XU3, X86, and Nvidia Jetson Xavier-based SoC platforms. Taken together, CEDR is a capable environment for enabling research in exploring the boundaries of productive application development, resource management heuristic development, and hardware configuration analysis for heterogeneous architectures.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4223941569",
    "type": "article"
  },
  {
    "title": "FELIX: A Ferroelectric FET Based Low Power Mixed-Signal In-Memory Architecture for DNN Acceleration",
    "doi": "https://doi.org/10.1145/3529760",
    "publication_date": "2022-04-09",
    "publication_year": 2022,
    "authors": "Taha Soliman; Nellie Laleni; Tobias Kirchner; Franz Müller; Ashish Shrivastava; Thomas Kämpfe; Andre Guntoro; Norbert Wehn",
    "corresponding_authors": "",
    "abstract": "Today, a large number of applications depend on deep neural networks (DNN) to process data and perform complicated tasks at restricted power and latency specifications. Therefore, processing-in-memory (PIM) platforms are actively explored as a promising approach to improve the throughput and the energy efficiency of DNN computing systems. Several PIM architectures adopt resistive non-volatile memories as their main unit to build crossbar-based accelerators for DNN inference. However, these structures suffer from several drawbacks such as reliability, low accuracy, large ADCs/DACs power consumption and area, high write energy, and so on. In this article, we present a new mixed-signal in-memory architecture based on the bit-decomposition of the multiply and accumulate (MAC) operations. Our in-memory inference architecture uses a single FeFET as a non-volatile memory cell. Compared to the prior work, this system architecture provides a high level of parallelism while using only 3-bit ADCs. Also, it eliminates the need for any DAC. In addition, we provide flexibility and a very high utilization efficiency even for varying tasks and loads. Simulations demonstrate that we outperform state-of-the-art efficiencies with 36.5 TOPS/W and can pack 2.05 TOPS with 8-bit activation and 4-bit weight precision in an area of 4.9 mm 2 using 22 nm FDSOI technology. Employing binary operation, we obtain 1169 TOPS/W and over 261 TOPS/W/mm 2 on system level.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4226064839",
    "type": "article"
  },
  {
    "title": "Trustworthy Autonomous System Development",
    "doi": "https://doi.org/10.1145/3545178",
    "publication_date": "2022-06-29",
    "publication_year": 2022,
    "authors": "Joseph Sifakis; David Harel",
    "corresponding_authors": "",
    "abstract": "Autonomous systems emerge from the need to progressively replace human operators by autonomous agents in a wide variety of application areas. We offer an analysis of the state of the art in developing autonomous systems, focusing on design and validation and showing that the multi-faceted challenges involved go well beyond the limits of weak AI. We argue that traditional model-based techniques are defeated by the complexity of the problem, while solutions based on end-to-end machine learning fail to provide the necessary trustworthiness. We advocate a hybrid design approach, which combines the two, adopting the best of each, and seeks tradeoffs between trustworthiness and performance. We claim that traditional risk analysis and mitigation techniques fail to scale and discuss the trend of moving away from correctness at design time and toward reliance on runtime assurance techniques. We argue that simulation and testing remain the only realistic approach for global validation and show how current methods can be adapted to autonomous systems. We conclude by discussing the factors that will play a decisive role in the acceptance of autonomous systems and by highlighting the urgent need for new theoretical foundations.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4301266050",
    "type": "article"
  },
  {
    "title": "Winograd Convolution for Deep Neural Networks: Efficient Point Selection",
    "doi": "https://doi.org/10.1145/3524069",
    "publication_date": "2022-03-21",
    "publication_year": 2022,
    "authors": "Syed Asad Alam; Andrew Anderson; Barbara Barabasz; David Gregg",
    "corresponding_authors": "",
    "abstract": "Convolutional neural networks (CNNs) have dramatically improved the accuracy of image, video, and audio processing for tasks such as object recognition, image segmentation, and interactive speech systems. CNNs require large amounts of computing resources for both training and inference, primarily because the convolution layers are computationally intensive. Fast convolution algorithms such as Winograd convolution can greatly reduce the computational cost of these layers. However, Winograd convolution has poor numeric properties, such that greater savings in computation cause exponentially increasing floating point errors. A defining feature of each Winograd convolution algorithm is a set of real-value points where polynomials are sampled. The choice of points impacts the numeric accuracy of the algorithm, but the optimal set of points for small convolutions remains unknown. Existing work considers only small integers and simple fractions as candidate points. In this work, we propose a novel approach to point selection using points of the form \\(\\lbrace -\\frac{1}{c},-c,c,\\frac{1}{c}\\rbrace\\) using the full range of real-valued numbers for c . We show that groups of this form cause cancellations in the Winograd transform matrices that reduce numeric error. We find empirically that the error for different values of c forms a rough curve across the range of real-value numbers. It is therefore possible to localize the values of c that lead to lower error. We show that it is not necessary to choose integers or simple fractions as evaluation points, and that lower errors can be achieved with non-obvious real-valued points. We study a range of sizes for small convolutions and achieve reduction in error ranging from 2% to around 59% for both 1D and 2D convolution, when compared to state of the art. Furthermore, we identify patterns in cases when we select a subset of our proposed points that will always lead to a lower error. Finally, we implement a complete Winograd convolution layer and use it to run state-of-the-art deep convolution neural networks on real datasets and show that our proposed points achieve reduction in error, ranging from 22% to 63%, while also showing how an increased Winograd output size can result in execution speed-up for some cases.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4293102204",
    "type": "article"
  },
  {
    "title": "Optimus: An Operator Fusion Framework for Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3520142",
    "publication_date": "2022-03-21",
    "publication_year": 2022,
    "authors": "Xuyi Cai; Ying Wang; Lei Zhang",
    "corresponding_authors": "",
    "abstract": "The reduction of neural parameters and operations for the applications on embedded and IoT platforms in current deep neural network (DNN) architectures has received increasing attention. Relatively, the intermediate feature maps of such lightweight neural networks begin to grow and usually outsize the on-chip memory as the new bottleneck, which introduces considerable power-consuming off-chip memory accesses. To reduce the feature-induced memory accesses, operator fusion has been proposed to parallelize the execution of multiple convolutional layers and shown significant reduction of off-chip memory accesses. However, how to fuse the neural operators is still a challenging issue that heavily depends on both the neural network (NN) topology and the specific DNN accelerator configuration. In this work, we observed prior operator fusion approaches fail to guarantee memory-level optimality as they search in the constrained operator fusion design space. Considering the complexity of the NN topologies and the constrained resources of the DNN accelerators, we develop a novel operator fusion framework, Optimus. Optimus includes an accurate memory cost model dedicated to the scheduler to evaluate the potential operator-fusion schemes and a directed acyclic graph-based operator fusion algorithm for both off-line and on-line workload deployment scenarios, which altogether generates high-efficiency operator-fusion solutions for arbitrary network models running on DNN accelerators. The experimental results show that Optimus reduces 17–75% off-chip memory accesses and obtains 1.86×–3.66× energy efficiency on state-of-the-art DNN workloads when compared to the baselines and brings significant power-efficiency boost to the DNN accelerators of different architectures and dataflows.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4293102247",
    "type": "article"
  },
  {
    "title": "MemFHE: End-to-end Computing with Fully Homomorphic Encryption in Memory",
    "doi": "https://doi.org/10.1145/3569955",
    "publication_date": "2022-11-01",
    "publication_year": 2022,
    "authors": "Saransh Gupta; Rosario Cammarota; Tajana Šimunić",
    "corresponding_authors": "",
    "abstract": "The increasing amount of data and the growing complexity of problems have resulted in an ever-growing reliance on cloud computing. However, many applications, most notably in healthcare, finance, or defense, demand security and privacy, which today’s solutions cannot fully address. Fully homomorphic encryption (FHE) elevates the bar of today’s solutions by adding confidentiality of data during processing. It allows computation on fully encrypted data without the need for decryption, thus fully preserving privacy. To enable processing encrypted data at usable levels of classic security, e.g., 128-bit, the encryption procedure introduces noticeable data size expansion—the ciphertext is much bigger than the native aggregate of native data types. In this article, we present MemFHE, which is the first accelerator of both client and server for the latest Ring-GSW (Gentry et al. [ 17 ])-based homomorphic encryption schemes using Processing in Memory (PIM). PIM alleviates the data movement issues with large FHE encrypted data while providing in situ execution and extensive parallelism needed for FHE’s polynomial operations. While the client-PIM can homomorphically encrypt and decrypt data, the server-PIM can process homomorphically encrypted data without decryption. MemFHE’s server-PIM is pipelined and is designed to provide flexible bootstrapping, allowing two encryption techniques and various FHE security levels based on the application requirements. We evaluate MemFHE for various security levels and compare it with state-of-the-art CPU implementations for Ring-GSW-based FHE. MemFHE is up to 20 k × (265×) faster than CPU (GPU) for FHE arithmetic operations and provides on average 2,007× higher throughput than [ 36 ] while implementing neural networks with FHE.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4308016342",
    "type": "article"
  },
  {
    "title": "EC-ECC: Accelerating Elliptic Curve Cryptography for Edge Computing on Embedded GPU TX2",
    "doi": "https://doi.org/10.1145/3492734",
    "publication_date": "2022-02-08",
    "publication_year": 2022,
    "authors": "Jiankuo Dong; Fangyu Zheng; Jingqiang Lin; Zhe Liu; Fu Xiao; Fan Guang",
    "corresponding_authors": "",
    "abstract": "Driven by artificial intelligence and computer vision industries, Graphics Processing Units (GPUs) are now rapidly achieving extraordinary computing power. In particular, the NVIDIA Tegra K1/X1/X2 embedded GPU platforms, which are also treated as edge computing devices, are now widely used in embedded environments such as mobile phones, game consoles, and vehicle-mounted systems to support high-dimension display, auto-pilot, and so on. Meanwhile, with the rise of the Internet of Things (IoT), the demand for cryptographic operations for secure communications and authentications between edge computing nodes and IoT devices is also expanding. In this contribution, instead of the conventional implementations based on FPGA, ASIC, and ARM CPUs, we provide an alternative solution for cryptographic implementation on embedded GPU devices. Targeting the new cipher suite added in TLS 1.3, we implement Edwards25519/448 and Curve25519/448 on an edge computing platform, embedded GPU NVIDIA Tegra X2, where various performance optimizations are customized for the target platform, including a novel parallel method for the register-limited embedded GPUs. With about 15 W of power consumption, it can provide 210k/31k ops/s of Curve25519/448 scalar multiplication, 834k/123k ops/s of fixed-point Edwards25519/448 scalar multiplication, and 150k/22k ops/s of unknown-point one, which are respectively the primitives and main workloads of key agreement, signature generation, and verification of the TLS 1.3 protocol. Our implementations achieve 8 to 26 times speedup of OpenSSL running in the very powerful ARM CPU of the same platform and outperform the state-of-the-art implementations in FPGA by a wide margin with better power efficiency.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4210937767",
    "type": "article"
  },
  {
    "title": "<i>AppAxO</i> : Designing <u>App</u> lication-specific <u>A</u> ppro <u>x</u> imate <u>O</u> perators for FPGA-based Embedded Systems",
    "doi": "https://doi.org/10.1145/3513262",
    "publication_date": "2022-02-11",
    "publication_year": 2022,
    "authors": "Salim Ullah; Siva Satyendra Sahoo; Nemath Ahmed; Debabrata Chaudhury; Akash Kumar",
    "corresponding_authors": "",
    "abstract": "Approximate arithmetic operators, such as adders and multipliers, are increasingly used to satisfy the energy and performance requirements of resource-constrained embedded systems. However, most of the available approximate operators have an application-agnostic design methodology, and the efficacy of these operators can only be evaluated by employing them in the applications. Furthermore, the various available libraries of approximate operators do not share any standard approximation-induction policy to design new operators according to an application’s accuracy and performance constraints. These limitations also hinder the utilization of machine learning models to explore and determine approximate operators according to an application’s requirements. In this work, we present a generic design methodology for implementing FPGA-based application-specific approximate arithmetic operators. Our proposed technique utilizes lookup tables and carry-chains of FPGAs to implement approximate operators according to the input configurations. For instance, for an \\( \\text{M}\\times \\text{N} \\) accurate multiplier utilizing K lookup tables, our methodology utilizes K -bit configurations to design \\( 2^K \\) approximate multipliers. We then utilize various machine learning models to evaluate and select configurations satisfying application accuracy and performance constraints. We have evaluated our proposed methodology for three benchmark applications, i.e., biomedical signal processing, image processing, and ANNs. We report more non-dominated approximate multipliers with better hypervolume contribution than state-of-the-art designs for these benchmark applications with the proposed design methodology.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4211125327",
    "type": "article"
  },
  {
    "title": "Domain-Specific Architectures: Research Problems and Promising Approaches",
    "doi": "https://doi.org/10.1145/3563946",
    "publication_date": "2022-09-21",
    "publication_year": 2022,
    "authors": "Anish Krishnakumar; Ümit Y. Ogras; Radu Mărculescu; Mike Kishinevsky; Trevor Mudge",
    "corresponding_authors": "",
    "abstract": "Process technology-driven performance and energy efficiency improvements have slowed down as we approach physical design limits. General-purpose manycore architectures attempt to circumvent this challenge, but they have a significant performance and energy-efficient gap compared to special-purpose solutions. Domain-specific architectures (DSAs), an instance of heterogeneous architectures, efficiently combine general-purpose cores and specialized hardware accelerators to boost energy efficiency and provide programming flexibility. Indeed, the hardware, software, and systems aspects in DSAs are highly tailored to maximize the energy efficiency of applications in a target domain. As DSAs and their conceptualization advance rapidly, there is a strong need to understand the research problems that need immediate attention. This article discusses the primary research directions in the design and runtime management of DSAs. Then, it surveys some promising approaches and highlights the outstanding research needs.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4296709256",
    "type": "article"
  },
  {
    "title": "Criticality-aware Monitoring and Orchestration for Containerized Industry 4.0 Environments",
    "doi": "https://doi.org/10.1145/3604567",
    "publication_date": "2023-06-18",
    "publication_year": 2023,
    "authors": "Marco Barletta; Marcello Cinque; Luigi De Simone; Raffaele Della Corte",
    "corresponding_authors": "",
    "abstract": "The evolution of industrial environments makes the reconfigurability and flexibility key requirements to rapidly adapt to changeable market needs. Computing paradigms like Edge/Fog computing are able to provide the required flexibility and scalability while guaranteeing low latencies and response times. Orchestration systems play a key role in these environments, enforcing automatic management of resources and workloads’ lifecycle, and drastically reducing the need for manual interventions. However, they do not currently meet industrial non-functional requirements, such as real-timeliness, determinism, reliability, and support for mixed-criticality workloads. In this article, we present k4.0s, an orchestration system for Industry 4.0 (I4.0) environments, which enables the support for real-time and mixed-criticality workloads. We highlight through experiments the need for novel monitoring approaches and propose a workflow for selecting monitoring metrics, which depends on both workload requirements and hosting node guarantees. We introduce new abstractions for the components of a cluster in order to enable criticality-aware monitoring and orchestration of real-time industrial workloads. Finally, we design an orchestration system architecture that reflects the proposed model, introducing new components and prototyping a Kubernetes-based implementation, taking the first steps towards a fully I4.0-enabled orchestration system.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4381123848",
    "type": "article"
  },
  {
    "title": "Fine-grained Hardware Acceleration for Efficient Batteryless Intermittent Inference on the Edge",
    "doi": "https://doi.org/10.1145/3608475",
    "publication_date": "2023-07-10",
    "publication_year": 2023,
    "authors": "Luca Caronti; Khakim Akhunov; Matteo Nardello; Kasım Sinan Yıldırım; Davide Brunelli",
    "corresponding_authors": "",
    "abstract": "Backing up the intermediate results of hardware-accelerated deep inference is crucial to ensure the progress of execution on batteryless computing platforms. However, hardware accelerators in low-power AI platforms only support the one-shot atomic execution of one neural network inference without any backups. This article introduces a new toolchain for MAX78000, which is a brand-new microcontroller with a hardware-based convolutional neural network (CNN) accelerator. Our toolchain converts any MAX78000-compatible neural network into an intermittently executable form. The toolchain enables finer checkpoint granularity on the MAX78000 CNN accelerator, allowing for backups of any intermediate neural network layer output. Based on the layer-by-layer CNN execution, we propose a new backup technique that performs only necessary (urgent) checkpoints. The method involves the batteryless system switching to ultra-low-power mode while charging, saving intermediate results only when input power is lower than ultra-low-power mode energy consumption. By avoiding unnecessary memory transfer, the proposed solution increases the inference throughput by 1.9× for simulation and by 1.2× for real-world setup compared to the coarse-grained baseline execution.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4383816923",
    "type": "article"
  },
  {
    "title": "Lightweight Hardware-Based Cache Side-Channel Attack Detection for Edge Devices (Edge-CaSCADe)",
    "doi": "https://doi.org/10.1145/3663673",
    "publication_date": "2024-05-11",
    "publication_year": 2024,
    "authors": "Pavitra Prakash Bhade; Joseph Paturel; Olivier Sentieys; Sharad Sinha",
    "corresponding_authors": "",
    "abstract": "Cache Side-Channel Attacks (CSCAs) have been haunting most processor architectures for decades now. Existing approaches to mitigation of such attacks have certain drawbacks, namely software mishandling, performance overhead, and low throughput due to false alarms. Hence, “mitigation only when detected” should be the approach to minimize the effects of such drawbacks. We propose a novel methodology of fine-grained detection of timing-based CSCA using a hardware-based detection module. We discuss the design, implementation, and use of our proposed detection module in processor architectures. Our approach successfully detects attacks that flush secret victim information from cache memory like Flush+Reload, Flush+Flush, Prime+Probe, Evict+Probe, and Prime+Abort, commonly known as cache timing attacks. Detection is on time with minimal performance overhead. The parameterizable number of counters used in our module allows detection of multiple attacks on multiple sensitive locations simultaneously. The fine-grained nature ensures negligible false alarms, severely reducing the need for any unnecessary mitigation. The proposed work is evaluated by synthesizing the entire detection algorithm as an attack detection block, Edge-CaSCADe, in a RISC-V processor as a target example. The detection results are checked under different workload conditions with respect to the number of attackers and the number of victims having RSA-, AES-, and ECC-based encryption schemes like ECIES, and on benchmark applications like MiBench and Embench. More than 98% detection accuracy within 2% of the beginning of an attack can be achieved with negligible false alarms. The detection module has an area and power overhead of 0.9% to 2% and 1% to 2.1% for the targeted RISC-V processor core without cache for one to five counters, respectively. The detection module does not affect the processor critical path and hence has no impact on its maximum operating frequency.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4396833974",
    "type": "article"
  },
  {
    "title": "Efficient Deep Learning Infrastructures for Embedded Computing Systems: A Comprehensive Survey and Future Envision",
    "doi": "https://doi.org/10.1145/3701728",
    "publication_date": "2024-10-24",
    "publication_year": 2024,
    "authors": "Xiangzhong Luo; Di Liu; Hao Kong; Shuo Huai; Hui Chen; Guochu Xiong; Weichen Liu",
    "corresponding_authors": "",
    "abstract": "Deep neural networks (DNNs) have recently achieved impressive success across a wide range of real-world vision and language processing tasks, spanning from image classification to many other downstream vision tasks, such as object detection, tracking, and segmentation. However, previous well-established DNNs, despite being able to maintain superior accuracy, have also been evolving to be deeper and wider and thus inevitably necessitate prohibitive computational resources for both training and inference. This trend further enlarges the computational gap between computation-intensive DNNs and resource-constrained embedded computing systems, making it challenging to deploy powerful DNNs in real-world embedded computing systems towards ubiquitous embedded intelligence. To alleviate this computational gap and enable ubiquitous embedded intelligence, we focus in this survey on discussing recent efficient deep learning infrastructures for embedded computing systems, spanning from training to inference , from manual to automated , from convolutional neural networks to transformers , from transformers to vision transformers , from vision models to large language models , from software to hardware , and from algorithms to applications . Specifically, we discuss recent efficient deep learning infrastructures for embedded computing systems from the lens of (1) efficient manual network design for embedded computing systems, (2) efficient automated network design for embedded computing systems, (3) efficient network compression for embedded computing systems, (4) efficient on-device learning for embedded computing systems, (5) efficient large language models for embedded computing systems, (6) efficient deep learning software and hardware for embedded computing systems, and (7) efficient intelligent applications for embedded computing systems. We also envision promising future directions and trends, which have the potential to deliver more ubiquitous embedded intelligence. We believe this survey has its merits and can shed light on future research, which can largely help researchers to quickly and smoothly get started in this emerging field.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4403735204",
    "type": "article"
  },
  {
    "title": "RAD-FS: Remote Timing and Power SCA Security in DVFS-augmented <i>Ultra-Low-Power</i> Embedded Systems",
    "doi": "https://doi.org/10.1145/3711836",
    "publication_date": "2025-01-27",
    "publication_year": 2025,
    "authors": "Daniel M. Dobkin; Nimrod Cever; Itamar Levi",
    "corresponding_authors": "",
    "abstract": "High-performance crypto-engines have become crucial components in modern System-On-Chip (SoC) architectures across platforms, from servers to edge-IoTs’. Alas, their secure operation faces a significant obstacle caused by information-leakage accessed through Side-Channel Analysis (SCA). Adversaries exploit statistical-analysis techniques on measured (e.g.,) power and timing signatures generated during (e.g.,) encryption, extracting secrets. Mathematical countermeasures against such attacks often impose substantial power-performance-area overheads. Dynamic Voltage and Frequency Scaling (DVFS) techniques provide power-efficiency by varying power consumption according to workload; these modulations are called power-states. Unintentionally, DVFS introduces new inherent weaknesses exploitable by malicious actors: power-states leak information in both power and timing side-channels, measurable in software and hardware. We introduce a method to increase side-channel resistance using integrated voltage regulators and DVFS: (1) Pushing known prior-art in the topic to Ultra Low Power (ULP) regime (2) For the first time introducing a mechanism to aid in counteracting the inherent weakness of DVFS in SCA (3) Providing measurements performed on 40nm process ULP PLS15 test-chip down at 580 mV power-supply (4) Offering improved and parameterized resistance to remote -timing vulnerabilities inherent to DVFS. We present various results and perform a detailed analysis while comparing performance and security to prior-art. Importantly, our solution is configurable in terms of security, maintaining degrees-of-freedom for power-optimization of DVFS.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406874965",
    "type": "article"
  },
  {
    "title": "Falsification of Cyber-physical Systems Using Bayesian Optimization",
    "doi": "https://doi.org/10.1145/3711922",
    "publication_date": "2025-02-27",
    "publication_year": 2025,
    "authors": "Zahra Ramezani; Kenan Šehić; Luigi Nardi; Knut Åkesson",
    "corresponding_authors": "",
    "abstract": "Cyber-physical systems (CPSs) are often complex and safety-critical, making it both challenging and crucial to ensure that the system’s specifications are met. Simulation-based falsification is a practical testing technique for increasing confidence in a CPS’s correctness, as it only requires that the system be simulated. Reducing the number of computationally intensive simulations needed for falsification is a key concern. In this study, we investigate Bayesian optimization (BO), a sample-efficient approach that learns a surrogate model to capture the relationship between input signal parameterization and specification evaluation. We propose two enhancements to the basic BO for improving falsification: (1) leveraging local surrogate models, and (2) utilizing the user’s prior knowledge. Additionally, we address the formulation of acquisition functions for falsification by proposing and evaluating various alternatives. Our benchmark evaluation demonstrates significant improvements when using local surrogate models in BO for falsifying challenging benchmark examples. Incorporating prior knowledge is found to be especially beneficial when the simulation budget is constrained. For some benchmark problems, the choice of acquisition function noticeably impacts the number of simulations required for successful falsification.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4408024820",
    "type": "article"
  },
  {
    "title": "Edge-Cloud Orchestration of Assertion-Based Monitors for Robotic Applications",
    "doi": "https://doi.org/10.1145/3723878",
    "publication_date": "2025-03-15",
    "publication_year": 2025,
    "authors": "Nicola Bombieri; Samuele Germiniani; Francesco Lumpp; Graziano Pravadelli",
    "corresponding_authors": "",
    "abstract": "The runtime verification of multi-domain software applications implementing the behaviors of modern robots is a challenging task. On the one hand, assertion-based verification (ABV) has shown great potential to check the correctness of complex systems at runtime. On the other hand, the computational overhead introduced by runtime ABV can be substantial, variable and non-deterministic. As a consequence, applying accurate ABV at runtime to autonomous robots, which are often characterized by resource-constrained computing architectures, can lead to severe slowdowns of the software execution and failures of temporal constraints, thus compromising the overall system’s correctness. We address this challenge by proposing a platform for runtime ABV that implements monitor synthesis from signal temporal logic assertions and dynamic monitor migration across edge devices and the cloud. The synthesized monitors are wrapped into ROS-compliant nodes and connected to the system under verification. The overall ABV framework and the related migration mechanism are then containerized with Docker for both edge and cloud computing. To evaluate the proposed platform, we present the results obtained with a set of synthetic benchmarks and with an industrial case study, which implements the mission of a Robotnik RB-Kairos mobile robot in a smart manufacturing production line. Note to Practitioners . This paper was motivated by the need for accurate and runtime verification of robotic systems software. Verification and validation of intelligent systems are often incomplete, as they cannot anticipate all potential scenarios, including errors or unexpected events. On top of this, assertion-based verification can also be resource-intensive; therefore, careful use of resources is required to avoid overloading the robot’s computational resources with the monitors. To achieve this, we used signal temporal logic, a widely accepted solution to monitor robotic and distributed applications. The main contribution of this work is a framework that can automatically synthesize the monitors that interface with the Robot Operating System (ROS) and also the capability of optimizing the end-to-end latency of verification at runtime by exploiting a distributed computing architecture (i.e., edge-cloud). In future work, we will address not only the minimization of end-to-end latency but also the timing upper bound of monitors to achieve runtime deterministic verification.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4408479766",
    "type": "article"
  },
  {
    "title": "Efficient and Robust Edge AI: Software, Hardware, and the Co-design",
    "doi": "https://doi.org/10.1145/3724396",
    "publication_date": "2025-03-25",
    "publication_year": 2025,
    "authors": "Bokyung Kim; Shiyu Li; Brady Taylor; Yiran Chen",
    "corresponding_authors": "",
    "abstract": "Artificial intelligence (AI) provides versatile capabilities in applications such as image classification and voice recognition that are most useful in edge or mobile computing settings. Shrinking these sophisticated algorithms into small form factors with minimal computing resources and power budgets requires innovation at several layers of abstraction: software, algorithmic, architectural, circuit, and device-level innovations. However, improvements to system efficiency may impact robustness and vice-versa. Therefore, a co-design framework is often necessary to customize a system for its given application. A system that prioritizes efficiency might use circuit-level innovations that introduce process variations or signal noise into the system, which may use software-level redundancy in order to compensate. In this tutorial, we will first examine various methods of improving efficiency and robustness in edge AI and their trade-offs at each level of abstraction. Then, we will outline co-design techniques for designing efficient and robust edge AI systems, using federated learning as a specific example to illustrate the effectiveness of co-design.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4408850206",
    "type": "article"
  },
  {
    "title": "A Novel Lattice-Based Fault Injection Attack Targeting the Nonce in the SM2 Digital Signature Algorithm",
    "doi": "https://doi.org/10.1145/3744246",
    "publication_date": "2025-06-07",
    "publication_year": 2025,
    "authors": "Cuiping Shao; Wenzhe Li; Huiyun Li; Zhimin Tang; Jianing Liang",
    "corresponding_authors": "",
    "abstract": "In embedded systems, particularly resource-constrained Internet of Things (IoT) devices, the SM2 Digital Signature Algorithm (SM2-DSA) standard is widely deployed for cryptographic security. While fault injection attacks can compromise digital signatures and extract private keys without physical damage, traditional approaches require precise temporal or spatial control, resulting in limited success rates and revealing insufficient research into the potential vulnerabilities of SM2-DSA. To address this issue, this paper introduces a novel and efficient lattice-based fault attack method targeting SM2-DSA. The method involves injecting faults into the nonce before the fourth step of the signature operation. By leveraging both the correct and erroneous intermediate values of Q obtained from the signature and verification processes, we can deduce partial bits of the nonce. Following this, we construct a lattice attack to recover the private key. Additionally, we establish the theoretical security boundary for lattice attack against SM2-DSA. Building upon the boundary, we propose an efficient implementation scheme for the attack. Experimental results demonstrate a 100% success rate over 1000 trials, using 61 signatures with 6 known bits of nonces for 256-bit SM2-DSA, with each recovery process completed in under 3 seconds. Finally, we propose countermeasures against this attack. Our proposed attack reveals potential security vulnerabilities in SM2-DSA implementations, providing constructive guidance for enhancing algorithmic security measures and defensive countermeasures.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4411121393",
    "type": "article"
  },
  {
    "title": "Register Blocking: A Source-to-Source Analytical Modelling Approach for Affine Loop Kernels",
    "doi": "https://doi.org/10.1145/3747183",
    "publication_date": "2025-07-05",
    "publication_year": 2025,
    "authors": "Theologos Anthimopoulos; Γεώργιος Κεραμίδας; Vasilios Kelefouras; Iakovos Stamoulis",
    "corresponding_authors": "",
    "abstract": "Register Blocking (RB), also known as ’Register-level Tiling’ or ’unroll-and-jam,’ is a key compiler optimization for developing efficient micro-kernels. However, applying RB effectively is a complex task due to several challenges. First, the exploration space of possible RB configurations is vast. Second, RB and loop permutation are interdependent, therefore addressing both optimizations simultaneously further inflates the exploration space. Third, the effectiveness of RB is highly dependent on the target hardware platform and the specific loop kernel being optimized. As a result, an extensive and time-consuming fine-tuning process is necessary for achieving an efficient implementation. To address these challenges, a source to source analytical modelling approach is proposed. The RB factors, the loops to apply RB, the number of allocated variables/registers per array reference, and the loops’ ordering, are generated by an analytical model, leveraging the target hardware architecture details and loop kernel characteristics. The proposed methodology has been evaluated on both embedded and general-purpose CPUs, using seven well-known loop kernels and three machine learning applications. The results show significant speedups over the GCC compiler, the Pluto tool, and related work.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4412046573",
    "type": "article"
  },
  {
    "title": "eMamba: Efficient Acceleration Framework for Mamba Models in Edge Computing",
    "doi": "https://doi.org/10.1145/3762190",
    "publication_date": "2025-08-19",
    "publication_year": 2025,
    "authors": "Kim Jiyong; J Y Lee; Jiun-Shiung Lin; Alish Kanani; Miao Sun; Ümit Y. Ogras; Jaehyun Park",
    "corresponding_authors": "",
    "abstract": "State Space Model (SSM)-based machine learning architectures have recently gained significant attention for processing sequential data. Mamba, a recent sequence-to-sequence SSM, offers competitive accuracy with superior computational efficiency compared to state-of-the-art transformer models. While this advantage makes Mamba particularly promising for resource-constrained edge devices, no hardware acceleration frameworks are currently optimized for deploying it in such environments. This paper presents eMamba, a comprehensive end-to-end hardware acceleration framework explicitly designed for deploying Mamba models on edge platforms. eMamba maximizes computational efficiency by replacing complex normalization layers with lightweight hardware-aware alternatives and approximating expensive operations, such as SiLU activation and exponentiation, considering the target applications. Then, it performs an approximation-aware neural architecture search (NAS) to tune the learnable parameters used during approximation. Evaluations with Fashion-MNIST, CIFAR-10, and MARS, an open-source human pose estimation dataset, show eMamba achieves comparable accuracy to state-of-the-art techniques using 1.63–19.9 × fewer parameters. In addition, it generalizes well to large-scale natural language tasks, demonstrating stable perplexity across varying sequence lengths on the WikiText2 dataset. We also quantize and implement the entire eMamba pipeline on an AMD ZCU102 FPGA and ASIC using GlobalFoundries (GF) 22 nm technology. Experimental results show 4.95–5.62 × lower latency and 2.22–9.95 × higher throughput, with 4.77 × smaller area, 9.84 × lower power, and 48.6 × lower energy consumption than baseline solutions while maintaining competitive accuracy.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4413308156",
    "type": "article"
  },
  {
    "title": "Optimizing AES-GCM on 32-Bit ARM Cortex-M4 Microcontrollers: Fixslicing and FACE-Based Approach",
    "doi": "https://doi.org/10.1145/3766074",
    "publication_date": "2025-09-05",
    "publication_year": 2025,
    "authors": "Hyunjun Kim; Hwajeong Seo",
    "corresponding_authors": "",
    "abstract": "Advanced Encryption Standard (AES) in Galois/Counter Mode (GCM) delivers both confidentiality and integrity, yet poses performance and security challenges on resource-limited microcontrollers. In this paper, we present an optimized AES-GCM implementation for the 32-bit ARM Cortex-M4 that combines the Fixslicing AES approach with the FACE (Fast AES-CTR Encryption) strategy, significantly reducing redundant computations in AES-CTR. We further examine two GHASH implementations, a 4-bit table-based approach and a Karatsuba-based constant-time variant, to balance speed, memory usage, and resistance to timing attacks. Our evaluations on an STM32F4 microcontroller show that the Fixslicing and FACE method reduces the AES-128 GCTR cycle counts by up to 19.41%, while the Table-based GHASH achieves nearly double the speed of its Karatsuba counterpart. These results confirm that with the right mix of bit-slicing optimizations, counter-mode caching, and lightweight polynomial multiplication, secure and efficient AES-GCM can be obtained even on low-power embedded devices.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4414018958",
    "type": "article"
  },
  {
    "title": "Data remapping for design space optimization of embedded memory systems",
    "doi": "https://doi.org/10.1145/643470.643474",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Rodric Rabbah; Krishna V. Palem",
    "corresponding_authors": "",
    "abstract": "In this article, we present a novel linear time algorithm for data remapping , that is, (i) lightweight; (ii) fully automated; and (iii) applicable in the context of pointer-centric programming languages with dynamic memory allocation support. All previous work in this area lacks one or more of these features. We proceed to demonstrate a novel application of this algorithm as a key step in optimizing the design of an embedded memory system. Specifically, we show that by virtue of locality enhancements via data remapping, we may reduce the memory subsystem needs of an application by 50%, and hence concomitantly reduce the associated costs in terms of size, power, and dollar-investment (61%). Such a reduction overcomes key hurdles in designing high-performance embedded computing solutions. Namely, memory subsystems are very desirable from a performance standpoint, but their costs have often limited their use in embedded systems. Thus, our innovative approach offers the intriguing possibility of compilers playing a significant role in exploring and optimizing the design space of a memory subsystem for an embedded design. To this end and in order to properly leverage the improvements afforded by a compiler optimization, we identify a range of measures for quantifying the cost-impact of popular notions of locality, prefetching, regularity of memory access, and others . The proposed methodology will become increasingly important, especially as the needs for application specific embedded architectures become prevalent. In addition, we demonstrate the wide applicability of data remapping using several existing microprocessors, such as the Pentium and UltraSparc. Namely, we show that remapping can achieve a performance improvement of 20% on the average. Similarly, for a parametric research HPL-PD microprocessor, which characterizes the new Itanium machines, we achieve a performance improvement of 28% on average. All of our results are achieved using applications from the DIS, Olden and SPEC2000 suites of integer and floating point benchmarks.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W2131574356",
    "type": "article"
  },
  {
    "title": "What is embedded systems and how should it be taught?---results from a didactic analysis",
    "doi": "https://doi.org/10.1145/1086519.1086528",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Martin Grimheden; Martin Törngren",
    "corresponding_authors": "",
    "abstract": "This paper provides an analysis of embedded systems education using a didactic approach. Didactics is a field of educational studies mostly referring to research aimed at investigating what's unique with a particular subject and how this subject ought to be taught. From the analysis we conclude that embedded systems has a thematic identity and a functional legitimacy. This implies that the subject would benefit from being taught with an exemplifying selection and using an interactive communication, meaning that the education should move from teaching “something of everything” toward “everything of something.” The interactive communication aims at adapting the education toward the individual student, which is feasible if using educational methods inspired by project-organized and problem-based learning. This educational setting is also advantageous as it prepares the students for a future career as embedded system engineers. The conclusions drawn from the analysis correlate with our own experiences from education in mechatronics as well as with a recently published study of 21 companies in Sweden dealing with industrial software engineering.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2002298982",
    "type": "article"
  },
  {
    "title": "Introducing embedded software and systems education and advanced learning technology in an engineering curriculum",
    "doi": "https://doi.org/10.1145/1086519.1086524",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "János Sztipanovits; Gautam Biswas; K.D. Frampton; Aniruddha Gokhale; Larry Howard; Gábor Karsai; T. John Koo; Xenofon Koutsoukos; Douglas C. Schmidt",
    "corresponding_authors": "",
    "abstract": "Embedded software and systems are at the intersection of electrical engineering, computer engineering, and computer science, with, increasing importance, in mechanical engineering. Despite the clear need for knowledge of systems modeling and analysis (covered in electrical and other engineering disciplines) and analysis of computational processes (covered in computer science), few academic programs have integrated the two disciplines into a cohesive program of study. This paper describes the efforts conducted at Vanderbilt University to establish a curriculum that addresses the needs of embedded software and systems. Given the compartmentalized nature of traditional engineering schools, where each discipline has an independent program of study, we have had to devise innovative ways to bring together the two disciplines. The paper also describes our current efforts in using learning technology to construct, manage, and deliver sophisticated computer-aided learning modules that can supplement the traditional course structure in the individual disciplines through out-of-class and in-class use.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2044360902",
    "type": "article"
  },
  {
    "title": "Task mapping and priority assignment for soft real-time applications under deadline miss ratio constraints",
    "doi": "https://doi.org/10.1145/1331331.1331343",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Sorin Manolache; Petru Eles; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "Both analysis and design optimisation of real-time systems has predominantly concentrated on considering hard real-time constraints. For a large class of applications, however, this is both unrealistic and leads to unnecessarily expensive implementations. This paper addresses the problem of task priority assignment and task mapping in the context of multiprocessor applications with stochastic execution times and in the presence of constraints on the percentage of missed deadlines. We propose a design space exploration strategy together with a fast method for system performance analysis. Experiments emphasize the efficiency of the proposed analysis method and optimisation heuristic in generating high-quality implementations of soft real-time systems with stochastic task execution times and constraints on deadline miss ratios.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2048368454",
    "type": "article"
  },
  {
    "title": "Energy efficient DVS schedule for fixed-priority real-time systems",
    "doi": "https://doi.org/10.1145/1274858.1274867",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Gang Quan; Xiaobo Sharon Hu",
    "corresponding_authors": "",
    "abstract": "Energy consumption has become an increasingly important consideration in designing many real-time embedded systems. Variable voltage processors, if used properly, can dramatically reduce such system energy consumption. In this paper, we present a technique to determine voltage settings for a variable voltage processor that utilizes a fixed-priority assignment to schedule jobs. By exploiting more efficiently the processor slack time, our approach can be more effective in reducing the execution speed for real-time tasks when necessary. Our approach also produces the minimum constant voltage needed to feasibly schedule the entire job set. With both randomly generated and practical examples, our heuristic approach can achieve the dynamic energy reduction very close to the theoretically optimal one (within 2%) with much less computation cost.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2071767154",
    "type": "article"
  },
  {
    "title": "FAST",
    "doi": "https://doi.org/10.1145/1132357.1132364",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "Kiran Seth; Aravindh Anantaraman; Frank Mueller; Eric Rotenberg",
    "corresponding_authors": "",
    "abstract": "Energy is a valuable resource in embedded systems as the lifetime of many such systems is constrained by their battery capacity. Recent advances in processor design have added support for dynamic frequency/voltage scaling (DVS) for saving energy. Recent work on real-time scheduling focuses on saving energy in static as well as dynamic scheduling environments by exploiting idle time and slack because of early task completion for DVS of subsequent tasks. These scheduling algorithms rely on a priori knowledge of worst-case execution times (WCET) for each task. They assume that DVS has no effect on the worst-case execution cycles (WCEC) of a task and scale the WCET according to the processor frequency. However, for systems with memory hierarchies, the WCEC typically does change under DVS because of requency modulation. Hence, current assumptions used by DVS schemes result in a highly exaggerated WCET. This paper contributes novel techniques for tight and flexible static timing analysis, particularly well-suited for dynamic scheduling schemes. The technical contributions are as follows: (1) We assess the problem of changing execution cycles owing to scaling techniques. (2) We propose a parametric approach toward bounding the WCET statically with respect to the frequency. Using a parametric model, we can capture the effect of changes in frequency on the WCEC and, thus, accurately model the WCET over any frequency range. (3) We discuss design and implementation of the frequency-aware static timing analysis (FAST) tool based on our prior experience with static timing analysis. (4) We demonstrate in experiments that our FAST tool provides safe upper bounds on the WCET, which are tight. The FAST tool allows us to capture the WCET of six benchmarks using equations that overestimate the WCET by less than 1%. FAST equations can also be used to improve existing DVS scheduling schemes to ensure that the effect of frequency scaling on WCET is considered and that the WCET used is not exaggerated. (5) We leverage three DVS scheduling schemes by incorporating FAST into them and by showing that the energy consumption further decreases. (6) We compare experimental results using two different energy models to demonstrate or verify the validity of simulation methods. To the best of our knowledge, this study of DVS effects on timing analysis is unprecedented.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2166745914",
    "type": "article"
  },
  {
    "title": "Dynamic scratchpad memory management for code in portable systems with an MMU",
    "doi": "https://doi.org/10.1145/1331331.1331335",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Bernhard Egger; Jaejin Lee; Heonshik Shin",
    "corresponding_authors": "",
    "abstract": "In this work, we present a dynamic memory allocation technique for a novel, horizontally partitioned memory subsystem targeting contemporary embedded processors with a memory management unit (MMU). We propose to replace the on-chip instruction cache with a scratchpad memory (SPM) and a small minicache. Serializing the address translation with the actual memory access enables the memory system to access either only the SPM or the minicache. Independent of the SPM size and based solely on profiling information, a postpass optimizer classifies the code of an application binary into a pageable and a cacheable code region. The latter is placed at a fixed location in the external memory and cached by the minicache. The former, the pageable code region, is copied on demand to the SPM before execution. Both the pageable code region and the SPM are logically divided into pages the size of an MMU memory page. Using the MMU's pagefault exception mechanism, a runtime scratchpad memory manager (SPMM) tracks page accesses and copies frequently executed code pages to the SPM before they get executed. In order to minimize the number of page transfers from the external memory to the SPM, good code placement techniques become more important with increasing sizes of the MMU pages. We discuss code-grouping techniques and provide an analysis of the effect of the MMU's page size on execution time, energy consumption, and external memory accesses. We show that by using the data cache as a victim buffer for the SPM, significant energy savings are possible. We evaluate our SPM allocation strategy with fifteen applications, including H.264, MP3, MPEG-4, and PGP. The proposed memory system requires 8% less die are compared to a fully-cached configuration. On average, we achieve a 31% improvement in runtime performance and a 35% reduction in energy consumption with an MMU page size of 256 bytes.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2036252741",
    "type": "article"
  },
  {
    "title": "Design and optimization of distributed sensing coverage in wireless sensor networks",
    "doi": "https://doi.org/10.1145/1347375.1347386",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Ting Yan; Yu Gu; Tian He; John A. Stankovic",
    "corresponding_authors": "",
    "abstract": "For many sensor network applications, such as military surveillance, it is necessary to provide full sensing coverage to a security-sensitive area while, at the same time, minimizing energy consumption and extending system lifetime by leveraging the redundant deployment of sensor nodes. In this paper, we propose a surveillance service for sensor networks based on a distributed energy-efficient sensing coverage protocol. In the protocol, each node is able to dynamically decide a schedule for itself to guarantee a certain degree-of-coverage (DOC) with average energy consumption inversely proportional to the node density. Several optimizations and extensions are proposed to enhance the basic design with a better load-balance feature and a longer network lifetime. We consider and address the impact of the target size and the unbalanced initial energy capacity of individual nodes to the network lifetime. Several practical issues such as the localization error, irregular sensing range, and unreliable communication links are addressed as well. Simulation shows that our protocol extends system lift-time significantly with low energy consumption. It outperforms other state-of-the-art schemes by as much as 50% reduction in energy consumption and as much as 130% increase in the half-life of the network.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2077242540",
    "type": "article"
  },
  {
    "title": "FIDES",
    "doi": "https://doi.org/10.1145/1457246.1457247",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Hiroaki Inoue; Junji Sakai; Sunao Torii; Masato Edahiro",
    "corresponding_authors": "",
    "abstract": "We propose a secure platform on a chip multiprocessor, FIDES, in order to enable next generation mobile terminals to execute downloaded native applications for Linux. Its most important feature is the higher security based on multigrained separation mechanisms. Four new technologies support the FIDES platform: bus filter logic, XIP kernels, policy separation, and dynamic access control. With these technologies, the FIDES platform can tolerate both application-level and kernel-level bugs on an actual download subsystem. Thus, the best-suited platform to secure next generation mobile terminals is FIDES.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2040146928",
    "type": "article"
  },
  {
    "title": "Tightening the bounds on feasible preemptions",
    "doi": "https://doi.org/10.1145/1880050.1880063",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Harini Ramaprasad; Frank Mueller",
    "corresponding_authors": "",
    "abstract": "Data caches are an increasingly important architectural feature in most modern computer systems. They help bridge the gap between processor speeds and memory access times. One inherent difficulty of using data caches in a real-time system is the unpredictability of memory accesses, which makes it difficult to calculate worst-case execution times (WCETs) of real-time tasks. While cache analysis for single real-time tasks has been the focus of much research in the past, bounding the preemption delay in a multitask preemptive environment is a challenging problem, particularly for data caches. This article makes multiple contributions in the context of independent, periodic tasks with deadlines less than or equal to their periods executing on a single processor. 1) For every task, we derive data cache reference patterns for all scalar and nonscalar references. These patterns are used to derive an upper bound on the WCET of real-time tasks. 2) We show that, when considering cache preemption effects, the critical instant does not occur upon simultaneous release of all tasks. We provide results for task sets with phase differences to prove our claim. 3) We develop a method to calculate tight upper bounds on the maximum number of possible preemptions for each job of a task and, considering the worst-case placement of these preemption points, derive a much tighter bound on its WCET. We provide results using both static-and dynamic-priority schemes. Our results show significant improvements in the bounds derived. We achieve up to an order of magnitude improvement over two prior methods and up to half an order of magnitude over a third prior method for the number of preemptions , the WCET and the response time of a task. Consideration of the best-case and worst-case execution times of higher-priority jobs enables these improvements.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2067675848",
    "type": "article"
  },
  {
    "title": "Online memory compression for embedded systems",
    "doi": "https://doi.org/10.1145/1698772.1698785",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Lei Yang; Robert P. Dick; Haris Lekatsas; Srimat Chakradhar",
    "corresponding_authors": "",
    "abstract": "Memory is a scarce resource during embedded system design. Increasing memory often increases packaging costs, cooling costs, size, and power consumption. This article presents CRAMES, a novel and efficient software-based RAM compression technique for embedded systems. The goal of CRAMES is to dramatically increase effective memory capacity without hardware or application design changes, while maintaining high performance and low energy consumption. To achieve this goal, CRAMES takes advantage of an operating system's virtual memory infrastructure by storing swapped-out pages in compressed format. It dynamically adjusts the size of the compressed RAM area, protecting applications capable of running without it from performance or energy consumption penalties. In addition to compressing working data sets, CRAMES also enables efficient in-RAM filesystem compression, thereby further increasing RAM capacity. CRAMES was implemented as a loadable module for the Linux kernel and evaluated on a battery-powered embedded system. Experimental results indicate that CRAMES is capable of doubling the amount of RAM available to applications running on the original system hardware. Execution time and energy consumption for a broad range of examples are rarely affected. When physical RAM is reduced to 62.5% of its original quantity, CRAMES enables the target embedded system to support the same applications with reasonable performance and energy consumption penalties (on average 9.5% and 10.5%), while without CRAMES those applications either may not execute or suffer from extreme performance degradation or instability. In addition to presenting a novel framework for dynamic data memory compression and in-RAM filesystem compression in embedded systems, this work identifies the software-based compression algorithms that are most appropriate for use in low-power embedded systems.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2085385727",
    "type": "article"
  },
  {
    "title": "Formal specification of wireless and pervasive healthcare applications",
    "doi": "https://doi.org/10.1145/1814539.1814551",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Antonio Coronato; Giuseppe De Pietro",
    "corresponding_authors": "",
    "abstract": "Wireless and pervasive healthcare applications typically present critical requirements from the point of view of functional correctness, reliability, availability, security, and safety. In contrast to the case of classic safety critical applications, the behavior of wireless and pervasive applications is affected by the movements and location of users and resources. This article presents a methodology to formally express requirements in safety critical wireless and pervasive healthcare applications in order to achieve a higher degree of dependability. In particular, it will be shown how it is possible to formalize and constrict mobility characteristics by combining, and in some cases extending, several formal methods. The article also describes a rigorous specification process. Finally, it concludes with a case study of a real safety critical pervasive healthcare application that is going to be deployed in a city hospital.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W1997618946",
    "type": "article"
  },
  {
    "title": "Network-Level Power-Performance Trade-Off in Wearable Activity Recognition",
    "doi": "https://doi.org/10.1145/2345770.2345781",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Piero Zappi; Daniel Roggen; Elisabetta Farella; Gerhard Tröster; Luca Benini",
    "corresponding_authors": "",
    "abstract": "Wearable gesture recognition enables context aware applications and unobtrusive HCI. It is realized by applying machine learning techniques to data from on-body sensor nodes. We present an gesture recognition system minimizing power while maintaining a run-time application defined performance target through dynamic sensor selection. Compared to the non managed approach optimized for recognition accuracy (95% accuracy), our technique can extend network lifetime by 4 times with accuracy &gt;90% and by 9 times with accuracy &gt;70%. We characterize the approach and outline its applicability to other scenarios.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2153861700",
    "type": "article"
  },
  {
    "title": "BAND-AiDe",
    "doi": "https://doi.org/10.1145/2331147.2331159",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Ayan Banerjee; Sailesh Kandula; Tridib Mukherjee; Sandeep K. S. Gupta",
    "corresponding_authors": "",
    "abstract": "Body area networks (BANs) are networks of medical devices implanted within or worn on the human body. Analysis and verification of BAN designs require (i) early feedback on the BAN design and (ii) high-confidence evaluation of BANs without requiring any hazardous, intrusive, and costly deployment. Any design of BAN further has to ensure (i) the safety of the human body, that is, limiting any undesirable side-effects (e.g., heat dissipation) of BAN operations (involving sensing, computation, and communication among the devices) on the human body, and (ii) the sustainability of the BAN operations, that is, the continuation of the operations under constrained resources (e.g., limited battery power in the devices) without requiring any redeployments. This article uses the Model Based Engineering (MBE) approach to perform design and analysis of BANs. In this regard, first, an abstract cyber-physical model of BANs, called BAN-CPS, is proposed that captures the undesirable side-effects of the medical devices (cyber) on the human body (physical); second, a design and analysis tool, named BAND-AiDe, is developed that allows specification of BAN-CPS using industry standard Abstract Architecture Description Language (AADL) and enables safety and sustainability analysis of BANs; and third, the applicability of BAND-AiDe is shown through a case study using both single and a network of medical devices for health monitoring applications.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W1978890724",
    "type": "article"
  },
  {
    "title": "A Hardware Abstraction Layer in Java",
    "doi": "https://doi.org/10.1145/2043662.2043666",
    "publication_date": "2011-11-01",
    "publication_year": 2011,
    "authors": "Martin Schoeberl; Stephan Korsholm; Tomáš Kalibera; Anders P. Ravn",
    "corresponding_authors": "",
    "abstract": "Embedded systems use specialized hardware devices to interact with their environment, and since they have to be dependable, it is attractive to use a modern, type-safe programming language like Java to develop programs for them. Standard Java, as a platform-independent language, delegates access to devices, direct memory access, and interrupt handling to some underlying operating system or kernel, but in the embedded systems domain resources are scarce and a Java Virtual Machine (JVM) without an underlying middleware is an attractive architecture. The contribution of this article is a proposal for Java packages with hardware objects and interrupt handlers that interface to such a JVM. We provide implementations of the proposal directly in hardware, as extensions of standard interpreters, and finally with an operating system middleware. The latter solution is mainly seen as a migration path allowing Java programs to coexist with legacy system components. An important aspect of the proposal is that it is compatible with the Real-Time Specification for Java (RTSJ).",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2037676168",
    "type": "article"
  },
  {
    "title": "Adaptive and Radio-Agnostic QoS for Body Sensor Networks",
    "doi": "https://doi.org/10.1145/2043662.2043672",
    "publication_date": "2011-11-01",
    "publication_year": 2011,
    "authors": "Gang Zhou; Qiang Li; Jing Li; Yafeng Wu; Shan Lin; Jian Lu; Chieh‐Yih Wan; Mark Yarvis; John A. Stankovic",
    "corresponding_authors": "",
    "abstract": "As wireless devices and sensors are increasingly deployed on people, researchers have begun to focus on wireless body-area networks. Applications of wireless body sensor networks include healthcare, entertainment, and personal assistance, in which sensors collect physiological and activity data from people and their environments. In these body sensor networks, quality of service is needed to provide reliable data communication over prioritized data streams. This article proposes BodyQoS, the first running QoS system demonstrated on an emulated body sensor network. BodyQoS adopts an asymmetric architecture, in which most processing is done on a resource-rich aggregator, minimizing the load on resource-limited sensor nodes. A virtual MAC is developed in BodyQoS to make it radio-agnostic, allowing a BodyQoS to schedule wireless resources without knowing the implementation details of the underlying MAC protocols. Another unique property of BodyQoS is its ability to provide adaptive resource scheduling. When the effective bandwidth of the channel degrades due to RF interference or body fading effect, BodyQoS adaptively schedules remaining bandwidth to meet QoS requirements. We have implemented BodyQoS in NesC on top of TinyOS, and evaluated its performance on MicaZ devices. Our system performance study shows that BodyQoS delivers significantly improved performance over conventional solutions in combating channel impairment.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2043858891",
    "type": "article"
  },
  {
    "title": "Automatic RTL Test Generation from SystemC TLM Specifications",
    "doi": "https://doi.org/10.1145/2220336.2220350",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Mingsong Chen; Prabhat Mishra; Dhrubajyoti Kalita",
    "corresponding_authors": "",
    "abstract": "SystemC transaction-level modeling (TLM) is widely used to enable early exploration for both hardware and software designs. It can reduce the overall design and validation effort of complex system-on-chip (SOC) architectures. However, due to lack of automated techniques coupled with limited reuse of validation efforts between abstraction levels, SOC validation is becoming a major bottleneck. This article presents a novel top-down methodology for automatically generating register transfer-level (RTL) tests from SystemC TLM specifications. It makes two important contributions: i) it proposes a method that can automatically generate TLM tests using various coverage metrics, and (ii) it develops a test refinement specification for automatically converting TLM tests to RTL tests in order to reduce overall validation effort. We have developed a tool which incorporates these activities to enable automated RTL test generation from SystemC TLM specifications. Case studies using a router example and a 64-bit Alpha AXP pipelined processor demonstrate that our approach can achieve intended functional coverage of the RTL designs, as well as capture various functional errors and inconsistencies between specifications and implementations.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2145101507",
    "type": "article"
  },
  {
    "title": "Achieving energy efficiency through runtime partial reconfiguration on reconfigurable systems",
    "doi": "https://doi.org/10.1145/2442116.2442122",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Shaoshan Liu; Richard Neil Pittman; Alessandro Forin; Jean‐Luc Gaudiot",
    "corresponding_authors": "",
    "abstract": "One major advantage of reconfigurable computing systems is their ability to reconfigure hardware at runtime. In this paper, we study the feasibility of achieving energy efficiency in reconfigurable computing systems (e.g., FPGAs) through runtime partial reconfiguration (PR) techniques. In the ideal scenario, we use a hardware accelerator to accelerate certain parts of the program execution; when the accelerator is not active, we use partial reconfiguration to unload it to reduce power consumption. Since the reconfiguration process may introduce a high energy overhead, it is unclear whether this approach is efficient. To approach this problem, we first analytically identify the conditions under which partial reconfiguration can reduce energy consumption. Our results indicate that the key to reduce partial reconfiguration energy overhead is to minimize the time overhead of the reconfiguration process. Based on this analysis, we design and implement a fast reconfiguration engine that achieves close-to-ideal throughput on Xilinx Virtex-4 FPGAs. Our fast reconfiguration engine utilizes a master-slave DMA pair to stream data between the SRAM and the Internal Configuration Access Port (ICAP). We experimentally verify our proposed solutions and compare our design to existing energy reduction techniques, such as clock gating. The results of our study show that by using partial reconfiguration to eliminate the power consumption of the accelerator when it is inactive, we can accelerate program execution and at the same time reduce the overall energy consumption by half.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W1993830474",
    "type": "article"
  },
  {
    "title": "LARK",
    "doi": "https://doi.org/10.1145/2043662.2043665",
    "publication_date": "2011-11-01",
    "publication_year": 2011,
    "authors": "Gianluca Dini; Ida Maria Savino",
    "corresponding_authors": "",
    "abstract": "Group communication has proven a powerful paradigm for designing applications and services in Wireless Sensor Networks (WSNs). Given the tight interaction between WSNs and the physical world, a security infringement may translate into a safety infringement. Therefore, in order to fully exploit the group communication paradigm we need to secure it. Traditionally, this requirement has been formalized in terms of backward and forward security and fulfilled by means of rekeying . In WSNs, group rekeying becomes particularly a complex problem because communication takes place over an easily accessible wireless medium and because sensor nodes have severe limitations in terms of computing, storage, energy, and tamper-resistance capabilities for cost reasons. In this article we present a Lightweight Authenticated ReKeying (LARK) scheme for clustered WSNs. LARK guarantees backward and forward security, is scalable in terms of communication overhead, and efficient in terms of computing overhead for key authentiticy verification. LARK achieves security, efficiency, and scalability by exploiting two basic well-known mechanisms, namely key graph and key chain , and integrating them in an original way. LARK supports a general group model where groups can be hierachical and partially overlapping. In contrast to other WSN group rekeying schemes, LARK considers grouping a tool for designing and implementing applications and services rather than for network management. Consequently, LARK receives a group topology reflecting the application needs and manages rekeying at single-group level. In the article we describe LARK, formally argue that it meets the backward and forward security requirements, and, finally, evaluate its performance in terms of communication, computing, and storage overhead in limited-resources sensor nodes.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2091030363",
    "type": "article"
  },
  {
    "title": "Ultra low-power signal processing in wearable monitoring systems",
    "doi": "https://doi.org/10.1145/2501626.2501636",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Hassan Ghasemzadeh; Roozbeh Jafari",
    "corresponding_authors": "",
    "abstract": "Advances in technology have led to the development of wearable sensing, computing, and communication devices that can be woven into the physical environment of our daily lives, enabling a large variety of new applications in several domains, including wellness and health care. Despite their tremendous potential to impact our lives, wearable health monitoring systems face a number of hurdles to become a reality. The enabling processors and architectures demand a large amount of energy, requiring sizable batteries. In this article, we propose a granular decision-making architecture for physical movement monitoring applications. The module can be viewed as a tiered wake-up circuitry. This decision-making module, in combination with a low-power microcontroller, allows for significant power saving through an ultra low-power processing architecture. The significant power saving is achieved by performing a preliminary ultra low-power signal processing, and hence, keeping the microcontroller off when the incoming signal is not of interest. The preliminary signal processing is performed by a set of special-purpose functional units, also called screening blocks, that implement template matching functions. We formulate and solve an optimization problem for selecting screening blocks such that the accuracy requirements of the signal processing are accommodated while the total power is minimized. Our experimental results on real data from wearable motion sensors show that the proposed algorithm achieves 63.2% energy saving while maintaining a sensitivity of 94.3% in recognizing transitional actions.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2058092201",
    "type": "article"
  },
  {
    "title": "Formal Specification of Medical Systems by Proof-Based Refinement",
    "doi": "https://doi.org/10.1145/2406336.2406351",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Domingo Mery; Neeraj Kumar Singh",
    "corresponding_authors": "",
    "abstract": "Formal methods have emerged as an alternative approach to ensuring quality and correctness of highly critical systems, overcoming limitations of traditional validation techniques such as simulation and testing. We propose a refinement-based methodology for complex medical systems design, which possesses all the required key features. A refinement-based combined approach of formal verification, model validation using a model-checker and refinement chart is proposed in this methodology for designing a high-confidence medical device. Furthermore, we show the effectiveness of this methodology for the design of a cardiac pacemaker system.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2062214872",
    "type": "article"
  },
  {
    "title": "The Perfect Getaway",
    "doi": "https://doi.org/10.1145/3035542",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Isabella Stilkerich; Clemens Lang; Christoph Erhardt; Christian Bay; Michael Stilkerich",
    "corresponding_authors": "",
    "abstract": "The use of a managed, type-safe language such as Java in real-time and embedded systems offers productivity and, in particular, safety and dependability benefits at a reasonable cost. It has been shown for commodity systems that Escape Analysis (EA) enables a set of useful optimizations, and benefits from the properties of a type-safe language. In this article, we explore the application of escape analysis in KESO [Stilkerich et al. 2012], a Java ahead-of-time compiler targeting embedded real-time systems. We present specific applications of EA for embedded programs that go beyond the widely known stack-allocation and synchronization optimizations such as extended remote-procedure-call (RPC) support for software-isolated applications, automated inference of immutable data, or improved upper space and time bounds for worst-case estimations.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2612721600",
    "type": "article"
  },
  {
    "title": "Cache persistence analysis",
    "doi": "https://doi.org/10.1145/2435227.2435236",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Christoph Cullmann",
    "corresponding_authors": "Christoph Cullmann",
    "abstract": "To compute a worst-case execution time (WCET) estimate for a program, the architectural effects of the underlying hardware must be modeled. For modern processors this results in the need for a cache and pipeline analysis. The timing-relevant result of the cache analysis is the categorization of the accesses to cached memory. Categorizations that are obtainable by the well-known must and may cache analysis [Ferdinand 1997] are always-hit, always-miss and not-classified. The cache persistence analysis tries to provide additional information for the not-classified case to limit the number of misses. There exists a cache persistence analysis by Ferdinand and Wilhelm based on abstract interpretation computing these classifications. In this article, we present a correctness issue with this analysis. To fix this issue, we propose two new abstract interpretation based persistence analyses and show their safety. One is based on the known may analysis and a second one on the concept of conflict counting. For fully timing compositional architectures [Wilhelm et al. 2009] the persistence information is straightforward to use. We will apply the concepts of persistence analysis for the first time to state-of-the-art architectures that exhibit both timing anomalies and domino effects. Such architectures do not allow the analyzer to quantify the costs of a single cache hit or miss in isolation. To make the usage of the persistence information feasible, we integrate the presented novel persistence analyses together with a novel path analysis approach into the industrially used WCET analyzer aiT.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2046003643",
    "type": "article"
  },
  {
    "title": "A Novel Memristor-Based Hardware Security Primitive",
    "doi": "https://doi.org/10.1145/2736285",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Jimson Mathew; Rajat Subhra Chakraborty; Durga Prasad Sahoo; Yuanfan Yang; Dhiraj K. Pradhan",
    "corresponding_authors": "",
    "abstract": "Memristor is an exciting new addition to the repertoire of fundamental circuit elements. Alternatives to many security protocols originally employing traditional mathematical cryptography involve novel hardware security primitives, such as Physically Unclonable Functions (PUFs). In this article, we propose a novel hybrid memristor-CMOS PUF circuit and demonstrate its suitability through extensive simulations of environmental and process variation effects. The proposed PUF circuit has substantially less hardware overhead than previously proposed memristor-based PUF circuits while being inherently resistant to machine learning-based modeling attacks because of challenge-dependent delays of the memristor stages. The proposed PUF can be conveniently used in many security applications and protocols based on hardware-intrinsic security.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2061983145",
    "type": "article"
  },
  {
    "title": "Transport-layer-assisted routing for runtime thermal management of 3D NoC systems",
    "doi": "https://doi.org/10.1145/2512468",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Chih-Hao Chao; Kun-Chih Chen; Tsu-Chu Yin; Shu-Yen Lin; An-Yeu Wu",
    "corresponding_authors": "",
    "abstract": "To ensure thermal safety and to avoid performance degradation from temperature regulation in 3D NoC, we propose a new temperature-traffic control framework. The framework contains the vertical throttling-based runtime thermal management (VT-RTM) scheme and the transport-layer assisted routing (TLAR) scheme. VT-RTM scheme increases the cooling speed and maintains high availability. TLAR scheme sustains the throughput of the nonstationary irregular mesh network. In our experiments, VT-RTM scheme reduces cooling time by 84% and achieves 98% network availability; the overall performance impact is around 8% of traditional schemes. TLAR scheme reduces average latency by 35∼% and improves sustainable throughput by 76%",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2079066303",
    "type": "article"
  },
  {
    "title": "Online learning of timeout policies for dynamic power management",
    "doi": "https://doi.org/10.1145/2529992",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Umair Ali Khan; Bernhard Rinner",
    "corresponding_authors": "",
    "abstract": "Dynamic power management (DPM) refers to strategies which selectively change the operational states of a device during runtime to reduce the power consumption based on the past usage pattern, the current workload, and the given performance constraint. The power management problem becomes more challenging when the workload exhibits nonstationary behavior which may degrade the performance of any single or static DPM policy. This article presents a reinforcement learning (RL)-based DPM technique for optimal selection of timeout values in the different device states. Each timeout period determines how long the device will remain in a particular state before the transition decision is taken. The timeout selection is based on workload estimates derived from a Multilayer Artificial Neural Network (ML-ANN) and an objective function given by weighted performance and power parameters. Our DPM approach is further able to adapt the power-performance weights online to meet user-specified power and performance constraints, respectively. We have completely implemented our DPM algorithm on our embedded traffic surveillance platform and performed long-term experiments using real traffic data to demonstrate the effectiveness of the DPM. Our results show that the proposed learning algorithm not only adequately explores the power-performance trade-off with nonstationary workload but can also successfully perform online adjustment of the trade-off parameter in order to meet the user-specified constraint.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2161503697",
    "type": "article"
  },
  {
    "title": "An Out-of-Order Load-Store Queue for Spatial Computing",
    "doi": "https://doi.org/10.1145/3126525",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Lana Josipović; Philip Brisk; Paolo Ienne",
    "corresponding_authors": "",
    "abstract": "The efficiency of spatial computing depends on the ability to achieve maximal parallelism. This necessitates memory interfaces that can correctly handle memory accesses that arrive in arbitrary order while still respecting data dependencies and ensuring appropriate ordering for semantic correctness. However, a typical memory interface for out-of-order processors (i.e., a load-store queue) cannot immediately meet these requirements: a different allocation policy is needed to achieve out-of-order execution in spatial systems that naturally omit the notion of sequential program order, a fundamental piece of information for correct execution. We show a novel and practical way to organize the allocation for an out-of-order load-store queue for spatial computing. The main idea is to dynamically allocate groups of memory accesses (depending on the dynamic behavior of the application), where the access order within the group is statically predetermined (for instance by a high-level synthesis tool). We detail the construction of our load-store queue and demonstrate on a few practical cases its advantages over standard accelerator-memory interfaces.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2760331766",
    "type": "article"
  },
  {
    "title": "Predictable Shared Cache Management for Multi-Core Real-Time Virtualization",
    "doi": "https://doi.org/10.1145/3092946",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "Hyoseung Kim; Ragunathan Rajkumar",
    "corresponding_authors": "",
    "abstract": "Real-time virtualization has gained much attention for the consolidation of multiple real-time systems onto a single hardware platform while ensuring timing predictability. However, a shared last-level cache (LLC) on modern multi-core platforms can easily hamper the timing predictability of real-time virtualization due to the resulting temporal interference among consolidated workloads. Since such interference caused by the LLC is highly variable and may have not even existed in legacy systems to be consolidated, it poses a significant challenge for real-time virtualization. In this article, we propose a predictable shared cache management framework for multi-core real-time virtualization. Our framework introduces two hypervisor-level techniques, vLLC and vColoring, that enable the cache allocation of individual tasks running in a virtual machine (VM), which is not achievable by the current state of the art. Our framework also provides a cache management scheme that determines cache allocation to tasks, designs VMs in a cache-aware manner, and minimizes the aggregated utilization of VMs to be consolidated. As a proof of concept, we implemented vLLC and vColoring in the KVM hypervisor running on x86 and ARM multi-core platforms. Experimental results with three different guest OSs (i.e., Linux/RK, vanilla Linux, and MS Windows Embedded) show that our techniques can effectively control the cache allocation of tasks in VMs. Our cache management scheme yields a significant utilization benefit compared to other approaches while satisfying timing constraints.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2774191434",
    "type": "article"
  },
  {
    "title": "NoC contention analysis using a branch-and-prune algorithm",
    "doi": "https://doi.org/10.1145/2567937",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Dakshina Dasari; Borislav Nikolić; Vincent Nélis; Stefan M. Petters",
    "corresponding_authors": "",
    "abstract": "“Many-core” systems based on a Network-on-Chip (NoC) architecture offer various opportunities in terms of performance and computing capabilities, but at the same time they pose many challenges for the deployment of real-time systems, which must fulfill specific timing requirements at runtime. It is therefore essential to identify, at design time, the parameters that have an impact on the execution time of the tasks deployed on these systems and the upper bounds on the other key parameters. The focus of this work is to determine an upper bound on the traversal time of a packet when it is transmitted over the NoC infrastructure. Towards this aim, we first identify and explore some limitations in the existing recursive-calculus-based approaches to compute the Worst-Case Traversal Time (WCTT) of a packet. Then, we extend the existing model by integrating the characteristics of the tasks that generate the packets. For this extended model, we propose an algorithm called “Branch and Prune” (BP). Our proposed method provides tighter and safe estimates than the existing recursive-calculus-based approaches. Finally, we introduce a more general approach, namely “Branch, Prune and Collapse” (BPC) which offers a configurable parameter that provides a flexible trade-off between the computational complexity and the tightness of the computed estimate. The recursive-calculus methods and BP present two special cases of BPC when a trade-off parameter is 1 or ∞, respectively. Through simulations, we analyze this trade-off, reason about the implications of certain choices, and also provide some case studies to observe the impact of task parameters on the WCTT estimates.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2041240648",
    "type": "article"
  },
  {
    "title": "Energy-efficient task allocation techniques for asymmetric multiprocessor embedded systems",
    "doi": "https://doi.org/10.1145/2544375.2544391",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Abdullah Elewi; Mohamed Shalan; Medhat Awadalla; E. M. Saad",
    "corresponding_authors": "",
    "abstract": "Asymmetric multiprocessor systems are considered power-efficient multiprocessor architectures. Furthermore, efficient task allocation (partitioning) can achieve more energy efficiency at these asymmetric multiprocessor platforms. This article addresses the problem of energy-aware static partitioning of periodic real-time tasks on asymmetric multiprocessor (multicore) embedded systems. The article formulates the problem according to the Dynamic Voltage and Frequency Scaling (DVFS) model supported by the platform and shows that it is an NP-hard problem. Then, the article outlines optimal reference partitioning techniques for each case of DVFS model with suitable assumptions. Finally, the article proposes modifications to the traditional bin-packing techniques and designs novel techniques taking into account the DVFS model supported by the platform. All algorithms and techniques are simulated and compared. The simulation shows promising results, where the proposed techniques reduced the energy consumption by 75% compared to traditional methods when DVFS is not supported and by 50% when per-core DVFS is supported by the platform.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2054274529",
    "type": "article"
  },
  {
    "title": "Video search and indexing with reinforcement agent for interactive multimedia services",
    "doi": "https://doi.org/10.1145/2423636.2423643",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Anand Paul; Bowei Chen; Karunanithi Bharanitharan; Jhing-Fa Wang",
    "corresponding_authors": "",
    "abstract": "In this study, we present a video search and indexing system based on the state support vector (SVM) network, video graph, and reinforcement agent for recognizing and organizing video events. In order to enhance the recognition performance of the state SVM network, two innovative techniques are presented: state transition correction and transition quality estimation. The classification results are also merged into the video indexing graph, which facilitates the search speed. A reinforcement algorithm with an efficient scheduling scheme significantly reduces both the power consumption and time. The experimental results show the proposed state SVM network was able to achieve a precision rate as high as 83.83% and the query results of the indexing graph reached 80% accuracy. The experiments also demonstrate the performance and feasibility of our system.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2062780934",
    "type": "article"
  },
  {
    "title": "A Novel Method for Online Detection of Faults Affecting Execution-Time in Multicore-Based Systems",
    "doi": "https://doi.org/10.1145/3063313",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Stefano Esposito; M. Violante; Marco Sozzi; Marco Terrone; Massimo Traversone",
    "corresponding_authors": "",
    "abstract": "This article proposes a bounded interference method, based on statistical evaluations, for online detection and tolerance of any fault capable of causing a deadline miss. The proposed method requires data that can be gathered during the profiling and worst-case execution time (WCET) analysis phase. This article describes the method, its application, and then it presents an avionic mixed-criticality use case for experimental evaluation, considering both dual-core and quad-core platforms. Results show that faults that can cause a timing violation are correctly identified while other faults that do not introduce a significant temporal interference can be tolerated to avoid high recovery overheads.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2612618018",
    "type": "article"
  },
  {
    "title": "Sequentially Constructive Concurrency—A Conservative Extension of the Synchronous Model of Computation",
    "doi": "https://doi.org/10.1145/2627350",
    "publication_date": "2014-07-01",
    "publication_year": 2014,
    "authors": "Reinhard von Hanxleden; Michael Mendler; Joaquín Aguado; Björn Duderstadt; Insa Fuhrmann; Christian Motika; Stephen Mercer; Owen O'Brien; Partha S. Roop",
    "corresponding_authors": "",
    "abstract": "Synchronous languages ensure determinate concurrency but at the price of restrictions on what programs are considered valid, or constructive . Meanwhile, sequential languages such as C and Java offer an intuitive, familiar programming paradigm but provide no guarantees with regard to determinate concurrency. The sequentially constructive (SC) model of computation (MoC) presented here harnesses the synchronous execution model to achieve determinate concurrency while taking advantage of familiar, convenient programming paradigms from sequential languages. In essence, the SC MoC extends the classical synchronous MoC by allowing variables to be read and written in any order and multiple times, as long as the sequentiality expressed in the program provides sufficient scheduling information to rule out race conditions. This allows to use programming patterns familiar from sequential programming, such as testing and later setting the value of a variable, which are forbidden in the standard synchronous MoC. The SC MoC is a conservative extension in that programs considered constructive in the common synchronous MoC are also SC and retain the same semantics. In this article, we investigate classes of shared variable accesses, define SC-admissible scheduling as a restriction of “free scheduling,” derive the concept of sequential constructiveness, and present a priority-based scheduling algorithm for analyzing and compiling SC programs efficiently.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2622045392",
    "type": "article"
  },
  {
    "title": "Achieving energy-synchronized communication in energy-harvesting wireless sensor networks",
    "doi": "https://doi.org/10.1145/2544375.2544388",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Yu Gu; Liang He; Ting Zhu; Tian He",
    "corresponding_authors": "",
    "abstract": "With advances in energy-harvesting techniques, it is now feasible to build sustainable sensor networks to support long-term applications. Unlike battery-powered sensor networks, the objective of sustainable sensor networks is to effectively utilize a continuous stream of ambient energy. Instead of pushing the limits of energy conservation, we aim to design energy-synchronized schemes that keep energy supplies and demands in balance. Specifically, this work presents Energy-Synchronized Communication (ESC) as a transparent middleware between the network layer and MAC layer that controls the amount and timing of RF activity at receiving nodes. In this work, we first derive a delay model for cross-traffic at individual nodes, which reveals an interesting stair effect . This effect allows us to design a localized energy synchronization control with ℴ( d 3 ) time complexity that shuffles or adjusts the working schedule of a node to optimize cross-traffic delays in the presence of changing duty cycle budgets, where d is the node degree in the network. Under different rates of energy fluctuations, shuffle-based and adjustment-based methods have different influences on logical connectivity and cross-traffic delay , due to the inconsistent views of working schedules among neighboring nodes before schedule updates. We study the trade-off between them and propose methods for updating working schedules efficiently. To evaluate our work, ESC is implemented on MicaZ nodes with two state-of-the-art routing protocols. Both testbed experiment and large-scale simulation results show significant performance improvements over randomized synchronization controls.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2072767657",
    "type": "article"
  },
  {
    "title": "Lightweight Architectures for Reliable and Fault Detection Simon and Speck Cryptographic Algorithms on FPGA",
    "doi": "https://doi.org/10.1145/3055514",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Prashant Ahir; Mehran Mozaffari Kermani; Reza Azarderakhsh",
    "corresponding_authors": "",
    "abstract": "The widespread use of sensitive and constrained applications necessitates lightweight (low-power and low-area) algorithms developed for constrained nano-devices. However, nearly all of such algorithms are optimized for platform-based performance and may not be useful for diverse and flexible applications. The National Security Agency (NSA) has proposed two relatively recent families of lightweight ciphers, that is, Simon and Speck, designed as efficient ciphers on both hardware and software platforms. This article proposes concurrent error detection schemes to provide reliable architectures for these two families of lightweight block ciphers. The research work on analyzing the reliability of these algorithms and providing fault diagnosis approaches has not been undertaken to date to the best of our knowledge. The main aim of the proposed reliable architectures is to provide high error coverage while maintaining acceptable area and power consumption overheads. To achieve this, we propose a variant of recomputing with encoded operands. These low-complexity schemes are suited for low-resource applications such as sensitive, constrained implantable and wearable medical devices. We perform fault simulations for the proposed architectures by developing a fault model framework. The architectures are simulated and analyzed on recent field-programmable grate array (FPGA) platforms, and it is shown that the proposed schemes provide high error coverage. The proposed low-complexity concurrent error detection schemes are a step forward toward more reliable architectures for Simon and Speck algorithms in lightweight, secure applications.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2560704708",
    "type": "article"
  },
  {
    "title": "Compiler-Directed Soft Error Detection and Recovery to Avoid DUE and SDC via Tail-DMR",
    "doi": "https://doi.org/10.1145/2930667",
    "publication_date": "2016-12-19",
    "publication_year": 2016,
    "authors": "Qingrui Liu; Changhee Jung; Dongyoon Lee; Devesh Tiwari",
    "corresponding_authors": "",
    "abstract": "This article presents Clover, a compiler-directed soft error detection and recovery scheme for lightweight soft error resilience. The compiler carefully generates soft-error-tolerant code based on idempotent processing without explicit checkpoints. During program execution, Clover relies on a small number of acoustic wave detectors deployed in the processor to identify soft errors by sensing the wave made by a particle strike. To cope with DUEs (detected unrecoverable errors) caused by the sensing latency of error detection, Clover leverages a novel selective instruction duplication technique called tail-DMR (dual modular redundancy) that provides a region-level error containment. Once a soft error is detected by either the sensors or the tail-DMR, Clover takes care of the error as in the case of exception handling. To recover from the error, Clover simply redirects program control to the beginning of the code region where the error is detected. The experimental results demonstrate that the average runtime overhead is only 26%, which is a 75% reduction compared to that of the state-of-the-art soft error resilience technique. In addition, this article evaluates an alternative technique called tail-wait, comparing it to Clover. According to the evaluation with the different processor configurations and the various error detection latencies, Clover turns out to be a superior technique, achieving 1.06 to 3.49 × speedup over the tail-wait.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2565180819",
    "type": "article"
  },
  {
    "title": "Is Your Bus Arbiter Really Fair? Restoring Fairness in AXI Interconnects for FPGA SoCs",
    "doi": "https://doi.org/10.1145/3358183",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Francesco Restuccia; Marco Pagani; Alessandro Biondi; Mauro Marinoni; Giorgio Buttazzo",
    "corresponding_authors": "",
    "abstract": "AMBA AXI is a popular bus protocol that is widely adopted as the medium to exchange data in field-programmable gate array system-on-chips (FPGA SoCs). The AXI protocol does not specify how conflicting transactions are arbitrated and hence the design of bus arbiters is left to the vendors that adopt AXI. Typically, a round-robin arbitration is implemented to ensure a fair access to the bus by the master nodes, as for the popular SoCs by Xilinx. This paper addresses a critical issue that can arise when adopting the AXI protocol under round-robin arbitration; specifically, in the presence of bus transactions with heterogeneous burst sizes. First, it is shown that a completely unfair bandwidth distribution can be achieved under some configurations, making possible to arbitrarily decrease the bus bandwidth of a target master node. This issue poses serious performance, safety, and security concerns. Second, a low-latency (one clock cycle) module named AXI burst equalizer (ABE) is proposed to restore fairness. Our investigations and proposals are supported by implementations and tests upon three modern SoCs. Experimental results are reported to confirm the existence of the issue and assess the effectiveness of the ABE with bus traffic generators and hardware accelerators from the Xilinx’s IP library.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W3000062206",
    "type": "article"
  },
  {
    "title": "STEAM",
    "doi": "https://doi.org/10.1145/2661430",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Vinay Hanumaiah; Digant Desai; Benjamin Gaudette; Carole-Jean Wu; Sarma Vrudhula",
    "corresponding_authors": "",
    "abstract": "Recent empirical studies have shown that multicore scaling is fast becoming power limited, and consequently, an increasing fraction of a multicore processor has to be under clocked or powered off. Therefore, in addition to fundamental innovations in architecture, compilers and parallelization of application programs, there is a need to develop practical and effective dynamic energy management (DEM) techniques for multicore processors. Existing DEM techniques mainly target reducing processor power consumption and temperature, and only few of them have addressed improving energy efficiency for multicore systems. With energy efficiency taking a center stage in all aspects of computing, the focus of the DEM needs to be on finding practical methods to maximize processor efficiency. Towards this, this article presents STEAM -- an optimal closed-loop DEM controller designed for multicore processors. The objective is to maximize energy efficiency by dynamic voltage and frequency scaling (DVFS). Energy efficiency is defined as the ratio of performance to power consumption or performance-per-watt (PPW). This is the same as the number of instructions executed per Joule. The PPW metric is actually replaced by P α PW (performance α -per-Watt), which allows for controlling the importance of performance versus power consumption by varying α. The proposed controller was implemented on a Linux system and tested with the Intel Sandy Bridge processor. There are three power management schemes called governors , available with Intel platforms. They are referred to as (1) Powersave (lowest power consumption), (2) Performance (achieves highest performance), and (3) Ondemand . Our simple and lightweight controller when executing SPEC CPU2006, PARSEC, and MiBench benchmarks have achieved an average of 18% improvement in energy efficiency (MIPS/Watt) over these ACPI policies. Moreover, STEAM also demonstrated an excellent prediction of core temperatures and power consumption, and the ability to control the core temperatures within 3 ˆ C of the specified maximum. Finally, the overhead of the STEAM implementation (in terms of CPU resources) is less than 0.25%. The entire implementation is self-contained and can be installed on any processor with very little prior knowledge of the processor.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2063373087",
    "type": "article"
  },
  {
    "title": "Antlab",
    "doi": "https://doi.org/10.1145/3126513",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Ivan Gavran; Rupak Majumdar; Indranil Saha",
    "corresponding_authors": "",
    "abstract": "We present Antlab, an end-to-end system that takes streams of user task requests and executes them using collections of robots. In Antlab, each request is specified declaratively in linear temporal logic extended with quantifiers over robots. The user does not program robots individually, nor know how many robots are available at any time or the precise state of the robots. The Antlab runtime system manages the set of robots, schedules robots to perform tasks, automatically synthesizes robot motion plans from the task specification, and manages the co-ordinated execution of the plan. We provide a constraint-based formulation for simultaneous task assignment and plan generation for multiple robots working together to satisfy a task specification. In order to scalably handle multiple concurrent tasks, we take a separation of concerns view to plan generation. First, we solve each planning problem in isolation, with an “ideal world” hypothesis that says there are no unspecified dynamic obstacles or adversarial environment actions. Second, to deal with imprecisions of the real world, we implement the plans in receding horizon fashion on top of a standard robot navigation stack. The motion planner dynamically detects environment actions or dynamic obstacles from the environment or from other robots and locally corrects the ideal planned path. It triggers a re-planning step dynamically if the current path deviates from the planned path or if planner assumptions are violated. We have implemented Antlab as a C++ and Python library on top of robots running on ROS, using SMT-based and AI planning-based implementations for task and path planning. We evaluated Antlab both in simulation as well as on a set of TurtleBot robots. We demonstrate that it can provide a scalable and robust infrastructure for declarative multi-robot programming.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2760578639",
    "type": "article"
  },
  {
    "title": "Graph-Based Modeling, Scheduling, and Verification for Intersection Management of Intelligent Vehicles",
    "doi": "https://doi.org/10.1145/3358221",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Yi‐Ting Lin; Hsiang Hsu; Shang-Chien Lin; Chung‐Wei Lin; Iris Hui-Ru Jiang; Changliu Liu",
    "corresponding_authors": "",
    "abstract": "Intersection management is one of the most representative applications of intelligent vehicles with connected and autonomous functions. The connectivity provides environmental information that a single vehicle cannot sense, and the autonomy supports precise vehicular control that a human driver cannot achieve. Intersection management solves the fundamental conflict resolution problem for vehicles—two vehicles should not appear at the same location at the same time, and, if they intend to do that, an order should be decided to optimize certain objectives such as the traffic throughput or smoothness. In this paper, we first propose a graph-based model for intersection management. The model is general and applicable to different granularities of intersections and other conflicting scenarios. We then derive formal verification approaches which can guarantee deadlock-freeness. Based on the graph-based model and the verification approaches, we develop a centralized cycle removal algorithm for the graph-based model to schedule vehicles to go through the intersection safely (without collisions) and efficiently without deadlocks. Experimental results demonstrate the expressiveness of the proposed model and the effectiveness and efficiency of the proposed algorithm.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2979999966",
    "type": "article"
  },
  {
    "title": "Design and Optimization of Energy-Accuracy Tradeoff Networks for Mobile Platforms via Pretrained Deep Models",
    "doi": "https://doi.org/10.1145/3366636",
    "publication_date": "2020-01-31",
    "publication_year": 2020,
    "authors": "Nitthilan Kannappan Jayakodi; Syrine Belakaria; Aryan Deshwal; Janardhan Rao Doppa",
    "corresponding_authors": "",
    "abstract": "Many real-world edge applications including object detection, robotics, and smart health are enabled by deploying deep neural networks (DNNs) on energy-constrained mobile platforms. In this article, we propose a novel approach to trade off energy and accuracy of inference at runtime using a design space called Learning Energy Accuracy Tradeoff Networks (LEANets). The key idea behind LEANets is to design classifiers of increasing complexity using pretrained DNNs to perform input-specific adaptive inference. The accuracy and energy consumption of the adaptive inference scheme depends on a set of thresholds, one for each classifier. To determine the set of threshold vectors to achieve different energy and accuracy tradeoffs, we propose a novel multiobjective optimization approach. We can select the appropriate threshold vector at runtime based on the desired tradeoff. We perform experiments on multiple pretrained DNNs including ConvNet, VGG-16, and MobileNet using diverse image classification datasets. Our results show that we get up to a 50% gain in energy for negligible loss in accuracy, and optimized LEANets achieve significantly better energy and accuracy tradeoff when compared to a state-of-the-art method referred to as Slimmable neural networks.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W3009906407",
    "type": "article"
  },
  {
    "title": "An Efficient Multidimensional Big Data Fusion Approach in Machine-to-Machine Communication",
    "doi": "https://doi.org/10.1145/2834118",
    "publication_date": "2016-06-07",
    "publication_year": 2016,
    "authors": "Awais Ahmad; Anand Paul; Mazhar Rathore; Hangbae Chang",
    "corresponding_authors": "",
    "abstract": "Machine-to-Machine communication (M2M) is nowadays increasingly becoming a world-wide network of interconnected devices uniquely addressable, via standard communication protocols. The prevalence of M2M is bound to generate a massive volume of heterogeneous, multisource, dynamic, and sparse data, which leads a system towards major computational challenges, such as, analysis, aggregation, and storage. Moreover, a critical problem arises to extract the useful information in an efficient manner from the massive volume of data. Hence, to govern an adequate quality of the analysis, diverse and capacious data needs to be aggregated and fused. Therefore, it is imperative to enhance the computational efficiency for fusing and analyzing the massive volume of data. Therefore, to address these issues, this article proposes an efficient, multidimensional, big data analytical architecture based on the fusion model. The basic concept implicates the division of magnitudes (attributes), i.e., big datasets with complex magnitudes can be altered into smaller data subsets using five levels of the fusion model that can be easily processed by the Hadoop Processing Server, resulting in formalizing the problem of feature extraction applications using earth observatory system, social networking, or networking applications. Moreover, a four-layered network architecture is also proposed that fulfills the basic requirements of the analytical architecture. The feasibility and efficiency of the proposed algorithms used in the fusion model are implemented on Hadoop single-node setup on UBUNTU 14.04 LTS core i5 machine with 3.2GHz processor and 4GB memory. The results show that the proposed system architecture efficiently extracts various features (such as land and sea) from the massive volume of satellite data.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2409687816",
    "type": "article"
  },
  {
    "title": "Hardware Performance Counter-Based Fine-Grained Malware Detection",
    "doi": "https://doi.org/10.1145/3403943",
    "publication_date": "2020-09-26",
    "publication_year": 2020,
    "authors": "Sai Praveen Kadiyala; Pranav Jadhav; Siew-Kei Lam; Thambipillai Srikanthan",
    "corresponding_authors": "",
    "abstract": "Detection of malicious programs using hardware-based features has gained prominence recently. The tamper-resistant hardware metrics prove to be a better security feature than the high-level software metrics, which can be easily obfuscated. Hardware Performance Counters (HPC), which are inbuilt in most of the recent processors, are often the choice of researchers amongst hardware metrics. However, a lack of determinism in their counts, thereby affecting the malware detection rate, minimizes the advantages of HPCs. To overcome this problem, in our work, we propose a three-step methodology for fine-grained malware detection. In the first step, we extract the HPCs of each system call of an unknown program. Later, we make a dimensionality reduction of the fine-grained data to identify the components that have maximum variance. Finally, we use a machine learning based approach to classify the nature of the unknown program into benign or malicious. Our proposed methodology has obtained a 98.4% detection rate, with a 3.1% false positive. It has improved the detection rate significantly when compared to other recent works in hardware-based anomaly detection.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W3087990352",
    "type": "article"
  },
  {
    "title": "Predictive Monitoring with Logic-Calibrated Uncertainty for Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3477032",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Meiyi Ma; John A. Stankovic; Ezio Bartocci; Lu Feng",
    "corresponding_authors": "",
    "abstract": "Predictive monitoring—making predictions about future states and monitoring if the predicted states satisfy requirements—offers a promising paradigm in supporting the decision making of Cyber-Physical Systems (CPS). Existing works of predictive monitoring mostly focus on monitoring individual predictions rather than sequential predictions. We develop a novel approach for monitoring sequential predictions generated from Bayesian Recurrent Neural Networks (RNNs) that can capture the inherent uncertainty in CPS, drawing on insights from our study of real-world CPS datasets. We propose a new logic named Signal Temporal Logic with Uncertainty (STL-U) to monitor a flowpipe containing an infinite set of uncertain sequences predicted by Bayesian RNNs. We define STL-U strong and weak satisfaction semantics based on whether all or some sequences contained in a flowpipe satisfy the requirement. We also develop methods to compute the range of confidence levels under which a flowpipe is guaranteed to strongly (weakly) satisfy an STL-U formula. Furthermore, we develop novel criteria that leverage STL-U monitoring results to calibrate the uncertainty estimation in Bayesian RNNs. Finally, we evaluate the proposed approach via experiments with real-world CPS datasets and a simulated smart city case study, which show very encouraging results of STL-U based predictive monitoring approach outperforming baselines.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W3201396315",
    "type": "article"
  },
  {
    "title": "LATTE: <u>L</u> STM Self- <u>Att</u> ention based Anomaly Detection in <u>E</u> mbedded Automotive Platforms",
    "doi": "https://doi.org/10.1145/3476998",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Vipin Kumar Kukkala; Sooryaa Vignesh Thiruloga; Sudeep Pasricha",
    "corresponding_authors": "",
    "abstract": "Modern vehicles can be thought of as complex distributed embedded systems that run a variety of automotive applications with real-time constraints. Recent advances in the automotive industry towards greater autonomy are driving vehicles to be increasingly connected with various external systems (e.g., roadside beacons, other vehicles), which makes emerging vehicles highly vulnerable to cyber-attacks. Additionally, the increased complexity of automotive applications and the in-vehicle networks results in poor attack visibility, which makes detecting such attacks particularly challenging in automotive systems. In this work, we present a novel anomaly detection framework called LATTE to detect cyber-attacks in Controller Area Network (CAN) based networks within automotive platforms. Our proposed LATTE framework uses a stacked Long Short Term Memory (LSTM) predictor network with novel attention mechanisms to learn the normal operating behavior at design time. Subsequently, a novel detection scheme (also trained at design time) is used to detect various cyber-attacks (as anomalies) at runtime. We evaluate our proposed LATTE framework under different automotive attack scenarios and present a detailed comparison with the best-known prior works in this area, to demonstrate the potential of our approach.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3199976315",
    "type": "article"
  },
  {
    "title": "Improving Power of DSP and CNN Hardware Accelerators Using Approximate Floating-point Multipliers",
    "doi": "https://doi.org/10.1145/3448980",
    "publication_date": "2021-07-09",
    "publication_year": 2021,
    "authors": "Vasileios Leon; Theodora Paparouni; Evangelos Petrongonas; Dimitrios Soudris; Kiamal Pekmestzi",
    "corresponding_authors": "",
    "abstract": "Approximate computing has emerged as a promising design alternative for delivering power-efficient systems and circuits by exploiting the inherent error resiliency of numerous applications. The current article aims to tackle the increased hardware cost of floating-point multiplication units, which prohibits their usage in embedded computing. We introduce AFMU (Approximate Floating-point MUltiplier), an area/power-efficient family of multipliers, which apply two approximation techniques in the resource-hungry mantissa multiplication and can be seamlessly extended to support dynamic configuration of the approximation levels via gating signals. AFMU offers large accuracy configuration margins, provides negligible logic overhead for dynamic configuration, and detects unexpected results that may arise due to the approximations. Our evaluation shows that AFMU delivers energy gains in the range 3.6%–53.5% for half-precision and 37.2%–82.4% for single-precision, in exchange for mean relative error around 0.05%–3.33% and 0.01%–2.20%, respectively. In comparison with state-of-the-art multipliers, AFMU exhibits up to 4–6× smaller error on average while delivering more energy-efficient computing. The evaluation in image processing shows that AFMU provides sufficient quality of service, i.e., more than 50 db PSNR and near 1 SSIM values, and up to 57.4% power reduction. When used in floating-point CNNs, the accuracy loss is small (or zero), i.e., up to 5.4% for MNIST and CIFAR-10, in exchange for up to 63.8% power gain.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3178289424",
    "type": "article"
  },
  {
    "title": "<i>SLAQA</i>",
    "doi": "https://doi.org/10.1145/3462776",
    "publication_date": "2021-07-09",
    "publication_year": 2021,
    "authors": "Sanjit Kumar Roy; Rajesh Devaraj; Arnab Sarkar; Debabrata Senapati",
    "corresponding_authors": "",
    "abstract": "Continuous demands for higher performance and reliability within stringent resource budgets is driving a shift from homogeneous to heterogeneous processing platforms for the implementation of today’s cyber-physical systems (CPSs). These CPSs are typically represented as Directed-acyclic Task Graph (DTG) due to the complex interactions between their functional components that are often distributed in nature. In this article, we consider the problem of scheduling a real-time application modelled as a single DTG, where tasks may have multiple implementations designated as quality-levels, with higher quality-levels producing more accurate results and contributing to higher rewards/Quality-of-Service for the system. First, we introduce an optimal solution using Integer Linear Programming (ILP) for a DTG with multiple quality-levels, to be executed on a heterogeneous distributed platform . However, this ILP-based optimal solution exhibits high computational complexity and does not scale for moderately large problem sizes. Hence, we propose two low-overhead heuristic algorithms called Global Slack Aware Quality-level Allocator ( G-SLAQA ) and Total Slack Aware Quality-level Allocator ( T-SLAQA ), which are able to produce satisfactorily efficient as well as fast solutions within a reasonable time. G-SLAQA , the baseline heuristic, is greedier and faster than its counter-part T-SLAQA , whose performance is at least as efficient as G-SLAQA . The efficiency of all the proposed schemes have been extensively evaluated through simulation-based experiments using benchmark and randomly generated DTGs. Through the case study of a real-world automotive traction controller , we generate schedules using our proposed schemes to demonstrate their practical applicability.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3180896571",
    "type": "article"
  },
  {
    "title": "Compositional Learning and Verification of Neural Network Controllers",
    "doi": "https://doi.org/10.1145/3477023",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Radoslav Ivanov; Kishor Jothimurugan; Steve Hsu; Shaan Vaidya; Rajeev Alur; Osbert Bastani",
    "corresponding_authors": "",
    "abstract": "Recent advances in deep learning have enabled data-driven controller design for autonomous systems. However, verifying safety of such controllers, which are often hard-to-analyze neural networks, remains a challenge. Inspired by compositional strategies for program verification, we propose a framework for compositional learning and verification of neural network controllers. Our approach is to decompose the task (e.g., car navigation) into a sequence of subtasks (e.g., segments of the track), each corresponding to a different mode of the system (e.g., go straight or turn). Then, we learn a separate controller for each mode, and verify correctness by proving that (i) each controller is correct within its mode, and (ii) transitions between modes are correct. This compositional strategy not only improves scalability of both learning and verification, but also enables our approach to verify correctness for arbitrary compositions of the subtasks. To handle partial observability (e.g., LiDAR), we additionally learn and verify a mode predictor that predicts which controller to use. Finally, our framework also incorporates an algorithm that, given a set of controllers, automatically synthesizes the pre- and postconditions required by our verification procedure. We validate our approach in a case study on a simulation model of the F1/10 autonomous car, a system that poses challenges for existing verification tools due to both its reliance on LiDAR observations, as well as the need to prove safety for complex track geometries. We leverage our framework to learn and verify a controller that safely completes any track consisting of an arbitrary sequence of five kinds of track segments.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3201037672",
    "type": "article"
  },
  {
    "title": "SNR: <u>S</u> queezing <u>N</u> umerical <u>R</u> ange Defuses Bit Error Vulnerability Surface in Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3477007",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Elbruz Ozen; Alex Orailoğlu",
    "corresponding_authors": "",
    "abstract": "As deep learning algorithms are widely adopted, an increasing number of them are positioned in embedded application domains with strict reliability constraints. The expenditure of significant resources to satisfy performance requirements in deep neural network accelerators has thinned out the margins for delivering safety in embedded deep learning applications, thus precluding the adoption of conventional fault tolerance methods. The potential of exploiting the inherent resilience characteristics of deep neural networks remains though unexplored, offering a promising low-cost path towards safety in embedded deep learning applications. This work demonstrates the possibility of such exploitation by juxtaposing the reduction of the vulnerability surface through the proper design of the quantization schemes with shaping the parameter distributions at each layer through the guidance offered by appropriate training methods, thus delivering deep neural networks of high resilience merely through algorithmic modifications. Unequaled error resilience characteristics can be thus injected into safety-critical deep learning applications to tolerate bit error rates of up to <?TeX $10\\%$?> at absolutely zero hardware, energy, and performance costs while improving the error-free model accuracy even further.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3201365832",
    "type": "article"
  },
  {
    "title": "Accelerating Attention Mechanism on FPGAs based on Efficient Reconfigurable Systolic Array",
    "doi": "https://doi.org/10.1145/3549937",
    "publication_date": "2022-07-20",
    "publication_year": 2022,
    "authors": "Wenhua Ye; Xu Zhou; Joey Tianyi Zhou; Cen Chen; Kenli Li",
    "corresponding_authors": "",
    "abstract": "Transformer model architectures have recently received great interest in natural language, machine translation, and computer vision, where attention mechanisms are their building blocks. However, the attention mechanism is expensive because of its intensive matrix computations and complicated data flow. The existing hardware architecture has some disadvantages for the computing structure of attention, such as inflexibility and low efficiency. Most of the existing papers accelerate attention by reducing the amount of computation through various pruning algorithms, which will affect the results to a certain extent with different sparsity. This paper proposes the hardware accelerator for the multi-head attention (MHA) on field-programmable gate arrays (FPGAs) with reconfigurable architecture, efficient systolic array, and hardware-friendly radix-2 softmax. We propose a novel method called Four inputs Processing Element (FPE) to double the computation rate of the data-aware systolic array (SA) and make it efficient and load balance. Especially, the computation framework is well designed to ensure the utilization of SA efficiently. Our design is evaluated on a Xilinx Alveo U250 card, and the proposed architecture achieves 51.3×, 17.3× improvement in latency, and 54.4×, 17.9× energy savings compared to CPU and GPU.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4286001027",
    "type": "article"
  },
  {
    "title": "Virtualizing a Post-Moore’s Law Analog Mesh Processor: The Case of a Photonic PDE Accelerator",
    "doi": "https://doi.org/10.1145/3544971",
    "publication_date": "2022-06-22",
    "publication_year": 2022,
    "authors": "Jeff Anderson; Engin Kayraklioglu; Hamid Reza Imani; Chen Shen; Mario Miscuglio; Volker J. Sorger; Tarek El‐Ghazawi",
    "corresponding_authors": "",
    "abstract": "Innovative processor architectures aim to play a critical role in future sustainment of performance improvements under severe limitations imposed by the end of Moore’s Law. The Reconfigurable Optical Computer (ROC) is one such innovative, Post-Moore’s Law processor. ROC is designed to solve partial differential equations in one shot as opposed to existing solutions, which are based on costly iterative computations. This is achieved by leveraging physical properties of a mesh of optical components that behave analogously to lumped electrical components. However, virtualization is required to combat shortfalls of the accelerator hardware. Namely, (1) the infeasibility of building large photonic arrays to accommodate arbitrarily large problems and (2) underutilization brought about by mismatches in problem and accelerator mesh sizes due to future advances in manufacturing technology. In this work, we introduce an architecture and methodology for lightweight virtualization of ROC that exploits advantages borne from optical computing technology. Specifically, we apply temporal and spatial virtualization to ROC and then extend the accelerator scheduling tradespace with the introduction of spectral virtualization. Additionally, we investigate multiple resource scheduling strategies for a system-on-chip (SoC)-based PDE acceleration architecture and show that virtual configuration management offers a speedup of approximately 2×. Finally, we show that overhead from virtualization is minimal, and our experimental results show two orders of magnitude increased speed as compared to microprocessor execution while keeping errors due to virtualization under 10%.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4283318450",
    "type": "article"
  },
  {
    "title": "Compositional Timing Analysis of Asynchronized Distributed Cause-effect Chains",
    "doi": "https://doi.org/10.1145/3587036",
    "publication_date": "2023-03-09",
    "publication_year": 2023,
    "authors": "Mario Günzel; Kuan-Hsun Chen; Niklas Ueter; Georg von der Brüggen; Marco Dürr; Jian-Jia Chen",
    "corresponding_authors": "",
    "abstract": "Real-time systems require the formal guarantee of timing constraints, not only for the individual tasks but also for the end-to-end latency of data flows. The data flow among multiple tasks, e.g., from sensors to actuators, is described by a cause-effect chain, independent from the priority order of the tasks. In this article, we provide an end-to-end timing-analysis for cause-effect chains on asynchronized distributed systems with periodic task activations, considering the maximum reaction time (MRT) (i.e., the duration of data processing) and the maximum data age (MDA) (i.e., the worst-case data freshness). We first provide an analysis of the end-to-end latency on one local electronic control unit (ECU) that has to consider only the jobs in a bounded time interval. We extend our analysis to globally asynchronized systems by exploiting a compositional property to combine the local results. Throughout synthesized data based on an automotive benchmark as well as on randomized parameters, we show that our analytical results improve the state-of-the-art.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4323662986",
    "type": "article"
  },
  {
    "title": "Enhancing the Energy Efficiency and Robustness of tinyML Computer Vision Using Coarsely-quantized Log-gradient Input Images",
    "doi": "https://doi.org/10.1145/3591466",
    "publication_date": "2023-04-08",
    "publication_year": 2023,
    "authors": "Qianyun Lu; Boris Murmann",
    "corresponding_authors": "",
    "abstract": "This article studies the merits of applying log-gradient input images to convolutional neural networks (CNNs) for tinyML computer vision (CV). We show that log gradients enable: (i) aggressive 1-bit quantization of first-layer inputs, (ii) potential CNN resource reductions, (iii) inherent insensitivity to illumination changes (1.7% accuracy loss across 2 -5 … 2 3 brightness variation vs. up to 10% for JPEG), and (iv) robustness to adversarial attacks (&gt;10% higher accuracy than JPEG-trained models). We establish these results using the PASCAL RAW image dataset and through a combination of experiments using quantization threshold search, neural architecture search, and a fixed three-layer network. The latter reveals that training on log-gradient images leads to higher filter similarity, making the CNN more prunable. The combined benefits of aggressive first-layer quantization, CNN resource reductions, and operation without tight exposure control and image signal processing (ISP) are helpful for pushing tinyML CV toward its ultimate efficiency limits.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4362720607",
    "type": "article"
  },
  {
    "title": "TinyNS: Platform-aware Neurosymbolic Auto Tiny Machine Learning",
    "doi": "https://doi.org/10.1145/3603171",
    "publication_date": "2023-05-31",
    "publication_year": 2023,
    "authors": "Swapnil Sayan Saha; Sandeep Singh Sandha; Mohit Aggarwal; Brian Wang; Liying Han; Julian de Gortari Briseno; Mani Srivastava",
    "corresponding_authors": "",
    "abstract": "Machine learning at the extreme edge has enabled a plethora of intelligent, time-critical, and remote applications. However, deploying interpretable artificial intelligence systems that can perform high-level symbolic reasoning and satisfy the underlying system rules and physics within the tight platform resource constraints is challenging. In this paper, we introduce TinyNS, the first platform-aware neurosymbolic architecture search framework for joint optimization of symbolic and neural operators. TinyNS provides recipes and parsers to automatically write microcontroller code for five types of neurosymbolic models, combining the context awareness and integrity of symbolic techniques with the robustness and performance of machine learning models. TinyNS uses a fast, gradient-free, black-box Bayesian optimizer over discontinuous, conditional, numeric, and categorical search spaces to find the best synergy of symbolic code and neural networks within the hardware resource budget. To guarantee deployability, TinyNS talks to the target hardware during the optimization process. We showcase the utility of TinyNS by deploying microcontroller-class neurosymbolic models through several case studies. In all use cases, TinyNS outperforms purely neural or purely symbolic approaches while guaranteeing execution on real hardware.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4378830682",
    "type": "article"
  },
  {
    "title": "SensorGAN: A Novel Data Recovery Approach for Wearable Human Activity Recognition",
    "doi": "https://doi.org/10.1145/3609425",
    "publication_date": "2023-07-14",
    "publication_year": 2023,
    "authors": "Dina Hussein; Ganapati Bhat",
    "corresponding_authors": "",
    "abstract": "Human activity recognition (HAR) and, more broadly, activities of daily life recognition using wearable devices have the potential to transform a number of applications, including mobile healthcare, smart homes, and fitness monitoring. Recent approaches for HAR use multiple sensors on various locations on the body to achieve higher accuracy for complex activities. While multiple sensors increase the accuracy, they are also susceptible to reliability issues when one or more sensors are unable to provide data to the application due to sensor malfunction, user error, or energy limitations. Training multiple activity classifiers that use a subset of sensors is not desirable, since it may lead to reduced accuracy for applications. To handle these limitations, we propose a novel generative approach that recovers the missing data of sensors using data available from other sensors. The recovered data are then used to seamlessly classify activities. Experiments using three publicly available activity datasets show that with data missing from one sensor, the proposed approach achieves accuracy that is within 10% of the accuracy with no missing data. Moreover, implementation on a wearable device prototype shows that the proposed approach takes about 1.5 ms for recovering data in the w-HAR dataset, which results in an energy consumption of 606 μJ. The low-energy consumption ensures that SensorGAN is suitable for effectively recovering data in tinyML applications on energy-constrained devices.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4384339401",
    "type": "article"
  },
  {
    "title": "Consistency vs. Availability in Distributed Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3609119",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Edward A. Lee; Ravi Akella; Soroush Bateni; Shaokai Lin; Marten Lohstroh; Christian Menard",
    "corresponding_authors": "",
    "abstract": "In distributed applications, Brewer’s CAP theorem tells us that when networks become partitioned (P), one must give up either consistency (C) or availability (A). Consistency is agreement on the values of shared variables; availability is the ability to respond to reads and writes accessing those shared variables. Availability is a real-time property whereas consistency is a logical property. We extend consistency and availability to refer to cyber-physical properties such as the state of the physical system and delays in actuation. We have further extended the CAP theorem to relate quantitative measures of these two properties to quantitative measures of communication and computation latency (L), obtaining a relation called the CAL theorem that is linear in a max-plus algebra. This paper shows how to use the CAL theorem in various ways to help design cyber-physical systems. We develop a methodology for systematically trading off availability and consistency in application-specific ways and to guide the system designer when putting functionality in end devices, in edge computers, or in the cloud. We build on the Lingua Franca coordination language to provide system designers with concrete analysis and design tools to make the required tradeoffs in deployable embedded software.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4386579499",
    "type": "article"
  },
  {
    "title": "SG-Float: Achieving Memory Access and Computing Power Reduction Using Self-Gating Float in CNNs",
    "doi": "https://doi.org/10.1145/3624582",
    "publication_date": "2023-09-26",
    "publication_year": 2023,
    "authors": "Jun-Shen Wu; T. I. Hsu; Ren-Shuo Liu",
    "corresponding_authors": "",
    "abstract": "Convolutional neural networks (CNNs) are essential for advancing the field of artificial intelligence. However, since these networks are highly demanding in terms of memory and computation, implementing CNNs can be challenging. To make CNNs more accessible to energy-constrained devices, researchers are exploring new algorithmic techniques and hardware designs that can reduce memory and computation requirements. In this work, we present self-gating float (SG-Float), algorithm hardware co-design of a novel binary number format, which can significantly reduce memory access and computing power requirements in CNNs. SG-Float is a self-gating format that uses the exponent to self-gate the mantissa to zero, exploiting the characteristic of floating-point that the exponent determines the magnitude of a floating-point value and the error tolerance property of CNNs. SG-Float represents relatively small values using only the exponent, which increases the proportion of ineffective mantissas, corresponding to reducing mantissa multiplications of floating-point numbers. To minimize the accuracy loss caused by the approximation error introduced by SG-Float, we propose a fine-tuning process to determine the exponent thresholds of SG-Float and reclaim the accuracy loss. We also develop a hardware optimization technique, called the SG-Float buffering strategy, to best match SG-Float with CNN accelerators and further reduce memory access. We apply the SG-Float buffering strategy to vector-vector multiplication processing elements (PEs), which NVDLA adopts, in TSMC 40nm technology. Our evaluation results demonstrate that SG-Float can achieve up to 35% reduction in memory access power and up to 54% reduction in computing power compared with AdaptivFloat, a state-of-the-art format, with negligible power and area overhead. Additionally, we show that SG-Float can be combined with neural network pruning methods to further reduce memory access and mantissa multiplications in pruned CNN models. Overall, our work shows that SG-Float is a promising solution to the problem of CNN memory access and computing power.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4387059120",
    "type": "article"
  },
  {
    "title": "Multi-Compression Scale DNN Inference Acceleration based on Cloud-Edge-End Collaboration",
    "doi": "https://doi.org/10.1145/3634704",
    "publication_date": "2023-11-28",
    "publication_year": 2023,
    "authors": "Huamei Qi; Fang Ren; Leilei Wang; Ping Jiang; Shaohua Wan; Xiaoheng Deng",
    "corresponding_authors": "",
    "abstract": "Edge intelligence has emerged as a promising paradigm to accelerate DNN inference by model partitioning, which is particularly useful for intelligent scenarios that demand high accuracy and low latency. However, the dynamic nature of the edge environment and the diversity of end devices pose a significant challenge for DNN model partitioning strategies. Meanwhile, limited resources of the edge server make it difficult to manage resource allocation efficiently among multiple devices. In addition, most of the existing studies disregard the different service requirements of the DNN inference tasks, such as its high accuracy-sensitive or high latency-sensitive. To address these challenges, we propose a Multi-Compression Scale DNN Inference Acceleration (MCIA) based on cloud-edge-end collaboration. We model this problem as a mixed-integer multi-dimensional optimization problem, jointly optimizing the DNN model version choice, the partitioning choice, and the allocation of computational and bandwidth resources to maximize the tradeoff between inference accuracy and latency depending on the property of the tasks. Initially, we train multiple versions of DNN inference models with different compression scales in the cloud, and deploy them to end devices and edge server. Next, a deep reinforcement learning-based algorithm is developed for joint decision making of adaptive collaborative inference and resource allocation based on the current multi-compression scale models and the task property. Experimental results show that MCIA can adapt to heterogeneous devices and dynamic networks, and has superior performance compared with other methods.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4389098960",
    "type": "article"
  },
  {
    "title": "Array recovery and high-level transformations for DSP applications",
    "doi": "https://doi.org/10.1145/643470.643472",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Björn Franke; Michael O’Boyle",
    "corresponding_authors": "",
    "abstract": "Efficient implementation of DSP applications is critical for many embedded systems. Optimizing compilers for application programs, written in C, largely focus on code generation and scheduling, which, with their growing maturity, are providing diminishing returns. As DSP applications typically make extensive use of pointer arithmetic, the alternative use of high-level, source-to-source, transformations has been largely ignored. This article develops an array recovery technique that automatically converts pointers to arrays, enabling the empirical evaluation of high-level transformations. High-level techniques were applied to the DSPstone benchmarks on three platforms: TriMedia TM-1000, Texas Instruments TMS320C6201, and the Analog Devices SHARC ADSP-21160. On average, the best transformation gave a factor of 2.43 improvement across the platforms. In certain cases, a speedup of 5.48 was found for the SHARC, 7.38 for the TM-1, and 2.3 for the C6201. These preliminary results justify pointer to array conversion and further investigation into the use of high-level techniques for embedded compilers.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2052356107",
    "type": "article"
  },
  {
    "title": "Energy-aware design of embedded memories",
    "doi": "https://doi.org/10.1145/605459.605461",
    "publication_date": "2003-02-01",
    "publication_year": 2003,
    "authors": "Luca Benini; Alberto Macii; Massimo Poncino",
    "corresponding_authors": "",
    "abstract": "Embedded systems are often designed under stringent energy consumption budgets, to limit heat generation and battery size. Since memory systems consume a significant amount of energy to store and to forward data, it is then imperative to balance power consumption and performance in memory system design. Contemporary system design focuses on the trade-off between performance and energy consumption in processing and storage units, as well as in their interconnections. Although memory design is as important as processor design in achieving the desired design objectives, the former topic has received less attention than the latter in the literature. This article centers on one of the most outstanding problems in chip design for embedded applications. It guides the reader through different memory technologies and architectures, and it reviews the most successful strategies for optimizing them in the power/performance plane.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2067184490",
    "type": "article"
  },
  {
    "title": "Energy macromodeling of embedded operating systems",
    "doi": "https://doi.org/10.1145/1053271.1053281",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "T. K. Tan; Anand Raghunathan; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "As embedded systems get more complex, deployment of embedded operating systems (OSs) as software run-time engines has become common. In particular, this trend is true even for battery-powered embedded systems, where maximizing battery life is a primary concern. In such OS-driven embedded software, the overall energy consumption depends very much on which OS is used and how the OS is used. Therefore, the energy effects of the OS need to be studied in order to design low-energy systems effectively.In this paper, we discuss the motivation for performing OS energy characterization and propose a methodology to perform the characterization systematically. The methodology consists of two parts. The first part is analysis , which is concerned with identifying a set of components that can be used to characterize the OS energy consumption, called energy characteristics . The second part is macromodeling , which is concerned with obtaining quantitative macromodels for the energy characteristics. It involves the process of experiment design, data collection, and macromodel fitting. The OS energy macromodels can be used conveniently as OS energy estimators in high-level or architectural optimization of embedded systems for low-energy consumption.As far as we know, this work is the first attempt to systematically tackle energy macromodeling of an embedded OS. To demonstrate our approach, we present experimental results for two well-known embedded OSs, namely, μC/OS and embedded Linux OS.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W1965649880",
    "type": "article"
  },
  {
    "title": "Energy efficient wireless packet scheduling and fair queuing",
    "doi": "https://doi.org/10.1145/972627.972629",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Vijay Raghunathan; Saurabh Ganeriwal; Mani Srivastava; Curt Schurgers",
    "corresponding_authors": "",
    "abstract": "As embedded systems are being networked, often wirelessly, an increasingly larger share of their total energy budget is due to the communication. This necessitates the development of power management techniques that address communication subsystems, such as radios, as opposed to computation subsystems, such as embedded processors, to which most of the research effort thus far has been devoted. In this paper, we present techniques for energy efficient packet scheduling and fair queuing in wireless communication systems. Our techniques are based on an extensive slack management approach that dynamically adapts the output rate of the system in accordance with the input packet arrival rate. We use a recently proposed radio power management technique, dynamic modulation scaling (DMS), as a control knob to enable energy-latency trade-offs during wireless packet transmission. We first analyze a single input stream scenario, and describe a rate adaptation technique that results in significantly lower energy consumption (reductions of up to 10 ×), while still bounding the resulting packet delays. By appropriately setting the various parameters of our algorithm, the system can be made to traverse the energy-latency-fidelity trade-off space. We extend our techniques to a multiple input stream scenario, and present E 2 WFQ , an energy efficient version of the weighted fair queuing (WFQ) algorithm for fair packet scheduling. Simulation results show that large energy savings can be obtained through the use of E 2 WFQ , with only a small, bounded increase in worst case packet latency. Further, our results demonstrate that E 2 WFQ does not adversely affect the throughput allocation (and hence, fairness) of WFQ.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2037871282",
    "type": "article"
  },
  {
    "title": "An optimal algorithm for minimizing run-time reconfiguration delay",
    "doi": "https://doi.org/10.1145/993396.993398",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Soheil Ghiasi; Ani Nahapetian; Majid Sarrafzadeh",
    "corresponding_authors": "",
    "abstract": "Reconfiguration delay is one of the major barriers in the way of dynamically adapting a system to its application requirements. The run-time reconfiguration delay is quite comparable to the application latency for many classes of applications and might even dominate the application run-time. In this paper, we present an efficient optimal algorithm for minimizing the run-time reconfiguration (context switching) delay of executing an application on a dynamically adaptable system. The system is composed of a number of cameras with embedded reconfigurable resources collaborating in order to track an object. The operations required to execute in order to track the object are revealed to the system at run-time and can change according to a number of parameters, such as the target shape and proximity. Similarly, we can assume that the applications comprising tasks are already scheduled and each of them has to be realized on the reconfigurable fabric in order to be executed.The modeling and the algorithm are both applicable to partially reconfigurable platforms as well as multi-FPGA systems. The algorithm can be directly applied to minimize the application run-time for the typical classes of applications, where the actual execution delay of the basic operations is negligible compared to the reconfiguration delay. We prove the optimality and the efficiency of our algorithm. We report the experimental results, which demonstrate a 2.5--40% improvement on the total run-time reconfiguration delay as compared to other heuristics.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2079308193",
    "type": "article"
  },
  {
    "title": "SAFE-OPS: An approach to embedded software security",
    "doi": "https://doi.org/10.1145/1053271.1053279",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Joseph Zambreno; Alok Choudhary; Rahul Simha; Bhagi Narahari; Nasir Memon",
    "corresponding_authors": "",
    "abstract": "The new-found ubiquity of embedded processors in consumer and industrial applications brings with it an intensified focus on security, as a strong level of trust in the system software is crucial to their widespread deployment. The growing area of software protection attempts to address the key steps used by hackers in attacking a software system. In this paper, we introduce a unique approach to embedded software protection that utilizes a hardware/software codesign methodology. Results demonstrate that this framework can be the successful basis for the development of embedded applications that meet a wide range of security and performance requirements.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W1964173930",
    "type": "article"
  },
  {
    "title": "Cache coherence tradeoffs in shared-memory MPSoCs",
    "doi": "https://doi.org/10.1145/1151074.1151081",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Mirko Loghi; Massimo Poncino; Luca Benini",
    "corresponding_authors": "",
    "abstract": "Shared memory is a common interprocessor communication paradigm for single-chip multiprocessor platforms. Snoop-based cache coherence is a very successful technique that provides a clean shared-memory programming abstraction in general-purpose chip multiprocessors, but there is no consensus on its usage in resource-constrained multiprocessor systems on chips (MPSoCs) for embedded applications. This work aims at providing a comparative energy and performance analysis of cache-coherence support schemes in MPSoCs. Thanks to the use of a complete multiprocessor simulation platform, which relies on accurate technology-homogeneous power models, we were able to explore different cache-coherent shared-memory communication schemes for a number of cache configurations and workloads.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2079555365",
    "type": "article"
  },
  {
    "title": "Semantics-preserving multitask implementation of synchronous programs",
    "doi": "https://doi.org/10.1145/1331331.1331339",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Paul Caspi; Norman Scaife; Christos Sofronis; Stavros Tripakis",
    "corresponding_authors": "",
    "abstract": "We study the implementation of a synchronous program as a set of multiple tasks running on the same computer, and scheduled by a real-time operating system using some preemptive scheduling policy, such as fixed priority or earliest-deadline first. Multitask implementations are necessary, for instance, in multiperiodic applications, when the worst-case execution time of the program is larger than its smallest period. In this case, a single-task implementation violates the schedulability assumption and, therefore, the synchrony hypothesis does not hold. We are aiming at semantics-preserving implementations, where, for a given input sequence, the output sequence produced by the implementation is the same as that produced by the original synchronous program, and this under all possible executions of the implementation. Straightforward implementation techniques are not semantics-preserving. We present an intertask communication protocol, called DBP, that is semantics-preserving and memory-optimal. DBP guarantees semantical preservation under all possible triggering patterns of the synchronous program: thus, it is applicable not only to time-, but also event-triggered applications. DBP works under both fixed priority and earliest-deadline first scheduling. DBP is a nonblocking protocol based on the use of intermediate buffers and manipulations of write-to/read-from pointers to these buffers: these manipulations happen upon arrivals, rather than executions of tasks, which is a distinguishing feature of DBP. DBP is memory-optimal in the sense that it uses as few buffers as needed, for any given triggering pattern. In the worst case, DBP requires, at most, N + 2 buffers for each writer, where N is the number of readers for this writer.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W1978672105",
    "type": "article"
  },
  {
    "title": "Causality interfaces for actor networks",
    "doi": "https://doi.org/10.1145/1347375.1347382",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Ye Zhou; Edward A. Lee",
    "corresponding_authors": "",
    "abstract": "We consider concurrent models of computation where “actors” (components that are in charge of their own actions) communicate by exchanging messages. The interfaces of actors principally consist of “ports,” which mediate the exchange of messages. Actor-oriented architectures contrast with and complement object-oriented models by emphasizing the exchange of data between concurrent components rather than transformation of state. Examples of such models of computation include the classical actor model, synchronous languages, data-flow models, process networks, and discrete-event models. Many experimental and production languages used to design embedded systems are actor oriented and based on one of these models of computation. Many of these models of computation benefit considerably from having access to causality information about the components. This paper augments the interfaces of such components to include such causality information. It shows how this causality information can be algebraically composed so that compositions of components acquire causality interfaces that are inferred from their components and the interconnections. We illustrate the use of these causality interfaces to statically analyze timed models and synchronous language compositions for causality loops and data-flow models for deadlock. We also show that that causality analysis for each communication cycle can be performed independently and in parallel, and it is only necessary to analyze one port for each cycle. Finally, we give a conservative approximation technique for handling dynamically changing causality properties.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2076218697",
    "type": "article"
  },
  {
    "title": "Composing heterogeneous reactive systems",
    "doi": "https://doi.org/10.1145/1376804.1376811",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Albert Benveniste; Benoı̂t Caillaud; Luca P. Carloni; Paul Caspi; Alberto Sangiovanni‐Vincentelli",
    "corresponding_authors": "",
    "abstract": "We present a compositional theory of heterogeneous reactive systems. The approach is based on the concept of tags marking the events of the signals of a system. Tags can be used for multiple purposes from indexing evolution in time (time stamping) to expressing relations among signals, like coordination (e.g., synchrony and asynchrony) and causal dependencies. The theory provides flexibility in system modeling because it can be used both as a unifying mathematical framework to relate heterogeneous models of computations and as a formal vehicle to implement complex systems by combining heterogeneous components. In particular, we introduce an algebra of tag structures to define heterogeneous parallel composition formally. Morphisms between tag structures are used to define relationships between heterogeneous models at different levels of abstraction. In particular, they can be used to represent design transformations from tightly synchronized specifications to loosely-synchronized implementations. The theory has an important application in the correct-by-construction deployment of synchronous design on distributed architectures.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2007527439",
    "type": "article"
  },
  {
    "title": "Deep network packet filter design for reconfigurable devices",
    "doi": "https://doi.org/10.1145/1331331.1331345",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Young H. Cho; William H. Mangione-Smith",
    "corresponding_authors": "",
    "abstract": "Most network routers and switches provide some protection against the network attacks. However, the rapidly increasing amount of damages reported over the past few years indicates the urgent need for tougher security. Deep-packet inspection is one of the solutions to capture packets that can not be identified using the traditional methods. It uses a list of signatures to scan the entire content of the packet, providing the means to filter harmful packets out of the network. Since one signature does not depend on the other, the filtering process has a high degree of parallelism. Most software and hardware deep-packet filters that are in use today execute the tasks under Von Neuman architecture. Such architecture can not fully take advantage of the parallelism. For instance, one of the most widely used network intrusion-detection systems, Snort, configured with 845 patterns, running on a dual 1-GHz Pentium III system, can sustain a throughput of only 50 Mbps. The poor performance is because of the fact that the processor is programmed to execute several tasks sequentially instead of simultaneously. We designed scalable deep-packet filters on field-programmable gate arrays (FPGAs) to search for all data-independent patterns simultaneously. With FPGAs, we have the ability to reprogram the filter when there are any changes to the signature set. The smallest full-pattern matcher implementation for the latest Snort NIDS fits in a single 400k Xilinx FPGA (Spartan 3-XC3S400) with a sustained throughput of 1.6 Gbps. Given a larger FPGA, the design can scale linearly to support a greater number of patterns, as well as higher data throughput.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2089125699",
    "type": "article"
  },
  {
    "title": "Compiler-assisted soft error detection under performance and energy constraints in embedded systems",
    "doi": "https://doi.org/10.1145/1550987.1550990",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Jie Hu; Feihui Li; V. Degalahal; Mahmut Kandemir; N. Vijaykrishnan; M.J. Irwin",
    "corresponding_authors": "",
    "abstract": "Soft errors induced by terrestrial radiation are becoming a significant concern in architectures designed in newer technologies. If left undetected, these errors can result in catastrophic consequences or costly maintenance problems in different embedded applications. In this article, we focus on utilizing the compiler's help in duplicating instructions for error detection in VLIW datapaths. The instruction duplication mechanism is further supported by a hardware enhancement for efficient result verification, which avoids the need of additional comparison instructions. In the proposed approach, the compiler determines the instruction schedule by balancing the permissible performance degradation and the energy constraint with the required degree of duplication. Our experimental results show that our algorithms allow the designer to perform trade-off analysis between performance, reliability, and energy consumption.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2025060113",
    "type": "article"
  },
  {
    "title": "Hybrid-compiled simulation",
    "doi": "https://doi.org/10.1145/1509288.1509292",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Mehrdad Reshadi; Prabhat Mishra; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Instruction-set simulators are critical tools for the exploration and validation of new processor architectures. Due to the increasing complexity of architectures and time-to-market pressure, performance is the most important feature of an instruction-set simulator. Interpretive simulators are flexible but slow, whereas compiled simulators deliver speed at the cost of flexibility and compilation overhead. This article presents a hybrid instruction-set-compiled simulation (HISCS) technique for generation of fast instruction-set simulators that combines the benefit of both compiled and interpretive simulation. This article makes two important contributions: (i) it improves the interpretive simulation performance by applying compiled simulation at the instruction level using a novel template-customization technique to generate optimized decoded instructions during compile time; and (ii) it reduces the compile-time overhead by combining the benefits of both static and dynamic-compiled simulation. Our experimental results using two contemporary processors (ARM7 and SPARC) demonstrate an order-of-magnitude reduction in compilation time as well as a 70% performance improvement, on average, over the best-known published result in instruction-set simulation.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W1975499774",
    "type": "article"
  },
  {
    "title": "Quantitative analysis of the speed/accuracy trade-off in transaction level modeling",
    "doi": "https://doi.org/10.1145/1457246.1457250",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Gunar Schirner; Rainer Dömer",
    "corresponding_authors": "",
    "abstract": "The increasing complexity of embedded systems requires modeling at higher levels of abstraction. Transaction level modeling (TLM) has been proposed to abstract communication for high-speed system simulation and rapid design space exploration. Although being widely accepted for its high performance and efficiency, TLM often exhibits a significant loss in model accuracy. In this article, we systematically analyze and quantify the speed/accuracy trade-off in TLM. To this end, we provide a classification of TLM abstraction levels based on model granularity and define appropriate metrics and test setups to quantitatively measure and compare the performance and accuracy of such models. Addressing several classes of embedded communication protocols, we apply our analysis to three common bus architectures, the industry-standard AMBA advanced high-performance bus (AHB) as an on-chip parallel bus, the controller area network (CAN) as an off-chip serial bus, and the Motorola ColdFire Master Bus as an example for a custom embedded processor bus. Based on the analysis of these individual busses, we then generalize our results for a broader conclusion. The general TLM trade-off offers gains of up to four orders of magnitude in simulation speed, generally however, at the price of low accuracy. We conclude further that model granularity is the key to efficient TLM abstraction, and we identify conditions for accuracy of abstract models. As a result, this article provides general guidelines that allow the system designer to navigate the TLM trade-off effectively and choose the most suitable model for the given application with fast and accurate results.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2076732255",
    "type": "article"
  },
  {
    "title": "Hierarchical agent monitoring design approach towards self-aware parallel systems-on-chip",
    "doi": "https://doi.org/10.1145/1698772.1698783",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Liang Guang; Ethiopia Nigussie; Pekka Rantala; Jouni Isoaho; Hannu Tenhunen",
    "corresponding_authors": "",
    "abstract": "Hierarchical agent framework is proposed to construct a monitoring layer towards self-aware parallel systems-on-chip (SoCs). With monitoring services as a new design dimension, systems are capable of observing and reconfiguring themselves dynamically at all levels of granularity, based on application requirements and platform conditions. Agents with hierarchical priorities work adaptively and cooperatively to maintain and improve system performance in the presence of variations and faults. Function partitioning of agents and hierarchical monitoring operations on parallel SoCs are analyzed. Applying the design approach on the Network-on-Chip (NoC) platform demonstrates the design process and benefits using the novel approach.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2051396856",
    "type": "article"
  },
  {
    "title": "Functional test generation using design and property decomposition techniques",
    "doi": "https://doi.org/10.1145/1550987.1550995",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Heon-Mo Koo; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "Functional verification of microprocessors is one of the most complex and expensive tasks in the current system-on-chip design methodology. Simulation using functional test vectors is the most widely used form of processor validation. A significant bottleneck in the validation of such systems is the lack of automated techniques for directed test generation. While existing model checking--based approaches have proposed several promising ideas for automated test generation, many challenges remain in applying them to industrial microprocessors. The time and resources required for test generation using existing model checking--based techniques can be prohibitively large. This article presents an efficient test generation technique using decompositional model checking. The contribution of the article is the development of both property and design decomposition procedures for efficient test generation of pipelined processors. Our experimental results using a multi-issue MIPS processor and an industrial processor based on Power Architecture™ Technology demonstrate several orders-of-magnitude reduction in validation effort by drastically reducing both test generation time and test program length.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2087214779",
    "type": "article"
  },
  {
    "title": "Cache partitioning for energy-efficient and interference-free embedded multitasking",
    "doi": "https://doi.org/10.1145/1698772.1698774",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Rakesh Reddy; П. П. Петров",
    "corresponding_authors": "",
    "abstract": "We propose a technique that leverages configurable data caches to address the problem of energy inefficiency and intertask interference in multitasking embedded systems. Data caches are often necessary to provide the required memory bandwidth. However, caches introduce two important problems for embedded systems. Caches contribute to a significant amount of power as they typically occupy a large part of the chip and are accessed frequently. In nanometer technologies, such large structures contribute significantly to the total leakage power as well. Additionally, cache outcomes in multitasking environments are notoriously difficult to predict, if not impossible, thus resulting in poor real-time guarantees. We study the effect of multiprogramming workloads on the data cache in a preemptive multitasking environment, and propose a technique which leverages configurable cache architectures to not only eliminate intertask cache interference, but also to significantly reduce both dynamic and leakage power. By mapping tasks to different cache partitions, interference is completely eliminated. Dynamic and leakage power are significantly reduced as only a subset of the cache is active at any moment. We introduce a profile-based, off-line algorithm, which identifies a beneficial cache partitioning. The OS configures the data cache during context-switch by activating the corresponding partition. Our experiments on a large set of multitasking benchmarks demonstrate that our technique not only efficiently eliminates intertask interference, but also significantly reduces both dynamic and leakage power.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2034382840",
    "type": "article"
  },
  {
    "title": "Parallel architectures for the kNN classifier -- design of soft IP cores and FPGA implementations",
    "doi": "https://doi.org/10.1145/2514641.2514649",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Ioannis Stamoulias; Ηλίας Σ. Μανωλάκος",
    "corresponding_authors": "",
    "abstract": "We designed a variety of k-nearest-neighbor parallel architectures for FPGAs in the form of parameterizable soft IP cores. We show that they can be used to solve large classification problems with thousands of training vectors, or thousands of vector dimensions using a single FPGA, and achieve very high throughput. They can be used to flexibly synthesize architectures that also cover: 1NN classification (vector quantization), multishot queries (with different k ), LOOCV cross-validation, and compare favorably to GPU implementations. To the best of our knowledge this is the first attempt to design flexible IP cores for the popular kNN classifier.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2063459162",
    "type": "article"
  },
  {
    "title": "A HW/SW co-verification framework for SystemC",
    "doi": "https://doi.org/10.1145/2435227.2435257",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Paula Herber; Sabine Glesner",
    "corresponding_authors": "",
    "abstract": "SystemC is widely used for modeling and simulation in hardware/software co-design. However, existing verification techniques are mostly ad-hoc and non-systematic. In this article, we present a systematic, comprehensive, and formally founded co-verification framework for digital HW/SW systems that are modeled in SystemC. The framework is based on a formal semantics of SystemC and uses a combination of model checking and testing, whereby testing includes both the automated generation of timed inputs and automated conformance evaluation. We demonstrate its performance and its error detecting capability with two case studies, namely a packet switch and an anti-slip regulation and anti-lock braking system.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2072922398",
    "type": "article"
  },
  {
    "title": "MORPHEUS",
    "doi": "https://doi.org/10.1145/2442116.2442120",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Nikolaos Voros; Michael Hübner; Jürgen Becker; Matthias Kühnle; Florian Thomaitiv; Arnaud Grasset; Paul Brelet; Philippe Bonnot; Fabio Campi; Eberhard Schüler; Henning Sahlbach; Sean Whitty; Rolf Ernst; Enrico Billich; Claudia Tischendorf; Ulrich Heinkel; Frank Ieromnimon; Dimitrios Kritharidis; Axel Schneider; Joachim Knaeblein; Wolfram Putzke-Röming",
    "corresponding_authors": "",
    "abstract": "Recently, system designers are facing the challenge of developing systems that have diverse features, are more complex and more powerful, with less power consumption and reduced time to market. These contradictory constraints have forced technology providers to pursue design solutions that will allow design teams to meet the above design targets. In that respect, this paper introduces an innovative technology platform, called MORPHEUS, which intents to provide complete design framework for dealing with the aforementioned challenges. MORPHEUS consists of a state of the art architecture that encompasses heterogeneous reconfigurable accelerators for implementing on the same hardware architecture applications with varying characteristics and a tool chain that, through a software oriented approach, eases the implementation of highly complex applications with heterogeneous characteristics. The proposed approach has been tested and evaluated through state of the art cases studies borrowed from complementary application domains.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2122620713",
    "type": "article"
  },
  {
    "title": "Conformance testing for cyber-physical systems",
    "doi": "https://doi.org/10.1145/2362336.2362351",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Matthias Woehrle; Kai Lampka; Lothar Thiele",
    "corresponding_authors": "",
    "abstract": "Cyber-Physical Systems (CPS) require a high degree of reliability and robustness. Hence it is important to assert their correctness with respect to extra-functional properties, like power consumption, temperature, etc. In turn the physical quantities may be exploited for assessing system implementations. This article develops a methodology for utilizing measurements of physical quantities for testing the conformance of a running CPS with respect to a formal description of its required behavior allowing to uncover defects. We present foundations and implementations of this approach and demonstrate its usefulness by conformance testing power measurements of a wireless sensor node with a formal model of its power consumption.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W1966061495",
    "type": "article"
  },
  {
    "title": "Efficient compilation of CUDA kernels for high-performance computing on FPGAs",
    "doi": "https://doi.org/10.1145/2514641.2514652",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Alexandros Papakonstantinou; Karthik Gururaj; John A. Stratton; Deming Chen; Jason Cong; Wen‐mei Hwu",
    "corresponding_authors": "",
    "abstract": "The rise of multicore architectures across all computing domains has opened the door to heterogeneous multiprocessors, where processors of different compute characteristics can be combined to effectively boost the performance per watt of different application kernels. GPUs, in particular, are becoming very popular for speeding up compute-intensive kernels of scientific, imaging, and simulation applications. New programming models that facilitate parallel processing on heterogeneous systems containing GPUs are spreading rapidly in the computing community. By leveraging these investments, the developers of other accelerators have an opportunity to significantly reduce the programming effort by supporting those accelerator models already gaining popularity. In this work, we adapt one such language, the CUDA programming model, into a new FPGA design flow called FCUDA, which efficiently maps the coarse- and fine-grained parallelism exposed in CUDA onto the reconfigurable fabric. Our CUDA-to-FPGA flow employs AutoPilot, an advanced high-level synthesis tool (available from Xilinx) which enables high-abstraction FPGA programming. FCUDA is based on a source-to-source compilation that transforms the SIMT (Single Instruction, Multiple Thread) CUDA code into task-level parallel C code for AutoPilot. We describe the details of our CUDA-to-FPGA flow and demonstrate the highly competitive performance of the resulting customized FPGA multicore accelerators. To the best of our knowledge, this is the first CUDA-to-FPGA flow to demonstrate the applicability and potential advantage of using the CUDA programming model for high-performance computing in FPGAs.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2021944457",
    "type": "article"
  },
  {
    "title": "Exact Safety Verification of Hybrid Systems Based on Bilinear SOS Representation",
    "doi": "https://doi.org/10.1145/2629424",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Zhengfeng Yang; Wang Lin; Min Wu",
    "corresponding_authors": "",
    "abstract": "In this article, we address the problem of safety verification of nonlinear hybrid systems. A hybrid symbolic-numeric method is presented to compute exact inequality invariants of hybrid systems efficiently. Some numerical invariants of a hybrid system can be obtained by solving a bilinear SOS programming via the PENBMI solver or iterative method, then the modified Newton refinement and rational vector recovery techniques are applied to obtain exact polynomial invariants with rational coefficients, which exactly satisfy the conditions of invariants. Experiments on some benchmarks are given to illustrate the efficiency of our algorithm.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2038498011",
    "type": "article"
  },
  {
    "title": "Dynamic Behavior Specification and Dynamic Mapping for Real-Time Embedded Systems",
    "doi": "https://doi.org/10.1145/2584658",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Hanwoong Jung; Chanhee Lee; Shin-haeng Kang; Sungchan Kim; Hyunok Oh; Soonhoi Ha",
    "corresponding_authors": "",
    "abstract": "As the number of processors in a chip increases and more functions are integrated, the system status will change dynamically due to various factors such as the workload variation, QoS requirement, and unexpected component failure. A typical method to deal with the dynamics of the system is to decide the mapping decision at runtime, based on the local information of the system status. It is very challenging to guarantee any real-time performance of a certain application in such a dynamically varying system. To solve this problem, we propose a hybrid specification of dataflow and FSM models to specify the dynamic behavior of a system distinguishing inter- and intra-application dynamism. At the top level, each application is specified by a dataflow task and the dynamic behavior is modeled as a control task that supervises the execution of applications. Inside a dataflow task, we specify the dynamic behavior using a similar way as FSM-based SADF in which an application is specified by a synchronous dataflow graph for each mode of operation. It enables us to perform compile-time scheduling of each graph to maximize the throughput varying the number of allocated processors, and store the scheduling information. When a change in system state is detected at runtime, the number of allocated processors to the active tasks is determined dynamically utilizing the stored scheduling information of those tasks in order to meet the real-time requirements. The proposed technique is implemented in the HOPES design environment. Through preliminary experiments with a simple smartphone example, we show the viability of the proposed methodology.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2054043437",
    "type": "article"
  },
  {
    "title": "Quantitative Analysis of Systems Using Game-Theoretic Learning",
    "doi": "https://doi.org/10.1145/2331147.2331165",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Sanjit A. Seshia; Alexander Rakhlin",
    "corresponding_authors": "",
    "abstract": "The analysis of quantitative properties, such as timing and power, is central to the design of reliable embedded software and systems. However, the verification of such properties on a program is made difficult by their heavy dependence on the program’s environment, such as the processor it runs on. Modeling the environment by hand can be tedious, error prone, and time consuming. In this article, we present a new game-theoretic approach to analyzing quantitative properties that is based on performing systematic measurements to automatically learn a model of the environment. We model the problem as a game between our algorithm (player) and the environment of the program (adversary) in which the player seeks to accurately predict the property of interest, while the adversary sets environment states and parameters. To solve this problem, we employ a randomized strategy that repeatedly tests the program along a linear-sized set of program paths called basis paths, using the resulting measurements to infer a weighted-graph model of the environment from which quantitative properties can be predicted. Test cases are automatically generated using satisfiability modulo theories (SMT) solving. We prove that our algorithm can, under certain assumptions and with arbitrarily high probability, accurately predict properties such as worst-case execution time or estimate the distribution of execution times. Experimental results for execution time analysis demonstrate that our approach is efficient, accurate, and highly portable.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2061291692",
    "type": "article"
  },
  {
    "title": "Real-Time Simulation Support for Runtime Verification of Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3063382",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Xi Zheng; Christine Julien; Hongxu Chen; Rodion Podorozhny; Franck Cassez",
    "corresponding_authors": "",
    "abstract": "In Cyber-Physical Systems (CPS), cyber and physical components must work seamlessly in tandem. Runtime verification of CPS is essential yet very difficult, due to deployment environments that are expensive, dangerous, or simply impossible to use for verification tasks. A key enabling factor of runtime verification of CPS is the ability to integrate real-time simulations of portions of the CPS into live running systems. We propose a verification approach that allows CPS application developers to opportunistically leverage real-time simulation to support runtime verification. Our approach, termed B race B ind , allows selecting, at runtime, between actual physical processes or simulations of them to support a running CPS application. To build B race B ind , we create a real-time simulation architecture to generate and manage multiple real-time simulation environments based on existing simulation models in a manner that ensures sufficient accuracy for verifying a CPS application. Specifically, B race B ind aims to both improve simulation speed and minimize latency, thereby making it feasible to integrate simulations of physical processes into the running CPS application. B race B ind then integrates this real-time simulation architecture with an existing runtime verification approach that has low computational overhead and high accuracy. This integration uses an aspect-oriented adapter architecture that connects the variables in the cyber portion of the CPS application with either sensors and actuators in the physical world or the automatically generated real-time simulation. Our experimental results show that, with a negligible performance penalty, our approach is both efficient and effective in detecting program errors that are otherwise only detectable in a physical deployment.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2612464746",
    "type": "article"
  },
  {
    "title": "Preserving Smart Sink-Location Privacy with Delay Guaranteed Routing Scheme for WSNs",
    "doi": "https://doi.org/10.1145/2990500",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Anfeng Liu; Xiao Liu; Zhipeng Tang; Laurence T. Yang; Zili Shao",
    "corresponding_authors": "",
    "abstract": "A Semi Random Circle routing for mobile Sink joint Ray Routing for data (SRCRR) scheme is proposed for preserving sink-location privacy with a delay guaranteed. In the SRCRR scheme, the data are directionally routed along ray paths and stored at intermediate nodes probabilistically. The Sink moves in a semirandom circular pattern to collect data from the local nodes occasionally, which guarantees that the data will be collected with an acceptable delay and prevents attackers from predicting their locations and movements. The experimental results indicate that the performance of the SRCRR scheme is better than that of the previous schemes.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2619165578",
    "type": "article"
  },
  {
    "title": "A Hybrid Genetic Algorithm for the Bottleneck Traveling Salesman Problem",
    "doi": "https://doi.org/10.1145/2406336.2406345",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Zakir Hussain Ahmed",
    "corresponding_authors": "Zakir Hussain Ahmed",
    "abstract": "The bottleneck traveling salesman problem is to find a Hamiltonian circuit that minimizes the largest cost of any of its arcs in a graph. A simple genetic algorithm (GA) using sequential constructive crossover has been developed to obtain heuristic solution to the problem. The hybrid GA incorporates 2-opt search, another proposed local search and immigration to the simple GA for obtaining better solution. The efficiency of our hybrid GA to the problem against two existing heuristic algorithms has been examined for some symmetric TSPLIB instances. The comparative study shows the effectiveness of our hybrid algorithm. Finally, we present solutions to the problem for asymmetric TSPLIB instances.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2026911372",
    "type": "article"
  },
  {
    "title": "Implementation and evaluation of mixed-criticality scheduling approaches for sporadic tasks",
    "doi": "https://doi.org/10.1145/2584612",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Huang-Ming Huang; Christopher Gill; Chenyang Lu",
    "corresponding_authors": "",
    "abstract": "Traditional fixed-priority scheduling analysis for periodic and sporadic task sets is based on the assumption that all tasks are equally critical to the correct operation of the system. Therefore, every task has to be schedulable under the chosen scheduling policy, and estimates of tasks' worst-case execution times must be conservative in case a task runs longer than is usual. To address the significant underutilization of a system's resources under normal operating conditions that can arise from these assumptions, several mixed-criticality scheduling approaches have been proposed. However, to date, there have been few quantitative comparisons of system schedulability or runtime overhead for the different approaches. In this article, we present a side-by-side implementation and evaluation of the known mixed-criticality scheduling approaches, for periodic and sporadic mixed-criticality tasks on uniprocessor systems, under a mixed-criticality scheduling model that is common to all these approaches. To make a fair evaluation of mixed-criticality scheduling, we also address previously open issues and propose modifications to improve particular approaches. Our empirical evaluations demonstrate that user-space implementations of mechanisms to enforce different mixed-criticality scheduling approaches can be achieved atop Linux without kernel modification, with reasonably low (but in some cases nontrivial) overhead for mixed-criticality real-time task sets.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2072712992",
    "type": "article"
  },
  {
    "title": "Design, Analysis and Verification of Real-Time Systems Based on Time Petri Net Refinement",
    "doi": "https://doi.org/10.1145/2406336.2406340",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Zhijun Ding; Changjun Jiang; MengChu Zhou",
    "corresponding_authors": "",
    "abstract": "A type of refinement operations of time Petri nets is presented for design, analysis and verification of complex real-time systems. First, the behavior preservation is studied under time constraints in a refinement operation, and a sufficient condition for behavior preservation is obtained. Then, the property preservation is considered, and the results indicate that if the refinement operation of time Petri nets satisfies behavior preservation, it can also preserve properties such as boundedness and liveness. Finally, based on the behavior preservation, a reachability decidability algorithm of a refined time Petri net is designed using the reachability trees of its original net and subnet. The research results are illustrated by an example of designing, analyzing and verifying a real-time manufacturing system.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2090533273",
    "type": "article"
  },
  {
    "title": "Tomahawk",
    "doi": "https://doi.org/10.1145/2517087",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Oliver Arnold; Emil Matúš; Benedikt Noethen; Markus Winter; T. Limberg; Gerhard Fettweis",
    "corresponding_authors": "",
    "abstract": "Heterogeneity and parallelism in MPSoCs for 4G (and beyond) communications signal processing are inevitable in order to meet stringent power constraints and performance requirements. The question arises on how to cope with the problem of system programmability and runtime management incurred by the statically or even dynamically varying number and type of processing elements. This work addresses this challenge by proposing the concept of a heterogeneous many-core platform called Tomahawk. Apart from the definition of the system architecture, in this approach a unified framework including a model of computation, a programming interface and a dedicated runtime management unit called CoreManager is proposed. The increase of system complexity in terms of application parallelism and number of resources may lead to a dramatic increase of the management costs, hence causing performance degradation. For this reason, the efficient implementation of the CoreManager becomes a major issue in system design. This work compares the performance and capabilities of various CoreManager HW/SW solutions, based on ASIC, RISC and ASIP paradigms. The results demonstrate that the proposed ASIP-based solution approaches the performance of the ASIC realization, while preserving the full flexibility of the software (RISC-based) implementation.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2106435547",
    "type": "article"
  },
  {
    "title": "Distributed Multi-Representative Re-Fusion Approach for Heterogeneous Sensing Data Collection",
    "doi": "https://doi.org/10.1145/2974021",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Anfeng Liu; Xiao Liu; Tianyi Wei; Laurence T. Yang; Seungmin Rho; Anand Paul",
    "corresponding_authors": "",
    "abstract": "A multi-representative re-fusion (MRRF) approximate data collection approach is proposed in which multiple nodes with similar readings form a data coverage set (DCS). The reading value of the DCS is represented by an R-node. The set near the Sink is smaller, while the set far from the Sink is larger, which can reduce the energy consumption in hotspot areas. Then, a distributed data-aggregation strategy is proposed that can re-fuse the value of R-nodes that are far from each other but have similar readings. Both comprehensive theoretical and experimental results indicate that the MRRF approach increases lifetime and energy efficiency.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2616931699",
    "type": "article"
  },
  {
    "title": "Collaborative PCA/DCA Learning Methods for Compressive Privacy",
    "doi": "https://doi.org/10.1145/2996460",
    "publication_date": "2017-07-07",
    "publication_year": 2017,
    "authors": "Sun‐Yuan Kung; Thee Chanyaswad; J. Morris Chang; Pei-Yuan Wu",
    "corresponding_authors": "",
    "abstract": "In the Internet era, the data being collected on consumers like us are growing exponentially, and attacks on our privacy are becoming a real threat. To better ensure our privacy, it is safer to let the data owner control the data to be uploaded to the network as opposed to taking chance with data servers or third parties. To this end, we propose compressive privacy , a privacy-preserving technique to enable the data creator to compress data via collaborative learning so that the compressed data uploaded onto the Internet will be useful only for the intended utility and not be easily diverted to malicious applications. For data in a high-dimensional feature vector space, a common approach to data compression is dimension reduction or, equivalently, subspace projection. The most prominent tool is principal component analysis (PCA). For unsupervised learning, PCA can best recover the original data given a specific reduced dimensionality. However, for the supervised learning environment, it is more effective to adopt a supervised PCA, known as discriminant component analysis (DCA), to maximize the discriminant capability. The DCA subspace analysis embraces two different subspaces. The signal-subspace components of DCA are associated with the discriminant distance/power (related to the classification effectiveness), whereas the noise subspace components of DCA are tightly coupled with recoverability and/or privacy protection. This article presents three DCA-related data compression methods useful for privacy-preserving applications: — Utility-driven DCA : Because the rank of the signal subspace is limited by the number of classes, DCA can effectively support classification using a relatively small dimensionality (i.e., high compression). — Desensitized PCA : By incorporating a signal-subspace ridge into DCA, it leads to a variant especially effective for extracting privacy-preserving components. In this case, the eigenvalues of the noise-space are made to become insensitive to the privacy labels and are ordered according to their corresponding component powers. — Desensitized K-means/SOM : Since the revelation of the K-means or SOM cluster structure could leak sensitive information, it is safer to perform K-means or SOM clustering on a desensitized PCA subspace.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2733464274",
    "type": "article"
  },
  {
    "title": "Efficient Control-Flow Subgraph Matching for Detecting Hardware Trojans in RTL Models",
    "doi": "https://doi.org/10.1145/3126552",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Luca Piccolboni; Alessandro Menon; Graziano Pravadelli",
    "corresponding_authors": "",
    "abstract": "Only few solutions for Hardware Trojan (HT) detection work at Register-Transfer Level (RTL), thus delaying the identification of possible security issues at lower abstraction levels of the design process. In addition, the most of existing approaches work only for specific kinds of HTs. To overcome these limitations, we present a verification approach that detects different types of HTs in RTL models by exploiting an efficient control-flow subgraph matching algorithm. The prototypes of HTs that can be detected are modelled in a library by using Control-Flow Graphs (CFGs) that can be parametrised and extended to cover several variants of Trojan patterns. Experimental results show that our approach is effective and efficient in comparison with other state-of-the-art solutions.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2757667045",
    "type": "article"
  },
  {
    "title": "Sensitivity of cache replacement policies",
    "doi": "https://doi.org/10.1145/2435227.2435238",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Jan Reineke; Daniel Grund",
    "corresponding_authors": "",
    "abstract": "The sensitivity of a cache replacement policy expresses to what extent the execution history may influence the number of cache hits and misses during program execution. We present an algorithm to compute the sensitivity of a replacement policy. We have implemented this algorithm in a tool called R elacs that can handle a large class of replacement policies including LRU, FIFO, PLRU, and MRU. Sensitivity properties obtained with R elacs demonstrate that the execution history can have a strong impact on the number of cache hits and misses if FIFO, PLRU, or MRU is used. A simple model of execution time is used to evaluate the impact of cache sensitivity on measured execution times. The model shows that measured execution times may strongly underestimate the worst-case execution time for FIFO, PLRU, and MRU.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2024815018",
    "type": "article"
  },
  {
    "title": "HERMES",
    "doi": "https://doi.org/10.1145/2435227.2435253",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Hyduke Noshadi; Foad Dabiri; Shaun Ahmadian; Navid Amini; Majid Sarrafzadeh",
    "corresponding_authors": "",
    "abstract": "We introduce Hermes , a lightweight smart shoe and its supporting infrastructure aimed at extending gait and instability analysis and human instability/balance monitoring outside of a laboratory environment. We aimed to create a scientific tool capable of high-level measures, by combining embedded sensing, signal processing and modeling techniques. Hermes monitors walking behavior and uses an instability assessment model to generate quantitative value with episodes of activity identified by physician, researchers or investigators as important. The underlying instability assessment model incorporates variability and correlation of features extracted during ambulation that have been identified by geriatric motion study experts as precursor to instability, balance abnormality and possible fall risk. Hermes provides a mobile, affordable and long-term instability analysis and detection system that is customizable to individual users, and is context-aware, with the capability of being guided by experts. Our experiments demonstrate the feasibility of our model and the complimentary role our system can play by providing long-term monitoring of patients outside a hospital or clinical setting at a reduced cost, with greater user convenience, compliance and inference capabilities that meet the physician's or investigator's needs.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2045015415",
    "type": "article"
  },
  {
    "title": "Energy Efficiency Analysis for the Single Frequency Approximation (SFA) Scheme",
    "doi": "https://doi.org/10.1145/2660490",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Santiago Pagani; Jian-Jia Chen",
    "corresponding_authors": "",
    "abstract": "Energy-efficient designs are important issues in computing systems. This article studies the energy efficiency of a simple and linear-time strategy, called the Single Frequency Approximation (SFA) scheme, for periodic real-time tasks on multicore systems with a shared supply voltage in a voltage island. The strategy executes all the cores at a single frequency to just meet the timing constraints. SFA has been adopted in the literature after task partitioning, but the worst-case performance of SFA in terms of energy consumption incurred is an open problem. We provide comprehensive analysis for SFA to derive the cycle utilization distribution for its worst-case behaviour for energy minimization. Our analysis shows that the energy consumption incurred by using SFA for task execution is at most 1.53 (1.74, 2.10, 2.69, respectively), compared to the energy consumption of the optimal voltage/frequency scaling, when the dynamic power consumption is a cubic function of the frequency and the voltage island has up to 4 (8, 16, 32, respectively) cores. The analysis shows that SFA is indeed an effective scheme under practical settings, even though it is not optimal. Furthermore, since all the cores run at a single frequency and no frequency alignment for Dynamic Voltage and Frequency Scaling (DVFS) between cores is needed, any unicore dynamic power management technique for reducing the energy consumption for idling can be easily incorporated individually on each core in the voltage island. This article also provides an analysis of energy consumption for SFA combined with procrastination for Dynamic Power Management (DPM), resulting in an increment of 1 from the previous results for task execution. Furthermore, we also extend our analysis for deriving the approximation factor of SFA for a multicore system with multiple voltage islands.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2054283680",
    "type": "article"
  },
  {
    "title": "Low-Cost Standard Signatures for Energy-Harvesting Wireless Sensor Networks",
    "doi": "https://doi.org/10.1145/2994603",
    "publication_date": "2017-04-28",
    "publication_year": 2017,
    "authors": "Giuseppe Ateniese; Giuseppe Bianchi; Angelo Capossele; Chiara Petrioli; Dora Spenza",
    "corresponding_authors": "",
    "abstract": "This work is motivated by a general question: can micro-scale energy-harvesting techniques be exploited to support low-cost standard security solutions on resource-constrained devices? We focus on guaranteeing integrity and authentication in Internet of Things (IoT) and Wireless Sensor Network (WSN) applications. In this article, we propose techniques to make ECDSA signatures low cost and implementable on resource-constrained devices. By combining precomputation techniques and energy-harvesting capabilities of modern sensor nodes, we achieve significant improvement over prior works. In addition, we show that the cost of ECDSA signatures can be reduced by up to a factor 10 by using harvesting-aware optimizations.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2587321586",
    "type": "article"
  },
  {
    "title": "Synthesis of Error-Recovery Protocols for Micro-Electrode-Dot-Array Digital Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3126538",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Mahmoud Elfar; Zhanwei Zhong; Zipeng Li; Krishnendu Chakrabarty; Miroslav Pajić",
    "corresponding_authors": "",
    "abstract": "A digital microfluidic biochip (DMFB) is an attractive technology platform for various biomedical applications. However, a conventional DMFB is limited by: (i) the number of electrical connections that can be practically realized, (ii) constraints on droplet size and volume, and (iii) the need for special fabrication processes and the associated reliability/yield concerns. To overcome the above challenges, DMFBs based on a micro-electrode-dot-array (MEDA) architecture have been proposed and fabricated recently. Error recovery is of key interest for MEDA biochips due to the need for system reliability. Errors are likely to occur during droplet manipulation due to defects, chip degradation, and the uncertainty inherent in biochemical experiments. In this paper, we first formalize error-recovery objectives, and then synthesize optimal error-recovery protocols using a model based on Stochastic Multiplayer Games (SMGs). We also present a global error-recovery technique that can update the schedule of fluidic operations in an adaptive manner. Using three representative real-life bioassays, we show that the proposed approach can effectively reduce the bioassay completion time and increase the probability of success for error recovery.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2759660240",
    "type": "article"
  },
  {
    "title": "Mining Timed Regular Specifications from System Traces",
    "doi": "https://doi.org/10.1145/3147660",
    "publication_date": "2018-01-03",
    "publication_year": 2018,
    "authors": "Apurva Narayan; Greta Cutulenco; Yogi Joshi; Sebastian Fischmeister",
    "corresponding_authors": "",
    "abstract": "Temporal properties define the order of occurrence and timing constraints on event occurrence. Such specifications are important for safety-critical real-time systems. We propose a framework for automatically mining temporal properties that are in the form of timed regular expressions (TREs) from system traces. Using an abstract structure of the property, the framework constructs a finite state machine to serve as an acceptor. We analytically derive speedup for the fragment and confirm the speedup using empirical validation with synthetic traces. The framework is evaluated on industrial-strength safety-critical real-time applications using traces with more than 1 million entries.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2781885368",
    "type": "article"
  },
  {
    "title": "HESSLE-FREE",
    "doi": "https://doi.org/10.1145/3358203",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Kasra Moazzemi; Biswadip Maity; Saehanseul Yi; Amir M. Rahmani; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "As computing platforms increasingly embrace heterogeneity, runtime resource managers need to efficiently, dynamically, and robustly manage shared resources (e.g., cores, power budgets, memory bandwidth). To address the complexities in heterogeneous systems, state-of-the-art techniques that use heuristics or machine learning have been proposed. On the other hand, conventional control theory can be used for formal guarantees, but may face unmanageable complexity for modeling system dynamics of complex heterogeneous systems. We address this challenge through HESSLE-FREE (Heterogeneous Systems Leveraging Fuzzy Control for Runtime Resource Management): an approach leveraging fuzzy control theory that combines the strengths of classical control theory together with heuristics to form a light-weight, agile, and efficient runtime resource manager for heterogeneous systems. We demonstrate the efficacy of HESSLE-FREE executing on a NVIDIA Jetson TX2 platform (containing a heterogeneous multi-processor with a GPU) to show that HESSLE-FREE: 1) provides opportunity for optimization in the controller and stability analysis to enhance the confidence in the reliability of the system; 2) coordinates heterogeneous compute units to achieve desired objectives (e.g., QoS, optimal power references, FPS) efficiently and with lower complexity , and 3) eases the burden of system specification.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2979870769",
    "type": "article"
  },
  {
    "title": "COSMOS",
    "doi": "https://doi.org/10.1145/3126566",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Luca Piccolboni; Paolo Mantovani; Giuseppe Di Guglielmo; Luca P. Carloni",
    "corresponding_authors": "",
    "abstract": "Hardware accelerators are key to the efficiency and performance of system-on-chip (SoC) architectures. With high-level synthesis (HLS), designers can easily obtain several performance-cost trade-off implementations for each component of a complex hardware accelerator. However, navigating this design space in search of the Pareto-optimal implementations at the system level is a hard optimization task. We present COSMOS, an automatic methodology for the design-space exploration (DSE) of complex accelerators, that coordinates both HLS and memory optimization tools in a compositional way. First, thanks to the co-design of datapath and memory, COSMOS produces a large set of Pareto-optimal implementations for each component of the accelerator. Then, COSMOS leverages compositional design techniques to quickly converge to the desired trade-off point between cost and performance at the system level. When applied to the system-level design (SLD) of an accelerator for wide-area motion imagery (WAMI), COSMOS explores the design space as completely as an exhaustive search, but it reduces the number of invocations to the HLS tool by up to 14.6×.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3100932218",
    "type": "article"
  },
  {
    "title": "Runtime Monitoring of Cyber-Physical Systems Under Timing and Memory Constraints",
    "doi": "https://doi.org/10.1145/2744196",
    "publication_date": "2015-10-20",
    "publication_year": 2015,
    "authors": "Ramy Medhat; Borzoo Bonakdarpour; Deepak Kumar; Sebastian Fischmeister",
    "corresponding_authors": "",
    "abstract": "The goal of runtime monitoring is to inspect the well-being of a system by employing a monitor process that reads the state of the system during execution and evaluates a set of properties expressed in some specification language. The main challenge in runtime monitoring is dealing with the costs imposed in terms of resource utilization. In the context of cyber-physical systems, it is crucial for a software monitoring solution to be time predictable to improve scheduling, as well as support composition of monitoring solutions with an overall predictable behavior. Moreover, a small memory footprint is often required in components of cyber-physical systems, especially in deeply embedded systems. In this article, we propose a novel control-theoretic software monitoring solution for coordinating time predictability and memory utilization in runtime monitoring of systems that interact with the physical world. The controllers attempt to reduce monitoring jitter and maximize memory utilization while simultaneously ensuring the soundness of evaluation of properties. For systems where multiple properties are required to be monitored simultaneously, we construct a buffer sharing mechanism in which controllers dynamically share the memory space to negate the effect of bursts of environment actions, thus reducing jitter due to transient high loads. To validate our design choices, we present three case studies: (1) a Bluetooth mobile payment system, which shows a sporadic rate of events during peak hours; (2) a laser beam stabilizer for target tracking, and (3) a monitoring system for air/fuel ratio in a car engine exhaust and the CAM inlet position in the engine’s cylinders. The experimental results of the case studies demonstrate up to 40% improvement in time predictability of the monitoring solution when compared to a basic event-triggered approach. Moreover, memory utilization reaches an average of 90% when using our dynamic buffer resizing mechanism.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2056047125",
    "type": "article"
  },
  {
    "title": "Minimizing Stack and Communication Memory Usage in Real-Time Embedded Applications",
    "doi": "https://doi.org/10.1145/2632160",
    "publication_date": "2014-07-23",
    "publication_year": 2014,
    "authors": "Haibo Zeng; Marco Di Natale; Qi Zhu",
    "corresponding_authors": "",
    "abstract": "In the development of real-time embedded applications, especially those on systems-on-chip, an efficient use of RAM memory is as important as the effective scheduling of the computation resources. The protection of communication and state variables accessed by concurrent tasks must provide real-time schedulability guarantees while using the least amount of memory. Several schemes, including preemption thresholds, have been developed to improve schedulability and save stack space by selectively disabling preemption. However, the design synthesis problem is still open. In this article, we target the assignment of the scheduling parameters to minimize memory usage for systems of practical interest, including designs compliant with automotive standards. We propose algorithms either proven optimal or shown to improve on randomized optimization methods like simulated annealing.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2138510156",
    "type": "article"
  },
  {
    "title": "<scp>q</scp> LUT",
    "doi": "https://doi.org/10.1145/3126531",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Arnab Raha; Vijay Raghunathan",
    "corresponding_authors": "",
    "abstract": "Approximate computing has emerged as a popular design paradigm for optimizing the performance and energy consumption of error-resilient applications in domains such as machine learning, graphics, data analytics, etc . Numerous techniques for approximate computing have been proposed at different layers of the system stack, from circuits to architecture to software. In this work, we propose a new technique, called quantized table lookup , for approximating the meta-functions used in the core computational kernels of error-resilient applications. In contrast to prior work that directly approximates the functionality of the meta-functions, the proposed technique instead approximates the input data to the meta-functions by reducing/quantizing them to a much smaller set of values that we call quantized inputs . The small number of quantized inputs enables us to completely replace the energy-intensive arithmetic units in the meta-function with small and energy-efficient lookup tables (called quantized lookup tables or q LUT) that contain precomputed output values corresponding to the quantized inputs. The proposed approximation technique is not only highly generic, but also inherently quality-configurable and input-aware. Quality-configurability and input-awareness are achieved by modulating the size of the q LUT as well as selecting the values of the quantized inputs judiciously based on the statistics of the original input data. To evaluate the proposed technique, we have implemented the dominant meta-functions of nine error-resilient application benchmarks as quantized table lookup based hardware accelerators using 45nm technology. Experimental results demonstrate average energy savings of 46% at the application-level for minimal (&lt;1%) loss in output quality.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2759259332",
    "type": "article"
  },
  {
    "title": "A Comparative Study of Predictable DRAM Controllers",
    "doi": "https://doi.org/10.1145/3158208",
    "publication_date": "2018-02-05",
    "publication_year": 2018,
    "authors": "Danlu Guo; Mohamed Hassan; Rodolfo Pellizzoni; Hiren Patel",
    "corresponding_authors": "",
    "abstract": "Recently, the research community has introduced several predictable dynamic random-access memory (DRAM) controller designs that provide improved worst-case timing guarantees for real-time embedded systems. The proposed controllers significantly differ in terms of arbitration, configuration, and simulation environment, making it difficult to assess the contribution of each approach. To bridge this gap, this article provides the first comprehensive evaluation of state-of-the-art predictable DRAM controllers. We propose a categorization of available controllers, and introduce an analytical performance model based on worst-case latency. We then conduct an extensive evaluation for all state-of-the-art controllers based on a common simulation platform, and discuss findings and recommendations.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2786904362",
    "type": "article"
  },
  {
    "title": "FPGA Stream-Monitoring of Real-time Properties",
    "doi": "https://doi.org/10.1145/3358220",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Jan Baumeister; Bernd Finkbeiner; Maximilian Schwenger; Hazem Torfah",
    "corresponding_authors": "",
    "abstract": "An essential part of cyber-physical systems is the online evaluation of real-time data streams. Especially in systems that are intrinsically safety-critical, a dedicated monitoring component inspecting data streams to detect problems at runtime greatly increases the confidence in a safe execution. Such a monitor needs to be based on a specification language capable of expressing complex, high-level properties using only the accessible low-level signals. Moreover, tight constraints on computational resources exacerbate the requirements on the monitor. Thus, several existing approaches to monitoring are not applicable due to their dependence on an operating system. We present an FPGA-based monitoring approach by compiling an RTL ola specification into synthesizable VHDL code. RTL ola is a stream-based specification language capable of expressing complex real-time properties while providing an upper bound on the execution time and memory requirements. The statically determined memory bound allows for a compilation to an FPGA with a fixed size. An advantage of FPGAs is a simple integration process in existing systems and superb executing time. The compilation results in a highly parallel implementation thanks to the modular nature of RTL ola specifications. This further increases the maximal event rate the monitor can handle.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2979502960",
    "type": "article"
  },
  {
    "title": "Automatic Update of Indoor Location Fingerprints with Pedestrian Dead Reckoning",
    "doi": "https://doi.org/10.1145/2667226",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Daisuke Taniuchi; Takuya Maekawa",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a new method for automatically updating a Wi-Fi indoor positioning model on a cloud server by employing uploaded sensor data obtained from the smartphone sensors of a specific user who spends a lot of time in a given environment (e.g., a worker in the environment). In this work, we attempt to track the user with pedestrian dead reckoning techniques, and at the same time we obtain Wi-Fi scan data from a mobile device possessed by the user. With the scan data and the estimated coordinates uploaded to a cloud server, we can automatically create a pair consisting of a scan and its corresponding indoor coordinates during the user's daily life and update an indoor positioning model on the server by using the information. With this approach, we try to cope with the instability of Wi-Fi-based positioning methods caused by changing environmental dynamics, that is, layout changes and moving or removal of Wi-Fi access points. Therefore, ordinary users (e.g., customers) who do not have rich sensors can benefit from the continually updating positioning model.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W1982578217",
    "type": "article"
  },
  {
    "title": "Crosstalk-Aware Automated Mapping for Optical Networks-on-Chip",
    "doi": "https://doi.org/10.1145/2930666",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Edoardo Fusella; Alessandro Cilardo",
    "corresponding_authors": "",
    "abstract": "Optical networks-on-chip (NoCs) provide a promising answer to address the increasing requirements of ultra-high bandwidth and extremely low power consumption. Designing a photonic interconnect, however, involves a number of challenges that have no equivalent in the electronic domain, particularly the crosstalk noise, which affects the signal-to-noise ratio (SNR) possibly resulting in an inoperable architecture and hence constraining the network scalability. In this article, we point out the implications of application-driven task mapping on crosstalk effects. We motivate the main rationale of our work and provide a formalization of the problem. Then we propose a class of algorithms that automatically map the application tasks onto a generic mesh-based photonic NoC architecture such that the worst-case crosstalk is minimized. We also present a purpose-built experimental setup used for evaluating several architectural solutions in terms of crosstalk noise and SNR. The setup is used to collect extensive results from several real-world applications and case studies. The collected results show that the crosstalk noise can be significantly reduced by adopting our approach, thereby allowing higher network scalability, and can exhibit encouraging improvements over application-oblivious architectures.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2531771089",
    "type": "article"
  },
  {
    "title": "Stochastic Assume-Guarantee Contracts for Cyber-Physical System Design",
    "doi": "https://doi.org/10.1145/3243216",
    "publication_date": "2019-01-25",
    "publication_year": 2019,
    "authors": "Pierluigi Nuzzo; Jiwei Li; Alberto Sangiovanni‐Vincentelli; Yugeng Xi; Dewei Li",
    "corresponding_authors": "",
    "abstract": "We present an assume-guarantee contract framework for cyber-physical system design under probabilistic requirements. Given a stochastic linear system and a set of requirements captured by bounded Stochastic Signal Temporal Logic (StSTL) contracts, we propose algorithms to check contract compatibility, consistency, and refinement, and generate a sequence of control inputs that satisfies a contract. We leverage encodings of the verification and control synthesis tasks into mixed integer optimization problems, and conservative approximations of probabilistic constraints that produce sound and tractable problem formulations. We illustrate the effectiveness of our approach on three case studies, including the design of controllers for aircraft power distribution networks.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2911738095",
    "type": "article"
  },
  {
    "title": "Compact and Flexible FPGA Implementation of Ed25519 and X25519",
    "doi": "https://doi.org/10.1145/3312742",
    "publication_date": "2019-04-02",
    "publication_year": 2019,
    "authors": "Furkan Turan; Ingrid Verbauwhede",
    "corresponding_authors": "",
    "abstract": "This article describes a field-programmable gate array (FPGA) cryptographic architecture, which combines the elliptic curve--based Ed25519 digital signature algorithm and the X25519 key establishment scheme in a single module. Cryptographically, these are high-security elliptic curve cryptography algorithms with short key sizes and impressive execution times in software. Our goal is to provide a lightweight FPGA module that enables them on resource-constrained devices, specifically for Internet of Things (IoT) applications. In addition, we aim at extensibility with customisable countermeasures against timing and differential power analysis side-channel attacks and fault-injection attacks. For the former, we offer a choice between time-optimised versus constant-time execution, with or without Z -coordinate randomisation and base-point blinding; and for the latter, we offer enabling or disabling default-case statements in the Finite State Machine (FSM) descriptions. To obtain compactness and at the same time fast execution times, we make maximum use of the Digital Signal Processing (DSP) slices on the FPGA. We designed a single arithmetic unit that is flexible to support operations with two moduli and non-modulus arithmetic. In addition, our design benefits in-place memory management and the local storage of inputs into DSP slices’ pipeline registers and takes advantage of distributed memory. These eliminate a memory access bottleneck. The flexibility is offered by a micro-code supported instruction-set architecture. Our design targets 7-Series Xilinx FPGAs and is prototyped on a Zynq System-on-Chip (SoC). The base design combining Ed25519 and X25519 in a single module, and its implementation requires only around 11.1K Lookup Tables (LUTs), 2.6K registers, and 16 DSP slices. Also, it achieves performance of 1.6ms for a signature generation and 3.6ms for a signature verification for a 1024-bit message with an 82MHz clock. Moreover, the design can be optimised only for X25519, which gives the most compact FPGA implementation compared to previously published X25519 implementations.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2926472889",
    "type": "article"
  },
  {
    "title": "Analytical Performance Models for NoCs with Multiple Priority Traffic Classes",
    "doi": "https://doi.org/10.1145/3358176",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Sumit K. Mandal; Raid Ayoub; Michael Kishinevsky; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "Networks-on-chip (NoCs) have become the standard for interconnect solutions in industrial designs ranging from client CPUs to many-core chip-multiprocessors. Since NoCs play a vital role in system performance and power consumption, pre-silicon evaluation environments include cycle-accurate NoC simulators. Long simulations increase the execution time of evaluation frameworks, which are already notoriously slow, and prohibit design-space exploration. Existing analytical NoC models, which assume fair arbitration, cannot replace these simulations since industrial NoCs typically employ priority schedulers and multiple priority classes. To address this limitation, we propose a systematic approach to construct priority-aware analytical performance models using micro-architecture specifications and input traffic. Our approach decomposes the given NoC into individual queues with modified service time to enable accurate and scalable latency computations. Specifically, we introduce novel transformations along with an algorithm that iteratively applies these transformations to decompose the queuing system. Experimental evaluations using real architectures and applications show high accuracy of 97% and up to 2.5× speedup in full-system simulation.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2979568057",
    "type": "article"
  },
  {
    "title": "Thermal-Aware Scheduling for Integrated CPUs--GPU Platforms",
    "doi": "https://doi.org/10.1145/3358235",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Youngmoon Lee; Kang G. Shin; Hoon Sung Chwa",
    "corresponding_authors": "",
    "abstract": "As modern embedded systems like cars need high-power integrated CPUs--GPU SoCs for various real-time applications such as lane or pedestrian detection, they face greater thermal problems than before, which may, in turn, incur higher failure rate and cooling cost. We demonstrate, via experimentation on a representative CPUs--GPU platform, the importance of accounting for two distinct thermal characteristics—the platform’s temperature imbalance and different power dissipations of different tasks —in real-time scheduling to avoid any burst of power dissipations while guaranteeing all timing constraints. To achieve this goal, we propose a new &lt;u&gt;R&lt;/u&gt;eal-&lt;u&gt;T&lt;/u&gt;ime &lt;u&gt;T&lt;/u&gt;hermal-&lt;u&gt;A&lt;/u&gt;ware &lt;u&gt;S&lt;/u&gt;cheduling (RT-TAS) framework. We first capture different CPU cores’ temperatures caused by different GPU power dissipations (i.e., CPUs--GPU thermal coupling ) with core-specific thermal coupling coefficients. We then develop thermally-balanced task-to-core assignment and CPUs--GPU co-scheduling . The former addresses the platform’s temperature imbalance by efficiently distributing the thermal load across cores while preserving scheduling feasibility. Building on the thermally-balanced task assignment, the latter cooperatively schedules CPU and GPU computations to avoid simultaneous peak power dissipations on both CPUs and GPU, thus mitigating excessive temperature rises while meeting task deadlines. We have implemented and evaluated RT-TAS on an automotive embedded platform to demonstrate its effectiveness in reducing the maximum temperature by 6−12.2° C over existing approaches without violating any task deadline.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2979866182",
    "type": "article"
  },
  {
    "title": "The Bionode",
    "doi": "https://doi.org/10.1145/3301310",
    "publication_date": "2019-01-31",
    "publication_year": 2019,
    "authors": "Daniel J. Pederson; Christopher J. Quinkert; Muhammad Abdullah Arafat; Jesse P. Somann; Jack Williams; Rebecca A. Bercich; Zhi Wang; Gabriel O. Albors; John G. R. Jefferys; Pedro P. Irazoqui",
    "corresponding_authors": "",
    "abstract": "Implantable closed-loop neuromodulation devices for use in long-term chronic studies in a lab or clinical trial are expensive to acquire and difficult to modify for specific use cases. This article documents the design and fabrication of a wireless implantable device using only commercially available off-the-shelf (COTS) components. This device, called the Bionode, can record and transmit up to four channels of biopotential data while simultaneously providing biphasic constant-current stimulation. The Bionode is a viable, low-cost, reusable, and easily modifiable research tool with clinical implications that has gained widespread use in various research projects at Purdue University.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2917045187",
    "type": "article"
  },
  {
    "title": "MOOS",
    "doi": "https://doi.org/10.1145/3358206",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Aryan Deshwal; Nitthilan Kannappan Jayakodi; Biresh Kumar Joardar; Janardhan Rao Doppa; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "The growing needs of emerging applications has posed significant challenges for the design of optimized manycore systems. Network-on-Chip (NoC) enables the integration of a large number of processing elements (PEs) in a single die. To design optimized manycore systems, we need to establish suitable trade-offs among multiple objectives including power, performance, and thermal. Therefore, we consider multi-objective design space exploration (MO-DSE) problems arising in the design of NoC-enabled manycore systems: placement of PEs and communication links to optimize two or more objectives (e.g., latency, energy, and throughput). Existing algorithms to solve MO-DSE problems suffer from scalability and accuracy challenges as size of the design space and the number of objectives grow. In this paper, we propose a novel framework referred as Multi-Objective Optimistic Search (MOOS) that performs adaptive design space exploration using a data-driven model to improve the speed and accuracy of multi-objective design optimization process. We apply MOOS to design both 3D heterogeneous and homogeneous manycore systems using Rodinia, PARSEC, and SPLASH2 benchmark suites. We demonstrate that MOOS improves the speed of finding solutions compared to state-of-the-art methods by up to 13X while uncovering designs that are up to 20% better in terms of NoC. The optimized 3D manycore systems improve the EDP up to 38% when compared to 3D mesh-based designs optimized for the placement of PEs.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2979967650",
    "type": "article"
  },
  {
    "title": "Overcoming Security Vulnerabilities in Deep Learning--based Indoor Localization Frameworks on Mobile Devices",
    "doi": "https://doi.org/10.1145/3362036",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Saideep Tiku; Sudeep Pasricha",
    "corresponding_authors": "",
    "abstract": "Indoor localization is an emerging application domain for the navigation and tracking of people and assets. Ubiquitously available Wi-Fi signals have enabled low-cost fingerprinting-based localization solutions. Further, the rapid growth in mobile hardware capability now allows high-accuracy deep learning--based frameworks to be executed locally on mobile devices in an energy-efficient manner. However, existing deep learning--based indoor localization solutions are vulnerable to access point (AP) attacks. This article presents an analysis into the vulnerability of a convolutional neural network--based indoor localization solution to AP security compromises. Based on this analysis, we propose a novel methodology to maintain indoor localization accuracy, even in the presence of AP attacks. The proposed secured neural network framework (S-CNNLOC) is validated across a benchmark suite of paths and is found to deliver up to 10× more resiliency to malicious AP attacks compared to its unsecured counterpart.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2983658668",
    "type": "article"
  },
  {
    "title": "Event-B Hybridation",
    "doi": "https://doi.org/10.1145/3448270",
    "publication_date": "2021-05-13",
    "publication_year": 2021,
    "authors": "Guillaume Dupont; Yamine Aït‐Ameur; Neeraj Kumar Singh; Marc Pantel",
    "corresponding_authors": "",
    "abstract": "Hybrid systems are complex systems where a software controller interacts with a physical environment, usually named a plant, through sensors and actuators. The specification and design of such systems usually rely on the description of both continuous and discrete behaviours. From complex embedded systems to autonomous vehicles, these systems became quite common, including in safety critical domains. However, their formal verification and validation as a whole is still a challenge. To address this challenge, this article contributes to the definition of a reusable and tool supported formal framework handling the design and verification of hybrid system models that integrate both discrete (the controller part) and continuous (the plant part) behaviours. This framework includes the development of a process for defining a class of basic theories and developing domain theories and then the use of these theories to develop a generic model and system-specific models. To realise this framework, we present a formal proof tool chain, based on the Event-B correct-by-construction method and its integrated development environment Rodin, to develop a set of theories, a generic model, proof processes, and the required properties for designing hybrid systems in Event-B. Our approach relies on hybrid automata as basic models for such systems. Discrete and continuous variables model system states and behaviours are given using discrete state changes and continuous evolution following a differential equation. The proposed approach is based on refinement and proof using the Event-B method and the Rodin toolset. Two case studies borrowed from the literature are used to illustrate our approach. An assessment of the proposed approach is provided for evaluating its extensibility, effectiveness, scalability, and usability.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3163059246",
    "type": "article"
  },
  {
    "title": "Towards an Integrated Vehicle Management System in DriveOS",
    "doi": "https://doi.org/10.1145/3477013",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Soham Sinha; Richard West",
    "corresponding_authors": "",
    "abstract": "Modern automotive systems feature dozens of electronic control units (ECUs) for chassis, body and powertrain functions. These systems are costly and inflexible to upgrade, requiring ever increasing numbers of ECUs to support new features such as advanced driver assistance (ADAS), autonomous technologies, and infotainment. To counter these challenges, we propose DriveOS, a safe, secure, extensible, and timing-predictable system for modern vehicle management in a centralized platform. DriveOS is based on a separation kernel, where timing and safety-critical ECU functions are implemented in a real-time OS (RTOS) alongside non-critical software in Linux or Android. The system enforces the separation, or partitioning, of both software and hardware among different OSes. DriveOS runs on a relatively low-cost embedded PC-class platform, supporting multiple cores and hardware virtualization capabilities. Instrument cluster, in-vehicle infotainment and advanced driver assistance system services are implemented in a Yocto Linux guest, which communicates with critical real-time services via secure shared memory. The RTOS manages a real-time controller area network (CAN) interface that is inaccessible to Linux services except via well-defined and legitimate communication channels. In this work, we integrate three Qt-based services written for Yocto Linux, running in parallel with a real-time longitudinal controller task and multiple CAN bus concentrators, for vehicular sensor data processing and actuation. We demonstrate the benefits and performance of DriveOS with a hardware-in-the-loop CARLA simulation using a real car dataset.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3199978469",
    "type": "article"
  },
  {
    "title": "Improving Performance-Power-Programmability in Space Avionics with Edge Devices: VBN on Myriad2 SoC",
    "doi": "https://doi.org/10.1145/3440885",
    "publication_date": "2021-03-27",
    "publication_year": 2021,
    "authors": "Vasileios Leon; George Lentaris; Evangelos Petrongonas; Dimitrios Soudris; Gianluca Furano; Antonis Tavoularis; David Moloney",
    "corresponding_authors": "",
    "abstract": "The advent of powerful edge devices and AI algorithms has already revolutionized many terrestrial applications; however, for both technical and historical reasons, the space industry is still striving to adopt these key enabling technologies in new mission concepts. In this context, the current work evaluates an heterogeneous multi-core system-on-chip processor for use on-board future spacecraft to support novel, computationally demanding digital signal processors and AI functionalities. Given the importance of low power consumption in satellites, we consider the Intel Movidius Myriad2 system-on-chip and focus on SW development and performance aspects. We design a methodology and framework to accommodate efficient partitioning, mapping, parallelization, code optimization, and tuning of complex algorithms. Furthermore, we propose an avionics architecture combining this commercial off-the-shelf chip with a field programmable gate array device to facilitate, among others, interfacing with traditional space instruments via SpaceWire transcoding. We prototype our architecture in the lab targeting vision-based navigation tasks. We implement a representative computer vision pipeline to track the 6D pose of ENVISAT using megapixel images during hypothetical spacecraft proximity operations. Overall, we achieve 2.6 to 4.9 FPS with only 0.8 to 1.1 W on Myriad2 , i.e., 10-fold acceleration versus modern rad-hard processors. Based on the results, we assess various benefits of utilizing Myriad2 instead of conventional field programmable gate arrays and CPUs.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3144975499",
    "type": "article"
  },
  {
    "title": "An Efficient CNN Accelerator for Low-Cost Edge Systems",
    "doi": "https://doi.org/10.1145/3539224",
    "publication_date": "2022-05-26",
    "publication_year": 2022,
    "authors": "Kyubaik Choi; Gerald E. Sobelman",
    "corresponding_authors": "",
    "abstract": "Customized hardware based convolutional neural network ( CNN or ConvNet ) accelerators have attracted significant attention for applications in a low-cost, edge computing system. However, there is a lack of research that seeks to optimize at both the algorithm and hardware levels simultaneously in resource-constrained FPGA systems. In this paper, we first analyze ConvNet models to find one that is most suitable for a low-cost FPGA implementation. Based on the analysis, we select MobileNetV2 as the backbone of our research due to its hardware-friendly structure. We use a quantized implementation with 4-bit precision and optimize further with a smaller input resolution of 192 × 192 to obtain a 68.8% detection accuracy on ImageNet, which represents only a 3.2% accuracy loss compared to a floating-point model that uses the full input size. We then develop a hardware implementation that uses a low-cost FPGA. To accelerate the depth-wise separable ConvNet and utilize DRAM resources efficiently with parallel processing, we propose a novel scoreboard architecture to dynamically schedule DRAM data requests in order to maintain a high hardware utilization. The number of DSP blocks used is about six times smaller than in prior work. In addition, internal block RAM utilization is approximately nine times more efficient than in prior work. Our proposed design achieves 3.07 frames per second (FPS) on the low-cost and resource constrained FPGA system.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4281562926",
    "type": "article"
  },
  {
    "title": "An Energy-Efficient DRAM Cache Architecture for Mobile Platforms With PCM-Based Main Memory",
    "doi": "https://doi.org/10.1145/3451995",
    "publication_date": "2022-01-14",
    "publication_year": 2022,
    "authors": "Dongsuk Shin; Hakbeom Jang; Kiseok Oh; Jae W. Lee",
    "corresponding_authors": "",
    "abstract": "A long battery life is a first-class design objective for mobile devices, and main memory accounts for a major portion of total energy consumption. Moreover, the energy consumption from memory is expected to increase further with ever-growing demands for bandwidth and capacity. A hybrid memory system with both DRAM and PCM can be an attractive solution to provide additional capacity and reduce standby energy. Although providing much greater density than DRAM, PCM has longer access latency and limited write endurance to make it challenging to architect it for main memory. To address this challenge, this article introduces CAMP, a novel DRAM c ache a rchitecture for m obile platforms with P CM-based main memory. A DRAM cache in this environment is required to filter most of the writes to PCM to increase its lifetime, and deliver highest efficiency even for a relatively small-sized DRAM cache that mobile platforms can afford. To address this CAMP divides DRAM space into two regions: a page cache for exploiting spatial locality in a bandwidth-efficient manner and a dirty block buffer for maximally filtering writes. CAMP improves the performance and energy-delay-product by 29.2% and 45.2%, respectively, over the baseline PCM-oblivious DRAM cache, while increasing PCM lifetime by 2.7×. And CAMP also improves the performance and energy-delay-product by 29.3% and 41.5%, respectively, over the state-of-the-art design with dirty block buffer, while increasing PCM lifetime by 2.5×.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4206315322",
    "type": "article"
  },
  {
    "title": "Secure and Lightweight Blockchain-based Truthful Data Trading for Real-Time Vehicular Crowdsensing",
    "doi": "https://doi.org/10.1145/3582008",
    "publication_date": "2023-01-25",
    "publication_year": 2023,
    "authors": "Haitao Xu; Saiyu Qi; Yong Qi; Wei Wei; Naixue Xiong",
    "corresponding_authors": "",
    "abstract": "As the number of smart cars grows rapidly, vehicular crowdsensing (VCS) is gradually becoming popular. In a VCS infrastructure, sensing devices and computing units hold on smart cars as well as cloud servers form an IoT-edge-cloud continuum to perform real-time sensing tasks. In order to encourage the smart cars to participate in the real-time VCS process, blockchain technology can be combined with VCS to provide an automated incentive for VCS data trading without relying on trusted third parties. However, directly using blockchain to enforce the VCS data trading process incurs expensive service fees and participants still can conduct various misbehavior. In this article, we propose a secure blockchain-based data trading system for VCS named BTT system to address the above issues. In particular, we first integrate the blockchain-based data trading process with a lightweight privacy-preserving truth discovery algorithm to ensure the accuracy of sensing data while preserving data privacy. We then propose a gas-aware optimization mechanism to minimize the gas consumption of the data trading process. Finally, we carefully design a distributed judgment mechanism to regulate all participants to behave correctly in the data trading process. To demonstrate the practicability of our design, we implement a prototype of the BTT system deployed on an Ethereum test network and conduct extensive simulations.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4318041137",
    "type": "article"
  },
  {
    "title": "An Ultra-low-power Embedded AI Fire Detection and Crowd Counting System for Indoor Areas",
    "doi": "https://doi.org/10.1145/3582433",
    "publication_date": "2023-02-13",
    "publication_year": 2023,
    "authors": "Alexios Papaioannou; C. Kouzinopoulos; Dimosthenis Ioannidis; Dimitrios Tzovaras",
    "corresponding_authors": "",
    "abstract": "Fire incidents in residential and industrial areas are often the cause of human casualties and property damage. Although there are existing systems that detect fire and monitor the presence of people in indoor areas, research on their implementation in embedded platforms is limited. This article introduces an ultra-low-power embedded system for fire detection and crowd counting using efficient deep learning methods. For the prediction of fire occurrences, environmental and gas sensor along with multilayer perceptron nodes are used. For crowd counting, a custom lightweight version of YOLOv5 is introduced, using an architecture based on ShuffleNetV2, resulting in a model with low memory requirements, high accuracy predictions, and fast inference on an embedded platform. The accuracy, power consumption, and memory requirements of the proposed system are evaluated using public datasets and datasets acquired by the environmental and image sensors, and its performance is compared to that of existing approaches.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4320498313",
    "type": "article"
  },
  {
    "title": "Hierarchical Resource Orchestration Framework for Real-time Containers",
    "doi": "https://doi.org/10.1145/3592856",
    "publication_date": "2023-04-25",
    "publication_year": 2023,
    "authors": "Václav Struhár; Silviu S. Craciunas; Mohammad Ashjaei; Moris Behnam; Alessandro Vittorio Papadopoulos",
    "corresponding_authors": "",
    "abstract": "Container-based virtualization is a promising deployment model in fog and edge computing applications, because it allows a seamless co-existence of virtualized applications in a heterogeneous environment without introducing significant overhead. Certain application domains (e.g., industrial automation, automotive, or aerospace) mandate that applications exhibit a certain degree of temporal predictability. Container-based virtualization cannot be easily used for such applications, since the technology is not designed to support real-time properties and handle temporal disturbances. This article proposes a framework consisting of a static offline and a dynamic online phase for resource allocation and adaptive re-dimensioning of real-time containers. In the offline phase, the optimal initial deployment and dimensioning of containers are decided based on ideal system models. Additionally, to adapt to dynamic variations caused by changing workloads or interferences, the online phase adapts the CPU usage and limits of real-time containers at runtime to improve the real-time behavior of the real-time containerized applications while optimizing resource usage. We implement the framework in a real Linux-based system and show through a series of experiments that the proposed framework is able to adjust and re-distribute computing resources between containers to improve the real-time behavior of containerized applications in the presence of temporal disturbances while optimizing resource usage.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4366985282",
    "type": "article"
  },
  {
    "title": "Florets for Chiplets: Data Flow-aware High-Performance and Energy-efficient Network-on-Interposer for CNN Inference Tasks",
    "doi": "https://doi.org/10.1145/3608098",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Harsh Sharma; Lukas Pfromm; Rasit Onur Topaloglu; Janardhan Rao Doppa; Ümit Y. Ogras; Ananth Kalyanraman; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Recent advances in 2.5D chiplet platforms provide a new avenue for compact scale-out implementations of emerging compute- and data-intensive applications including machine learning. Network-on-Interposer (NoI) enables integration of multiple chiplets on a 2.5D system. While these manycore platforms can deliver high computational throughput and energy efficiency by running multiple specialized tasks concurrently, conventional NoI architectures have a limited computational throughput due to their inherent multi-hop topologies. In this paper, we propose Floret, a novel NoI architecture based on space-filling curves (SFCs). The Floret architecture leverages suitable task mapping, exploits the data flow pattern, and optimizes the inter-chiplet data exchange to extract high performance for multiple types of convolutional neural network (CNN) inference tasks running concurrently. We demonstrate that the Floret architecture reduces the latency and energy up to 58% and 64%, respectively, compared to state-of-the-art NoI architectures while executing datacenter-scale workloads involving multiple CNN tasks simultaneously. Floret achieves high performance and significant energy savings with much lower fabrication cost by exploiting the data-flow awareness of the CNN inference tasks.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4386568732",
    "type": "article"
  },
  {
    "title": "DASS: Differentiable Architecture Search for Sparse Neural Networks",
    "doi": "https://doi.org/10.1145/3609385",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Hamid Mousavi; Mohammad Loni; Mina Alibeigi; Masoud Daneshtalab",
    "corresponding_authors": "",
    "abstract": "The deployment of Deep Neural Networks (DNNs) on edge devices is hindered by the substantial gap between performance requirements and available computational power. While recent research has made significant strides in developing pruning methods to build a sparse network for reducing the computing overhead of DNNs, there remains considerable accuracy loss, especially at high pruning ratios. We find that the architectures designed for dense networks by differentiable architecture search methods are ineffective when pruning mechanisms are applied to them. The main reason is that the current methods do not support sparse architectures in their search space and use a search objective that is made for dense networks and does not focus on sparsity. This paper proposes a new method to search for sparsity-friendly neural architectures. It is done by adding two new sparse operations to the search space and modifying the search objective. We propose two novel parametric SparseConv and SparseLinear operations in order to expand the search space to include sparse operations. In particular, these operations make a flexible search space due to using sparse parametric versions of linear and convolution operations. The proposed search objective lets us train the architecture based on the sparsity of the search space operations. Quantitative analyses demonstrate that architectures found through DASS outperform those used in the state-of-the-art sparse networks on the CIFAR-10 and ImageNet datasets. In terms of performance and hardware effectiveness, DASS increases the accuracy of the sparse version of MobileNet-v2 from 73.44% to 81.35% (+7.91% improvement) with a 3.87× faster inference time.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4386580453",
    "type": "article"
  },
  {
    "title": "Code Generation For Neural Networks Based On Fixed-Point Arithmetic",
    "doi": "https://doi.org/10.1145/3563945",
    "publication_date": "2024-08-14",
    "publication_year": 2024,
    "authors": "Hanane Benmaghnia; Matthieu Martel; Yassamine Seladji",
    "corresponding_authors": "",
    "abstract": "Over the past few years, neural networks have started penetrating safety critical systems to make decisions as, for example, in robots, rockets, and autonomous driving cars. Neural networks based on floating-point arithmetic are very time and memory consuming, which are not compatible with embedded systems known to have limited resources. They are also very sensitive to the precision in which they have been trained, so changing this precision generally degrades the quality of their answers. To deal with that, we introduce a new technique to generate a fixed-point code for a trained neural network. This technique is based on fixed-point arithmetic with mixed-precision. This arithmetic is based on integer operations only, which are compatible with small memory devices. The obtained neural network has the same behavior as the initial one (based on the floating-point arithmetic) up to an error threshold defined by the user. The experimental results show the efficiency of our tool SyFix in terms of memory saved and the accuracy of the computations.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4295979716",
    "type": "article"
  },
  {
    "title": "Fast Loosely-Timed Deep Neural Network Models with Accurate Memory Contention",
    "doi": "https://doi.org/10.1145/3607548",
    "publication_date": "2024-08-14",
    "publication_year": 2024,
    "authors": "Emad Arasteh; Rainer Dömer",
    "corresponding_authors": "",
    "abstract": "The emergence of data-intensive applications, such as Deep Neural Networks (DNN), exacerbates the well-known memory bottleneck in computer systems and demands early attention in the design flow. Electronic System-Level (ESL) design using SystemC Transaction Level Modeling (TLM) enables effective performance estimation, design space exploration (DSE), and gradual refinement. However, memory contention is often only detectable after detailed TLM-2.0 approximately-timed or cycle-accurate RTL models are developed. A memory bottleneck detected at such a late stage can severely limit the available design choices or even require costly redesign. In this work, we propose a novel TLM-2.0 loosely-timed contention-aware (LT-CA) modeling style that offers high-speed simulation close to traditional loosely-timed (LT) models, yet shows the same accuracy for memory contention as low-level approximately-timed (AT) models. Thus, our proposed LT-CA modeling breaks the speed/accuracy tradeoff between regular LT and AT models and offers fast and accurate observation and visualization of memory contention. Our extensible SystemC model generator automatically produces desired TLM-1 and TLM-2.0 models from a DNN architecture description for design space exploration focusing on memory contention. We demonstrate our approach with a real-world industry-strength DNN application, GoogLeNet. The experimental results show that the proposed LT-CA modeling is 46× faster in simulation than equivalent AT models with an average error of less than 1% in simulated time. Early detection of memory contentions also suggests that local memories close to computing cores can eliminate memory contention in such applications.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4384339318",
    "type": "article"
  },
  {
    "title": "Stash: Flexible Energy Storage for Intermittent Sensors",
    "doi": "https://doi.org/10.1145/3641511",
    "publication_date": "2024-01-19",
    "publication_year": 2024,
    "authors": "Arwa Alsubhi; Simeon Babatunde; Nicole Tobias; Jacob Sorber",
    "corresponding_authors": "",
    "abstract": "Batteryless sensors promise a sustainable future for sensing, but they face significant challenges when storing and using environmental energy. Incoming energy can fluctuate unpredictably between periods of scarcity and abundance, and device performance depends on both incoming energy and how much a device can store. Existing batteryless devices have used fixed or run-time selectable front-end capacitor banks to meet the energy needs of different tasks. Neither approach adapts well to rapidly changing energy harvesting conditions, nor does it allow devices to store excess energy during times of abundance without sacrificing performance. This article presents Stash, a hardware back-end energy storage technique that allows batteryless devices to charge quickly and store excess energy when it is abundant, extending their operating time and carrying out additional tasks without compromising the main ones. Stash performs like a small capacitor device when small capacitors excel and like a large capacitor device when large capacitors excel, with no additional software complexity and negligible power overhead. We evaluate Stash using two applications—temperature sensing and wearable activity monitoring—under both synthetic solar energy and recorded solar and thermal traces from various human activities. Our results show that Stash increased sensor coverage by up to 15% under variable energy-harvesting conditions when compared to competitor configurations that used fixed small, large, and reconfigurable front-end energy storage.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4391026426",
    "type": "article"
  },
  {
    "title": "Intelligent Caching for Vehicular Dew Computing in Poor Network Connectivity Environments",
    "doi": "https://doi.org/10.1145/3643038",
    "publication_date": "2024-01-25",
    "publication_year": 2024,
    "authors": "Liang Zhao; Hongxuan Li; Enchao Zhang; Ammar Hawbani; Ming‐Wei Lin; Shaohua Wan; Mohsen Guizani",
    "corresponding_authors": "",
    "abstract": "In vehicular networks, some edge servers may not function properly due to the time-varying load condition and the uneven computing resource distribution, resulting in a low quality of caching services. To overcome this challenge, we develop a Vehicular dew computing (VDC) architecture for the first time by combining dew computing with vehicular networks, which can achieve wireless communication between vehicles in a resource-constrained environment. Consequently, it is crucial to develop an adaptive caching scheme that empowers vehicles to form efficient cooperation in VDC. In this paper, we propose an intelligent caching scheme based on VDC architecture, which includes two parts. First, to meet the dynamic nature of VDC, a spatiotemporal vehicle clustering algorithm is proposed to establish adaptive cooperation to assist content caching for vehicles. Second, the multi-armed bandit algorithm is employed to select suitable content for caching in vehicles based on real-time file popularity, and a model is established to dynamically update each vehicle’s request preferences. Extensive experiments are conducted to demonstrate that the proposed scheme has excellent performance in terms of cluster head stability and cache hit rate.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4391221839",
    "type": "article"
  },
  {
    "title": "TREAFET: Temperature-Aware Real-Time Task Scheduling for FinFET based Multicores",
    "doi": "https://doi.org/10.1145/3665276",
    "publication_date": "2024-05-16",
    "publication_year": 2024,
    "authors": "Shounak Chakraborty; Yanshul Sharma; Sanjay Moulik",
    "corresponding_authors": "",
    "abstract": "The recent shift in the VLSI industry from conventional MOSFET to FinFET for designing contemporary chip-multiprocessor (CMP) has noticeably improved hardware platforms’ computing capabilities, but at the cost of several thermal issues. Unlike the conventional MOSFET, FinFET devices experience a significant increase in circuit speed at a higher temperature, called temperature effect inversion (TEI), but higher temperature can also curtail the circuit lifetime due to self-heating effects (SHEs). These fundamental thermal properties of FinFET introduced a new challenge for scheduling time-critical tasks on FinFET-based multicores that how to exploit TEI towards improving performance while combating SHEs. In this work, TREAFET , a temperature-aware real-time scheduler, attempts to exploit the TEI feature of FinFET-based multicores in a time-critical computing paradigm. At first, the overall progress of individual tasks is monitored, tasks are allocated to the cores, and finally, a schedule is prepared. By considering the thermal profiles of the individual tasks and the current thermal status of the cores, hot tasks are assigned to the cold cores and vice-versa. Finally, the performance and temperature are balanced on-the-fly by incorporating a prudential voltage scaling towards exploiting TEI while guaranteeing the deadline and thermal safety. Moreover, TREAFET stimulates the average runtime frequency by employing an opportunistic energy-adaptive voltage spiking mechanism, in which energy saving during memory stalls at the cores is traded off during the time slice having the spiked voltage. Simulation results claim TREAFET maintains a safe and stable thermal status (peak temperature below 80 °C) and improves frequency up to 17% over the assigned value, which ensures legitimate time-critical performance for a variety of workloads while surpassing a state-of-the-art technique. The stimulated frequency in TREAFET also finishes the tasks early, thus providing opportunities to save energy by power gating the cores, and achieves a 24% energy delay product (EDP) gain on average.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4396956720",
    "type": "article"
  },
  {
    "title": "A design flow for partially reconfigurable hardware",
    "doi": "https://doi.org/10.1145/993396.993399",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Ian Robertson; James Irvine",
    "corresponding_authors": "",
    "abstract": "This paper presents a top-down designer-driven design flow for creating hardware that exploits partial run-time reconfiguration. Computer-aided design (CAD) tools are presented, which complement conventional FPGA design environments to enable the specification, simulation (both functional and timing), synthesis, automatic placement and routing, partial configuration generation and control of partially reconfigurable designs. Collectively these tools constitute the dynamic circuit switching CAD framework. A partially reconfigurable Viterbi decoder design is presented to demonstrate the design flow and illustrate possible power consumption reductions and performance improvements through the exploitation of partial reconfiguration.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2029850906",
    "type": "article"
  },
  {
    "title": "Memory safety without garbage collection for embedded applications",
    "doi": "https://doi.org/10.1145/1053271.1053275",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Dinakar Dhurjati; Sumant Kowshik; Vikram Adve; Chris Lattner",
    "corresponding_authors": "",
    "abstract": "Traditional approaches to enforcing memory safety of programs rely heavily on run-time checks of memory accesses and on garbage collection, both of which are unattractive for embedded applications. The goal of our work is to develop advanced compiler techniques for enforcing memory safety with minimal run-time overheads. In this paper, we describe a set of compiler techniques that, together with minor semantic restrictions on C programs and no new syntax, ensure memory safety and provide most of the error-detection capabilities of type-safe languages, without using garbage collection, and with no run-time software checks, (on systems with standard hardware support for memory management). The language permits arbitrary pointer-based data structures, explicit deallocation of dynamically allocated memory, and restricted array operations. One of the key results of this paper is a compiler technique that ensures that dereferencing dangling pointers to freed memory does not violate memory safety, without annotations, run-time checks, or garbage collection , and works for arbitrary type-safe C programs. Furthermore, we present a new interprocedural analysis for static array bounds checking under certain assumptions. For a diverse set of embedded C programs, we show that we are able to ensure memory safety of pointer and dynamic memory usage in all these programs with no run-time software checks (on systems with standard hardware memory protection), requiring only minor restructuring to conform to simple type restrictions. Static array bounds checking fails for roughly half the programs we study due to complex array references, and these are the only cases where explicit run-time software checks would be needed under our language and system assumptions.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2063453797",
    "type": "article"
  },
  {
    "title": "Dynamic voltage scheduling with buffers in low-power multimedia applications",
    "doi": "https://doi.org/10.1145/1027794.1027796",
    "publication_date": "2004-11-01",
    "publication_year": 2004,
    "authors": "Chaeseok Im; Soonhoi Ha; Huiseok Kim",
    "corresponding_authors": "",
    "abstract": "Power-efficient design of multimedia applications becomes more important as they are used increasingly in many embedded systems. We propose a simple dynamic voltage scheduling (DVS) technique, which suits multimedia applications well and, in case of soft real-time applications, allows all idle intervals of the processor to be fully exploited by using buffers. Our main theme is to determine the minimum buffer size to maximize energy saving in three cases: (i) single task, (ii) multiple subtask, and (iii) multitask. We also present a technique of adjusting task deadlines for further reducing energy consumption in the multiple-subtask and multitask cases. Unlike other DVS techniques using buffers, we guarantee to meet the real-time latency constraint. Experimental results show that the proposed technique does indeed achieve significant power reduction in real-world multimedia applications.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2064591131",
    "type": "article"
  },
  {
    "title": "Efficient digit-serial normal basis multipliers over binary extension fields",
    "doi": "https://doi.org/10.1145/1015047.1015053",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "Arash Reyhani-Masoleh; M.A. Hasan",
    "corresponding_authors": "",
    "abstract": "In this article, two digit-serial architectures for normal basis multipliers over ( GF (2 m )) are presented. These two structures have the same gate count and gate delay. We also consider two special cases of optimal normal bases for the two digit-serial architectures. A straightforward implementation leaves gate redundancy in both of them. An algorithm that can considerably reduce the redundancy is also developed. The proposed architectures are compared with the existing ones in terms of gate and time complexities.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W1978673726",
    "type": "article"
  },
  {
    "title": "An overview of embedded system design education at berkeley",
    "doi": "https://doi.org/10.1145/1086519.1086521",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Alberto Sangiovanni‐Vincentelli; Alessandro Pinto",
    "corresponding_authors": "",
    "abstract": "Embedded systems have been a traditional area of strength in the research agenda of the University of California at Berkeley. In parallel to this effort, a pattern of graduate and undergraduate classes has emerged that is the result of a distillation process of the research results. In this paper, we present the considerations that are driving our curriculum development and we review our undergraduate and graduate program. In particular, we describe in detail a graduate class (EECS249: Design of Embedded Systems: Modeling, Validation and Synthesis) that has been taught for six years. A common feature of our education agenda is the search for fundamentals of embedded system science rather than embedded system design techniques, an approach that today is rather unique.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W1986895635",
    "type": "article"
  },
  {
    "title": "Dynamic delay-constrained minimum-energy dissemination in wireless sensor networks",
    "doi": "https://doi.org/10.1145/1086519.1086530",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Hyung Seok Kim; Tarek Abdelzaher; Wook Hyun Кwon",
    "corresponding_authors": "",
    "abstract": "Disseminating data generated by sensors to users is one of useful functions of sensor networks. In probable real-time applications of sensor networks, multiple mobile users should receive data within their end-to-end delay constraint. In this paper, we propose a dynamic DElay-constrained minimum-Energy Dissemination (DEED) scheme. A dissemination tree (d-tree) is updated in a distributed way without regenerating the tree from scratch, such that energy consumption of the tree is minimized while satisfying end-to-end delay constraints. The d-tree is adjusted using delay estimation based on geometric distance. DEED increases the probability that packets arrive at users within an upper-bound end-to-end delay (UBED) and minimizes energy consumption in both building the d-tree and disseminating data to mobile sinks. Evaluation results show that DEED makes each node consume small energy resources and maintains fewer UBED misses when compared to Directed Diffusion and other baselines for sensor networks.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2067853683",
    "type": "article"
  },
  {
    "title": "A control theoretic approach to energy-efficient pipelined computation in MPSoCs",
    "doi": "https://doi.org/10.1145/1274858.1274865",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Salvatore Carta; A. Alimonda; Alessandro Pisano; Andrea Acquaviva; Luca Benini",
    "corresponding_authors": "",
    "abstract": "In this work, we describe a control theoretic approach to dynamic voltage/frequency scaling (DVFS) in a pipelined MPSoC architecture with soft real-time constraints, aimed at minimizing energy consumption with throughput guarantees. Theoretical analysis and experiments carried out on a cycle-accurate, energy-aware, and multiprocessor simulation platform are provided. We give a dynamic model of the system behavior which allows to synthesize linear and nonlinear feedback control schemes for the run-time adjustment of the core frequencies. We study the characteristics of the proposed techniques in both transient and steady-state conditions. Finally, we compare the proposed feedback approaches and local DVFS policies from an energy consumption viewpoint.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2147742154",
    "type": "article"
  },
  {
    "title": "Scalable precision cache analysis for real-time software",
    "doi": "https://doi.org/10.1145/1274858.1274863",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Jan Staschulat; Rolf Ernst",
    "corresponding_authors": "",
    "abstract": "Caches are needed to increase the processor performance, but the temporal behavior is difficult to predict, especially in embedded systems with preemptive scheduling. Current approaches use simplified assumptions or propose complex analysis algorithms to bound the cache-related preemption delay. In this paper, a scalable preemption delay analysis for associative instruction caches to control the analysis precision and the time-complexity is proposed. An accurate preemption delay calculation is integrated into a cache-aware schedulability analysis. The framework is evaluated in several experiments.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2078921946",
    "type": "article"
  },
  {
    "title": "Energy-optimizing source code transformations for operating system-driven embedded software",
    "doi": "https://doi.org/10.1145/1324969.1324971",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Yunsi Fei; Srivaths Ravi; Anand Raghunathan; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "This paper proposes four types of source code transformations for operating system (OS)-driven embedded software programs to reduce their energy consumption. Their key features include spanning of process boundaries and minimization of the energy consumed in the execution of OS services—opportunities which are beyond the reach of conventional compiler optimizations and source code transformations. We have applied the proposed transformations to several multiprocess benchmark programs in the context of an embedded Linux OS running on an Intel StrongARM processor. They achieve up to 37.9% (23.8%, on average) energy reduction compared to highly compiler-optimized implementations.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2083774192",
    "type": "article"
  },
  {
    "title": "Link-time compaction and optimization of ARM executables",
    "doi": "https://doi.org/10.1145/1210268.1210273",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Bjorn De Sutter; Ludo Van Put; Dominique Chanet; Bruno De Bus; Koen De Bosschere",
    "corresponding_authors": "",
    "abstract": "The overhead in terms of code size, power consumption, and execution time caused by the use of precompiled libraries and separate compilation is often unacceptable in the embedded world, where real-time constraints, battery life-time, and production costs are of critical importance. In this paper, we present our link-time optimizer for the ARM architecture. We discuss how we can deal with the peculiarities of the ARM architecture related to its visible program counter and how the introduced overhead can to a large extent be eliminated. Our link-time optimizer is evaluated with four tool chains, two proprietary ones from ARM and two open ones based on GNU GCC. When used with proprietary tool chains from ARM Ltd., our link-time optimizer achieved average code size reductions of 16.0 and 18.5%, while the programs have become 12.8 and 12.3% faster, and 10.7 to 10.1% more energy efficient. Finally, we show how the incorporation of link-time optimization in tool chains may influence library interface design.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2028800816",
    "type": "article"
  },
  {
    "title": "The XTREM power and performance simulator for the Intel XScale core",
    "doi": "https://doi.org/10.1145/1210268.1210272",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Gilberto Contreras; Margaret Martonosi; Jinzhang Peng; Guei-Yuan Lueh; Roy Dz-Ching Ju",
    "corresponding_authors": "",
    "abstract": "Managing power concerns in microprocessors has become a pressing research problem across the domains of computer architecture, CAD, and compilers. As a result, several parameterized cycle-level power simulators have been introduced. While these simulators can be quite useful for microarchitectural studies, their generality limits how accurate they can be for any one chip family. Furthermore, their hardware focus means that they do not explicitly enable studying the interaction of different software layers, such as Java applications and their underlying runtime system software. This paper describes and evaluates XTREM, a power-simulation tool tailored for the Intel XScale microarchitecture. In building XTREM, our goals were to develop a microarchitecture simulator that, while still offering size parameterizations for cache and other structures, more accurately reflected a realistic processor pipeline. We present a detailed set of validations based on multimeter power measurements and hardware performance counter sampling. XTREM exhibits an average performance error of only 6.5% and an even smaller average power error: 4%. The paper goes on to present an application study enabled by the simulator. Namely, we use XTREM to produce an energy consumption breakdown for Java CDC and CLDC applications. Our simulator measurements indicate that a large percentage of the total energy consumption (up to 35%) is devoted to the virtual machine's support functions.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W1987805948",
    "type": "article"
  },
  {
    "title": "System-wide energy minimization for real-time tasks",
    "doi": "https://doi.org/10.1145/1347375.1347381",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Xiliang Zhong; Chengzhong Xu",
    "corresponding_authors": "",
    "abstract": "We present a dynamic voltage scaling (DVS) technique that minimizes system-wide energy consumption for both periodic and sporadic tasks. It is known that a system consists of processors and a number of other components. Energy-aware processors can be run in different speed levels; components like memory and I/O subsystems and network interface cards can be in a standby state when they are active, but idle. Processor energy optimization solutions are not necessarily efficient from the perspective of systems. Current system-wide energy optimization studies are often limited to periodic tasks with heuristics in getting approximated solutions. In this paper, we develop an exact dynamic programming algorithm for periodic tasks on processors with practical discrete speed levels. The algorithm determines the lower bound of energy expenditure in pseudopolynomial time. An approximation algorithm is proposed to provide performance guarantee with a given bound in polynomial running time. Because of their time efficiency, both the optimization and approximation algorithms can be adapted for online scheduling of sporadic tasks with irregular task releases. We prove that system-wide energy optimization for sporadic tasks is NP-hard in the strong sense. We develop (pseudo-) polynomial-time solutions by exploiting its inherent properties.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W1996511375",
    "type": "article"
  },
  {
    "title": "SystemC/C-based model-driven design for embedded systems",
    "doi": "https://doi.org/10.1145/1550987.1550993",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Elvinia Riccobene; Patrizia Scandurra; S. Bocchio; Alberto Rosti; Luigi Lavazza; Luigi Mantellini",
    "corresponding_authors": "",
    "abstract": "This article summarizes our effort, since 2004 up to the present time, for improving the current industrial Systems-on-Chip and Embedded Systems design by joining the capabilities of the unified modeling language (UML) and SystemC/C programming languages to operate at system-level. The proposed approach exploits the OMG model-driven architecture—a framework for Model-driven Engineering—capabilities of reducing abstract, coarse-grained and platform-independent system models to fine-grained and platform-specific models. We first defined a design methodology and a development flow for the hardware, based on a SystemC UML profile and encompassing different levels of abstraction. We then included a multithread C UML profile for modelling software applications. Both SystemC/C profiles are consistent sets of modelling constructs designed to lift the programming features (both structural and behavioral) of the two coding languages to the UML modeling level. The new codesign flow is supported by an environment, which allows system modeling at higher abstraction levels (from a functional executable level to a register transfer level) and supports automatic code-generation/back-annotation from/to UML models.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2011494809",
    "type": "article"
  },
  {
    "title": "GUSTO",
    "doi": "https://doi.org/10.1145/1721695.1721698",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Ali Irturk; Bridget Benson; Shahnam Mirzaei; Ryan Kastner",
    "corresponding_authors": "",
    "abstract": "Matrix inversion is a common function found in many algorithms used in wireless communication systems. As FPGAs become an increasingly attractive platform for wireless communication, it is important to understand the trade-offs in designing a matrix inversion core on an FPGA. This article describes a matrix inversion core generator tool, GUSTO, that we developed to ease the design space exploration across different matrix inversion architectures. GUSTO is the first tool of its kind to provide automatic generation of a variety of general-purpose matrix inversion architectures with different parameterization options. GUSTO also provides an optimized application-specific architecture with an average of 59% area decrease and 3X throughput increase over its general-purpose architecture. The optimized architectures generated by GUSTO provide comparable results to published matrix inversion architecture implementations, but offer the advantage of providing the designer the ability to study the trade-offs between architectures with different design parameters.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2053466962",
    "type": "article"
  },
  {
    "title": "Platform-based software design flow for heterogeneous MPSoC",
    "doi": "https://doi.org/10.1145/1376804.1376807",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Katalin Popovici; Xavier Guérin; Frédéric Rousseau; Pier Stanislao Paolucci; Ahmed Jerraya",
    "corresponding_authors": "",
    "abstract": "Current multimedia applications demand complex heterogeneous multiprocessor architectures with specific communication infrastructure in order to achieve the required performances. Programming these architectures usually results in writing separate low-level code for the different processors (DSP, microcontroller), implying late global validation of the overall application with the hardware platform. We propose a platform-based software design flow able to efficiently use the resources of the architecture and allowing easy experimentation of several mappings of the application onto the platform resources. We use a high-level environment to capture both application and architecture initial representations. An executable software stack is generated automatically for each processor from the initial model. The software generation and validation is performed gradually corresponding to different software abstraction levels. Specific software development platforms (abstract models of the architecture) are generated and used to allow debugging of the different software components with explicit hardware-software interaction. We applied this approach on a multimedia platform, involving a high performance DSP and a RISC processor, to explore communication architecture and generate an efficient executable code for a multimedia application. Based on automatic tools, the proposed flow increases productivity and preserves design quality.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2135572848",
    "type": "article"
  },
  {
    "title": "Nonblocking real-time garbage collection",
    "doi": "https://doi.org/10.1145/1814539.1814545",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Martin Schoeberl; Wolfgang Puffitsch",
    "corresponding_authors": "",
    "abstract": "A real-time garbage collector has to fulfill two basic properties: ensure that programs with bounded allocation rates do not run out of memory and provide short blocking times. Even for incremental garbage collectors, two major sources of blocking exist, namely, root scanning and heap compaction. Finding root nodes of an object graph is an integral part of tracing garbage collectors and cannot be circumvented. Heap compaction is necessary to avoid probably unbounded heap fragmentation, which in turn would lead to unacceptably high memory consumption. In this article, we propose solutions to both issues. Thread stacks are local to a thread, and root scanning, therefore, only needs to be atomic with respect to the thread whose stack is scanned. This fact can be utilized by either blocking only the thread whose stack is scanned, or by delegating the responsibility for root scanning to the application threads. The latter solution eliminates blocking due to root scanning completely. The impact of this solution on the execution time of a garbage collector is shown for two different variants of such a root scanning algorithm. During heap compaction, objects are copied. Copying is usually performed atomically to avoid interference with application threads, which could render the state of an object inconsistent. Copying of large objects and especially large arrays introduces long blocking times that are unacceptable for real-time systems. In this article, an interruptible copy unit is presented that implements nonblocking object copy. The unit can be interrupted after a single word move. We evaluate a real-time garbage collector that uses the proposed techniques on a Java processor. With this garbage collector, it is possible to run high-priority hard real-time tasks at 10 kHz parallel to the garbage collection task on a 100 MHz system.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2092364586",
    "type": "article"
  },
  {
    "title": "Closed-loop--based self-adaptive Hardware/Software-Embedded systems",
    "doi": "https://doi.org/10.1145/1952522.1952531",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Jean-Philippe Diguet; Yvan Eustache; Guy Gogniat",
    "corresponding_authors": "",
    "abstract": "This article presents our methodology for implementing self-adaptivness within an OS-based and reconfigurable embedded system according to objectives such as quality of service, performance, or power consumption. We detail our approach to separate application-specific decisions and hardware/software-implementation decisions at system level. The former are related to the efficiency control of applications and based on the knowledge of application engineers. The latter are generic and address the choice between various hardware and software implementations according to user objectives. The decision management is implemented as an adaptive closed-loop model. We describe how each design step may be implemented and especially how we solved the issue of stability. Finally, we present a video-tracking application implemented on a FPGA to demonstrate the effectiveness of our solution, results are given for a system built around a NIOS soft-core with μCOS II RTOS and new services for managing hardware and software tasks transparently.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2070329405",
    "type": "article"
  },
  {
    "title": "Component-based modeling and verification of dynamic adaptation in safety-critical embedded systems",
    "doi": "https://doi.org/10.1145/1880050.1880056",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Rasmus Adler; Ina Schaefer; Mario Trapp; Arnd Poetzsch‐Heffter",
    "corresponding_authors": "",
    "abstract": "Adaptation is increasingly used in the development of safety-critical embedded systems, in particular to reduce hardware needs and to increase availability. However, composing a system from many reconfigurable components can lead to a huge number of possible system configurations, inducing a complexity that cannot be handled during system design. To overcome this problem, we propose a new component-based modeling and verification method for adaptive embedded systems. The component-based modeling approach facilitates abstracting a composition of components to a hierarchical component. In the hierarchical component, the number of possible configurations of the composition is reduced to a small number of hierarchical configurations. Only these hierarchical configurations have to be considered when the hierarchical component is used in further compositions such that design complexity is reduced at each hierarchical level. In order to ensure well-definedness of components, we provide a model of computation enabling the formal verification of critical requirements of the adaptation behavior.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2078654030",
    "type": "article"
  },
  {
    "title": "System/network design-space exploration based on TLM for networked embedded systems",
    "doi": "https://doi.org/10.1145/1721695.1721703",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Nicola Bombieri; Franco Fummi; Davide Quaglia",
    "corresponding_authors": "",
    "abstract": "This article presents a methodology for the design of Networked Embedded Systems (NESs), which extends Transaction Level Modeling (TLM) to perform system/network design-space exploration. As a result, a new design dimension is added to the traditional TLM refinement process to represent network configuration alternatives. Each network configuration can be used to drive both architecture exploration and system validation after each refinement step. A system/network simulation taxonomy is investigated aiming at precisely identifying the role of cosimulation in system/network design-space exploration. Furthermore, a general criterion to map functionalities to system and network models is presented. As a case study, the proposed methodology is applied to the design of a Voice-over-IP client.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2087436673",
    "type": "article"
  },
  {
    "title": "Buffer capacity computation for throughput-constrained modal task graphs",
    "doi": "https://doi.org/10.1145/1880050.1880053",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Maarten H. Wiggers; Marco J.G. Bekooij; Gerard J.M. Smit",
    "corresponding_authors": "",
    "abstract": "Increasingly, stream-processing applications include complex control structures to better adapt to changing conditions in their environment. This adaptivity often results in task execution rates that are dependent on the processed stream. Current approaches to compute buffer capacities that are sufficient to satisfy a throughput constraint have limited applicability in case of data-dependent task execution rates. In this article, we present a dataflow model that allows tasks to have loops with an unbounded number of iterations. For instances of this dataflow model, we present efficient checks on their validity. Furthermore, we present an efficient algorithm to compute buffer capacities that are sufficient to satisfy a throughput constraint. This allows to guarantee satisfaction of a throughput constraint over different modes of a stream processing application, such as the synchronization and synchronized modes of a digital radio receiver.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2125802341",
    "type": "article"
  },
  {
    "title": "Scheduling and Optimization of Fault-Tolerant Embedded Systems with Transparency/Performance Trade-Offs",
    "doi": "https://doi.org/10.1145/2345770.2345773",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Viacheslav Izosimov; Paul Pop; Petru Eles; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a strategy for the synthesis of fault-tolerant schedules and for the mapping of fault-tolerant applications. Our techniques handle transparency/performance trade-offs and use the faultoccurrence information to reduce the overhead due to fault tolerance. Processes and messages are statically scheduled, and we use process reexecution for recovering from multiple transient faults. We propose a finegrained transparent recovery, where the property of transparency can be selectively applied to processes and messages. Transparency hides the recovery actions in a selected part of the application so that they do not affect the schedule of other processes and messages. While leading to longer schedules, transparent recovery has the advantage of both improved debuggability and less memory needed to store the faulttolerant schedules.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2053230911",
    "type": "article"
  },
  {
    "title": "A hybrid hardware--software technique to improve reliability in embedded processors",
    "doi": "https://doi.org/10.1145/1952522.1952529",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Roshan Ragel; Sri Parameswaran",
    "corresponding_authors": "",
    "abstract": "Numerous methods have been described in research literature with methods to improve reliability of processors by the use of control-flow checking. High performance and code-size penalties cripple the proposed software approaches, while hardware approaches are not scalable and are thus rarely implemented in real embedded systems. In this article, we show that by including control-flow checking as an issue to be considered when designing as embedded processor, we are able to reduce overheads considerably and still provide a scalable solution to this problem. The technique described in this article includes architectural improvements to the processor and binary rewriting of the application. Architectural refinement incorporates additional instructions to the instruction set architecture, while the binary rewriting utilizes these additional instructions into the program flow. Applications from an embedded systems benchmark suite have been used to test and evaluate the system. Our approach increased code size by only 5.55% to 13.5% and reduced performance by just 0.54% to 2.83% for eight different industry standard benchmarks. The additional hardware overhead due to the additional instruction in the design is just 2.70%. In contrast, the state-of-the-art software-only approach required 50% to 150% additional code, and reduced performance by 53.5% to 99.5% when monitoring was inserted. Fault injection analysis demonstrates that our solution is capable of capturing and recovering from all the injected control-flow errors, while the software-only approach detected 87% of the injected control-flow errors.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W1999309394",
    "type": "article"
  },
  {
    "title": "xTune",
    "doi": "https://doi.org/10.1145/2362336.2362340",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Minyoung Kim; Mark-Oliver Stehr; Carolyn Talcott; Nikil Dutt; Nalini Venkatasubramanian",
    "corresponding_authors": "",
    "abstract": "Resource-limited mobile embedded systems can benefit greatly from dynamic adaptation of system parameters. We propose a novel approach that employs iterative tuning using lightweight formal verification at runtime with feedback for dynamic adaptation. One objective of this approach is to enable trade-off analysis across multiple layers (e.g., application, middleware, OS) and predict the possible property violations as the system evolves dynamically over time. Specifically, an executable formal specification is developed for each layer of the mobile system under consideration. The formal specification is then analyzed using statistical property checking and statistical quantitative analysis, to determine the impact of various resource management policies for achieving desired timing/QoS properties. Integration of formal analysis with dynamic behavior from system execution results in a feedback loop that enables model refinement and further optimization of policies and parameters. We demonstrate the applicability of this approach to the adaptive provisioning of resource-limited distributed real-time systems using a mobile multimedia case study.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2009040830",
    "type": "article"
  },
  {
    "title": "A resource-driven DVFS scheme for smart handheld devices",
    "doi": "https://doi.org/10.1145/2539036.2539049",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Yu-Ming Chang; Pi-Cheng Hsiu; Yuan-Hao Chang; Che-Wei Chang",
    "corresponding_authors": "",
    "abstract": "Reducing the energy consumption of the emerging genre of smart handheld devices while simultaneously maintaining mobile applications and services is a major challenge. This work is inspired by an observation on the resource usage patterns of mobile applications. In contrast to existing DVFS scheduling algorithms and history-based prediction techniques, we propose a resource-driven DVFS scheme in which resource state machines are designed to model the resource usage patterns in an online fashion to guide DVFS. We have implemented the proposed scheme on Android smartphones and conducted experiments based on real-world applications. The results are very encouraging and demonstrate the efficacy of the proposed scheme.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2036908209",
    "type": "article"
  },
  {
    "title": "Safety-critical medical device development using the UPP2SF model translation tool",
    "doi": "https://doi.org/10.1145/2584651",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Miroslav Pajić; Zhihao Jiang; Insup Lee; Oleg Sokolsky; Rahul Mangharam",
    "corresponding_authors": "",
    "abstract": "Software-based control of life-critical embedded systems has become increasingly complex, and to a large extent has come to determine the safety of the human being. For example, implantable cardiac pacemakers have over 80,000 lines of code which are responsible for maintaining the heart within safe operating limits. As firmware-related recalls accounted for over 41% of the 600,000 devices recalled in the last decade, there is a need for rigorous model-driven design tools to generate verified code from verified software models. To this effect, we have developed the UPP2SF model-translation tool, which facilitates automatic conversion of verified models (in UPPAAL) to models that may be simulated and tested (in Simulink/Stateflow). We describe the translation rules that ensure correct model conversion, applicable to a large class of models. We demonstrate how UPP2SF is used in the model-driven design of a pacemaker whose model is (a) designed and verified in UPPAAL (using timed automata), (b) automatically translated to Stateflow for simulation-based testing, and then (c) automatically generated into modular code for hardware-level integration testing of timing-related errors. In addition, we show how UPP2SF may be used for worst-case execution time estimation early in the design stage. Using UPP2SF, we demonstrate the value of integrated end-to-end modeling, verification, code-generation and testing process for complex software-controlled embedded systems.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2150124918",
    "type": "article"
  },
  {
    "title": "High-Performance Ideal Lattice-Based Cryptography on 8-Bit AVR Microcontrollers",
    "doi": "https://doi.org/10.1145/3092951",
    "publication_date": "2017-07-13",
    "publication_year": 2017,
    "authors": "Zhe Liu; Thomas Pöppelmann; Tobias Oder; Hwajeong Seo; Sujoy Sinha Roy; Tim Güneysu; Johann Großschädl; Howon Kim; Ingrid Verbauwhede",
    "corresponding_authors": "",
    "abstract": "Over recent years lattice-based cryptography has received much attention due to versatile average-case problems like Ring-LWE or Ring-SIS that appear to be intractable by quantum computers. In this work, we evaluate and compare implementations of Ring-LWE encryption and the bimodal lattice signature scheme (BLISS) on an 8-bit Atmel ATxmega128 microcontroller. Our implementation of Ring-LWE encryption provides comprehensive protection against timing side-channels and takes 24.9ms for encryption and 6.7ms for decryption. To compute a BLISS signature, our software takes 317ms and 86ms for verification. These results underline the feasibility of lattice-based cryptography on constrained devices.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2734990741",
    "type": "article"
  },
  {
    "title": "Maximal Synthesis for Hennessy-Milner Logic",
    "doi": "https://doi.org/10.1145/2680540",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "A.C. van Hulst; Michel Reniers; Wan Fokkink",
    "corresponding_authors": "",
    "abstract": "This article concerns the maximal synthesis for Hennessy-Milner Logic on Kripke structures with labeled transitions. We formally define, and prove the validity of, a theoretical framework that modifies a Kripke model to the least possible extent in order to satisfy a given HML formula. Applications of this work can be found in the field of controller synthesis and supervisory control for discrete-event systems. Synthesis is realized technically by first projecting the given Kripke model onto a bisimulation-equivalent partial tree representation, thereby unfolding up to the depth of the synthesized formula. Operational rules then define the required adaptations upon this structure in order to achieve validity of the synthesized formula. Synthesis might result in multiple valid adaptations, which are all related to the original model via simulation. Each simulant of the original Kripke model, which satisfies the synthesized formula, is also related to one of the synthesis results via simulation. This indicates maximality, or maximal permissiveness, in the context of supervisory control. In addition to the formal construction of synthesis as presented in this article, we present it in algorithmic form and analyze its computational complexity. Computer-verified proofs for two important theorems in this article have been created using the Coq proof assistant.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2067026144",
    "type": "article"
  },
  {
    "title": "Embedding formal performance analysis into the design cycle of MPSoCs for real-time streaming applications",
    "doi": "https://doi.org/10.1145/2146417.2146425",
    "publication_date": "2012-03-01",
    "publication_year": 2012,
    "authors": "Kai Huang; Wolfgang Haid; Iuliana Bacivarov; Matthias Keller; Lothar Thiele",
    "corresponding_authors": "",
    "abstract": "Modern real-time streaming applications are increasingly implemented on multiprocessor systems-on-chip (MPSoC). The implementation, as well as the verification of real-time applications executing on MPSoCs, are difficult tasks, however. A major challenge is the performance analysis of MPSoCs, which is required for early design space exploration and final system verification. Simulation-based methods are not well-suited for this purpose, due to long runtimes and non-exhaustive corner-case coverage. To overcome these limitations, formal performance analysis methods that provide guarantees for meeting real-time constraints have been developed. Embedding formal performance analysis into the MPSoC design cycle requires the generation of a faithful analysis model and its calibration with the system-specific parameters. In this article, a design flow that automates these steps is presented. In particular, we integrate modular performance analysis (MPA) into the distributed operation layer (DOL) MPSoC programming environment. The result is an MPSoC software design flow that allows for automatically generating the system implementation, together with an analysis model for system verification.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2081927288",
    "type": "article"
  },
  {
    "title": "Protecting Mobile Health Records in Cloud Computing",
    "doi": "https://doi.org/10.1145/2983625",
    "publication_date": "2017-01-02",
    "publication_year": 2017,
    "authors": "Jianghua Liu; Jinhua Ma; Wei Wu; Xiaofeng Chen; Xinyi Huang; Li Xu",
    "corresponding_authors": "",
    "abstract": "Electronic healthcare (eHealth) systems have replaced traditional paper-based medical systems due to attractive features such as universal accessibility, high accuracy, and low cost. As a major constituent part of eHealth systems, mobile healthcare (mHealth) applies Mobile Internet Devices (MIDs) and Embedded Devices (EDs), such as tablets, smartphones, and other devices embedded in the bodies of individuals, to improve the quality of life and provide more convenient healthcare services for patients. Unfortunately, MIDs and EDs have only limited computational capacity, storage space, and power supply. By taking this into account, we present a new design to guarantee the integrity of eHealth records and the anonymity of the data owner in a more efficient and flexible way. The essence of our design is a general method which can convert any secure Attribute-Based Signature (ABS) scheme into a highly efficient and secure Online/Offline Attribute-Based Signature (OOABS) scheme. We prove the security and analyze the efficiency improvement of the new design. Additionally, we illustrate the proposed generic construction by applying it to a specific ABS scheme.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2561214459",
    "type": "article"
  },
  {
    "title": "Dynamic Power and Energy Management for Energy Harvesting Nonvolatile Processor Systems",
    "doi": "https://doi.org/10.1145/3077575",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Kaisheng Ma; Xueqing Li; Huichu Liu; Sheng Xiao; Yiqun Wang; Karthik Swaminathan; Yongpan Liu; Yuan Xie; John J. Sampson; Vijaykrishnan Narayanan",
    "corresponding_authors": "",
    "abstract": "Self-powered systems running on scavenged energy will be a key enabler for pervasive computing across the Internet of Things. The variability of input power in energy-harvesting systems limits the effectiveness of static optimizations aimed at maximizing the input-energy-to-computation ratio. We show that the resultant gap between available and exploitable energy is significant, and that energy storage optimizations alone do not significantly close the gap. We characterize these effects on a real, fabricated energy-harvesting system based on a nonvolatile processor. We introduce a unified energy-oriented approach to first optimize the number of backups, by more aggressively using the stored energy available when power failure occurs, and then optimize forward progress via improving the rate of input energy to computation via dynamic voltage and frequency scaling and self-learning techniques. We evaluate combining these schemes and show capture of up to 75.5% of all input energy toward processor computation, an average of 1.54 × increase over the best static “Forward Progress” baseline system. Notably, our energy-optimizing policy combinations simultaneously improve both the rate of forward progress and the rate of backup events (by up to 60.7% and 79.2% for RF power, respectively, and up to 231.2% and reduced to zero, respectively, for solar power). This contrasts with static frequency optimization approaches in which these two metrics are antagonistic.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2612839290",
    "type": "article"
  },
  {
    "title": "Algebra of Parameterised Graphs",
    "doi": "https://doi.org/10.1145/2627351",
    "publication_date": "2014-07-01",
    "publication_year": 2014,
    "authors": "Andrey Mokhov; Victor Khomenko",
    "corresponding_authors": "",
    "abstract": "One of the difficulties in designing modern hardware systems is the necessity for comprehending and dealing with a very large number of system configurations, operational modes, and behavioural scenarios. It is often infeasible to consider and specify each individual mode explicitly, and one needs methodologies and tools to exploit similarities between the individual modes and work with groups of modes rather than individual ones. The modes and groups of modes have to be managed in a compositional way: the specification of the system should be composed from specifications of its blocks. This includes both structural and behavioural composition. Furthermore, one should be able to transform and optimise the specifications in a formal way. In this article, we propose a new formalism, called parameterised graphs . It extends the existing conditional partial order graphs (CPOGs) formalism in several ways. First, it deals with general graphs rather than just partial orders. Moreover, it is fully compositional. To achieve this, we introduce an algebra of parameterised graphs by specifying the equivalence relation by a set of axioms, which is proved to be sound, minimal, and complete. This allows one to manipulate the specifications as algebraic expressions using the rules of this algebra. We demonstrate the usefulness of the developed formalism on several case studies coming from the area of microelectronics design.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2680592554",
    "type": "article"
  },
  {
    "title": "Near-Optimal Co-Deployment of Chargers and Sink Stations in Rechargeable Sensor Networks",
    "doi": "https://doi.org/10.1145/3070721",
    "publication_date": "2017-08-29",
    "publication_year": 2017,
    "authors": "Songyuan Li; Lingkun Fu; Shibo He; Youxian Sun",
    "corresponding_authors": "",
    "abstract": "Wireless charging technology has drawn great attention of both academia and industry in recent years, due to its potential of significantly improving the system performance of sensor networks. The emergence of an open-source experimental platform for wireless rechargeable sensor networks, Powercast, has made the theoretical research closer to reality. This pioneering platform is able to recharge sensor nodes much more efficiently and allows different communication protocols to be implemented upon users’ demands. Different from the RFID-based model widely used in the existing works, Powercast designs the charger and sink station separately. This leads to a new design challenge of cooperatively deploying minimum number of chargers and sink stations in wireless rechargeable sensor networks. Such a co-deployment issue is extremely challenging, since the deployments of chargers and sink stations are coupled, and each subproblem is known to be NP-hard. The key to the design is to understand the intrinsic relationship between data flow and energy flow, which is interdependent. In this article, we tackle this challenge by dividing it into two subproblems and optimizing charger and sink station deployment iteratively. Specifically, we first transform each subproblem to a max-flow problem. With this, we are able to select chargers or sink stations according to their contributions to the total flow rate. We design greedy-based algorithms with a guaranteed worst-case bound ln R/ξ for the subproblems of charger deployment and sink station deployment, respectively. Further, we address the original problem by designing an iterative algorithm that solves two subproblems alternatively to achieve a near optimal performance. We corroborate our analysis by extensive simulations under practical coefficient settings and demonstrate the advantage of the proposed algorithm.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2752523658",
    "type": "article"
  },
  {
    "title": "Approximate Memristive In-memory Computing",
    "doi": "https://doi.org/10.1145/3126526",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Hasan Erdem Yantır; Ahmed M. Eltawil; Fadi Kurdahi",
    "corresponding_authors": "",
    "abstract": "The bottleneck between the processing elements and memory is the biggest issue contributing to the scalability problem in computing. In-memory computation is an alternative approach that combines memory and processor in the same location, and eliminates the potential memory bottlenecks. Associative processors are a promising candidate for in-memory computation, however the existing implementations have been deemed too costly and power hungry. Approximate computing is another promising approach for energy-efficient digital system designs where it sacrifices the accuracy for the sake of energy reduction and speedup in error-resilient applications. In this study, approximate in-memory computing is introduced in memristive associative processors. Two approximate computing methodologies are proposed; bit trimming and memristance scaling. Results show that the proposed methods not only reduce energy consumption of in-memory parallel computing but also improve their performance. As compared to other existing approximate computing methodologies on different architectures (e.g., CPU, GPU, and ASIC), approximate memristive in-memory computing exhibits better results in terms of energy reduction (up to 80x) and speedup (up to 20x) on a variety of benchmarks from different domains when quality degradation is limited to 10% and it confirms that memristive associative processors provide a highly-promising platform for approximate computing.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2757647500",
    "type": "article"
  },
  {
    "title": "Management and optimization for nonvolatile memory-based hybrid scratchpad memory on multicore embedded processors",
    "doi": "https://doi.org/10.1145/2560019",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Jingtong Hu; Qingfeng Zhuge; Chun Jason Xue; Wei-Che Tseng; Edwin H.‐M. Sha",
    "corresponding_authors": "",
    "abstract": "The recent emergence of various Non-Volatile Memories (NVMs), with many attractive characteristics such as low leakage power and high-density, provides us with a new way of addressing the memory power consumption problem. In this article, we target embedded CMPs, and propose a novel Hybrid Scratch Pad Memory (HSPM) architecture which consists of SRAM and NVM to take advantage of the ultra-low leakage power, high density of NVM, and fast access of SRAM. A novel data allocation algorithm as well as an algorithm to determine the NVM/SRAM ratio for the novel HSPM architecture are proposed. The experimental results show that the data allocation algorithm can reduce the memory access time by 33.51% and the dynamic energy consumption by 16.81% on average for the HSPM architecture when compared with a greedy algorithm. The NVM/SRAM size determination algorithm can further reduce the memory access time by 14.7% and energy consumption by 20.1% on average.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2112892407",
    "type": "article"
  },
  {
    "title": "Global and Partitioned Multiprocessor Fixed Priority Scheduling with Deferred Preemption",
    "doi": "https://doi.org/10.1145/2739954",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Robert I. Davis; Alan Burns; José Marinho; Vincent Nélis; Stefan M. Petters; Marko Bertogna",
    "corresponding_authors": "",
    "abstract": "This article introduces schedulability analysis for Global Fixed Priority Scheduling with Deferred Preemption (gFPDS) for homogeneous multiprocessor systems. gFPDS is a superset of Global Fixed Priority Preemptive Scheduling (gFPPS) and Global Fixed Priority Nonpreemptive Scheduling (gFPNS). We show how schedulability can be improved using gFPDS via appropriate choice of priority assignment and final nonpreemptive region lengths, and provide algorithms that optimize schedulability in this way. Via an experimental evaluation we compare the performance of multiprocessor scheduling using global approaches: gFPDS, gFPPS, and gFPNS, and also partitioned approaches employing FPDS, FPPS, and FPNS on each processor.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2166318031",
    "type": "article"
  },
  {
    "title": "Necessary and Sufficient Conditions for Thermal Schedulability of Periodic Real-Time Tasks Under Fluid Scheduling Model",
    "doi": "https://doi.org/10.1145/2883612",
    "publication_date": "2016-05-23",
    "publication_year": 2016,
    "authors": "Rehan Ahmed; Parameswaran Ramanathan; Kewal K. Saluja",
    "corresponding_authors": "",
    "abstract": "With the growing need to address the thermal issues in modern processing platforms, various performance throttling schemes have been proposed in literature (DVFS, clock gating, and so on) to manage temperature. In real-time systems, such methods are often unacceptable, as they can result in potentially catastrophic deadline misses. As a result, real-time scheduling research has recently focused on developing algorithms that meet the compute deadline while satisfying power and thermal constraints. Basic bounds that can determine if a set of tasks can be scheduled or not were established in the 1970s based on computation utilization. Similar results for thermal bounds have not been forthcoming. In this article, we address the problem of thermal constraint schedulability of tasks and derive necessary and sufficient conditions for thermal feasibility of periodic tasksets on a unicore system. We prove that a GPS-inspired fluid scheduling scheme is thermally optimal when context switch/preemption overhead is ignored. Extension of sufficient conditions to a nonfluid model is still an open problem. We also extend some of the results to a multicore processing environment. We demonstrate the efficacy of our results through extensive simulations. We also evaluate the proposed concepts on a hardware testbed.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2400846429",
    "type": "article"
  },
  {
    "title": "On-Board Format-Independent Security of Functional Magnetic Resonance Images",
    "doi": "https://doi.org/10.1145/2893474",
    "publication_date": "2017-01-10",
    "publication_year": 2017,
    "authors": "Arcangelo Castiglione; Raffaele Pizzolante; Francesco Palmieri; Barbara Masucci; Bruno Carpentieri; Alfredo De Santis; Aniello Castiglione",
    "corresponding_authors": "",
    "abstract": "Functional magnetic resonance imaging (fMRI) provides an effective and noninvasive tool for researchers to understand cerebral functions and correlate them with brain activities. In addition, with the ever-increasing diffusion of the Internet, such images may be exchanged in several ways, allowing new research and medical services. On the other hand, ensuring the security of exchanged fMRI data becomes a main concern due to their special characteristics arising from strict ethics and legislative and diagnostic implications. Again, the risks increase when dealing with open environments like the Internet. For this reason, security mechanisms that ensure protection of such data are strongly required. However, we remark that the mechanisms commonly employed for data protection are doomed to fail when dealing with imaging data. In this article, we propose a novel watermarking scheme explicitly addressed for this type of imaging. Such a scheme can be used for several purposes, particularly to ensure authenticity and integrity. Moreover, we show how to integrate our scheme within commercial off-the-shelf fMRI system. Finally, the validity and the efficiency of our scheme has been assessed through testing.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2569381793",
    "type": "article"
  },
  {
    "title": "Axiom",
    "doi": "https://doi.org/10.1145/3047413",
    "publication_date": "2017-04-28",
    "publication_year": 2017,
    "authors": "Marco Tiloca; Kirill Nikitin; Shahid Raza",
    "corresponding_authors": "",
    "abstract": "This article presents Axiom, a DTLS-based approach to efficiently secure multicast group communication among IoT-constrained devices. Axiom provides an adaptation of the DTLS record layer, relies on key material commonly shared among the group members, and does not require one to perform any DTLS handshake. We made a proof-of-concept implementation of Axiom based on the tinyDTLS library for the Contiki OS and used it to experimentally evaluate performance of our approach on real IoT hardware. Results show that Axiom is affordable on resource-constrained platforms and performs significantly better than related alternative approaches.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2606082551",
    "type": "article"
  },
  {
    "title": "Lightweight Data Compression for Mobile Flash Storage",
    "doi": "https://doi.org/10.1145/3126511",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Cheng Ji; Li-Pin Chang; Liang Shi; Congming Gao; Chao Wu; Yuangang Wang; Chun Jason Xue",
    "corresponding_authors": "",
    "abstract": "Data compression is beneficial to flash storage lifespan. However, because the design of mobile flash storage is highly cost-sensitive, hardware compression becomes a less attractive option. This study investigates the feasibility of data compression on mobile flash storage. It first characterizes data compressibility based on mobile apps, and the analysis shows that write traffic bound for mobile storage volumes is highly compressible. Based on this finding, a lightweight approach is introduced for firmware-based data compression in mobile flash storage. The controller and flash module work in a pipelined fashion to hide the data compression overhead. Together with this pipelined design, the proposed approach selectively compresses incoming data of high compressibility, while leaving data of low compressibility to a compression-aware garbage collector. Experimental results show that our approach greatly reduced the frequency of block erase by 50.5% compared to uncompressed flash storage. Compared to unconditional data compression, our approach improved the write latency by 10.4% at a marginal cost of 4% more block erase operations.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2757796760",
    "type": "article"
  },
  {
    "title": "Model-based, Mutation-driven Test-case Generation Via Heuristic-guided Branching Search",
    "doi": "https://doi.org/10.1145/3289256",
    "publication_date": "2019-01-25",
    "publication_year": 2019,
    "authors": "Andreas Fellner; Willibald Krenn; Rupert Schlick; Thorsten Tarrach; Georg Weißenbacher",
    "corresponding_authors": "",
    "abstract": "This work introduces a heuristic-guided branching search algorithm for model-based, mutation-driven test-case generation. The algorithm is designed towards the efficient and computationally tractable exploration of discrete, non-deterministic models with huge state spaces. Asynchronous parallel processing is a key feature of the algorithm. The algorithm is inspired by the successful path planning algorithm Rapidly exploring Random Trees (RRT). We adapt RRT in several aspects towards test-case generation. Most notably, we introduce parametrized heuristics for start and successor state selection, as well as a mechanism to construct test cases from the data produced during the search. We implemented our algorithm in the existing test-case generation framework MoMuT. We present an extensive evaluation of the proposed heuristics and parameters of the algorithm, based on a diverse set of demanding models obtained in an industrial context. In total, we continuously utilized 128 CPU cores on three servers for several weeks to gather the experimental data presented. We show that branching search works well and the use of multiple heuristics is justified. With our new algorithm, we are now able to process models consisting of over 2,300 concurrent objects. To our knowledge, there is no other mutation-driven test-case generation tool that is able to process models of this magnitude.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2997924541",
    "type": "article"
  },
  {
    "title": "Architecture Support for Domain-Specific Accelerator-Rich CMPs",
    "doi": "https://doi.org/10.1145/2584664",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Jason Cong; Mohammad Ali Ghodrat; Michael Gill; Beayna Grigorian; Glenn Reinman",
    "corresponding_authors": "",
    "abstract": "This work discusses hardware architectural support for domain-specific accelerator-rich CMPs. First, we present a hardware resource management scheme for sharing of loosely coupled accelerators and arbitration of multiple requesting cores. Second, we present a mechanism for accelerator virtualization. This allows multiple accelerators to efficiently compose a larger virtual accelerator out of multiple smaller accelerators, as well as to collaborate as multiple copies of a simple accelerator. All of this work is supported by a fully automated simulation tool-chain for both accelerator generation and management. We present the applicability of our approach to four different application domains: medical imaging, commercial, computer vision, and navigation. Our results demonstrate large performance improvements and energy savings over a software implementation. We also show additional improvements that result from enhanced load balancing and simplification of the communication between the core and the arbitration mechanism.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2034024954",
    "type": "article"
  },
  {
    "title": "MultiNets",
    "doi": "https://doi.org/10.1145/2489788",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Shahriar Nirjon; Angela Nicoarǎ; Cheng-Hsin Hsu; Jatinder Singh; John A. Stankovic",
    "corresponding_authors": "",
    "abstract": "MultiNets is a system supporting seamless switch-over between wireless interfaces on mobile devices in real-time. MultiNets is configurable to run in three different modes: (i) Energy Saving mode --for choosing the interface that saves the most energy based on the condition of the device, (ii) Offload mode --for offloading data traffic from the cellular to WiFi network, and (iii) Performance mode --for selecting the network for the fastest data connectivity. MultiNets also provides a powerful API that gives the application developers: (i) the choice to select a network interface to communicate with a specific server, and (ii) the ability to simultaneously transfer data over multiple network interfaces. MultiNets is modular, easily integrable, lightweight, and applicable to various mobile operating systems. We implement MultiNets on Android devices as a show case. MultiNets does not require any extra support from the network infrastructure and runs existing applications transparently. To evaluate MultiNets, we first collect data traces from 13 actual Android smartphone users over three months. We then use the collected traces to show that, by automatically switching to WiFi whenever it is available, MultiNets can offload on average 79.82% of the data traffic. We also illustrate that, by optimally switching between the interfaces, MultiNets can save on average 21.14 KJ of energy per day, which is equivalent to 27.4% of the daily energy usage. Using our API, we demonstrate that a video streaming application achieves 43--271% higher streaming rate when concurrently using WiFi and 3G interfaces. We deploy MultiNets in a real-world scenario and our experimental results show that depending on the user requirements, it outperforms the state-of-the-art Android system either by saving up to 33.75% energy, achieving near-optimal offloading, or achieving near-optimal throughput while substantially reducing TCP interruptions due to switching.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2068601757",
    "type": "article"
  },
  {
    "title": "Towards Write-Activity-Aware Page Table Management for Non-volatile Main Memories",
    "doi": "https://doi.org/10.1145/2697394",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Tianzheng Wang; Duo Liu; Yi Wang; Zili Shao",
    "corresponding_authors": "",
    "abstract": "Non-volatile memories such as phase change memory (PCM) and memristor are being actively studied as an alternative to DRAM-based main memory in embedded systems because of their properties, which include low power consumption and high density. Though PCM is one of the most promising candidates with commercial products available, its adoption has been greatly compromised by limited write endurance. As main memory is one of the most heavily accessed components, it is critical to prolong the lifetime of PCM. In this article, we present w rite- a ctivity-aware p age t able m anagement (WAPTM), a simple yet effective page table management scheme for reducing unnecessary writes, by redesigning system software and exploiting write-activity-aware features provided by the hardware. We implemented WAPTM in Google Android based on the ARM architecture and evaluated it with real Android applications. Experimental results show that WAPTM can significantly reduce writes in page tables, proving the feasibility and potential of prolonging the lifetime of PCM-based main memory through reducing writes at the OS level.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2078646778",
    "type": "article"
  },
  {
    "title": "Stable Greedy",
    "doi": "https://doi.org/10.1145/2820613",
    "publication_date": "2016-01-13",
    "publication_year": 2016,
    "authors": "Li-Pin Chang; Yu-Syun Liu; Wen-Huei Lin",
    "corresponding_authors": "",
    "abstract": "Commodity solid state drives (SSDs) have recently begun involving the adoption of powerful controllers for multichannel flash management at the page level. However, many of these models still use primitive garbage-collection algorithms, because previous approaches are subject to poor scalability with high-capacity flash memory. This study presents Stable Greedy for garbage collection in page-mapping multichannel SSDs. Stable Greedy identifies page-accurate data hotness using block-level information, and jointly considers block space utilization and block stability for victim selection. Its design considers flash wear leveling for SSD lifetime enhancement at the block level as well as at the channel level. Stable Greedy runs at a constant time, and requires limited RAM space. The simulation results revealed that Stable Greedy outperformed previous methods considerably under various workloads and multichannel architectures. Stable Greedy was successfully implemented on the OpenSSD platform, and the actual performance measurements were consistent with the simulation results.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2236494643",
    "type": "article"
  },
  {
    "title": "Efficient, Long-Term Logging of Rich Data Sensors Using Transient Sensor Nodes",
    "doi": "https://doi.org/10.1145/3047499",
    "publication_date": "2017-09-20",
    "publication_year": 2017,
    "authors": "Andres Gomez; Lukas Sigrist; Thomas Schalch; Luca Benini; Lothar Thiele",
    "corresponding_authors": "",
    "abstract": "While energy harvesting is generally seen to be the key to power cyber-physical systems in a low-cost, long-term, efficient manner, it has generally required large energy storage devices to mitigate the effects of the source’s variability. The emerging class of transiently powered systems embrace this variability by performing computation in proportion to the energy harvested, thereby minimizing the obtrusive and expensive storage element. By using an efficient Energy Management Unit (EMU), small bursts of energy can be buffered in an optimally sized capacitor and used to supply generic loads, even when the average harvested power is only a fraction of that required for sustained system operation. Dynamic Energy Burst Scaling (DEBS) can be used by the load to dynamically configure the EMU to supply small bursts of energy at its optimal power point, independent from the harvester’s operating point. Parameters like the maximum burst size, the solar panel’s area, as well as the use of energy-efficient Non-Volatile Memory Hierarchy (NVMH) can have a significant impact on the transient system’s characteristics such as the wake-up time and the amount of work that can be done per unit of energy. Experimental data from a solar-powered, long-term autonomous image acquisition application show that, regardless of its configuration, the EMU can supply energy bursts to a 43.4mW load with efficiencies of up to 79.7% and can work with input power levels as low as 140μW. When the EMU is configured to use DEBS and NVMH, the total energy cost of acquiring, processing and storing an image can be reduced by 77.8%, at the price of increasing the energy buffer size by 65%.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2756088899",
    "type": "article"
  },
  {
    "title": "CAMsure",
    "doi": "https://doi.org/10.1145/3126547",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "M. Sadegh Riazi; Mohammad Samragh; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "We introduce CAMsure, the first realization of secure Content Addressable Memory (CAM) in the context of approximate search using near-neighbor algorithms. CAMsure provides a lightweight solution for practical secure (approximate) search with a minimal drop in the accuracy of the search results. CAM has traditionally been used as a hardware search engine that explores the entire memory in a single clock cycle. However, there has been little attention to the security of the data stored in CAM. Our approach stores distance-preserving hash embeddings within CAM to ensure data privacy. The hashing method provides data confidentiality while preserving similarity in the sense that a high resemblance in the data domain is translated to a small Hamming distance in the hash domain. Consequently, the objective of near-neighbor search is converted to approximate lookup table search which is compatible with the realizations of emerging content addressable memories. Our methodology delivers on average two orders of magnitude faster response time compared to RAM-based solutions that preserve the privacy of data owners.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2758985339",
    "type": "article"
  },
  {
    "title": "Edge-TM",
    "doi": "https://doi.org/10.1145/3126556",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Dimitra Papagiannopoulou; Andrea Marongiu; Tali Moreshet; Maurice Herlihy; R. Iris Bahar",
    "corresponding_authors": "",
    "abstract": "Scaling of semiconductor devices has enabled higher levels of integration and performance improvements at the price of making devices more susceptible to the effects of static and dynamic variability. Adding safety margins (guardbands) on the operating frequency or supply voltage prevents timing errors, but has a negative impact on performance and energy consumption. We propose Edge-TM , an adaptive hardware/software error management policy that ( i ) optimistically scales the voltage beyond the edge of safe operation for better energy savings and ( ii ) works in combination with a Hardware Transactional Memory (HTM)-based error recovery mechanism. The policy applies dynamic voltage scaling (DVS) (while keeping frequency fixed) based on the feedback provided by HTM, which makes it simple and generally applicable. Experiments on an embedded platform show our technique capable of 57% energy improvement compared to using voltage guardbands and an extra 21-24% improvement over existing state-of-the-art error tolerance solutions, at a nominal area and time overhead.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2759569413",
    "type": "article"
  },
  {
    "title": "P-Alloc",
    "doi": "https://doi.org/10.1145/3126554",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Yi Wang; Lisha Dong; Rui Mao",
    "corresponding_authors": "",
    "abstract": "Three-dimensional (3D) flash memory is an emerging memory technology that enables a number of improvements to conventional planar NAND flash memory, including larger capacity, less program disturbance, and lower access latency. In contrast to conventional planar flash memory, 3D flash memory adopts charge-trapping mechanism. NAND strings punch through multiple stacked layers to form the three-dimensional infrastructure. However, the etching processes for NAND strings are unable to produce perfectly vertical features, especially on the scale of 20 nanometers or less. The process variation will cause uneven distribution of electrons, which poses a threat to the integrity of data stored in flash. This paper present P-Alloc , a process-variation tolerant reliability management strategy for 3D charge-trapping flash memory. P-Alloc offers both hardware and software support to allocate data to the 3D flash in the presence of process variation. P-Alloc predicts the state of a physical page, i.e., the basic unit for each write or read operation in flash memory, and tries to assign critical data to more reliable pages. A hardware-based voltage threshold compensation scheme is also proposed to further reduce the faults. We demonstrate the viability of the proposed scheme using a variety of realistic workloads. Our extensive evaluations show that, P-Alloc significantly enhances the reliability and reduces the access latency compared to the baseline scheme.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2759844020",
    "type": "article"
  },
  {
    "title": "Synergy",
    "doi": "https://doi.org/10.1145/3301278",
    "publication_date": "2019-03-18",
    "publication_year": 2019,
    "authors": "Guanwen Zhong; Akshat Dubey; Cheng Tan; Tulika Mitra",
    "corresponding_authors": "",
    "abstract": "Convolutional Neural Networks (CNN) have been widely deployed in diverse application domains. There has been significant progress in accelerating both their training and inference using high-performance GPUs, FPGAs, and custom ASICs for datacenter-scale environments. The recent proliferation of mobile and Internet of Things (IoT) devices have necessitated real-time, energy-efficient deep neural network inference on embedded-class, resource-constrained platforms. In this context, we present Synergy , an automated, hardware-software co-designed, pipelined, high-throughput CNN inference framework on embedded heterogeneous system-on-chip (SoC) architectures (Xilinx Zynq). Synergy leverages, through multi-threading, all the available on-chip resources, which includes the dual-core ARM processor along with the FPGA and the NEON Single-Instruction Multiple-Data (SIMD) engines as accelerators. Moreover, Synergy provides a unified abstraction of the heterogeneous accelerators (FPGA and NEON) and can adapt to different network configurations at runtime without changing the underlying hardware accelerator architecture by balancing workload across accelerators through work-stealing. Synergy achieves 7.3X speedup, averaged across seven CNN models, over a well-optimized software-only solution. Synergy demonstrates substantially better throughput and energy-efficiency compared to the contemporary CNN implementations on the same SoC architecture.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2795444169",
    "type": "article"
  },
  {
    "title": "Scratchpad-Memory Management for Multi-Threaded Applications on Many-Core Architectures",
    "doi": "https://doi.org/10.1145/3301308",
    "publication_date": "2019-01-31",
    "publication_year": 2019,
    "authors": "Vanchinathan Venkataramani; Mun Choon Chan; Tulika Mitra",
    "corresponding_authors": "",
    "abstract": "Contemporary many-core architectures, such as Adapteva Epiphany and Sunway TaihuLight, employ per-core software-controlled Scratchpad Memory (SPM) rather than caches for better performance-per-watt and predictability. In these architectures, a core is allowed to access its own SPM as well as remote SPMs through the Network-On-Chip (NoC). However, the compiler/programmer is required to explicitly manage the movement of data between SPMs and off-chip memory. Utilizing SPMs for multi-threaded applications is even more challenging, as the shared variables across the threads need to be placed appropriately. Accessing variables from remote SPMs with higher access latency further complicates this problem as certain links in the NoC may be heavily contended by multiple threads. Therefore, certain variables may need to be replicated in multiple SPMs to reduce the contention delay and/or the overall access time. We present Coordinated Data Management (CDM), a compile-time framework that automatically identifies shared/private variables and places them with replication (if necessary) to suitable on-chip or off-chip memory, taking NoC contention into consideration. We develop both an exact Integer Linear Programming (ILP) formulation as well as an iterative, scalable algorithm for placing the data variables in multi-threaded applications on many-core SPMs. Experimental evaluation on the Parallella hardware platform confirms that our allocation strategy reduces the overall execution time and energy consumption by 1.84× and 1.83× , respectively, when compared to the existing approaches.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2911579567",
    "type": "article"
  },
  {
    "title": "Cache Reconfiguration Using Machine Learning for Vulnerability-aware Energy Optimization",
    "doi": "https://doi.org/10.1145/3309762",
    "publication_date": "2019-03-31",
    "publication_year": 2019,
    "authors": "Alif Ahmed; Yuanwen Huang; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "Dynamic cache reconfiguration has been widely explored for energy optimization and performance improvement for single-core systems. Cache partitioning techniques are introduced for the shared cache in multicore systems to alleviate inter-core interference. While these techniques focus only on performance and energy, they ignore vulnerability due to soft errors. In this article, we present a static profiling based algorithm to enable vulnerability-aware energy-optimization for real-time multicore systems. Our approach can efficiently search the space of cache configurations and partitioning schemes for energy optimization while task deadlines and vulnerability constraints are satisfied. A machine learning technique has been employed to minimize the static profiling time without sacrificing the accuracy of results. Our experimental results demonstrate that our approach can achieve 19.2% average energy savings compared with the base configuration, while drastically reducing the vulnerability (49.3% on average) compared to state-of-the-art techniques. Furthermore, the machine learning technique enabled more than 10x speedup in static profiling time with a negligible prediction error of 3%.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2932363433",
    "type": "article"
  },
  {
    "title": "Worst-case Satisfaction of STL Specifications Using Feedforward Neural Network Controllers",
    "doi": "https://doi.org/10.1145/3358239",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Shakiba Yaghoubi; Georgios Fainekos",
    "corresponding_authors": "",
    "abstract": "In this paper, a reinforcement learning approach for designing feedback neural network controllers for nonlinear systems is proposed. Given a Signal Temporal Logic (STL) specification which needs to be satisfied by the system over a set of initial conditions, the neural network parameters are tuned in order to maximize the satisfaction of the STL formula. The framework is based on a max-min formulation of the robustness of the STL formula. The maximization is solved through a Lagrange multipliers method, while the minimization corresponds to a falsification problem. We present our results on a vehicle and a quadrotor model and demonstrate that our approach reduces the training time more than 50 percent compared to the baseline approach.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2979818850",
    "type": "article"
  },
  {
    "title": "Identifying Region-Wide Functions Using Urban Taxicab Trajectories",
    "doi": "https://doi.org/10.1145/2821507",
    "publication_date": "2016-03-11",
    "publication_year": 2016,
    "authors": "Daqiang Zhang; Jiafu Wan; Zongjian He; Shengjie Zhao; Ke Fan; Sang Oh Park; Zhibin Jiang",
    "corresponding_authors": "",
    "abstract": "With the urban development and enlargement, various regions such as residential zones and administrative districts now appear as parts of cities. People exhibit different mobility patterns in each region, which is closely relevant to region-wide functions. In this article, we propose a scheme to discover region-wide functions using large-scale Shanghai taxicab trajectories that capture enormous traces for more than 13,000 taxicabs over a period of about 3 years. We investigate these taxicab trajectories and conduct an extensive preliminary study. Then, we divide the city into disjointed regions using Voronoi decomposition. By incorporating people's pick-up and drop-off information, we refine the Voronoi partitioning results to identify region-wide functional areas. Finally, we study people's movement frequency on weekdays and weekends for every kind of urban functional regions. We also look into human mobility within or across the identified urban functional regions. Experimental results show that human movement is bounded with the function of urban regions, and more than 90% of people visit neighboring (less than 20km travel distance) functional regions with high probability.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2309421598",
    "type": "article"
  },
  {
    "title": "A Real-Time FPGA-Based Accelerator for ECG Analysis and Diagnosis Using Association-Rule Mining",
    "doi": "https://doi.org/10.1145/2821508",
    "publication_date": "2016-02-26",
    "publication_year": 2016,
    "authors": "Xiaoqi Gu; Yongxin Zhu; Shengyan Zhou; Chaojun Wang; Meikang Qiu; Guoxing Wang",
    "corresponding_authors": "",
    "abstract": "Telemedicine provides health care services at a distance using information and communication technologies, which intends to be a solution to the challenges faced by current health care systems with growing numbers of population, increased demands from patients, and shortages in human resources. Recent advances in telemedicine, especially in wearable electrocardiogram (ECG) monitors, call for more intelligent and efficient automatic ECG analysis and diagnostic systems. We present a streaming architecture implemented on Field-Programmable Gate Arrays (FPGAs) to accelerate real-time ECG signal analysis and diagnosis in a pipelining and parallel way. Association-rule mining is employed to generate early diagnostic results by matching features of ECG with generated association rules. To improve performance of the processing, we propose a hardware-oriented data-mining algorithm named Bit_Q_Apriori . The corresponding hardware implementation indicates a good scalability and outperforms other hardware designs in terms of performance, throughput, and hardware cost.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2332848104",
    "type": "article"
  },
  {
    "title": "User-Centric Scheduling and Governing on Mobile Devices with big.LITTLE Processors",
    "doi": "https://doi.org/10.1145/2829946",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Pi-Cheng Hsiu; Po-Hsien Tseng; Wei-Ming Chen; Chin-Chiang Pan; Tei‐Wei Kuo",
    "corresponding_authors": "",
    "abstract": "Mobile applications will become progressively more complicated and diverse. Heterogeneous computing architectures like big.LITTLE are a hardware solution that allows mobile devices to combine computing performance and energy efficiency. However, software solutions that conform to the paradigm of conventional fair scheduling and governing are not applicable to mobile systems, thereby degrading user experience or reducing energy efficiency. In this article, we exploit the concept of application sensitivity, which reflects the user’s attention on each application, and devise a user-centric scheduler and governor that allocate computing resources to applications according to their sensitivity. Furthermore, we integrate our design into the Android operating system. The results of experiments conducted on a commercial big.LITTLE smartphone with real-world mobile apps demonstrate that the proposed design can achieve significant gains in energy efficiency while improving the quality of user experience.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2340258890",
    "type": "article"
  },
  {
    "title": "Parallelizing Industrial Hard Real-Time Applications for the parMERASA Multicore",
    "doi": "https://doi.org/10.1145/2910589",
    "publication_date": "2016-05-23",
    "publication_year": 2016,
    "authors": "Theo Ungerer; Christian Bradatsch; Martin Frieb; Florian Kluge; Jörg Mische; Alexander Stegmeier; Ralf Jahr; Mike Gerdes; Pavel Zaykov; Lucie Matušová; Zai Jian Jia Li; Zlatko Petrov; Bert Böddeker; Sebastian Kehr; Hans Regler; Andreas Hugl; Christine Rochange; Haluk Ozaktas; Hugues Cassé; Armelle Bonenfant; Pascal Sainrat; Nick Lay; David George; Ian Broster; Eduardo Quiñones; Miloš Panić; Jaume Abella; Carles Hernàndez; Francisco J. Cazorla; Sascha Uhrig; Mathias Rohde; Arthur Pyka",
    "corresponding_authors": "",
    "abstract": "The EC project parMERASA (Multicore Execution of Parallelized Hard Real-Time Applications Supporting Analyzability) investigated timing-analyzable parallel hard real-time applications running on a predictable multicore processor. A pattern-supported parallelization approach was developed to ease sequential to parallel program transformation based on parallel design patterns that are timing analyzable. The parallelization approach was applied to parallelize the following industrial hard real-time programs: 3D path planning and stereo navigation algorithms (Honeywell International s.r.o.), control algorithm for a dynamic compaction machine (BAUER Maschinen GmbH), and a diesel engine management system (DENSO AUTOMOTIVE Deutschland GmbH). This article focuses on the parallelization approach, experiences during parallelization with the applications, and quantitative results reached by simulation, by static WCET analysis with the OTAWA tool, and by measurement-based WCET analysis with the RapiTime tool.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2399204844",
    "type": "article"
  },
  {
    "title": "Usage-Specific Semantic Integration for Cyber-Physical Robot Systems",
    "doi": "https://doi.org/10.1145/2873057",
    "publication_date": "2016-05-23",
    "publication_year": 2016,
    "authors": "Fang Li; Jiafu Wan; Ping Zhang; Di Li; Zhang Da-qiang; Keliang Zhou",
    "corresponding_authors": "",
    "abstract": "The multidisciplinary nature and time criticality of computing in Cyber-Physical Robot Systems (CPRS) makes it significantly different from traditional computer systems. This article attempts to create a usage-specific language called Cyber-Physical Robot Language (CPRL), which supports the CPRS design and implementation in an integrative and swift way. Multiview description and integration strategies as well as formal execution semantics for usage-specific simulation and verification are outlined. A graphic unified environment for CPRS modeling is supplied, in which several tools are integrated. A 6-DOF distributed robot system development in the environment is presented. The approach is an attempt to support CPRS design in an effective way, at the same time guaranteeing the system function and performance requirements.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2401219049",
    "type": "article"
  },
  {
    "title": "CURA",
    "doi": "https://doi.org/10.1145/2909875",
    "publication_date": "2016-08-02",
    "publication_year": 2016,
    "authors": "Chun‐Han Lin; Chih-Kai Kang; Pi-Cheng Hsiu",
    "corresponding_authors": "",
    "abstract": "Organic Light-Emitting Diode (OLED) technology is regarded as a promising alternative to mobile displays. In this article, we introduce the design, algorithm, and implementation of a novel framework called CURA for quality-retaining power saving on mobile OLED displays. First, we link human visual attention to OLED power saving and model the OLED image scaling optimization problem. The objective is to minimize the power required to display an image without adversely impacting the user’s visual experience. Then, we present the algorithm used to solve the modeled problem, and prove its optimality even without an accurate power model. Finally, based on the framework, we implement two practical applications on a commercial OLED mobile tablet. The results of experiments conducted on the tablet with real images demonstrate that CURA can reduce significant OLED power consumption while retaining the visual quality of images.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2498116261",
    "type": "article"
  },
  {
    "title": "FFConv",
    "doi": "https://doi.org/10.1145/3380548",
    "publication_date": "2020-03-11",
    "publication_year": 2020,
    "authors": "Afzal Ahmad; Muhammad Adeel Pasha",
    "corresponding_authors": "",
    "abstract": "Image classification is known to be one of the most challenging problems in the domain of computer vision. Significant research is being done on developing systems and algorithms improving accuracy, performance, area, and power consumption for related problems. Convolutional Neural Networks (CNNs) have shown to give outstanding accuracies for problems such as image classification, object detection, and semantic segmentation. While CNNs are pioneering the development of high accuracy systems, their excessive computational complexity presents a barrier for a more permeated deployment. Although Graphical Processing Units (GPUs), due to their massively parallel architecture, have shown to give performance orders of magnitude better than general purpose processors, the former are limited by their high power consumption and generality. Consequently, Field Programmable Gate Arrays (FPGAs) are being explored to implement CNN architectures, as they also provide massively parallel logic resources but with a relatively lower power consumption than GPUs. In this article, we present FFConv, an efficient FPGA-based fast convolutional layer accelerator for CNNs. We design a pipelined, high-throughput convolution engine based on the Winograd minimal filtering (also called Fast Convolution) algorithms for computing the convolutional layers of three popular CNN architectures: VGG16, Alexnet, and Shufflenet. We implement our accelerator on a Virtex-7 FPGA platform where we exploit the computational parallelization to the maximum while exploring optimizations aimed at improving performance. The resultant design loses only 0.43%, 0.47%, and 0.61% Top-1 classification accuracy for VGG16, Alexnet, and Shufflenet-v1, respectively, while significantly improving throughput, resource, and power efficiency compared to previous state-of-the-art designs.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3010819965",
    "type": "article"
  },
  {
    "title": "Golden Chip-Free Trojan Detection Leveraging Trojan Trigger’s Side-Channel Fingerprinting",
    "doi": "https://doi.org/10.1145/3419105",
    "publication_date": "2020-12-07",
    "publication_year": 2020,
    "authors": "Jiaji He; Haocheng Ma; Yanjiang Liu; Yiqiang Zhao",
    "corresponding_authors": "",
    "abstract": "Hardware Trojans (HTs) have become a major threat for the integrated circuit industry and supply chain and have motivated numerous developments of HT detection schemes. Although the side-channel HT detection approach is among the most promising solutions, most of the previous methods require a trusted golden chip reference. Furthermore, detection accuracy is often influenced by environmental noise and process variations. In this article, a novel electromagnetic (EM) side-channel fingerprinting-based HT detection method is proposed. Different from previous methods, the proposed solution eliminates the requirement of a trusted golden fabricated chip. Rather, only the genuine RTL code is required to generate the EM signatures as references. A factor analysis method is utilized to extract the spectral features of the HT trigger’s EM radiation, and then a k -means clustering method is applied for HT detection. Experimentation on two selected sets of Trust-Hub benchmarks has been performed on FPGA platforms, and the results show that the proposed framework can detect all dormant HTs with a high confidence level.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3112299287",
    "type": "article"
  },
  {
    "title": "Energy Modeling for the Bluetooth Low Energy Protocol",
    "doi": "https://doi.org/10.1145/3379339",
    "publication_date": "2020-03-16",
    "publication_year": 2020,
    "authors": "Philipp H. Kindt; Daniel Yunge; Robert Diemer; Samarjit Chakraborty",
    "corresponding_authors": "",
    "abstract": "Bluetooth Low Energy (BLE) is a wireless protocol optimized for low-power communication. To design energy-efficient devices, the protocol provides a number of parameters that need to be optimized within an energy, latency, and throughput design space. Therefore, an energy model that can predict the energy consumption of a BLE-based wireless device for different parameter value settings is needed. As BLE differs from the well-known Bluetooth Basic Rate (BR) significantly, models for Bluetooth BR cannot be easily applied to the BLE protocol. In past years, there have been a couple of proposals on energy models for BLE. However, none of them can model all the operating modes of the protocol. This article presents an energy model of the BLE protocol, which allows the computation of a device’s power consumption in all possible operating modes. To the best of our knowledge, our proposed model is not only one of the most accurate ones known so far (because it accounts for all protocol parameters), but it is also the only one that models all the operating modes of BLE. Based on this model, guidelines for system designers are presented that help choose the right parameters for optimizing the energy consumption. The model is publicly available as a software library for download.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3003184959",
    "type": "article"
  },
  {
    "title": "Real-time Attack-recovery for Cyber-physical Systems Using Linear-quadratic Regulator",
    "doi": "https://doi.org/10.1145/3477010",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Lin Zhang; Pengyuan Lu; Fanxin Kong; Xin Chen; Oleg Sokolsky; Insup Lee",
    "corresponding_authors": "",
    "abstract": "The increasing autonomy and connectivity in cyber-physical systems (CPS) come with new security vulnerabilities that are easily exploitable by malicious attackers to spoof a system to perform dangerous actions. While the vast majority of existing works focus on attack prevention and detection, the key question is “what to do after detecting an attack?”. This problem attracts fairly rare attention though its significance is emphasized by the need to mitigate or even eliminate attack impacts on a system. In this article, we study this attack response problem and propose novel real-time recovery for securing CPS. First, this work’s core component is a recovery control calculator using a Linear-Quadratic Regulator (LQR) with timing and safety constraints. This component can smoothly steer back a physical system under control to a target state set before a safe deadline and maintain the system state in the set once it is driven to it. We further propose an Alternating Direction Method of Multipliers (ADMM) based algorithm that can fast solve the LQR-based recovery problem. Second, supporting components for the attack recovery computation include a checkpointer, a state reconstructor, and a deadline estimator. To realize these components respectively, we propose (i) a sliding-window-based checkpointing protocol that governs sufficient trustworthy data, (ii) a state reconstruction approach that uses the checkpointed data to estimate the current system state, and (iii) a reachability-based approach to conservatively estimate a safe deadline. Finally, we implement our approach and demonstrate its effectiveness in dealing with totally 15 experimental scenarios which are designed based on 5 CPS simulators and 3 types of sensor attacks.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3200969900",
    "type": "article"
  },
  {
    "title": "HMDS: A Makespan Minimizing DAG Scheduler for Heterogeneous Distributed Systems",
    "doi": "https://doi.org/10.1145/3477037",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Debabrata Senapati; Arnab Sarkar; Chandan Karfa",
    "corresponding_authors": "",
    "abstract": "The problem of scheduling Directed Acyclic Graphs in order to minimize makespan ( schedule length ), is known to be a challenging and computationally hard problem. Therefore, researchers have endeavored towards the design of various heuristic solution generation techniques both for homogeneous as well as heterogeneous computing platforms. This work first presents HMDS-Bl , a list-based heuristic makespan minimization algorithm for task graphs on fully connected heterogeneous platforms. Subsequently, HMDS-Bl has been enhanced by empowering it with a low-overhead depth-first branch and bound based search approach, resulting in a new algorithm called HMDS . HMDS has been equipped with a set of novel tunable pruning mechanisms, which allow the designer to obtain a judicious balance between performance ( makespan ) and solution generation times, depending on the specific scenario at hand. Experimental analyses using randomly generated DAGs as well as benchmark task graphs, have shown that HMDS is able to comprehensively outperform state-of-the-art algorithms such as HEFT , PEFT , PPTS , etc., in terms of archived makespans while incurring bounded additional computation time overhead.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3201122766",
    "type": "article"
  },
  {
    "title": "A Composable Monitoring System for Heterogeneous Embedded Platforms",
    "doi": "https://doi.org/10.1145/3461647",
    "publication_date": "2021-07-09",
    "publication_year": 2021,
    "authors": "Giacomo Valente; Tiziana Fanni; Carlo Sau; Tania Di Mascio; Luigi Pomante; Francesca Palumbo",
    "corresponding_authors": "",
    "abstract": "Advanced computations on embedded devices are nowadays a must in any application field. Often, to cope with such a need, embedded systems designers leverage on complex heterogeneous reconfigurable platforms that offer high performance, thanks to the possibility of specializing/customizing some computing elements on board, and are usually flexible enough to be optimized at runtime. In this context, monitoring the system has gained increasing interest. Ideally, monitoring systems should be non-intrusive, serve several purposes, and provide aggregated information about the behavior of the different system components. However, current literature is not close to such ideality: For example, existing monitoring systems lack in being applicable to modern heterogeneous platforms. This work presents a hardware monitoring system that is intended to be minimally invasive on system performance and resources, composable, and capable of providing to the user homogeneous observability and transparent access to the different components of a heterogeneous computing platform, so system metrics can be easily computed from the aggregation of the collected information. Building on a previous work, this article is primarily focused on the extension of an existing hardware monitoring system to cover also specialized coprocessing units, and the assessment is done on a Xilinx FPGA-based System on Programmable Chip. Different explorations are presented to explain the level of customizability of the proposed hardware monitoring system, the tradeoffs available to the user, and the benefits with respect to standard de facto monitoring support made available by the targeted FPGA vendor.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3182643845",
    "type": "article"
  },
  {
    "title": "RT-ZooKeeper: Taming the Recovery Latency of a Coordination Service",
    "doi": "https://doi.org/10.1145/3477034",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Haoran Li; Chenyang Lu; Christopher Gill",
    "corresponding_authors": "",
    "abstract": "Fault-tolerant coordination services have been widely used in distributed applications in cloud environments. Recent years have witnessed the emergence of time-sensitive applications deployed in edge computing environments, which introduces both challenges and opportunities for coordination services. On one hand, coordination services must recover from failures in a timely manner. On the other hand, edge computing employs local networked platforms that can be exploited to achieve timely recovery. In this work, we first identify the limitations of the leader election and recovery protocols underlying Apache ZooKeeper, the prevailing open-source coordination service. To reduce recovery latency from leader failures, we then design RT-Zookeeper with a set of novel features including a fast-convergence election protocol, a quorum channel notification mechanism, and a distributed epoch persistence protocol. We have implemented RT-Zookeeper based on ZooKeeper version 3.5.8. Empirical evaluation shows that RT-ZooKeeper achieves 91% reduction in maximum recovery latency in comparison to ZooKeeper. Furthermore, a case study demonstrates that fast failure recovery in RT-ZooKeeper can benefit a common messaging service like Kafka in terms of message latency.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3200687135",
    "type": "article"
  },
  {
    "title": "Efficient Realization of Decision Trees for Real-Time Inference",
    "doi": "https://doi.org/10.1145/3508019",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Kuan-Hsun Chen; Chiahui Su; Christian Hakert; Sebastian Buschjäger; Chao-Lin Lee; Jenq‐Kuen Lee; Katharina Morik; Jian-Jia Chen",
    "corresponding_authors": "",
    "abstract": "For timing-sensitive edge applications, the demand for efficient lightweight machine learning solutions has increased recently. Tree ensembles are among the state-of-the-art in many machine learning applications. While single decision trees are comparably small, an ensemble of trees can have a significant memory footprint leading to cache locality issues, which are crucial to performance in terms of execution time. In this work, we analyze memory-locality issues of the two most common realizations of decision trees, i.e., native and if-else trees. We highlight that both realizations demand a more careful memory layout to improve caching behavior and maximize performance. We adopt a probabilistic model of decision tree inference to find the best memory layout for each tree at the application layer. Further, we present an efficient heuristic to take architecture-dependent information into account thereby optimizing the given ensemble for a target computer architecture. Our code-generation framework, which is freely available on an open-source repository, produces optimized code sessions while preserving the structure and accuracy of the trees. With several real-world data sets, we evaluate the elapsed time of various tree realizations on server hardware as well as embedded systems for Intel and ARM processors. Our optimized memory layout achieves a reduction in execution time up to 75 % execution for server-class systems, and up to 70 % for embedded systems, respectively.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4210473334",
    "type": "article"
  },
  {
    "title": "AdaTest: Reinforcement Learning and Adaptive Sampling for On-chip Hardware Trojan Detection",
    "doi": "https://doi.org/10.1145/3544015",
    "publication_date": "2022-06-14",
    "publication_year": 2022,
    "authors": "Huili Chen; Xinqiao Zhang; Ke Huang; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "This paper proposes AdaTest, a novel adaptive test pattern generation framework for efficient and reliable Hardware Trojan (HT) detection. HT is a backdoor attack that tampers with the design of victim integrated circuits (ICs) . AdaTest improves the existing HT detection techniques in terms of scalability and accuracy of detecting smaller Trojans in the presence of noise and variations. To achieve high trigger coverage, AdaTest leverages Reinforcement Learning (RL) to produce a diverse set of test inputs. Particularly, we progressively generate test vectors with high ‘reward’ values in an iterative manner. In each iteration, the test set is evaluated and adaptively expanded as needed. Furthermore, AdaTest integrates adaptive sampling to prioritize test samples that provide more information for HT detection, thus reducing the number of samples while improving the samples’ quality for faster exploration. We develop AdaTest with a Software/Hardware co-design principle and provide an optimized on-chip architecture solution. AdaTest’s architecture minimizes the hardware overhead in two ways: (i) Deploying circuit emulation on programmable hardware to accelerate reward evaluation of the test input; (ii) Pipelining each computation stage in AdaTest by automatically constructing auxiliary circuit for test input generation, reward evaluation, and adaptive sampling. We evaluate AdaTest’s performance on various HT benchmarks and compare it with two prior works that use logic testing for HT detection. Experimental results show that AdaTest engenders up to two orders of test generation speedup and two orders of test set size reduction compared to the prior works while achieving the same level or higher Trojan detection rate.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4224069029",
    "type": "article"
  },
  {
    "title": "Reliability Assessment and Safety Arguments for Machine Learning Components in System Assurance",
    "doi": "https://doi.org/10.1145/3570918",
    "publication_date": "2022-11-17",
    "publication_year": 2022,
    "authors": "Yi Dong; Wei Huang; Vibhav Bharti; Victoria Cox; Alec Banks; Sen Wang; Xingyu Zhao; Sven Schewe; Xiaowei Huang",
    "corresponding_authors": "",
    "abstract": "The increasing use of Machine Learning (ML) components embedded in autonomous systems -- so-called Learning-Enabled Systems (LESs) -- has resulted in the pressing need to assure their functional safety. As for traditional functional safety, the emerging consensus within both, industry and academia, is to use assurance cases for this purpose. Typically assurance cases support claims of reliability in support of safety, and can be viewed as a structured way of organising arguments and evidence generated from safety analysis and reliability modelling activities. While such assurance activities are traditionally guided by consensus-based standards developed from vast engineering experience, LESs pose new challenges in safety-critical application due to the characteristics and design of ML models. In this article, we first present an overall assurance framework for LESs with an emphasis on quantitative aspects, e.g., breaking down system-level safety targets to component-level requirements and supporting claims stated in reliability metrics. We then introduce a novel model-agnostic Reliability Assessment Model (RAM) for ML classifiers that utilises the operational profile and robustness verification evidence. We discuss the model assumptions and the inherent challenges of assessing ML reliability uncovered by our RAM and propose solutions to practical use. Probabilistic safety argument templates at the lower ML component-level are also developed based on the RAM. Finally, to evaluate and demonstrate our methods, we not only conduct experiments on synthetic/benchmark datasets but also scope our methods with case studies on simulated Autonomous Underwater Vehicles and physical Unmanned Ground Vehicles.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4309618441",
    "type": "article"
  },
  {
    "title": "Tutorial: Toward Robust Deep Learning against Poisoning Attacks",
    "doi": "https://doi.org/10.1145/3574159",
    "publication_date": "2022-12-06",
    "publication_year": 2022,
    "authors": "Huili Chen; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "Deep Learning (DL) has been increasingly deployed in various real-world applications due to its unprecedented performance and automated capability of learning hidden representations. While DL can achieve high task performance, the training process of a DL model is both time- and resource-consuming. Therefore, current supply chains of the DL models assume the customers obtain pre-trained Deep Neural Networks (DNNs) from the third-party providers that have sufficient computing power. In the centralized setting, the model designer trains the DL model using the local dataset. However, the collected training data may contain erroneous or poisoned data points. The model designer might craft malicious training samples and inject a backdoor in the DL model distributed to the users. As a result, the user’s model will malfunction. In the federated learning setting, the cloud server aggregates local models trained on individual local datasets and updates the global model. In this scenario, the local client could poison the local training set and/or arbitrarily manipulate the local update. If the cloud server incorporates the malicious local gradients in model aggregation, the resulting global model will have degraded performance or backdoor behaviors. In this article, we present a comprehensive overview of contemporary data poisoning and model poisoning attacks against DL models in both centralized and federated learning scenarios. In addition, we review existing detection and defense techniques against various poisoning attacks.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4311644718",
    "type": "article"
  },
  {
    "title": "Neural Network Compression for Noisy Storage Devices",
    "doi": "https://doi.org/10.1145/3588436",
    "publication_date": "2023-03-18",
    "publication_year": 2023,
    "authors": "Berivan Isik; Kristy Choi; Xin Zheng; Tsachy Weissman; Stefano Ermon; H.‐S. Philip Wong; Armin Alaghi",
    "corresponding_authors": "",
    "abstract": "Compression and efficient storage of neural network (NN) parameters is critical for applications that run on resource-constrained devices. Despite the significant progress in NN model compression, there has been considerably less investigation in the actual physical storage of NN parameters. Conventionally, model compression and physical storage are decoupled, as digital storage media with error-correcting codes (ECCs) provide robust error-free storage. However, this decoupled approach is inefficient as it ignores the overparameterization present in most NNs and forces the memory device to allocate the same amount of resources to every bit of information regardless of its importance. In this work, we investigate analog memory devices as an alternative to digital media – one that naturally provides a way to add more protection for significant bits unlike its counterpart, but is noisy and may compromise the stored model’s performance if used naively. We develop a variety of robust coding strategies for NN weight storage on analog devices, and propose an approach to jointly optimize model compression and memory resource allocation. We then demonstrate the efficacy of our approach on models trained on MNIST, CIFAR-10, and ImageNet datasets for existing compression techniques. Compared to conventional error-free digital storage, our method reduces the memory footprint by up to one order of magnitude, without significantly compromising the stored model’s accuracy.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3132779505",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Approximate Edge Inference Systems",
    "doi": "https://doi.org/10.1145/3589766",
    "publication_date": "2023-03-31",
    "publication_year": 2023,
    "authors": "Soumendu Kumar Ghosh; Arnab Raha; Vijay Raghunathan",
    "corresponding_authors": "",
    "abstract": "The rapid proliferation of the Internet of Things and the dramatic resurgence of artificial intelligence based application workloads have led to immense interest in performing inference on energy-constrained edge devices. Approximate computing (a design paradigm that trades off a small degradation in application quality for disproportionate energy savings) is a promising technique to enable energy-efficient inference at the edge. This article introduces the concept of an approximate edge inference system ( AxIS ) and proposes a systematic methodology to perform joint approximations between different subsystems in a deep neural network (DNN)-based edge inference system, leading to significant energy benefits compared to approximating individual subsystems in isolation. We use a smart camera system that executes various DNN-based image classification and object detection applications to illustrate how the sensor, memory, compute, and communication subsystems can all be approximated synergistically. We demonstrate our proposed methodology using two variants of a smart camera system: (a) Cam Edge , where the DNN is executed locally on the edge device, and (b) Cam Cloud , where the edge device sends the captured image to a remote cloud server that executes the DNN. We have prototyped such an approximate inference system using an Intel Stratix IV GX-based Terasic TR4-230 FPGA development board. Experimental results obtained using six large DNNs and four compact DNNs running image classification applications demonstrate significant energy savings (≈ 1.6× -4.7× for large DNNs and ≈ 1.5× -3.6× for small DNNs), for minimal (&lt;1%) loss in application-level quality. Furthermore, results using four object detection DNNs exhibit energy savings of ≈ 1.5× -5.2× for similar quality loss. Compared to approximating a single subsystem in isolation, AxIS achieves 1.05× -3.25× gains in energy savings for image classification and 1.35× -4.2× gains for object detection on average, for minimal (&lt;1%) application-level quality loss.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4362473790",
    "type": "article"
  },
  {
    "title": "A Review of Abstraction Methods Toward Verifying Neural Networks",
    "doi": "https://doi.org/10.1145/3617508",
    "publication_date": "2023-08-28",
    "publication_year": 2023,
    "authors": "Fateh Boudardara; Abderraouf Boussif; Pierre-Jean Meyer; Mohamed Ghazel",
    "corresponding_authors": "",
    "abstract": "Neural networks as a machine learning technique are increasingly deployed in various domains. Despite their performance and their continuous improvement, the deployment of neural networks in safety-critical systems, in particular for autonomous mobility, remains restricted. This is mainly due to the lack of (formal) specifications and verification methods and tools that allow for having sufficient confidence in the behavior of the neural-network-based functions. Recent years have seen neural network verification getting more attention; many verification methods were proposed, yet the practical applicability of these methods to real-world neural network models remains limited. The main challenge of neural network verification methods is related to the computational complexity and the large size of neural networks pertaining to complex functions. As a consequence, applying abstraction methods for neural network verification purposes is seen as a promising mean to cope with such issues. The aim of abstraction is to build an abstract model by omitting some irrelevant details or some details that are not highly impacting w.r.t some considered features. Thus, the verification process is made faster and easier while preserving, to some extent, the relevant behavior regarding the properties to be examined on the original model. In this article, we review both the abstraction techniques for activation functions and model size reduction approaches, with a particular focus on the latter. The review primarily discusses the application of abstraction techniques on feed-forward neural networks and explores the potential for applying abstraction to other types of neural networks. Throughout the article, we present the main idea of each approach and then discuss its respective advantages and limitations in detail. Finally, we provide some insights and guidelines to improve the discussed methods.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4386224163",
    "type": "review"
  },
  {
    "title": "Energy-Aware Adaptive Mixed-Criticality Scheduling with Semi-Clairvoyance and Graceful Degradation",
    "doi": "https://doi.org/10.1145/3632749",
    "publication_date": "2023-11-13",
    "publication_year": 2023,
    "authors": "Yi-Wen Zhang; Hui Zheng; Zonghua Gu",
    "corresponding_authors": "",
    "abstract": "The classic Mixed-Criticality System (MCS) task model is a non-clairvoyance model in which the change of the system behavior is based on the completion of high-criticality tasks while dropping low-criticality tasks in high-criticality mode. In this paper, we simultaneously consider graceful degradation and semi-clairvoyance in MCS. We first propose the analysis for adaptive mixed-criticality with semi-clairvoyance denoted as C-AMC-sem. The so-called semi-clairvoyance refers to the system’s behavior change being revealed at the time that jobs are released. Moreover, we propose a new algorithm based on C-AMC-sem to reduce energy consumption. Finally, we verify the performance of the proposed algorithms via experiments upon synthetically generated tasksets. The experimental results indicate that the proposed algorithms significantly outperform the existing algorithms.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4388638918",
    "type": "article"
  },
  {
    "title": "The Sparse Synchronous Model on Real Hardware",
    "doi": "https://doi.org/10.1145/3572920",
    "publication_date": "2024-08-14",
    "publication_year": 2024,
    "authors": "John Hui; Stephen A. Edwards",
    "corresponding_authors": "",
    "abstract": "We present the Sparse Synchronous model (SSM) of computation, which allows a programmer to specify software timing more precisely than the traditional “heartbeat” of mainstream operating systems or the synchronous languages. SSM is a mix of semantics inspired by discrete event simulators and the synchronous languages designed to operate in resource-constrained environments such as microcontrollers. SSM provides precise timing prescriptions, concurrency, and determinism. We implement SSM in SSML, a toy language along with a runtime system that includes a scheduler, memory manager, and an interface that works with a real-time operating system to keep the model synchronized with the real world. Experimentally, we find our implementation is able to perform jitter-free I/O in the 10s of kHz on a microcontroller.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4311401823",
    "type": "article"
  },
  {
    "title": "Deterministic Coordination Across Multiple Timelines",
    "doi": "https://doi.org/10.1145/3615357",
    "publication_date": "2024-08-14",
    "publication_year": 2024,
    "authors": "Marten Lohstroh; Soroush Bateni; Christian Menard; Alexander Schulz-Rosengarten; Jerónimo Castrillón; Edward A. Lee",
    "corresponding_authors": "",
    "abstract": "We discuss a novel approach for constructing deterministic reactive systems that revolves around a temporal model that incorporates a multiplicity of timelines. This model is central to Lingua Franca ( LF ), a polyglot coordination language and compiler toolchain we are developing for the definition and composition of concurrent components called reactors, which are objects that react to and emit discrete events. Our temporal model differs from existing models like the logical execution time (LET) paradigm and synchronous languages in that it reflects that there are always at least two distinct timelines involved in a reactive system; a logical one and a physical one—and possibly multiple of each kind. This article explains how the relationship between events across timelines facilitates reasoning about consistency and availability across components in cyber-physical systems (CPSs).",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4387664626",
    "type": "article"
  },
  {
    "title": "STDF: Spatio-Temporal Deformable Fusion for Video Quality Enhancement on Embedded Platforms",
    "doi": "https://doi.org/10.1145/3645113",
    "publication_date": "2024-02-08",
    "publication_year": 2024,
    "authors": "Jianing Deng; Shunjie Dong; Lvcheng Chen; Jingtong Hu; Cheng Zhuo",
    "corresponding_authors": "",
    "abstract": "With the development of embedded systems and deep learning, it is feasible to combine them for offering various and convenient human-centered services, which is based on high-quality (HQ) videos. However, due to the limit of video traffic load and unavoidable noise, the visual quality of an image from an edge camera may degrade significantly, influencing the overall video and service quality. To maintain video stability, video quality enhancement (QE), aiming at recovering HQ videos from their distorted low-quality (LQ) sources, has aroused increasing attention in recent years. The key challenge for video QE lies in how to effectively aggregate complementary information from multiple frames (i.e., temporal fusion). To handle diverse motion in videos, existing methods commonly apply motion compensation before the temporal fusion. However, the motion field estimated from the distorted LQ video tends to be inaccurate and unreliable, thereby resulting in ineffective fusion and restoration. In addition, motion estimation for consecutive frames is generally conducted in a pairwise manner, which leads to expensive and inefficient computation. In this article, we propose a fast yet effective temporal fusion scheme for video QE by incorporating a novel Spatio-Temporal Deformable Convolution (STDC) to simultaneously compensate motion and aggregate temporal information. Specifically, the proposed temporal fusion scheme takes a target frame along with its adjacent reference frames as input to jointly estimate an offset field to deform the spatio-temporal sampling positions of convolution. As a result, complementary information from multiple frames can be fused within the STDC operation in one forward pass. Extensive experimental results on three benchmark datasets show that our method performs favorably to the state of the art in terms of accuracy and efficiency.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4391653272",
    "type": "article"
  },
  {
    "title": "Tuning garbage collection for reducing memory system energy in an embedded java environment",
    "doi": "https://doi.org/10.1145/581888.581892",
    "publication_date": "2002-11-01",
    "publication_year": 2002,
    "authors": "Gong Chen; R. Shetty; Mahmut Kandemir; N. Vijaykrishnan; M.J. Irwin; Mario Wolczko",
    "corresponding_authors": "",
    "abstract": "Java has been widely adopted as one of the software platforms for the seamless integration of diverse computing devices. Over the last year, there has been great momentum in adopting Java technology in devices such as cellphones, PDAs, and pagers where optimizing energy consumption is critical. Since, traditionally, the Java virtual machine (JVM), the cornerstone of Java technology, is tuned for performance, taking into account energy consumption requires reevaluation, and possibly redesign of the virtual machine. This motivates us to tune specific components of the virtual machine for a battery-operated architecture. As embedded JVMs are designed to run for long periods of time on limited-memory embedded systems, creating and managing Java objects is of critical importance. The garbage collector (GC) is an important part of the JVM responsible for the automatic reclamation of unused memory. This article shows that the GC is not only important for limited-memory systems but also for energy-constrained architectures.This article focuses on tuning the GC to reduce energy consumption in a multibanked memory architecture. Tuning the GC is important not because it consumes a sizeable portion of overall energy during execution, but because it influences the energy consumed in the memory during application execution. In particular, we present a GC-controlled leakage energy optimization technique that shuts off memory banks that do not hold live data. Using two different commercial GCs and a suite of thirteen mobile applications, we evaluate the effectiveness of the GC-controlled energy optimization technique and study its sensitivity to different parameters such as bank size, the garbage collection frequency, object allocation style, compaction style, and compaction frequency. We observe that the energy consumption of an embedded Java application can be significantly more if the GC parameters are not tuned appropriately. Further, we notice that the object allocation pattern and the number of memory banks available in the underlying architecture are limiting factors on how effectively GC parameters can be used to optimize the memory energy consumption.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W1982284547",
    "type": "article"
  },
  {
    "title": "Blocking-aware processor voltage scheduling for real-time tasks",
    "doi": "https://doi.org/10.1145/993396.993401",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Fan Zhang; Samuel T. Chanson",
    "corresponding_authors": "",
    "abstract": "As mobile computing is getting popular, there is a growing need for techniques that minimize energy consumption on battery-powered mobile devices. Processor voltage scheduling can effectively reduce processor energy consumption by lowering the processor speed. In this paper, we study voltage scheduling for real-time periodic tasks with non-preemptible sections. Three schemes are proposed: The static speed algorithm derives the minimum static feasible speed based on the stack resource policy. Due to blocking, this static speed is usually higher than the speed required for scheduling fully preemptible tasks (called the utilization speed). Two dynamic speed algorithms are then introduced to further reduce energy consumption. The novel dual speed algorithm operates the processor at the utilization speed whenever possible and switches to the higher static speed only when blocking occurs. The dual speed dynamic reclaiming algorithm reserves time budget for each job, reclaims the unused time budget from completed jobs and redistributes it to subsequent jobs so they can run at a lower speed whenever possible. Feasibility conditions for real-time task sets have been derived and proved mathematically. Simulation results show that the proposed voltage scheduling algorithms dramatically reduce processor energy consumption over non-power-aware scheduling algorithms. Furthermore, the two dynamic speed algorithms consistently outperform the static speed scheme in a wide range of system and workload conditions.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2061892585",
    "type": "article"
  },
  {
    "title": "A curriculum for embedded system engineering",
    "doi": "https://doi.org/10.1145/1086519.1086525",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "R.E. Seviora",
    "corresponding_authors": "R.E. Seviora",
    "abstract": "The paper presents a curriculum for a 4-year undergraduate program in Embedded System Engineering (ESE). The curriculum was developed using a two-step approach. First, a body of education knowledge for Embedded System Engineering was defined. The body consists of sixteen knowledge areas. Each area is composed of several knowledge units, some designated as core and others as electives. The minimum lecture time for the core of each knowledge area is identified. The Body of Knowledge for Computer Engineering, developed by the IEEE-CS/ACM task force for Computing Curricula, was used as a reference. The education knowledge for ESE then served as the base for the development of the program curriculum. The curriculum has a strong mathematics and basic science base, an in-depth exposure to engineering science and design of systems implemented with digital hardware and software, and coverage of two prominent application areas of embedded systems. The curriculum core takes approximately 3 years of the program; the remaining part is elective.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W1987373466",
    "type": "article"
  },
  {
    "title": "Elliptic and hyperelliptic curves on embedded μP",
    "doi": "https://doi.org/10.1145/1015047.1015051",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "Thomas Wollinger; Jan Pelzl; Volker Wittelsberger; Christof Paar; Gökay Saldamlı; Çetin Kaya Koç",
    "corresponding_authors": "",
    "abstract": "It is widely recognized that data security will play a central role in future IT systems. Providing public-key cryptographic primitives, which are the core tools for security, is often difficult on embedded processor due to computational, memory, and power constraints. This contribution appears to be the first thorough comparison of two public-key families, namely elliptic curve (ECC) and hyperelliptic curve cryptosystems on a wide range of embedded processor types (ARM, ColdFire, PowerPC). We investigated the influence of the processor type, resources, and architecture regarding throughput. Further, we improved previously known HECC algorithms resulting in a more efficient arithmetic.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2026832064",
    "type": "article"
  },
  {
    "title": "The design of dynamically reconfigurable datapath coprocessors",
    "doi": "https://doi.org/10.1145/993396.993403",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "Zhining Huang; Sharad Malik; Nahri Moreano; Guido Araújo",
    "corresponding_authors": "",
    "abstract": "Increasing nonrecurring engineering and mask costs are making it harder to turn to hardwired application specific integrated circuit (ASIC) solutions for high-performance applications. The volume required to amortize these high costs has been increasing, making it increasingly expensive to afford ASIC solutions for medium-volume products. This has led to designers seeking programmable solutions of varying sorts using these so-called programmable platforms. These programmable platforms span a large range from bit-level programmable field programmable gate arrays to word-level programmable application-specific, and in some cases even general-purpose processors. The programmability comes with a power and performance overhead. Attempts to reduce this overhead typically involve making some core hardwired ASIC like logic blocks accessible to the programmable elements. This paper presents one such hybrid solution in this space---a relatively simple processor with a dynamically reconfigurable datapath acting as an accelerating coprocessor. This datapath consists of hardwired function units and reconfigurable interconnect. We present a methodology for the design of these solutions and illustrate it with two complete case studies: an MPEG2 coder, and a GSM coder, to show how significant speedups can be obtained using relatively little hardware. This work is part of the MESCAL project, which is geared towards developing design environments for the development of application-specific platforms.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2094999871",
    "type": "article"
  },
  {
    "title": "Robust implicit EDF",
    "doi": "https://doi.org/10.1145/1274858.1274866",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Tanya L. Crenshaw; Spencer Hoke; Ajay Tirumala; Marco Caccamo",
    "corresponding_authors": "",
    "abstract": "Advances in wireless technology have brought us closer to extensive deployment of distributed real-time embedded systems connected through a wireless channel. The medium-access control (MAC) layer protocol is critical in providing a real-time guarantee. We have devised a real-time wireless MAC protocol, robust implicit earliest deadline first, or RI-EDF. Packets are transmitted according to EDF scheduling rules, offering a protocol that implicitly avoids contention. In the event of a packet loss or a node failure, every node has the opportunity to recover the schedule based on a static recovery priority, offering a protocol that is robust with no central point of failure. We demonstrate in simulations that RI-EDF provides better goodput and lower packet loss than existing protocols like 802.11 PCF and EDCF. In our implementation and distributed control test-bed, we show that RI-EDF provides better throughput than the TinyOS MAC-layer protocol. Overall, RI-EDF provides predictable temporal behavior with minimal impact on node failures, packet losses, and noise in the channel.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W1988669199",
    "type": "article"
  },
  {
    "title": "An energy-aware framework for dynamic software management in mobile computing systems",
    "doi": "https://doi.org/10.1145/1347375.1347380",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Yunsi Fei; Lin Zhong; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Energy efficiency has become a very important and challenging issue for resource-constrained mobile computers. In this article, we propose a novel dynamic software management (DSOM) framework to improve battery utilization. We have designed and implemented a DSOM module in user space, independent of the operating system (OS), which explores quality-of-service (QoS) adaptation to reduce system energy and employs a priority-based preemption policy for multiple applications to avoid competition for limited energy resources. Software energy macromodels for mobile applications are employed to predict energy demand at each QoS level, so that the DSOM module is able to select the best possible trade-off between energy conservation and application QoS; it also honors the priority desired by the user. Our experimental results for some mobile applications (video player, speech recognizer, voice-over-IP) show that this approach can meet user-specified task-oriented goals and significantly improve battery utilization.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2085156986",
    "type": "article"
  },
  {
    "title": "Energy-aware cosynthesis of real-time multimedia applications on MPSoCs using heterogeneous scheduling policies",
    "doi": "https://doi.org/10.1145/1331331.1331333",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Minyoung Kim; Sudarshan Banerjee; Nikil Dutt; Nalini Venkatasubramanian",
    "corresponding_authors": "",
    "abstract": "Real-time multimedia applications are increasingly being mapped onto MPSoC (multiprocessor system-on-chip) platforms containing hardware--software IPs (intellectual property), along with a library of common scheduling policies such as EDF, RM. The choice of a scheduling policy for each IP is a key decision that greatly affects the design's ability to meet real-time constraints, and also directly affects the energy consumed by the design. We present a cosynthesis framework for design space exploration that considers heterogeneous scheduling while mapping multimedia applications onto such MPSoCs. In our approach, we select a suitable scheduling policy for each IP such that system energy is minimized—our framework also includes energy-reduction techniques utilizing dynamic power management. Experimental results on a realistic multimode multimedia terminal application demonstrate that our approach enables us to select design points with up to 60.5% reduced energy for a given area constraint, while meeting all real-time requirements. More importantly, our approach generates a tradeoff space between energy and cost allowing designers to comparatively evaluate multiple system level mappings.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2045648945",
    "type": "article"
  },
  {
    "title": "A truly two-dimensional systolic array FPGA implementation of QR decomposition",
    "doi": "https://doi.org/10.1145/1596532.1596535",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Xiaojun Wang; Miriam Leeser",
    "corresponding_authors": "",
    "abstract": "We have implemented a two-dimensional systolic array QR decomposition on a Xilinx Virtex5 FPGA using the Givens rotation algorithm. QR decomposition is a key step in many DSP applications including sonar beamforming, channel equalization, and 3G wireless communication. Compared to previous work that implements Givens rotations using a one-dimensional systolic array, our implementation uses a truly two-dimensional systolic array architecture. As a result, latency scales well for larger matrices. In addition, prior work avoids divide and square root operations in the Givens rotation algorithm by using special operations such as CORDIC or special number systems such as the logarithmic number system (LNS). In contrast, our design uses straightforward floating-point divide and square root implementations, which makes it easier to be used within a larger system. In our design, the input matrix size can be configured at compile time to many different sizes, making it easily scalable to future large FPGAs or over multiple FPGAs. The QR module is fully pipelined with a throughput of over 130MHz for the IEEE single-precision floating-point format. The peak performance for a 12 × 12 input matrix is approximately 35 GFLOPs.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W1986431723",
    "type": "article"
  },
  {
    "title": "Fast exploration of bus-based communication architectures at the CCATB abstraction",
    "doi": "https://doi.org/10.1145/1331331.1331346",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Sudeep Pasricha; Nikil Dutt; Mohamed Ben-Romdhane",
    "corresponding_authors": "",
    "abstract": "Currently, system-on-chip (SoC) designs are becoming increasingly complex, with more and more components being integrated into a single SoC design. Communication between these components is increasingly dominating critical system paths and frequently becomes the source of performance bottlenecks. It, therefore, becomes imperative for designers to explore the communication space early in the design flow. Traditionally, system designers have used Pin-Accurate Bus Cycle Accurate (PA-BCA) models for early communication space exploration. These models capture all of the bus signals and strictly maintain cycle accuracy, which is useful for reliable performance exploration but results in slow simulation speeds for complex, designs, even when they are modeled using high-level languages. Recently, there have been several efforts to use the Transaction-Level Modeling (TLM) paradigm for improving simulation performance in BCA models. However, these transaction-based BCA (T-BCA) models capture a lot of details that can be eliminated when exploring communication architectures. In this paper, we extend the TLM approach and propose a new transaction-based modeling abstraction level (CCATB) to explore the communication design space. Our abstraction level bridges the gap between the TLM and BCA levels, and yields an average performance speedup of 120% over PA-BCA and 67% over T-BCA models, on average. The CCATB models are not only faster to simulate, but also extremely accurate and take less time to model compared to both T-BCA and PA-BCA models. We describe the mechanisms that produce the speedup in CCATB models and also analyze how the achieved simulation speedup scales with design complexity. To demonstrate the effectiveness of using CCATB for exploration, we present communication space exploration case studies from the broadband communication and multimedia application domains.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2054259023",
    "type": "article"
  },
  {
    "title": "Transmission power assignment with postural position inference for on-body wireless communication links",
    "doi": "https://doi.org/10.1145/1814539.1814553",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Muhannad Quwaider; Jayanthi Rao; Subir Biswas",
    "corresponding_authors": "",
    "abstract": "This article presents a novel transmission power assignment mechanism for on-body wireless links formed between severely energy-constrained wearable and implanted sensors. The key idea is to develop a measurement-based framework in which the postural position as it pertains to a given wireless link is first inferred based on the measured RF signal strength and packet drops. Then optimal power assignment is done by fitting those measurement results into a model describing the relationship between the assigned power and the resulting signal strength. A closed loop power control mechanism is then added for iterative convergence to the optimal power level as a response to both intra-and-inter posture body movements. This provides a practical paradigm for on-body power assignment, which cannot leverage the existing mechanisms in the literature that rely on localization, which is not realistic for on-body sensors. Extensive experimental results are provided to demonstrate the model building and algorithm performance on a prototype body area network. The proposed mechanism has also been compared with a number of other closed loop mechanisms and an experimental benchmark.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2036966666",
    "type": "article"
  },
  {
    "title": "MobiSense",
    "doi": "https://doi.org/10.1145/1814539.1814552",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Agustinus Borgy Waluyo; Wee-Soon Yeoh; Isaac Pek; Yi-Han Yong; Xiang Chen",
    "corresponding_authors": "",
    "abstract": "This article introduces MobiSense, a novel mobile health monitoring system for ambulatory patients. MobiSense resides in a mobile device, communicates with a set of body sensor devices attached to the wearer, and processes data from these sensors. MobiSense is able to detect body postures such as lying, sitting, and standing, and walking speed, by utilizing our rule-based heuristic activity classification scheme based on the extended Kalman (EK) Filtering algorithm. Furthermore, the proposed system is capable of controlling each of the sensor devices, and performing resource reconfiguration and management schemes (sensor sleep/wake-up mode). The architecture of MobiSense is highlighted and discussed in depth. The system has been implemented, and its prototype is showcased. We have also carried out rigorous performance measurements of the system including real-time and query latency as well as the power consumption of the sensor nodes. The accuracy of our activity classifier scheme has been evaluated by involving several human subjects, and we found promising results.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2046718428",
    "type": "article"
  },
  {
    "title": "Classes and inheritance in actor-oriented design",
    "doi": "https://doi.org/10.1145/1550987.1550992",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Edward A. Lee; Xiaojun Liu; Stephen Neuendorffer",
    "corresponding_authors": "",
    "abstract": "Actor-oriented components emphasize concurrency and temporal semantics and are used for modeling and designing embedded software and hardware. Actors interact with one another through ports via a messaging schema that can follow any of several concurrent semantics. Domain-specific actor-oriented languages and frameworks are common (Simulink, LabVIEW, SystemC, etc.). However, they lack many modularity and abstraction mechanisms that programmers have become accustomed to in object-oriented components, such as classes, inheritance, interfaces, and polymorphism, except as inherited from the host language. This article shows a form that such mechanisms can take in actor-oriented components, gives a formal structure, and describes a prototype implementation. The mechanisms support actor-oriented class definitions, subclassing, inheritance, and overriding. The formal structure imposes structural constraints on a model (mainly the “derivation invariant”) that lead to a policy to govern inheritance. In particular, the structural constraints permit a disciplined form of multiple inheritance with unambiguous inheritance and overriding behavior. The policy is based formally on a generalized ultrametric space with some remarkable properties. In this space, inheritance is favored when actors are “closer” (in the generalized ultrametric), and we show that when inheritance can occur from multiple sources, one source is always unambiguously closer than the other.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W1971855334",
    "type": "article"
  },
  {
    "title": "A reliability enhancement design under the flash translation layer for MLC-based flash-memory storage systems",
    "doi": "https://doi.org/10.1145/2512467",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Yuan-Hao Chang; Ming-Chang Yang; Tei‐Wei Kuo; Ren‐Hung Hwang",
    "corresponding_authors": "",
    "abstract": "Although flash memory has gained very strong momentum in the storage market, the reliability of flash-memory chips has been dropped significantly in the past years. This article presents a reliability enhancement design under the flash management layer (i.e., flash translation layer) to address this concern so as to reduce the design complexity of flash-memory management software/firmware and to improve the maintainability and portability of existing and future products. In particular, a log-based write strategy with a hash-based caching policy is proposed to provide extra ECC redundancy and performance improvement. Strategies for bad block management are also presented. The failure rate of flash-memory storage systems is analyzed with the considerations of bit errors. The proposed design is later evaluated by a series of experiments based on realistic traces. It was shown that the proposed approach could significantly improve the reliability of flash memory with very limited system overheads.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2029736618",
    "type": "article"
  },
  {
    "title": "An adaptive file-system-oriented FTL mechanism for flash-memory storage systems",
    "doi": "https://doi.org/10.1145/2146417.2146426",
    "publication_date": "2012-03-01",
    "publication_year": 2012,
    "authors": "Yuan-Hao Chang; Po-Liang Wu; Tei‐Wei Kuo; Shih‐Hao Hung",
    "corresponding_authors": "",
    "abstract": "As flash memory becomes popular over various platforms, there is a strong demand regarding the performance degradation problem, due to the special characteristics of flash memory. This research proposes the design of a file-system-oriented flash translation layer, in which a filter mechanism is designed to separate the access requests of file-system metadata and file contents for better performance. A recovery scheme is then proposed for maintaining the integrity of a file system. The proposed flash translation layer is implemented as a Linux device driver and evaluated with respect to ext2 and ext3 file systems. Experiments were also done over NTFS by a series of realistic traces. The experimental results show significant performance improvement over ext2, ext3, and NTFS file systems with limited system overheads.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2171116656",
    "type": "article"
  },
  {
    "title": "Improving the fault resilience of an H.264 decoder using static analysis methods",
    "doi": "https://doi.org/10.1145/2536747.2536753",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Florian Schmoll; Andreas Heinig; Peter Marwedel; Michael S. Engel",
    "corresponding_authors": "",
    "abstract": "Fault tolerance rapidly evolves into one of the most significant design objectives for embedded systems due to reduced semiconductor structures and supply voltages. However, resource-constrained systems cannot afford traditional error correction for overhead and cost reasons. New methods are required to sustain acceptable service quality in case of errors while avoiding crashes. We present a flexible fault-tolerance approach that is able to select correction actions depending on error semantics using application annotations and static analysis approaches. We verify the validity of our approach by analyzing the vulnerability and improving the reliability of an H.264 decoder using flexible error handling.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2009832136",
    "type": "article"
  },
  {
    "title": "Formal Verification of Downtimeless System Evolution in Embedded Automation Controllers",
    "doi": "https://doi.org/10.1145/2406336.2406353",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Christoph Sünder; Valeriy Vyatkin; Alois Zoitl",
    "corresponding_authors": "",
    "abstract": "This article presents a new formal approach to validation of on-the-fly modification of control software in automation systems. The concept of downtimeless system evolution (DSE) is introduced. The DSE is essentially based on the use of IEC 61499 system architecture and formal modeling and verification of the hardware and software of an automation device. The validation is performed by means of two complimentary techniques: analytic calculations and formal verification by model-checking.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2014187419",
    "type": "article"
  },
  {
    "title": "Wireless noncontact ECG and EEG biopotential sensors",
    "doi": "https://doi.org/10.1145/2485984.2485991",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Miao Yu; Patrick Ng; Gert Cauwenberghs",
    "corresponding_authors": "",
    "abstract": "Wearable, unobtrusive and patient friendly physiological sensors will be a key driving force in the wireless health revolution. Cardiac (ECG) and brain (EEG) signals are two important signal modalities indicative of healthy and diseased states of body and mind that directly benefit from long-term monitoring. Despite advancements in wireless and embedded electronics technology, however, ECG/EEG monitoring devices still face problems with patient compliance and comfort from the use wet/gel electrodes. We have developed two wireless biopotential instrumentation systems using noncontact electrodes that can operate without direct skin contact and through thin layers of fabric. The first system is a general purpose replacement for traditional ECG/EEG telemetry systems and the second is a compact, fully self-contained wireless ECG tag. All of the issues relating to the design of low noise, high performance noncontact sensors are discussed along with full technical details, circuit schematics and construction techniques. The noncontact electrode has been integrated into both a wearable ECG chest harness as well an EEG headband and characterized in a battery of experiments that represent potential health applications including resting ECG, exercise ECG and EEG directly against standard clinical adhesive Ag/AgCl electrodes. With careful design and secure mechanical harnesses the noncontact sensor is capable of approaching the quality of conventional electrodes.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2037676047",
    "type": "article"
  },
  {
    "title": "A reliable gateway for in-vehicle networks based on LIN, CAN, and FlexRay",
    "doi": "https://doi.org/10.1145/2146417.2146424",
    "publication_date": "2012-03-01",
    "publication_year": 2012,
    "authors": "Suk-Hyun Seo; Jin-Ho Kim; Sung‐Ho Hwang; Key Ho Kwon; Jae Wook Jeon",
    "corresponding_authors": "",
    "abstract": "This article describes a reliable gateway for in-vehicle networks. Such networks include local interconnect networks, controller area networks, and FlexRay. There is some latency when transferring a message from one node (source) to another node (destination). A high probability of error exists due to different protocol specifications such as baud-rate, and message frame format. Therefore, deploying a reliable gateway is a challenge to the automotive industry. We propose a reliable gateway based on the OSEK/VDX components for in-vehicle networks. We also examine the gateway system developed, and then we evaluate the performance of our proposed system.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2044470426",
    "type": "article"
  },
  {
    "title": "Verification of Periodically Controlled Hybrid Systems",
    "doi": "https://doi.org/10.1145/2331147.2331163",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Tichakorn Wongpiromsarn; Sayan Mitra; Andrew Lamperski; Richard M. Murray",
    "corresponding_authors": "",
    "abstract": "This article introduces Periodically Controlled Hybrid Automata (PCHA) for modular specification of embedded control systems. In a PCHA, control actions that change the control input to the plant occur roughly periodically, while other actions that update the state of the controller may occur in the interim. Such actions could model, for example, sensor updates and information received from higher-level planning modules that change the set point of the controller. Based on periodicity and subtangential conditions, a new sufficient condition for verifying invariant properties of PCHAs is presented. For PCHAs with polynomial continuous vector fields, it is possible to check these conditions automatically using, for example, quantifier elimination or sum of squares decomposition. We examine the feasibility of this automatic approach on a small example. The proposed technique is also used to manually verify safety and progress properties of a fairly complex planner-controller subsystem of an autonomous ground vehicle. Geometric properties of planner-generated paths are derived which guarantee that such paths can be safely followed by the controller.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1966911833",
    "type": "article"
  },
  {
    "title": "Implementing constrained cyber-physical systems with IEC 61499",
    "doi": "https://doi.org/10.1145/2362336.2362345",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Li Hsien Yoong; Partha S. Roop; Zoran Salčić",
    "corresponding_authors": "",
    "abstract": "Cyber-physical systems (CPS) are integrations of computation and control with sensing and actuation of the physical environment. Typically, such systems consist of embedded computers that monitor and control physical processes in a feedback loop. While modern electronic systems are increasingly characterized as CPS, their design and synthesis still rely on traditional methods, which lack systematic and automated techniques for accomplishment. Recently, IEC 61499 has been proposed as a standard for designing industrial process-control and measurement systems. It prescribes a component-based approach for developing industrial automation software using function blocks. Executable code can then be automatically generated and simulated from these function blocks. This bodes well for designers of CPS, who are more likely to be experts in specific industrial domains, rather than in computer science. The intuitive graphical nature and automatic code synthesis of IEC 61499 programs will alleviate the programming burden of industrial engineers, while ensuring more reliable software. While software synthesis from IEC 61499 programs is not new, the generation of efficient code from them has been wanting. This has made it difficult for function blocks to be used in software development for resource-constrained embedded controllers commonly employed in CPS. To address this, we present an approach that can generate very efficient code from function block descriptions. Experimental results from a benchmark suite shows that our approach produces substantially faster and smaller code compared to existing techniques.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2060674828",
    "type": "article"
  },
  {
    "title": "The ReNoC Reconfigurable Network-on-Chip",
    "doi": "https://doi.org/10.1145/2043662.2043669",
    "publication_date": "2011-11-01",
    "publication_year": 2011,
    "authors": "Matthias Bo Stuart; Mikkel Bystrup Stensgaard; Jens Sparsø",
    "corresponding_authors": "",
    "abstract": "This article presents a reconfigurable network-on-chip architecture called ReNoC, which is intended for use in general-purpose multiprocessor system-on-chip platforms, and which enables application-specific logical NoC topologies to be configured, thus providing both efficiency and flexibility. The article presents three novel algorithms that synthesize an application-specific NoC topology, map it onto the physical ReNoC architecture, and create deadlock-free, application-specific routing algorithms. We apply our algorithms to a mixture of real and synthetic applications and target three different physical architectures. Compared to a conventional NoC, ReNoC reduces power consumption by up to 58% on average.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2150550003",
    "type": "article"
  },
  {
    "title": "Configurable Detection of SDC-causing Errors in Programs",
    "doi": "https://doi.org/10.1145/3014586",
    "publication_date": "2017-03-28",
    "publication_year": 2017,
    "authors": "Qining Lu; Guanpeng Li; Karthik Pattabiraman; Meeta S. Gupta; Jude A. Rivers",
    "corresponding_authors": "",
    "abstract": "Silent Data Corruption (SDC) is a serious reliability issue in many domains, including embedded systems. However, current protection techniques are brittle and do not allow programmers to trade off performance for SDC coverage. Further, many require tens of thousands of fault-injection experiments, which are highly time- and resource-intensive. In this article, we propose two empirical models, SDCTune and SDCAuto , to predict the SDC proneness of a program’s data. Both models are based on static and dynamic features of the program alone and do not require fault injections to be performed. The main difference between them is that SDCTune requires manual tuning while SDCAuto is completely automated, using machine-learning algorithms. We then develop an algorithm using both models to selectively protect the most SDC-prone data in the program subject to a given performance overhead bound. Our results show that both models are accurate at predicting the relative SDC rate of an application compared to fault injection, for a fraction of the time taken. Further, in terms of efficiency of detection (i.e., ratio of SDC coverage provided to performance overhead), our technique outperforms full duplication by a factor of 0.78x to 1.65x with the SDCTune model and 0.62x to 0.96x with SDCAuto model.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2242116942",
    "type": "article"
  },
  {
    "title": "PMC",
    "doi": "https://doi.org/10.1145/3019611",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Mohamed Hassan; Hiren Patel; Rodolfo Pellizzoni",
    "corresponding_authors": "",
    "abstract": "We propose a novel approach to schedule memory requests in Mixed Criticality Systems (MCS). This approach supports an arbitrary number of criticality levels by enabling the MCS designer to specify memory requirements per task. It retains locality within large-size requests to satisfy memory requirements of all tasks. To achieve this target, we introduce a compact time-division-multiplexing scheduler, and a framework that constructs optimal schedules to manage requests to off-chip memory. We also present a static analysis that guarantees meeting requirements of all tasks. We compare the proposed controller against state-of-the-art memory controllers using both a case study and synthetic experiments.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2612242064",
    "type": "article"
  },
  {
    "title": "Application-Aware Swapping for Mobile Systems",
    "doi": "https://doi.org/10.1145/3126509",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Sang-Hoon Kim; Jinkyu Jeong; Jin‐Soo Kim",
    "corresponding_authors": "",
    "abstract": "There has been a constant demand for memory in modern mobile systems to provide users with better experience. Swapping is one of the cost-effective software solutions to provide extra usable memory by reclaiming inactive pages and improving memory utilization. However, swapping has not been actively adopted to mobile systems since it incurs a significant amount of I/O, which in fact impairs system performance as well as user experience. In this paper, we propose a novel scheme to properly harness the swapping to mobile systems. We identify that a vast amount of I/O for swapping comes from the conflict of the traditional page-level approach of the swapping and the process-level memory management scheme tailored to mobile systems. Moreover, we find out that the current victim page selection policy is not effective due to the process-level policy. To address these problems, we revise the victim selection policy to resolve the conflict and to selectively perform swapping according to the efficacy of swapping. Evaluation using a running prototype with realistic workloads indicates that the propose scheme effectively reduces the paging traffic, thereby improving user experience as well as energy consumption.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2759112196",
    "type": "article"
  },
  {
    "title": "Trinity",
    "doi": "https://doi.org/10.1145/3173039",
    "publication_date": "2018-02-13",
    "publication_year": 2018,
    "authors": "Feng Li; Yanbing Yang; Zicheng Chi; Liya Zhao; Yaowen Yang; Jun Luo",
    "corresponding_authors": "",
    "abstract": "Whereas a lot of efforts have been put on energy conservation in wireless sensor networks (WSNs), the limited lifetime of these systems still hampers their practical deployments. This situation is further exacerbated indoors, as conventional energy harvesting (e.g., solar) may not always work. To enable long-lived indoor sensing, we report in this article a self-sustaining sensing system that draws energy from indoor environments, adapts its duty-cycle to the harvested energy, and pays back the environment by enhancing the awareness of the indoor microclimate through an “energy-free” sensing. First of all, given the pervasive operation of heating, ventilation, and air conditioning (HVAC) systems indoors, our system harvests energy from airflow introduced by the HVAC systems to power each sensor node. Secondly, as the harvested power is tiny, an extremely low but synchronous duty-cycle has to be applied whereas the system gets no energy surplus to support existing synchronization schemes. So, we design two complementary synchronization schemes that cost virtually no energy. Finally, we exploit the feature of our harvester to sense the airflow speed in an energy-free manner. To our knowledge, this is the first indoor wireless sensing system that encapsulates energy harvesting, network operating, and sensing all together.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2793310285",
    "type": "article"
  },
  {
    "title": "Schedulability Analysis of Tasks with Corunner-Dependent Execution Times",
    "doi": "https://doi.org/10.1145/3203407",
    "publication_date": "2018-05-22",
    "publication_year": 2018,
    "authors": "Björn Andersson; Hyoseung Kim; Dionisio de Niz; Mark Klein; Ragunathan Rajkumar; John P. Lehoczky",
    "corresponding_authors": "",
    "abstract": "Consider fixed-priority preemptive partitioned scheduling of constrained-deadline sporadic tasks on a multiprocessor. A task generates a sequence of jobs and each job has a deadline that must be met. Assume tasks have Corunner-dependent execution times; i.e., the execution time of a job J depends on the set of jobs that happen to execute (on other processors) at instants when J executes. We present a model that describes Corunner-dependent execution times. For this model, we show that exact schedulability testing is co-NP-hard in the strong sense. Facing this complexity, we present a sufficient schedulability test, which has pseudo-polynomial-time complexity if the number of processors is fixed. We ran experiments with synthetic software benchmarks on a quad-core Intel multicore processor with the Linux/RK operating system and found that for each task, its maximum measured response time was bounded by the upper bound computed by our theory.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2804116742",
    "type": "article"
  },
  {
    "title": "Efficient localization scheme with ring overlapping by utilizing mobile anchors in wireless sensor networks",
    "doi": "https://doi.org/10.1145/2423636.2423638",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Yeong-Sheng Chen; Yun-Ju Ting; Chih‐Heng Ke; Naveen Chilamkruti; Jong Hyuk Park",
    "corresponding_authors": "",
    "abstract": "This study proposes an efficient localization scheme in wireless sensor networks. The proposed scheme utilizes mobile anchors and is based on ring overlapping. In a wireless sensor network, the nodes that know their locations are called reference nodes, and the other nodes that are without the knowledge of their locations are called blind nodes. To localize a certain blind node, by comparing the relative RSSI (Received Signal Strength Indicator) values among nodes, mobile beacons are utilized to find out the rings that are centered at a reference node and contain the blind node. These rings are called B-Rings. Since the mobile anchors and the reference nodes know their own locations, the B-Rings can be precisely derived. Moreover, by using multiple mobile beacons, the widths of the B-Rings can be further minimized; and then by overlapping them, the location of the blind nodes can be efficiently estimated. Most existing localization schemes that utilize mobile anchors let the mobile anchors move randomly. In contrast, the proposed scheme provides regular and simple movement mechanisms for the mobile anchors. Thus, the mobile anchors consume less energy than the other schemes, in which the mobile anchors move randomly. Analytical analysis and simulation results show that the proposed localization mechanism can achieve better location accuracy as well as less movement length of the mobile anchor than the other existing related approaches.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W1977560745",
    "type": "article"
  },
  {
    "title": "WCET analysis with MRU cache",
    "doi": "https://doi.org/10.1145/2584655",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Nan Guan; Mingsong Lv; Wang Yi; Ge Yu",
    "corresponding_authors": "",
    "abstract": "Most previous work on cache analysis for WCET estimation assumes a particular replacement policy called LRU. In contrast, much less work has been done for non-LRU policies, since they are generally considered to be very unpredictable. However, most commercial processors are actually equipped with these non-LRU policies, since they are more efficient in terms of hardware cost, power consumption and thermal output, while still maintaining almost as good average-case performance as LRU. In this work, we study the analysis of MRU, a non-LRU replacement policy employed in mainstream processor architectures like Intel Nehalem. Our work shows that the predictability of MRU has been significantly underestimated before, mainly because the existing cache analysis techniques and metrics do not match MRU well. As our main technical contribution, we propose a new cache hit/miss classification, k -Miss, to better capture the MRU behavior, and develop formal conditions and efficient techniques to decide k -Miss memory accesses. A remarkable feature of our analysis is that the k -Miss classifications under MRU are derived by the analysis result of the same program under LRU. Therefore, our approach inherits the advantages in efficiency and precision of the state-of-the-art LRU analysis techniques based on abstract interpretation. Experiments with instruction caches show that our proposed MRU analysis has both good precision and high efficiency, and the obtained estimated WCET is rather close to (typically 1%∼8% more than) that obtained by the state-of-the-art LRU analysis, which indicates that MRU is also a good candidate for cache replacement policies in real-time systems.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2019517268",
    "type": "article"
  },
  {
    "title": "Optimal Priority Assignment to Control Tasks",
    "doi": "https://doi.org/10.1145/2660496",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Giulio M. Mancuso; Enrico Bini; Gabriele Pannocchia",
    "corresponding_authors": "",
    "abstract": "In embedded real-time systems, task priorities are often assigned to meet deadlines. However, in control tasks, a late completion of a task has no catastrophic consequence; rather, it has a quantifiable impact in the control performance achieved by the task. In this article, we address the problem of determining the optimal assignment of priorities and periods of sampled-data control tasks that run over a shared computation unit. We show that the minimization of the overall cost can be performed efficiently using a branch and bound algorithm that can be further speeded up by allowing for a small degree of suboptimality. Detailed numerical simulations are presented to show the advantages of various branching alternatives, the overall algorithm effectiveness, and its scalability with the number of tasks.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2026702799",
    "type": "article"
  },
  {
    "title": "Rigorous rental memory management for embedded systems",
    "doi": "https://doi.org/10.1145/2435227.2435239",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Jinkyu Jeong; Hwanju Kim; Jeaho Hwang; Joonwon Lee; Seungryoul Maeng",
    "corresponding_authors": "",
    "abstract": "Memory reservation in embedded systems is a prevalent approach to provide a physically contiguous memory region to its integrated devices, such as a camera device and a video decoder. Inefficiency of the memory reservation becomes a more significant problem in emerging embedded systems, such as smartphones and smart TVs. Many ways of using these systems increase the idle time of their integrated devices, and eventually decrease the utilization of their reserved memory. In this article, we propose a scheme to minimize the memory inefficiency caused by the memory reservation. The memory space reserved for a device can be rented for other purposes when the device is not active. For this scheme to be viable, latencies associated with reallocating the memory space should be minimal. Volatile pages are good candidates for such page reallocation since they can be reclaimed immediately as they are needed by the original device. We also provide two optimization techniques, lazy-migration and adaptive-activation. The former increases the lowered utilization of the rental memory by our volatile page allocations, and the latter saves active pages in the rental memory during the reallocation. We implemented our scheme on a smartphone development board with the Android Linux kernel. Our prototype has shown that the time for the return operation is less than 0.77 seconds in the tested cases. We believe that this time is acceptable to end-users in terms of transparency since the time can be hidden in application initialization time. The rental memory also brings throughput increases ranging from 2% to 200% based on the available memory and the applications' memory intensiveness.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2051915263",
    "type": "article"
  },
  {
    "title": "High-Performance and Energy-Efficient Network-on-Chip Architectures for Graph Analytics",
    "doi": "https://doi.org/10.1145/2961027",
    "publication_date": "2016-09-01",
    "publication_year": 2016,
    "authors": "Karthi Duraisamy; Hao Lu; Partha Pratim Pande; Ananth Kalyanaraman",
    "corresponding_authors": "",
    "abstract": "With its applicability spanning numerous data-driven fields, the implementation of graph analytics on multicore platforms is gaining momentum. One of the most important components of a multicore chip is its communication backbone. Due to inherent irregularities in data movements manifested by graph-based applications, it is essential to design efficient on-chip interconnection architectures for multicore chips performing graph analytics. In this article, we present a detailed analysis of the traffic patterns generated by graph-based applications when mapped to multicore chips. Based on this analysis, we explore the design-space for the Network-on-Chip (NoC) architecture to enable an efficient implementation of graph analytics. We principally consider three types of NoC architectures, viz., traditional mesh, small-world, and high-radix networks. We demonstrate that the small-world-network-enabled wireless NoC (WiNoC) is the most suitable platform for executing the considered graph applications. The WiNoC achieves an average of 38% and 18% full-system Energy Delay Product savings compared to wireline-mesh and high-radix NoCs, respectively.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2512825584",
    "type": "article"
  },
  {
    "title": "Integrated Through-Silicon Via Placement and Application Mapping for 3D Mesh-Based NoC Design",
    "doi": "https://doi.org/10.1145/2968446",
    "publication_date": "2016-11-03",
    "publication_year": 2016,
    "authors": "Kanchan Manna; Shivam Swami; Santanu Chattopadhyay; Indranil Sengupta",
    "corresponding_authors": "",
    "abstract": "This article proposes a solution to the integrated problem of Through-Silicon Via (TSV) placement and mapping of cores to the routers in a three-dimensional mesh-based Network-on-Chip (NoC) system. TSV geometry restricts their number in three-dimensional (3D) ICs. As a result, only about 25% of routers in a 3D NoC can possess vertical connections. Mapping plays an important role in evolving good system solutions in such a situation. TSVs have been placed with detailed consultation with the application mapping process. The integrated problem was first solved using the exact method of Integer Liner Programming (ILP). Next, a solution was obtained via a Particle Swarm Optimization (PSO) formulation. Several augmentations to the basic PSO strategy have been proposed to generate good-quality solutions. The results obtained are better than many of the contemporary approaches and close to the theoretical situation in which all routers are 3D in nature.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2549004257",
    "type": "article"
  },
  {
    "title": "Formal Requirement Debugging for Testing and Verification of Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3147451",
    "publication_date": "2017-12-12",
    "publication_year": 2017,
    "authors": "Adel Dokhanchi; Bardh Hoxha; Georgios Fainekos",
    "corresponding_authors": "",
    "abstract": "A framework for the elicitation and debugging of formal specifications for Cyber-Physical Systems is presented. The elicitation of specifications is handled through a graphical interface. Two debugging algorithms are presented. The first checks for erroneous or incomplete temporal logic specifications without considering the system. The second can be utilized for the analysis of reactive requirements with respect to system test traces. The specification debugging framework is applied on a number of formal specifications collected through a user study. The user study establishes that requirement errors are common and that the debugging framework can resolve many insidious specification errors.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2549790574",
    "type": "article"
  },
  {
    "title": "Efficient Elliptic Curve Cryptography for Embedded Devices",
    "doi": "https://doi.org/10.1145/2967103",
    "publication_date": "2016-12-19",
    "publication_year": 2016,
    "authors": "Zhe Liu; Jian Weng; Zhi Hu; Hwajeong Seo",
    "corresponding_authors": "",
    "abstract": "Many resource-constrained embedded devices, such as wireless sensor nodes, require public key encryption or a digital signature, which has induced plenty of research on efficient and secure implementation of elliptic curve cryptography (ECC) on 8-bit processors. In this work, we study the suitability of a special class of finite fields, called optimal prime fields (OPFs), for a “lightweight” ECC implementation with a view toward high performance and security. First, we introduce a highly optimized arithmetic library for OPFs that includes two implementations for each finite field arithmetic operation, namely a performance-optimized version and a security-optimized variant. The latter is resistant against simple power analysis attacks in the sense that it always executes the same sequence of instructions, independent of the operands. Based on this OPF library, we then describe a performance-optimized and a security-optimized implementation of scalar multiplication on the elliptic curve over OPFs at several security levels. The former uses the Gallant-Lambert-Vanstone method on twisted Edwards curves and reaches an execution time of 3.14M cycles (over a 160-bit OPF) on an 8-bit ATmega128 processor, whereas the latter is based on a Montgomery curve and executes in 5.53M cycles.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2566880782",
    "type": "article"
  },
  {
    "title": "Timestamp Temporal Logic (TTL) for Testing the Timing of Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3126510",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Mohammadreza Mehrabian; Mohammad Khayatian; Aviral Shrivastava; John C. Eidson; Patricia Derler; Hugo A. Andrade; Ya-Shian Li-Baboud; Edward Griffor; Marc A. Weiss; Kevin Stanton",
    "corresponding_authors": "",
    "abstract": "In order to test the performance and verify the correctness of Cyber-Physical Systems (CPS), the timing constraints on the system behavior must be met. Signal Temporal Logic (STL) can efficiently and succinctly capture the timing constraints of a given system model. However, many timing constraints on CPS are more naturally expressed in terms of events on signals. While it is possible to specify event-based timing constraints in STL, such statements can quickly become long and arcane in even simple systems. Timing constraints for CPS, which can be large and complex systems, are often associated with tolerances, the expression of which can make the timing constraints even more cumbersome using STL. This paper proposes a new logic, Timestamp Temporal Logic (TTL), to provide a definitional extension of STL that more intuitively expresses the timing constraints of distributed CPS. TTL also allows for a more natural expression of timing tolerances. Additionally, this paper outlines a methodology to automatically generate logic code and programs to monitor the expressed timing constraints. Since our TTL monitoring logic evaluates the timing constraints using only the timestamps of the required events on the signal, the TTL monitoring logic has significantly less memory footprint when compared to traditional STL monitoring logic, which stores the signal value at the required sampling frequency. The key contribution of this paper is a scalable approach for online monitoring of the timing constraints. We demonstrate the capabilities of TTL and our methodology for online monitoring of TTL constraints on two case studies: 1) Synchronization and phase control of two generators and, 2) Simultaneous image capture using distributed cameras for 3D image reconstruction.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2758992328",
    "type": "article"
  },
  {
    "title": "Control Flow Checking or Not? (for Soft Errors)",
    "doi": "https://doi.org/10.1145/3301311",
    "publication_date": "2019-01-31",
    "publication_year": 2019,
    "authors": "Abhishek Rhisheekesan; Reiley Jeyapaul; Aviral Shrivastava",
    "corresponding_authors": "",
    "abstract": "Huge leaps in performance and power improvements of computing systems are driven by rapid technology scaling, but technology scaling has also rendered computing systems susceptible to soft errors. Among the soft error protection techniques, Control Flow Checking (CFC) based techniques have gained a reputation of being lightweight yet effective. The main idea behind CFCs is to check if the program is executing the instructions in the right order. In order to validate the protection claims of existing CFCs, we develop a systematic and quantitative method to evaluate the protection achieved by CFCs using the metric of vulnerability. Our quantitative analysis indicates that existing CFC techniques are not only ineffective in providing protection from soft faults, but incur additional performance and power overheads. Our results show that software-only CFC protection schemes increase system vulnerability by 18%--21% with 17%--38% performance overhead and hybrid CFC protection increases vulnerability by 5%. Although the vulnerability remains almost the same for hardware-only CFC protection, they incur overheads of design cost, area, and power due to the hardware modifications required for their implementations.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2917704380",
    "type": "article"
  },
  {
    "title": "CompAct",
    "doi": "https://doi.org/10.1145/3358178",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Jeff Zhang; Parul Raj; Shuayb Zarar; Amol Ambardekar; Siddharth Garg",
    "corresponding_authors": "",
    "abstract": "This paper addresses the design of systolic array (SA) based convolutional neural network (CNN) accelerators for mobile and embedded domains. On- and off-chip memory accesses to the large activation inputs (sometimes called feature maps) of CNN layers contribute significantly to total energy consumption for such accelerators; while prior has proposed off-chip compression, activations are still stored on-chip in uncompressed form, requiring either large on-chip activation buffers or slow and energy-hungry off-chip accesses. In this paper, we propose CompAct, a new architecture that enables on-chip compression of activations for SA based CNN accelerators. CompAct is built around several key ideas. First, CompAct identifies an SA schedule that has nearly regular access patterns, enabling the use of a modified run-length coding scheme (RLC). Second, CompAct improves compression ratio of the RLC scheme using Sparse-RLC in later CNN layers and Lossy-RLC in earlier layers. Finally, CompAct proposes look-ahead snoozing that operates synergistically with RLC to reduce the leakage energy of activation buffers. Based on detailed synthesis results, we show that CompAct enables up to 62% reduction in activation buffer energy, and 34% reduction in total chip energy.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2948229371",
    "type": "article"
  },
  {
    "title": "A Dual-Mode Strategy for Performance-Maximisation and Resource-Efficient CPS Design",
    "doi": "https://doi.org/10.1145/3358213",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Xiaotian Dai; Wanli Chang; Shuai Zhao; Alan Burns",
    "corresponding_authors": "",
    "abstract": "The emerging scenarios of cyber-physical systems (CPS), such as autonomous vehicles, require implementing complex functionality with limited resources, as well as high performances. This paper considers a common setup in which multiple control and non-control tasks share one processor, and proposes a dual-mode strategy. The control task switches between two sampling periods when rejecting (coping with) a disturbance. We create an optimisation framework looking for the switching sampling periods and time instants that maximise the control performance (indexed by settling time) and resource efficiency (indexed by the number of tasks that are schedulable on the processor). The latter objective is enabled with schedulability analysis tailored for the dual-mode model. Experimental results show that (i) given a set of tasks, the proposed strategy improves the control performances whilst retaining schedulability; and (ii) given requirements on the control performances, the proposed strategy is able to schedule more tasks.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2980119441",
    "type": "article"
  },
  {
    "title": "Transport-layer-assisted routing for runtime thermal management of 3D NoC systems",
    "doi": "https://doi.org/10.1145/2501626.2512468",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Chih-Hao Chao; Kun-Chih Chen; Tsu-Chu Yin; Shu-Yen Lin; An-Yeu Wu",
    "corresponding_authors": "",
    "abstract": "To ensure thermal safety and to avoid performance degradation from temperature regulation in 3D NoC, we propose a new temperature-traffic control framework. The framework contains the vertical throttling-based runtime thermal management (VT-RTM) scheme and the transport-layer assisted routing (TLAR) scheme. VT-RTM scheme increases the cooling speed and maintains high availability. TLAR scheme sustains the throughput of the nonstationary irregular mesh network. In our experiments, VT-RTM scheme reduces cooling time by 84% and achieves 98% network availability; the overall performance impact is around 8% of traditional schemes. TLAR scheme reduces average latency by 35∼% and improves sustainable throughput by 76%",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4243424694",
    "type": "article"
  },
  {
    "title": "A Real-Time Multichannel Memory Controller and Optimal Mapping of Memory Clients to Memory Channels",
    "doi": "https://doi.org/10.1145/2661635",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Manil Dev Gomony; Benny Åkesson; Kees Goossens",
    "corresponding_authors": "",
    "abstract": "Ever-increasing demands for main memory bandwidth and memory speed/power tradeoff led to the introduction of memories with multiple memory channels, such as Wide IO DRAM. Efficient utilization of a multichannel memory as a shared resource in multiprocessor real-time systems depends on mapping of the memory clients to the memory channels according to their requirements on latency, bandwidth, communication, and memory capacity. However, there is currently no real-time memory controller for multichannel memories, and there is no methodology to optimally configure multichannel memories in real-time systems. As a first work toward this direction, we present two main contributions in this article: (1) a configurable real-time multichannel memory controller architecture with a novel method for logical-to-physical address translation and (2) two design-time methods to map memory clients to the memory channels, one an optimal algorithm based on an integer programming formulation of the mapping problem, and the other a fast heuristic algorithm. We demonstrate the real-time guarantees on bandwidth and latency provided by our multichannel memory controller architecture by experimental evaluation. Furthermore, we compare the performance of the mapping problem formulation in a solver and the heuristic algorithm against two existing mapping algorithms in terms of computation time and mapping success ratio. We show that an optimal solution can be found in 2 hours using the solver and in less than 1 second with less than 7% mapping failure using the heuristic for realistically sized problems. Finally, we demonstrate configuring a Wide IO DRAM in a high-definition (HD) video and graphics processing system to emphasize the practical applicability and effectiveness of this work.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2069490402",
    "type": "article"
  },
  {
    "title": "Theory and Application of Delay Constraints in Arbiter PUF",
    "doi": "https://doi.org/10.1145/2815621",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Urbi Chatterjee; Rajat Subhra Chakraborty; Hitesh Kapoor; Debdeep Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "Physically Unclonable Function (PUF) circuits are often vulnerable to mathematical model-building attacks . We theoretically quantify the advantage provided to an adversary by any training dataset expansion technique along the lines of security analysis of cryptographic hash functions. We present an algorithm to enumerate certain sets of delay constraints for the widely studied Arbiter PUF (APUF) circuit, then demonstrate how these delay constraints can be utilized to expand the set of known Challenge--Response Pairs (CRPs), thus facilitating model-building attacks. We provide experimental results for Field Programmable Gate Array (FPGA)--based APUF to establish the effectiveness of the proposed attack.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2297840895",
    "type": "article"
  },
  {
    "title": "A Survey of Asynchronous Programming Using Coroutines in the Internet of Things and Embedded Systems",
    "doi": "https://doi.org/10.1145/3319618",
    "publication_date": "2019-05-31",
    "publication_year": 2019,
    "authors": "Bruce Belson; Jason Holdsworth; Wei Xiang; Bronson Philippa",
    "corresponding_authors": "",
    "abstract": "Many Internet of Things and embedded projects are event-driven, and therefore require asynchronous and concurrent programming. Current proposals for C++20 suggest that coroutines will have native language support. It is timely to survey the current use of coroutines in embedded systems development. This paper investigates existing research which uses or describes coroutines on resource-constrained platforms. The existing research is analysed with regard to: software platform, hardware platform and capacity; use cases and intended benefits; and the application programming interface design used for coroutines. A systematic mapping study was performed, to select studies published between 2007 and 2018 which contained original research into the application of coroutines on resource-constrained platforms. An initial set of 566 candidate papers were reduced to only 35 after filters were applied, revealing the following taxonomy. The C & C++ programming languages were used by 22 studies out of 35. As regards hardware, 16 studies used 8- or 16-bit processors while 13 used 32-bit processors. The four most common use cases were concurrency (17 papers), network communication (15), sensor readings (9) and data flow (7). The leading intended benefits were code style and simplicity (12 papers), scheduling (9) and efficiency (8). A wide variety of techniques have been used to implement coroutines, including native macros, additional tool chain steps, new language features and non-portable assembly language. We conclude that there is widespread demand for coroutines on resource-constrained devices. Our findings suggest that there is significant demand for a formalised, stable, well-supported implementation of coroutines in C++, designed with consideration of the special needs of resource-constrained devices, and further that such an implementation would bring benefits specific to such devices.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2951467711",
    "type": "article"
  },
  {
    "title": "ICNN",
    "doi": "https://doi.org/10.1145/3355553",
    "publication_date": "2019-11-30",
    "publication_year": 2019,
    "authors": "Katayoun Neshatpour; Houman Homayoun; Avesta Sasan",
    "corresponding_authors": "",
    "abstract": "Modern and recent architectures of vision-based Convolutional Neural Networks (CNN) have improved detection and prediction accuracy significantly. However, these algorithms are extremely computationally intensive. To break the power and performance wall of CNN computation, we reformulate the CNN computation into an iterative process, where each iteration processes a sub-sample of input features with smaller network and ingests additional features to improve the prediction accuracy. Each smaller network could either classify based on its input set or feed computed and extracted features to the next network to enhance the accuracy. The proposed approach allows early-termination upon reaching acceptable confidence. Moreover, each iteration provides a contextual awareness that allows an intelligent resource allocation and optimization for the proceeding iterations. In this article, we propose various policies to reduce the computational complexity of CNN through the proposed iterative approach. We illustrate how the proposed policies construct a dynamic architecture suitable for a wide range of applications with varied accuracy requirements, resources, and time-budget, without further need for network re-training. Furthermore, we carry out a visualization of the detected features in each iteration through deconvolution network to gain more insight into the successive traversal of the ICNN.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2996132293",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2885505",
    "publication_date": "2016-02-26",
    "publication_year": 2016,
    "authors": "Sara Vinco; Christian Pilato",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2315432685",
    "type": "editorial"
  },
  {
    "title": "SmartLMK",
    "doi": "https://doi.org/10.1145/2894755",
    "publication_date": "2016-05-11",
    "publication_year": 2016,
    "authors": "Sang-Hoon Kim; Jinkyu Jeong; Jin‐Soo Kim; Seungryoul Maeng",
    "corresponding_authors": "",
    "abstract": "As the mobile computing environment evolves, users demand high-quality apps and better user experience. Consequently, memory demand in mobile devices has soared. Device manufacturers have fulfilled the demand by equipping devices with more RAM. However, such a hardware approach is only a temporary solution and does not scale well in the resource-constrained mobile environment. Meanwhile, mobile systems adopt a new app life cycle and a memory reclamation scheme tailored for the life cycle. When a user leaves an app, the app is not terminated but cached in memory as long as there is enough free memory. If the free memory gets low, a victim app is terminated and the associated memory to the app is reclaimed. This process-level approach has worked well in the mobile environment. However, user experience can be impaired severely because the victim selection policy does not consider the user experience. In this article, we propose a novel memory reclamation scheme called SmartLMK . SmartLMK minimizes the impact of the process-level reclamation on user experience. The worthiness to keep an app in memory is modeled by means of user-perceived app launch time and app usage statistics. The memory footprint and impending memory demand are estimated from the history of the memory usage. Using these values and memory models, SmartLMK picks up the least valuable apps and terminates them at once. Our evaluation on a real Android-based smartphone shows that SmartLMK efficiently distinguishes the valuable apps among cached apps and keeps those valuable apps in memory. As a result, the user-perceived app launch time can be improved by up to 13.2%.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2349734317",
    "type": "article"
  },
  {
    "title": "Dealing with Uncertainty in pWCET Estimations",
    "doi": "https://doi.org/10.1145/3396234",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Federico Reghenzani; Luca Santinelli; William Fornaciari",
    "corresponding_authors": "",
    "abstract": "The problem of estimating a tight and safe Worst-Case Execution Time (WCET), needed for certification in safety-critical environment, is a challenging problem for modern embedded systems. A possible solution proposed in past years is to exploit statistical tools to obtain a probability distribution of the WCET. These probabilistic real-time analyses for WCET are, however, subject to errors, even when all the applicability hypotheses are satisfied and verified. This is caused by the uncertainties of the probabilistic-WCET distribution estimator. This article aims at improving the measurement-based probabilistic timing analysis approach providing some techniques to analyze and deal with such uncertainties. The so-called region of acceptance model based on state-of-the-art statistical test procedures is defined over the distribution space parameters. From this model, a set of strategies is derived and discussed to provide the methodology to deal with the trade-off safety/tightness of the WCET estimation. These techniques are then tested over real datasets, including industrial safety-critical applications, to show the increased value of using the proposed approach in probabilistic WCET analyses.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3099618317",
    "type": "article"
  },
  {
    "title": "SAGE: A Split-Architecture Methodology for Efficient End-to-End Autonomous Vehicle Control",
    "doi": "https://doi.org/10.1145/3477006",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Arnav Vaibhav Malawade; Mohanad Odema; Sebastien Lajeunesse-degroot; Mohammad Abdullah Al Faruque",
    "corresponding_authors": "",
    "abstract": "Autonomous vehicles (AV) are expected to revolutionize transportation and improve road safety significantly. However, these benefits do not come without cost; AVs require large Deep-Learning (DL) models and powerful hardware platforms to operate reliably in real-time, requiring between several hundred watts to one kilowatt of power. This power consumption can dramatically reduce vehicles' driving range and affect emissions. To address this problem, we propose SAGE: a methodology for selectively offloading the key energy-consuming modules of DL architectures to the cloud to optimize edge energy usage while meeting real-time latency constraints. Furthermore, we leverage Head Network Distillation (HND) to introduce efficient bottlenecks within the DL architecture in order to minimize the network overhead costs of offloading with almost no degradation in the model's performance. We evaluate SAGE using an Nvidia Jetson TX2 and an industry-standard Nvidia Drive PX2 as the AV edge devices and demonstrate that our offloading strategy is practical for a wide range of DL models and internet connection bandwidths on 3G, 4G LTE, and WiFi technologies. Compared to edge-only computation, SAGE reduces energy consumption by an average of 36.13%, 47.07%, and 55.66% for an AV with one low-resolution camera, one high-resolution camera, and three high-resolution cameras, respectively. SAGE also reduces upload data size by up to 98.40% compared to direct camera offloading.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3184369898",
    "type": "article"
  },
  {
    "title": "TAMA",
    "doi": "https://doi.org/10.1145/3462700",
    "publication_date": "2021-07-09",
    "publication_year": 2021,
    "authors": "Rashid Aligholipour; Mohammad Baharloo; Behnam Farzaneh; Meisam Abdollahi; Ahmad Khonsari",
    "corresponding_authors": "",
    "abstract": "Nowadays, static power consumption in chip multiprocessor (CMP) is the most crucial concern of chip designers. Power-gating is an effective approach to mitigate static power consumption particularly in low utilization. Network-on-Chip (NoC) as the backbone of multi- and many-core chips has no exception. Previous state-of-the-art techniques in power-gating desire to decrease static power consumption alongside the lack of diminution in performance of NoC. However, maintaining the performance and utilization of the power-gating approach has not yet been addressed very well. In this article, we propose TAMA (Turn-Aware Mapping &amp; Architecture) as an effective method to boost the performance of the TooT method that was only powering on a router during turning pass or packet injection. In other words, in the TooT method, straight and eject packets pass the router via a bypass route without powering on the router. By employing meta-heuristic approaches (Genetic and Ant Colony algorithms), we develop a specific application mapping that attempts to decrease the number of turns through interconnection networks. Accordingly, the average latency of packet transmission decreases due to fewer turns. Also, by powering on turn routers in advance with lightweight hardware, the latency of sending packets diminishes. The experimental results demonstrate that our proposed approach, i.e., TAMA achieves more than 13% reduction in packet latency of NoC in comparison with TooT. Besides the packet latency, the power consumption of TAMA is reduced by about 87% compared to the traditional approach.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3181416725",
    "type": "article"
  },
  {
    "title": "CICERO: A Domain-Specific Architecture for Efficient Regular Expression Matching",
    "doi": "https://doi.org/10.1145/3476982",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Daniele Parravicini; Davide Conficconi; Emanuele Del Sozzo; Christian Pilato; Marco D. Santambrogio",
    "corresponding_authors": "",
    "abstract": "Regular Expression (RE) matching is a computational kernel used in several applications. Since RE complexity and data volumes are steadily increasing, hardware acceleration is gaining attention also for this problem. Existing approaches have limited flexibility as they require a different implementation for each RE. On the other hand, it is complex to map efficient RE representations like non-deterministic finite-state automata onto software-programmable engines or parallel architectures. In this work, we present CICERO , an end-to-end framework composed of a domain-specific architecture and a companion compilation framework for RE matching. Our solution is suitable for many applications, such as genomics/proteomics and natural language processing. CICERO aims at exploiting the intrinsic parallelism of non-deterministic representations of the REs. CICERO can trade-off accelerators’ efficiency and processors’ flexibility thanks to its programmable architecture and the compilation framework. We implemented CICERO prototypes on embedded FPGA achieving up to 28.6× and 20.8× more energy efficiency than embedded and mainstream processors, respectively. Since it is a programmable architecture, it can be implemented as a custom ASIC that is orders of magnitude more energy-efficient than mainstream processors.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3200051020",
    "type": "article"
  },
  {
    "title": "Improving Variational Autoencoder based Out-of-Distribution Detection for Embedded Real-time Applications",
    "doi": "https://doi.org/10.1145/3477026",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Yeli Feng; Daniel Jun Xian Ng; Arvind Easwaran",
    "corresponding_authors": "",
    "abstract": "Uncertainties in machine learning are a significant roadblock for its application in safety-critical cyber-physical systems (CPS). One source of uncertainty arises from distribution shifts in the input data between training and test scenarios. Detecting such distribution shifts in real-time is an emerging approach to address the challenge. The high dimensional input space in CPS applications involving imaging adds extra difficulty to the task. Generative learning models are widely adopted for the task, namely out-of-distribution (OoD) detection. To improve the state-of-the-art, we studied existing proposals from both machine learning and CPS fields. In the latter, safety monitoring in real-time for autonomous driving agents has been a focus. Exploiting the spatiotemporal correlation of motion in videos, we can robustly detect hazardous motion around autonomous driving agents. Inspired by the latest advances in the Variational Autoencoder (VAE) theory and practice, we tapped into the prior knowledge in data to further boost OoD detection’s robustness. Comparison studies over nuScenes and Synthia data sets show our methods significantly improve detection capabilities of OoD factors unique to driving scenarios, 42% better than state-of-the-art approaches. Our model also generalized near-perfectly, 97% better than the state-of-the-art across the real-world and simulation driving data sets experimented. Finally, we customized one proposed method into a twin-encoder model that can be deployed to resource limited embedded devices for real-time OoD detection. Its execution time was reduced over four times in low-precision 8-bit integer inference, while detection capability is comparable to its corresponding floating-point model.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3200940659",
    "type": "article"
  },
  {
    "title": "Block Walsh–Hadamard Transform-based Binary Layers in Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3510026",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Hongyi Pan; Diaa Badawi; Ahmet Enis Çetin",
    "corresponding_authors": "",
    "abstract": "Convolution has been the core operation of modern deep neural networks. It is well known that convolutions can be implemented in the Fourier Transform domain. In this article, we propose to use binary block Walsh–Hadamard transform (WHT) instead of the Fourier transform. We use WHT-based binary layers to replace some of the regular convolution layers in deep neural networks. We utilize both one-dimensional (1D) and 2D binary WHTs in this article. In both 1D and 2D layers, we compute the binary WHT of the input feature map and denoise the WHT domain coefficients using a nonlinearity that is obtained by combining soft-thresholding with the tanh function. After denoising, we compute the inverse WHT. We use 1D-WHT to replace the 1 × 1 convolutional layers, and 2D-WHT layers can replace the 3 × 3 convolution layers and Squeeze-and-Excite layers. 2D-WHT layers with trainable weights can be also inserted before the Global Average Pooling layers to assist the dense layers. In this way, we can reduce the number of trainable parameters significantly with a slight decrease in trainable parameters. In this article, we implement the WHT layers into MobileNet-V2, MobileNet-V3-Large, and ResNet to reduce the number of parameters significantly with negligible accuracy loss. Moreover, according to our speed test, the 2D-FWHT layer runs about 24 times as fast as the regular 3 × 3 convolution with 19.51% less RAM usage in an NVIDIA Jetson Nano experiment.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4210398316",
    "type": "article"
  },
  {
    "title": "Software-Managed Read and Write Wear-Leveling for Non-Volatile Main Memory",
    "doi": "https://doi.org/10.1145/3483839",
    "publication_date": "2022-01-31",
    "publication_year": 2022,
    "authors": "Christian Hakert; Kuan-Hsun Chen; Horst Schirmeier; Lars Bauer; Paul R. Genßler; Georg von der Brüggen; Hussam Amrouch; Jörg Henkel; Jian-Jia Chen",
    "corresponding_authors": "",
    "abstract": "In-memory wear-leveling has become an important research field for emerging non-volatile main memories over the past years. Many approaches in the literature perform wear-leveling by making use of special hardware. Since most non-volatile memories only wear out from write accesses, the proposed approaches in the literature also usually try to spread write accesses widely over the entire memory space. Some non-volatile memories, however, also wear out from read accesses, because every read causes a consecutive write access. Software-based solutions only operate from the application or kernel level, where read and write accesses are realized with different instructions and semantics. Therefore different mechanisms are required to handle reads and writes on the software level. First, we design a method to approximate read and write accesses to the memory to allow aging aware coarse-grained wear-leveling in the absence of special hardware, providing the age information. Second, we provide specific solutions to resolve access hot-spots within the compiled program code (text segment) and on the application stack. In our evaluation, we estimate the cell age by counting the total amount of accesses per cell. The results show that employing all our methods improves the memory lifetime by up to a factor of 955×.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4211093385",
    "type": "article"
  },
  {
    "title": "Resource-Efficient Continual Learning for Sensor-Based Human Activity Recognition",
    "doi": "https://doi.org/10.1145/3530910",
    "publication_date": "2022-04-30",
    "publication_year": 2022,
    "authors": "Clayton Frederick Souza Leite; Yu Xiao",
    "corresponding_authors": "",
    "abstract": "Recent advances in deep learning have granted unrivaled performance to sensor-based human activity recognition (HAR) . However, in a real-world scenario, the HAR solution is subject to diverse changes over time such as the need to learn new activity classes or variations in the data distribution of the already-included activities. To solve these issues, previous studies have tried to apply directly the continual learning methods borrowed from the computer vision domain, where it is vastly explored. Unfortunately, these methods either lead to surprisingly poor results or demand copious amounts of computational resources, which is infeasible for the low-cost resource-constrained devices utilized in HAR. In this paper, we provide a resource-efficient and high-performance continual learning solution for HAR. It consists of an expandable neural network trained with a replay-based method that utilizes a highly-compressed replay memory whose samples are selected to maximize data variability. Experiments with four open datasets, which were conducted on two distinct microcontrollers, show that our method is capable of achieving substantial accuracy improvements over baselines in continual learning such as Gradient Episodic Memory, while utilizing only one-third of the memory and being up to 3× faster.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4225114541",
    "type": "article"
  },
  {
    "title": "𝖧𝗒𝖣𝖱𝖤𝖠: Utilizing Hyperdimensional Computing for a More Robust and Efficient Machine Learning System",
    "doi": "https://doi.org/10.1145/3524067",
    "publication_date": "2022-07-13",
    "publication_year": 2022,
    "authors": "Justin Morris; Kazim Ergun; Behnam Khaleghi; Mohsen Imani; Barış Akşanlı; Tajana Šimunić",
    "corresponding_authors": "",
    "abstract": "Today’s systems rely on sending all the data to the cloud and then using complex algorithms, such as Deep Neural Networks, which require billions of parameters and many hours to train a model. In contrast, the human brain can do much of this learning effortlessly. Hyperdimensional (HD) Computing aims to mimic the behavior of the human brain by utilizing high-dimensional representations. This leads to various desirable properties that other Machine Learning (ML) algorithms lack, such as robustness to noise in the system and simple, highly parallel operations. In this article, we propose 𝖧𝗒𝖣𝖱𝖤𝖠, a HyperDimensional Computing system that is Robust, Efficient, and Accurate. We propose a Processing-in-Memory (PIM) architecture that works in a federated learning environment with challenging communication scenarios that cause errors in the transmitted data. 𝖧𝗒𝖣𝖱𝖤𝖠 adaptively changes the bitwidth of the model based on the signal-to-noise ratio (SNR) of the incoming sample to maintain the accuracy of the HD model while achieving significant speedup and energy efficiency. Our PIM architecture is able to achieve a speedup of 28× and 255× better energy efficiency compared to the baseline PIM architecture for Classification and achieves 32 × speed up and 289 × higher energy efficiency than the baseline architecture for Clustering. 𝖧𝗒𝖣𝖱𝖤𝖠 is able to achieve this by relaxing hardware parameters to gain energy efficiency and speedup while introducing computational errors. We show experimentally, HD Computing is able to handle the errors without a significant drop in accuracy due to its unique robustness property. For wireless noise, we found that 𝖧𝗒𝖣𝖱𝖤𝖠 is 48 × more robust to noise than other comparable ML algorithms. Our results indicate that our proposed system loses less than 1% Classification accuracy, even in scenarios with an SNR of 6.64. We additionally test the robustness of using HD Computing for Clustering applications and found that our proposed system also looses less than 1% in the mutual information score, even in scenarios with an SNR under 7 dB, which is 57 × more robust to noise than K-means.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4285086368",
    "type": "article"
  },
  {
    "title": "Temporal Robustness of Temporal Logic Specifications: Analysis and Control Design",
    "doi": "https://doi.org/10.1145/3550072",
    "publication_date": "2022-07-20",
    "publication_year": 2022,
    "authors": "Alëna Rodionova; Lars Lindemann; Manfred Morari; George J. Pappas",
    "corresponding_authors": "",
    "abstract": "We study the temporal robustness of temporal logic specifications and show how to design temporally robust control laws for time-critical control systems. This topic is of particular interest in connected systems and interleaving processes such as multi-robot and human-robot systems where uncertainty in the behavior of individual agents and humans can induce timing uncertainty. Despite the importance of time-critical systems, temporal robustness of temporal logic specifications has not been studied, especially from a control design point of view. We define synchronous and asynchronous temporal robustness and show that these notions quantify the robustness with respect to synchronous and asynchronous time shifts in the predicates of the temporal logic specification. It is further shown that the synchronous temporal robustness upper bounds the asynchronous temporal robustness. We then study the control design problem in which we aim to design a control law that maximizes the temporal robustness of a dynamical system. Our solution consists of a Mixed-Integer Linear Programming (MILP) encoding that can be used to obtain a sequence of optimal control inputs. While asynchronous temporal robustness is arguably more nuanced than synchronous temporal robustness, we show that control design using synchronous temporal robustness is computationally more efficient. This trade-off can be exploited by the designer depending on the particular application at hand. We conclude the paper with a variety of case studies.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4286001025",
    "type": "article"
  },
  {
    "title": "QUAREM: Maximising QoE Through Adaptive Resource Management in Mobile MPSoC Platforms",
    "doi": "https://doi.org/10.1145/3526116",
    "publication_date": "2022-03-21",
    "publication_year": 2022,
    "authors": "Samuel Isuwa; Somdip Dey; Andre P. Ortega; Amit Kumar Singh; Bashir M. Al‐Hashimi; Geoff V. Merrett",
    "corresponding_authors": "",
    "abstract": "Heterogeneous multi-processor system-on-chip (MPSoC) smartphones are required to offer increasing performance and user quality-of-experience (QoE) , despite comparatively slow advances in battery technology. Approaches to balance instantaneous power consumption, performance and QoE have been reported, but little research has considered how to perform longer-term budgeting of resources across a complete battery discharge cycle. Approaches that have considered this are oblivious to the daily variability in the user’s desired charging time-of-day (plug-in time), resulting in a failure to meet the user’s battery life expectations, or else an unnecessarily over-constrained QoE. This paper proposes QUAREM, an adaptive resource management approach in mobile MPSoC platforms that maximises QoE while meeting battery life expectations. The proposed approach utilises a model that learns and then predicts the dynamics of the energy usage pattern and plug-in times. Unlike state-of-the-art approaches, we maximise the QoE through the adaptive balancing of the battery life and the quality of service (QoS) for the duration of the battery discharge. Our model achieves a good degree of accuracy with a mean absolute percentage error of 3.47% and 2.48% for the energy demand and plug-in times, respectively. Experimental evaluation on an off-the-shelf commercial smartphone shows that QUAREM achieves the expected battery life of the user within 20–25% energy demand variation with little or no QoE degradation.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4293102306",
    "type": "article"
  },
  {
    "title": "Deadline-Aware Task Offloading for Vehicular Edge Computing Networks Using Traffic Light Data",
    "doi": "https://doi.org/10.1145/3594541",
    "publication_date": "2023-04-25",
    "publication_year": 2023,
    "authors": "Pratham Oza; Nathaniel Hudson; Thidapat Chantem; Hana Khamfroush",
    "corresponding_authors": "",
    "abstract": "As vehicles have become increasingly automated, novel vehicular applications have emerged to enhance the safety and security of the vehicles and improve user experience. This brings ever-increasing data and resource requirements for timely computation by the vehicle’s on-board computing systems. To meet these demands, prior work proposes deploying vehicular edge computing (VEC) resources in road-side units (RSUs) in the traffic infrastructure with which the vehicles can communicate and offload compute-intensive tasks. Due to the limited communication range of these RSUs, the communication link between the vehicles and the RSUs — and, therefore, the response times of the offloaded applications — are significantly impacted by vehicle mobility through road traffic. Existing task offloading strategies do not consider the influence of traffic lights on vehicular mobility while offloading workloads onto the RSUs. This causes deadline misses and quality-of-service (QoS) reduction for the offloaded tasks. In this article, we present a novel task model that captures time and location-specific requirements for vehicular applications. We then present a deadline-based strategy that incorporates traffic light data to opportunistically offload tasks. Our approach allows up to 33% more tasks to be offloaded onto RSUs compared with existing work without causing deadline misses, maximizing the resource utilization of RSUs.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4366985264",
    "type": "article"
  },
  {
    "title": "GHOST: A Graph Neural Network Accelerator using Silicon Photonics",
    "doi": "https://doi.org/10.1145/3609097",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Salma Afifi; Febin Sunny; Amin Shafiee; Mahdi Nikdast; Sudeep Pasricha",
    "corresponding_authors": "",
    "abstract": "Graph neural networks (GNNs) have emerged as a powerful approach for modelling and learning from graph-structured data. Multiple fields have since benefitted enormously from the capabilities of GNNs, such as recommendation systems, social network analysis, drug discovery, and robotics. However, accelerating and efficiently processing GNNs require a unique approach that goes beyond conventional artificial neural network accelerators, due to the substantial computational and memory requirements of GNNs. The slowdown of scaling in CMOS platforms also motivates a search for alternative implementation substrates. In this paper, we present GHOST , the first silicon-photonic hardware accelerator for GNNs. GHOST efficiently alleviates the costs associated with both vertex-centric and edge-centric operations. It implements separately the three main stages involved in running GNNs in the optical domain, allowing it to be used for the inference of various widely used GNN models and architectures, such as graph convolution networks and graph attention networks. Our simulation studies indicate that GHOST exhibits at least 10.2 × better throughput and 3.8 × better energy efficiency when compared to GPU, TPU, CPU and multiple state-of-the-art GNN hardware accelerators.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4386568813",
    "type": "article"
  },
  {
    "title": "IoV-Fog-Assisted Framework for Accident Detection and Classification",
    "doi": "https://doi.org/10.1145/3633805",
    "publication_date": "2023-11-24",
    "publication_year": 2023,
    "authors": "Navin Kumar; Sandeep K. Sood; Munish Saini",
    "corresponding_authors": "",
    "abstract": "The evolution of vehicular research into an effectuating area like the Internet of Vehicles (IoV) was verified by technical developments in hardware. The integration of the Internet of Things (IoT) and Vehicular Ad-hoc Networks (VANET) has significantly impacted addressing various problems, from dangerous situations to finding practical solutions. During a catastrophic collision, the vehicle experiences extreme turbulence, which may be captured using Micro-Electromechanical systems (MEMS) to yield signatures characterizing the severity of the accident. This study presents a three-layer design, with the data collecting layer relying on a low-power IoT configuration that includes GPS and an MPU 6050 placed on an Arduino Mega. The fog layer oversees data pre-processing and other low-level computing operations. With its extensive computing capabilities, the farthest cloud layer carries out Multidimensional Dynamic Time Warping (MDTW) to identify accidents and maintains the information repository by updating it. The experimentation compared the state-of-the-art algorithms such as Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Random Forest Tree (RFT) using threshold-based detection with the proposed MDTW clustering approach. Data collection involves simulating accidents via VirtualCrash for training and testing, whereas the IoV circuitry would be utilized in actual real-life scenarios. The proposed approach achieved an F1-Score of 0.8921 and 0.8184 for rear and head-on collisions.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4388973077",
    "type": "article"
  },
  {
    "title": "Code size reduction technique and implementation for software-pipelined DSP applications",
    "doi": "https://doi.org/10.1145/950162.950168",
    "publication_date": "2003-11-01",
    "publication_year": 2003,
    "authors": "Qingfeng Zhuge; Bin Xiao; Edwin H.‐M. Sha",
    "corresponding_authors": "",
    "abstract": "Software pipelining technique is extensively used to exploit instruction-level parallelism of loops, but also significantly expands the code size. For embedded systems with very limited on-chip memory resources, code size becomes one of the most important optimization concerns. This paper presents the theoretical foundation of code size reduction for software-pipelined loops based on retiming concept. We propose a general Code-size REDuction technique (CRED) for various kinds of processors. Our CRED algorithms integrate the code size reduction with software pipelining. The experimental results show the effectiveness of the CRED technique on both code size reduction and code size/performance trade-off space exploration.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2001363041",
    "type": "article"
  },
  {
    "title": "Low-energy off-chip SDRAM memory systems for embedded applications",
    "doi": "https://doi.org/10.1145/605459.605464",
    "publication_date": "2003-02-01",
    "publication_year": 2003,
    "authors": "Hojun Shim; Yongsoo Joo; Yong‐Seok Choi; Hyung Gyu Lee; Naehyuck Chang",
    "corresponding_authors": "",
    "abstract": "Memory systems are dominant energy consumers, and thus many energy reduction techniques for memory buses and devices have been proposed. For practical energy reduction practices, we have to take into account the interaction between a processor and cache memories together with application programs. Furthermore, energy characterization of memory systems must be accurate enough to justify various techniques. In this article, we build an in-house energy simulator for memory systems that is accelerated by special hardware support while maintaining accuracy. We explore energy behavior of memory systems for various values of the processor and memory clock frequencies and cache configuration. Each experiment is performed with 24M instruction steps of real application programs to guarantee accuracy.The simulator is based on precise energy characterization of memory systems including buses, bus drivers, and memory devices by a cycle-accurate energy measurement technique. We characterize energy consumption of each component by an energy state machine whose states and transitions are associated with the dynamic and static energy costs, respectively. Our approach easily characterizes the energy consumption of complex SDRAMs. We divide and quantify energy components of main memory systems for high-level reduction. The energy simulator enables us to devise practical energy reduction schemes by providing the actual amount of reduction out of the total energy consumption in main memory systems. We introduce several practical energy reduction techniques for SDRAM memory systems and demonstrate energy reduction ratio over the SDRAM memory systems with commercial SDRAM controller chipsets. We classify the SDRAM memory systems into high-performance and mid-performance classes and achieve suitable system configurations for each class. For instance, a typical high-performance 32-bit, 64 MB SDRAM memory system consumes 19.6 mJ, 33.8 mJ, 35.4 mJ, and 37.0 mJ for 24M instructions of an MP3 decoder, a JPEG compressor, a JPEG decompressor, and an MPEG4 decoder, respectively. Our reduction scheme saves 12.7 mJ, 15.1 mJ, 15.5 mJ, and 14.8 mJ, and the reduction ratios are 64.8%, 44.6%, 43.8%, and 40.1%, respectively, without compromising execution speed.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W1973296922",
    "type": "article"
  },
  {
    "title": "Combining supervisor synthesis and model checking",
    "doi": "https://doi.org/10.1145/1067915.1067920",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "Roberto Ziller; Klaus Schneider",
    "corresponding_authors": "",
    "abstract": "Model checking and supervisor synthesis have been successful in solving different design problems related to discrete systems in the last decades. In this paper, we analyze some advantages and drawbacks of these approaches and combine them for mutual improvement. We achieve this through a generalization of the supervisory control problem proposed by Ramadge and Wonham. The objective of that problem is to synthesize a supervisor which constrains a system's behavior according to a given specification, ensuring controllability and coaccessibility. By introducing a new representation of the solution using systems of μ-calculus equations, we are able to handle these two conditions separately and thus to exchange the coaccessibility requirement by any condition that could be used in model checking. Well-known results on μ-calculus model checking allow us to easily assess the computational complexity of any generalization. Moreover, the model checking approach also delivers algorithms to solve the generalized synthesis problem. We include an example in which the coaccessibility requirement is replaced by fairness constraints. The paper also contains an analysis of related work by several authors.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W1985861264",
    "type": "article"
  },
  {
    "title": "Automatic compilation to a coarse-grained reconfigurable system-opn-chip",
    "doi": "https://doi.org/10.1145/950162.950167",
    "publication_date": "2003-11-01",
    "publication_year": 2003,
    "authors": "Girish Venkataramani; Walid Najjar; Fadi Kurdahi; Nader Bagherzadeh; W. Böhm; J. Hammes",
    "corresponding_authors": "",
    "abstract": "The rapid growth of device densities on silicon has made it feasible to deploy reconfigurable hardware as a highly parallel computing platform. However, one of the obstacles to the wider acceptance of this technology is its programmability. The application needs to be programmed in hardware description languages or an assembly equivalent, whereas most application programmers are used to the algorithmic programming paradigm. SA-C has been proposed as an expression-oriented language designed to implicitly express data parallel operations. The Morphosys project proposes an SoC architecture consisting of reconfigurable hardware that supports a data-parallel, SIMD computational model. This paper describes a compiler framework to analyze SA-C programs, perform optimizations, and automatically map the application onto the Morphosys architecture. The mapping process is static and it involves operation scheduling, processor allocation and binding, and register allocation in the context of the Morphosys architecture. The compiler also handles issues concerning data streaming and caching in order to minimize data transfer overhead. We have compiled some important image-processing kernels, and the generated schedules reflect an average speedup in execution times of up to 6× compared to the execution on 800 MHz Pentium III machines.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2008598932",
    "type": "article"
  },
  {
    "title": "Schedulability-driven frame packing for multicluster distributed embedded systems",
    "doi": "https://doi.org/10.1145/1053271.1053276",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Paul Pop; Petru Eles; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "We present an approach to frame packing for multicluster distributed embedded systems consisting of time-triggered and event-triggered clusters, interconnected via gateways. In our approach, the application messages are packed into frames such that the application is schedulable, thus the end-to-end message communication constraints are satisfied. We have proposed a schedulability analysis for applications consisting of mixed event-triggered and time-triggered processes and messages, and a worst-case queuing delay analysis for the gateways, responsible for routing inter-cluster traffic. Optimization heuristics for frame packing aiming at producing a schedulable system have been proposed. Extensive experiments and a real-life example show the efficiency of our frame-packing approach.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W1998165968",
    "type": "article"
  },
  {
    "title": "Iterative schedule optimization for voltage scalable distributed embedded systems",
    "doi": "https://doi.org/10.1145/972627.972636",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Markus Schmitz; Bashir M. Al‐Hashimi; Petru Eles",
    "corresponding_authors": "",
    "abstract": "We present an iterative schedule optimization for multirate system specifications, mapped onto heterogeneous distributed architectures containing dynamic voltage scalable processing elements (DVS-PEs). To achieve a high degree of energy reduction, we formulate a generalized DVS problem, taking into account the power variations among the executing tasks. An efficient heuristic is presented that identifies optimized supply voltages by not only \"simply\" exploiting slack time, but under the additional consideration of the power profiles. Thereby, this algorithm minimizes the energy dissipation of heterogeneous architectures, including power-managed processing elements, effectively. Further, we address the simultaneous schedule optimization toward timing behavior and DVS utilization by integrating the proposed DVS heuristic into a genetic list scheduling approach. We investigate and analyze the possible energy reduction at both steps of the co-synthesis (voltage scaling and scheduling), including the power variations effects. Extensive experiments indicate that the presented work produces solutions with high quality.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2099270353",
    "type": "article"
  },
  {
    "title": "Modeling and validation of pipeline specifications",
    "doi": "https://doi.org/10.1145/972627.972633",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Prabhat Mishra; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Verification is one of the most complex and expensive tasks in the current Systems-on-Chip design process. Many existing approaches employ a bottom-up approach to pipeline validation, where the functionality of an existing pipelined processor is, in essence, reverse-engineered from its RT-level implementation. Our validation technique is complementary to these bottom-up approaches. Our approach leverages the system architect's knowledge about the behavior of the pipelined architecture, through architecture description language (ADL) constructs, and thus allows a powerful top-down approach to pipeline validation. The most important requirement in top-down validation process is to ensure that the specification (reference model) is golden. This paper addresses automatic validation of processor, memory, and coprocessor pipelines described in an ADL. We present a graph-based modeling that captures both structure and behavior of the architecture. Based on this model, we present algorithms to ensure that the static behavior of the pipeline is well formed by analyzing the structural aspects of the specification. We applied our methodology to verify specification of several realistic architectures from different architectural domains to demonstrate the usefulness of our approach.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2150139614",
    "type": "article"
  },
  {
    "title": "A retargetable framework for instruction-set architecture simulation",
    "doi": "https://doi.org/10.1145/1151074.1151083",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Mehrdad Reshadi; Nikil Dutt; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "Instruction-set architecture (ISA) simulators are an integral part of today's processor and software design process. While increasing complexity of the architectures demands high-performance simulation, the increasing variety of available architectures makes retargetability a critical feature of an instruction-set simulator. Retargetability requires generic models while high-performance demands target specific customizations. To address these contradictory requirements, we have developed a generic instruction model and a generic decode algorithm that facilitates easy and efficient retargetability of the ISA-simulator for a wide range of processor architectures, such as RISC, CISC, VLIW, and variable length instruction-set processors. The instruction model is used to generate compact and easy to debug instruction descriptions that are very similar to that of architecture manual. These descriptions are used to generate high-performance simulators. Our retargetable framework combines the flexibility of interpretive simulation with the speed of compiled simulation. The generation of the simulator is completely separate from the simulation engine. Hence, we can incorporate any fast simulation technique in our retargetable framework without introducing any performance penalty. To demonstrate this, we have incorporated fast IS-CS simulation engine in our retargetable framework which has generated 70% performance improvement over the best known simulators in this category. We illustrate the retargetability of our approach using two popular, yet different, realistic architectures: the SPARC and the ARM.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2157512422",
    "type": "article"
  },
  {
    "title": "Memory overflow protection for embedded systems using run-time checks, reuse, and compression",
    "doi": "https://doi.org/10.1145/1196636.1196637",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "Surupa Biswas; Thomas W. Carley; Matthew Simpson; Bhuvan Middha; Rajeev Barua",
    "corresponding_authors": "",
    "abstract": "Embedded systems usually lack virtual memory and are vulnerable to memory overflow since they lack a mechanism to detect overflow or use swap space thereafter. We present a method to detect memory overflows using compiler-inserted software run-time checks. Its overheads in run-time and energy are 1.35 and 1.12%, respectively. Detection of overflow allows system-specific remedial action. We also present techniques to grow the stack or heap segment after they overflow, into previously unutilized space, such as dead variables, free holes in the heap, and space freed by compressing live variables. These may avoid the out-of-memory error if the space recovered is enough to complete execution. The reuse methods are able to grow the stack or heap beyond its overflow by an amount that varies widely by application---the amount of recovered space ranges from 0.7 to 93.5% of the combined stack and heap size.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W1977042717",
    "type": "article"
  },
  {
    "title": "Reducing power while increasing performance with supercisc",
    "doi": "https://doi.org/10.1145/1165780.1165785",
    "publication_date": "2006-08-01",
    "publication_year": 2006,
    "authors": "Alex K. Jones; Raymond R. Hoare; Dara Kusic; Gayatri Mehta; Josh Fazekas; John M. Foster",
    "corresponding_authors": "",
    "abstract": "Multiprocessor Systems on Chips (MPSoCs) have become a popular architectural technique to increase performance. However, MPSoCs may lead to undesirable power consumption characteristics for computing systems that have strict power budgets, such as PDAs, mobile phones, and notebook computers. This paper presents the super-complex instruction-set computing (SuperCISC) Embedded Processor Architecture and, in particular, investigates performance and power consumption of this device compared to traditional processor architecture-based execution. SuperCISC is a heterogeneous, multicore processor architecture designed to exceed performance of traditional embedded processors while maintaining a reduced power budget compared to low-power embedded processors. At the heart of the SuperCISC processor is a multicore VLIW (Very Large Instruction Word) containing several homogeneous execution cores/functional units. In addition, complex and heterogeneous combinational hardware function cores are tightly integrated to the core VLIW engine providing an opportunity for improved performance and reduced energy consumption. Our SuperCISC processor core has been synthesized for both a 90-nm Stratix II Field Programmable Gate Aray (FPGA) and a 160-nm standard cell Application-Specific Integrated Circuit (ASIC) fabrication process from OKI, each operating at approximately 167 MHz for the VLIW core. We examine several reasons for speedup and power improvement through the SuperCISC architecture, including predicated control flow , cycle compression , and a reduction in arithmetic power consumption, which we call power compression . Finally, testing our SuperCISC processor with multimedia and signal-processing benchmarks, we show how the SuperCISC processor can provide performance improvements ranging from 7X to 160X with an average of 60X, while also providing orders of magnitude of power improvements for the computational kernels. The power improvements for our benchmark kernels range from just over 40X to over 400X, with an average savings exceeding 130X. By combining these power and performance improvements, our total energy improvements all exceed 1000X. As these savings are limited to the computational kernels of the applications, which often consume approximately 90% of the execution time, we expect our savings to approach the ideal application improvement of 10X.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2078262581",
    "type": "article"
  },
  {
    "title": "A formal method for hardware IP design and integration under I/O and timing constraints",
    "doi": "https://doi.org/10.1145/1132357.1132359",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "Philippe Coussy; Emmanuel Casseau; Pierre Bomel; Adel Baganne; Éric Martin",
    "corresponding_authors": "",
    "abstract": "IP integration, which is one of the most important SoC design steps, requires taking into account communication and timing constraints. In that context, design and reuse can be improved using IP cores described at a high abstraction level. In this paper, we present an IP design approach that relies on three main phases: (1) constraint modeling, (2) IP constraint analysis steps for feasibility checking, and (3) synthesis. We propose a set of techniques dedicated to the digital signal processing domain that lead to an optimized IP core integration. Based on a generic architecture of components, the method we propose provides automatic generation of IP cores designed under integration constraints. We show the effectiveness of our approach with a DCT core design case study.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2083396724",
    "type": "article"
  },
  {
    "title": "Accurate and fast system-level power modeling",
    "doi": "https://doi.org/10.1145/1274858.1274864",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Ankush Varma; Bruce Jacob; Eric Debes; I. Kozintsev; Paul Klein",
    "corresponding_authors": "",
    "abstract": "Accurate and fast system modeling is central to the rapid design space exploration needed for embedded-system design. With fast, complex SoCs playing a central role in such systems, system designers have come to require MIPS-range simulation speeds and near-cycle accuracy. The sophisticated simulation frameworks that have been developed for high-speed system performance modeling do not address power consumption, although it is a key design constraint. In this paper, we define a simulation-based methodology for extending system performance-modeling frameworks to also include power modeling. We demonstrate the use of this methodology with a case study of a real, complex embedded system, comprising the Intel XScale®g embedded microprocessor, its WMMX™ SIMD coprocessor, L1 caches, SDRAM and the on-board address and data buses. We describe detailed power models for each of these components and validate them against physical measurements from hardware, demonstrating that such frameworks enable designers to model both power and performance at high speeds without sacrificing accuracy. Our results indicate that the power estimates obtained are accurate within 5% of physical measurements from hardware, while simulation speeds consistently exceed a million instructions per second (MIPS).",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2152752923",
    "type": "article"
  },
  {
    "title": "Verifying average dwell time of hybrid systems",
    "doi": "https://doi.org/10.1145/1457246.1457249",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Sayan Mitra; Daniel Liberzon; Nancy Lynch",
    "corresponding_authors": "",
    "abstract": "Average dwell time (ADT) properties characterize the rate at which a hybrid system performs mode switches. In this article, we present a set of techniques for verifying ADT properties. The stability of a hybrid system A can be verified by combining these techniques with standard methods for checking stability of the individual modes of A. We introduce a new type of simulation relation for hybrid automata— switching simulation —for establishing that a given automaton A switches more rapidly than another automaton B. We show that the question of whether a given hybrid automaton has ADT τ a can be answered either by checking an invariant or by solving an optimization problem. For classes of hybrid automata for which invariants can be checked automatically, the invariant-based method yields an automatic method for verifying ADT; for automata that are outside this class, the invariant has to be checked using inductive techniques. The optimization-based method is automatic and is applicable to a restricted class of initialized hybrid automata. A solution of the optimization problem either gives a counterexample execution that violates the ADT property, or it confirms that the automaton indeed satisfies the property. The optimization and the invariant-based methods can be used in combination to find the unknown ADT of a given hybrid automaton.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2063793676",
    "type": "article"
  },
  {
    "title": "Memory allocation for embedded systems with a compile-time-unknown scratch-pad size",
    "doi": "https://doi.org/10.1145/1509288.1509293",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Nghi Nguyen; Ángel Manuel Gamaza Domínguez; Rajeev Barua",
    "corresponding_authors": "",
    "abstract": "This article presents the first memory allocation scheme for embedded systems having a scratch-pad memory whose size is unknown at compile time. A scratch-pad memory (SPM) is a fast compiler-managed SRAM that replaces the hardware-managed cache. All existing memory allocation schemes for SPM require the SPM size to be known at compile time. Unfortunately, because of this constraint, the resulting executable is tied to that size of SPM and is not portable to other processor implementations having a different SPM size. Size-portable code is valuable when programs are downloaded during deployment either via a network or portable media. Code downloads are used for fixing bugs or for enhancing functionality. The presence of different SPM sizes in different devices is common because of the evolution in VLSI technology across years. The result is that SPM cannot be used in such situations with downloaded codes. To overcome this limitation, our work presents a compiler method whose resulting executable is portable across SPMs of any size. Our technique is to employ a customized installer software, which decides the SPM allocation just before the program's first run, since the SPM size can be discovered at that time. The installer then, based on the decided allocation, modifies the program executable accordingly. The resulting executable places frequently used objects in SPM, considering both code and data for placement. To keep the overhead low, much of the preprocessing for the allocation is done at compile time. Results show that our benchmarks average a 41% speedup versus an all-DRAM allocation, while the optimal static allocation scheme, which knows the SPM size at compile time and is thus an unachievable upper-bound and is only slightly faster (45% faster than all-DRAM). Results also show that the overhead from our customized installer averages about 1.5% in code size, 2% in runtime, and 3% in compile time for our benchmarks.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1979940985",
    "type": "article"
  },
  {
    "title": "Minimal placement of bank selection instructions for partitioned memory architectures",
    "doi": "https://doi.org/10.1145/1331331.1331336",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Bernhard Scholz; Bernd Burgstaller; Jingling Xue",
    "corresponding_authors": "",
    "abstract": "We have devised an algorithm for minimal placement of bank selections in partitioned memory architectures. This algorithm is parameterizable for a chosen metric, such as speed, space, or energy. Bank switching is a technique that increases the code and data memory in microcontrollers without extending the address buses. Given a program in which variables have been assigned to data banks, we present a novel optimization technique that minimizes the overhead of bank switching through cost-effective placement of bank selection instructions. The placement is controlled by a number of different objectives, such as runtime, low power, small code size or a combination of these parameters. We have formulated the minimal placement of bank selection instructions as a discrete optimization problem that is mapped to a partitioned boolean quadratic programming (PBQP) problem. We implemented the optimization as part of a PIC Microchip backend and evaluated the approach for several optimization objectives. Our benchmark suite comprises programs from MiBench and DSPStone plus a microcontroller real-time kernel and drivers for microcontroller hardware devices. Our optimization achieved a reduction in program memory space of between 2.7 and 18.2%, and an overall improvement with respect to instruction cycles between 5.0 and 28.8%. Our optimization achieved the minimal solution for all benchmark programs. We investigated the scalability of our approach toward the requirements of future generations of microcontrollers. This study was conducted as a worst-case analysis on the entire MiBench suite. Our results show that our optimization (1) scales well to larger numbers of memory banks, (2) scales well to the larger problem sizes that will become feasible with future microcontrollers, and (3) achieves minimal placement for more than 72% of all functions from MiBench.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1982134186",
    "type": "article"
  },
  {
    "title": "No-Heap remote objects for distributed real-time Java",
    "doi": "https://doi.org/10.1145/1814539.1814546",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Pablo Basanta Val; Marisol García‐Valls; Iria Estévez Ayres",
    "corresponding_authors": "",
    "abstract": "This article presents an approach to providing real-time support for Java's Remote Method Invocation (RMI) and its integration with the RTSJ memory model in order to leave out garbage collection. A new construct for remote objects, called No-heap Remote object ( NhRo ), is introduced. The use of a NhRo guarantees that memory required to perform a remote invocation (at the server side) does not use heap memory. Thus, the aim is to avoid garbage collection in the remote invocation process, improving predictability and memory isolation of distributed Java-based real-time applications. The article presents the bare model and the main programming patterns that are associated with the NhRo model. Sun RMI implementation has been modified to integrate the NhRo model in both static and dynamic environments.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2048436701",
    "type": "article"
  },
  {
    "title": "A Unified Methodology for Scheduling in Distributed Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/2331147.2331167",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Qinghui Tang; Sandeep K. S. Gupta; Georgios Varsamopoulos",
    "corresponding_authors": "",
    "abstract": "A distributed cyber-physical system (DCPS) may receive and induce energy-based interference to and from its environment. This article presents a model and an associated methodology that can be used to (i) schedule tasks in DCPSs to ensure that the thermal effects of the task execution are within acceptable levels, and (ii) verify that a given schedule meets the constraints. The model uses coarse discretization of space and linearity of interference. The methodology involves characterizing the interference of the task execution and fitting it into the model, then using the fitted model to verify a solution or explore the solution space.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2042330014",
    "type": "article"
  },
  {
    "title": "KNOWME",
    "doi": "https://doi.org/10.1145/2331147.2331158",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Gautam Thatte; Ming Li; Sangwon Lee; Adar Emken; Shrikanth Narayanan; Urbashi Mitra; Donna Spruijt‐Metz; Murali Annavaram",
    "corresponding_authors": "",
    "abstract": "The use of biometric sensors for monitoring an individual’s health and related behaviors, continuously and in real time, promises to revolutionize healthcare in the near future. In an effort to better understand the complex interplay between one’s medical condition and social, environmental, and metabolic parameters, this article presents the KNOWME platform, a complete, end-to-end, body area sensing system that integrates off-the-shelf biometric sensors with a Nokia N95 mobile phone to continuously monitor the metabolic signals of a subject. With a current focus on pediatric obesity, KNOWME employs metabolic signals to monitor and evaluate physical activity. KNOWME development and in-lab deployment studies have revealed three major challenges: (1) the need for robustness to highly varying operating environments due to subject-induced variability, such as mobility or sensor placement; (2) balancing the tension between achieving high fidelity data collection and minimizing network energy consumption; and (3) accurate physical activity detection using a modest number of sensors. The KNOWME platform described herein directly addresses these three challenges. Design robustness is achieved by creating a three-tiered sensor data collection architecture. The system architecture is designed to provide robust, continuous, multichannel data collection and scales without compromising normal mobile device operation. Novel physical activity detection methods which exploit new representations of sensor signals provide accurate and efficient physical activity detection. The physical activity detection method employs personalized training phases and accounts for intersession variability. Finally, exploiting the features of the hardware implementation, a low-complexity sensor sampling algorithm is developed, resulting in significant energy savings without loss of performance.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2112114220",
    "type": "article"
  },
  {
    "title": "Pacemaker control of heart rate variability",
    "doi": "https://doi.org/10.1145/2435227.2435246",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Paul Bogdan; Siddharth Jain; Radu Mărculescu",
    "corresponding_authors": "",
    "abstract": "Cardiac diseases, like those related to abnormal heart rate activity, have an enormous economic and psychological impact worldwide. The approaches used to control the behavior of modern pacemakers ignore the fractal nature of heart rate activity. The purpose of this article is to present a Cyber Physical System approach to pacemaker design that exploits precisely the fractal properties of heart rate activity in order to design the pacemaker controller. Towards this end, we solve a finite horizon optimal control problem based on the heartbeat time series and show that this control problem can be converted into a system of linear equations. We also compare and contrast the performance of the fractal optimal control problem under six different cost functions. Finally, to get an idea of hardware complexity, we implement the fractal optimal controller on a Virtex4 FPGA and report some preliminary results in terms of area overhead.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2000340009",
    "type": "article"
  },
  {
    "title": "Multicore-based vector coprocessor sharing for performance and energy gains",
    "doi": "https://doi.org/10.1145/2514641.2514644",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Spiridon F. Beldianu; Sotirios G. Ziavras",
    "corresponding_authors": "",
    "abstract": "For most of the applications that make use of a dedicated vector coprocessor, its resources are not highly utilized due to the lack of sustained data parallelism which often occurs due to vector-length variations in dynamic environments. The motivation of our work stems from: (a) the mandate for multicore designs to make efficient use of on-chip resources for low power and high performance; (b) the omnipresence of vector operations in high-performance scientific and emerging embedded applications; (c) the need to often handle a variety of vector sizes; and (d) vector kernels in application suites may have diverse computation needs. We present a robust design framework for vector coprocessor sharing in multicore environments that maximizes vector unit utilization and performance at substantially reduced energy costs. For our adaptive vector unit, which is attached to multiple cores, we propose three basic shared working policies that enforce coarse-grain, fine-grain, and vector-lane sharing. We benchmark these vector coprocessor sharing policies for a dual-core system and evaluate them using the floating-point performance, resource utilization, and power/energy consumption metrics. Benchmarking for FIR filtering, FFT, matrix multiplication, and LU factorization shows that these coprocessor sharing policies yield high utilization and performance with low energy costs. The proposed policies provide 1.2--2 speedups and reduce the energy needs by about 50% as compared to a system having a single core with an attached vector coprocessor. With the performance expressed in clock cycles, the sharing policies demonstrate 3.62--7.92 speedups compared to optimized Xeon runs. We also introduce performance and empirical power models that can be used by the runtime system to estimate the effectiveness of each policy in a hybrid system that can simultaneously implement this suite of shared coprocessor policies.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2017065085",
    "type": "article"
  },
  {
    "title": "Integrated Code Generation for Loops",
    "doi": "https://doi.org/10.1145/2180887.2180896",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Mattias Eriksson; Christoph Keßler",
    "corresponding_authors": "",
    "abstract": "Code generation in a compiler is commonly divided into several phases: instruction selection, scheduling, register allocation, spill code generation, and, in the case of clustered architectures, cluster assignment. These phases are interdependent; for instance, a decision in the instruction selection phase affects how an operation can be scheduled We examine the effect of this separation of phases on the quality of the generated code. To study this we have formulated optimal methods for code generation with integer linear programming; first for acyclic code and then we extend this method to modulo scheduling of loops. In our experiments we compare optimal modulo scheduling, where all phases are integrated, to modulo scheduling, where instruction selection and cluster assignment are done in a separate phase. The results show that, for an architecture with two clusters, the integrated method finds a better solution than the nonintegrated method for 27% of the instances.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2039755759",
    "type": "article"
  },
  {
    "title": "A hard real-time capable multi-core SMT processor",
    "doi": "https://doi.org/10.1145/2442116.2442129",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Marco Paolieri; Jörg Mische; Stefan Metzlaff; Mike Gerdes; Eduardo Quiñones; Sascha Uhrig; Theo Ungerer; Francisco J. Cazorla",
    "corresponding_authors": "",
    "abstract": "Hard real-time applications in safety critical domains require high performance and time analyzability. Multi-core processors are an answer to these demands, however task interferences make multi-cores more difficult to analyze from a worst-case execution time point of view than single-core processors. We propose a multi-core SMT processor that ensures a bounded maximum delay a task can suffer due to inter-task interferences. Multiple hard real-time tasks can be executed on different cores together with additional non real-time tasks. Our evaluation shows that the proposed MERASA multi-core provides predictability for hard real-time tasks and also high performance for non hard real-time tasks.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2065221974",
    "type": "article"
  },
  {
    "title": "SIPF",
    "doi": "https://doi.org/10.1145/3014584",
    "publication_date": "2017-01-16",
    "publication_year": 2017,
    "authors": "Jun Song; Fan Yang; Kim‐Kwang Raymond Choo; Zhijian Zhuang; Lizhe Wang",
    "corresponding_authors": "",
    "abstract": "Ensuring the security and privacy of vehicular ad hoc networks (VANETs) and related services such as secure payment has been the focus of recent research efforts. Existing secure payment solutions generally require stable and reliable network connection. This is, however, a challenge in a VANET setting. Drive-thru Internet, a secure payment solution for VANETs, involves a great number of fast-moving vehicles competing for connections/communications simultaneously. Thus, service providers may find it challenging to provide real-time payment services or may have to sacrifice the confidentiality and the authenticity of payment vouchers for usability. In this article, we propose a secure installment payment framework for drive-thru Internet deployment in a VANET setting. The framework also provides the capability to embody properties such as confidentiality of payment vouchers, offline signature verification, periodical reconciliation, and installment payment. Performance evaluation and security analysis demonstrate the utility of the framework in a VANET setting.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2576241217",
    "type": "article"
  },
  {
    "title": "LOCUS",
    "doi": "https://doi.org/10.1145/3122786",
    "publication_date": "2017-11-14",
    "publication_year": 2017,
    "authors": "Cheng Tan; Aditi Kulkarni; Vanchinathan Venkataramani; Manupa Karunaratne; Tulika Mitra; Li-Shiuan Peh",
    "corresponding_authors": "",
    "abstract": "Application requirements, such as real-time response, are pushing wearable devices to leverage more powerful processors inside the SoC (system on chip). However, existing wearable devices are not well suited for such challenging applications due to poor performance, and the conventional powerful many-core architectures are not appropriate either due to the stringent power budget in this domain. We propose LOCUS—a low-power, customizable, many-core processor for next-generation wearable devices. LOCUS combines customizable processor cores with a customizable network on a message-passing architecture to deliver very competitive performance/watt—an average 3.1× compared to quad-core ARM processors used in state-of-the-art wearable devices. A combination of full system simulation with representative applications from the wearable domain and RTL synthesis of the architecture show that 16-core LOCUS achieves an average 1.52× performance/watt improvement over a conventional 16-core shared memory many-core architecture. A dynamic power management mechanism is proposed to further decrease the power consumption in both computation and communication, which improves the performance/watt of LOCUS by 1.17×.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2768819501",
    "type": "article"
  },
  {
    "title": "Power-Temperature Stability and Safety Analysis for Multiprocessor Systems",
    "doi": "https://doi.org/10.1145/3126567",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Ganapati Bhat; Suat Gümüşsoy; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "Modern multiprocessor system-on-chips (SoCs) integrate multiple heterogeneous cores to achieve high energy efficiency. The power consumption of each core contributes to an increase in the temperature across the chip floorplan. In turn, higher temperature increases the leakage power exponentially, and leads to a positive feedback with nonlinear dynamics. This paper presents a power-temperature stability and safety analysis technique for multiprocessor systems. This analysis reveals the conditions under which the power-temperature trajectory converges to a stable fixed point. We also present a simple formula to compute the stable fixed point and maximum thermally-safe power consumption at runtime . Hardware measurements on a state-of-the-art mobile processor show that our analytical formulation can predict the stable fixed point with an average error of 2.6%. Hence, our approach can be used at runtime to ensure thermally safe operation and guard against thermal threats.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3099008941",
    "type": "article"
  },
  {
    "title": "Personalized optimization for android smartphones",
    "doi": "https://doi.org/10.1145/2544375.2544380",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Wook Song; Yeseong Kim; Hakbong Kim; Je-Hun Lim; Jihong Kim",
    "corresponding_authors": "",
    "abstract": "As a highly personalized computing device, smartphones present a unique new opportunity for system optimization. For example, it is widely observed that a smartphone user exhibits very regular application usage patterns (although different users are quite different in their usage patterns). User-specific high-level app usage information, when properly managed, can provide valuable hints for optimizing various system design requirements. In this article, we describe the design and implementation of a personalized optimization framework for the Android platform that takes advantage of user's application usage patterns in optimizing the performance of the Android platform. Our optimization framework consists of two main components, the application usage modeling module and the usage model-based optimization module. We have developed two novel application usage models that correctly capture typical smartphone user's application usage patterns. Based on the application usage models, we have implemented an app-launching experience optimization technique which tries to minimize user-perceived delays, extra energy consumption, and state loss when a user launches apps. Our experimental results on the Nexus S Android reference phones show that our proposed optimization technique can avoid unnecessary application restarts by up to 78.4% over the default LRU-based policy of the Android platform.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1965780940",
    "type": "article"
  },
  {
    "title": "Resource Synchronization and Preemption Thresholds Within Mixed-Criticality Scheduling",
    "doi": "https://doi.org/10.1145/2783440",
    "publication_date": "2015-10-20",
    "publication_year": 2015,
    "authors": "Qingling Zhao; Zonghua Gu; Haibo Zeng",
    "corresponding_authors": "",
    "abstract": "In a mixed-criticality system, multiple tasks with different levels of criticality may coexist on the same hardware platform. The scheduling algorithm EDF-VD (Earliest Deadline First with Virtual Deadlines) has been proposed for mixed-criticality systems, which assumes tasks do not share any common resources. We present MC-SRP (Mixed-Criticality Stack Resource Policy), a resource synchronization protocol for EDF-VD, which allows resource sharing among tasks at the same criticality level and guarantees that each task is blocked at most once in each criticality mode. In addition, we present MC-SRPT (MC-SRP with Thresholds) for reducing the application stack size requirement in resource-constrained embedded systems.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1981263595",
    "type": "article"
  },
  {
    "title": "A theory of robust omega-regular software synthesis",
    "doi": "https://doi.org/10.1145/2539036.2539044",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Rupak Majumdar; Elaine Render; Paulo Tabuada",
    "corresponding_authors": "",
    "abstract": "A key property for systems subject to uncertainty in their operating environment is robustness : ensuring that unmodeled but bounded disturbances have only a proportionally bounded effect upon the behaviors of the system. Inspired by ideas from robust control and dissipative systems theory, we present a formal definition of robustness as well as algorithmic tools for the design of optimally robust controllers for ω-regular properties on discrete transition systems. Formally, we define metric automata —automata equipped with a metric on states—and strategies on metric automata which guarantee robustness for ω-regular properties. We present fixed-point algorithms to construct optimally robust strategies in polynomial time. In contrast to strategies computed by classical graph theoretic approaches, the strategies computed by our algorithm ensure that the behaviors of the controlled system gracefully degrade under the action of disturbances; the degree of degradation is parameterized by the magnitude of the disturbance. We show an application of our theory to the design of controllers that tolerate infinitely many transient errors provided they occur infrequently enough.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2052647688",
    "type": "article"
  },
  {
    "title": "System-level approach to the design of a smart distributed surveillance system using systemj",
    "doi": "https://doi.org/10.1145/2362336.2362344",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Avinash Malik; Zoran Salčić; Christopher Chong; Salman Javed",
    "corresponding_authors": "",
    "abstract": "Distributed surveillance systems represent a class of sensor networks used for object location and tracking, road traffic monitoring, security, and other purposes. They are very complex to describe, design, and run. Because of their sensitivity, they need to be carefully designed and validated. We present a system-level approach to modeling and designing such systems using a new system-level programming language, SystemJ, which enables designers to describe computational and communication parts of such applications in a highly abstract manner. The designed system can be modeled and validated even before deployment and in that way contribute to the overall reliability and trustworthiness of such systems. As an additional tool, the design environment for specification of the surveillance system topology, physical and communication properties, selected sensors and their interconnectivity with the computing resources was developed. This tool enables easy composition of multiple sensors and their respective controllers, capturing changes of configuration of the system and underlying communication, and automatic generation of the formal description of the surveillance system. This description is then used for the generation of executable code and/or the templates for detailed SystemJ application-specific code, as well as for generation of the operator GUI in a surveillance system.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2085985154",
    "type": "article"
  },
  {
    "title": "Automatic synthesis of physical system differential equation models to a custom network of general processing elements on FPGAs",
    "doi": "https://doi.org/10.1145/2514641.2514650",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Chen Huang; Frank Vahid; Tony Givargis",
    "corresponding_authors": "",
    "abstract": "Fast execution of physical system models has various uses, such as simulating physical phenomena or real-time testing of medical equipment. Physical system models commonly consist of thousands of differential equations. Solving such equations using software on microprocessor devices may be slow. Several past efforts implement such models as parallel circuits on special computing devices called Field-Programmable Gate Arrays (FPGAs), demonstrating large speedups due to the excellent match between the massive fine-grained local communication parallelism common in physical models and the fine-grained parallel compute elements and local connectivity of FPGAs. However, past implementation efforts were mostly manual or ad hoc. We present the first method for automatically converting a set of ordinary differential equations into circuits on FPGAs. The method uses a general Processing Element (PE) that we developed, designed to quickly solve a set of ordinary differential equations while using few FPGA resources. The method instantiates a network of general PEs, partitions equations among the PEs to minimize communication, generates each PE's custom program, creates custom connections among PEs, and maintains synchronization of all PEs in the network. Our experiments show that the method generates a 400-PE network on a commercial FPGA that executes four different models on average 15x faster than a 3 GHz Intel processor, 30x faster than a commercial 4-core ARM, 14x faster than a commercial 6-core Texas Instruments digital signal processor, and 4.4x faster than an NVIDIA 336-core graphics processing unit. We also show that the FPGA-based approach is reasonably cost effective compared to using the other platforms. The method yields 2.1x faster circuits than a commercial high-level synthesis tool that uses the traditional method for converting behavior to circuits, while using 2x fewer lookup tables, 2x fewer hardcore multiplier (DSP) units, though 3.5x more block RAM due to being programmable. Furthermore, the method does not just generate a single fastest design, but generates a range of designs that trade off size and performance, by using different numbers of PEs.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2088293894",
    "type": "article"
  },
  {
    "title": "A system-level infrastructure for multidimensional MP-SoC design space co-exploration",
    "doi": "https://doi.org/10.1145/2536747.2536749",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Zai Jian Jia; Tomás Bautista; Antonio Núñez; Andy D. Pimentel; Mark G. Thompson",
    "corresponding_authors": "",
    "abstract": "In this article, we present a flexible and extensible system-level MP-SoC design space exploration (DSE) infrastructure, called NASA. This highly modular framework uses well-defined interfaces to easily integrate different system-level simulation tools as well as different combinations of search strategies in a simple plug-and-play fashion. Moreover, NASA deploys a so-called dimension-oriented DSE approach, allowing designers to configure the appropriate number of, well-tuned and possibly different, search algorithms to simultaneously co-explore the various design space dimensions. As a result, NASA provides a flexible and re-usable framework for the systematic exploration of the multidimensional MP-SoC design space, starting from a set of relatively simple user specifications. To demonstrate the capabilities of the NASA framework and to illustrate its distinct aspects, we also present several DSE experiments in which, for example, we compare NASA configurations using a single search algorithm for all design space dimensions to configurations using a separate search algorithm per dimension. These proof-of-concept experiments indicate that the latter multidimensional co-exploration can find better design points and evaluates a higher diversity of design alternatives as compared to the more traditional approach of using a single search algorithm for all dimensions.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2144128384",
    "type": "article"
  },
  {
    "title": "FlashLight",
    "doi": "https://doi.org/10.1145/2180887.2180895",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Jaegeuk Kim; Hyotaek Shim; Seon-Yeong Park; Seungryoul Maeng; Jin‐Soo Kim",
    "corresponding_authors": "",
    "abstract": "A very promising approach for using NAND flash memory as a storage medium is a flash file system. In order to design a higher-performance flash file system, two issues should be considered carefully. One issue is the design of an efficient index structure that contains the locations of both files and data in the flash memory. For large-capacity storage, the index structure must be stored in the flash memory to realize low memory consumption; however, this may degrade the system performance. The other issue is the design of a novel garbage collection (GC) scheme that reclaims obsolete pages. This scheme can induce considerable additional read and write operations while identifying and migrating valid pages. In this article, we present a novel flash file system that has the following features: ( i ) a lightweight index structure that introduces the hybrid indexing scheme and intra-inode index logging , and ( ii ) an efficient GC scheme that adopts a dirty list with an on-demand GC approach as well as fine-grained data separation and erase-unit data allocation . We implemented FlashLight in a Linux OS with kernel version 2.6.21 on an embedded device. The experimental results obtained using several benchmark programs confirm that FlashLight improves the performance by up to 27.4% over UBIFS by alleviating index management and GC overheads by up to 33.8%.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2163872587",
    "type": "article"
  },
  {
    "title": "AdaFT",
    "doi": "https://doi.org/10.1145/2980763",
    "publication_date": "2017-03-28",
    "publication_year": 2017,
    "authors": "Ye Xu; Israel Koren; C.M. Krishna",
    "corresponding_authors": "",
    "abstract": "Cyber-physical systems (CPS) frequently have to use massive redundancy to meet application requirements for high reliability. While such redundancy is required, it can be activated adaptively, based on the current state of the controlled plant. Most of the time, the plant is in a state that allows for a lower level of fault tolerance. Avoiding the continuous deployment of massive fault tolerance will greatly reduce the workload of the CPS, and lower the operating temperature of the cyber sub-system, thus increasing its reliability. In this article, we extend our prior research by demonstrating a software simulation framework Adaptive Fault Tolerance (AdaFT) that can automatically generate the sub-spaces within which our adaptive fault tolerance can be applied. We also show the theoretical benefits of AdaFT and its actual implementation in several real-world CPSs.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2599479953",
    "type": "article"
  },
  {
    "title": "Fault-Tolerant Preemptive Aperiodic RT Scheduling by Supervisory Control of TDES on Multiprocessors",
    "doi": "https://doi.org/10.1145/3012278",
    "publication_date": "2017-04-11",
    "publication_year": 2017,
    "authors": "Rajesh Devaraj; Arnab Sarkar; Santosh Biswas",
    "corresponding_authors": "",
    "abstract": "Safety-critical real-time systems must meet stringent timing and fault-tolerance requirements. This article proposes a methodology for synthesizing an optimal preemptive multiprocessor aperiodic task scheduler using a formal supervisory control framework. The scheduler can tolerate single/multiple permanent processor faults. Further, the synthesis framework has been empowered with a novel BDD-based symbolic computation mechanism to control the exponential state-space complexity of the optimal exhaustive enumeration-oriented synthesis methodology.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2607135713",
    "type": "article"
  },
  {
    "title": "Petri Net Models and Collaborativeness for Parallel Processes with Resource Sharing and Message Passing",
    "doi": "https://doi.org/10.1145/2810001",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Guanjun Liu; MengChu Zhou; Changjun Jiang",
    "corresponding_authors": "",
    "abstract": "Petri nets are widely used to model and analyse concurrent systems. There exist two distinct classes of Petri nets that focus on different features of concurrent systems. The first one features multiple parallel processes sharing a group of common resources but not interacting/collaborating with each other. The second one allows multiple parallel processes to interact/collaborate with each other via message exchange but does not share any common resources. However, in many distributed environments, multiple processes both interact/collaborate with each other and share some common resources. To model and analyse such systems, this article defines a new class of Petri nets called Parallel Process Nets (P 2 Ns) that may be viewed as a generalization of the two mentioned above. We propose collaborativeness and close collaborativeness for P 2 Ns. The former guarantees that a modelled system is both deadlock-free and livelock-free, and the latter guarantees that it is deadlock-free, livelock-free, and starvation-free. These concepts and ideas are illustrated through some classical examples such as Producer-Consumer Problem and Dinning Philosophers Problem. Algorithms are developed to decide them. At last, P 2 Ns are applied to the modelling and analysis of two real systems: hospital information system and elevator scheduling system.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2620052665",
    "type": "article"
  },
  {
    "title": "Diagonal Component Expansion for Flow-Layer Placement of Flow-Based Microfluidic Biochips",
    "doi": "https://doi.org/10.1145/3126529",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Brian Crites; Karen Kong; Philip Brisk",
    "corresponding_authors": "",
    "abstract": "Continuous flow-based microfluidic devices have seen a huge increase in interest because of their ability to automate and miniaturize biochemistry and biological processes, as well as their promise of creating a programmable platform for chemical and biological experimentation. The major hurdle in the adoption of these types of devices is in the design, which is largely done by hand using tools such as AutoCAD or SolidWorks, which require immense domain knowledge and are hard to scale. This paper investigates the problem of automated physical design for continuous flow-based microfluidic very large scale integration (mVLSI) biochips, starting from a netlist specification of the flow layer. After an initial planar graph embedding, vertices in the netlist are expanded into two-dimensional components, followed by fluid channel routing. A new heuristic, DIagonal Component Expansion (DICE) is introduced for the component expansion step. Compared to a baseline expansion method, DICE improves area utilization by a factor of 8.90x and reduces average fluid routing channel length by 47.4%.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2758844534",
    "type": "article"
  },
  {
    "title": "A High-Speed Accelerator for Homomorphic Encryption using the Karatsuba Algorithm",
    "doi": "https://doi.org/10.1145/3126558",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Vincent Migliore; Cédric Seguin; Maria Méndez Real; Vianney Lapôtre; Arnaud Tisserand; Caroline Fontaine; Guy Gogniat; Russell Tessier",
    "corresponding_authors": "",
    "abstract": "Somewhat Homomorphic Encryption (SHE) schemes can be used to carry out operations on ciphered data. In a cloud computing scenario, personal information can be processed secretly, inferring a high level of confidentiality. The principle limitation of SHE is the size of ciphertext compared to the size of the message. This issue can be addressed by using a batching technique that “packs” several messages into one ciphertext. However, this method leads to important drawbacks in standard implementations. This paper presents a fast hardware/software co-design implementation of an encryption procedure using the Karatsuba algorithm. Our hardware accelerator is 1.5 times faster than the state of the art for 1 encryption and 4 times faster for 4 encryptions.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2759027818",
    "type": "article"
  },
  {
    "title": "Underminer",
    "doi": "https://doi.org/10.1145/3122787",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "Ayça Balkan; Paulo Tabuada; Jyotirmoy V. Deshmukh; Xiaoqing Jin; James Kapinski",
    "corresponding_authors": "",
    "abstract": "Evaluation of industrial embedded control system designs is a time-consuming and imperfect process. While an ideal process would apply a formal verification technique such as model checking or theorem proving, these techniques do not scale to industrial design problems, and it is often difficult to use these techniques to verify performance aspects of control system designs, such as stability or convergence. For industrial designs, engineers rely on testing processes to identify critical or unexpected behaviors. We propose a novel framework called Underminer to improve the testing process; this is an automated technique to identify nonconverging behaviors in embedded control system designs. Underminer treats the system as a black box and lets the designer indicate the model parameters, inputs, and outputs that are of interest. It differentiates convergent from nonconvergent behaviors using Convergence Classifier Functions (CCFs). The tool can be applied in the context of testing models created late in the controller development stage, where it assumes that the given model displays mostly convergent behavior and learns a CCF in an unsupervised fashion from such convergent model behaviors. This CCF is then used to guide a thorough exploration of the model with the help of optimization-guided techniques or adaptive sampling techniques, with the goal of identifying rare nonconvergent model behaviors. Underminer can also be used early in the development stage, where models may have some significant nonconvergent behaviors. Here, the framework permits designers to indicate their mental model for convergence by labeling behaviors as convergent/nonconvergent and then constructs a CCF using a supervised learning technique. In this use case, the goal is to use the CCF to test an improved design for the model. Underminer supports a number of convergence-like notions, such as those based on Lyapunov analysis and temporal logic, and also CCFs learned directly from labeled output behaviors using machine-learning techniques such as support vector machines and neural networks. We demonstrate the efficacy of Underminer by evaluating its performance on several academic as well as industrial examples.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2773814846",
    "type": "article"
  },
  {
    "title": "Simulation-Driven Reachability Using Matrix Measures",
    "doi": "https://doi.org/10.1145/3126685",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "Chuchu Fan; James Kapinski; Xiaoqing Jin; Sayan Mitra",
    "corresponding_authors": "",
    "abstract": "Simulation-driven verification can provide formal safety guarantees for otherwise intractable nonlinear and hybrid system models. A key step in simulation-driven algorithms is to compute the reach set overapproximations from a set of initial states through numerical simulations and sensitivity analysis. This article addresses this problem by providing algorithms for computing discrepancy functions as the upper bound on the sensitivity, that is, the rate at which trajectories starting from neighboring states converge or diverge. The algorithms rely on computing local bounds on matrix measures as the exponential change rate of the discrepancy function. We present two techniques to compute the matrix measures under different norms: regular Euclidean norm or Euclidean norm under coordinate transformation, such that the exponential rate of the discrepancy function, and therefore, the conservativeness of the overapproximation, is locally minimized. The proposed algorithms enable automatic reach set computations of general nonlinear systems and have been successfully used on several challenging benchmark models. All proposed algorithms for computing discrepancy functions give soundness and relative completeness of the overall simulation-driven safety-bounded verification algorithm. We present a series of experiments to illustrate the accuracy and performance of the algorithms.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2774589618",
    "type": "article"
  },
  {
    "title": "Compact Implementations of ARX-Based Block Ciphers on IoT Processors",
    "doi": "https://doi.org/10.1145/3173455",
    "publication_date": "2018-02-06",
    "publication_year": 2018,
    "authors": "Hwajeong Seo; Il-Woong Jeong; Jung‐Keun Lee; Woo-Hwan Kim",
    "corresponding_authors": "",
    "abstract": "In this article, we present implementations for Addition, Rotation, and eXclusive-or (ARX)-based block ciphers, including LEA and HIGHT, on IoT devices, including 8-bit AVR, 16-bit MSP, 32-bit ARM, and 32-bit ARM-NEON processors. We optimized 32-/8-bitwise ARX operations for LEA and HIGHT block ciphers by considering variations in word size, the number of general purpose registers, and the instruction set of the target IoT devices. Finally, we achieved the most compact implementations of LEA and HIGHT block ciphers. The implementations were fairly evaluated through the Fair Evaluation of Lightweight Cryptographic Systems framework, and implementations won the competitions in the first and the second rounds.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2787387205",
    "type": "article"
  },
  {
    "title": "A Lightweight Cryptographic Protocol with Certificateless Signature for the Internet of Things",
    "doi": "https://doi.org/10.1145/3301306",
    "publication_date": "2019-04-05",
    "publication_year": 2019,
    "authors": "Lu Zhou; Chunhua Su; Kuo‐Hui Yeh",
    "corresponding_authors": "",
    "abstract": "The universality of smart-devices has brought rapid development and the significant advancement of ubiquitous applications for the Internet of Things (IoT). Designing new types of IoT-compatible cryptographic protocols has become a more popular way to secure IoT-based applications. Significant attention has been dedicated to the challenge of implementing a lightweight and secure cryptographic protocol for IoT devices. In this study, we propose a lightweight cryptographic protocol integrating certificateless signature and bilinear pairing crypto-primitives. In the proposed protocol, we elegantly refine the processes to account for computation-limited IoT devices during security operations. Rigorous security analyses are conducted to guarantee the robustness of the proposed cryptographic protocol. In addition, we demonstrate a thorough performance evaluation, where an IoT-based test-bed, i.e., the Raspberry PI, is simulated as the underlying platform of the implementation of our proposed cryptographic protocol. The results show the practicability of the proposed protocol.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2938630680",
    "type": "article"
  },
  {
    "title": "Design-Level and Code-Level Security Analysis of IoT Devices",
    "doi": "https://doi.org/10.1145/3310353",
    "publication_date": "2019-05-07",
    "publication_year": 2019,
    "authors": "Farid Molazem Tabrizi; Karthik Pattabiraman",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) is playing an important role in different aspects of our lives. Smart grids, smart cars, and medical devices all incorporate IoT devices as key components. The ubiquity and criticality of these devices make them an attractive target for attackers. Therefore, we need techniques to analyze their security so that we can address their potential vulnerabilities. IoT devices, unlike remote servers, are user-facing and, therefore, an attacker may interact with them more extensively, e.g., via physical access. Existing techniques for analyzing security of IoT devices either rely on a pre-defined set of attacks and, therefore, have limited effect or do not consider the specific capabilities the attackers have against IoT devices. Security analysis techniques may operate at the design-level, leveraging abstraction to avoid state-space explosion, or at the code-level for ensuring accuracy. In this article, we introduce two techniques, one at the design-level, and the other at the code-level, to analyze security of IoT devices, and compare their effectiveness. The former technique uses model checking, while the latter uses symbolic execution, to find attacks based on the attacker’s capabilities. We evaluate our techniques on an open source smart meter. We find that our code-level analysis technique is able to find three times more attacks and complete the analysis in half the time, compared to the design-level analysis technique, with no false positives.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2944303438",
    "type": "article"
  },
  {
    "title": "Achieving Lossless Accuracy with Lossy Programming for Efficient Neural-Network Training on NVM-Based Systems",
    "doi": "https://doi.org/10.1145/3358191",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Wei-Chen Wang; Yuan-Hao Chang; Tei‐Wei Kuo; Chien-Chung Ho; Yu-Ming Chang; Hung-Sheng Chang",
    "corresponding_authors": "",
    "abstract": "Neural networks over conventional computing platforms are heavily restricted by the data volume and performance concerns. While non-volatile memory offers potential solutions to data volume issues, challenges must be faced over performance issues, especially with asymmetric read and write performance. Beside that, critical concerns over endurance must also be resolved before non-volatile memory could be used in reality for neural networks. This work addresses the performance and endurance concerns altogether by proposing a data-aware programming scheme. We propose to consider neural network training jointly with respect to the data-flow and data-content points of view. In particular, methodologies with approximate results over Dual-SET operations were presented. Encouraging results were observed through a series of experiments, where great efficiency and lifetime enhancement is seen without sacrificing the result accuracy.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2979690924",
    "type": "article"
  },
  {
    "title": "READY",
    "doi": "https://doi.org/10.1145/3358187",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Lucas Bragança Da Silva; Ricardo Ferreira; Michael Canesche; Marcelo M. Menezes; Maria de Fátima Araújo Vieira; Jeronimo Costa Penha; Peter Jamieson; José Augusto M. Nacif",
    "corresponding_authors": "",
    "abstract": "In this work, we propose a framework called REconfigurable Accelerator DeploY (READY), the first framework to support polynomial runtime mapping of dataflow applications in high-performance CPU-FPGA platforms. READY introduces an efficient mapping with fine-grained multithreading onto an overlay architecture that hides the latency of a global interconnection network. In addition to our overlay architecture, we show how this system helps solve some of the challenges for FPGA cloud computing adoption in high-performance computing. The framework encapsulates dataflow descriptions by using a target independent, high-level API, and a dataflow model that allows for explicit spatial and temporal parallelism. READY directly maps the dataflow kernels onto the accelerator. Our tool is flexible and extensible and provides the infrastructure to explore different accelerator designs. We validate READY on the Intel Harp platform, and our experimental results show an average 2x execution runtime improvement when compared to an 8-thread multi-core processor.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2980034311",
    "type": "article"
  },
  {
    "title": "Optode Design Space Exploration for Clinically-robust Non-invasive Fetal Oximetry",
    "doi": "https://doi.org/10.1145/3358207",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Daniel Fong; Vivek J. Srinivasan; Kourosh Vali; Soheil Ghiasi",
    "corresponding_authors": "",
    "abstract": "Non-invasive transabdominal fetal oximetry (TFO) has the potential to improve delivery outcomes by providing physicians with an objective metric of fetal well-being during labor. Fundamentally, the technology is based on sending light through the maternal abdomen to investigate deep fetal tissue, followed by detection and processing of the light that returns (via scattering) to the outside of the maternal abdomen. The placement of the photodetector in relation to the light source critically impacts TFO system performance, including its operational robustness in the face of fetal depth variation. However, anatomical differences between pregnant women cause the fetal depths to vary drastically, which further complicates the optical probe (optode) design optimization. In this paper, we present a methodology to solve this problem. We frame optode design space exploration as a multi-objective optimization problem, where hardware complexity (cost) and performance across a wider patient population (robustness) form competing objectives. We propose a model-based approach to characterize the Pareto-optimal points in the optode design space, through which a specific design is selected. Experimental evaluation via simulation and in vivo measurement on pregnant sheep support the efficacy of our approach.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2996883697",
    "type": "article"
  },
  {
    "title": "A Probabilistic Calculus for Probabilistic Real-Time Systems",
    "doi": "https://doi.org/10.1145/2717113",
    "publication_date": "2015-04-30",
    "publication_year": 2015,
    "authors": "Luca Santinelli; Liliana Cucu‐Grosjean",
    "corresponding_authors": "",
    "abstract": "Challenges within real-time research are mostly in terms of modeling and analyzing the complexity of actual real-time embedded systems. Probabilities are effective in both modeling and analyzing embedded systems by increasing the amount of information for the description of elements composing the system. Elements are tasks and applications that need resources, schedulers that execute tasks, and resource provisioning that satisfies the resource demand. In this work, we present a model that considers component-based real-time systems with component interfaces able to abstract both the functional and nonfunctional requirements of components and the system. Our model faces probabilities and probabilistic real-time systems unifying in the same framework probabilistic scheduling techniques and compositional guarantees varying from soft to hard real time. We provide an algebra to work with the probabilistic notation developed and form an analysis in terms of sufficient probabilistic schedulability conditions for task systems with either preemptive fixed-priority or earliest deadline first scheduling paradigms.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W1971452963",
    "type": "article"
  },
  {
    "title": "Stubborn Sets for Time Petri Nets",
    "doi": "https://doi.org/10.1145/2680541",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Hanifa Boucheneb; Kamel Barkaoui",
    "corresponding_authors": "",
    "abstract": "The main limitation of the verification approaches based on state enumeration is the state explosion problem. The partial order reduction techniques aim at attenuating this problem by reducing the number of transitions to be fired from each state while preserving properties of interest. Among the reduction techniques proposed in the literature, this article considers the stubborn set method of Petri nets and investigates its extension to time Petri nets. It establishes some useful sufficient conditions for stubborn sets, which preserve deadlocks and k-boundedness of places.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W1984616519",
    "type": "article"
  },
  {
    "title": "Multilevel Phase Analysis",
    "doi": "https://doi.org/10.1145/2629594",
    "publication_date": "2015-03-09",
    "publication_year": 2015,
    "authors": "Weihua Zhang; Jiaxin Li; Yi Li; Haibo Chen",
    "corresponding_authors": "",
    "abstract": "Phase analysis, which classifies the set of execution intervals with similar execution behavior and resource requirements, has been widely used in a variety of systems, including dynamic cache reconfiguration, prefetching, race detection, and sampling simulation. Although phase granularity has been a major factor in the accuracy of phase analysis, it has not been well investigated, and most systems usually adopt a fine-grained scheme. However, such a scheme can only take account of recent local phase information and could be frequently interfered by temporary noise due to instant phase changes, which might notably limit the accuracy. In this article, we make the first investigation on the potential of multilevel phase analysis (MLPA), where different granularity phase analyses are combined together to improve the overall accuracy. The key observation is that the coarse-grained intervals belonging to the same phase usually consist of stably distributed fine-grained phases. Moreover, the phase of a coarse-grained interval can be accurately identified based on the fine-grained intervals at the beginning of its execution. Based on the observation, we design and implement an MLPA scheme. In such a scheme, a coarse-grained phase is first identified based on the fine-grained intervals at the beginning of its execution. The following fine-grained phases in it are then predicted based on the sequence of fine-grained phases in the coarse-grained phase. Experimental results show that such a scheme can notably improve the prediction accuracy. Using a Markov fine-grained phase predictor as the baseline, MLPA can improve prediction accuracy by 20%, 39%, and 29% for next phase, phase change, and phase length prediction for SPEC2000, respectively, yet incur only about 2% time overhead and 40% space overhead (about 360 bytes in total). To demonstrate the effectiveness of MLPA, we apply it to a dynamic cache reconfiguration system that dynamically adjusts the cache size to reduce the power consumption and access time of the data cache. Experimental results show that MLPA can further reduce the average cache size by 15% compared to the fine-grained scheme. Moreover, for MLPA, we also observe that coarse-grained phases can better capture the overall program characteristics with fewer of phases and the last representative phase could be classified in a very early program position, leading to fewer execution internals being functionally simulated. Based on this observation, we also design a multilevel sampling simulation technique that combines both fine- and coarse-grained phase analysis for sampling simulation. Such a scheme uses fine-grained simulation points to represent only the selected coarse-grained simulation points instead of the entire program execution; thus, it could further reduce both the functional and detailed simulation time. Experimental results show that MLPA for sampling simulation can achieve a speedup in simulation time of about 8.3X with similar accuracy compared to 10M SimPoint.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2020498587",
    "type": "article"
  },
  {
    "title": "Ultra-low-power adder stage design for exascale floating point units",
    "doi": "https://doi.org/10.1145/2567932",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Alberto A. Del Barrio; Nader Bagherzadeh; R. Hermida",
    "corresponding_authors": "",
    "abstract": "Currently, the most powerful supercomputers can provide tens of petaflops. Future many-core systems are estimated to provide an exaflop. However, the power budget limitation makes these machines still unfeasible and unaffordable. Floating Point Units (FPUs) are critical from both the power consumption and performance points of view of today's microprocessors and supercomputers. Literature offers very different designs. Some of them are focused on increasing performance no matter the penalty, and others on decreasing power at the expense of lower performance. In this article, we propose a novel approach for reducing the power of the FPU without degrading the rest of parameters. Concretely, this power reduction is also accompanied by an area reduction and a performance improvement. Hence, an overall energy gain will be produced. According to our experiments, our proposed unit consumes 17.5%, 23% and 16.5% less energy for single, double and quadruple precision, with an additional 15%, 21.5% and 14.5% delay reduction, respectively. Furthermore, area is also diminished by 4%, 4.5 and 5%.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2170140732",
    "type": "article"
  },
  {
    "title": "Exploiting Page Correlations for Write Buffering in Page-Mapping Multichannel SSDs",
    "doi": "https://doi.org/10.1145/2815622",
    "publication_date": "2016-01-13",
    "publication_year": 2016,
    "authors": "Sheng-Min Huang; Li-Pin Chang",
    "corresponding_authors": "",
    "abstract": "Advanced solid-state disks (SSDs) have been equipped with page-mapping flash translation layers and multichannel architectures. The SSDs employ a RAM-based write buffer, which delays write requests for reducing write traffic, reorders requests for mitigating garbage-collection overhead, and produces parallel page writes for improving channel time utilization. This work presents a novel write buffer algorithm that exploits temporal and spatial correlations among buffer pages. The write-buffer groups temporally or spatially correlate buffer pages and then write the grouped buffer pages to the same flash block. In this way, when the correlated page data are updated in the future, flash blocks will receive bulk page invalidations and become good candidates for garbage collection. With multichannel architectures, the write buffer adaptively disperses read-most sequential data over channels for high page-level parallelism of sequential reads, while clustering write-most sequential data in the same channel for a reduced cost of garbage collection. We evaluated the proposed method and previously proposed buffer algorithms. Our method was shown to outperform the existing methods by up to 134%. We also implemented our buffer design on the OpenSSD platform; the time and space overheads of our design were reported to be very low.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2237851351",
    "type": "article"
  },
  {
    "title": "Adaptive Workload Management in Mixed-Criticality Systems",
    "doi": "https://doi.org/10.1145/2950058",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Biao Hu; Kai Huang; Gang Chen; Long Cheng; Alois Knoll",
    "corresponding_authors": "",
    "abstract": "Due to the efficient resource usage of integrating tasks with different criticality onto a shared platform, the integration with mixed-criticality tasks is becoming an increasingly important trend in the design of real-time systems. One challenge in such a mixed-criticality system is to maximize the service for low-critical tasks, while meeting the timing constraints of high-critical tasks. In this article, we investigate how to adaptively manage the low-critical workload during runtime to meet both goals, that is, providing the service for low-critical tasks as much as possible and guaranteeing the hard real-time requirements for high-critical tasks. Unlike previous methods, which enforce an offline bound towards the low-critical workload, runtime adaptation approaches are proposed in which the incoming workload of low-critical tasks is adaptively regulated by considering the actual demand of high-critical tasks. This actual demand of the high-critical tasks, in turn, is adaptively updated using their historical arrival information. Based on this adaptation scheme, two scheduling policies—the priority-adjustment policy and the workload-shaping policy—are proposed to do the workload management. In order to reduce online management overhead, a lightweight scheme with O ( n · log ( n )) complexity is developed. Extensive simulation results are presented to demonstrate the effectiveness of our proposed workload management approaches.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2530657413",
    "type": "article"
  },
  {
    "title": "An FPGA-Based Architecture for High-Speed Compressed Signal Reconstruction",
    "doi": "https://doi.org/10.1145/3056481",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Guoxian Huang; Lei Wang",
    "corresponding_authors": "",
    "abstract": "Compressive Sensing (CS) is an emerging research area that allows efficient signal acquisition under the sub-Nyquist rate while still promising reliable data recovery. However, practical applications of CS in hardware platforms are limited as signal reconstruction is still challenging due to its high computational complexity, especially for autonomous real-time signal recovery. In this article, we propose an algorithmic transformation technique referred to as Matrix Inversion Bypass (MIB) to improve the signal recovery efficiency of the Orthogonal Matching Pursuit (OMP)-based CS reconstruction. The basic idea of MIB is to decouple the computations of intermediate signal estimates and matrix inversions, thereby enabling parallel processing of these two time-consuming operations in the OMP algorithm. The proposed MIB naturally leads to a parallel architecture for high-speed dedicated hardware implementations. An FPGA-based implementation is developed with the optimized structure aimed at the efficient utilization of hardware resources while realizing high-speed signal recovery. The proposed architecture can perform the signal recovery at up to 1.4 × faster than the OMP-based implementation using almost the same hardware resources.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2618157045",
    "type": "article"
  },
  {
    "title": "DC4CD",
    "doi": "https://doi.org/10.1145/3105923",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "Salvatore Gaglio; Giuseppe Lo Re; Gloria Martorella; Daniele Peri",
    "corresponding_authors": "",
    "abstract": "In this article, we present Distributed Computing for Constrained Devices (DC4CD), a novel software architecture that supports symbolic distributed computing on wireless sensor networks. DC4CD integrates the functionalities of a high-level symbolic interpreter, a compiler, and an operating system, and includes networking abstractions to exchange high-level symbolic code among peer devices. Contrarily to other architectures proposed in the literature, DC4CD allows for changes at runtime, even on deployed nodes of both application and system code. Experimental results show that DC4CD is more efficient in terms of memory usage than existing architectures, with which it also compares well in terms of execution efficiency.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2773793473",
    "type": "article"
  },
  {
    "title": "Lightweight Implementations of NIST P-256 and SM2 ECC on 8-bit Resource-Constraint Embedded Device",
    "doi": "https://doi.org/10.1145/3236010",
    "publication_date": "2019-04-09",
    "publication_year": 2019,
    "authors": "Lu Zhou; Chunhua Su; Zhi Hu; Sokjoon Lee; Hwajeong Seo",
    "corresponding_authors": "",
    "abstract": "Elliptic Curve Cryptography (ECC) now is one of the most important approach to instantiate asymmetric encryption and signature schemes, which has been extensively exploited to protect the security of cyber-physical systems. With the advent of the Internet of Things (IoT), a great deal of constrained devices may require software implementations of ECC operations. Under this circumstances, the SM2, a set of public key cryptographic algorithms based on elliptic curves published by Chinese Commercial Cryptography Administration Office, was standardized at ISO in 2017 to enhance the cyber-security. However, few research works on the implementation of SM2 for constrained devices have been conducted. In this work, we fill this gap and propose our efficient, secure, and compact implementation of scalar multiplication on a 256-bit elliptic curve recommended by the SM2, as well as a comparison implementation of scalar multiplication on the same bit-length elliptic curve recommended by NIST. We re-design some existent techniques to fit the low-end IoT platform, namely 8-bit AVR processors, and our implementations evaluated on the desired platform show that the SM2 algorithms have competitive efficiency and security with NIST, which would work well to secure the IoT world.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2937611351",
    "type": "article"
  },
  {
    "title": "High-Level Synthesis of Approximate Designs under Real-Time Constraints",
    "doi": "https://doi.org/10.1145/3358182",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Marcos T. Leipnitz; Gabriel L. Nazar",
    "corresponding_authors": "",
    "abstract": "The adoption of High-Level Synthesis (HLS) has increased as the latest HLS tools have evolved to provide high-quality results while improving productivity and time-to-market. Concurrently, many works have been proposing the incorporation of approximate computing techniques within HLS toolchains, allowing automated generation of inexact circuits for error-tolerant application domains with the aim of trading-off computation accuracy with area/power savings or performance improvements. Thus, when attempting to make a design meet timing requirements, designers of real-time systems using HLS may resort to approximation approaches. However, current approximate HLS tools do not allow specifying real-time constraints, being instead error-constrained to explore area, power, or performance optimizations. In this work, we propose an approximate HLS framework for real-time systems that can be integrated with state-of-the-art HLS tools. With this framework designers can specify real-time constraints and satisfy them while minimizing the output error. It uses scheduling information and Worst-Case Execution Time (WCET) analysis for iteratively exploring time-error trade-offs of approximations in the time-critical execution path. Experimental results on signal and image processing benchmarks show that we can reduce the WCET of exact designs by up to 35% with acceptable quality degradation.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2979792834",
    "type": "article"
  },
  {
    "title": "Design Space Exploration for Ultra-Low-Energy and Secure IoT MCUs",
    "doi": "https://doi.org/10.1145/3384446",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Ehsan Aerabi; Milad Bohlouli; Mohammad Hasan Ahmadi Livany; Mahdi Fazeli; Athanasios Papadimitriou; David Hély",
    "corresponding_authors": "",
    "abstract": "This article explores the design space of secure communication in ultra-low-energy IoT devices based on Micro-Controller Units (MCUs). It tries to identify, benchmark, and compare security-related design choices in a Commercial-Off-The-Shelf (COTS) embedded IoT system which contributes to the energy consumption. We conduct a study over a large group of software crypto algorithms: symmetric, stream, hash, AEAD, MAC, digital signature, and key exchange. A comprehensive report of the targeted optimization attributes (memory, performance, and specifically energy) will be presented from over 450 experiments and 170 different crypto source codes. The article also briefly explores a few system-related choices which can affect the energy consumption of secure communication, namely, architecture choice, communication bandwidth, signal strength, and processor frequency. In the end, the article gives an overview of the obtained results and the contribution of all. Finally, it shows, in a case study, how the results could be utilized to have a secure communication in an exemplary IoT device. This article gives IoT designers insight into ultra-low-energy security, helps them to choose appropriate cryptographic algorithms, reduce trial-and-error of alternatives, save effort, and hence cut the design costs.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3028987799",
    "type": "article"
  },
  {
    "title": "A Design-Time/Run-Time Application Mapping Methodology for Predictable Execution Time in MPSoCs",
    "doi": "https://doi.org/10.1145/3274665",
    "publication_date": "2018-09-30",
    "publication_year": 2018,
    "authors": "Andreas Weichslgartner; Stefan Wildermann; Deepak Gangadharan; Michael Glaß; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "Executing multiple applications on a single MPSoC brings the major challenge of satisfying multiple quality requirements regarding real-time, energy, and so on. Hybrid application mapping denotes the combination of design-time analysis with run-time application mapping. In this article, we present such a methodology, which comprises a design space exploration coupled with a formal performance analysis. This results in several resource reservation configurations, optimized for multiple objectives, with verified real-time guarantees for each individual application. The Pareto-optimal configurations are handed over to run-time management, which searches for a suitable mapping according to this information. To provide any real-time guarantees, the performance analysis needs to be composable and the influence of the applications on each other has to be bounded. We achieve this either by spatial or a novel temporal isolation for tasks and by exploiting composable networks-on-chip (NoCs). With the proposed temporal isolation, tasks of different applications can be mapped to the same resource, while, with spatial isolation, one computing resource can be exclusively used by only one application. The experiments reveal that the success rate in finding feasible application mappings can be increased by the proposed temporal isolation by up to 30% and energy consumption can be reduced compared to spatial isolation.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3124701911",
    "type": "article"
  },
  {
    "title": "Feasibility of Fork-Join Real-Time Task Graph Models",
    "doi": "https://doi.org/10.1145/2809780",
    "publication_date": "2016-02-20",
    "publication_year": 2016,
    "authors": "Jinghao Sun; Nan Guan; Yang Wang; Qingxu Deng; Peng Zeng; Wang Yi",
    "corresponding_authors": "",
    "abstract": "In the formal analysis of real-time systems, modeling of branching codes and modeling of intratask parallelism structures are two of the most important research topics. These two real-time properties are combined, resulting in the fork-join real-time task (FJRT) model, which extends the digraph-based task model with forking and joining semantics. We prove that the EDF schedulability problem on a preemptive uniprocessor for the FJRT model is coNP-hard in the strong sense, even if the utilization of the task system is bounded by a constant strictly less than 1. Then, we show that the problem becomes tractable with some slight structural restrictions on parallel sections, for which we propose an exact schedulability test with pseudo-polynomial time complexity. Our results thus establish a borderline between the tractable and intractable FJRT models.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2302319408",
    "type": "article"
  },
  {
    "title": "A Logic-Based Benders Decomposition Approach for Mapping Applications on Heterogeneous Multicore Platforms",
    "doi": "https://doi.org/10.1145/2838733",
    "publication_date": "2016-02-20",
    "publication_year": 2016,
    "authors": "A. Emeretlis; George Theodoridis; Panayiotis Alefragis; Nikolaos Voros",
    "corresponding_authors": "",
    "abstract": "The development of efficient methods for mapping applications on heterogeneous multicore platforms is a key issue in the field of embedded systems. In this article, a novel approach based on the Logic-Based Benders decomposition principle is introduced for mapping complex applications on these platforms, aiming at optimizing their execution time. To provide optimal solutions for this problem in a short time, a new hybrid model that combines Integer Linear Programming (ILP) and Constraint Programming (CP) models is introduced. Also, to reduce the complexity of the model and its solution time, a set of novel techniques for generating additional constraints called Benders cuts is proposed. An extensive set of experiments has been performed in which synthetic applications described by Directed Acyclic Graphs (DAGs) were mapped to a number of heterogeneous multicore platforms. Moreover, experiments with DAGs that correspond to two real-life applications have also been performed. Based on the experimental results, it is proven that the proposed approach outperforms the pure ILP model in terms of the solution time and quality of the solution. Specifically, the proposed approach is able to find an optimal solution within a time limit of 2 hours in the vast majority of performed experiments, while the pure ILP model fails. Also, for the cases where both methods fail to find an optimal solution within the time limit, the solution of the proposed approach is systematically better than the solution of the ILP model.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2343882994",
    "type": "article"
  },
  {
    "title": "ELSA",
    "doi": "https://doi.org/10.1145/3366634",
    "publication_date": "2020-01-31",
    "publication_year": 2020,
    "authors": "Elham Azari; Sarma Vrudhula",
    "corresponding_authors": "",
    "abstract": "The next significant step in the evolution and proliferation of artificial intelligence technology will be the integration of neural network (NN) models within embedded and mobile systems. This calls for the design of compact, energy efficient NN models in silicon. In this paper, we present a scalable ASIC design of an LSTM accelerator named ELSA, that is suitable for energy-constrained devices. It includes several architectural innovations to achieve small area and high energy efficiency. To reduce the area and power consumption of the overall design, the compute-intensive units of ELSA employ approximate multiplications and still achieve high performance and accuracy. The performance is further improved through efficient synchronization of the elastic pipeline stages to maximize the utilization. The paper also includes a performance model of ELSA, as a function of the hidden nodes and time steps, permitting its use for the evaluation of any LSTM application. ELSA was implemented in RTL and was synthesized and placed and routed in 65nm technology. Its functionality is demonstrated for language modeling-a common application of LSTM. ELSA is compared against a baseline implementation of an LSTM accelerator with standard functional units and without any of the architectural innovations of ELSA. The paper demonstrates that ELSA can achieve significant improvements in power, area and energy-efficiency when compared to the baseline design and several ASIC implementations reported in the literature, making it suitable for use in embedded systems and real-time applications.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3004421177",
    "type": "article"
  },
  {
    "title": "Horizontal Side-Channel Vulnerabilities of Post-Quantum Key Exchange and Encapsulation Protocols",
    "doi": "https://doi.org/10.1145/3476799",
    "publication_date": "2021-10-18",
    "publication_year": 2021,
    "authors": "Furkan Aydın; Aydın Aysu; Mohit Tiwari; Andreas Gerstlauer; Michael Orshansky",
    "corresponding_authors": "",
    "abstract": "Key exchange protocols and key encapsulation mechanisms establish secret keys to communicate digital information confidentially over public channels. Lattice-based cryptography variants of these protocols are promising alternatives given their quantum-cryptanalysis resistance and implementation efficiency. Although lattice cryptosystems can be mathematically secure, their implementations have shown side-channel vulnerabilities. But such attacks largely presume collecting multiple measurements under a fixed key, leaving the more dangerous single-trace attacks unexplored. This article demonstrates successful single-trace power side-channel attacks on lattice-based key exchange and encapsulation protocols. Our attack targets both hardware and software implementations of matrix multiplications used in lattice cryptosystems. The crux of our idea is to apply a horizontal attack that makes hypotheses on several intermediate values within a single execution all relating to the same secret, and to combine their correlations for accurately estimating the secret key. We illustrate that the design of protocols combined with the nature of lattice arithmetic enables our attack. Since a straightforward attack suffers from false positives, we demonstrate a novel extend-and-prune procedure to recover the key by following the sequence of intermediate updates during multiplication. We analyzed two protocols, Frodo and FrodoKEM , and reveal that they are vulnerable to our attack. We implement both stand-alone hardware and RISC-V based software realizations and test the effectiveness of the proposed attack by using concrete parameters of these protocols on physical platforms with real measurements. We show that the proposed attack can estimate secret keys from a single power measurement with over 99% success rate.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3205521370",
    "type": "article"
  },
  {
    "title": "Determinism",
    "doi": "https://doi.org/10.1145/3453652",
    "publication_date": "2021-05-29",
    "publication_year": 2021,
    "authors": "Edward A. Lee",
    "corresponding_authors": "Edward A. Lee",
    "abstract": "This article is about deterministic models, what they are, why they are useful, and what their limitations are. First, the article emphasizes that determinism is a property of models, not of physical systems. Whether a model is deterministic or not depends on how one defines the inputs and behavior of the model. To define behavior, one has to define an observer. The article compares and contrasts two classes of ways to define an observer, one based on the notion of “state” and another that more flexibly defines the observables. The notion of “state” is shown to be problematic and lead to nondeterminism that is avoided when the observables are defined differently. The article examines determinism in models of the physical world. In what may surprise many readers, it shows that Newtonian physics admits nondeterminism and that quantum physics may be interpreted as a deterministic model. Moreover, it shows that both relativity and quantum physics undermine the notion of “state” and therefore require more flexible ways of defining observables. Finally, the article reviews results showing that sufficiently rich sets of deterministic models are incomplete. Specifically, nondeterminism is inescapable in any system of models rich enough to encompass Newton’s laws.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4256027002",
    "type": "article"
  },
  {
    "title": "A Passive Online Technique for Learning Hybrid Automata from Input/Output Traces",
    "doi": "https://doi.org/10.1145/3556543",
    "publication_date": "2022-08-16",
    "publication_year": 2022,
    "authors": "Iman Saberi; Fathiyeh Faghih; Farzad Sobhi Bavil",
    "corresponding_authors": "",
    "abstract": "Specification synthesis is the process of deriving a model from the input-output traces of a system. It is used extensively in test design, reverse engineering, and system identification. One type of the resulting artifact of this process for cyber-physical systems is hybrid automata. They are intuitive, precise, tool independent, and at a high level of abstraction, and can model systems with both discrete and continuous variables. In this article, we propose a new technique for synthesizing hybrid automaton from the input-output traces of a non-linear cyber-physical system. Similarity detection in non-linear behaviors is the main challenge for extracting such models. We address this problem by utilizing the Dynamic Time Warping technique. Our approach is passive, meaning that it does not need interaction with the system during automata synthesis from the logged traces; and online, which means that each input/output trace is used only once in the procedure. In other words, each new trace can be used to improve the already synthesized automaton. We evaluated our algorithm in one industrial and two simulated case studies. The accuracy of the derived automata shows promising results.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3127716161",
    "type": "article"
  },
  {
    "title": "Formally Verified Next-generation Airborne Collision Avoidance Games in ACAS X",
    "doi": "https://doi.org/10.1145/3544970",
    "publication_date": "2022-06-25",
    "publication_year": 2022,
    "authors": "Rachel Cleaveland; Stefan Mitsch; André Platzer",
    "corresponding_authors": "",
    "abstract": "The design of aircraft collision avoidance algorithms is a subtle but important challenge that merits the need for provable safety guarantees. Obtaining such guarantees is nontrivial given the unpredictability of the interplay of the intruder aircraft decisions, the ownship pilot reactions, and the subtlety of the continuous motion dynamics of aircraft. Existing collision avoidance systems, such as TCAS and the Next-Generation Airborne Collision Avoidance System ACAS X, have been analyzed assuming severe restrictions on the intruder's flight maneuvers, limiting their safety guarantees in real-world scenarios where the intruder may change its course. This work takes a conceptually significant and practically relevant departure from existing ACAS X models by generalizing them to hybrid games with first-class representations of the ownship and intruder decisions coming from two independent players, enabling significantly advanced predictive power. By proving the existence of winning strategies for the resulting Adversarial ACAS X in differential game logic, collision-freedom is established for the rich encounters of ownship and intruder aircraft with independent decisions along differential equations for flight paths with evolving vertical/horizontal velocities. We present three classes of models of increasing complexity: single-advisory infinite-time models, bounded time models, and infinite time, multi-advisory models. Within each class of models, we identify symbolic conditions and prove that there then always is a possible ownship maneuver that will prevent a collision between the two aircraft.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3166694670",
    "type": "article"
  },
  {
    "title": "Software Hint-Driven Data Management for Hybrid Memory in Mobile Systems",
    "doi": "https://doi.org/10.1145/3494536",
    "publication_date": "2022-01-14",
    "publication_year": 2022,
    "authors": "Fei Wen; Mian Qin; Paul V. Gratz; Narasimha Reddy",
    "corresponding_authors": "",
    "abstract": "Hybrid memory systems, comprised of emerging non-volatile memory (NVM) and DRAM, have been proposed to address the growing memory demand of current mobile applications. Recently emerging NVM technologies, such as phase-change memories (PCM), memristor, and 3D XPoint, have higher capacity density, minimal static power consumption and lower cost per GB. However, NVM has longer access latency and limited write endurance as opposed to DRAM. The different characteristics of distinct memory classes render a new challenge for memory system design. Ideally, pages should be placed or migrated between the two types of memories according to the data objects’ access properties. Prior system software approaches exploit the program information from OS but at the cost of high software latency incurred by related kernel processes. Hardware approaches can avoid these latencies, however, hardware’s vision is constrained to a short time window of recent memory requests, due to the limited on-chip resources. In this work, we propose OpenMem: a hardware-software cooperative approach that combines the execution time advantages of pure hardware approaches with the data object properties in a global scope. First, we built a hardware-based memory manager unit (HMMU) that can learn the short-term access patterns by online profiling, and execute data migration efficiently. Then, we built a heap memory manager for the heterogeneous memory systems that allows the programmer to directly customize each data object’s allocation to a favorable memory device within the presumed object life cycle. With the programmer’s hints guiding the data placement at allocation time, data objects with similar properties will be congregated to reduce unnecessary page migrations. We implemented the whole system on the FPGA board with embedded ARM processors. In testing under a set of benchmark applications from SPEC 2017 and PARSEC, experimental results show that OpenMem reduces 44.6% energy consumption with only a 16% performance degradation compared to the all-DRAM memory system. The amount of writes to the NVM is reduced by 14% versus the HMMU-only, extending the NVM device lifetime.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4206436066",
    "type": "article"
  },
  {
    "title": "More Is Less: Model Augmentation for Intermittent Deep Inference",
    "doi": "https://doi.org/10.1145/3506732",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Chih-Kai Kang; Hashan Roshantha Mendis; Chun‐Han Lin; Ming-Syan Chen⋆; Pi-Cheng Hsiu",
    "corresponding_authors": "",
    "abstract": "Energy harvesting creates an emerging intermittent computing paradigm but poses new challenges for sophisticated applications such as intermittent deep neural network (DNN) inference. Although model compression has adapted DNNs to resource-constrained devices, under intermittent power, compressed models will still experience multiple power failures during a single inference. Footprint-based approaches enable hardware-accelerated intermittent DNN inference by tracking footprints, independent of model computations, to indicate accelerator progress across power cycles. However, we observe that the extra overhead required to preserve progress indicators can severely offset the computation progress accumulated by intermittent DNN inference. This work proposes the concept of model augmentation to adapt DNNs to intermittent devices. Our middleware stack, JAPARI, appends extra neural network components into a given DNN, to enable the accelerator to intrinsically integrate progress indicators into the inference process, without affecting model accuracy. Their specific positions allow progress indicator preservation to be piggybacked onto output feature preservation to amortize the extra overhead, and their assigned values ensure uniquely distinguishable progress indicators for correct inference recovery upon power resumption. Evaluations on a Texas Instruments device under various DNN models, capacitor sizes, and progress preservation granularities show that JAPARI can speed up intermittent DNN inference by 3× over the state of the art, for common convolutional neural architectures that require heavy acceleration.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4210278476",
    "type": "article"
  },
  {
    "title": "Online Learning for Orchestration of Inference in Multi-user End-edge-cloud Networks",
    "doi": "https://doi.org/10.1145/3520129",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Sina Shahhosseini; Dongjoo Seo; Anil Kanduri; Tianyi Hu; Sung-Soo Lim; Bryan Donyanavard; Amir M. Rahmani; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Deep-learning-based intelligent services have become prevalent in cyber-physical applications, including smart cities and health-care. Deploying deep-learning-based intelligence near the end-user enhances privacy protection, responsiveness, and reliability. Resource-constrained end-devices must be carefully managed to meet the latency and energy requirements of computationally intensive deep learning services. Collaborative end-edge-cloud computing for deep learning provides a range of performance and efficiency that can address application requirements through computation offloading. The decision to offload computation is a communication-computation co-optimization problem that varies with both system parameters (e.g., network condition) and workload characteristics (e.g., inputs). However, deep learning model optimization provides another source of tradeoff between latency and model accuracy. An end-to-end decision-making solution that considers such computation-communication problem is required to synergistically find the optimal offloading policy and model for deep learning services. To this end, we propose a reinforcement-learning-based computation offloading solution that learns optimal offloading policy considering deep learning model selection techniques to minimize response time while providing sufficient accuracy. We demonstrate the effectiveness of our solution for edge devices in an end-edge-cloud system and evaluate with a real-setup implementation using multiple AWS and ARM core configurations. Our solution provides 35% speedup in the average response time compared to the state-of-the-art with less than 0.9% accuracy reduction, demonstrating the promise of our online learning framework for orchestrating DL inference in end-edge-cloud systems.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4214921909",
    "type": "article"
  },
  {
    "title": "Design-Technology Co-Optimization for NVM-Based Neuromorphic Processing Elements",
    "doi": "https://doi.org/10.1145/3524068",
    "publication_date": "2022-03-21",
    "publication_year": 2022,
    "authors": "Shihao Song; Adarsha Balaji; Anup Das; Nagarajan Kandasamy",
    "corresponding_authors": "",
    "abstract": "An emerging use case of machine learning (ML) is to train a model on a high-performance system and deploy the trained model on energy-constrained embedded systems. Neuromorphic hardware platforms, which operate on principles of the biological brain, can significantly lower the energy overhead of an ML inference task, making these platforms an attractive solution for embedded ML systems. We present a design-technology tradeoff analysis to implement such inference tasks on the processing elements (PEs) of a non-volatile memory (NVM)-based neuromorphic hardware. Through detailed circuit-level simulations at scaled process technology nodes, we show the negative impact of technology scaling on the information-processing latency, which impacts the quality of service of an embedded ML system. At a finer granularity, the latency inside a PE depends on (1) the delay introduced by parasitic components on its current paths, and (2) the varying delay to sense different resistance states of its NVM cells. Based on these two observations, we make the following three contributions. First, on the technology front, we propose an optimization scheme where the NVM resistance state that takes the longest time to sense is set on current paths having the least delay, and vice versa, reducing the average PE latency, which improves the quality of service. Second, on the architecture front, we introduce isolation transistors within each PE to partition it into regions that can be individually power-gated, reducing both latency and energy. Finally, on the system-software front, we propose a mechanism to leverage the proposed technological and architectural enhancements when implementing an ML inference task on neuromorphic PEs of the hardware. Evaluations with a recent neuromorphic hardware architecture show that our proposed design-technology co-optimization approach improves both performance and energy efficiency of ML inference tasks without incurring high cost-per-bit.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4221145728",
    "type": "article"
  },
  {
    "title": "Application-centric Network Management - Addressing Safety and Real-time in V2X Applications",
    "doi": "https://doi.org/10.1145/3528411",
    "publication_date": "2022-04-30",
    "publication_year": 2022,
    "authors": "Rolf Ernst; Dominik Stöhrmann; Alex Bendrick; Adam Kostrzewa",
    "corresponding_authors": "",
    "abstract": "The current roadmaps and surveys for future wireless networking typically focus on communication and networking technologies and use representative applications to derive future network requirements. Such a benchmarking approach, however, does not cover the application integration challenge that arises from the many distributed applications sharing a network infrastructure, each with their individual topology and data structure. The paper addresses V2X networks as an important example. Crucial end-to-end application constraints including real-time and safety encourage a closer look at application interference and systematic integration. This perspective paper proposes a two-layer resource management that divides the problem into an application integration and a network management task. Valet parking with high-resolution infrastructure camera support is elaborated as a use case that overarches vehicle network and wireless network management. Experiments demonstrate the benefits of complementing the current network-centric management by an application-centric integration.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4225140359",
    "type": "article"
  },
  {
    "title": "Quantized Sparse Training: A Unified Trainable Framework for Joint Pruning and Quantization in DNNs",
    "doi": "https://doi.org/10.1145/3524066",
    "publication_date": "2022-07-15",
    "publication_year": 2022,
    "authors": "Jun-Hyung Park; Kang-Min Kim; SangKeun Lee",
    "corresponding_authors": "",
    "abstract": "Deep neural networks typically have extensive parameters and computational operations. Pruning and quantization techniques have been widely used to reduce the complexity of deep models. Both techniques can be jointly used for realizing significantly higher compression ratios. However, separate optimization processes and difficulties in choosing the hyperparameters limit the application of both the techniques simultaneously. In this study, we propose a novel compression framework, termed as quantized sparse training, that prunes and quantizes networks jointly in a unified training process. We integrate pruning and quantization into a gradient-based optimization process based on the straight-through estimator. Quantized sparse training enables us to simultaneously train, prune, and quantize a network from scratch. The empirical results validate the superiority of the proposed methodology over the recent state-of-the-art baselines with respect to both the model size and accuracy. Specifically, quantized sparse training achieves a 135 KB model size in the case of VGG16, without any accuracy degradation, which is 40% of the model size feasible based on the state-of-the-art pruning and quantization approach.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4285590283",
    "type": "article"
  },
  {
    "title": "Survey of Control-flow Integrity Techniques for Real-time Embedded Systems",
    "doi": "https://doi.org/10.1145/3538275",
    "publication_date": "2022-07-18",
    "publication_year": 2022,
    "authors": "Tanmaya Mishra; Thidapat Chantem; Ryan Gerdes",
    "corresponding_authors": "",
    "abstract": "Computing systems, including real-time embedded systems, are becoming increasingly connected to allow for more advanced and safer operation. Such embedded systems are resource-constrained, such as lower processing capabilities, as compared to general purpose computing systems like desktops or servers. However, allowing external interfaces to such embedded systems increases their exposure to attackers. With an increase in attacks against embedded systems ranging from home appliances to industrial control systems operating critical equipment that have hard real-time requirements, it is imperative that defense mechanisms be created that explicitly consider such resource and real-time constraints constraints. Control-flow integrity (CFI) is a family of defense mechanisms that prevent attackers from modifying the flow of execution. We survey CFI techniques, ranging from the basic to state-of-the-art, that are built for embedded systems and real-time embedded systems and find that there is a dearth, especially for real-time embedded systems, of CFI mechanisms. We then present open challenges to the community to help drive research in this domain.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4285728596",
    "type": "article"
  },
  {
    "title": "CODEBench: A Neural Architecture and Hardware Accelerator Co-Design Framework",
    "doi": "https://doi.org/10.1145/3575798",
    "publication_date": "2022-12-08",
    "publication_year": 2022,
    "authors": "Shikhar Tuli; Chia‐Hao Li; Ritvik Sharma; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Recently, automated co-design of machine learning (ML) models and accelerator architectures has attracted significant attention from both the industry and academia. However, most co-design frameworks either explore a limited search space or employ suboptimal exploration techniques for simultaneous design decision investigations of the ML model and the accelerator. Furthermore, training the ML model and simulating the accelerator performance is computationally expensive. To address these limitations, this work proposes a novel neural architecture and hardware accelerator co-design framework, called CODEBench. It is composed of two new benchmarking sub-frameworks, CNNBench and AccelBench, which explore expanded design spaces of convolutional neural networks (CNNs) and CNN accelerators. CNNBench leverages an advanced search technique, BOSHNAS, to efficiently train a neural heteroscedastic surrogate model to converge to an optimal CNN architecture by employing second-order gradients. AccelBench performs cycle-accurate simulations for a diverse set of accelerator architectures in a vast design space. With the proposed co-design method, called BOSHCODE, our best CNN-accelerator pair achieves 1.4% higher accuracy on the CIFAR-10 dataset compared to the state-of-the-art pair, while enabling 59.1% lower latency and 60.8% lower energy consumption. On the ImageNet dataset, it achieves 3.7% higher Top1 accuracy at 43.8% lower latency and 11.2% lower energy consumption. CODEBench outperforms the state-of-the-art framework, i.e., Auto-NBA, by achieving 1.5% higher accuracy and 34.7x higher throughput, while enabling 11.0x lower energy-delay product (EDP) and 4.0x lower chip area on CIFAR-10.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4310997605",
    "type": "article"
  },
  {
    "title": "TinyM <sup>2</sup> Net-V2: A Compact Low Power Software Hardware Architecture for <u>M</u> ulti <u>m</u> odal Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3595633",
    "publication_date": "2023-05-03",
    "publication_year": 2023,
    "authors": "Hasib-Al Rashid; Utteja Kallakuri; Tinoosh Mohsenin",
    "corresponding_authors": "",
    "abstract": "With the evaluation of Artificial Intelligence (AI), there has been a resurgence of interest in how to use AI algorithms on low-power embedded systems to broaden potential use cases of the Internet of Things (IoT). To mimic multimodal human perception, multimodal deep neural networks (M-DNN) have recently become very popular with the classification task due to their impressive performance for computer vision and audio processing tasks. This article presents TinyM 2 Net-V2 —a compact low-power software hardware architecture for m ulti m odal deep neural networks for resource-constrained tiny devices. To compress the models to implement on tiny devices, cyclicly sparsification and hybrid quantization (4-bits weights and 8-bits activations) methods are used. Although model compression techniques are an active research area, we are the first to demonstrate their efficacy for multimodal deep neural networks, using cyclicly sparsification and hybrid quantization of weights/activations. TinyM 2 Net-V2 shows that even a tiny multimodal deep neural network model can improve the classification accuracy more than that of any unimodal counterparts. Parameterized M-DNN model architecture was designed to be evaluated in two different case-studies: vehicle detection from multimodal images and audios and COVID-19 detection from multimodal audio recordings. The most compressed TinyM 2 Net-V2 achieves 92.5% COVID-19 detection accuracy (6.8% improvement from the unimodal full precision model) and 90.6% vehicle classification accuracy (7.7% improvement from the unimodal full precision model). A parameterized and flexible FPGA hardware accelerator was designed as well for TinyM 2 Net-V2 models. To the best of our knowledge, this is the first work accelerating multimodal deep neural network models on low-power Artix-7 FPGA hardware. We achieved energy efficiency of 9.04 GOP/s/W and 15.38 GOP/s/W for case-study 1 and case-study 2, respectively, which is comparable to the state-of-the-art results. Finally, we compared our tiny FPGA hardware implementation results with off-the-shelf resource-constrained devices and showed our implementation is faster and consumed less power compared to the off-the-shelf resource-constrained devices.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4367848206",
    "type": "article"
  },
  {
    "title": "XimSwap: many-to-many face swapping for TinyML",
    "doi": "https://doi.org/10.1145/3603173",
    "publication_date": "2023-06-01",
    "publication_year": 2023,
    "authors": "Alberto Ancilotto; Francesco Paissan; Elisabetta Farella",
    "corresponding_authors": "",
    "abstract": "The unprecedented development of deep learning approaches for video processing has caused growing privacy concerns. To ensure data analysis while maintaining privacy, it is essential to address how to protect individuals’ identities. One solution is to anonymize data at the source, avoiding the transmission or storage of information that could lead to identification. This study introduces XimSwap, a novel deep learning technique for real-time video anonymization, which can remove facial identification features directly on edge devices with minimal computational resources. Our approach offers a comprehensive solution that guarantees privacy by design. This novel method for implementing face-swapping ensures that the pose and expression of a target face remain unchanged and can be used on embedded devices with very limited computational resources. By incorporating style transfer layers into convolutional ones and optimizing the network’s operation, we achieved a reduction of over 98% in the required operations and parameters compared with state-of-the-art architectures. Our approach also significantly reduces RAM usage, making it possible to implement the anonymization process on tiny edge devices, including microcontrollers, such as the STM32H743.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4379014908",
    "type": "article"
  },
  {
    "title": "Faster Implementation of Ideal Lattice-Based Cryptography Using AVX512",
    "doi": "https://doi.org/10.1145/3609223",
    "publication_date": "2023-07-14",
    "publication_year": 2023,
    "authors": "Douwei Lei; Debiao He; Cong Peng; Min Luo; Zhe Liu; Xinyi Huang",
    "corresponding_authors": "",
    "abstract": "With the development of quantum computing, the existing cryptography schemes based on classical cryptographic primitives will no longer be secure. Hence, cryptographers are designing post-quantum cryptographic (PQC) schemes, and ideal lattice-based cryptography has emerged as a prime candidate. Today, as ideal lattice-based cryptography becomes more mature, its performance becomes an important optimization goal. In ideal lattice-based cryptography, polynomial arithmetic and polynomial sampling are the most time-consuming operations and therefore need to be accelerated. In this article, taking advantage of the parallelism of new 512-bit advanced vector instructions (AVX512), we present parallel implementations of polynomial arithmetic and polynomial sampling, thus comprehensively improving their performance. We conduct experiments with the Dilithium scheme(one scheme of NIST PQC Standardization Process Round-4). Our implementation gets a nice performance boost compared to its pure C language and 256-bit advanced vector instructions (AVX2) implementation.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4384339345",
    "type": "article"
  },
  {
    "title": "Towards Building Verifiable CPS using Lingua Franca",
    "doi": "https://doi.org/10.1145/3609134",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Shaokai Lin; Yatin A. Manerkar; Marten Lohstroh; Elizabeth Polgreen; Sheng-Jung Yu; Chadlia Jerad; Edward A. Lee; Sanjit A. Seshia",
    "corresponding_authors": "",
    "abstract": "Formal verification of cyber-physical systems (CPS) is challenging because it has to consider real-time and concurrency aspects that are often absent in ordinary software. Moreover, the software in CPS is often complex and low-level, making it hard to assure that a formal model of the system used for verification is a faithful representation of the actual implementation, which can undermine the value of a verification result. To address this problem, we propose a methodology for building verifiable CPS based on the principle that a formal model of the software can be derived automatically from its implementation. Our approach requires that the system implementation is specified in Lingua Franca (LF), a polyglot coordination language tailored for real-time, concurrent CPS, which we made amenable to the specification of safety properties via annotations in the code. The program structure and the deterministic semantics of LF enable automatic construction of formal axiomatic models directly from LF programs. The generated models are automatically checked using Bounded Model Checking (BMC) by the verification engine Uclid5 using the Z3 SMT solver. The proposed technique enables checking a well-defined fragment of Safety Metric Temporal Logic (Safety MTL) formulas. To ensure the completeness of BMC, we present a method to derive an upper bound on the completeness threshold of an axiomatic model based on the semantics of LF. We implement our approach in the LF V erifier and evaluate it using a benchmark suite with 22 programs sampled from real-life applications and benchmarks for Erlang, Lustre, actor-oriented languages, and RTOSes. The LF V erifier correctly checks 21 out of 22 programs automatically.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4386568752",
    "type": "article"
  },
  {
    "title": "BitSET: Bit-Serial Early Termination for Computation Reduction in Convolutional Neural Networks",
    "doi": "https://doi.org/10.1145/3609093",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Yunjie Pan; Jiecao Yu; Andrew Lukefahr; Reetuparna Das; Scott Mahlke",
    "corresponding_authors": "",
    "abstract": "Convolutional Neural Networks (CNNs) have demonstrated remarkable performance across a wide range of machine learning tasks. However, the high accuracy usually comes at the cost of substantial computation and energy consumption, making it difficult to be deployed on mobile and embedded devices. In CNNs, the compute-intensive convolutional layers are usually followed by a ReLU activation layer, which clamps negative outputs to zeros, resulting in large activation sparsity. By exploiting such sparsity in CNN models, we propose a software-hardware co-design BitSET, that aggressively saves energy during CNN inference. The bit-serial BitSET accelerator adopts a prediction-based bit-level early termination technique that terminates the ineffectual computation of negative outputs early. To assist the algorithm, we propose a novel weight encoding that allows more accurate predictions with fewer bits. BitSET leverages the bit-level computation reduction both in the predictive early termination algorithm and in the non-predictive, energy-efficient bit-serial architecture. Compared to UNPU, an energy-efficient bit-serial CNN accelerator, BitSET yields an average 1.5× speedup and 1.4× energy efficiency improvement with no accuracy loss due to a 48% reduction in bit-level computations. Relaxing the allowed accuracy loss to 1% increases the gains to an average of 1.6× speedup and 1.4× energy efficiency improvement.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4386568792",
    "type": "article"
  },
  {
    "title": "<scp>Hephaestus</scp> : Codesigning and Automating 3D Image Registration on Reconfigurable Architectures",
    "doi": "https://doi.org/10.1145/3607928",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Giuseppe Sorrentino; M. Vénere; Davide Conficconi; Eleonora D’Arnese; Marco D. Santambrogio",
    "corresponding_authors": "",
    "abstract": "Healthcare is a pivotal research field, and medical imaging is crucial in many applications. Therefore finding new architectural and algorithmic solutions would benefit highly repetitive image processing procedures. One of the most complex tasks in this sense is image registration, which finds the optimal geometric alignment among 3D image stacks and is widely employed in healthcare and robotics. Given the high computational demand of such a procedure, hardware accelerators are promising real-time and energy-efficient solutions, but they are complex to design and integrate within software pipelines. Therefore, this work presents an automation framework called Hephaestus that generates efficient 3D image registration pipelines combined with reconfigurable accelerators. Moreover, to alleviate the burden from the software, we codesign software-programmable accelerators that can adapt at run-time to the image volume dimensions. Hephaestus features a cross-platform abstraction layer that enables transparently high-performance and embedded systems deployment. However, given the computational complexity of 3D image registration, the embedded devices become a relevant and complex setting being constrained in memory; thus, they require further attention and tailoring of the accelerators and registration application to reach satisfactory results. Therefore, with Hephaestus , we also propose an approximation mechanism that enables such devices to perform the 3D image registration and even achieve, in some cases, the accuracy of the high-performance ones. Overall, Hephaestus demonstrates 1.85× of maximum speedup, 2.35× of efficiency improvement with respect to the State of the Art, a maximum speedup of 2.51× and 2.76× efficiency improvements against our software, while attaining state-of-the-art accuracy on 3D registrations.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4386569012",
    "type": "article"
  },
  {
    "title": "TEFLON: Thermally Efficient Dataflow-Aware 3D NoC for Accelerating CNN Inferencing on Manycore PIM Architectures",
    "doi": "https://doi.org/10.1145/3665279",
    "publication_date": "2024-08-14",
    "publication_year": 2024,
    "authors": "Gaurav Narang; Chukwufumnanya Ogbogu; Janardhan Rao Doppa; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Resistive random-access memory (ReRAM)-based processing-in-memory (PIM) architectures are used extensively to accelerate inferencing/training with convolutional neural networks (CNNs). Three-dimensional (3D) integration is an enabling technology to integrate many PIM cores on a single chip. In this work, we propose the design of a t hermally e fficient data flo w-aware monolithic 3D (M3D) N oC architecture referred to as TEFLON to accelerate CNN inferencing without creating any thermal bottlenecks. TEFLON reduces the Energy-Delay-Product (EDP) by 42%, 46%, and 45% on an average compared to a conventional 3D mesh NoC for systems with 36-, 64-, and 100-PIM cores, respectively. TEFLON reduces the peak chip temperature by 25 K and improves the inference accuracy by up to 11% compared to sole performance-optimized SFC-based counterpart for inferencing with diverse deep CNN models using CIFAR-10/100 datasets on a 3D system with 100-PIM cores.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4396956635",
    "type": "article"
  },
  {
    "title": "Revealing CNN Architectures via Side-Channel Analysis in Dataflow-based Inference Accelerators",
    "doi": "https://doi.org/10.1145/3688001",
    "publication_date": "2024-08-12",
    "publication_year": 2024,
    "authors": "Hansika Weerasena; Prabhat Mishra",
    "corresponding_authors": "",
    "abstract": "Convolutional Neural Networks (CNNs) are widely used in various domains, including image recognition, medical diagnosis and autonomous driving. Recent advances in dataflow-based CNN accelerators have enabled CNN inference in resource-constrained edge devices. These dataflow accelerators utilize inherent data reuse of convolution layers to process CNN models efficiently. Concealing the architecture of CNN models is critical for privacy and security. This article evaluates memory-based side-channel information to recover CNN architectures from dataflow-based CNN inference accelerators. The proposed attack exploits spatial and temporal data reuse of the dataflow mapping on CNN accelerators and architectural hints to recover the structure of CNN models. Experimental results demonstrate that our proposed side-channel attack can recover the structures of popular CNN models, namely, Lenet, Alexnet, VGGnet16, and YOLOv2.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4401517314",
    "type": "article"
  },
  {
    "title": "Partitioned instruction cache architecture for energy efficiency",
    "doi": "https://doi.org/10.1145/643470.643473",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Soontae Kim; N. Vijaykrishnan; Mahmut Kandemir; Anand Sivasubramaniam; M.J. Irwin",
    "corresponding_authors": "",
    "abstract": "The demand for high-performance architectures and powerful battery-operated mobile devices has accentuated the need for low-power systems. In many media and embedded applications, the memory system can consume more than 50% of the overall system energy, making it a ripe candidate for optimization. To address this increasingly important problem, this article studies energy-efficient cache architectures in the memory hierarchy that can have a significant impact on the overall system energy consumption.Existing cache optimization approaches have looked at partitioning the caches at the circuit level and enabling/disabling these cache partitions (subbanks) at the architectural level for both performance and energy. In contrast, this article focuses on partitioning the cache resources architecturally for energy and energy-delay optimizations. Specifically, we investigate ways of splitting the cache into several smaller units, each of which is a cache by itself (called a subcache ). Subcache architectures not only reduce the per-access energy costs, but can potentially improve the locality behavior as well.The proposed subcache architecture employs a page-based placement strategy, a dynamic page remapping policy, and a subcache prediction policy in order to improve the memory system energy behavior, especially on-chip cache energy. Using applications from the SPECjvm98 and SPEC CPU2000 benchmarks, the proposed subcache architecture is shown to be very effective in improving both the energy and energy-delay metrics. It is more beneficial in larger caches as well.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W1990306341",
    "type": "article"
  },
  {
    "title": "Tiny instruction caches for low power embedded systems",
    "doi": "https://doi.org/10.1145/950162.950163",
    "publication_date": "2003-11-01",
    "publication_year": 2003,
    "authors": "Ross Gordon; Susan Cotterell; Frank Vahid",
    "corresponding_authors": "",
    "abstract": "Instruction caches have traditionally been used to improve software performance. Recently, several tiny instruction cache designs, including filter caches and dynamic loop caches, have been proposed to instead reduce software power. We propose several new tiny instruction cache designs, including preloaded loop caches, and one-level and two-level hybrid dynamic/preloaded loop caches. We evaluate the existing and proposed designs on embedded system software benchmarks from both the Powerstone and MediaBench suites, on two different processor architectures, for a variety of different technologies. We show on average that filter caching achieves the best instruction fetch energy reductions of 60--80%, but at the cost of about 20% performance degradation, which could also affect overall energy savings. We show that dynamic loop caching gives good instruction fetch energy savings of about 30%, but that if a designer is able to profile a program, preloaded loop caching can more than double the savings. We describe automated methods for quickly determining the best loop cache configuration, methods useful in a core-based design flow.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2022525681",
    "type": "article"
  },
  {
    "title": "Data space-oriented tiling for enhancing locality",
    "doi": "https://doi.org/10.1145/1067915.1067922",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "I. Kadayif; Mahmut Kandemir",
    "corresponding_authors": "",
    "abstract": "Improving locality of data references is becoming increasingly important due to increasing gap between processor cycle times and off-chip memory access latencies. Improving data locality not only improves effective memory access time but also reduces memory system energy consumption due to data references. An optimizing compiler can play an important role in enhancing data locality in array-intensive embedded media applications with regular data access patterns.This paper presents a compiler-based data space-oriented tiling approach (DST). In this strategy, the data space (e.g., an array of signals) is logically divided into chunks (called data tiles) and each data tile is processed in turn. In processing a data tile, our approach traverses the entire iteration space of all nests in the code and executes all iterations (potentially coming from different nests) that access the data tile being processed. In doing so, it also takes data dependences into account. Since a data space is common across all nests that access it, DST can potentially achieve better results than traditional iteration space (loop) tiling by exploiting internest data locality.We also present an example application of DST for improving the effectiveness of a scratch pad memory (SPM) for data accesses. SPMs are alternatives to conventional cache memories in embedded computing world. These small on-chip memories, like caches, provide fast and low-power access to data; but, they differ from conventional data caches in that their contents are managed by compiler instead of hardware. We have implemented DST in a source-to-source translator and quantified its benefits using a simulator. Our preliminary results with several array-intensive applications and varying input sizes show that our approach outperforms classical iteration space-oriented tiling as well as a data-oriented approach that considers each nest in isolation.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2046164356",
    "type": "article"
  },
  {
    "title": "Modeling and optimizing run-time reconfiguration using evolutionary computation",
    "doi": "https://doi.org/10.1145/1027794.1027795",
    "publication_date": "2004-11-01",
    "publication_year": 2004,
    "authors": "Jim Harkin; T.M. McGinnity; Liam Maguire",
    "corresponding_authors": "",
    "abstract": "The hardware--software (HW--SW) partitioning of applications to dynamically reconfigurable embedded systems allows for customization of their hardware resources during run-time to meet the demands of executing applications. The run-time reconfiguration (RTR) of such systems can have an impact on the HW--SW partitioning strategy and the system performance. It is therefore important to consider approaches to optimally reduce the RTR overhead during the HW--SW partitioning stage. In order to examine potential benefits in performance, it is necessary to develop a method to model and evaluate the RTR. In this paper, a novel method of modeling and evaluating such RTR-reduced HW--SW partitions is presented. The techniques of computation-reconfiguration overlap and the retention of circuitry between reconfigurations are used within this model to explore the possibilities of RTR reduction. The integration of this model into the authors' current genetic-algorithm-driven HW--SW partitioner is also presented, with two applications used to illustrate the benefits of RTR-reduced exploration during HW--SW partitioning.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W1987412466",
    "type": "article"
  },
  {
    "title": "Towards fault-tolerant cryptographic computations over finite fields",
    "doi": "https://doi.org/10.1145/1015047.1015054",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "Arash Reyhani-Masoleh; M.A. Hasan",
    "corresponding_authors": "",
    "abstract": "Cryptographic schemes, such as authentication, confidentiality, and integrity, rely on computations in very large finite fields, whose hardware realization may require millions of logic gates. In a straightforward design, even a single fault in such a complex circuit is likely to yield an incorrect result and may be exploited by an attacker to break the cryptosystem. In this regard, we consider computing over finite fields in presence of certain faults in multiplier circuits. Our work reported here deals with errors caused by such faults in polynomial basis multipliers over finite fields of characteristic two and presents a scheme to correct single errors. Towards this, pertinent theoretical results are derived, and both bit-parallel and bit-serial fault tolerant multipliers are proposed.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2080481349",
    "type": "article"
  },
  {
    "title": "Automatic rate desynchronization of embedded reactive programs",
    "doi": "https://doi.org/10.1145/1165780.1165786",
    "publication_date": "2006-08-01",
    "publication_year": 2006,
    "authors": "Alain Girault; Xavier Nicollin; Marc Pouzet",
    "corresponding_authors": "",
    "abstract": "Many embedded reactive programs perform computations at different rates, while still requiring the overall application to satisfy very tight temporal constraints. We propose a method to automatically distribute programs such that the obtained parts can be run at different rates, which we call rate desynchronization . We consider general programs whose control structure is a finite state automaton and with a DAG of actions in each state. The motivation is to take into account long-duration tasks inside the programs: these are tasks whose execution time is long compared to the other computations in the application, and whose maximal execution rate is known and bounded. Merely scheduling such a long duration task at a slow rate would not work since the whole program would be slowed down if compiled into sequential code. It would thus be impossible to meet the temporal constraints, unless such long duration tasks could be desynchronized from the remaining computations. This is precisely what our method achieves: it distributes the initial program into several parts, so that the parts performing the slow computations can be run at an appropriate rate, therefore not impairing the global reaction time of the program. We present in detail our method, all the involved algorithms, and a small running example. We also compare our method with the related work.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W1965516968",
    "type": "article"
  },
  {
    "title": "Collaborative operating system and compiler power management for real-time applications",
    "doi": "https://doi.org/10.1145/1132357.1132361",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "Nevine AbouGhazaleh; Daniel Mossé; Bruce R. Childers; Rami Melhem",
    "corresponding_authors": "",
    "abstract": "Managing energy consumption has become vitally important to battery-operated portable and embedded systems. Dynamic voltage scaling (DVS) reduces the processor's dynamic power consumption quadratically at the expense of linearly decreasing the performance. When reducing energy with DVS for real-time systems, one must consider the performance penalty to ensure that deadlines can be met. In this paper, we introduce a novel collaborative approach between the compiler and the operating system (OS) to reduce energy consumption. We use the compiler to annotate an application's source code with path-dependent information called power-management hints (PMHs). This fine-grained information captures the temporal behavior of the application, which varies by executing different paths. During program execution, the OS periodically changes the processor's frequency and voltage based on the temporal information provided by the PMHs. These speed adaptation points are called power-management points (PMPs). We evaluate our scheme using three embedded applications: a video decoder, automatic target recognition, and a sub-band tuner. Our scheme shows an energy reduction of up to 57% over no power-management and up to 32% over a static power-management scheme. We compare our scheme to other schemes that solely utilize PMPs for power-management and show experimentally that our scheme achieves more energy savings. We also analyze the advantages and disadvantages of our approach relative to another compiler-directed scheme.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2006223455",
    "type": "article"
  },
  {
    "title": "Automated reduction of the memory footprint of the Linux kernel",
    "doi": "https://doi.org/10.1145/1274858.1274861",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Dominique Chanet; Bjorn De Sutter; Bruno De Bus; Ludo Van Put; Koen De Bosschere",
    "corresponding_authors": "",
    "abstract": "The limited built-in configurability of Linux can lead to expensive code size overhead when it is used in the embedded market. To overcome this problem, we propose the application of link-time compaction and specialization techniques that exploit the a priori known, fixed runtime environment of many embedded systems. In experimental setups based on the ARM XScale and i386 platforms, the proposed techniques are able to reduce the kernel memory footprint with over 16%. We also show how relatively simple additions to existing binary rewriters can implement the proposed techniques for a complex, very unconventional program, such as the Linux kernel. We note that even after specialization, a lot of seemingly unnecessary code remains in the kernel and propose to reduce the footprint of this code by applying code-compression techniques. This technique, combined with the previous ones, reduces the memory footprint with over 23% for the i386 platform and 28% for the ARM platform. Finally, we pinpoint an important code size growth problem when compaction and compression techniques are combined on the ARM platform.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2062227764",
    "type": "article"
  },
  {
    "title": "A stochastic bitwidth estimation technique for compact and low-power custom processors",
    "doi": "https://doi.org/10.1145/1347375.1347387",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Emre Özer; Andy Nisbet; David Gregg",
    "corresponding_authors": "",
    "abstract": "There is an increasing trend toward compiling from C to custom hardware for designing embedded systems in which the area and power consumption of application-specific functional units, registers, and memory blocks are heavily dependent on the bit-widths of integer operands used in computations. The actual bit-width required to store the values assigned to an integer variable during the execution of a program will not, in general, match the built-in C data types. Thus, precious area is wasted if the built-in data type sizes are used to declare the size of integer operands. In this paper, we introduce stochastic bit-width estimation that follows a simulation-based probabilistic approach to estimate the bit-widths of integer variables using extreme value theory. The estimation technique is also empirically compared to two compile-time integer bit-width analysis techniques. Our experimental results show that the stochastic bit-width estimation technique dramatically reduces integer bit-widths and, therefore, enables more compact and power-efficient custom hardware designs than the compile-time integer bit-width analysis techniques. Up to 37% reduction in custom hardware area and 30% reduction in logic power consumption using stochastic bit-width estimation can be attained over ten integer applications implemented on an FPGA chip.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2004464838",
    "type": "article"
  },
  {
    "title": "Managing embedded systems complexity with aspect-oriented model-driven engineering",
    "doi": "https://doi.org/10.1145/1880050.1880057",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Cormac Driver; Sean Reilly; Éamonn Linehan; Vinny Cahill; Siobhàn Clarke",
    "corresponding_authors": "",
    "abstract": "Model-driven engineering addresses issues of platform heterogeneity and code quality through the use of high-level system models and subsequent automatic transformations. Adoption of the model-driven software engineering paradigm for embedded systems necessitates specification of appropriate models of often complex systems. Modern embedded systems are typically composed of multiple functional and nonfunctional concerns, with the nonfunctional concerns (e.g., timing and performance) typically affecting the design and implementation of the functional concerns. The presence of crosscutting concerns makes specification of adequate platform-independent models a significant challenge. Aspect-oriented software development is a separation of concerns technique that decomposes systems into distinct features with minimal overlap. In this article, we illustrate how Theme/UML, an aspect-oriented modeling approach, can be used to separate embedded systems concerns and reduce complexity in design. We also present Model-Driven Theme/UML, a toolset for model-driven engineering of embedded systems that supports modularised design with Theme/UML and automatic transformations to composed models and source code.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2078532846",
    "type": "article"
  },
  {
    "title": "Providing DoS resistance for signature-based broadcast authentication in sensor networks",
    "doi": "https://doi.org/10.1145/2442116.2442123",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Qi Dong; Donggang Liu; Peng Ning",
    "corresponding_authors": "",
    "abstract": "Recent studies have demonstrated that it is feasible to perform public key cryptographic operations on resource-constrained sensor platforms. However, the significant energy consumption introduced by public key operations makes any public key-based protocol an easy target of Denial-of-Service (DoS) attacks. For example, if digital signature schemes such as ECDSA are used directly for broadcast authentication without further protection, an attacker can simply broadcast fake messages and force the receiving nodes to perform a huge number of unnecessary signature verifications, eventually exhausting their battery power. This paper shows how to mitigate such DoS attacks when digital signatures are used for broadcast authentication in sensor networks. Specifically, this paper first presents two filtering techniques, the group-based filter and the key chain-based filter , to handle the DoS attacks against signature verification. Both methods can significantly reduce the number of unnecessary signature verifications when a sensor node is under DoS attacks. This paper then combines these two filters and proposes a hybrid solution to further improve the performance.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2050452690",
    "type": "article"
  },
  {
    "title": "Configurable memory security in embedded systems",
    "doi": "https://doi.org/10.1145/2442116.2442121",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Jérémie Crenne; Romain Vaslin; Guy Gogniat; Jean-Philippe Diguet; Russell Tessier; Deepak Unnikrishnan",
    "corresponding_authors": "",
    "abstract": "System security is an increasingly important design criterion for many embedded systems. These systems are often portable and more easily attacked than traditional desktop and server computing systems. Key requirements for system security include defenses against physical attacks and lightweight support in terms of area and power consumption. Our new approach to embedded system security focuses on the protection of application loading and secure application execution. During secure application loading, an encrypted application is transferred from on-board flash memory to external double data rate synchronous dynamic random access memory (DDR-SDRAM) via a microprocessor. Following application loading, the core-based security technique provides both confidentiality and authentication for data stored in a microprocessor's system memory. The benefits of our low overhead memory protection approaches are demonstrated using four applications implemented in a field-programmable gate array (FPGA) in an embedded system prototyping platform. Each application requires a collection of tasks with varying memory security requirements. The configurable security core implemented on-chip inside the FPGA with the microprocessor allows for different memory security policies for different application tasks. An average memory saving of 63% is achieved for the four applications versus a uniform security approach. The lightweight circuitry included to support application loading from flash memory adds about 10% FPGA area overhead to the processor-based system and main memory security hardware.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2070693795",
    "type": "article"
  },
  {
    "title": "Robust architectures for embedded wireless network control and actuation",
    "doi": "https://doi.org/10.1145/2362336.2362349",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Miroslav Pajić; Alexander Chernoguzov; Rahul Mangharam",
    "corresponding_authors": "",
    "abstract": "Networked cyber-physical systems are fundamentally constrained by the tight coupling and closed-loop control of physical processes. To address actuation in such closed-loop wireless control systems there is a strong need to rethink the communication architectures and protocols for reliability, coordination, and control. We introduce the Embedded Virtual Machine (EVM), a programming abstraction where controller tasks with their control and timing properties are maintained across physical node boundaries and functionality is capable of migrating to the most competent set of physical controllers. In the context of process and discrete control, an EVM is the distributed runtime system that dynamically selects primary-backup sets of controllers given spatial and temporal constraints of the underlying wireless network. EVM-based algorithms allow network control algorithms to operate seamlessly over less reliable wireless networks with topological changes. They introduce new capabilities such as predictable outcomes during sensor/actuator failure, adaptation to mode changes, and runtime optimization of resource consumption. An automated design flow from Simulink to platform-independent domain-specific languages, and subsequently, to platform-dependent code generation is presented. Through case studies in discrete and process control we demonstrate the capabilities of EVM-based wireless network control systems.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2077526341",
    "type": "article"
  },
  {
    "title": "Integrated Task and Interrupt Management for Real-Time Systems",
    "doi": "https://doi.org/10.1145/2220336.2220344",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Luis Eduardo Leyva-del-Foyo; Pedro Mejía-Álvarez; Dionisio de Niz",
    "corresponding_authors": "",
    "abstract": "Real-time scheduling algorithms like RMA or EDF and their corresponding schedulability test have proven to be powerful tools for developing predictable real-time systems. However, the traditional interrupt management model presents multiple inconsistencies that break the assumptions of many of the real-time scheduling tests, diminishing its utility. In this article, we analyze these inconsistencies and present a model that resolves them by integrating interrupts and tasks in a single scheduling model. We then use the RMA theory to calculate the cost of the model and analyze the circumstances under which it can provide the most value. This model was implemented in a kernel module. The portability of the design of our module is discussed in terms of its independence from both the hardware and the kernel. We also discuss the implementation issues of the model over conventional PC hardware, along with its cost and novel optimizations for reducing the overhead. Finally, we present our experimental evaluation to show evidence of its temporal determinism and overhead.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2163250203",
    "type": "article"
  },
  {
    "title": "A reliability enhancement design under the flash translation layer for MLC-based flash-memory storage systems",
    "doi": "https://doi.org/10.1145/2501626.2512467",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Yuan-Hao Chang; Ming-Chang Yang; Tei‐Wei Kuo; Ren‐Hung Hwang",
    "corresponding_authors": "",
    "abstract": "Although flash memory has gained very strong momentum in the storage market, the reliability of flash-memory chips has been dropped significantly in the past years. This article presents a reliability enhancement design under the flash management layer (i.e., flash translation layer) to address this concern so as to reduce the design complexity of flash-memory management software/firmware and to improve the maintainability and portability of existing and future products. In particular, a log-based write strategy with a hash-based caching policy is proposed to provide extra ECC redundancy and performance improvement. Strategies for bad block management are also presented. The failure rate of flash-memory storage systems is analyzed with the considerations of bit errors. The proposed design is later evaluated by a series of experiments based on realistic traces. It was shown that the proposed approach could significantly improve the reliability of flash memory with very limited system overheads.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4233363419",
    "type": "article"
  },
  {
    "title": "Time-Triggered Implementations of Dynamic Controllers",
    "doi": "https://doi.org/10.1145/2331147.2331168",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Truong X. Nghiem; George J. Pappas; Rajeev Alur; Antoine Girard",
    "corresponding_authors": "",
    "abstract": "Bridging the gap between model-based design and platform-based implementation is one of the critical challenges for embedded software systems. In the context of embedded control systems that interact with an environment, a variety of errors due to quantization, delays, and scheduling policies may generate executable code that does not faithfully implement the model-based design. In this article, we show that the performance gap between the model-level semantics of linear dynamic controllers, for example, the proportional-integral-derivative (PID) controllers and their implementation-level semantics, can be rigorously quantified if the controller implementation is executed on a predictable time-triggered architecture. Our technical approach uses lifting techniques for periodic time-varying linear systems in order to compute the exact error between the model semantics and the execution semantics. Explicitly computing the impact of the implementation on overall system performance allows us to compare and partially order different implementations with various scheduling or timing characteristics.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2007385877",
    "type": "article"
  },
  {
    "title": "Market-based resource allocation for distributed data processing in wireless sensor networks",
    "doi": "https://doi.org/10.1145/2442116.2442134",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Andrew T. Zimmerman; Jerome P. Lynch; Frank Ferrese",
    "corresponding_authors": "",
    "abstract": "In recent years, improved wireless technologies have enabled the low-cost deployment of large numbers of sensors for a wide range of monitoring applications. Because of the computational resources (processing capability, storage capacity, etc.) collocated with each sensor in a wireless network, it is often possible to perform advanced data analysis tasks autonomously and in-network, eliminating the need for the post-processing of sensor data. With new parallel algorithms being developed for in-network computation, it has become necessary to create a framework in which all of a wireless network's scarce resources (CPU time, wireless bandwidth, storage capacity, battery power, etc.) can be best utilized in the midst of competing computational requirements. In this study, a market-based method is developed to autonomously distribute these scarce network resources across various computational tasks with competing objectives and/or resource demands. This method is experimentally validated on a network of wireless sensing prototypes, where it is shown to be capable of Pareto-optimally allocating scarce network resources. Then, it is applied to the real-world problem of rupture detection in shipboard chilled water systems.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2012321919",
    "type": "article"
  },
  {
    "title": "Schedulability analysis of EDF-scheduled embedded real-time systems with resource sharing",
    "doi": "https://doi.org/10.1145/2442116.2442117",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Fengxiang Zhang; Alan Burns",
    "corresponding_authors": "",
    "abstract": "Earliest Deadline First (EDF) is the most widely studied optimal dynamic scheduling algorithm for uniprocessor real-time systems. In the existing literature, however, there is no complete exact analysis for EDF scheduling when both resource sharing and release jitter are considered. Since resource sharing and release jitter are important characteristics of embedded real-time systems, a solid theoretical foundation should be provided for EDF scheduled systems. In this paper, we extend traditional processor demand analysis to let arbitrary deadline real-time tasks share non-preemptable resources and suffer release jitter. A complete and exact schedulability analysis for EDF scheduled systems is provided. This analysis is incorporated into QPA (Quick Processor-demand Analysis) which provides an efficient implementation of the exact test.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2051701341",
    "type": "article"
  },
  {
    "title": "A complete self-testing and self-configuring NoC infrastructure for cost-effective MPSoCs",
    "doi": "https://doi.org/10.1145/2485984.2485994",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Alberto Ghiribaldi; Daniele Ludovici; Francisco Antonio García Triviño; Alessandro Strano; José Flich; José L. Sánchez; Francisco J. Alfaro; M. Favalli; Davide Bertozzi",
    "corresponding_authors": "",
    "abstract": "Networks-on-chip need to survive to manufacturing faults in order to sustain yield. An effective testing and configuration strategy however implies two opposite requirements. One one hand, a fast and scalable built-in self-testing and self-diagnosis procedure has to be carried out concurrently at NoC switches. On the other hand, programming the NoC routing mechanism to go around faulty links and switches can be optimally performed by a centralized controller with global network visibility. To the best of our knowledge, this article proposes for the first time a global network testing and configuration strategy that meets the opposite requirements by means of a fault-tolerant dual network architecture and a fast configuration algorithm for the most common failure patterns. Experimental results report an area overhead as low as 12.5% with respect to the baseline switch architecture while achieving a high degree of fault tolerance. In fact, even when multiple stuck-at faults are considered, the capability of fault masking by the dual network is always over 80%, and the support for multiple link failures is more than 90% in presence of two unusable links in the main network with minimum set-up times.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2084501492",
    "type": "article"
  },
  {
    "title": "Impact of Wireless Channel Temporal Variation on MAC Design for Body Area Networks",
    "doi": "https://doi.org/10.1145/2331147.2331161",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Athanassios Boulis; Yuriy Tselishchev; Lavy Libman; David B. Smith; Leif Hanlen",
    "corresponding_authors": "",
    "abstract": "We investigate the impact of wireless channel temporal variations on the design of medium access control (MAC) protocols for body area networks (BANs). Our measurements-based channel model captures large and small time-scale signal correlations, giving an accurate picture of the signal variation, specifically, the deep fades which are the features that mostly affect the behavior of the MAC. We test the effect of the channel model on the performance of the 802.15.4 MAC both in contention access mode and TDMA access mode. We show that there are considerable differences in the performance of the MAC compared to simulations that do not model channel temporal variation. Furthermore, explaining the behavior of the MAC under a temporal varying channel, we can suggest specific design choices for the emerging BAN MAC standard.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2131179866",
    "type": "article"
  },
  {
    "title": "Why Data Deletion Fails? A Study on Deletion Flaws and Data Remanence in Android Systems",
    "doi": "https://doi.org/10.1145/3007211",
    "publication_date": "2017-01-10",
    "publication_year": 2017,
    "authors": "Junliang Shu; Yuanyuan Zhang; Juanru Li; Bodong Li; Dawu Gu",
    "corresponding_authors": "",
    "abstract": "Smart mobile devices are becoming the main vessel of personal privacy information. While they carry valuable information, data erasure is somehow much more vulnerable than was predicted. The security mechanisms provided by the Android system are not flexible enough to thoroughly delete sensitive data. In addition to the weakness among several provided data-erasing and file-deleting mechanisms, we also target the Android OS design flaws in data erasure, and unveil that the design of the Android OS contradicts some secure data-erasure demands. We present the data-erasure flaws in three typical scenarios on mainstream Android devices, such as the data clearing flaw , application uninstallation flaw , and factory reset flaw . Some of these flaws are inherited data-deleting security issues from the Linux kernel, and some are new vulnerabilities in the Android system. Those scenarios reveal the data leak points in Android systems. Moreover, we reveal that the data remanence on the disk is rarely affected by the user’s daily operation, such as file deletion and app installation and uninstallation, by a real-world data deletion latency experiment. After one volunteer used the Android phone for 2 months, the data remanence amount was still considerable. Then, we proposed DataRaider for file recovering from disk fragments. It adopts a file-carving technique and is implemented as an automated sensitive information recovering framework. DataRaider is able to extract private data in a raw disk image without any file system information, and the recovery rate is considerably high in the four test Android phones. We propose some mitigation for data remanence issues, and give the users some suggestions on data protection in Android systems.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2569693223",
    "type": "article"
  },
  {
    "title": "Data-Driven Synchronization for Internet-of-Things Systems",
    "doi": "https://doi.org/10.1145/2983627",
    "publication_date": "2017-04-28",
    "publication_year": 2017,
    "authors": "Terrell R. Bennett; Nicholas Gans; Roozbeh Jafari",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) is fueled by the growth of sensors, actuators, and services that collect and process raw sensor data. Wearable and environmental sensors will be a major component of the IoT and provide context about people and activities that are occurring. It is imperative that sensors in the IoT are synchronized, which increases the usefulness and value of the sensor data and allows data from multiple sources to be combined and compared. Due to the heterogeneous nature of sensors (e.g., synchronization protocols, communication channels, etc.), synchronization can be difficult. In this article, we present novel techniques for synchronizing data from multi-sensor environments based on the events and interactions measured by the sensors. We present methods to determine which interactions can likely be used for synchronization and methods to improve synchronization by removing erroneous synchronization points. We validate our technique through experiments with wearable and environmental sensors in a laboratory environment. Experiments resulted in median drift error reduction from 66% to 98% for sensors synchronized through physical interactions.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2610069609",
    "type": "article"
  },
  {
    "title": "CGPredict",
    "doi": "https://doi.org/10.1145/3126546",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Siqi Wang; Guanwen Zhong; Tulika Mitra",
    "corresponding_authors": "",
    "abstract": "Heterogeneous multiprocessor system-on-chip architectures are endowed with accelerators such as embedded GPUs and FPGAs capable of general-purpose computation. The application developers for such platforms need to carefully choose the accelerator with the maximum performance benefit. For a given application, usually, the reference code is specified in a high-level single-threaded programming language such as C. The performance of an application kernel on an accelerator is a complex interplay among the exposed parallelism, the compiler, and the accelerator architecture. Thus, determining the performance of a kernel requires its redevelopment into each accelerator-specific language, causing substantial wastage of time and effort. To aid the developer in this early design decision, we present an analytical framework CGPredict to predict the performance of a computational kernel on an embedded GPU architecture from un-optimized, single-threaded C code. The analytical approach provides insights on application characteristics which suggest further application-specific optimizations. The estimation error is as low as 2.66% (average 9%) compared to the performance of the same kernel written in native CUDA code running on NVIDIA Kepler embedded GPU. This low performance estimation error enables CGPredict to provide an early design recommendation of the accelerator starting from C code.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2757759139",
    "type": "article"
  },
  {
    "title": "Response-Time Analysis for Task Chains with Complex Precedence and Blocking Relations",
    "doi": "https://doi.org/10.1145/3126505",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Johannes Schlatow; Rolf Ernst",
    "corresponding_authors": "",
    "abstract": "For the development of complex software systems, we often resort to component-based approaches that separate the different concerns, enhance verifiability and reusability, and for which microkernel-based implementations are a good fit to enforce these concepts. Composing such a system of several interacting software components will, however, lead to complex precedence and blocking relations, which must be taken into account when performing latency analysis. When modelling these systems by classical task graphs, some of these effects are obfuscated and tend to render such an analysis either overly pessimistic or even optimistic. We therefore firstly present a novel task (meta-)model that is more expressive and accurate w.r.t. these (functional) precedence and mutual blocking relations. Secondly, we apply the busy-window approach and formulate a modular response-time analysis on task-chain level suitable but not restricted to static-priority scheduled systems. We show that the conjunction of both concepts allows the calculation of reasonably tight latency bounds for scenarios not adequately covered by related work.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2758914330",
    "type": "article"
  },
  {
    "title": "A Structured Methodology for Pattern based Adaptive Scheduling in Embedded Control",
    "doi": "https://doi.org/10.1145/3126514",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Sumana Ghosh; Souradeep Dutta; Soumyajit Dey; Pallab Dasgupta",
    "corresponding_authors": "",
    "abstract": "Software implementation of multiple embedded control loops often share compute resources. The control performance of such implementations have been shown to improve if the sharing of bandwidth between control loops can be dynamically regulated in response to input disturbances. In the absence of a structured methodology for planning such measures, the scheduler may spend too much time in deciding the optimal scheduling pattern. Our work leverages well known results in the domain of network control systems and applies them in the context of bandwidth sharing among controllers. We provide techniques that may be used a priori for computing co-schedulable execution patterns for a given set of control loops such that stability is guaranteed under all possible disturbance scenarios. Additionally, the design of the control loops optimize the average case control performance by adaptive sharing of bandwidth under time varying input disturbances.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2759883963",
    "type": "article"
  },
  {
    "title": "CaffePresso",
    "doi": "https://doi.org/10.1145/3105925",
    "publication_date": "2017-11-14",
    "publication_year": 2017,
    "authors": "Gopalakrishna Hegde; Siddhartha Siddhartha; Nachiket Kapre",
    "corresponding_authors": "",
    "abstract": "Auto-tuning and parametric implementation of deep learning kernels allow off-the-shelf accelerator-based embedded platforms to deliver high-performance and energy-efficient mappings of the inference phase of lightweight neural networks. Low-complexity classifiers are characterized by operations on small image maps with two to three deep layers and few class labels. For these use cases, we consider a range of embedded systems with 20W power budgets such as the Xilinx ZC706 (FPGA), NVIDIA Jetson TX1 (GPU), TI Keystone II (DSP), and Adapteva Parallella (RISC+NoC). In CaffePresso, we combine auto-tuning of the implementation parameters, and platform-specific constraints deliver optimized solutions for each input ConvNet specification.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2768797272",
    "type": "article"
  },
  {
    "title": "Design and Analysis of Battery-Aware Automotive Climate Control for Electric Vehicles",
    "doi": "https://doi.org/10.1145/3203408",
    "publication_date": "2018-07-05",
    "publication_year": 2018,
    "authors": "Korosh Vatanparvar; Mohammad Abdullah Al Faruque",
    "corresponding_authors": "",
    "abstract": "Electric Vehicles (EV) as a zero-emission means of transportation encounter challenges in battery design that cause a range anxieties for the drivers. Besides the electric motor, the Heating, Ventilation, and Air Conditioning (HVAC) system is another major contributor to the power consumption that may influence the EV battery lifetime and driving range. In the state-of-the-art methodologies for battery management systems, the battery performance is monitored and improved. While in the automotive climate control, the passenger’s thermal comfort is the main objective. Hence, the influence of the HVAC power on the battery behavior for the purpose of jointly optimized battery management and climate control has not been considered. In this article, we propose an automotive climate control methodology that is aware of the battery behavior and performance, while maintaining the passenger’s thermal comfort. In our methodology, battery parameters and cabin temperature are modeled and estimated, and the HVAC utilization is optimized and adjusted with respect to the electric motor and HVAC power requests. Therefore, the battery stress reduces, while the cabin temperature is maintained by predicting and optimizing the system states in the near-future. We have implemented our methodology and compared its performance to the state-of-the-art in terms of battery lifetime improvement and energy consumption reduction. We have also conducted experiments and analyses to explore multiple control window sizes, drive profiles, ambient temperatures, and modeling error rates in the methodology. It is shown that our battery-aware climate control can extend the battery lifetime by up to 13.2% and reduce the energy consumption by up to 14.4%.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2845944010",
    "type": "article"
  },
  {
    "title": "Exact WCRT Analysis for Message-Processing Tasks on Gateway-Integrated In-Vehicle CAN Clusters",
    "doi": "https://doi.org/10.1145/3284178",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Guoqi Xie; Gang Zeng; Ryo Kurachi; Hiroaki Takada; Renfa Li; Keqin Li",
    "corresponding_authors": "",
    "abstract": "A typical automotive integrated architecture is a controller area network (CAN) cluster integrated by a central gateway. This study proposes a novel and exact worst-case response time (WCRT) analysis method for message-processing tasks in the gateway. We first propose a round search method to obtain lower bound on response time (LBRT) and upper bound on response time (UBRT), respectively. We then obtain the exact WCRT belonging to the scope of the LBRT and UBRT with an effective non-exhaustive exploration. Experimental results on a real CAN message set reveal that the proposed exact analysis method can reduce 99.99999% combinations on large-scale CAN clusters.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2905880474",
    "type": "article"
  },
  {
    "title": "Quantifying the Information Leakage in Cache Attacks via Symbolic Execution",
    "doi": "https://doi.org/10.1145/3288758",
    "publication_date": "2019-01-08",
    "publication_year": 2019,
    "authors": "Sudipta Chattopadhyay; Moritz Beck; Ahmed Rezine; Andreas Zeller",
    "corresponding_authors": "",
    "abstract": "Cache attacks allow attackers to infer the properties of a secret execution by observing cache hits and misses. But how much information can actually leak through such attacks? For a given program, a cache model, and an input, our CHALICE framework leverages symbolic execution to compute the amount of information that can possibly leak through cache attacks. At the core of CHALICE is a novel approach to quantify information leakage that can highlight critical cache side-channel leakage on arbitrary binary code. In our evaluation on real-world programs from OpenSSL and Linux GDK libraries, CHALICE effectively quantifies information leakage: For an AES-128 implementation on Linux, for instance, CHALICE finds that a cache attack can leak as much as 127 out of 128 bits of the encryption key.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2910299242",
    "type": "article"
  },
  {
    "title": "FPGA Implementation of the ECC Over GF(2 <sup>m</sup> ) for Small Embedded Applications",
    "doi": "https://doi.org/10.1145/3310354",
    "publication_date": "2019-03-27",
    "publication_year": 2019,
    "authors": "Salah Harb; Moath Jarrah",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a compact elliptic curve cryptographic core over GF(2 m ). The proposed architecture is based on the Lopez-Dahab projective point arithmetic operations. To achieve efficiency in resources usage, an iterative method that uses a ROM-based state machine is developed for the elliptic curve cryptography (ECC) point doubling and addition operations. The compact ECC core has been implemented using Virtex FPGA devices. The number of the required slices is 2,102 at 321MHz and 6,738 slices at 262MHz for different GF(2 m ). Extensive experiments were conducted to compare our solution to existing methods in the literature. Our compact core consumes less area than all previously proposed methods. It also provides an excellent performance for scalar multiplication. In addition, the ECC core is implemented in ASIC 0.18μm CMOS technology, and the results show excellent performance. Therefore, our proposed ECC core method provides a balance in terms of speed, area, and power consumption. This makes the proposed design the right choice for cryptosystems in limited-resource devices such as cell phones, IP cores of SoCs, and smart cards. Moreover, side-channel attack resistance is implemented to prevent power analysis.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2935161401",
    "type": "article"
  },
  {
    "title": "Coherent Extension, Composition, and Merging Operators in Contract Models for System Design",
    "doi": "https://doi.org/10.1145/3358216",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Roberto Passerone; Inigo Incer; Alberto Sangiovanni‐Vincentelli",
    "corresponding_authors": "",
    "abstract": "Contract models have been proposed to promote and facilitate reuse and distributed development. In this paper, we cast contract models into a coherent formalism used to derive general results about the properties of their operators. We study several extensions of the basic model, including the distinction between weak and strong assumptions and maximality of the specification. We then analyze the disjunction and conjunction operators, and show how they can be broken up into a sequence of simpler operations. This leads to the definition of a new contract viewpoint merging operator, which better captures the design intent in contrast to the more traditional conjunction. The adjoint operation, which we call separation, can be used to re-partition the specification into different viewpoints. We show the symmetries of these operations with respect to composition and quotient.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3080122937",
    "type": "article"
  },
  {
    "title": "Energy-efficient and high-performance software architecture for storage class memory",
    "doi": "https://doi.org/10.1145/2442116.2442131",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Seungjae Baek; Jongmoo Choi; Dong‐Hee Lee; Sam H. Noh",
    "corresponding_authors": "",
    "abstract": "Recently, interest in incorporating Storage Class Memory (SCM), which blurs the distinction between memory and storage, into mainstream computing has been increasing rapidly. In this paper, we address the emerging questions regarding the use of SCM. Based on an embedded platform that employs FeRAM, a type of SCM, we present our findings. In summary, by introducing SCM, power efficiency improves while performance is degraded. We also show that such performance degradations may be removed with operating system level schemes that fully exploit the characteristics of SCM. Finally, we present permanent computing that supports lightweight system on/off capabilities by using SCM.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1971266949",
    "type": "article"
  },
  {
    "title": "Host-Compiled Multicore System Simulation for Early Real-Time Performance Evaluation",
    "doi": "https://doi.org/10.1145/2678020",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Parisa Razaghi; Andreas Gerstlauer",
    "corresponding_authors": "",
    "abstract": "With increasing complexity and software content, modern embedded platforms employ a heterogeneous mix of multicore processors along with hardware accelerators in order to provide high performance in limited power budgets. To evaluate real-time performance and other constraints, full system simulations are essential. With traditional approaches being either slow or inaccurate, so-called source-level or host-compiled simulators have recently emerged as a solution for rapid evaluation of the complete system at early design stages. In such approaches, a faster simulation is achieved by abstracting execution behavior and increasing simulation granularity. However, existing source-level simulators often focus on application behavior only while neglecting the effects of hardware/software interactions and their associated speed and accuracy trade-offs. In this article, we present a host-compiled simulator that emulates software execution in a full-system context. Our simulator incorporates abstract models of both real-time operating systems (RTOSs) and multicore processors to replicate timing-accurate hardware/software interactions and to enable full system cosimulation. An integrated approach for automatic timing granularity adjustment (ATGA) uses observations of the system state to automatically control the timing model and optimally navigate speed versus accuracy conditions. Results as applied to industrial-strength platforms confirm that OS- and system-level effects can significantly contribute to overall accuracy and simulation overhead. By providing careful abstractions, our models can achieve full system simulations at equivalent speeds of more than a thousand MIPS with less than 3% timing error. Coupled with the capability to easily adjust simulation parameters and configurations, this demonstrates the benefits of our simulator for early application development and design space exploration.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1981549778",
    "type": "article"
  },
  {
    "title": "A Software Scheme for Multithreading on CGRAs",
    "doi": "https://doi.org/10.1145/2638558",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Jared Pager; Reiley Jeyapaul; Aviral Shrivastava",
    "corresponding_authors": "",
    "abstract": "Recent industry trends show a drastic rise in the use of hand-held embedded devices, from everyday applications to medical (e.g., monitoring devices) and critical defense applications (e.g., sensor nodes). The two key requirements in the design of such devices are their processing capabilities and battery life. There is therefore an urgency to build high-performance and power-efficient embedded devices, inspiring researchers to develop novel system designs for the same. The use of a coprocessor (application-specific hardware) to offload power-hungry computations is gaining favor among system designers to suit their power budgets. We propose the use of CGRAs (Coarse-Grained Reconfigurable Arrays) as a power-efficient coprocessor. Though CGRAs have been widely used for streaming applications, the extensive compiler support required limits its applicability and use as a general purpose coprocessor. In addition, a CGRA structure can efficiently execute only one statically scheduled kernel at a time, which is a serious limitation when used as an accelerator to a multithreaded or multitasking processor. In this work, we envision a multithreaded CGRA where multiple schedules (or kernels) can be executed simultaneously on the CGRA (as a coprocessor). We propose a comprehensive software scheme that transforms the traditionally single-threaded CGRA into a multithreaded coprocessor to be used as a power-efficient accelerator for multithreaded embedded processors. Our software scheme includes (1) a compiler framework that integrates with existing CGRA mapping techniques to prepare kernels for execution on the multithreaded CGRA and (2) a runtime mechanism that dynamically schedules multiple kernels (offloaded from the processor) to execute simultaneously on the CGRA coprocessor. Our multithreaded CGRA coprocessor implementation thus makes it possible to achieve improved power-efficient computing in modern multithreaded embedded systems.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1994107935",
    "type": "article"
  },
  {
    "title": "Design of Liveness-Enforcing Supervisors for S3PR Based on Complementary Places",
    "doi": "https://doi.org/10.1145/2406336.2406338",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Shouguang Wang; Chengying Wang; Yanping Yu",
    "corresponding_authors": "",
    "abstract": "In this article, an algorithm is proposed to design liveness-enforcing supervisors for systems of simple sequential processes with resources (S 3 PR) based on complementary places. Firstly, a mixed integer programming (MIP) based deadlock detection method is used to find unmarked strict minimal siphons from an infinite-capacity net. Next, the finite-capacity net, in which liveness can be enforced, is obtained by adding capacity function to the infinite-capacity net. Finally, complementary-place transformation is used to transform the finite-capacity net into an infinite-capacity net. This article focuses on adding a complementary place to each operation place that is related to unmarked siphons, deals with the deadlock problem from a new view point, and hence advances the deadlock control theory. Compared with the existing methods, the new policy is easier to implement for real industrial systems. More importantly, design of a complementary-place supervisor is very easy. Finally, in some cases, the new policy can obtain a structurally simpler supervisor with more permissive behavior than the existing methods do. A flexible manufacturing systems (FMS) example is used to compare the proposed policy with some other methods.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2004675751",
    "type": "article"
  },
  {
    "title": "Post-silicon platform for the functional diagnosis and debug of networks-on-chip",
    "doi": "https://doi.org/10.1145/2567936",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Rawan Abdel-Khalek; Valeria Bertacco",
    "corresponding_authors": "",
    "abstract": "The increasing number of units in today's systems-on-chip and multicore processors has led to complex intra-chip communication solutions. Specifically, Networks-on-Chip (NoCs) have emerged as a favorable fabric to provide high bandwidth and low latency in connecting many units in a same chip. To achieve these goals, the NoC often includes complex components and advanced features, leading to the development of large and highly complex interconnect subsystems. One of the biggest challenges in these designs is to ensure the correct functionality of this communication infrastructure. To support this goal, an increasing fraction of the validation effort has shifted to post-silicon validation, because it permits exercising network activities that are too complex to be validated in pre-silicon. However, post-silicon validation is hindered by the lack of observability of the network's internal operations and thus, diagnosing functional errors during this phase is very difficult. In this work, we propose a post-silicon validation platform that improves observability of network operations by taking periodic snapshots of the traffic traversing the network. Each node's local cache is configured to temporarily store the snapshot logs in a designated area reserved for post-silicon validation and relinquished after product release. Each snapshot log is analyzed locally by a software algorithm running on its corresponding core, in order to detect functional errors. Upon error detection, all snapshot logs are aggregated at a central location to extract additional debug data, including an overview of network traffic surrounding the error event, as well as a partial reconstruction of the routes followed by packets in flight at the time. In our experiments, we found that this approach allows us to detect several types of functional errors, as well as observe, on average, over 50% of the network's traffic and reconstruct at least half of each of their routes through the network.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2028725073",
    "type": "article"
  },
  {
    "title": "Instruction-Cache Locking for Improving Embedded Systems Performance",
    "doi": "https://doi.org/10.1145/2700100",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Kapil Anand; Rajeev Barua",
    "corresponding_authors": "",
    "abstract": "Cache memories in embedded systems play an important role in reducing the execution time of applications. Various kinds of extensions have been added to cache hardware to enable software involvement in replacement decisions, improving the runtime over a purely hardware-managed cache. Novel embedded systems, such as Intel’s XScale and ARM Cortex processors, facilitate locking one or more lines in cache; this feature is called cache locking . We present a method in for instruction-cache locking that is able to reduce the average-case runtime of a program. We demonstrate that the optimal solution for instruction cache locking can be obtained in polynomial time. However, a fundamental lack of correlation between cache hardware and software program points renders such optimal solutions impractical. Instead, we propose two practical heuristics-based approaches to achieve cache locking. First, we present a static mechanism for locking the cache, in which the locked contents of the cache are kept fixed over the execution of the program. Next, we present a dynamic mechanism that accounts for changing program requirements at runtime. We devise a cost--benefit model to discover the memory addresses that should be locked in the cache. We implement our scheme inside a binary rewriter, widening the applicability of our scheme to binaries compiled using any compiler. Results obtained on a suite of MiBench benchmarks show that our static mechanism results in 20% improvement in the instruction-cache miss rate on average and up to 18% improvement in the execution time on average for applications having instruction accesses as a bottleneck, compared to no cache locking. The dynamic mechanism improves the cache miss rate by 35% on average and execution time by 32% on instruction-cache-constrained applications.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2063389777",
    "type": "article"
  },
  {
    "title": "Optimized and Scalable Co-Processor for McEliece with Binary Goppa Codes",
    "doi": "https://doi.org/10.1145/2736284",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Pedro Maat C. Massolino; Paulo S. L. M. Barreto; Wilson Vicente Ruggiero",
    "corresponding_authors": "",
    "abstract": "Asymmetric cryptographic primitives are essential to enable secure communications in public networks or public mediums. Such primitives can be deployed as software libraries or hardware co-processors, the latter being more commonly employed in systems on chip (SoC) scenarios, embedded devices, or application-specific servers. Unfortunately, the most commonly available solutions, based on RSA or elliptic curve cryptography (ECC), are highly processing intensive due to the underlying extended-precision modular arithmetic. Consequently, they are not available on highly constrained platforms. Aiming to tackle this issue, we here investigate an alternative asymmetric encryption scheme that relies on lightweight arithmetic: McEliece. This scheme is especially appealing because, being based on error correction codes, it displays a simpler arithmetic and leads to better performance when compared to RSA or ECC. To evaluate the implementation of this scheme in hardware, we propose and analyze a flexible architecture whose security level and time versus area usage characteristics can be reconfigured as desired. The proposed architecture is suitable to all usual security levels, ranging from 80 to 256 bits. It is also very efficient, being able to perform data decryption with binary Goppa codes in 56µs with 3,402 slices on a Xilinx Spartan-3AN FPGA, whereas the best-known result in the literature for the same FPGA is 115µs with 7,331 slices. Alternatively, the architecture can operate with quasi-dyadic Goppa (QD-Goppa) codes, which involves smaller keys than traditional binary Goppa codes. In the latter case, for an 80-bit security level, the decryption operation can take from 1.1ms with 1,129 slices to 68µs with 8,268 sices. By choosing a more hardware-friendly decoding algorithm, focusing hardware resources on most bottleneck operations and sharing hardware resource for two different algorithms, better results than the those in the literature were obtained.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2082866368",
    "type": "article"
  },
  {
    "title": "Towards a scalable, low-power all-optical architecture for networks-on-chip",
    "doi": "https://doi.org/10.1145/2567930",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Somayyeh Koohi; Yawei Yin; Shaahin Hessabi; S. J. Ben Yoo",
    "corresponding_authors": "",
    "abstract": "This article proposes a scalable wavelength-routed optical Network on Chip (NoC) based on the Spidergon topology, named Power-efficient Scalable Wavelength-routed Network-on-chip (PeSWaN). The key idea of the proposed all-optical architecture is the utilization of per-receiver wavelengths in the data network to prevent network contention and the adoption of per-sender wavelengths in the control network to avoid end-point contention. By performing a series of simulations, we study the efficiency of the proposed architecture, its power and energy consumption, and the data transmission delay. Moreover, we compare the proposed architecture with electrical NoCs and alternative ONoC architectures under various traffic patterns.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2101922210",
    "type": "article"
  },
  {
    "title": "A hardware architecture for real-time object detection using depth and edge information",
    "doi": "https://doi.org/10.1145/2539036.2539050",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Christos Kyrkou; Christos Ttofis; Theocharis Theocharides",
    "corresponding_authors": "",
    "abstract": "Emerging embedded 3D vision systems for robotics and security applications utilize object detection to perform video analysis in order to intelligently interact with their host environment and take appropriate actions. Such systems have high performance and high detection-accuracy demands, while requiring low energy consumption, especially when dealing with embedded mobile systems. However, there is a large image search space involved in object detection, primarily because of the different sizes in which an object may appear, which makes it difficult to meet these demands. Hence, it is possible to meet such constraints by reducing the search space involved in object detection. To this end, this article proposes a depth and edge accelerated search method and a dedicated hardware architecture that implements it to provide an efficient platform for generic real-time object detection. The hardware integration of depth and edge processing mechanisms, with a support vector machine classification core onto an FPGA platform, results in significant speed-ups and improved detection accuracy. The proposed architecture was evaluated using images of various sizes, with results indicating that the proposed architecture is capable of achieving real-time frame rates for a variety of image sizes (271 fps for 320 × 240, 42 fps for 640 × 480, and 23 fps for 800 × 600) compared to existing works, while reducing the false-positive rate by 52%.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2156710385",
    "type": "article"
  },
  {
    "title": "Contract-Based Requirement Modularization via Synthesis of Correct Decompositions",
    "doi": "https://doi.org/10.1145/2885752",
    "publication_date": "2016-02-26",
    "publication_year": 2016,
    "authors": "Thi Thieu Hoa Le; Roberto Passerone; Uli Fahrenberg; Axel Legay",
    "corresponding_authors": "",
    "abstract": "In distributed development of modern systems, contracts play a vital role in ensuring interoperability of components and adherence to specifications. It is therefore often desirable to verify the satisfaction of an overall property represented as a contract, given the satisfaction of smaller properties also represented as contracts. When the verification result is negative, designers must face the issue of refining the subproperties and components. This is an instance of the classical synthesis problems: “can we construct a model that satisfies some given specification?” In this work, we propose two strategies enabling designers to synthesize or refine a set of contracts so that their composition satisfies a given contract. We develop a generic algebraic method and show how it can be applied in different contract models to support top-down component-based development of distributed systems.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2326271904",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3001902",
    "publication_date": "2016-11-03",
    "publication_year": 2016,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2548760866",
    "type": "editorial"
  },
  {
    "title": "Global Optimization of Fixed-Priority Real-Time Systems by RTOS-Aware Control-Flow Analysis",
    "doi": "https://doi.org/10.1145/2950053",
    "publication_date": "2017-01-02",
    "publication_year": 2017,
    "authors": "Christian Dietrich; Martin Hoffmann; Daniel Lohmann",
    "corresponding_authors": "",
    "abstract": "Cyber--physical systems typically target a dedicated purpose; their embedded real-time control system, such as an automotive control unit, is designed with a well-defined set of functionalities. On the software side, this results in a large amount of implicit and explicit static knowledge about the system and its behavior already at compile time. Compilers have become increasingly better at extracting and exploiting such static knowledge. For instance, many optimizations have been lifted up to the interprocedural or even to the whole-program level. However, whole-program optimizations generally stop at the application--kernel boundary: control-flow transitions between different threads are not yet analyzed. In this article, we cross the application--kernel boundary by combining the semantics of a real-time operating system (RTOS) with deterministic fixed-priority scheduling (e.g., OSEK/AUTOSAR, ARINC 653, μITRON, POSIX.4) and the explicit application knowledge to enable system-wide, flow-sensitive compiler optimizations. We present two methods to extract a cross-kernel, control-flow--graph that provides a global view on all possible execution paths of a real-time system. Having this knowledge at hand, we tailor the operating system kernel more closely to the particular application scenario. For the example of a real-world safety-critical control system, we present three possible use cases. (1) Runtime optimizations, by means of specialized system calls for each call site, allow one speed up the kernel execution path by 28% in our benchmark scenario. Furthermore, we target transient hardware fault tolerance with two automated software-based countermeasures: (2) generation of OS state assertions on the expected system behavior, and (3) a system-wide dominator-region based control-flow error detection, both of which leverage significant robustness improvements.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2563449037",
    "type": "article"
  },
  {
    "title": "BenchPrime",
    "doi": "https://doi.org/10.1145/3126499",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Qingrui Liu; Xiaolong Wu; Larry Kittinger; Markus Levy; Changhee Jung",
    "corresponding_authors": "",
    "abstract": "This paper presents BenchPrime, an automated benchmark analysis toolset that is systematic and extensible to analyze the similarity and diversity of benchmark suites. BenchPrime takes multiple benchmark suites and their evaluation metrics as inputs and generates a hybrid benchmark suite comprising only essential applications. Unlike prior work, BenchPrime uses linear discriminant analysis rather than principal component analysis, as well as selects the best clustering algorithm and the optimized number of clusters in an automated and metric-tailored way, thereby achieving high accuracy. In addition, BenchPrime ranks the benchmark suites in terms of their application set diversity and estimates how unique each benchmark suite is compared to other suites. As a case study, this work for the first time compares the DenBench with the MediaBench and MiBench using four different metrics to provide a multi-dimensional understanding of the benchmark suites. For each metric, BenchPrime measures to what degree DenBench applications are irreplaceable with those in MediaBench and MiBench. This provides means for identifying an essential subset from the three benchmark suites without compromising the application balance of the full set. The experimental results show that the necessity of including DenBench applications varies across the target metrics and that significant redundancy exists among the three benchmark suites.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2758020742",
    "type": "article"
  },
  {
    "title": "Low-Cost Memory Fault Tolerance for IoT Devices",
    "doi": "https://doi.org/10.1145/3126534",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Mark Gottscho; Irina Alam; Clayton Schoeny; Lara Dolecek; Puneet Gupta",
    "corresponding_authors": "",
    "abstract": "IoT devices need reliable hardware at low cost. It is challenging to efficiently cope with both hard and soft faults in embedded scratchpad memories. To address this problem, we propose a two-step approach: FaultLink and Software-Defined Error-Localizing Codes (SDELC). FaultLink avoids hard faults found during testing by generating a custom-tailored application binary image for each individual chip. During software deployment-time, FaultLink optimally packs small sections of program code and data into fault-free segments of the memory address space and generates a custom linker script for a lazy-linking procedure. During run-time, SDELC deals with unpredictable soft faults via novel and inexpensive Ultra-Lightweight Error-Localizing Codes (UL-ELCs). These require fewer parity bits than single-error-correcting Hamming codes. Yet our UL-ELCs are more powerful than basic single-error-detecting parity: they localize single-bit errors to a specific chunk of a codeword. SDELC then heuristically recovers from these localized errors using a small embedded C library that exploits observable side information (SI) about the application’s memory contents. SI can be in the form of redundant data (value locality), legal/illegal instructions, etc. Our combined FaultLink+SDELC approach improves min-VDD by up to 440 mV and correctly recovers from up to 90% (70%) of random single-bit soft faults in data (instructions) with just three parity bits per 32-bit word.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2760274952",
    "type": "article"
  },
  {
    "title": "OPPC",
    "doi": "https://doi.org/10.1145/3126684",
    "publication_date": "2017-10-24",
    "publication_year": 2017,
    "authors": "Chi Lin; Yanhong Zhou; Houbing Song; Chang Wu Yu; Guowei Wu",
    "corresponding_authors": "",
    "abstract": "The lack of schedulability evaluation of previous charging schemes in wireless rechargeable sensor networks (WRSNs) degrades the charging efficiency, leading to node exhaustion. We propose an Optimal Path Planning Charging scheme, namely OPPC, for the on-demand charging architecture. OPPC evaluates the schedulability of a charging mission, which makes charging scheduling predictable. It provides an optimal charging path which maximizes charging efficiency. When confronted with a non-schedulable charging mission, a node discarding algorithm is developed to enable the schedulability. Experimental simulations demonstrate that OPPC can achieve better performance in successful charging rate as well as charging efficiency.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2766248232",
    "type": "article"
  },
  {
    "title": "Exploiting Sparsity to Accelerate Fully Connected Layers of CNN-Based Applications on Mobile SoCs",
    "doi": "https://doi.org/10.1145/3122788",
    "publication_date": "2017-12-07",
    "publication_year": 2017,
    "authors": "Xinfeng Xie; Dayou Du; Qian Li; Yun Liang; Wai Teng Tang; Zhong Liang Ong; Mian Lu; Huynh Phung Huynh; Rick Siow Mong Goh",
    "corresponding_authors": "",
    "abstract": "Convolutional neural networks (CNNs) are widely employed in many image recognition applications. With the proliferation of embedded and mobile devices, such applications are becoming commonplace on mobile devices. Network pruning is a commonly used strategy to reduce the memory and storage footprints of CNNs on mobile devices. In this article, we propose customized versions of the sparse matrix multiplication algorithm to speed up inference on mobile devices and make it more energy efficient. Specifically, we propose a Block Compressed Sparse Column algorithm and a bit-representation-based algorithm (BitsGEMM) that exploit sparsity to accelerate the fully connected layers of a network on the NVIDIA Jetson TK1 platform. We evaluate the proposed algorithms using real-world object classification and object detection applications. Experiments show that performance speedups can be achieved over the original baseline implementation using cuBLAS. On object detection CNNs, an average speedup of 1.82× is obtained over baseline cuBLAS in the fully connected layer of the VGG model, whereas on classification CNNs, an average speedup of 1.51× is achieved for the fully connected layer of the pruned-VGG model. Energy consumption reduction of 43--46% is also observed due to decreased computational and memory bandwidth demands.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2772753951",
    "type": "article"
  },
  {
    "title": "Time and Sequence Integrated Runtime Anomaly Detection for Embedded Systems",
    "doi": "https://doi.org/10.1145/3122785",
    "publication_date": "2017-12-07",
    "publication_year": 2017,
    "authors": "Sixing Lu; Roman Lysecky",
    "corresponding_authors": "",
    "abstract": "Network-connected embedded systems grow on a large scale as a critical part of Internet of Things, and these systems are under the risk of increasing malware. Anomaly-based detection methods can detect malware in embedded systems effectively and provide the advantage of detecting zero-day exploits relative to signature-based detection methods, but existing approaches incur significant performance overheads and are susceptible to mimicry attacks. In this article, we present a formal runtime security model that defines the normal system behavior including execution sequence and execution timing. The anomaly detection method in this article utilizes on-chip hardware to non-intrusively monitor system execution through trace port of the processor and detect malicious activity at runtime. We further analyze the properties of the timing distribution for control flow events, and select subset of monitoring targets by three selection metrics to meet hardware constraint. The designed detection method is evaluated by a network-connected pacemaker benchmark prototyped in FPGA and simulated in SystemC, with several mimicry attacks implemented at different levels. The resulting detection rate and false positive rate considering constraints on the number of monitored events supported in the on-chip hardware demonstrate good performance of our approach.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2773129630",
    "type": "article"
  },
  {
    "title": "Synergistic CPU-GPU Frequency Capping for Energy-Efficient Mobile Games",
    "doi": "https://doi.org/10.1145/3145337",
    "publication_date": "2017-12-19",
    "publication_year": 2017,
    "authors": "Jurn-Gyu Park; Chen-Ying Hsieh; Nikil Dutt; Sung-Soo Lim",
    "corresponding_authors": "",
    "abstract": "Mobile platforms are increasingly using Heterogeneous Multiprocessor Systems-on-Chip (HMPSoCs) with differentiated processing cores and GPUs to achieve high performance for graphics-intensive applications such as mobile games. Traditionally, separate CPU and GPU governors are deployed in order to achieve energy efficiency through Dynamic Voltage Frequency Scaling (DVFS) but miss opportunities for further energy savings through coordinated system-level application of DVFS. We present a cooperative CPU-GPU DVFS strategy (called Co-Cap) that orchestrates energy-efficient CPU and GPU DVFS through synergistic CPU and GPU frequency capping to avoid frequency overprovisioning while maintaining desired performance. Unlike traditional approaches that target a narrow set of mobile games, our Co-Cap approach is applicable across a wide range of microbenchmarks and mobile games. Our methodology employs a systematic training phase using fine-grained refinement steps with evaluations of frequency capping tables followed by a deployment phase, allowing deployment across a wide range of microbenchmarks and mobile games with varying graphics workloads. Our experimental results across multiple sets of over 200 microbenchmarks and 40 mobile games show that Co-Cap improves energy per frame by on average 8.9% (up to 18.3%) and 7.8% (up to 27.6%) (16.6% and 15.7% in CPU-dominant applications) and achieves minimal frames-per-second (FPS) loss by 0.9% and 0.85% (1.3% and 1.5% in CPU-dominant applications) on average in training and deployment sets, respectively, compared to the default CPU and GPU governors, with negligible overhead in execution time and power consumption on the ODROID-XU3 platform.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2780572480",
    "type": "article"
  },
  {
    "title": "TF-Net",
    "doi": "https://doi.org/10.1145/3358189",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Jiecao Yu; Andrew Lukefahr; Reetuparna Das; Scott Mahlke",
    "corresponding_authors": "",
    "abstract": "Deep Neural Networks (DNNs) have become an essential component of various applications. While today’s DNNs are mainly restricted to cloud services, network connectivity, energy, and data privacy problems make it important to support efficient DNN computation on low-cost, low-power processors like microcontrollers. However, due to the constrained computation resources, it is challenging to execute large DNN models on microcontrollers. Using sub-byte low-precision input activations and weights is a typical method to reduce DNN computation. But on byte-addressable microcontrollers, the sub-byte computation is not well supported. The sub-byte inputs and weights need to be unpacked from bitstreams before computation, which incurs significant computation and energy overhead. In this paper, we propose the TF-Net pipeline to efficiently deploy sub-byte DNNs on microcontrollers. While TF-Net allows for a range of weight and input precision, we find Ternary weights and Four-bit inputs provide the optimal balance between model accuracy, computation performance, and energy efficiency. TF-Net first includes a training framework for sub-byte low-precision DNN models. Two algorithms are then introduced to accelerate the trained models. The first, direct buffer convolution, amortizes unpacking overhead by caching unpacked inputs. The second, packed sub-byte multiply-accumulate, utilizes a single multiplication instruction to perform multiple sub-byte multiply-accumulate computations. To further accelerate DNN computation, we propose two instructions, Multiply-Shift-Accumulate and Unpack, to extend the existing microcontroller instruction set. On the tested networks, TF-Net can help improve the computation performance and energy efficiency by 1.83× and 2.28× on average, respectively.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2979730268",
    "type": "article"
  },
  {
    "title": "Deriving Equations from Sensor Data Using Dimensional Function Synthesis",
    "doi": "https://doi.org/10.1145/3358218",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Youchao Wang; Sam Willis; Vasileios Tsoutsouras; Phillip Stanley‐Marbell",
    "corresponding_authors": "",
    "abstract": "We present a new method for deriving functions that model the relationship between multiple signals in a physical system. The method, which we call dimensional function synthesis , applies to data streams where the dimensions of the signals are known. The method comprises two phases: a compile-time synthesis phase and a subsequent calibration using sensor data. We implement dimensional function synthesis and use the implementation to demonstrate efficiently summarizing multi-modal sensor data for two physical systems using 90 laboratory experiments and 10 000 synthetic idealized measurements. We evaluate the performance of the compile-time phase of dimensional function synthesis as well as the calibration phase overhead, inference latency, and accuracy of the models our method generates. The results show that our technique can generate models in less than 300 ms on average across all the physical systems we evaluated. When calibrated with sensor data, our models outperform traditional regression and neural network models in inference accuracy in all the cases we evaluated. In addition, our models perform better in training latency (over 8660× improvement) and required arithmetic operations in inference (over 34× improvement). These significant gains are largely the result of exploiting information on the physics of signals that has hitherto been ignored.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2979941234",
    "type": "article"
  },
  {
    "title": "Accumulative Display Updating for Intermittent Systems",
    "doi": "https://doi.org/10.1145/3358190",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Hashan Roshantha Mendis; Pi-Cheng Hsiu",
    "corresponding_authors": "",
    "abstract": "Electrophoretic displays are ideal for self-powered systems, but currently require an uninterrupted power supply to carry out the full display update cycle. Although sensible for battery-powered devices, when directly applied to intermittently-powered systems, guaranteeing display update atomicity usually results in repeated execution until completion or can incur high hardware/software overheads, heavy programmer intervention and large energy buffering requirements to provide sufficient display update energy. This paper introduces the concept, design and implementation of accumulative display updating, which relaxes the atomicity constraints of display updating, such that the display update process can be accumulatively completed across power cycles, without the need for sufficient energy for the entire display update. To allow for process logical continuity, we track the update progress during execution and facilitate a safe display shutdown procedure to overcome physical and operability issues related to abrupt power failure. Additionally, a context-aware updating policy is proposed to handle data freshness issues, where the delay in addressing new update requests can cause the display contents to be in conflict with new data available. Experimental results on a Texas Instruments device with an integrated electrophoretic display show that, compared to atomic display updating, our design can significantly increase accurate forward progress, decrease the average response time of display updating and reduce time and energy wastage when displaying fresh data.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2979945823",
    "type": "article"
  },
  {
    "title": "DEEPEYE",
    "doi": "https://doi.org/10.1145/3381805",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Yuan Cheng; Guangya Li; Ngai Wong; Hai‐Bao Chen; Hao Yu",
    "corresponding_authors": "",
    "abstract": "Video object detection and action recognition typically require deep neural networks (DNNs) with huge number of parameters. It is thereby challenging to develop a DNN video comprehension unit in resource-constrained terminal devices. In this article, we introduce a deeply tensor-compressed video comprehension neural network, called DEEPEYE, for inference on terminal devices. Instead of building a Long Short-Term Memory (LSTM) network directly from high-dimensional raw video data input, we construct an LSTM-based spatio-temporal model from structured, tensorized time-series features for object detection and action recognition. A deep compression is achieved by tensor decomposition and trained quantization of the time-series feature-based LSTM network. We have implemented DEEPEYE on an ARM-core-based IOT board with 31 FPS consuming only 2.4W power. Using the video datasets MOMENTS, UCF11 and HMDB51 as benchmarks, DEEPEYE achieves a 228.1× model compression with only 0.47% mAP reduction; as well as 15 k × parameter reduction with up to 8.01% accuracy improvement over other competing approaches.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3032223871",
    "type": "article"
  },
  {
    "title": "Analyzing Event-Based Scheduling in Concurrent Reactive Systems",
    "doi": "https://doi.org/10.1145/2783438",
    "publication_date": "2015-09-24",
    "publication_year": 2015,
    "authors": "Jianmin Jiang; Huibiao Zhu; Qin Li; Yongxin Zhao; Lin Zhao; Shi Zhang; Ping Gong; Hong Zhong",
    "corresponding_authors": "",
    "abstract": "The traditional research on scheduling focuses on task scheduling and schedulability analysis in concurrent reactive systems. In this article, we dedicate ourselves to event-based scheduling. We first formally define an event-based scheduling policy and propose the notion of the correctness of a scheduling policy in terms of weak termination. Then we investigate the correctness of the decomposition of scheduling controls and finally obtain a decentralized scheduling method. The method can automatically decompose the scheduling policies of a concurrent reactive system into atomic scheduling policies. Every atomic scheduling policy corresponds to one subsystem. Each of the subsystems is a completely independent system, which may be developed and deployed independently. An experiment demonstrates these results that may help engineers to design correct and efficient schedule policies for a concurrent reactive system.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2046998979",
    "type": "article"
  },
  {
    "title": "Memory-Model-Aware Testing",
    "doi": "https://doi.org/10.1145/2753761",
    "publication_date": "2015-09-24",
    "publication_year": 2015,
    "authors": "Florian Furbach; Roland Meyer; Klaus Schneider; Maximilian Senftleben",
    "corresponding_authors": "",
    "abstract": "To improve the performance of the memory system, multiprocessors implement weak memory consistency models. Weak memory models admit different views of the processes on their load and store instructions, thus allowing for computations that are not sequentially consistent. Program analyses have to take into account the memory model of the targeted hardware. This is challenging because numerous memory models have been developed, and every memory model requires its own analysis. In this article, we study a prominent approach to program analysis: testing. The testing problem takes as input sequences of operations, one for each process in the concurrent program. The task is to check whether these sequences can be interleaved to an execution of the entire program that respects the constraints of a memory model under consideration. We determine the complexity of the testing problem for most of the known memory models. Moreover, we study the impact on the complexity of parameters, such as the number of concurrent processes, the length of their executions, and the number of shared variables. What differentiates our contribution from related results is a uniform approach that avoids considering each memory model on its own. We build upon work of Steinke and Nutt. They showed that the existing memory models form a hierarchy where one model is called weaker than another one if it includes the latter’s behavior. Using the Steinke-Nutt hierarchy, we develop three general concepts that allow us to quickly determine the complexity of a testing problem. First, we generalize the technique of problem reductions from complexity theory. So-called range reductions propagate hardness results between memory models, and we apply them to establish NP lower bounds for the stronger memory models. Second, for the weaker models, we present polynomial-time testing algorithms that are inspired by determinization algorithms for automata. Finally, we describe a single SAT encoding of the testing problem that works for all memory models in the Steinke-Nutt hierarchy to prove their membership in NP . Our results are general enough to carry over to future weak memory models. Moreover, they show that SAT solvers are adequate tools for testing.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2080658418",
    "type": "article"
  },
  {
    "title": "Exploiting replication to improve performances of NUCA-based CMP systems",
    "doi": "https://doi.org/10.1145/2566568",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Pierfrancesco Foglia; Marco Solinas",
    "corresponding_authors": "",
    "abstract": "Improvements in semiconductor nanotechnology made chip multiprocessors the reference architecture for high-performance microprocessors. CMPs usually adopt large Last-Level Caches (LLC) shared among cores and private L1 caches, whose performances depend on the wire-delay dominated response time of LLC. NUCA (NonUniform Cache Architecture) caches represent a viable solution for tolerating wire-delay effects. In this article, we present Re-NUCA, a NUCA cache that exploits replication of blocks inside the LLC to avoid performance limitations of D-NUCA caches due to conflicting access to shared data. Results show that a Re-NUCA LLC permits to improve performances of more than 5% on average, and up to 15% for applications that strongly suffer from conflicting access to shared data, while reducing network traffic and power consumption with respect to D-NUCA caches. Besides, it outperforms different S-NUCA schemes optimized with victim replication.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2089978293",
    "type": "article"
  },
  {
    "title": "A Cross-Layer Reliability Design Methodology for Efficient, Dependable Wireless Receivers",
    "doi": "https://doi.org/10.1145/2584666",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Christina Gimmler-Dumont; Norbert Wehn",
    "corresponding_authors": "",
    "abstract": "Continued progressive downscaling of CMOS technologies threatens the reliability of chips for future embedded systems. We developed a novel design methodology for dependable wireless communication systems which exploits the mutual trade-offs of system performance, hardware reliability, and implementation complexity. Our cross-layer approach combines resilience techniques on hardware level with algorithmic techniques exploiting the available flexibility in the receiver. The overhead is minimized by recovering only from those hardware errors that have a strong impact on the system behavior. We apply our new methodology on a double-iterative MIMO-BICM receiver which belongs to the most complex systems in current communication standards.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2092697329",
    "type": "article"
  },
  {
    "title": "Cooperative Data Reduction in Wireless Sensor Network",
    "doi": "https://doi.org/10.1145/2786755",
    "publication_date": "2015-12-08",
    "publication_year": 2015,
    "authors": "Shiwen Zhang; Qingquan Zhang; Sheng Xiao; Ting Zhu; Yu Gu; Yaping Lin",
    "corresponding_authors": "",
    "abstract": "In wireless sensor networks, owing to the limited energy of the sensor node, it is very meaningful to propose a dynamic scheduling scheme with data management that reduces energy as soon as possible. However, traditional techniques treat data management as an isolated process on only selected individual nodes. In this article, we propose an aggressive data reduction architecture, which is based on error control within sensor segments and integrates three parallel dynamic control mechanisms. We demonstrate that this architecture not only achieves energy savings but also guarantees the data accuracy specified by the application. Furthermore, based on this architecture, we propose two implementations. The experimental results show that both implementations can raise the energy savings while keeping the error at an predefined and acceptable level. We observed that, compared with the basic implementation, the enhancement implementation achieves a relatively higher data accuracy. Moreover, the enhancement implementation is more suitable for the harsh environmental monitoring applications. Further, when both implementations achieve the same accuracy, the enhancement implementation saves more energy. Extensive experiments on realistic historical soil temperature data confirm the efficacy and efficiency of two implementations.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2296446023",
    "type": "article"
  },
  {
    "title": "Preaveraging and Carry Propagate Approaches to Side-Channel Analysis of HMAC-SHA256",
    "doi": "https://doi.org/10.1145/2794093",
    "publication_date": "2016-02-20",
    "publication_year": 2016,
    "authors": "Catherine H. Gebotys; Brian White; Edgar Mateos",
    "corresponding_authors": "",
    "abstract": "Although HMAC-SHA has been standardized for over a decade, few published attacks on the single-cycle round implementation exist. In this research, new attack techniques are provided, for the first time, (1) to help to discriminate between values of secret intermediate variables within HMAC and (2) to reduce the large word size complexity. Preaveraging and carry propagate techniques are proposed using chosen plaintexts and shown to significantly reduce the complexity and runtimes for side-channel analysis of an Altera FPGA platform. This research is important for advancing side channel analysis of complex embedded ASICs and ensuring secure implementations in future embedded ubiquitous devices.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2312683735",
    "type": "article"
  },
  {
    "title": "BBB-CFI",
    "doi": "https://doi.org/10.1145/3371151",
    "publication_date": "2020-01-31",
    "publication_year": 2020,
    "authors": "Wenjian He; Sanjeev Das; Wei Zhang; Yang Liu",
    "corresponding_authors": "",
    "abstract": "Code-reuse attack is a concrete threat to computing systems because it can evade conventional security defenses. Control flow integrity (CFI) is proposed to repel this threat. However, former implementations of CFI suffer from two major drawbacks: complex offline processing on programs and high overheads at runtime. Therefore, it is impractical for performance-constrained devices to adopt the technology, leaving them vulnerable to exploitation. In this article, we develop a cross-layer approach named basic-block-boundary-based control flow integrity (BBB-CFI) to minimize the overheads of both offline analysis and runtime checking. Our approach employs basic block information inside the binary code and read-only data to enforce CFI. We identify a key binary-level property called basic block boundary , and based on it we propose the code-inspired method where short code sequences can endorse a control flow transition. Our solution enables quick application launching because it does not require control flow graph construction at the offline stage. We only demand a lightweight analysis on read-only data and a small amount of code of the application. According to the experiments, our approach incurs a negligible 0.11% runtime performance overhead with a minor processor extension, whereas it achieves an order of magnitude speedup in pre-preprocessing compared to a baseline approach. Without control flow analysis or recompilation, BBB-CFI still effectively reduces 90% of the attack surface in terms of gadget numbers. Besides this, we show that the Turing-completeness in the libc is unsustainable. Our approach also demonstrates high applicability to many programs, and it is capable of protecting striped binaries.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3005046538",
    "type": "article"
  },
  {
    "title": "MAGNETO",
    "doi": "https://doi.org/10.1145/3422308",
    "publication_date": "2020-12-07",
    "publication_year": 2020,
    "authors": "Omar Adel Ibrahim; Savio Sciancalepore; Gabriele Oligeri; Roberto Di Pietro",
    "corresponding_authors": "",
    "abstract": "Universal Serial Bus (USB) Flash Drives are nowadays one of the most convenient and diffused means to transfer files, especially when no Internet connection is available. However, USB flash drives are also one of the most common attack vectors used to gain unauthorized access to host devices. For instance, it is possible to replace a USB drive so that when the USB key is connected, it would install passwords stealing tools, root-kit software, and other disrupting malware. In such a way, an attacker can steal sensitive information via the USB-connected devices, as well as inject any kind of malicious software into the host. To thwart the above-cited raising threats, we propose MAGNETO, an efficient, non-interactive, and privacy-preserving framework to verify the authenticity of a USB flash drive, rooted in the analysis of its unintentional magnetic emissions. We show that the magnetic emissions radiated during boot operations on a specific host are unique for each device, and sufficient to uniquely fingerprint both the brand and the model of the USB flash drive, or the specific USB device, depending on the used equipment. Our investigation on 59 different USB flash drives---belonging to 17 brands, including the top brands purchased on Amazon in mid-2019---, reveals a minimum classification accuracy of 98.2% in the identification of both brand and model, accompanied by a negligible time and computational overhead. MAGNETO can also identify the specific USB Flash drive, with a minimum classification accuracy of 91.2%. Overall, MAGNETO proves that unintentional magnetic emissions can be considered as a viable and reliable means to fingerprint read-only USB flash drives. Finally, future research directions in this domain are also discussed.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3111004365",
    "type": "article"
  },
  {
    "title": "Two Birds With One Stone: Boosting Both Search and Write Performance for Tree Indices on Persistent Memory",
    "doi": "https://doi.org/10.1145/3476981",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Yongping Luo; Peiquan Jin; Zhou Zhang; Junchen Zhang; Bin Cheng; Qinglin Zhang",
    "corresponding_authors": "",
    "abstract": "The advance of byte-addressable persistent memory (PM) makes it a hot topic to revisit traditional tree indices such as B+-tree and radix tree, and a few new persistent memory-friendly tree indices have been proposed. However, due to the special features of persistent memory compared to DRAM and the limitations of B+-tree-like indices, it is much harder to optimize both search and write performance for tree indices on persistent memory. As a result, most existing indices for persistent memory, e.g., WB-tree, proposed to improve write performance while sacrificing search performance. Aiming to optimize both write and search performance for tree indices on persistent memory, in this paper, we first propose a novel Two-Layer Architecture (TLA) for constructing tree indices on persistent memory. The key idea, of TLA is to organize the index with a search-optimized top layer and a write-optimized bottom layer, letting the top layer optimize search performance and the bottom layer improve write performance. By adopting efficient structures for the two layers, TLA can boost both write and search performance for tree indices on persistent memory. Following the TLA architecture, we present a new index called TLBtree (Two-Layer B+-tree) offering high search and write performance for persistent memory. Moreover, we develop a concurrent TLBtree to support non-blocking read operations in multi-core environment. We evaluate our proposals under a server equipped with real Intel Optane persistent memory. The results show that TLBtree outperforms the state-of-the-art tree indices, including WB-tree, Fast&amp;Fair, and FPTree, in both search and write performance. Also, the concurrent TLBtree can achieve up to 3.7x speedup than its competitors under the multi-core environment.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3199353323",
    "type": "article"
  },
  {
    "title": "Test Generation for Hardware Trojan Detection Using Correlation Analysis and Genetic Algorithm",
    "doi": "https://doi.org/10.1145/3446837",
    "publication_date": "2021-03-26",
    "publication_year": 2021,
    "authors": "Zhendong Shi; Haocheng Ma; Qizhi Zhang; Yanjiang Liu; Yiqiang Zhao; Jiaji He",
    "corresponding_authors": "",
    "abstract": "Hardware Trojan (HT) is a major threat to the security of integrated circuits (ICs). Among various HT detection approaches, side channel analysis (SCA)-based methods have been extensively studied. SCA-based methods try to detect HTs by comparing side channel signatures from circuits under test with those from trusted golden references. The pre-condition for SCA-based HT detection to work is that the testers can collect extra signatures/anomalies introduced by activated HTs. Thus, activation of HTs and amplification of the differences between circuits under test and golden references are the keys to SCA-based HT detection methods. Test vectors are of great importance to the activation of HTs, but existing test generation methods have two major limitations. First, the number of test vectors required to trigger HTs is quite large. Second, the HT circuit’s activities are marginal compared with the whole circuit’s activities. In this article, we propose an optimized test generation methodology to assist SCA-based HT detection. Considering the HTs’ inherent surreptitious nature, inactive nodes with low transition probability are more likely to be selected as HT trigger nodes. Therefore, the correlations between circuit inputs and inactive nodes are first exploited to activate HTs. Then a test reordering process based on the genetic algorithm (GA) is implemented to increase the proportion of the HT circuit’s activities to the whole circuit’s activities. Experiments on 10 selected ISCAS benchmarks, wb_conmax benchmark, and b17 benchmark demonstrate that the number of test vectors required to trigger HTs reduces 28.8% on average compared with the result of MERO and MERS methods. After the test vector reordering process, the proportion of the HT circuit’s activities to the whole circuit’s activities is improved by 95% on average, compared with the result of MERS method.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3146111283",
    "type": "article"
  },
  {
    "title": "Thermal-aware Adaptive Platform Management for Heterogeneous Embedded Systems",
    "doi": "https://doi.org/10.1145/3477028",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Srijeeta Maity; Anirban Ghose; Soumyajit Dey; Swarnendu Biswas",
    "corresponding_authors": "",
    "abstract": "Recent trends in real-time applications have raised the demand for high-throughput embedded platforms with integrated CPU-GPU based Systems-On-Chip (SoCs). The enhanced performance of such SoCs, however, comes at the cost of increased power consumption, resulting in significant heat dissipation and high on-chip temperatures. The prolonged occurrences of high on-chip temperature can cause accelerated in-circuit ageing, which severely degrades the long-term performance and reliability of the chip. Violation of thermal constraints leads to on-board dynamic thermal management kicking-in, which may result in timing unpredictability for real-time tasks due to transient performance degradation. Recent work in adaptive software design have explored this issue from a control theoretic stand-point, striving for smooth thermal envelopes by tuning the core frequency. Existing techniques do not handle thermal violations for periodic real-time task sets in the presence of dynamic events like change of task periodicity, more so in the context of heterogeneous SoCs with integrated CPU-GPUs. This work presents an OpenCL runtime extension for thermal-aware scheduling of periodic, real-time tasks on heterogeneous multi-core platforms. Our framework mitigates dynamic thermal violations by adaptively tuning task mapping parameters, with the eventual control objective of satisfying both platform-level thermal constraints and task-level deadline constraints. We consider multiple platform-level control actions like task migration, frequency tuning and idle slot insertion as the task mapping parameters. To the best of our knowledge, this is the first work that considers such a variety of task mapping control actions in the context of heterogeneous embedded platforms. We evaluate the proposed framework on an Odroid-XU4 board using OpenCL benchmarks and demonstrate its effectiveness in reducing thermal violations.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3200470386",
    "type": "article"
  },
  {
    "title": "Horizontal Auto-Scaling for Multi-Access Edge Computing Using Safe Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3475991",
    "publication_date": "2021-10-18",
    "publication_year": 2021,
    "authors": "Kaustabha Ray; Ansuman Banerjee",
    "corresponding_authors": "",
    "abstract": "Multi-Access Edge Computing (MEC) has emerged as a promising new paradigm allowing low latency access to services deployed on edge servers to avert network latencies often encountered in accessing cloud services. A key component of the MEC environment is an auto-scaling policy which is used to decide the overall management and scaling of container instances corresponding to individual services deployed on MEC servers to cater to traffic fluctuations. In this work, we propose a Safe Reinforcement Learning (RL)-based auto-scaling policy agent that can efficiently adapt to traffic variations to ensure adherence to service specific latency requirements. We model the MEC environment using a Markov Decision Process (MDP). We demonstrate how latency requirements can be formally expressed in Linear Temporal Logic (LTL). The LTL specification acts as a guide to the policy agent to automatically learn auto-scaling decisions that maximize the probability of satisfying the LTL formula. We introduce a quantitative reward mechanism based on the LTL formula to tailor service specific latency requirements. We prove that our reward mechanism ensures convergence of standard Safe-RL approaches. We present experimental results in practical scenarios on a test-bed setup with real-world benchmark applications to show the effectiveness of our approach in comparison to other state-of-the-art methods in literature. Furthermore, we perform extensive simulated experiments to demonstrate the effectiveness of our approach in large scale scenarios.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3205650449",
    "type": "article"
  },
  {
    "title": "Federated Self-training for Semi-supervised Audio Recognition",
    "doi": "https://doi.org/10.1145/3520128",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Vasileios Tsouvalas; Aaqib Saeed; Tanır Özçelebi",
    "corresponding_authors": "",
    "abstract": "Federated Learning is a distributed machine learning paradigm dealing with decentralized and personal datasets. Since data reside on devices such as smartphones and virtual assistants, labeling is entrusted to the clients or labels are extracted in an automated way. Specifically, in the case of audio data, acquiring semantic annotations can be prohibitively expensive and time-consuming. As a result, an abundance of audio data remains unlabeled and unexploited on users’ devices. Most existing federated learning approaches focus on supervised learning without harnessing the unlabeled data. In this work, we study the problem of semi-supervised learning of audio models via self-training in conjunction with federated learning. We propose FedSTAR to exploit large-scale on-device unlabeled data to improve the generalization of audio recognition models. We further demonstrate that self-supervised pre-trained models can accelerate the training of on-device models, significantly improving convergence within fewer training rounds. We conduct experiments on diverse public audio classification datasets and investigate the performance of our models under varying percentages of labeled and unlabeled data. Notably, we show that with as little as 3% labeled data available, FedSTAR on average can improve the recognition rate by 13.28% compared to the fully supervised federated model.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3177660058",
    "type": "article"
  },
  {
    "title": "Cache Interference-aware Task Partitioning for Non-preemptive Real-time Multi-core Systems",
    "doi": "https://doi.org/10.1145/3487581",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Jun Xiao; Yixian Shen; Andy D. Pimentel",
    "corresponding_authors": "",
    "abstract": "Shared caches in multi-core processors introduce serious difficulties in providing guarantees on the real-time properties of embedded software due to the interaction and the resulting contention in the shared caches. Prior work has studied the schedulability analysis of global scheduling for real-time multi-core systems with shared caches. This article considers another common scheduling paradigm: partitioned scheduling in the presence of shared cache interference. To achieve this, we propose CITTA, a cache interference-aware task partitioning algorithm. We first analyze the shared cache interference between two programs for set-associative instruction and data caches. Then, an integer programming formulation is constructed to calculate the upper bound on cache interference exhibited by a task, which is required by CITTA. We conduct schedulability analysis of CITTA and formally prove its correctness. A set of experiments is performed to evaluate the schedulability performance of CITTA against global EDF scheduling and other greedy partition approaches such as First-fit and Worst-fit over randomly generated tasksets and realistic workloads in embedded systems. Our empirical evaluations show that CITTA outperforms global EDF scheduling and greedy partition approaches in terms of task sets deemed schedulable.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4210499125",
    "type": "article"
  },
  {
    "title": "Contention Grading and Adaptive Model Selection for Machine Vision in Embedded Systems",
    "doi": "https://doi.org/10.1145/3520134",
    "publication_date": "2022-03-26",
    "publication_year": 2022,
    "authors": "Başar Kütükçü; Sabur Baidya; Anand Raghunathan; Sujit Dey",
    "corresponding_authors": "",
    "abstract": "Real-time machine vision applications running on resource-constrained embedded systems face challenges for maintaining performance. An especially challenging scenario arises when multiple applications execute at the same time, creating contention for the computational resources of the system. This contention results in increase in inference delay of the machine vision applications, which can be unacceptable for time-critical tasks. To address this challenge, we propose an adaptive model selection framework that mitigates the impact of system contention and prevents unexpected increases in inference delay by trading off the application accuracy minimally. The framework has two parts, which are performed pre-deployment and at runtime. The pre-deployment part profiles the system for contention in a black-box manner and produces a model set that is specifically optimized for the contention levels observed in the system. The runtime part predicts the inference delays of each model considering the system contention and selects the best model according to the predictions for each frame. Compared to a fixed individual model with similar accuracy, our framework improves the performance by significantly reducing the inference delay violations against a specified threshold. We implement our framework on the Nvidia Jetson TX2 platform and show that our approach achieves greater than 20% reductions in delay violations over the individual baseline models.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4220807708",
    "type": "article"
  },
  {
    "title": "FARSI: An Early-stage Design Space Exploration Framework to Tame the Domain-specific System-on-chip Complexity",
    "doi": "https://doi.org/10.1145/3544016",
    "publication_date": "2022-06-16",
    "publication_year": 2022,
    "authors": "Behzad Boroujerdian; Ying Jing; Devashree Tripathy; Amit Kumar; Lavanya Subramanian; Luke Yen; Vincent T. Lee; Vivek Venkatesan; Amit Kumar Jindal; Robert Shearer; Vijay Janapa Reddi",
    "corresponding_authors": "",
    "abstract": "Domain-specific SoCs (DSSoCs) are an attractive solution for domains with extremely stringent power, performance, and area constraints. However, DSSoCs suffer from two fundamental complexities. On the one hand, their many specialized hardware blocks result in complex systems and thus high development effort. On the other hand, their many system knobs expand the complexity of design space, making the search for the optimal design difficult. Thus to reach prevalence, taming such complexities is necessary. To address these challenges, in this work, we identify the necessary features of an early-stage design space exploration framework that targets the complex design space of DSSoCs and provide an instance of one such framework that we refer to as FARSI. FARSI provides an agile system-level simulator with speed up and accuracy of 8,400× and 98.5% compared to Synopsys Platform Architect. FARSI also provides an efficient exploration heuristic and achieves up to 62× and 35× improvement in convergence time compared to the classic simulated annealing (SA) and modern Multi-Objective Optimistic Search. This is done by augmenting SA with architectural reasoning such as locality exploitation and bottleneck relaxation. Furthermore, we embed various co-design capabilities and show that, on average, they have a 32% impact on the convergence rate. Finally, we demonstrate that using development-cost-aware policies can lower the system complexity, both in terms of the component count and variation by as much as 60% and 82% (e.g., for Network-on-a-Chip subsystem), respectively.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4282983059",
    "type": "article"
  },
  {
    "title": "ETAP: Energy-aware Timing Analysis of Intermittent Programs",
    "doi": "https://doi.org/10.1145/3563216",
    "publication_date": "2022-09-15",
    "publication_year": 2022,
    "authors": "Ferhat Erata; Eren Yıldız; Arda Göknil; Kasım Sinan Yıldırım; Jakub Szefer; Ružica Piskač; Gökçin Sezgin",
    "corresponding_authors": "",
    "abstract": "Energy harvesting battery-free embedded devices rely only on ambient energy harvesting that enables stand-alone and sustainable IoT applications. These devices execute programs when the harvested ambient energy in their energy reservoir is sufficient to operate and stop execution abruptly (and start charging) otherwise. These intermittent programs have varying timing behavior under different energy conditions, hardware configurations, and program structures. This paper presents Energy-aware Timing Analysis of intermittent Programs (ETAP), a probabilistic symbolic execution approach that analyzes the timing and energy behavior of intermittent programs at compile time. ETAP symbolically executes the given program while taking time and energy cost models for ambient energy and dynamic energy consumption into account. We evaluated ETAP on several intermittent programs and compared the compile-time analysis results with executions on real hardware. The results show that ETAP's normalized prediction accuracy is 99.5%, and it speeds up the timing analysis by at least two orders of magnitude compared to manual testing.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4295925151",
    "type": "article"
  },
  {
    "title": "Trireme: Exploration of Hierarchical Multi-level Parallelism for Hardware Acceleration",
    "doi": "https://doi.org/10.1145/3580394",
    "publication_date": "2023-01-17",
    "publication_year": 2023,
    "authors": "Georgios Zacharopoulos; Adel Ejjeh; Ying Jing; En-Yu Yang; Tianyu Jia; Iulian Brumar; Jeremy Intan; Muhammad Huzaifa; Sarita V. Adve; Vikram Adve; Gu-Yeon Wei; David Brooks",
    "corresponding_authors": "",
    "abstract": "The design of heterogeneous systems that include domain specific accelerators is a challenging and time-consuming process. While taking into account area constraints, designers must decide which parts of an application to accelerate in hardware and which to leave in software. Moreover, applications in domains such as Extended Reality (XR) offer opportunities for various forms of parallel execution, including loop level, task level, and pipeline parallelism. To assist the design process and expose every possible level of parallelism, we present Trireme , a fully automated tool-chain that explores multiple levels of parallelism and produces domain-specific accelerator designs and configurations that maximize performance, given an area budget. FPGA SoCs were used as target platforms, and Catapult HLS [ 7 ] was used to synthesize RTL using a commercial 12 nm FinFET technology. Experiments on demanding benchmarks from the XR domain revealed a speedup of up to 20×, as well as a speedup of up to 37× for smaller applications, compared to software-only implementations.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4316813671",
    "type": "article"
  },
  {
    "title": "Formal Synthesis of Neural Barrier Certificates for Continuous Systems via Counterexample Guided Learning",
    "doi": "https://doi.org/10.1145/3609125",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Hanrui Zhao; Niuniu Qi; Lydia Dehbi; Xia Zeng; Zhengfeng Yang",
    "corresponding_authors": "",
    "abstract": "This paper presents a novel approach to safety verification based on neural barrier certificates synthesis for continuous dynamical systems. We construct the synthesis framework as an inductive loop between a Learner and a Verifier based on barrier certificate learning and counterexample guidance. Compared with the counterexample-guided verification method based on the SMT solver, we design and learn neural barrier functions with special structure, and use the special form to convert the counterexample generation into a polynomial optimization problem for obtaining the optimal counterexample. In the verification phase, the task of identifying the real barrier certificate can be tackled by solving the Linear Matrix Inequalities (LMI) feasibility problem, which is efficient and makes the proposed method formally sound. The experimental results demonstrate that our approach is more effective and practical than the traditional SOS-based barrier certificates synthesis and the state-of-the-art neural barrier certificates learning approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4386568800",
    "type": "article"
  },
  {
    "title": "DTRL: Decision Tree-based Multi-Objective Reinforcement Learning for Runtime Task Scheduling in Domain-Specific System-on-Chips",
    "doi": "https://doi.org/10.1145/3609108",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Toygun Başaklar; A. Alper Goksoy; Anish Krishnakumar; Suat Gümüşsoy; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "Domain-specific systems-on-chip (DSSoCs) combine general-purpose processors and specialized hardware accelerators to improve performance and energy efficiency for a specific domain. The optimal allocation of tasks to processing elements (PEs) with minimal runtime overheads is crucial to achieving this potential. However, this problem remains challenging as prior approaches suffer from non-optimal scheduling decisions or significant runtime overheads. Moreover, existing techniques focus on a single optimization objective, such as maximizing performance. This work proposes DTRL, a decision-tree-based multi-objective reinforcement learning technique for runtime task scheduling in DSSoCs. DTRL trains a single global differentiable decision tree (DDT) policy that covers the entire objective space quantified by a preference vector. Our extensive experimental evaluations using our novel reinforcement learning environment demonstrate that DTRL captures the trade-off between execution time and power consumption, thereby generating a Pareto set of solutions using a single policy. Furthermore, comparison with state-of-the-art heuristic–, optimization–, and machine learning-based schedulers shows that DTRL achieves up to 9× higher performance and up to 3.08× reduction in energy consumption. The trained DDT policy achieves 120 ns inference latency on Xilinx Zynq ZCU102 FPGA at 1.2 GHz, resulting in negligible runtime overheads. Evaluation on the same hardware shows that DTRL achieves up to 16% higher performance than a state-of-the-art heuristic scheduler.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4386568841",
    "type": "article"
  },
  {
    "title": "<scp>ObNoCs</scp> : Protecting Network-on-Chip Fabrics Against Reverse-Engineering Attacks",
    "doi": "https://doi.org/10.1145/3609107",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Dipal Halder; Maneesh Merugu; Sandip Ray",
    "corresponding_authors": "",
    "abstract": "Modern System-on-Chip designs typically use Network-on-Chip (NoC) fabrics to implement coordination among integrated hardware blocks. An important class of security vulnerabilities involves a rogue foundry reverse-engineering the NoC topology and routing logic. In this paper, we develop an infrastructure, ObNoCs , for protecting NoC fabrics against such attacks. ObNoCs systematically replaces router connections with switches that can be programmed after fabrication to induce the desired topology. Our approach provides provable redaction of NoC functionality: switch configurations induce a large number of legal topologies, only one of which corresponds to the intended topology. We implement the ObNoCs methodology on Intel Quartus™ Platform, and experimental results on realistic SoC designs show that the architecture incurs minimal overhead in power, resource utilization, and system latency.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4386569057",
    "type": "article"
  },
  {
    "title": "Enabling Binary Neural Network Training on the Edge",
    "doi": "https://doi.org/10.1145/3626100",
    "publication_date": "2023-10-04",
    "publication_year": 2023,
    "authors": "Erwei Wang; James J. Davis; Daniele Moro; Piotr Zieliński; Jia Jie Lim; Claudionor Coelho; Satrajit Chatterjee; Peter Y. K. Cheung; George A. Constantinides",
    "corresponding_authors": "",
    "abstract": "The ever-growing computational demands of increasingly complex machine learning models frequently necessitate the use of powerful cloud-based infrastructure for their training. Binary neural networks are known to be promising candidates for on-device inference due to their extreme compute and memory savings over higher-precision alternatives. However, their existing training methods require the concurrent storage of high-precision activations for all layers, generally making learning on memory-constrained devices infeasible. In this article, we demonstrate that the backward propagation operations needed for binary neural network training are strongly robust to quantization, thereby making on-the-edge learning with modern models a practical proposition. We introduce a low-cost binary neural network training strategy exhibiting sizable memory footprint reductions while inducing little to no accuracy loss vs Courbariaux &amp; Bengio’s standard approach. These decreases are primarily enabled through the retention of activations exclusively in binary format. Against the latter algorithm, our drop-in replacement sees memory requirement reductions of 3–5×, while reaching similar test accuracy (± 2 pp) in comparable time, across a range of small-scale models trained to classify popular datasets. We also demonstrate from-scratch ImageNet training of binarized ResNet-18, achieving a 3.78× memory reduction. Our work is open-source, and includes the Raspberry Pi-targeted prototype we used to verify our modeled memory decreases and capture the associated energy drops. Such savings will allow for unnecessary cloud offloading to be avoided, reducing latency, increasing energy efficiency, and safeguarding end-user privacy.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4387344527",
    "type": "article"
  },
  {
    "title": "Compact Instruction Set Extensions for Dilithium",
    "doi": "https://doi.org/10.1145/3643826",
    "publication_date": "2024-02-02",
    "publication_year": 2024,
    "authors": "Lu Li; Qi Tian; Guofeng Qin; Shuaiyu Chen; Weijia Wang",
    "corresponding_authors": "",
    "abstract": "Post-quantum cryptography is considered to provide security against both traditional and quantum computer attacks. Dilithium is a digital signature algorithm that derives its security from the challenge of finding short vectors in lattices. It has been selected as one of the standardizations in the NIST post-quantum cryptography project. Hardware-software co-design is a commonly adopted implementation strategy to address various implementation challenges, including limited resources, high performance, and flexibility requirements. In this study, we investigate using compact instruction set extensions (ISEs) for Dilithium, aiming to improve software efficiency with low hardware overheads. To begin with, we propose tightly coupled accelerators that are deeply integrated into the RISC-V processor. These accelerators target the most computationally demanding components in resource-constrained processors, such as polynomial generation, Number Theoretic Transform (NTT), and modular arithmetic. Next, we design a set of custom instructions that seamlessly integrate with the RISC-V base instruction formats, completing the accelerators in a compact manner. Subsequently, we implement our ISEs in a chip design for the Hummingbird E203 core and conduct performance benchmarks for Dilithium utilizing these ISEs. Additionally, we evaluate the resource consumption of the ISEs on FPGA and ASIC technologies. Compared to the reference software implementation on the RISC-V core, our co-design demonstrates a remarkable speedup factor ranging from 6.95 to 9.96. This significant improvement in performance is achieved by incorporating additional hardware resources, specifically, a 35% increase in LUTs, a 14% increase in FFs, 7 additional DSPs, and no additional RAM. Furthermore, compared to the state-of-the-art approach, our work achieves faster speed performance with a reduced circuit cost. Specifically, the usage of additional LUTs, FFs, and RAMs is reduced by 47.53%, 50.43%, and 100%, respectively. On ASIC technology, our approach demonstrates 12, 412 cell counts. Our co-design provides a better tradeoff implementation on speed performance and circuit overheads.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4391473781",
    "type": "article"
  },
  {
    "title": "Implementing Privacy Homomorphism with Random Encoding and Computation Controlled by a Remote Secure Server",
    "doi": "https://doi.org/10.1145/3651617",
    "publication_date": "2024-03-08",
    "publication_year": 2024,
    "authors": "Kevin Hutto; Vincent J. Mooney",
    "corresponding_authors": "",
    "abstract": "Remote IoT devices face significant security risks due to their inherent physical vulnerability. An adversarial actor with sufficient capability can monitor the devices or exfiltrate data to access sensitive information. Remotely deployed devices such as sensors need enhanced resilience against memory leakage if performing privileged tasks. To increase the security and trust of these devices we present a novel framework implementing a privacy homomorphism which creates sensor data directly in an encoded format. The sensor data is permuted at the time of creation in a manner which appears random to an observer. A separate secure server in communication with the device provides necessary information which allows the device to perform processing on the encoded data but does not allow decoding of the result. The device transmits the encoded results to the secure server which maintains the ability to interpret the results. In this paper we show how this framework works for an image sensor calculating differences between a stream of images, with initial results showing an overhead as low as only 266% in terms of throughput when compared to computing on standard unencoded numbers such as two’s complement. We further show 5,000x speedup over a recent homomorphic encryption ASIC.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4392595463",
    "type": "article"
  },
  {
    "title": "On-device Online Learning and Semantic Management of TinyML Systems",
    "doi": "https://doi.org/10.1145/3665278",
    "publication_date": "2024-05-16",
    "publication_year": 2024,
    "authors": "Haoyu Ren; Darko Anicic; Xue Li; Thomas A. Runkler",
    "corresponding_authors": "",
    "abstract": "Recent advances in Tiny Machine Learning (TinyML) empower low-footprint embedded devices for real-time on-device Machine Learning (ML). While many acknowledge the potential benefits of TinyML, its practical implementation presents unique challenges. This study aims to bridge the gap between prototyping single TinyML models and developing reliable TinyML systems in production: (1) Embedded devices operate in dynamically changing conditions. Existing TinyML solutions primarily focus on inference, with models trained offline on powerful machines and deployed as static objects. However, static models may underperform in the real world due to evolving input data distributions. We propose online learning to enable training on constrained devices, adapting local models toward the latest field conditions. (2) Nevertheless, current on-device learning methods struggle with heterogeneous deployment conditions and the scarcity of labeled data when applied across numerous devices. We introduce federated meta-learning incorporating online learning to enhance model generalization, facilitating rapid learning. This approach ensures optimal performance among distributed devices by knowledge sharing. (3) Moreover, TinyML’s pivotal advantage is widespread adoption. Embedded devices and TinyML models prioritize extreme efficiency, leading to diverse characteristics ranging from memory and sensors to model architectures. Given their diversity and non-standardized representations, managing these resources becomes challenging as TinyML systems scale up. We present semantic management for the joint management of models and devices at scale. We demonstrate our methods through a basic regression example and then assess them in three real-world TinyML applications: handwritten character image classification, keyword audio classification, and smart building presence detection. The results confirm the effectiveness of our approaches from various perspectives, such as accuracy improvement, resource savings, and engineering effort reduction.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4396976427",
    "type": "article"
  },
  {
    "title": "LiteHash: Hash Functions for Resource-Constrained Hardware",
    "doi": "https://doi.org/10.1145/3677181",
    "publication_date": "2024-07-09",
    "publication_year": 2024,
    "authors": "Sagar Dev Achar; P Thejaswini; Sukumar Nandi; Sunit Kumar Nandi",
    "corresponding_authors": "",
    "abstract": "The global paradigm shift towards edge computing has led to a growing demand for efficient integrity verification. Hash functions are one-way algorithms which act as a zero-knowledge proof of a datum’s contents. However, it is infeasible to compute hashes on devices with limited processing power and memory. Hence, we propose four novel LiteHash functions which are architecturally similar to SHA-512 yet simpler. By using various approximation techniques, our implementations reduce the computational costs of digesting a message into a hash. On validating our proposed designs using the NIST PRNG Test Suite, we observe SHA-512 equivalent cryptographic security while satisfying all desired hash function property requirements. We observe a minimum of 9.41% reduction in area, 20.47% reduction in power and 22.05% increase in throughput. Our designs offer a throughput of upto 2 Gbps while reducing area and power by a maximum of 16.86% and 32.48% respectively. LiteHash functions also support the computation of the entire SHA-2 family of hash functions (SHA-224/256/384/512) with minor architectural modifications.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4400460456",
    "type": "article"
  },
  {
    "title": "OASIS: Optimized Adaptive System for Intelligent SLAM",
    "doi": "https://doi.org/10.1145/3761808",
    "publication_date": "2025-08-15",
    "publication_year": 2025,
    "authors": "Alles Rebel; Nikil Dutt; Bryan Donyanavard",
    "corresponding_authors": "",
    "abstract": "Visual Simultaneous Localization and Mapping (VSLAM) is essential for mobile autonomous systems operating in complex dynamic environments. VSLAM algorithms are computationally intensive and must execute in real-time on resource-constrained embedded devices. Variations in environmental complexity can lead to longer frame processing times, causing dropped frames, lost localization information, and degraded accuracy. To address these challenges, we introduce OASIS, a novel adaptive approximation method that dynamically reduces input frame areas based on realtime visual importance. Unlike traditional optimizations that require adjusting internal SLAM parameters, OASIS selectively minimizes computation by adaptively filtering less critical image regions, significantly reducing computational load. Evaluations on the EuRoC MAV dataset demonstrate that our approach balances accuracy and system predictability, achieving up to a 71.8% reduction in worst-case pose estimation errors. OASIS offers a significant advancement in reliable, predictable, and energy-efficient SLAM tailored for mobile autonomous robotic applications.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413381054",
    "type": "article"
  },
  {
    "title": "Design of secure cryptography against the threat of power-attacks in DSP-embedded processors",
    "doi": "https://doi.org/10.1145/972627.972632",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Catherine H. Gebotys",
    "corresponding_authors": "Catherine H. Gebotys",
    "abstract": "Embedded wireless devices require secure high-performance cryptography in addition to low-cost and low-energy dissipation. This paper presents for the first time a design methodology for security on a VLIW complex DSP-embedded processor core. Elliptic curve cryptography is used to demonstrate the design for security methodology. Results are verified with real dynamic power measurements and show that compared to previous research a 79% improvement in performance is achieved. Modification of power traces are performed to resist simple power analysis attack with up to 39% overhead in performance, up to 49% overheads in energy dissipation, and up to 11% overhead in code size. Simple power analysis on the VLIW DSP core is shown to be more correlated to routine ordering than individual instructions. For the first time, differential power analysis results on a VLIW using real power measurements are presented. Results show that the processor instruction level parallelism and large bus size contribute in making differential power analysis attacks extremely difficult. This research is important for industry since efficient yet secure cryptography is crucial for wireless communication devices.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2010738008",
    "type": "article"
  },
  {
    "title": "Synthesis of application-specific highly efficient multi-mode cores for embedded systems",
    "doi": "https://doi.org/10.1145/1053271.1053278",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Lih‐Yih Chiou; Swarup Bhunia; Kaushik Roy",
    "corresponding_authors": "",
    "abstract": "In this paper, we present a novel design methodology for synthesizing multiple configurations (or modes) into a single programmable core that can be used in embedded systems. Recent portable applications require reconfigurability of a system along with efficiency in terms of power, performance, and area. The field programmable gate arrays (FPGAs) provide a reconfigurable platform; however, they are slower in speed with significantly higher power and area than achievable by a customized application-specific integrated circuits (ASIC). Implementation of a system in either FPGA or ASIC represents a trade-off between programmability and design efficiency. In this work, we have developed techniques to realize efficient reconfigurable cores for a set of user-specified applications. The resultant system, named as multimode system, can easily switch configurations throughout the set of configurations it is designed for. A data flow graph transformation method coupled with efficient scheduling and allocation is used to automatically synthesize a Multi-Mode system from its behavior-level specifications. Experimental results on several applications demonstrate that our implementations can achieve about 60X power reduction on average and run 3.5X faster over corresponding FPGA implementations.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2053661496",
    "type": "article"
  },
  {
    "title": "Energy-efficient, utility accrual scheduling under resource constraints for mobile embedded systems",
    "doi": "https://doi.org/10.1145/1165780.1165781",
    "publication_date": "2006-08-01",
    "publication_year": 2006,
    "authors": "Haisang Wu; Binoy Ravindran; E. Douglas Jensen; Peng Li",
    "corresponding_authors": "",
    "abstract": "We present an energy-efficient, utility accrual, real-time scheduling algorithm called ReUA. ReUA considers an application model where activities are subject to time/utility function time constraints, mutual exclusion constraints on shared non-CPU resources, and statistical performance requirements on individual activity timeliness behavior. The algorithm targets mobile embedded systems where system-level energy consumption is also a major concern. For such a model, we consider the scheduling objectives of (1) satisfying the statistical performance requirements and (2) maximizing the system-level energy efficiency, while respecting resource constraints. Since the problem is NP-hard, ReUA allocates CPU cycles using statistical properties of application cycle demands, and heuristically computes schedules with a polynomial time cost. We analytically establish several timeliness and nontimeliness properties of the algorithm. Further, our simulation experiments illustrate ReUA's effectiveness and superiority.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1997537897",
    "type": "article"
  },
  {
    "title": "Exploiting synchronous and asynchronous DVS for feedback EDF scheduling on an embedded platform",
    "doi": "https://doi.org/10.1145/1324969.1324972",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Yifan Zhu; Frank Mueller",
    "corresponding_authors": "",
    "abstract": "Contemporary processors support dynamic voltage scaling (DVS) to reduce power consumption by varying processor voltage/frequency dynamically. We develop power-aware feedback--DVS algorithms for hard real-time systems that adapt to dynamically changing workloads. The algorithms lower execution speed while guaranteeing timing constraints. We study energy consumption for synchronous and asynchronous DVS switching on a PowerPC board. Energy, measured via data acquisition, is reduced up to 70% over naïve DVS for our feedback scheme with 24% peak savings over previous algorithms. These results, albeit differing in quantity, confirm trends observed under simulation. They are the first of their kind on an embedded board.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2128589366",
    "type": "article"
  },
  {
    "title": "EM analysis of a wireless Java-based PDA",
    "doi": "https://doi.org/10.1145/1376804.1376812",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Catherine H. Gebotys; Brian White",
    "corresponding_authors": "",
    "abstract": "The susceptibility of wireless portable devices to electromagnetic (EM) attacks is largely unknown. If analysis of electromagnetic (EM) waves emanating from the wireless device during a cryptographic computation do leak sufficient information, it may be possible for an attacker to reconstruct the secret key. Possession of the secret cryptographic key would render all future wireless communications insecure and cause further potential problems, such as identity theft. Despite the complexities of a PDA wireless device, such as operating system events, interrupts, cache misses, and other interfering events, this article demonstrates that, for the first time, repeatable EM differential attacks are possible. The proposed differential analysis methodology involves precharacterization of the PDA device (thresholding and pattern recognition), and a new frequency-based differential analysis. Unlike previous research, the new methodology does not require perfect alignment of EM frames and is repeatable in the presence of a complex embedded system (including cache misses, operating system events, etc), thus supporting attacks on real embedded systems. This research is important for future wireless embedded systems, which will increasingly demand higher levels of security.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1982525829",
    "type": "article"
  },
  {
    "title": "Buffer optimization in multitask implementations of Simulink models",
    "doi": "https://doi.org/10.1145/1347375.1347376",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Marco Di Natale; Valerio Pappalardo",
    "corresponding_authors": "",
    "abstract": "Automatic generation of a controller implementation from a synchronous reactive model is among the best practices for software development in the automotive and aeronautics industry, because of the possibility of simulation, model checking, and error-free implementation. This paper discusses an algorithm for optimizing the single-processor multitask implementation of Simulink models with real-time execution constraints, derived from the sampling rates of the functional blocks. Existing code generation tools enforce the addition of extra buffering and latencies whenever there is a rate transition among functional blocks. This work shows how timing analysis can be used to find the cases in which additional buffering and latency can be avoided, improving the space and time performance of the application. The proposed search algorithm allows finding a solution with reduced and possibly minimal use of buffering even for very high values of processor utilization.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2059274931",
    "type": "article"
  },
  {
    "title": "Iterational retiming with partitioning",
    "doi": "https://doi.org/10.1145/1698772.1698780",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Chun Jason Xue; Jingtong Hu; Zili Shao; Edwin H.‐M. Sha",
    "corresponding_authors": "",
    "abstract": "The widening gap between processor and memory performance is the main bottleneck for modern computer systems to achieve high processor utilization. To hide memory latency, a variety of techniques have been proposed—from intermediate fast memories (caches) to various prefetching and memory management techniques. In this article, we propose a new loop scheduling with memory management technique, Iterational Retiming with Partitioning (IRP), that can completely hide memory latencies for applications with multidimensional loops on architectures like CELL processor. In IRP, the iteration space is first partitioned carefully. Then a two-part schedule, consisting of processor and memory parts, is produced such that the execution time of the memory part never exceeds the execution time of the processor part. These two parts are executed simultaneously and complete memory latency hiding is reached. In this article, we prove that such optimal two-part schedule can always be achieved given the right partition size and shape. Experiments on DSP benchmarks show that IRP consistently produces optimal solutions as well as significant improvement over previous techniques.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W1965084585",
    "type": "article"
  },
  {
    "title": "Attack-tolerant localization via iterative verification of locations in sensor networks",
    "doi": "https://doi.org/10.1145/1457246.1457248",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Taejoon Park; Kang G. Shin",
    "corresponding_authors": "",
    "abstract": "In sensor networks, secure localization—determining sensors' locations in a hostile, untrusted environment—is a challenging, but very important, problem that has not yet been addressed effectively. This paper presents an attack-tolerant localization protocol, called Verification for Iterative Localization (VeIL), under which sensors cooperatively safeguard the localization service. By exploiting the high spatiotemporal correlation existing between adjacent nodes, VeIL realizes (a) adaptive management of a profile for normal localization behavior, and (b) distributed detection of false locations advertised by attackers by comparing them against the profile of normal behavior. Our analysis and simulation results show that VeIL achieves high-level tolerance to many critical attacks, and is computationally feasible on resource-limited sensors.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2040532716",
    "type": "article"
  },
  {
    "title": "Analysis of SystemC actor networks for efficient synthesis",
    "doi": "https://doi.org/10.1145/1880050.1880054",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Joachim Falk; Christian Zebelein; Joachim Keinert; Christian Haubelt; Jüergen Teich; Shuvra S. Bhattacharyya",
    "corresponding_authors": "",
    "abstract": "Applications in the signal processing domain are often modeled by dataflow graphs. Due to heterogeneous complexity requirements, these graphs contain both dynamic and static dataflow actors. In previous work, we presented a generalized clustering approach for these heterogeneous dataflow graphs in the presence of unbounded buffers. This clustering approach allows the application of static scheduling methodologies for static parts of an application during embedded software generation for multiprocessor systems. It systematically exploits the predictability and efficiency of the static dataflow model to obtain latency and throughput improvements. In this article, we present a generalization of this clustering technique to dataflow graphs with bounded buffers, therefore enabling synthesis for embedded systems without dynamic memory allocation. Furthermore, a case study is given to demonstrate the performance benefits of the approach.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W1970832884",
    "type": "article"
  },
  {
    "title": "Analytic modeling of network processors for parallel workload mapping",
    "doi": "https://doi.org/10.1145/1509288.1509290",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Ning Weng; Tilman Wolf",
    "corresponding_authors": "",
    "abstract": "Network processors are heterogeneous system-on-chip multiprocessors that are optimized to perform packet forwarding and processing tasks at Gigabit data rates. To meet the performance demands of increasing link speeds and complex network applications, network processors are implemented with several dozen embedded processor cores and hardware accelerators that run multiple packet processing applications in parallel. The parallel nature of the processing system makes it increasingly difficult for application developers to understand and manage resources and map processing tasks to the hardware. To address this problem, we present a methodology for profiling and analyzing network processor applications, mapping processing tasks to a generalized network processor architecture, and analytically determining the expected throughput performance. The key novelty of this work is not only the adaptation of application analysis and mapping algorithms to heterogeneous network processors, but also that the entire process can be automated and hidden from the application developer. Starting with the analysis of a uniprocessor implementation of the application, the process yields a mapping of the partitioned application that shows best performance for a given network processor system. The simplicity of the proposed randomized mapping algorithm allows the use of this methodology in network processor runtime systems where dynamic reallocation of tasks is necessary but processing power is limited. We present results that show the effectiveness of the analysis and mapping methodology as well as its application to design space exploration.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W1980478243",
    "type": "article"
  },
  {
    "title": "Scratchpad memory allocation for data aggregates via interval coloring in superperfect graphs",
    "doi": "https://doi.org/10.1145/1880050.1880064",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Lian Li; Jingling Xue; Jens Knoop",
    "corresponding_authors": "",
    "abstract": "Existing methods place data or code in scratchpad memory (SPM) by relying on heuristics or resorting to integer programming or mapping it to a graph-coloring problem. In this article, the SPM allocation problem for arrays is formulated as an interval coloring problem. The key observation is that in many embedded C programs, two arrays can be modeled such that either their live ranges do not interfere or one contains the other (with good accuracy). As a result, array interference graphs often form a special class of superperfect graphs (known as comparability graphs), and their optimal interval colorings become efficiently solvable. This insight has led to the development of an SPM allocation algorithm that places arrays in an interference graph in SPM by examining its maximal cliques. If the SPM is no smaller than the clique number of an interference graph, then all arrays in the graph can be placed in SPM optimally. Otherwise, we rely on containment-motivated heuristics to split or spill array live ranges until the resulting graph is optimally colorable. We have implemented our algorithm in SUIF/machSUIF and evaluated it using a set of embedded C benchmarks from MediaBench and MiBench. Compared to a graph-coloring algorithm and an optimal ILP algorithm (when it runs to completion), our algorithm achieves close-to-optimal results and is superior to graph coloring for the benchmarks tested.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2003028733",
    "type": "article"
  },
  {
    "title": "A comparison of software platforms for wireless sensor networks",
    "doi": "https://doi.org/10.1145/1457255.1457264",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Mohammad Mozumdar; Luciano Lavagno; Laura Vanzago",
    "corresponding_authors": "",
    "abstract": "Wireless sensor networks are characterized by very tight code size and power constraints and by a lack of well-established standard software development platforms such as Posix. In this article, we present a comparative study between a few fairly different such platforms, namely MANTIS, TinyOS, and ZigBee, when considering them from the application developer's perspective, that is, by focusing mostly on functional aspects, rather than on performance or code size. In other words, we compare both the tasking model used by these platforms and the API libraries they offer. Sensor network applications are basically event based, so most of the software platforms are also built on considering event handling mechanism, however some use a more traditional thread based model. In this article, we consider implementations of a simple generic application in MANTIS, TinyOS, and the Ember ZigBee development framework, with the goal of depicting major differences between these platforms, and suggesting a programming style aimed at maximizing portability between them.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2071123501",
    "type": "article"
  },
  {
    "title": "Fast multidimension multichoice knapsack heuristic for MP-SoC runtime management",
    "doi": "https://doi.org/10.1145/1952522.1952528",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "C. Ykman-Couvreur; V. Nollet; F. Catthoor; Henk Corporaal",
    "corresponding_authors": "",
    "abstract": "Since the application complexity is growing and applications can be dynamically activated, the major challenge for heterogeneous multiprocessor platforms is to select at runtime an energy-efficient mapping of these applications. Taking into account that many different possible implementations per application can be available, and that the selection must meet the application deadlines under the available platform resources, this runtime optimization problem can be modeled as a Multidimension Multichoice Knapsack Problem (MMKP), which is known to be NP-hard. Not only algorithms for an optimal solution, but also state-of-the-art heuristics for real-time systems are still too slow for runtime management of multiprocessor platforms. This article provides a new fast and lightweight heuristic for finding near-optimal solutions for MMKP problems. The main contribution of this heuristic is: (i) the Pareto filtering of each initial MMKP set to reduce the search space, (ii) the sorting of all Pareto points together in a single two-dimension search space, where (iii) a very fast greedy algorithm solves the MMKP. Experiments show that our heuristic finds solutions close (within 0% to 0.4%) to the ones obtained by the fastest state-of-the-art heuristics, in just a fraction of the execution time (more than 97.5% gain on a StrongARM processor) and can run in less than 1ms for multiprocessor problem sizes. This is required for realistic OS reaction times in video and wireless application sets.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1989650455",
    "type": "article"
  },
  {
    "title": "Parametric timing analysis and its application to dynamic voltage scaling",
    "doi": "https://doi.org/10.1145/1880050.1880061",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Sibin Mohan; Frank Mueller; Michael Root; William Hawkins; Christopher Healy; David Whalley; Emilio Vivancos",
    "corresponding_authors": "",
    "abstract": "Embedded systems with real-time constraints depend on a priori knowledge of worst-case execution times (WCETs) to determine if tasks meet deadlines. Static timing analysis derives bounds on WCETs but requires statically known loop bounds. This work removes the constraint on known loop bounds through parametric analysis expressing WCETs as functions. Tighter WCETs are dynamically discovered to exploit slack by dynamic voltage scaling (DVS) saving 60% to 82% energy over DVS-oblivious techniques and showing savings close to more costly dynamic-priority DVS algorithms. Overall, parametric analysis expands the class of real-time applications to programs with loop-invariant dynamic loop bounds while retaining tight WCET bounds.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2009782718",
    "type": "article"
  },
  {
    "title": "Automatic Synthesis of Switching Controllers for Linear Hybrid Systems",
    "doi": "https://doi.org/10.1145/3047500",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Massimo Benerecetti; Marco Faella",
    "corresponding_authors": "",
    "abstract": "We consider the problem of computing the controllable region of a Linear Hybrid Automaton with controllable and uncontrollable transitions, w.r.t. a reachability objective. We provide an algorithm for the finite-horizon version of the problem, based on computing the set of states that must reach a given non-convex polyhedron while avoiding another one, subject to a polyhedral constraint on the slope of the trajectory. Experimental results are presented, based on an implementation of the proposed algorithm on top of the tool SpaceEx.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1964723886",
    "type": "article"
  },
  {
    "title": "QUKU",
    "doi": "https://doi.org/10.1145/2435227.2435259",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Neil Bergmann; Sunil Shukla; Jürgen Becker",
    "corresponding_authors": "",
    "abstract": "A new architecture, QUKU, is proposed for implementing stream-based algorithms on FPGAs, which combines the advantages of FPGA and Coarse Grain Reconfigurable Arrays (CGRAs). QUKU consists of a dynamically reconfigurable, coarse-grain Processing Element (PE) array with an associated softcore processor providing system support. At a coarse-grain, the PE array can be reconfigured on a cycle-by-cycle basis to change the PE functionality similarly to that in a conventional CGRA. At a fine-grain, the whole FPGA can be reconfigured statically to implement a completely different PE array that serves the target application in a better way. Advantages of the fine-grain reconfiguration include individually customized PEs, adaptable numeric format support and customizable interconnect network. A prototype CAD tool framework is also developed which facilitates programming the QUKU architecture. An example application consisting of two different image detectors is implemented to demonstrate the advantages of QUKU. QUKU provides up to 140 times speedup and 40 times improvement in area-time product compared to an implementation running on an FPGA-based softcore. The area-time product for QUKU is around 16% lower than that of a custom circuit based implementation on the same FPGA. The per-PE customization provides an area-time saving of approximately 31% compared to a homogeneous 4 × 4 array of PEs for the same application. The experimental results demonstrate that a dual layered reconfigurable architecture provides significant potential benefits in terms of flexibility, area and processing efficiency over existing reconfigurable computing architectures for DSP.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1971086750",
    "type": "article"
  },
  {
    "title": "Using Auxiliary Sensors for Pairwise Key Establishment in WSN",
    "doi": "https://doi.org/10.1145/2345770.2345771",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Qi Dong; Donggang Liu",
    "corresponding_authors": "",
    "abstract": "Many techniques have been developed recently for establishing pairwise keys in sensor networks. However, some of them are vulnerable to a few compromised sensor nodes, while others could involve expensive protocols for establishing keys. This article introduces a much better alternative that can achieve both high resilience to node compromises and high efficiency in key establishment. The main idea is to deploy a small number of additional sensor nodes, called assisting nodes , to help key establishment between sensor nodes. The proposed approach has many advantages over existing approaches. In particular, a sensor node only needs to make a few local communications and perform a few efficient hash operations to setup a key with any other sensor node in the network at a very high probability. The majority of sensor nodes only need to store a single key. Besides, it also provides high resilience to node compromises. The theoretical analysis, simulation studies, and experiments on TelosB sensor motes also demonstrate the advantages of this key establishment protocol in sensor networks.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1990789264",
    "type": "article"
  },
  {
    "title": "Design-space exploration and runtime resource management for multicores",
    "doi": "https://doi.org/10.1145/2514641.2514647",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Giovanni Mariani; Gianluca Palermo; Vittorio Zaccaria; Cristina Silvano",
    "corresponding_authors": "",
    "abstract": "Application-specific multicore architectures are usually designed by using a configurable platform in which a set of parameters can be tuned to find the best trade-off in terms of the selected figures of merit (such as energy, delay, and area). This multi-objective optimization phase is called Design-Space Exploration (DSE). Among the design-time (hardware) configurable parameters we can find the memory subsystem configuration (such as cache size and associativity) and other architectural parameters such as the instruction-level parallelism of the system processors. Among the runtime (software) configurable parameters we can find the degree of task-level parallelism associated with each application running on the platform. The contribution of this article is twofold; first, we introduce an evolutionary (NSGA-II-based) methodology for identifying a hardware configuration which is robust with respect to applications and corresponding datasets. Second, we introduce a novel runtime heuristic that exploits design-time identified operating points to provide guaranteed throughput to each application. Experimental results show that the design-time/runtime combined approach improves the runtime performance of the system with respect to existing reference techniques, while meeting the overall power budget.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1999232651",
    "type": "article"
  },
  {
    "title": "A Robust Mechanism for Adaptive Scheduling of Multimedia Applications",
    "doi": "https://doi.org/10.1145/2043662.2043670",
    "publication_date": "2011-11-01",
    "publication_year": 2011,
    "authors": "Tommaso Cucinotta; Luca Abeni; Luigi Palopoli; Giuseppe Lipari",
    "corresponding_authors": "",
    "abstract": "We propose an adaptive scheduling technique to schedule highly dynamic multimedia tasks on a CPU. We use a combination of two techniques: the first one is a feedback mechanism to track the resource requirements of the tasks based on “local” observations. The second one is a mechanism that operates with a “global” visibility, reclaiming unused bandwidth. The combination proves very effective: resource reclaiming increases the robustness of the feedback, while the identification of the correct bandwidth made by the feedback increases the effectiveness of the reclamation. We offer both theoretical results and an extensive experimental validation of the approach.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2008654482",
    "type": "article"
  },
  {
    "title": "Poly-DWT",
    "doi": "https://doi.org/10.1145/2146417.2146423",
    "publication_date": "2012-03-01",
    "publication_year": 2012,
    "authors": "Amit Pande; Joseph Zambreno",
    "corresponding_authors": "",
    "abstract": "Many modern computing applications have been enabled through the use of real-time multimedia processing. While several hardware architectures have been proposed in the research literature to support such primitives, these fail to address applications whose performance and resource requirements have a dynamic aspect. Embedded multimedia systems typically need a power and computation efficient design in addition to good compression performance. In this article, we introduce a Polymorphic Wavelet Architecture (Poly-DWT) as a crucial building block towards the development of embedded systems to address such challenges. We illustrate how our Poly-DWT architecture can potentially make dynamic resource allocation decisions, such as the internal bit representation and the processing kernel, according to the application requirements. We introduce a filter switching architecture that allows for dynamic switching between 5/3 and 9/7 wavelet filters and leads to a more power efficient design. Further, a multiplier-free design with a low adder requirement demonstrates the potential of Poly-DWT for embedded systems. Through an FPGA prototype, we perform a quantitative analysis of our Poly-DWT architecture, and compare our filter to existing approaches to illustrate the area and performance benefits inherent in our approach.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2009135061",
    "type": "article"
  },
  {
    "title": "Adaptive calibration for fusion-based cyber-physical systems",
    "doi": "https://doi.org/10.1145/2362336.2362347",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Rui Tan; Guoliang Xing; Xue Liu; Jianguo Yao; Zhaohui Yuan",
    "corresponding_authors": "",
    "abstract": "Many Cyber-Physical Systems (CPS) are composed of low-cost devices that are deeply integrated with physical environments. As a result, the performance of a CPS system is inevitably undermined by various physical uncertainties , which include stochastic noises, hardware biases, unpredictable environment changes, and dynamics of the physical process of interest. Traditional solutions to these issues (e.g., device calibration and collaborative signal processing) work in an open-loop fashion and hence often fail to adapt to the uncertainties after system deployment. In this article, we propose an adaptive system-level calibration approach for a class of CPS systems whose primary objective is to detect events or targets of interest. Through collaborative data fusion, our calibration approach features a feedback control loop that exploits system heterogeneity to mitigate the impact of aforementioned uncertainties on the system performance. In contrast to existing heuristic-based solutions, our control-theoretical calibration algorithm can ensure provable system stability and convergence. We also develop a routing algorithm for fusion-based multihop CPS systems that is robust to communication unreliability and delay. Our approach is evaluated by both experiments on a testbed of Tmotes as well as extensive simulations based on data traces gathered from a real vehicle detection experiment. The results demonstrate that our calibration algorithm enables a CPS system to maintain the optimal sensing performance in the presence of various system and environmental dynamics.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2058887615",
    "type": "article"
  },
  {
    "title": "Energy Conservation for Image Retrieval on Mobile Systems",
    "doi": "https://doi.org/10.1145/2345770.2345779",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Karthik Kumar; Yamini Nimmagadda; Yung-Hsiang Lu",
    "corresponding_authors": "",
    "abstract": "Mobile systems such as PDAs and cell phones play an increasing role in handling visual contents such as images. Thousands of images can be stored in a mobile system with the advances in storage technology: this creates the need for better organization and retrieval of these images. Content Based Image Retrieval (CBIR) is a method to retrieve images based on their visual contents. In CBIR, images are compared by matching their numerical representations called features; CBIR is computation and memory intensive and consumes significant amounts of energy. This article examines energy conservation for CBIR on mobile systems. We present three improvements to save energy while performing the computation on the mobile system: selective loading, adaptive loading, and caching features in memory. Using these improvements adaptively reduces the features to be loaded into memory for each search. The reduction is achieved by estimating the difficulty of the search. If the images in the collection are dissimilar, fewer features are sufficient; less computation is performed and energy can be saved. We also consider the effect of consecutive user queries and show how features can be cached in memory to save energy. We implement a CBIR algorithm on an HP iPAQ hw6945 and show that these improvements can save energy and allow CBIR to scale up to 50,000 images on a mobile system. We further investigate if energy can be saved by migrating parts of the computation to a server, called computation offloading . We analyze the impact of the wireless bandwidth, server speed, number of indexed images, and the number of image queries on the energy consumption. Using our scheme, CBIR can be made energy efficient under all conditions.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2069028796",
    "type": "article"
  },
  {
    "title": "A rule-based quasi-static scheduling approach for static islands in dynamic dataflow graphs",
    "doi": "https://doi.org/10.1145/2442116.2442124",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Joachim Falk; Christian Zebelein; Christian Haubelt; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "In this article, an efficient rule-based clustering algorithm for static dataflow subgraphs in a dynamic dataflow graph is presented. The clustered static dataflow actors are quasi-statically scheduled , in such a way that the global performance in terms of latency and throughput is improved compared to a dynamically scheduled execution, while avoiding the introduction of deadlocks as generated by naive static scheduling approaches. The presented clustering algorithm outperforms previously published approaches by a faster computation and more compact representation of the derived quasi-static schedule. This is achieved by a rule-based approach, which avoids an explicit enumeration of the state space. A formal proof of the correctness of the presented clustering approach is given. Experimental results show significant improvements in both, performance and code size, compared to a state-of-the-art clustering algorithm.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2157656634",
    "type": "article"
  },
  {
    "title": "The Design and Implementation of the Synchronous Language CÉU",
    "doi": "https://doi.org/10.1145/3035544",
    "publication_date": "2017-07-13",
    "publication_year": 2017,
    "authors": "Francisco Sant’Anna; Roberto Ierusalimschy; Noemí Rodríguez; Silvana Rossetto; Adriano Branco",
    "corresponding_authors": "",
    "abstract": "C éU is a synchronous language targeting soft real-time systems. It is inspired by Esterel and has a simple semantics with fine-grain control over program execution. C éU uses an event-triggered notion of time that enables compile-time checks to detect conflicting concurrent statements, resulting in deterministic and concurrency-safe programs. We present the particularities of our design in comparison to Esterel, such as stack-based internal events, concurrency checks, safe integration with C, and first-class timers. We also present two implementation back ends: one aiming for resource efficiency and interoperability with C, and another as a virtual machine that allows remote reprogramming.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2735309446",
    "type": "article"
  },
  {
    "title": "Harmonicity-Aware Task Partitioning for Fixed Priority Scheduling of Probabilistic Real-Time Tasks on Multi-Core Platforms",
    "doi": "https://doi.org/10.1145/3064813",
    "publication_date": "2017-07-28",
    "publication_year": 2017,
    "authors": "Tianyi Wang; Soamar Homsi; Linwei Niu; Shaolei Ren; Ou Bai; Gang Quan; Meikang Qiu",
    "corresponding_authors": "",
    "abstract": "The uncertainty due to performance variations of IC chips and resource sharing on multi-core platforms have significantly degraded the predictability of real-time systems. Traditional deterministic approaches based on the worst-case assumptions become extremely pessimistic and thus unpractical. In this article, we address the problem of scheduling a set of fixed-priority periodic real-time tasks on multi-core platforms in a probabilistic manner. Specifically, we consider task execution time as a probabilistic distribution and study how to schedule these tasks on multi-core platforms with guaranteed Quality of Service (QoS) requirements in terms of deadline-missing probabilities. Moreover, it is a well-known fact that the relationship among task periods, if exploited appropriately, can significantly improve the processor utilization. To this end, we present a novel approach to partition real-time tasks that can take both task execution time distributions and their period relationships into consideration. From our extensive experiment results, our proposed methods can greatly improve the schedulability of real-time tasks when compared with existing approaches.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2740127617",
    "type": "article"
  },
  {
    "title": "Toward a Practical Regularity-based Model",
    "doi": "https://doi.org/10.1145/3092945",
    "publication_date": "2017-08-14",
    "publication_year": 2017,
    "authors": "Yu Li; Albert M. K. Cheng",
    "corresponding_authors": "",
    "abstract": "Most Hierarchical Real-time Scheduling (HiRTS) techniques have focused on temporal resource partitions in which time units are periodically distributed. Although such periodic partitions could provide great flexibility for the resource-level scheduling, engineers face significant obstacles when trying to determine the schedulability of real-time tasks running on them. The main reason is that periodic partitions fail to effectively bound the difference between the ideal and the actual resource allocation. To solve this problem, some researchers introduced the Regular Partition, a type of temporal resource partition that is almost evenly distributed. Recent research has shown that it achieves maximal transparency for task scheduling—some classical real-time scheduling problems on a regular partition can be easily transformed into equivalent problems on a dedicated single resource. However, the resource partitioning problem for regular partitions is much more complicated than the one for periodic partitions. Based on a practical two-layer HiRTS platform, this article introduces MulZ (Multiple Z-seqences), which is the first to solve this problem with a partitioned scheduling strategy. By using a more complicated approximation methodology, our experimental results show that MulZ outperforms the current best global scheduling algorithm on this problem. After that, it compares the overall performance of the periodic partition and the regular partition. We conclude that the regular partition is a better choice for the integration of real-time applications.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2748430486",
    "type": "article"
  },
  {
    "title": "Harvest Energy from the Water",
    "doi": "https://doi.org/10.1145/3047646",
    "publication_date": "2017-09-20",
    "publication_year": 2017,
    "authors": "Qi Chen; Ye Liu; Guangchi Liu; Qing Yang; Xianming Shi; Hongwei Gao; Lü Su; Quanlong Li",
    "corresponding_authors": "",
    "abstract": "Water quality data is incredibly important and valuable, but its acquisition is not always trivial. A promising solution is to distribute a wireless sensor network in water to measure and collect the data; however, a drawback exists in that the batteries of the system must be replaced or recharged after being exhausted. To mitigate this issue, we designed a self-sustained water quality sensing system that is powered by renewable bioenergy generated from microbial fuel cells (MFCs). MFCs collect the energy released from native magnesium oxidizing microorganisms (MOMs) that are abundant in natural waters. The proposed energy-harvesting technology is environmentally friendly and can provide maintenance-free power to sensors for several years. Despite these benefits, an MFC can only provide microwatt-level power that is not sufficient to continuously power a sensor. To address this issue, we designed a power management module to accumulate energy when the input voltage is as low as 0.33V. We also proposed a radio-frequency (RF) activation technique to remotely activate sensors that otherwise are switched off in default. With this innovative technique, a sensor’s energy consumption in sleep mode can be completely avoided. Additionally, this design can enable on-demand data acquisitions from sensors. We implement the proposed system and evaluate its performance in a stream. In 3-month field experiments, we find the system is able to reliably collect water quality data and is robust to environment changes.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2754876126",
    "type": "article"
  },
  {
    "title": "A Synchronous Look at the Simulink Standard Library",
    "doi": "https://doi.org/10.1145/3126516",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Timothy Bourke; François Carcenac; Jean-Louis Colaço; Bruno Pagano; Cédric Pasteur; Marc Pouzet",
    "corresponding_authors": "",
    "abstract": "Hybrid systems modelers like Simulink come with a rich collection of discrete-time and continuous-time blocks. Most blocks are not defined in terms of more elementary ones—and some cannot be—but are instead written in imperative code and explained informally in a reference manual. This raises the question of defining a minimal set of orthogonal programming constructs such that most blocks can be programmed directly and thereby given a specification that is mathematically precise, and whose compiled version performs comparably to handwritten code. In this paper, we show that a fairly large set of blocks of a standard library like the one provided by Simulink can be programmed in a precise, purely functional language using stream equations, hierarchical automata, Ordinary Differential Equations (ODEs), and deterministic synchronous parallel composition. Some blocks cannot be expressed in our setting as they mix discrete-time and continuous-time signals in unprincipled ways that are statically forbidden by the type checker. The experiment is conducted in Zélus, a synchronous language that conservatively extends L ustre with ODEs to program systems that mix discrete-time and continuous-time signals.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2757225717",
    "type": "article"
  },
  {
    "title": "GPU Performance Estimation using Software Rasterization and Machine Learning",
    "doi": "https://doi.org/10.1145/3126557",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Kenneth O‘Neal; Philip Brisk; Ahmed Abousamra; Zack Waters; Emily Shriver",
    "corresponding_authors": "",
    "abstract": "This paper introduces a predictive modeling framework to estimate the performance of GPUs during pre-silicon design. Early-stage performance prediction is useful when simulation times impede development by rendering driver performance validation, API conformance testing and design space explorations infeasible. Our approach builds a Random Forest regression model to analyze DirectX 3D workload behavior when executed by a software rasterizer, which we have extended with a workload characterizer to collect further performance information via program counters. In addition to regression models, this work produces detailed feature rankings which can provide valuable architectural insight, and accurate performance estimates for an Intel integrated Skylake generation GPU. Our models achieve reasonable out-of-sample-error rates of 14%, with an average simulation speedup of 327x.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2758264231",
    "type": "article"
  },
  {
    "title": "A Majority-Based Reliability-Aware Task Mapping in High-Performance Homogenous NoC Architectures",
    "doi": "https://doi.org/10.1145/3131273",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "Alireza Namazi; Meisam Abdollahi; Saeed Safari; Siamak Mohammadi",
    "corresponding_authors": "",
    "abstract": "This article presents a new reliability-aware task mapping approach in a many-core platform at design time for applications with DAG-based task graphs. The main goal is to devise a task mapping which meets a predefined reliability threshold considering a minimized performance degradation. The proposed approach uses a majority-voting replication technique to fulfill error-masking capability. A quantitative reliability model is also proposed for the platform. Our platform is a homogenous many-core architecture with mesh-based interconnection using traditional deterministic XY routing algorithm. Our iterative approach is applicable to an unlimited number of system fault types. All parts of the platform, including cores, links, and routers, are assumed to be prone to failures. We used the MNLP optimization technique to find the optimal mapping of the presented task graph. Experimental results show that our suggested task mappings not only comply with predefined reliability thresholds but also achieve notable time complexity reduction with respect to exhaustive space exploration.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2773905261",
    "type": "article"
  },
  {
    "title": "Improving SIMD Parallelism via Dynamic Binary Translation",
    "doi": "https://doi.org/10.1145/3173456",
    "publication_date": "2018-02-12",
    "publication_year": 2018,
    "authors": "Ding‐Yong Hong; Yuping Liu; Sheng‐Yu Fu; Jan‐Jan Wu; Wei‐Chung Hsu",
    "corresponding_authors": "",
    "abstract": "Recent trends in SIMD architecture have tended toward longer vector lengths, and more enhanced SIMD features have been introduced in newer vector instruction sets. However, legacy or proprietary applications compiled with short-SIMD ISA cannot benefit from the long-SIMD architecture that supports improved parallelism and enhanced vector primitives, resulting in only a small fraction of potential peak performance. This article presents a dynamic binary translation technique that enables short-SIMD binaries to exploit benefits of new SIMD architectures by rewriting short-SIMD loop code. We propose a general approach that translates loops consisting of short-SIMD instructions to machine-independent IR, conducts SIMD loop transformation/optimization at this IR level, and finally translates to long-SIMD instructions. Two solutions are presented to enforce SIMD load/store alignment, one for the problem caused by the binary translator’s internal translation condition and one general approach using dynamic loop peeling optimization. Benchmark results show that average speedups of 1.51× and 2.48× are achieved for an ARM NEON to x86 AVX2 and x86 AVX-512 loop transformation, respectively.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2787850818",
    "type": "article"
  },
  {
    "title": "<scp>S</scp> L <scp>I</scp> SCP-light",
    "doi": "https://doi.org/10.1145/3233245",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Riham AlTawy; Raghvendra Rohit; Morgan He; Kalikinkar Mandal; Gangqiang Yang; Guang Gong",
    "corresponding_authors": "",
    "abstract": "The emerging areas in which highly resource constrained devices are interacting wirelessly to accomplish tasks have led manufacturers to embed communication systems in them. Tiny low-end devices such as sensor networks nodes and Radio Frequency Identification (RFID) tags are of particular importance due to their vulnerability to security attacks, which makes protecting their communication privacy and authenticity an essential matter. In this work, we present a lightweight do-it-all cryptographic design that offers the basic underlying functionalities to secure embedded communication systems in tiny devices. Specifically, we revisit the design approach of the sLiSCP family of lightweight cryptographic permutations, which was proposed in SAC 2017. sLiSCP is designed to be used in a unified duplex sponge construction to provide minimal overhead for multiple cryptographic functionalities within one hardware design. The design of sLiSCP follows a 4-subblock Type-2 Generalized Feistel-like Structure (GFS) with unkeyed round-reduced Simeck as the round function, which are extremely efficient building blocks in terms of their hardware area requirements. In S L I SCP-light, we tweak the GFS design and turn it into an elegant Partial Substitution-Permutation Network construction, which further reduces the hardware areas of the S L I SCP permutations by around 16% of their original values. The new design also enhances the bit diffusion and algebraic properties of the permutations and enables us to reduce the number of steps, thus achieving a better throughput in both the hashing and authentication modes. We perform a thorough security analysis of the new design with respect to its diffusion, differential and linear, and algebraic properties. For S L I SCP-light-192, we report parallel implementation hardware areas of 1,820 (respectively, 1,892)GE in CMOS 65 nm (respectively, 130 nm ) ASIC. The areas for S L I SCP-light-256 are 2,397 and 2,500GE in CMOS 65 nm and 130 nm ASIC, respectively. Overall, the unified duplex sponge mode of S L I SCP-light-192, which provides (authenticated) encryption and hashing functionalities, satisfies the area (1,958GE), power (3.97μ W ), and throughput (44.4kbps) requirements of passive RFID tags.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2888884259",
    "type": "article"
  },
  {
    "title": "Can Android Run on Time? Extending and Measuring the Android Platform's Timeliness",
    "doi": "https://doi.org/10.1145/3289257",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Yin Yan; Girish Gokul; Karthik Dantu; Steven Y. Ko; Lukasz Ziarek; Jan Vítek",
    "corresponding_authors": "",
    "abstract": "Time predictability is difficult to achieve in the complex, layered execution environments that are common in modern embedded devices such as smartphones. We explore adopting the Android programming model for a range of embedded applications that extends beyond mobile devices, under the constraint that changes to widely used libraries should be minimized. The challenges we explore include the interplay between real-time activities and the rest of the system, how to express the timeliness requirements of components, and how well those requirements can be met on stock embedded platforms. We detail the design and implementation of our modifications to the Android framework along with a real-time VM and OS, and we provide experimental data validating feasibility over five applications.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2908655465",
    "type": "article"
  },
  {
    "title": "BlueIO",
    "doi": "https://doi.org/10.1145/3309765",
    "publication_date": "2019-04-09",
    "publication_year": 2019,
    "authors": "Zhe Jiang; Neil Audsley; Pan Dong",
    "corresponding_authors": "",
    "abstract": "In safety-critical systems, time predictability is vital. This extends to I/O operations that require predictability, timing-accuracy, parallel access, scalability, and isolation. Currently, existing approaches cannot achieve all these requirements at the same time. In this article, we propose a framework of hardware framework for real-time I/O virtualization—termed BlueIO —to meet all these requirements simultaneously. BlueIO integrates the functionalities of I/O virtualization, low-layer I/O drivers, and a clock cycle level timing-accurate I/O controller (using the GPIOCP [36]). BlueIO provides this functionality in the hardware layer, supporting abstract virtualized access to I/O from the software domain. The hardware implementation includes I/O virtualization and I/O drivers, provides isolation and parallel (concurrent) access to I/O operations, and improves I/O performance. Furthermore, the approach includes the previously proposed GPIOCP to guarantee that I/O operations will occur at a specific clock cycle (i.e., be timing-accurate and predictable). In this article, we present a hardware consumption analysis of BlueIO to show that it linearly scales with the number of CPUs and I/O devices, which is evidenced by our implementation in VLSI and FPGA. We also describe the design and implementation of BlueIO and demonstrate how a BlueIO-based system can be exploited to meet real-time requirements with significant improvements in I/O performance and a low running cost on different OSs.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2938838710",
    "type": "article"
  },
  {
    "title": "Specification Mining and Robust Design under Uncertainty",
    "doi": "https://doi.org/10.1145/3358231",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Panagiotis Kyriakis; Jyotirmoy V. Deshmukh; Paul Bogdan",
    "corresponding_authors": "",
    "abstract": "In this paper, we propose Stochastic Temporal Logic (StTL) as a formalism for expressing probabilistic specifications on time-varying behaviors of controlled stochastic dynamical systems. To make StTL a more effective specification formalism, we introduce the quantitative semantics for StTL to reason about the robust satisfaction of an StTL specification by a given system. Additionally, we propose using the robustness value as the objective function to be maximized by a stochastic optimization algorithm for the purpose of controller design. Finally, we formulate an algorithm for parameter inference for Parameteric-StTL specifications, which allows specifications to be mined from output traces of the underlying system. We demonstrate and validate our framework on two case studies inspired by the automotive domain.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2980304492",
    "type": "article"
  },
  {
    "title": "Tÿcho",
    "doi": "https://doi.org/10.1145/3362692",
    "publication_date": "2019-11-30",
    "publication_year": 2019,
    "authors": "Gustav Cedersjö; Jörn W. Janneck",
    "corresponding_authors": "",
    "abstract": "Many application areas for embedded systems, such as DSP, media coding, and image processing, are based on stream processing. Stream programs in these areas are often naturally described as graphs, where nodes are computational kernels that send data over the edges. This structure also exhibits large amounts of concurrency, because the kernels can execute independently as long as there are data to process on the edges. The explicit data dependencies also help making efficient sequential implementations of such programs, allowing programs to be more portable between platforms with various degrees of parallelism. The kernels can be expressed in many different ways; for example, as imperative programs with read and write statements for the communication or as a set of actions that can be performed and conditions for when these actions can be executed. Traditionally, there has been a tension between how the kernels are expressed and how efficiently they can be implemented. There are very efficient implementation techniques for stream programs with restricted expressiveness, such as synchronous dataflow. In this article, we present a framework for building stream program compilers that we call Tÿcho. At the core of this framework is a common kernel representation, based on a machine model for stream program kernels called actor machine , on which transformations and optimizations are performed. Both imperative and action-based kernels are translated to this common representation, making the same optimizations applicable to different kinds of kernels, and even across source language boundaries. An actor machine is described by the steps of execution that a kernel can take, and the conditions for taking them, together with a controller that decides how the conditions are tested and the steps are taken. We outline how kernels of an imperative process language and an action-based language are decomposed and translated to the common kernel representation, and we describe a simple backend that generates sequential C code from this representation. We present optimization heuristics of the decision process in the controller that we evaluate using a few dozen kernels from a video decoder with various degrees of complexity. We also present kernel fusion, by merging the controllers of actor machines, as a way of scheduling kernels on the same processor, which we compare to prior art.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2995669284",
    "type": "article"
  },
  {
    "title": "Sea depth measurement with restricted floating sensors",
    "doi": "https://doi.org/10.1145/2501626.2512448",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Mo Li; Zheng Yang; Yunhao Liu",
    "corresponding_authors": "",
    "abstract": "Sea depth monitoring is a critical task for ensuring safe operation of harbors. Traditional schemes largely rely on labor-intensive work and expensive hardware. This study explores the possibility of deploying networked sensors on the surface of the sea, measuring and reporting the sea depth of given areas. We propose a Restricted Floating Sensors (RFS) model in which sensor nodes are anchored to the sea bottom, floating within a restricted area. Distinguished from traditional stationary or mobile sensor networks, the RFS network consists of sensor nodes with restricted mobility. We construct the network model and elaborate the corresponding localization problem. We show that by locating such RFS sensors, the sea depth can be estimated without the help of any extra ranging devices. A prototype system with 25 Telos sensor nodes is deployed to validate this design. We also examine the efficiency and scalability of this design through large-scale simulations.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4238179166",
    "type": "article"
  },
  {
    "title": "Data embedding in image-media using weight-function on modulo operations",
    "doi": "https://doi.org/10.1145/2423636.2423639",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Hung–Min Sun; Chi-Yao Weng; Shiuh-Jeng Wang; Cheng-Hsing Yang",
    "corresponding_authors": "",
    "abstract": "Multimedia hiding system is to embed message behind the specified media, but it is still kept normal in media representations via human sensitive organizations without causing imperceptibility. In this article, we propose a data hiding system by means of flexible exploiting modification directions to achieve safer message concealments in image-media. In our scheme, n cover-pixels are flexibly chosen on modulo operations to embed a secret s , where n = ⌈ log 3 ( s ) ⌉. The varied pixel values associated with the chosen n pixels are only changed among [-1, 1]. Because the numbers of adjustable pixels are much greater than the pixels in the past scheme, our scheme is able to obtain a higher embedded ratio in response to the capacity requirements of information hiding systems. In addition, we also applied the statistics-steganalyzers to demonstrate that our scheme has accomplishment not only higher capacity but also kept the robustness against the blind steganalyzers.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1997672406",
    "type": "article"
  },
  {
    "title": "An adaptive, low-cost wear-leveling algorithm for multichannel solid-state disks",
    "doi": "https://doi.org/10.1145/2539036.2539051",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Li-Pin Chang; Tung-Yang Chou; Li-Chun Huang",
    "corresponding_authors": "",
    "abstract": "Multilevel flash memory cells double or even triple storage density, producing affordable solid-state disks for end users. As flash memory endures only limited program-erase cycles, solid-state disks employ wear-leveling methods to prevent any portions of flash memory from being retired prematurely. Modern solid-state disks must consider wear evenness at both block and channel levels. This study first presents a block-level wear-leveling method whose design has two new ideas. First, the proposed method reuses the intelligence available in flash-translation layers so it does not require any new data structures. Second, it adaptively tunes the threshold of block-level wear leveling according to the runtime write pattern. This study further introduces a new channel-level wear-leveling strategy, because block-level wear leveling is confined to a channel, but realistic workloads do not evenly write all channels. The proposed method swaps logical blocks among channels for achieving an eventually-even state of channel lifetimes. A series of trace-driven simulations show that our wear-leveling method outperforms existing approaches in terms of wear evenness and overhead reduction.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2001461406",
    "type": "article"
  },
  {
    "title": "Exploiting Concurrency for the Automated Synthesis of MPSoC Interconnects",
    "doi": "https://doi.org/10.1145/2700075",
    "publication_date": "2015-04-30",
    "publication_year": 2015,
    "authors": "Alessandro Cilardo; Edoardo Fusella; Luca Gallo; Antonino Mazzeo",
    "corresponding_authors": "",
    "abstract": "Multiprocessor Systems-on-Chip (MPSoC) applications can rely today on a very large spectrum of interconnection topologies potentially meeting given communication requirements, determining various trade-offs between cost and performance. Building interconnects that enable concurrent communication tasks introduces decisive opportunities for reducing the overall communication latency. This work identifies three levels of parallelism at the interconnect level: global parallelism across different independent domains; local or intradomain parallelism, relying on inherently concurrent interconnect components such as crossbars; and interdomain parallelism, where multiple concurrent paths across different local domains are exploited. We propose an automated methodology to search the design space, aimed at maximizing the exploitation of these forms of parallelism. The approach also takes into consideration possible dependencies between communication tasks, which further constrains the design space, making the identification of a feasible solution more challenging. By jointly solving a scheduling and interconnect synthesis problem, the methodology turns the description of the application communication requirements, including data dependencies, into an on-chip synthesizable interconnection structure along with a communication schedule satisfying given area constraints. The article thoroughly describes the formalisms and the methodology used to derive such optimized heterogeneous topologies. It also discusses some case studies emphasizing the impact of the proposed approach and highlighting the essential differences with a few other solutions presented in the technical literature.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2003042495",
    "type": "article"
  },
  {
    "title": "Computation of Minimal Siphons in Petri Nets by Using Binary Decision Diagrams",
    "doi": "https://doi.org/10.1145/2406336.2406339",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Yufeng Chen; Gaiyun Liu",
    "corresponding_authors": "",
    "abstract": "Siphons play an important role in the development of deadlock control methods by using Petri nets. The number of siphons increases exponentially with respect to the size of a Petri net. This article presents a symbolic approach to the computation of minimal siphons in Petri nets by using binary decision diagrams (BDD). The siphons of a Petri net can be found via a set of logic conditions. The logic conditions are symbolically modeled by using Boolean algebras. The operations of Boolean algebras are implemented by BDD that are capable of representing large sets of siphons with small shared data structures. The proposed method first uses BDD to compute all siphons of a Petri net and then a binary relation is designed to extract all minimal siphons. Finally, by using a number of examples, the efficiency of the proposed method is verified through different-sized problems.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2029320999",
    "type": "article"
  },
  {
    "title": "An approach to manage reconfigurations and reduce area cost in hard real-time reconfigurable systems",
    "doi": "https://doi.org/10.1145/2560037",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Juan Antonio Clemente; Javier Resano; Daniel Mozos",
    "corresponding_authors": "",
    "abstract": "This article presents a methodology for building real-time reconfigurable systems that ensures that all the temporal constraints of a set of applications are met while optimizing the utilization of the available reconfigurable resources. Starting from a static platform that meets all the real-time deadlines, our approach takes advantage of runtime reconfiguration in order to reduce the area needed while guaranteeing that all the deadlines are still met. This goal is achieved by identifying which tasks must be always ready for execution in order to meet the deadlines and by means of a methodology that also allows reducing the area requirements.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2091667700",
    "type": "article"
  },
  {
    "title": "Predictability for timing and temperature in multiprocessor system-on-chip platforms",
    "doi": "https://doi.org/10.1145/2435227.2435244",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Lothar Thiele; Lars Schor; Iuliana Bacivarov; Hoeseok Yang",
    "corresponding_authors": "",
    "abstract": "High computational performance in multiprocessor system-on-chips (MPSoCs) is constrained by the ever-increasing power densities in integrated circuits, so that nowadays MPSoCs face various thermal issues. For instance, high chip temperatures may lead to long-term reliability concerns and short-term functional errors. Therefore, the new challenge in designing embedded real-time MPSoCs is to guarantee the final performance and correct function of the system, considering both functional and non-functional properties. One way to achieve this is by ruling out mapping alternatives that do not fulfill requirements on performance or peak temperature already in early design stages. In this article, we propose a thermal-aware optimization framework for mapping real-time applications onto MPSoC platforms. The performance and temperature of mapping candidates are evaluated by formal temporal and thermal analysis models. To this end, analysis models are automatically generated during design space exploration, based on the same specifications as used for software synthesis. The analysis models are automatically calibrated with performance data reflecting the execution of the system on the target platform. The data is automatically obtained prior to design space exploration based on a set of benchmark mappings. Case studies show that the performance and temperature requirements are often conflicting goals and optimizing them together leads to major benefits in terms of a guaranteed and predictable high performance.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2134249540",
    "type": "article"
  },
  {
    "title": "OCEAN",
    "doi": "https://doi.org/10.1145/2584667",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Mohamed M. Sabry; David Atienza; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "Recent process technology advances trigger reliability issues that degrade the Quality-of-Service (QoS) required by embedded Systems-on-Chip (SoCs). To maintain the required QoS with acceptable overheads, we propose OCEAN, a novel cross-layer error mitigation. OCEAN enforces on-chip SRAMs reliability with a fault-tolerant buffer. We utilize this buffer to protect a portion of the processed data used to restore from runtime error. We optimally select the buffer size to minimize the energy overhead, with timing and area constraints. OCEAN achieves full error mitigation with 10.1% average energy overhead compared to base-line operation that does not include any error correction capability, and 65% energy savings, compared to a cross-layer error mitigation mechanism.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2153985558",
    "type": "article"
  },
  {
    "title": "On Memory Reuse Between Inputs and Outputs of Dataflow Actors",
    "doi": "https://doi.org/10.1145/2871744",
    "publication_date": "2016-02-17",
    "publication_year": 2016,
    "authors": "Karol Desnos; Maxime Pelcat; Jean-François Nezan; Slaheddine Aridhi",
    "corresponding_authors": "",
    "abstract": "This article introduces a new technique to minimize the memory footprints of Digital Signal Processing (DSP) applications specified with Synchronous Dataflow (SDF) graphs and implemented on shared-memory Multiprocessor System-on-Chip (MPSoCs). In addition to the SDF specification, which captures data dependencies between coarse-grained tasks called actors, the proposed technique relies on two optional inputs abstracting the internal data dependencies of actors: annotations of the ports of actors, and script-based specifications of merging opportunities between input and output buffers of actors. Experimental results on a set of applications show a reduction of the memory footprint by 48% compared to state-of-the-art minimization techniques.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2323048437",
    "type": "article"
  },
  {
    "title": "A Methodology for Estimating Performance and Power Consumption of Embedded Flash File Systems",
    "doi": "https://doi.org/10.1145/2903139",
    "publication_date": "2016-08-02",
    "publication_year": 2016,
    "authors": "Pierre Olivier; Jalil Boukhobza; Eric Senn; Hamza Ouarnoughi",
    "corresponding_authors": "",
    "abstract": "In the embedded systems domain, obtaining performance and power consumption estimations is extremely valuable in numerous cases. This is particularly true during the design stage, as designers of complex embedded systems face an increasingly large design space. Secondary storage is a well-known performance bottleneck and has also been reported as an important factor of power consumption. Flash memory is the main secondary storage media in an embedded system and exhibits specific constraints in its usage. One popular way to manage these constraints is to use dedicated Flash File Systems (FFS). In this article, we propose a methodology to estimate the performance and power consumption of applicative I/Os on an FFS-based storage system within embedded Linux. The methodology is divided into three sequential steps. In the exploration phase, the main factors of an FFS storage system impacting performance and power consumption are identified. In the modeling phase, this impact is formalized into models. Finally, in the last phase, the models are implemented in a simulator named OpenFlash. OpenFlash allows obtaining performance and power consumption estimations for an applicative workload processed by the Linux FFS storage stack on an embedded platform. The simulator is validated against real measurements and the estimation error stays below 10%.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2485369195",
    "type": "article"
  },
  {
    "title": "An Indoor Test Methodology for Solar-Powered Wireless Sensor Networks",
    "doi": "https://doi.org/10.1145/2994604",
    "publication_date": "2017-03-28",
    "publication_year": 2017,
    "authors": "Wilson M. Tan; P. J. Sullivan; Hamish Watson; Joanna E Slota-Newson; Stephen A. Jarvis",
    "corresponding_authors": "",
    "abstract": "Repeatable and accurate tests are important when designing hardware and algorithms for solar-powered wireless sensor networks (WSNs). Since no two days are exactly alike with regard to energy harvesting, tests must be carried out indoors. Solar simulators are traditionally used in replicating the effects of sunlight indoors; however, solar simulators are expensive, have lighting elements that have short lifetimes, and are usually not designed to carry out the types of tests that hardware and algorithm designers require. As a result, hardware and algorithm designers use tests that are inaccurate and not repeatable (both for others and also for the designers themselves). In this article, we propose an indoor test methodology that does not rely on solar simulators. The test methodology has its basis in astronomy and photovoltaic cell design. We present a generic design for a test apparatus that can be used in carrying out the test methodology. We also present a specific design that we use in implementing an actual test apparatus. We test the efficacy of our test apparatus and, to demonstrate the usefulness of the test methodology, perform experiments akin to those required in projects involving solar-powered WSNs. Results of the said tests and experiments demonstrate that the test methodology is an invaluable tool for hardware and algorithm designers working with solar-powered WSNs.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2520846276",
    "type": "article"
  },
  {
    "title": "System-Level Design Optimization for Security-Critical Cyber-Physical-Social Systems",
    "doi": "https://doi.org/10.1145/2925991",
    "publication_date": "2017-04-14",
    "publication_year": 2017,
    "authors": "Jing Zeng; Laurence T. Yang; Man Lin; Zili Shao; Dakai Zhu",
    "corresponding_authors": "",
    "abstract": "Cyber-physical-social systems (CPSS), an emerging computing paradigm, have attracted intensive attentions from the research community and industry. We are facing various challenges in designing secure, reliable, and user-satisfied CPSS. In this article, we consider these design issues as a whole and propose a system-level design optimization framework for CPSS design where energy consumption, security-level, and user satisfaction requirements can be fulfilled while satisfying constraints for system reliability. Specifically, we model the constraints (energy efficiency, security, and reliability) as the penalty functions to be incorporated into the corresponding objective functions for the optimization problem. A smart office application is presented to demonstrate the feasibility and effectiveness of our proposed design optimization approach.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2606291490",
    "type": "article"
  },
  {
    "title": "Efficient Kernel Management on GPUs",
    "doi": "https://doi.org/10.1145/3070710",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Yun Liang; Xiuhong Li",
    "corresponding_authors": "",
    "abstract": "Graphics Processing Units (GPUs) have been widely adopted as accelerators for compute-intensive applications due to its tremendous computational power and high memory bandwidth. As the complexity of applications continues to grow, each new generation of GPUs has been equipped with advanced architectural features and more resources to sustain its performance acceleration capability. Recent GPUs have been featured with concurrent kernel execution, which is designed to improve the resource utilization by executing multiple kernels simultaneously. However, it is still a challenge to find a way to manage the resources on GPUs for concurrent kernel execution. Prior works only achieve limited performance improvement as they do not optimize the thread-level parallelism (TLP) and model the resource contention for the concurrently executing kernels. In this article, we design an efficient kernel management framework that optimizes the performance for concurrent kernel execution on GPUs. Our kernel management framework contains two key components: TLP modulation and cache bypassing. The TLP modulation is employed to adjust the TLP for the concurrently executing kernels. It consists of three parts: kernel categorization, static TLP modulation, and dynamic TLP modulation. The cache bypassing is proposed to mitigate the cache contention by only allowing a subset of a kernel’s blocks to access the L1 data cache. Experiments indicate that our framework can improve the performance by 1.51 × on average (energy-efficiency by 1.39 × on average), compared with the default concurrent kernel execution framework.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2618092901",
    "type": "article"
  },
  {
    "title": "Synthesis of Flexible Accelerators for Early Adoption of Ring-LWE Post-quantum Cryptography",
    "doi": "https://doi.org/10.1145/3378164",
    "publication_date": "2020-03-11",
    "publication_year": 2020,
    "authors": "Hamid Nejatollahi; F.A. Valencia; Subhadeep Banik; Francesco Regazzoni; Rosario Cammarota; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "The advent of the quantum computer makes current public-key infrastructure insecure. Cryptography community is addressing this problem by designing, efficiently implementing, and evaluating novel public-key algorithms capable of withstanding quantum computational power. Governmental agencies, such as NIST, are promoting standardization of quantum-resistant algorithms that is expected to run for 7 years. Several modern applications must maintain permanent data secrecy; therefore, they ultimately require the use of quantum-resistant algorithms. Because algorithms are still under scrutiny for eventual standardization, the deployment of the hardware implementation of quantum-resistant algorithms is still in early stages. In this article, we propose a methodology to design programmable hardware accelerators for lattice-based algorithms, and we use the proposed methodology to implement flexible and energy efficient post-quantum cache-based accelerators for NewHope , Kyber , Dilithium , Key Consensus from Lattice ( KCL ), and R.EMBLEM submissions to the NIST standardization contest. To the best of our knowledge, we propose the first efficient domain-specific, programmable cache-based accelerators for lattice-based algorithms. We design a single accelerator for a common kernel among various schemes with different kernel sizes, i.e., loop count, and data types. This is in contrast to the traditional approach of designing one special purpose accelerators for each scheme. We validate our methodology by integrating our accelerators into an HLS-based SoC infrastructure based on the X86 processor and evaluate overall performance. Our experiments demonstrate the suitability of the approach and allow us to collect insightful information about the performance bottlenecks and the energy efficiency of the explored algorithms. Our results provide guidelines for hardware designers, highlighting the optimization points to address for achieving the highest energy minimization and performance increase. At the same time, our proposed design allows us to specify and execute new variants of lattice-based schemes with superior energy efficiency compared to the main application processor without changing the hardware acceleration platform. For example, we manage to reduce the energy consumption up to 2.1× and energy-delay product (EDP) up to 5.2× and improve the speedup up to 2.5×.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3010670488",
    "type": "article"
  },
  {
    "title": "Fast and Energy-Efficient State Checkpointing for Intermittent Computing",
    "doi": "https://doi.org/10.1145/3391903",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Saad Ahmed; Naveed Anwar Bhatti; Muhammad Hamad Alizai; Junaid Haroon Siddiqui; Luca Mottola",
    "corresponding_authors": "",
    "abstract": "Intermittently powered embedded devices ensure forward progress of programs through state checkpointing in non-volatile memory. Checkpointing is, however, expensive in energy and adds to the execution times. To minimize this overhead, we present DICE, a system that renders differential checkpointing profitable on these devices. DICE is unique because it is a software-only technique and efficient because it only operates in volatile main memory to evaluate the differential. DICE may be integrated with reactive (Hibernus) or proactive (MementOS, HarvOS) checkpointing systems, and arbitrary code can be enabled with DICE using automatic code-instrumentation requiring no additional programmer effort. By reducing the cost of checkpoints, DICE cuts the peak energy demand of these devices, allowing operation with energy buffers that are one-eighth of the size originally required, thus leading to benefits such as smaller device footprints and faster recharging to operational voltage level. The impact on final performance is striking: with DICE, Hibernus requires one order of magnitude fewer checkpoints and one order of magnitude shorter time to complete a workload in real-world settings.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3097218653",
    "type": "article"
  },
  {
    "title": "UWB microwave imaging for breast cancer detection",
    "doi": "https://doi.org/10.1145/2530534",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Mario R. Casu; Francesco Colonna; Marco Crepaldi; Danilo Demarchi; Mariagrazia Graziano; Maurizio Zamboni",
    "corresponding_authors": "",
    "abstract": "An UWB microwave imaging system for breast cancer detection consists of antennas, transceivers, and a high-performance embedded system for elaborating the received signals and reconstructing breast images. In this article we focus on this embedded system. To accelerate the image reconstruction, the Beamforming phase has to be implemented in a parallel fashion. We assess its implementation in three currently available high-end platforms based on a multicore CPU, a GPU, and an FPGA, respectively. We then project the results applying technology scaling rules to future many-core CPUs, many-thread GPUs, and advanced FPGAs. We consider an optimistic case in which available resources increase according to Moore's law only, and a pessimistic case in which only a fraction of those resources are available due to a limited power budget. In both scenarios, an implementation that includes a high-end FPGA outperforms the other alternatives. Since the number of effectively usable cores in future many-cores will be power-limited, and there is a trend toward the integration of power-efficient accelerators, we conjecture that a chip consisting of a many-core section and a reconfigurable logic section will be the perfect platform for this application.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1967495981",
    "type": "article"
  },
  {
    "title": "A Hardware-Efficient Architecture for Accurate Real-Time Disparity Map Estimation",
    "doi": "https://doi.org/10.1145/2629699",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Christos Ttofis; Christos Kyrkou; Theocharis Theocharides",
    "corresponding_authors": "",
    "abstract": "Emerging embedded vision systems utilize disparity estimation as a means to perceive depth information to intelligently interact with their host environment and take appropriate actions. Such systems demand high processing performance and accurate depth perception while requiring low energy consumption, especially when dealing with mobile and embedded applications, such as robotics, navigation, and security. The majority of real-time dedicated hardware implementations of disparity estimation systems have adopted local algorithms relying on simple cost aggregation strategies with fixed and rectangular correlation windows. However, such algorithms generally suffer from significant ambiguity along depth borders and areas with low texture. To this end, this article presents the hardware architecture of a disparity estimation system that enables good performance in both accuracy and speed. The architecture implements an adaptive support weight stereo correspondence algorithm that integrates image segmentation information in an attempt to increase the robustness of the matching process. The article also presents hardware-oriented algorithmic modifications/optimization techniques that make the algorithm hardware-friendly and suitable for efficient dedicated hardware implementation. A comparison to the literature asserts that an FPGA implementation of the proposed architecture is among the fastest implementations in terms of million disparity estimations per second (MDE/s), and with an overall accuracy of 90.21%, it presents an effective processing speed/disparity map accuracy trade-off.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1972672785",
    "type": "article"
  },
  {
    "title": "Performance and Reliability Analysis of Cross-Layer Optimizations of NAND Flash Controllers",
    "doi": "https://doi.org/10.1145/2629562",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Davide Bertozzi; Stefano Di Carlo; Salvatore Galfano; Marco Indaco; P. Olivo; P. Prinetto; Cristian Zambelli",
    "corresponding_authors": "",
    "abstract": "NAND flash memories are becoming the predominant technology in the implementation of mass storage systems for both embedded and high-performance applications. However, when considering data and code storage in Non-Volatile Memories (NVMs), such as NAND flash memories, reliability and performance become a serious concern for systems designers. Designing NAND flash-based systems based on worst-case scenarios leads to waste of resources in terms of performance, power consumption, and storage capacity. This is clearly in contrast with the request for runtime reconfigurability, adaptivity, and resource optimization in modern computing systems. There is a clear trend toward supporting differentiated access modes in flash memory controllers, each one setting a differentiated tradeoff point in the performance-reliability optimization space. This is supported by the possibility of tuning the NAND flash memory performance, reliability, and power consumption through several tuning knobs such as the flash programming algorithm and the flash error correcting code. However, to successfully exploit these degrees of freedom, it is mandatory to clearly understand the effect that the combined tuning of these parameters has on the full NVM subsystem. This article performs a comprehensive quantitative analysis of the benefits provided by the runtime reconfigurability of an MLC NAND flash controller through the combined effect of an adaptable memory programming circuitry coupled with runtime adaptation of the ECC correction capability. The full NVM subsystem is taken into account, starting from a characterization of the low-level circuitry to the effect of the adaptation on a wide set of realistic benchmarks in order to provide readers a clear view of the benefit this combined adaptation may provide at the system level.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2018080642",
    "type": "article"
  },
  {
    "title": "Static Task Partitioning for Locked Caches in Multicore Real-Time Systems",
    "doi": "https://doi.org/10.1145/2638557",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Abhik Sarkar; Frank Mueller; Harini Ramaprasad",
    "corresponding_authors": "",
    "abstract": "Growing processing demand on multitasking real-time systems can be met by employing scalable multicore architectures. For such environments, locking cache lines for hard real-time systems ensures timing predictability of data references and may lower worst-case execution time. This work studies the benefits of cache locking on massive multicore architectures with private caches in the context of hard real-time systems. In shared cache architectures, the cache is a single resource shared among all of the tasks. However, in scalable cache architectures with private caches, conflicts exist only among the tasks scheduled on one core. This calls for a cache-aware allocation of tasks onto cores. The objective of this work is to increase the predictability of memory accesses resolved by caches while reducing the number of cores for a given task set. This allows designers to reduce the footprint of their subsystem of real-time tasks and thereby cost, either by choosing a product with fewer cores as a target or to allow more subsystems to be co-located on a given fixed number of cores. Our work proposes a novel variant of the cache-unaware First Fit Decreasing (FFD) algorithm called Naive locked First Fit Decreasing (NFFD) policy. We propose two cache-aware static scheduling schemes: (a) Greedy First Fit Decreasing (GFFD) and (b) Colored First Fit Decreasing (CoFFD) for task sets where tasks do not have intratask conflicts among locked regions (Scenario A). NFFD is capable of scheduling high utilization task sets that FFD cannot schedule. Experiments also show that CoFFD consistently outperforms GFFD, resulting in a lower number of cores and lower system utilization. CoFFD reduces the number of core requirements by 30% to 60% compared to NFFD. For a more generic case where tasks have intratask conflicts, we split the task partitioning between two phases: task selection and task allocation (Scenario B). Instead of resolving conflicts at a global level, these algorithms resolve conflicts among regions while allocating a task onto a core and unlocking at region level instead of task level. We show that a combination of dynamic ordering (task selection) with Chaitin’s Coloring (task allocation) scheme reduces the number of cores required by up to 22% over a basic scheme (in a combination of monotone ordering and regional FFD). Regional unlocking allows this scheme to outperform CoFFD for medium utilization task sets from Scenario A. However, CoFFD performs better than any other scheme for high utilization task sets from Scenario A. Overall, this work is unique in considering the challenges of future multicore architectures for real-time systems and provides key insights into task partitioning and cache-locking mechanisms for architectures with private caches.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2020347537",
    "type": "article"
  },
  {
    "title": "Explicit reservation of cache memory in a predictable, preemptive multitasking real-time system",
    "doi": "https://doi.org/10.1145/2523070",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Jack Whitham; Neil Audsley; Robert I. Davis",
    "corresponding_authors": "",
    "abstract": "We describe and evaluate explicit reservation of cache memory to reduce the cache-related preemption delay (CRPD) observed when tasks share a cache in a preemptive multitasking hard real-time system. We demonstrate the approach using measurements obtained from a hardware prototype, and present schedulability analyses for systems that share a cache by explicit reservation. These analyses form the basis for a series of experiments to further evaluate the approach. We find that explicit reservation is most useful for larger task sets with high utilization. Some task sets cannot be scheduled with a conventional cache, but are schedulable with explicit reservation.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2022540691",
    "type": "article"
  },
  {
    "title": "Reducing asynchrony in channel garbage-collection for improving internal parallelism of multichannel solid-state disks",
    "doi": "https://doi.org/10.1145/2544375.2544383",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Li-Pin Chang; Chen-Yi Wen",
    "corresponding_authors": "",
    "abstract": "Solid-state disks use multichannel architectures to boost their data transfer rates. Because realistic disk workloads have numerous small write requests, modern flash-storage devices adopt a write buffer and a set of independent channels for better parallelism in serving small write requests. When a channel is undergoing garbage collection, it stops responding to inbound write traffic and accumulates page data in the write buffer. This results in contention for buffer space and creates idle periods in channels. This study presents a channel-management strategy, called garbage-collection advancing , which allows early start of garbage collection in channels for increasing the overlap among channel activities of garbage collection and restoring the balance of buffer-space usage among channels. This study further introduces cycle filling , which is a version of garbage-collection advancing tailored for the operation model of flash planes. Experimental results show that the proposed methods greatly outperformed existing designs of multichannel systems in terms of response and throughput. We also successfully implemented the proposed methods in a real solid-state disk and proved their feasibility in real hardware.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2063569037",
    "type": "article"
  },
  {
    "title": "HARS",
    "doi": "https://doi.org/10.1145/2517311",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Yves Lhuillier; Maroun Ojail; Alexandre Guerre; Jean‐Marc Philippe; Karim Ben Chehida; Farhat Thabet; Caaliph Andriamisaina; Chafic Jaber; Raphaël David",
    "corresponding_authors": "",
    "abstract": "The current trend in embedded computing consists in increasing the number of processing resources on a chip. Following this paradigm, cluster-based many-core accelerators with a shared hierarchical memory have emerged. Handling synchronizations on these architectures is critical since parallel implementations speed-ups of embedded applications strongly depend on the ability to exploit the largest possible number of cores while limiting task management overhead. This article presents the combination of a low-overhead complete runtime software and a flexible hardware accelerator for synchronizations called HARS (Hardware-Assisted Runtime Software). Experiments on a multicore test chip showed that the hardware accelerator for synchronizations has less than 1% area overhead compared to a cluster of the chip while reducing synchronization latencies (up to 2.8 times compared to a test-and-set implementation) and contentions. The runtime software part offers basic features like memory management but also optimized execution engines to allow the easy and efficient extraction of the parallelism in applications with multiple programming models. By using the hardware acceleration as well as a very low overhead task scheduling software technique, we show that HARS outperforms an optimized state-of-the-art task scheduler by 13% for the execution of a parallel application.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2067976678",
    "type": "article"
  },
  {
    "title": "Contention-free executions for real-time multiprocessor scheduling",
    "doi": "https://doi.org/10.1145/2494530",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Jinkyu Lee; Arvind Easwaran; Insik Shin",
    "corresponding_authors": "",
    "abstract": "A time slot is defined as contention-free if the number of jobs with remaining executions in the slot is no larger than the number of processors, or contending , otherwise. Then an important property holds that in any contention-free slot, all jobs with remaining executions are guaranteed to be scheduled as long as the scheduler is work-conserving. This article aims at improving schedulability by utilizing the contention-free slots. To achieve this, this article presents a policy (called CF policy) that moves some job executions from contending slots to contention-free ones. This policy can be employed by any work-conserving, preemptive scheduling algorithm, and we show that any algorithm extended with this policy dominates the original algorithm in terms of schedulability. We also present improved schedulability tests for algorithms that employ this policy, based on the observation that interference from jobs is reduced when their executions are postponed to contention-free slots. Simulation results demonstrate that the CF policy, incorporated into existing algorithms, significantly improves schedulability of those existing algorithms.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2135997108",
    "type": "article"
  },
  {
    "title": "Scheduling Temporal Data with Dynamic Snapshot Consistency Requirement in Vehicular Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/2629546",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Kai Liu; Victor C. S. Lee; Joseph Kee‐Yin Ng; Sang H. Son; Edwin H.‐M. Sha",
    "corresponding_authors": "",
    "abstract": "Timely and efficient data dissemination is one of the fundamental requirements to enable innovative applications in vehicular cyber-physical systems (VCPS). In this work, we intensively analyze the characteristics of temporal data dissemination in VCPS. On this basis, we formulate the static and dynamic snapshot consistency requirements on serving real-time requests for temporal data items. Two online algorithms are proposed to enhance the system performance with different requirements. In particular, a reschedule mechanism is developed to make the scheduling adaptable to the dynamic snapshot consistency requirement. A comprehensive performance evaluation demonstrates the superiority of the proposed algorithms.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2158641729",
    "type": "article"
  },
  {
    "title": "Model-Based Design of Correct Controllers for Dynamically Reconfigurable Architectures",
    "doi": "https://doi.org/10.1145/2873056",
    "publication_date": "2016-05-23",
    "publication_year": 2016,
    "authors": "Xin An; Éric Rutten; Jean-Philippe Diguet; Abdoulaye Gamatié",
    "corresponding_authors": "",
    "abstract": "Dynamically reconfigurable hardware has been identified as a promising solution for the design of energy-efficient embedded systems. However, its adoption is limited by costly design effort, including verification and validation, which is even more complex than for nondynamically reconfigurable systems. In this article, we propose a tool-supported formal method to automatically design a correct-by-construction control of the reconfiguration. By representing system behaviors with automata, we exploit automated algorithms to synthesize controllers that safely enforce reconfiguration strategies formulated as properties to be satisfied by control. We design generic modeling patterns for a class of reconfigurable architectures, taking into account both hardware architecture and applications, as well as relevant control objectives. We validate our approach on two case studies implemented on FPGAs.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2287932747",
    "type": "article"
  },
  {
    "title": "Reliability-Aware Adaptations for Shared Last-Level Caches in Multi-Cores",
    "doi": "https://doi.org/10.1145/2961059",
    "publication_date": "2016-09-01",
    "publication_year": 2016,
    "authors": "Florian Kriebel; Semeen Rehman; Arun Subramaniyan; Segnon Jean Bruno Ahandagbe; Muhammad Shafique; Jörg Henkel",
    "corresponding_authors": "",
    "abstract": "On account of their large footprint, on-chip last-level caches in multi-core systems are one of the most vulnerable components to soft errors. However, vulnerability to soft errors highly depends on the configuration and parameters of the last-level cache, especially when executing different applications concurrently. In this article we propose a novel reliability-aware reconfigurable last-level cache architecture (R 2 Cache) and cache vulnerability model for multi-cores. R 2 Cache supports various reliability-wise efficient cache configurations (i.e., cache parameter selection and cache partitioning) for different concurrently executing applications. The proposed vulnerability model takes into account the vulnerability of both the data and tag arrays as well as the active cache area for applications in different execution phases. To enable runtime adaptations, we introduce a lightweight online vulnerability predictor that exploits the knowledge of performance metrics like number of L2 misses to accurately estimate the cache vulnerability to soft errors. Based on the predicted vulnerabilities of different concurrently executing applications in the current execution epoch, our runtime reliability manager reconfigures the cache such that, for the next execution epoch, the total vulnerability for all concurrently executing applications is minimized under user-provided tolerable performance/energy overheads. In scenarios where single-bit error correction for cache lines may be afforded, vulnerability-aware reconfigurations can be leveraged to increase the reliability of the last-level cache against multi-bit errors. Compared to state-of-the-art vulnerability-minimizing and reconfigurable caches, the proposed architecture provides 35.27% and 23.42% vulnerability savings, respectively, when averaged across numerous experiments, while reducing the vulnerability by more than 65% and 60%, respectively, for selected applications and application phases.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2510874310",
    "type": "article"
  },
  {
    "title": "Autonomous OA Removal in Real-Time from Single Channel EEG Data on a Wearable Device Using a Hybrid Algebraic-Wavelet Algorithm",
    "doi": "https://doi.org/10.1145/2983629",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Charvi A. Majmudar; Bashir I. Morshed",
    "corresponding_authors": "",
    "abstract": "Electroencephalography (EEG) is a non-invasive technique to record brain activities in natural settings. Ocular Artifacts (OA) usually contaminates EEG signals, removal of which is critical for accurate feature extraction and classification. With the increasing adoption of wearable technologies, single-channel real-time EEG systems that often require real-time signal processing for immediate real-time feedback are becoming more prevalent. However, traditional OA removal algorithms usually require multiple channels of EEG data, are computationally expensive, and do not perform well in real-time. In this article, a new hybrid algorithm is proposed that autonomously detects OA and subsequently removes OA from a single-channel steaming EEG data in real-time. The proposed single EEG channel algorithm also does not require additional reference electrooculography (EOG) channel. The algorithm has also been implemented on an embedded hardware platform of single channel wearable EEG system (NeuroMonitor). The algorithm first detects the OA zones using an Algebraic approach and then removes these artifacts from the detected OA zones using the Discrete Wavelet Transform (DWT) decomposition method. The de-noising technique is applied only to the OA zone, which minimizes loss of neural information outside the OA zone. A qualitative and quantitative performance evaluation was carried out with a 0.5s epoch in overlapping sliding window technique using time-frequency analysis, mean square coherence, and correlation coefficient statistics. The hybrid OA removal algorithm demonstrated real-time operation with 3s latency on the PSoC-3-microcontroller-based EEG system. Successful implementation of OA removal from single-channel real-time EEG data using the proposed algorithm shows promise for real-time feedback applications of wearable EEG devices.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2531280785",
    "type": "article"
  },
  {
    "title": "Parallel SystemC Simulation for ESL Design",
    "doi": "https://doi.org/10.1145/2987374",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Jan Henrik Weinstock; Luis Gabriel Murillo; Rainer Leupers; Gerd Ascheid",
    "corresponding_authors": "",
    "abstract": "Virtual platforms have become essential tools for the design of embedded systems. Developers rely on them for design space exploration and software debugging. However, with rising HW/SW complexity and the need to simulate more and more processors simultaneously, the performance of virtual platforms degrades rapidly. Parallel simulation techniques can help to counter this by leveraging multicore PCs, which are widely available today. This work presents a novel parallel simulation approach that is targeted toward acceleration of virtual platforms from the ESL domain. By trading some timing accuracy, multiprocessor virtual platforms can be accelerated by up to 3.4× on regular quad-core workstations.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2531523960",
    "type": "article"
  },
  {
    "title": "Facilitating Human Activity Data Annotation via Context-Aware Change Detection on Smartwatches",
    "doi": "https://doi.org/10.1145/3431503",
    "publication_date": "2021-01-11",
    "publication_year": 2021,
    "authors": "Ali Akbari; Jonathan Martinez; Roozbeh Jafari",
    "corresponding_authors": "",
    "abstract": "Annotating activities of daily living (ADL) is vital for developing machine learning models for activity recognition. In addition, it is critical for self-reporting purposes such as in assisted living where the users are asked to log their ADLs. However, data annotation becomes extremely challenging in real-world data collection scenarios, where the users have to provide annotations and labels on their own. Methods such as self-reports that rely on users’ memory and compliance are prone to human errors and become burdensome since they increase users’ cognitive load. In this article, we propose a light yet effective context-aware change point detection algorithm that is implemented and run on a smartwatch for facilitating data annotation for high-level ADLs. The proposed system detects the moments of transition from one to another activity and prompts the users to annotate their data. We leverage freely available Bluetooth low energy (BLE) information broadcasted by various devices to detect changes in environmental context. This contextual information is combined with a motion-based change point detection algorithm, which utilizes data from wearable motion sensors, to reduce the false positives and enhance the system's accuracy. Through real-world experiments, we show that the proposed system improves the quality and quantity of labels collected from users by reducing human errors while eliminating users’ cognitive load and facilitating the data annotation process.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3120838687",
    "type": "article"
  },
  {
    "title": "Design Space Exploration for Secure IoT Devices and Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3430372",
    "publication_date": "2021-05-29",
    "publication_year": 2021,
    "authors": "Lukas Gressl; Christian Steger; Ulrich Neffe",
    "corresponding_authors": "",
    "abstract": "With the advent of the Internet of Things (IoT) and Cyber-Physical Systems (CPS), embedded devices have been gaining importance in our daily lives, as well as industrial processes. Independent of their usage, be it within an IoT system or a CPS, embedded devices are always an attractive target for security attacks, mainly due to their continuous network availability and the importance of the data they handle. Thus, the design of such systems requires a thorough consideration of the various security constraints they are liable to. Introducing these security constraints, next to other requirements, such as power consumption, and performance increases the number of design choices a system designer must consider. As the various constraints are often conflicting with each other, designers face the complex task of balancing them. System designers facilitate Design Space Exploration (DSE) tools to support a system designer in this job. However, available DSE tools only offer a limited way of considering security constraints during the design process. In this article, we introduce a novel DSE framework, which allows the consideration of security constraints, in the form of attack scenarios, and attack mitigations in the form of security tasks. Based on the descriptions of the system’s functionality and architecture, possible attacks, and known mitigation techniques, the framework finds the optimal design for a secure IoT device or CPS. Our framework’s functionality and its benefits are shown based on the design of a secure sensor system.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3172215075",
    "type": "article"
  },
  {
    "title": "Skills Gaps in the Industry",
    "doi": "https://doi.org/10.1145/3463340",
    "publication_date": "2021-07-09",
    "publication_year": 2021,
    "authors": "Deniz Akdur",
    "corresponding_authors": "Deniz Akdur",
    "abstract": "Many practitioners in the software-intensive embedded industry often face difficulties after beginning their careers due to misalignment of the skills learned at the university with what is required in the workplace. Companies spend crucial resources to train personnel whose academic backgrounds are not only based on “computing disciplines” but also on non-computing ones. Analyzing the gap between the software industry and academia is important for three reasons: (1) for employers, hiring properly trained practitioners allows them to spend less time in training them while incorporating them more efficiently into the workforce; (2) for practitioners, knowing the most important skillset is helpful to increase their chance of employability; and (3) for academia, understanding the necessary skillset is critical to making curriculum changes. To achieve these objectives, we conducted a survey that yielded responses from 659 software professionals working worldwide in different roles. In this study, we only included the responses of 393 embedded software practitioners whose undergraduate degree was completed in Turkey, working in 10 countries. This article sheds light on the most important skills in the embedded software industry by presenting various cross-factor analyses. Understanding the coverage of these skills in the curriculum (mostly in Turkish universities) helps bridge the gaps, which can and should be achieved through more Industry Academia Collaborations (IACs).",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3179576898",
    "type": "article"
  },
  {
    "title": "An Interpretable Machine Learning Model Enhanced Integrated CPU-GPU DVFS Governor",
    "doi": "https://doi.org/10.1145/3470974",
    "publication_date": "2021-10-18",
    "publication_year": 2021,
    "authors": "Jurn-Gyu Park; Nikil Dutt; Sung-Soo Lim",
    "corresponding_authors": "",
    "abstract": "Modern heterogeneous CPU-GPU-based mobile architectures, which execute intensive mobile gaming/graphics applications, use software governors to achieve high performance with energy-efficiency. However, existing governors typically utilize simple statistical or heuristic models, assuming linear relationships using a small unbalanced dataset of mobile games; and the limitations result in high prediction errors for dynamic and diverse gaming workloads on heterogeneous platforms. To overcome these limitations, we propose an interpretable machine learning (ML) model enhanced integrated CPU-GPU governor: (1) It builds tree-based piecewise linear models (i.e., model trees) offline considering both high accuracy (low error) and interpretable ML models based on mathematical formulas using a simulatability operation counts quantitative metric. And then (2) it deploys the selected models for online estimation into an integrated CPU-GPU Dynamic Voltage Frequency Scaling governor. Our experiments on a test set of 20 mobile games exhibiting diverse characteristics show that our governor achieved significant energy efficiency gains of over 10% (up to 38%) improvements on average in energy-per-frame with a surprising-but-modest 3% improvement in Frames-per-Second performance, compared to a typical state-of-the-art governor that employs simple linear regression models.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3206763569",
    "type": "article"
  },
  {
    "title": "DL-RSIM: A Reliability and Deployment Strategy Simulation Framework for ReRAM-based CNN Accelerators",
    "doi": "https://doi.org/10.1145/3507639",
    "publication_date": "2022-01-31",
    "publication_year": 2022,
    "authors": "Wei‐Ting Lin; Hsiang-Yun Cheng; Chia-Lin Yang; Meng-Yao Lin; Kai Lien; Han-Wen Hu; Hung-Sheng Chang; Hsiang-Pang Li; Meng‐Fan Chang; Yen-Ting Tsou; Chin-Fu Nien",
    "corresponding_authors": "",
    "abstract": "Memristor-based deep learning accelerators provide a promising solution to improve the energy efficiency of neuromorphic computing systems. However, the electrical properties and crossbar structure of memristors make these accelerators error-prone. In addition, due to the hardware constraints, the way to deploy neural network models on memristor crossbar arrays affects the computation parallelism and communication overheads. To enable reliable and energy-efficient memristor-based accelerators, a simulation platform is needed to precisely analyze the impact of non-ideal circuit/device properties on the inference accuracy and the influence of different deployment strategies on performance and energy consumption. In this paper, we propose a flexible simulation framework, DL-RSIM, to tackle this challenge. A rich set of reliability impact factors and deployment strategies are explored by DL-RSIM, and it can be incorporated with any deep learning neural networks implemented by TensorFlow. Using several representative convolutional neural networks as case studies, we show that DL-RSIM can guide chip designers to choose a reliability-friendly design option and energy-efficient deployment strategies and develop optimization techniques accordingly.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4210819681",
    "type": "article"
  },
  {
    "title": "Minimizing Stack Memory for Partitioned Mixed-criticality Scheduling on Multiprocessor Platforms",
    "doi": "https://doi.org/10.1145/3506703",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Qingling Zhao; Mengfei Qu; Zonghua Gu; Haibo Zeng",
    "corresponding_authors": "",
    "abstract": "A Mixed-Criticality System (MCS) features the integration of multiple subsystems that are subject to different levels of safety certification on a shared hardware platform. In cost-sensitive application domains such as automotive E/E systems, it is important to reduce application memory footprint, since such a reduction may enable the adoption of a cheaper microprocessor in the family. Preemption Threshold Scheduling (PTS) is a well-known technique for reducing system stack usage. We consider partitioned multiprocessor scheduling, with Preemption Threshold Adaptive Mixed-Criticality (PT-AMC) as the task scheduling algorithm on each processor and address the optimization problem of finding a feasible task-to-processor mapping with minimum total system stack usage on a resource-constrained multi-processor. We present the Extended Maximal Preemption Threshold Assignment Algorithm (EMPTAA), with dual purposes of improving the taskset’s schedulability if it is not already schedulable, and minimizing system stack usage of the schedulable taskset. We present efficient heuristic algorithms for finding sub-optimal yet high-quality solutions, including Maximum Utilization Difference based Partitioning (MUDP) and MUDP with Backtrack Mapping (MUDP-BM), as well as a Branch-and-Bound (BnB) algorithm for finding the optimal solution. Performance evaluation with synthetic task sets demonstrates the effectiveness and efficiency of the proposed algorithms.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4214829469",
    "type": "article"
  },
  {
    "title": "Graph Transformations for Memory Peak Minimization by Scheduling",
    "doi": "https://doi.org/10.1145/3707206",
    "publication_date": "2025-01-23",
    "publication_year": 2025,
    "authors": "Pascal Fradet; Alain Girault; Alexandre Honorat",
    "corresponding_authors": "",
    "abstract": "Many computing systems are constrained by a fixed amount of available shared memory. Modeling applications with task graphs or Synchronous DataFlow (SDF) graphs makes it possible to analyze and optimize their memory usage. The NP-complete problem studied here is to find a sequential schedule of dataflow graphs that minimizes their memory peak. We propose four task graph transformations that reduce the graph size while preserving the minimal memory peak. They are able to compress all Series-Parallel Directed Acyclic Graphs (SP-DAG) to a single node representing an optimal schedule (optimal in the sense that its memory peak is minimal). They also offer simple criteria to schedule optimally independent tasks and guided us to develop an optimal compositional scheduling analysis. These transformations are quite effective and compress a large class of graphs into a single node representing an optimal schedule. When this is not the case, we propose an optimized branch and bound algorithm to complete the analysis of the reduced graphs. This algorithm is able to find the optimal schedule of graphs comprising up to 100 tasks. Our approach also applies to SDF graphs after converting them to task graphs. However, since this conversion may produce huge graphs, we also describe a new suboptimal method, similar to Partial Expansion Graphs, to reduce the graph and schedule sizes. We evaluate our approach on classic benchmarks, on which we always outperform the state-of-the-art.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402386650",
    "type": "article"
  },
  {
    "title": "SmartTBD: Smart Tracking for Resource-constrained Object Detection",
    "doi": "https://doi.org/10.1145/3703912",
    "publication_date": "2025-01-06",
    "publication_year": 2025,
    "authors": "Sihan Zhou; Alejandra C. Hernandez; Clara Gómez; Wenjie Yin; Mårten Björkman",
    "corresponding_authors": "",
    "abstract": "With the growing demand for video analysis on mobile devices, object tracking has demonstrated to be a suitable assistance to object detection under the Tracking-By-Detection (TBD) paradigm for reducing computational overhead and power demands. However, performing TBD with fixed hyper-parameters leads to computational inefficiency and ignores perceptual dynamics, as fixed setups tend to run suboptimally, given the variability of scenarios. In this article, we propose SmartTBD, a scheduling strategy for TBD based on multi-objective optimization of accuracy-latency metrics. SmartTBD is a novel deep reinforcement learning based scheduling architecture that computes appropriate TBD configurations in video sequences to improve the speed and detection accuracy. This involves a challenging optimization problem due to the intrinsic relation between the video characteristics and the TBD performance. Therefore, we leverage video characteristics, frame information, and the past TBD results to drive the optimization problem. Our approach surpasses baselines with fixed TBD configurations and recent research, achieving accuracy comparable to pure detection while significantly reducing latency. Moreover, it enables performance analysis of tracking and detection in diverse scenarios. The method is proven to be generalizable and highly practical in common video analytics datasets on resource-constrained devices.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406102927",
    "type": "article"
  },
  {
    "title": "HeterogeneousRTOS: A CPU-FPGA Real-Time OS for Fault Tolerance on COTS at Near-Zero Timing Cost",
    "doi": "https://doi.org/10.1145/3712062",
    "publication_date": "2025-01-17",
    "publication_year": 2025,
    "authors": "Francesco Ratti; Johannes Knödtel; Marc Reichenbach",
    "corresponding_authors": "",
    "abstract": "Ionizing particles in the atmosphere may strike circuits causing Single Event Upsets (SEU), affecting the output correctness. Critical real-time systems are traditionally custom-designed, featuring redundancy for guaranteeing fault resilience. The downsides of such custom systems are typically weight, power, energy, space, and cost, compared to Commercial Off-the-Shelf (COTS) solutions. We explored the use of COTS in critical real-time environments by designing a CPU-FPGA heterogeneous system, which features an ARM CPU, running a modified version of FreeRTOS and an FPGA, on which the fault-detector and the scheduler are synthesized, in a redundant configuration for increasing fault resiliency. Moving the scheduler to the FPGA increases its fault resiliency while removing the periodic scheduler execution overhead from the CPU, making the scheduler overhead negligible and allowing for an elevated time resolution: the tasks can almost completely utilize the CPU time. Similarly, synthesizing the fault detector on the FPGA allows the execution of the fault detection in a fault-tolerant way without wasting CPU time. Transient fault resiliency in application tasks is achieved via fault detection and the subsequent fault recovery via re-execution. The fault detector implemented on FPGA uses a machine learning technique to model the behavior of tasks (offline and possibly online) and analyses it during their execution. Regarding fault recovery, the scheduler on the FPGA features a novel mixed-criticality scheduling algorithm that manages re-executions, ensuring the meeting of tasks’ timing constraints. The fault detection showed noticeable results while providing a lower overhead than general-purpose software techniques for improving fault resiliency. To the best of our knowledge, the integrated CPU-FPGA version of the system, featuring fault-tolerance and real-time scheduling, is a novel contribution that may enable the use of low-cost and fast COTS components in critical real-time environments. The source code for both hardware and software was released as open source.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406536903",
    "type": "article"
  },
  {
    "title": "Abnormality Detection Using Power Rising and Descending Signature (PRIDES)",
    "doi": "https://doi.org/10.1145/3711834",
    "publication_date": "2025-01-24",
    "publication_year": 2025,
    "authors": "Ashish Mahanta; Haibo Wang",
    "corresponding_authors": "",
    "abstract": "This paper presents a new paradigm for abnormality detection using a novel power signature that characterizes the rising and descending patterns of energy consumption. The proposed methodology includes a low-overhead power signature generation circuit, computation-light analysis methods, and optimal generation of the golden signature used in the analysis. The proposed power signature generation circuit is designed using 90 nm CMOS technology, and its operation is validated via circuit simulations. The effectiveness of the proposed method in detecting the insertion of potentially malicious code is demonstrated with data obtained from hardware experiments and circuit simulations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406803477",
    "type": "article"
  },
  {
    "title": "PUF-Dilithium: Design of a PUF-Based Dilithium Architecture Benchmarked on ARM Processors",
    "doi": "https://doi.org/10.1145/3715328",
    "publication_date": "2025-01-25",
    "publication_year": 2025,
    "authors": "Saeed Aghapour; Kasra Ahmadi; Mila Anastasova; Reza Azarderakhsh; Mehran Mozaffari Kermani",
    "corresponding_authors": "",
    "abstract": "Addressing the looming threat posed by quantum computers capable of breaching current public key cryptography schemes has become imperative. To this end, the National Institute of Standards and Technology (NIST) initiated a competition in Post-Quantum Cryptography (PQC), resulting in the selection of four schemes as the new standardized replacements, while a fourth round and an additional signature round is still ongoing. Notably, CRYSTALS-Dilithium, a lattice-based signature scheme, has exhibited promising resilience due to its efficiency and simplicity. Despite the finalization of standardization for these new four schemes, transitioning from classical cryptography to these alternatives necessitates further investigation and analysis. Comprehensive scrutiny of these newly standardized schemes is imperative, including considerations of implementation efficiency across various platforms and side-channel vulnerability analysis. This paper introduces a novel design leveraging physical unclonable functions (PUFs) to bolster the physical security of CRYSTALS-Dilithium. Physical security is paramount in scenarios where network nodes are exposed to public scrutiny, potentially making them targets for adversaries. After discussing the advantages of our design compared to the original design, we implemented it on two different architectures, ARMv7 and ARMv8. Our results indicate substantial improvements in both security and performance compared to existing references. Moreover, noting the new competition initiated by the NIST in 2023 for new signatures (first round finalized in October 2024), potentially the proposed schemes can be adopted to the new standards set to be finalized in the coming years. These make our scheme not solely confined to the current standards and would be an important merit of the presented approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406824424",
    "type": "article"
  },
  {
    "title": "Automatic Generation of Fast and Accurate Performance Models for Deep Neural Network Accelerators",
    "doi": "https://doi.org/10.1145/3715122",
    "publication_date": "2025-01-25",
    "publication_year": 2025,
    "authors": "Konstantin Lübeck; A. Jung; Felix Wedlich; Mika Markus Müller; Federico Peccia; Felix Thömmes; Jannik Steinmetz; Valentin Biermaier; Adrian Frischknecht; Paul Palomero Bernardo; Oliver Bringmann",
    "corresponding_authors": "",
    "abstract": "Implementing Deep Neural Networks (DNNs) on resource-constrained edge devices is a challenging task that requires tailored hardware accelerator architectures and a clear understanding of their performance characteristics when executing the intended AI workload. To facilitate this, we present an automated generation approach for fast performance models to accurately estimate the latency of a DNN mapped onto systematically modeled and concisely described accelerator architectures. Using our accelerator architecture description method, we modeled representative DNN accelerators such as Gemmini, UltraTrail, Plasticine-derived, and a parameterizable systolic array. Together with DNN mappings for those modeled architectures, we perform a combined DNN/hardware dependency graph analysis, which enables us, in the best case, to evaluate only 154 loop kernel iterations to estimate the performance for 4.19 billion instructions achieving a significant speedup. We outperform regression and analytical models in terms of mean absolute percentage error (MAPE) compared to simulation results, while being several magnitudes faster than an RTL simulation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406825384",
    "type": "article"
  },
  {
    "title": "FirmCAN: Sensitive CAN Knowledge Leakage from Automotive ECUs",
    "doi": "https://doi.org/10.1145/3711832",
    "publication_date": "2025-01-31",
    "publication_year": 2025,
    "authors": "Xinpeng Hao; Xiangxue Li",
    "corresponding_authors": "",
    "abstract": "As de facto standards of in-vehicle network communications among various ECUs (Electronic Control Units), CAN (Controller Area Network) protocols invented by Bosch rely on the privately-defined unique identifiers CAN ID in CAN messages which do not convey any destination address. On the other hand, sticking to error handling mechanisms in CAN protocols, an ECU with an amount of transmission errors would enter bus-off state (i.e., go offline thereupon) and shall be recovered according to some prescribed bus-off recovery mode (BOM). All these sensitive CAN knowledge concealed inside an ECU by OEMs (Original Equipment Manufacturers) shall not be revealed and could be found extensive practical applications to both adversarial behavior (e.g., target ECU attacks) and security enhancement mechanisms (e.g., intrusion detection system designs). The paper presents FirmCAN, the first automatic analysis framework to dope out sensitive CAN knowledge (CAN IDs and bus-off recovery mode in particular) compiled in automotive ECU firmwares. FirmCAN first identifies base address (using accurate absolute function entry addresses), and then performs CAN module API positioning and sensitive configuration information resolution. We buckle down to automotive ECUs that resort to fixed-address mailboxes as CAN module transmission buffers (e.g., Renesas SuperH/RA series) and present concrete algorithms for each analysis phase. Our experimental evaluations first investigate firmwares extracted from real automotive ECUs. We then develop our own applications using RA6M4 development boards, which not only produce required firmwares to evaluate FirmCAN, but also create ground truth through hardware debugging. All evaluations demonstrate that FirmCAN can accurately garner above-mentioned sensitive CAN knowledge. FirmCAN can be trivially generalized to engage in extended frames and CAN modules with similar transmission logic, e.g., TI (Texas Instruments), ST (ST Microelectronics), etc.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407049657",
    "type": "article"
  },
  {
    "title": "A Compact and Parallel Swap-Based Shuffler Based on Butterfly Network and Its Complexity Against Side Channel Analysis",
    "doi": "https://doi.org/10.1145/3715961",
    "publication_date": "2025-02-03",
    "publication_year": 2025,
    "authors": "Jong-Yeon Park; Seonggyeom Kim; W.C. Lee; Bo Gyeong Kang; I.S. Song; J. H. Oh; Kouichi Sakurai",
    "corresponding_authors": "",
    "abstract": "A prominent countermeasure against side-channel attacks, the hiding countermeasure , typically involves shuffling operations using a permutation algorithm. This is especially crucial in the era of Post-Quantum Cryptography, where computational characteristics of lattice and code-based cryptography heighten the need for robust defenses. In this context, securely and efficiently generating permutations is critical for an algorithm’s overall security and performance. Among the various approaches, the Fisher-Yates shuffle is widely adopted due to its security and ease of implementation. However, it is limited by a complexity of \\(\\mathcal {O}(N) \\) due to its sequential nature. In response, we propose a time-area trade-off swap algorithm, \\(\\mathsf {FSS} \\) , that leverages a Butterfly Network structure, achieving only log ( N ) depth, log ( N ) work, and \\(\\mathcal {O}(1) \\) operation time in parallel. Our analysis calculates the maximum gain an attacker can achieve through butterfly operations with log ( N ) depth, from a side-channel analysis perspective. Notably, we derive a generalized formula for the attack complexity of higher-order side-channel attacks for arbitrary input sizes, utilizing the fractal structure of the butterfly network. Moreover, our research demonstrates the efficiency and security of this permutation approach across different platforms. We include practical implementation results on ASIC, as well as on CPU and GPU architectures, which underscore the algorithm’s performance advantages and robustness across diverse hardware environments. Through this exploration, we show that efficient and secure permutations can indeed be achieved with minimal randomness requirements.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407108066",
    "type": "article"
  },
  {
    "title": "Side Channel Attacks on GPRS Standard Encryption Algorithms",
    "doi": "https://doi.org/10.1145/3716385",
    "publication_date": "2025-02-10",
    "publication_year": 2025,
    "authors": "Zheng Wu; Lin Ding; Zhengting Li; Xinhai Wang; Ziyu Guan",
    "corresponding_authors": "",
    "abstract": "GEA-1 and its successor GEA-2 are stream ciphers that were selected as the General Packet Radio Service (GPRS) standard encryption algorithms, used to protect the communication between phones and base stations from eavesdropping. These stream ciphers, once widely used for GPRS encryption in the late 1990s and early 2000s, are surprisingly still supported in many current mobile phones and in numerous developing regions even today. GEA-2a is a more secure, improved version of GEA-2 designed by Ding et al. in 2022. Side channel attack utilizes easily accessible information from cryptographic devices, such as power consumption, electromagnetic radiation, and runtime, to obtain secret information in the cryptographic systems. Side channel attack is a powerful attack method that has been successfully applied in many stream ciphers, such as TRIVIUM and GRAIN-128-AEAD. In this article, we put forward an automated framework that can mount side channel attack on stream ciphers with structures similar to the GPRS standard encryption algorithms GEA-1 and GEA-2. We use satisfiability modulo theory for modeling, while considering the software and hardware implementation of the algorithms, and use Microsoft’s open source solver Z3 to solve the constructed instances. The experimental results indicate that the internal states of GEA-1, GEA-2, and GEA-2a in the keystream generation phase can be recovered practically under the HW/32 model. For models where the solution time is too long, by guessing a small number of bits, the state bits can be fully recovered within an acceptable time. Our automated framework is effective in both noiseless and noisy trace scenarios.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407301531",
    "type": "article"
  },
  {
    "title": "Formal Modeling of Hybrid System Based on Semi-continuous Colored Petri Net: A Case Study of Adaptive Cruise Control System",
    "doi": "https://doi.org/10.1145/3715960",
    "publication_date": "2025-02-10",
    "publication_year": 2025,
    "authors": "Wangyang Yu; Qi Guo; Yumeng Cheng; Lu Liu; Fei Hao; Xiaojun Zhai; Minsi Chen",
    "corresponding_authors": "",
    "abstract": "Many Next-Generation consumer electronic devices would be distributed hybrid electronic systems, such as UAVs (Unmanned Aerial Vehicles) and smart electronic cars. The safety and risk control are the key issues for the sustainability of such consumer electronic systems. The modeling of hybrid electronic systems is difficult to be abstracted by traditional Petri Nets. This also makes the reachable marking graph unable to be applied to Petri nets of the hybrid electronic systems. This paper proposes a novel Petri Net to model and analyze the hybrid electronic systems. We name it a Semi-continuous Colored Petri Net (SCPN) that inherits the excellent modeling capabilities and analysis methods of Petri Nets, and can formally depict hybrid quantities. In addition, we propose the construction algorithm for an SCPN reachable marking graph and prove its finiteness. Finally, we model and analyze an Adaptive Cruise Control (ACC) system of smart electronic cars as an example to prove the validity of SCPN. We use the proposed SCPN to model and analyze the running process of an ACC system under the continuous deceleration scenario of the front vehicle. The application study shows that the ACC system has logic flaws under the constant headway strategy when the front vehicle continues to decelerate. Based on this analysis, improvements to the SCPN of the ACC system are made, effectively enhancing its safety and logical correctness.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407301575",
    "type": "article"
  },
  {
    "title": "MemATr: An Efficient and Lightweight Memory-augmented Transformer for Video Anomaly Detection",
    "doi": "https://doi.org/10.1145/3719203",
    "publication_date": "2025-02-21",
    "publication_year": 2025,
    "authors": "Jingjing Chang; Peining Zhen; Xiaotao Yan; Yixin Yang; Ziyang Gao; Hai‐Bao Chen",
    "corresponding_authors": "",
    "abstract": "Anomaly detection in videos is a long-standing and challenging problem. Previous methods often adopt deep and large neural networks to achieve the best detection accuracy; however, the high computational costs prevent them from being used in real-world applications with constrained computational resources. In this paper, we develop a mem ory- a ugmented tr ansformer named MemATr, which is capable of detecting video anomalies effectively. The proposed network is lightweight and can be easily deployed on mobile devices. Furthermore, we propose a memory transformer module to make predictions that are closer to normal inputs, thereby leading to a higher error for abnormal input patterns. Memory-attention is the main component of the proposed memory transformer, which can retrieve the features from learnable values rather than from the backbone like previous methods. Extensive experiments on the UCSD Ped2, CUHK Avenue, and ShanghaiTech benchmarks can demonstrate that our model has a significantly smaller model size while still achieving competitive detection accuracy. Our model has only 1/12 the number of parameters of the baseline model. Besides, our model achieves a 4.6% increase in accuracy on the ShanghaiTech dataset and has roughly the same accuracy compared with the baseline on the other two datasets. We validate the performance of the proposed model on the mobile device and the result shows it only has 49.8ms latency. The effectiveness of the proposed method on mobile devices is further supported by experimental results. A new quantitative parameter AMD (Applicability for Mobile Devices) is proposed to offer a novel approach to assist in making trade-offs for mobile devices. The proposed model obtains state-of-the-art results in terms of AMD.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407813694",
    "type": "article"
  },
  {
    "title": "Faster than Fast: Accelerating Oriented FAST Feature Detection on Low-end Embedded GPUs",
    "doi": "https://doi.org/10.1145/3725217",
    "publication_date": "2025-03-18",
    "publication_year": 2025,
    "authors": "Qiong Chang; Xinyuan Chen; Xiang Li; Weimin Wang; Jun Miyazaki",
    "corresponding_authors": "",
    "abstract": "The visual-based SLAM (Simultaneous Localization and Mapping) is a technology widely used in applications such as robotic navigation and virtual reality, which primarily focuses on detecting feature points from visual images to construct an unknown environmental map and simultaneously determines its own location. It usually imposes stringent requirements on hardware power consumption, processing speed and accuracy. Currently, the ORB (Oriented FAST and Rotated BRIEF)-based SLAM systems have exhibited superior performance in terms of processing speed and robustness. However, they still fall short of meeting the demands for real-time processing on mobile platforms. This limitation is primarily due to the time-consuming Oriented FAST calculations accounting for approximately half of the entire SLAM system. This paper presents two methods to accelerate the Oriented FAST feature detection on low-end embedded GPUs. These methods optimize the most time-consuming steps in Oriented FAST feature detection: FAST feature point detection and Harris corner detection, which is achieved by implementing a binary-level encoding strategy to determine candidate points quickly and a separable Harris detection strategy with efficient low-level GPU hardware-specific instructions. Extensive experiments on a Jetson TX2 embedded GPU demonstrate an average speedup of over 7.3 times compared to widely used OpenCV with GPU support. This significant improvement highlights its effectiveness and potential for real-time applications in mobile and resource-constrained environments.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408550645",
    "type": "article"
  },
  {
    "title": "A Workload-Balance-Aware Accelerator Enabling Dense-to-Arbitrary-Sparse Neural Networks",
    "doi": "https://doi.org/10.1145/3725532",
    "publication_date": "2025-03-20",
    "publication_year": 2025,
    "authors": "Zihao Zhao; Yanhong Wang; Jin Xu; Haotian Zheng; Maohua Nie; Longfei Gou; Junmin He; Yongchuan Dong; Qiaosha Zou; Y.C. Zhang; C.‐J. Richard Shi",
    "corresponding_authors": "",
    "abstract": "Deep neural networks (DNNs) have proved their great potential over various perceptual and cognitive tasks with the cost of ever-growing storage capacity and computation complexity. Sparse representations in neural networks have emerged as a compelling method to achieve substantial reductions in computational overhead and energy consumption. However, the introduction of sparsity presents challenges such as irregular memory accesses and wasted computation cycles. Traditional methods have attempted to address these challenges with varied success, unfortunately, often involving complex hardware designs or sacrificing sparsity’s benefits. In this paper, we propose a software-hardware co-design solution, comprising an offline workload balancing encoding algorithm toward arbitrary sparsity in DNNs, and a dedicated Processing Element (PE) array-based accelerator with a lightweight switch network. Extensive experiments are conducted to demonstrate the conclusion that our proposal is feasible to support various network structures and a wide range of sparsity ratios. With the encoding algorithm, a 1.16x-2.61x acceleration is achieved compared to the baseline. The system-on-chip measures 7.9 mm 2 , achieving an energy efficiency of 0.7TOPS/W (dense), 2.1TOPS/W (at 75% sparsity), and 10.3TOPS/W (at 99.9% sparsity) at 0.9V and 1066MHz clock frequency.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408684581",
    "type": "article"
  },
  {
    "title": "A VC Dimension-Oriented Improvement Method of PUFs for the Anti-Modeling-Attack Capability",
    "doi": "https://doi.org/10.1145/3727340",
    "publication_date": "2025-04-01",
    "publication_year": 2025,
    "authors": "Yongliang Chen; Xiaole Cui; Sunrui Zhang; Xiaoxin Cui",
    "corresponding_authors": "",
    "abstract": "The physical unclonable function (PUF) serves as a security primitive of circuits, which is applicable to the embedded systems with lightweight authentication function. However, the modeling attack, which estimates the unknown CRPs by establishing the mathematical model of PUF, is a real threat to the PUF based crypto-systems. Subsequently, the anti-modeling-attack PUF becomes a research hotspot. The systematic design method of secure PUF is still a open issue, although some secure PUF schemes have been proposed based on the repeated trials. This work proposes a security improvement method of PUFs to enhance the anti-modeling-attack capability. The growth function and the Vapnik-Chervonenkis (VC) dimension of PUF are defined as the indicators of PUF security. The proposed method regards the improvement of PUF as an optimization problem, which aims to obtain a PUF scheme with the better security indicators. Guided by the indicators, the proposed method is able to specify the improvement sites of PUF and the techniques to be applied. In addition, three approaches are proposed to inspire the new security improvement techniques. An improved arbiter PUF and an improved array-based PUF are designed as the instances of the results from the proposed method. Both of the improved PUF schemes have the stronger security than the original schemes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409062053",
    "type": "article"
  },
  {
    "title": "RPFF-PA : Reliable and Parallel Fault-tolerant Framework for Path Latency Reduction Deployed in Register Arrays",
    "doi": "https://doi.org/10.1145/3728471",
    "publication_date": "2025-04-07",
    "publication_year": 2025,
    "authors": "Jiawei Nian; Mengfei Yang; Xin Gao; Hongjin Liu; Fang Fang; Long Cheng; Xingtang Wu",
    "corresponding_authors": "",
    "abstract": "Soft errors can lead to electronic device failures caused by radiation events. Therefore, fault-tolerant designs are essential for safeguarding critical memory components and processors. The N-modular redundancy (NMR) scheme presents a practical means of implementing register protection. However, the NMR fault-tolerant scheme is serially configured on the critical path, increasing path latency of approximately 12.4 \\(\\% \\) -35.5 \\(\\% \\) . In this paper, we propose a parallel fault-tolerant framework for register arrays(RPFF-PA), which realizes the parallelized execution of hardern processes and read/write operations. By executing the decoding process in parallel with the decision circuit, the latency cost caused by fault-tolerant components is significantly reduced. The results demonstrate that the strategy reduces path latency by 5.2 \\(\\% \\) -20.3 \\(\\% \\) compared to the original NMR approach. Furthermore, the framework includes a real-time error correction module capable of effectively addressing the error accumulation issue, thereby enhancing the reliability of the fault-tolerant system.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409211784",
    "type": "article"
  },
  {
    "title": "AI Attacks AI: Recovering Neural Network Architecture from NVDLA Using AI-Assisted Side Channel Attack",
    "doi": "https://doi.org/10.1145/3731560",
    "publication_date": "2025-04-21",
    "publication_year": 2025,
    "authors": "Naina Gupta; Arpan Jati; Anupam Chattopadhyay",
    "corresponding_authors": "",
    "abstract": "During the last decade, there has been a stunning progress in the domain of Artificial Intelligence (AI) aided by highly trained Machine Learning (ML) models. Such models are valuable Intellectual Property (IP) and, therefore, have been subjected to various model recovery attacks. In this work, we study the vulnerabilities of commercial, open-source accelerator NVDLA and present the first successful model recovery attack. For this purpose, we used power and timing information from the side-channel leakage of convolutional neural networks (CNN) models to train CNN-based attack models. Utilizing these attack models, we demonstrate that even with a highly pipelined architecture, multiple parallel execution in the accelerator along with Linux OS running tasks in the background, recovery of number of layers, kernel sizes, output neurons and distinguishing different layers, is possible with very high accuracy. This is also the first work to show the impact of differences in hyperparameters on the power traces. Our solution is fully automated, AI-based, and portable to other hardware neural networks, thus presenting a greater threat toward IP protection. Using LeNet as the target victim model, we demonstrate an accuracy of more than 95% in recovering various parameters. This study presents a serious practical threat, in the form of side-channel attack, towards complex commercial architectures. Furthermore, we show that AI-guided attack significantly boosts the attacker capability.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409623750",
    "type": "article"
  },
  {
    "title": "Intermediary Output Caching for Diffusion Model-Based Text-to-Image GenAI Services in Edge Computing Networks",
    "doi": "https://doi.org/10.1145/3733106",
    "publication_date": "2025-04-28",
    "publication_year": 2025,
    "authors": "Yanyi Li; Jiangtian Nie; Shaobo Li; Kebing Jin; Jianhang Tang; Yang Zhang; Dusit Niyato",
    "corresponding_authors": "",
    "abstract": "The remarkable advancement of generative artificial intelligence (GenAI) has driven revolutionary applications for text-to-image generation, like Stable Diffusion and Imagen. Especially, the diffusion model can generate stunning images from natural language descriptions by using a reverse continuous denoising process. However, the computation burden of diffusion model-based GenAI services poses a significant hurdle for their practical implementation. In this work, we propose a novel edge computing-assisted GenAI framework to enable efficient GenAI service provision, where the intermediate output generated by diffusion models can be cached on edge servers and reused by various users to improve edge computing resource utilization. Assuming the existence of causally correlated auxiliary information, a long-term caching problem is formulated under intra-time-slot caching constraints by considering various maximally reusable steps of diffusion model-based GenAI tasks and the available caching capacity at edge servers. By leveraging the Lyapunov optimization framework, we transform the time-average caching problem into several deterministic problems for different time slots. We develop a deep reinforcement learning-based caching (DRC) algorithm to obtain caching decisions in each time slot, where a deep neural network (DNN)-based caching action generation module and a model-based evaluation module are designed. Finally, we conduct extensive simulation experiments by comparing the DRC algorithm with benchmark algorithms. The simulation results depict that the proposed DRC algorithm can reduce response time and improve cache hit rates significantly. The code is available at https://gitee.com/pipihinsky/DRC.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409893269",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Formal Methods and Models for System Design",
    "doi": "https://doi.org/10.1145/3722218",
    "publication_date": "2025-05-12",
    "publication_year": 2025,
    "authors": "Jens Brandt; Indranil Saha; Lijun Zhang",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410287015",
    "type": "article"
  },
  {
    "title": "Diff-Acc: An Efficient FPGA Accelerator for Unconditional Diffusion Models",
    "doi": "https://doi.org/10.1145/3728470",
    "publication_date": "2025-05-14",
    "publication_year": 2025,
    "authors": "Shidi Tang; Ruiqi Chen; Rui Liu; Yixiao Lv; Pengwei Zheng; He Li; Ming Ling",
    "corresponding_authors": "",
    "abstract": "The diffusion model has achieved remarkable success in the era of Artificial Intelligence Generated Content (AIGC) across various tasks, such as image, video, text, material modeling, and molecular design. However, the diffusion model is computational intensive due to the long iteration of the reverse denoising process, which hinders its further advancement. Therefore, there is an urgent need to accelerate the diffusion model, especially in edge scenarios that require real-time computation. While researchers have made efforts to accelerate the diffusion model at the algorithm level using either efficient sampling or model quantization, they still suffer from accuracy degradation. More importantly, they have overlooked the hardware-level acceleration challenge. This work aims to bridge the gap by introducing Diff-Acc , the first FPGA accelerator for unconditional diffusion models with a novel step-wise quantization method that requires minimal calibration data to achieve the state-of-the-art (SOTA) PTQ quantization accuracy. Additionally, we adopt several hardware-oriented optimizations to reduce the computational overhead. At the architecture level, we fully analyze the computation flow of diffusion models and propose a novel architecture with group-wise parallelism to tackle the long iteration challenge. Besides, we decouple the data dependencies and adopt proper computational transformations at the micro-architecture level. Experiments on two unconditional diffusion models (DDIM and DDPM) with two image datasets (CIFAR-10 and ImageNet) demonstrate that our quantization method achieves the substantial improvements in image quality (FID: 6.67, sFID: 11.24) under 8-bit PTQ quantization. Compared with both server-based (Tesla V100 and Intel Xeon) and edge-based (Raspberry Pi 4 and Jetson Nano) platforms, Diff-Acc implemented on the Zynq UltraScale+ XCZU9EG FPGA demonstrates an up-to 12.5 × energy efficiency. Particularly versus edge-based platforms, Diff-Acc achieves up to 10.26 × and 1.97 × performance improvements over CPU and GPU, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410374386",
    "type": "article"
  },
  {
    "title": "Do Not Trust Power Management: A Survey on Internal Energy-based Attacks Circumventing Trusted Execution Environments Security Properties",
    "doi": "https://doi.org/10.1145/3735556",
    "publication_date": "2025-05-14",
    "publication_year": 2025,
    "authors": "Gwenn Le Gonidec; Guillaume Bouffard; Jean-Christophe Prévotet; Maria Méndez Real",
    "corresponding_authors": "",
    "abstract": "Over the past few years, several research groups have introduced innovative hardware designs for Trusted Execution Environments (TEEs), aiming to secure applications against potentially compromised privileged software, including the kernel [10, 63]. Since 2015 [94], a new class of software-enabled hardware attacks leveraging energy management mechanisms has emerged. These internal energy-based attacks comprise fault [86], side-channel [46] and covert channel attacks [28]. Their aim is to bypass TEE security guarantees and expose sensitive information such as cryptographic keys. They have increased in prevalence in the past few years [9, 24, 40]. Popular TEE implementations, such as ARM TrustZone and Intel SGX, incorporate countermeasures against these attacks. However, these countermeasures either hinder the capabilities of the power management mechanisms or have been shown to provide insufficient system protection [9, 55]. This article presents the first comprehensive knowledge survey of these attacks, along with an evaluation of literature countermeasures. We believe that this study will spur further community efforts towards this increasingly important type of attacks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410375299",
    "type": "article"
  },
  {
    "title": "Reaction Latency Analysis of Message Synchronization in Edge-assisted Autonomous Driving",
    "doi": "https://doi.org/10.1145/3736412",
    "publication_date": "2025-05-16",
    "publication_year": 2025,
    "authors": "Reza Jafarpourmarzouni; FNU Sumaiya; Ruoxiang Li; Nan Guan; Guang Wang; Peipei Zhou; Zheng Dong",
    "corresponding_authors": "",
    "abstract": "In the realm of connected autonomous vehicles, the integration of data from both onboard and edge sensors is vital for environmental perception and navigation. However, the fusion of this sensor data faces challenges due to timestamp disparities, particularly when edge devices are involved. The Robotic Operating System (ROS) addresses this with synchronization policies like Approximate and Exact Time, along with the newer Synchronizing the Earliest Arrival Messages (SEAM). Understanding SEAM’s performance in edge-assisted environments is crucial yet under-explored. This paper presents a comprehensive analysis of SEAM synchronization within ROS. Our study focuses on critical latency metrics for ROS message synchronization in edge-assisted autonomous driving. Specifically, we analyze two key latency metrics, the passing latency and reaction latency, which are needed to analyze the end-to-end delay and reaction time on the system level. We conduct experiments under different settings to evaluate the precision of our proposed latency upper bounds against the maximum experimental latency in simulation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410443644",
    "type": "article"
  },
  {
    "title": "Efficient Implementation of LinearUCB through Algorithmic Improvements and Vector Computing Acceleration for Embedded Learning Systems",
    "doi": "https://doi.org/10.1145/3736226",
    "publication_date": "2025-05-24",
    "publication_year": 2025,
    "authors": "Marco Angioli; Marcello Barbirotta; Abdallah Cheikh; Antonio Mastrandrea; Francesco Menichelli; Mauro Olivieri",
    "corresponding_authors": "",
    "abstract": "As the Internet of Things expands, embedding Artificial Intelligence algorithms in resource-constrained devices has become increasingly important to enable real-time, autonomous decision-making without relying on centralized cloud servers. However, implementing and executing complex algorithms in embedded devices poses significant challenges due to limited computational power, memory, and energy resources. 2This article presents algorithmic and hardware techniques to efficiently implement two LinearUCB Contextual Bandits algorithms on resource-constrained embedded devices. Algorithmic modifications based on the Sherman–Morrison–Woodbury formula streamline model complexity, while vector acceleration is harnessed to speed up matrix operations. We analyze the impact of each optimization individually and then combine them in a two-pronged strategy. The results show notable improvements in execution time and energy consumption, demonstrating the effectiveness of combining algorithmic and hardware optimizations to enhance learning models for edge computing environments with low-power and real-time requirements.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410714689",
    "type": "article"
  },
  {
    "title": "Thetis-lathe: Guidance on Reducing Residual Safety Obstacle in System Software from Rust Source Codes",
    "doi": "https://doi.org/10.1145/3736729",
    "publication_date": "2025-05-26",
    "publication_year": 2025,
    "authors": "Renshuang Jiang; Pan Dong; Yan Ding; Ran Wei; Zhe Jiang",
    "corresponding_authors": "",
    "abstract": "Programming languages play a crucial role in ensuring the safety of the Operating System (OS). Traditional low-level languages (e.g., C, C++), while high-performance, usually offer very limited protections on safety, and their vulnerability patches (e.g., AddressSanitizer, DangSan), while effective in mitigating some issues, are often too expensive. Rust language combines memory safety with performance, providing a fresh paradigm for constructing efficient, reliable, and dependable. However, existing Rust rely on unsafe code fragments to interface with low-level hardware and other programming languages, introducing critical issues: (1) compromised system-wide safety due to the presence of unsafe code, (2) inaccurate defect detection because of unavoidable interactions between unsafe and safe code; and (3) difficulty in finding an optimal balance between accuracy and efficiency of defect detection and elimination. In contrast to the previous work, we believe — “ prevention is always better than cure ”. Therefore, we propose a new methodology (namely Thetis) to detect and guide the minimization of unsafe fragments in Rust source code. For unsafe code detection, Thetis designs an automated inspection method based on feature extraction. For unsafe code elimination based on Unsafe Rust types and interchangeability, Thetis prop defect optimization suggestions and designs a framework to automatically provide safer code recommendations. We have designed and implemented a new tool called Thetis-lathe based on Thetis and have also ported Thetis-lathe to three mainstream Rust applications, i.e., BlogOS, rCore, and Miri Failure Set. Evaluations show that our tool improved the accuracy of defects and decreased the amount of unsafe code by 35% and undefined behavior by approximately 50%. Furthermore, Thetis-lathe speeds up the run-time about 5x compared with the sanitizer and LMbench results indicate that our approach introduces 7.6% (average) performance overhead on the entire system.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410747805",
    "type": "article"
  },
  {
    "title": "Towards Accurate RISC-V Full System Simulation via Component-Level Calibration",
    "doi": "https://doi.org/10.1145/3737876",
    "publication_date": "2025-06-04",
    "publication_year": 2025,
    "authors": "Karan Pathak; Joshua Klein; Giovanni Ansaloni; Said Hamdioui; Georgi Gaydadjiev; Marina Zapater; David Atienza",
    "corresponding_authors": "",
    "abstract": "Full-System (FS) simulation is essential for performance evaluation of complete systems that execute complex applications on a complete software stack consisting of an operating system and user applications. Nevertheless, they require careful fine-tuning against real hardware to obtain reliable performance statistics, which can become tedious, error-prone, and time-consuming with typical trial-and-error approaches. We propose a novel, streamlined, component-level calibration methodology to address these shortcomings to validate FS simulation models. Our methodology greatly accelerates the validation process without sacrificing accuracy. It is Instruction Set Architecture (ISA)-agnostic, and can tackle hardware specifications at different levels of detail. We demonstrate its effectiveness by validating FS models against both open-hardware and IP-protected (closed hardware) RISC-V silicon, achieving a mean error of 19%–23% for the SPEC CPU2017 suite in the two cases. We introduce the first open-source RISC-V-based FS-validated simulation models with a complete and replicable methodology.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411031224",
    "type": "article"
  },
  {
    "title": "Activation Map-based Knowledge Distillation for Real-time Cervical OCT Image Classification",
    "doi": "https://doi.org/10.1145/3746229",
    "publication_date": "2025-06-24",
    "publication_year": 2025,
    "authors": "Qingbin Wang; Yuchen Pei; Wai Chon Wong; Xuefeng Mu; Yan Zhang; Yutao Ma",
    "corresponding_authors": "",
    "abstract": "Cervical cancer is a significant global health concern for women. Optical coherence tomography (OCT) offers a non-invasive, high-resolution imaging method for cervical examinations. The clinical need for real-time AI-aided diagnosis in low-resource settings necessitates model compression for deep learning models. Therefore, we develop a novel activation map-based knowledge distillation (AMKD) framework to address this issue. The AMKD framework ensures that the compressed (student) model achieves classification performance approximating that of the teacher model while maintaining the same activation area, enhancing interpretability for gynecologists. Due to the lack of high-quality annotated data, we also utilize unlabeled images for self-supervised distillation pre-training to improve model performance. On an internal dataset, the compressed models based on ResNet, ConvNeXt, and Swin-Transformer outperformed existing knowledge distillation frameworks while demonstrating better interpretability. On two external validation sets, the best compressed (ResNet) model surpassed the average performance of four medical experts in sensitivity and negative predictive value for cervical OCT volume classification, showcasing enhanced lesion detection capabilities. For a cervical OCT image of 760 × 1200 pixels, the compressed ResNet model with 1.37 M parameters uses 1.13 GB GPU memory during inference and predicts the input image in 0.06 seconds, potentially improving real-time detection of cervical lesions in resource-limited clinical settings.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411576412",
    "type": "article"
  },
  {
    "title": "Latency-Aware Pruning and Quantization of Self-Supervised Speech Transformers for Edge Devices",
    "doi": "https://doi.org/10.1145/3746638",
    "publication_date": "2025-06-28",
    "publication_year": 2025,
    "authors": "Seyed Milad Ebrahimipour; Seyyed Hasan Mozafari; James J. Clark; Warren J. Gross; Brett H. Meyer",
    "corresponding_authors": "",
    "abstract": "The growing adoption of self-supervised learning transformers for speech (speech SSL) is constrained by their significant computational and memory demands, making deployment on resource-constrained edge devices challenging. We propose a latency-aware compression framework that integrates structured pruning and quantization to address these challenges. Guided by a latency model that considers the combined effects of pruning and quantization, our method dynamically identifies and removes less critical blocks while maintaining task performance, avoiding the inefficiencies of over-pruning and under-pruning seen in prior approaches. Unlike prior methods specialized in either post-training compression without fine-tuning data or in cases where fine-tuning data is available, our method is effective in both settings. Experimental results show that, in task-agnostic compression, our method achieves a 4.2 × speedup on the Hikey970 edge development platform, outperforming previous task-agnostic pruning methods in most tasks, while requiring only 21–24 GPU hours—a 3 × reduction compared to prior methods. Additionally, our method achieves a lower word error rate of 7.8% using task-specific pruning, while reducing computational overhead by approximately 19.4% in terms of GFLOPs compared to previous task-specific methods. Finally, our method consistently achieves higher accuracy than the state-of-the-art post-training compression approach across various latency speedup constraints, even without fine-tuning data.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411757453",
    "type": "article"
  },
  {
    "title": "Wi-GPD Identification System Based on Gait Point Density",
    "doi": "https://doi.org/10.1145/3746639",
    "publication_date": "2025-07-03",
    "publication_year": 2025,
    "authors": "Ying Liu; Zhe Cao; Jianlin Cai; Yuqing He; Mengting Hu",
    "corresponding_authors": "",
    "abstract": "A significant challenge currently facing Wi-Fi-based gait recognition technology is that changes in walking paths in a multipath environment can significantly interfere with the CSI gait signal collected via Wi-Fi, which greatly hinders the application of this technology in real life. To deal with this problem, most existing Wi-Fi gait recognition systems adopt the strategy of fixing walking paths or using multiple receivers, but these methods undoubtedly increase the complexity and cost of the system. This paper proposes an innovative solution: an identification system independent of the walking path and requires only a pair of transceivers. The system is based on the identification of the IQ signal density characteristics. Specifically, the CSI signal is first decomposed and reconstructed using VMD technology, eliminating noise interference in a multipath environment. A unique point density feature is extracted from the IQ signal, which integrates both phase and amplitude information. This feature effectively distinguishes gait and is not influenced by changes in walking paths. At the same time, it can visually highlight the commonalities and differences when depicting the same person and distinguishing between different individuals' gaits, providing a strong basis for gait recognition classification. Finally, the deep learning model was introduced into the identification process, improving the system's accuracy. The experimental results show that in a dataset containing 5-20 testers, the Wi-GPD system achieves an identification accuracy of up to 84.75%-99.5%, thoroughly verifying its effectiveness and reliability.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411977096",
    "type": "article"
  },
  {
    "title": "A Framework for Multi-Robot Programming: From High-Level Specification to Retargetable Deployment",
    "doi": "https://doi.org/10.1145/3747325",
    "publication_date": "2025-07-05",
    "publication_year": 2025,
    "authors": "Woosuk Kang; Eunjin Jeong; Kyonghwan Yoon; Soonhoi Ha",
    "corresponding_authors": "",
    "abstract": "In addition to the various requirements that a multi-robot framework should meet, swarm robotics applications also demand robustness, flexibility, and scalability. While several frameworks have been developed for multi-robot operation, they mostly fall short of adequately supporting some of these essential requirements. In this work, we introduce a novel multi-robot programming framework called HiSARM (High-level Specification, Automatic code generation, and Retargetable deployment for Multi-robot systems), designed to assist both mission planners and robot software developers. HiSARM employs a high-level language to enable mission planners to specify collaborative tasks among multiple robots intuitively. From these scripts written in a high-level language, executable robot code is automatically generated. Mission planners can easily customize the executable robot code according to their specific needs within HiSARM. Additionally, HiSARM provides multiple verification environments by introducing a formal intermediate representation and enabling retargetable deployment of the binary file across various domains, including simulation and real robots. For robot software developers, HiSARM eases the development process for robot software developers by categorizing software components and auto-generating swarm-related functions. We tested HiSARM with multiple scenarios in simulation and real robot environments, demonstrating that it effectively supports all the necessary features for multi-robot applications, including swarm operations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412046492",
    "type": "article"
  },
  {
    "title": "Middleware for Distributed Applications in a LoRa Mesh Network",
    "doi": "https://doi.org/10.1145/3747295",
    "publication_date": "2025-07-07",
    "publication_year": 2025,
    "authors": "Joan Miquel Solé; Roger Pueyo Centelles; Fèlix Freitag; Roc Meseguer; Roger Baig",
    "corresponding_authors": "",
    "abstract": "Recently, LoRa mesh networks have gained an increasing interest as a communication layer for sending data between IoT nodes. However, the network service of the firmware on the microcontroller-based nodes is typically limited to sending and receiving LoRa packets through the LoRa radio. Therefore, the packet processing by the node has to be done using an application-specific implementation. In this paper, we present the design and implementation of a middleware that facilitates the development and operation of multiple distributed applications on LoRa mesh network nodes. The components we propose leverage the routing capacity of a LoRa mesh network enabled by the LoRaMesher library and provide a service for applications to send and receive messages from each other. Running several applications concurrently is also supported. We experiment with the middleware implemented in the node firmware with distributed applications that span from the LoRa mesh network to the Internet over MQTT. Our results show the support of bidirectional application-level communication, which can be used to build cross-network distributed applications that integrate services on LoRa mesh network nodes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412069555",
    "type": "article"
  },
  {
    "title": "<i>P</i> <sup>2</sup> <i>SDS</i> : A Polynomial-Time Pattern-Guided Stable Dynamic Scheduling for Weakly Hard Control Task Systems",
    "doi": "https://doi.org/10.1145/3748329",
    "publication_date": "2025-07-11",
    "publication_year": 2025,
    "authors": "Debasish Banerjee; Sumana Ghosh",
    "corresponding_authors": "",
    "abstract": "Real-time scheduling of control tasks in a weakly hard system, where the tasks can miss a few of their deadlines without impeding the system’s performance, is a riveting research direction nowadays. While analyzing the schedulability of control tasks in a weakly hard setting, it is pivotal to take into account both the control stability and the desired performance of the underlying system. Though a scanty amount of research efforts are reported in the literature, focusing on the control-scheduling co-design aspects, most of them are completely offline in nature, and hence, not applicable for obtaining dynamic scheduling decisions at runtime. More specifically, a polynomial-time online scheduler, handling both stability and control performance, is almost absent in the literature. To bridge this design gap, in this work, we propose P 2 SDS , a novel online scheduling approach that preserves stability and enhances control performance by synthesizing optimal control execution patterns (CEPs) for scheduling control tasks, while running in polynomial time. The synthesized CEPs respect stability-induced weakly hard constraints endorsing optimal control performances of the underlying systems. A rigorous set of simulation-based experiments over 15 standard benchmarks from the automotive domain is carried out to establish the efficacy and real-time applicability of the proposed method. A comparative analysis of P 2 SDS with respect to the state-of-the-art approaches reports around \\(99\\% \\) improvement in running time at maximum; \\(88\\% \\) , \\(9.042\\% \\) , and \\(87.5\\% \\) improvements in stability, control performance and schedulability ratio respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412196048",
    "type": "article"
  },
  {
    "title": "Optimization of DNN-based HSI Segmentation FPGA-based SoC for ADS: A Practical Approach",
    "doi": "https://doi.org/10.1145/3748722",
    "publication_date": "2025-07-16",
    "publication_year": 2025,
    "authors": "Jon Gutiérrez‐Zaballa; Koldo Basterretxea; Javier Echanobe",
    "corresponding_authors": "",
    "abstract": "The use of HSI for autonomous navigation is a promising research field aimed at improving the accuracy and robustness of detection, tracking, and scene understanding systems based on vision sensors. Combining advanced computer algorithms, such as DNNs, with small-size snapshot HSI cameras enhances the reliability of these systems. HSI overcomes intrinsic limitations of greyscale and RGB imaging in depicting physical properties of targets, particularly regarding spectral reflectance and metamerism. Despite promising results in HSI-based vision developments, safety-critical systems like ADS demand strict constraints on latency, resource consumption, and security, motivating the shift of ML workloads to edge platforms. This involves a thorough software/hardware co-design scheme to distribute and optimize the tasks efficiently among the limited resources of computing platforms. With respect to inference, the over-parameterized nature of DNNs poses significant computational challenges for real-time on-the-edge deployment. In addition, the intensive data preprocessing required by HSI, which is frequently overlooked, must be carefully managed in terms of memory arrangement and inter-task communication to enable an efficient integrated pipeline design on a SoC. This work presents a set of optimization techniques for the practical co-design of a DNN-based HSI segmentation processor deployed on a FPGA-based SoC targeted at ADS, including key optimizations such as functional software/hardware task distribution, hardware-aware preprocessing, ML model compression, and a complete pipelined deployment. Applied compression techniques significantly reduce the complexity of the designed DNN to 24.34% of the original operations and to 1.02% of the original number of parameters, achieving a 2.86x speed-up in the inference task without noticeable degradation of the segmentation accuracy.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412473429",
    "type": "article"
  },
  {
    "title": "Optimizing Sparse Matrix Convolution on RISC-V Core: Custom Instructions for Embedded System",
    "doi": "https://doi.org/10.1145/3756322",
    "publication_date": "2025-07-26",
    "publication_year": 2025,
    "authors": "Huachen Zhang; Jianyang Ding; Bowen Jiang; Tsung-Che Lu; Wei Xu; Zhilei Chai",
    "corresponding_authors": "",
    "abstract": "With the increasing demand for deep neural network (DNN) inference tasks on embedded platforms, deploying compute-intensive DNNs on resource-constrained embedded platforms faces challenges. While sparsification technology offers a potential solution, its implementation on edge platforms still faces difficulties. In this paper, we propose a novel sparse convolution acceleration processor based on RISC-V architecture, and design specialized custom instructions to enable efficient edge DNN inference. To this end, we mainly address three technical issues. In response to numerical characteristics of sparse convolution, the designed processor can implement a hardware-friendly architecture that transforms convolutions into sparse matrix multiplication. Additionally, it employs a column-major and element-level parallel strategy to optimize load imbalance issues present in the Gustavson algorithm, thereby enhancing sparse matrix computations. To further improve computational efficiency, our work is designed by incorporating efficient execution units that reduce instruction execution overheads while minimizing memory access frequency. Compared to traditional accelerators, our work supports custom instruction formats in C programming language, offering superior flexibility. Extensive experimental results indicate that our work can reduce execution time over 70% when running most DNNs with convolution operations compared to conventional instruction sets. Moreover, the functionality of our work is validated on an FPGA platform, and its performance is comprehensively evaluated based on a 55nm CMOS process. The results show that our work can achieve a peak energy efficiency of 675 GOPS/W in most network inference tasks, demonstrating exceptional computational performance and energy efficiency.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412652998",
    "type": "article"
  },
  {
    "title": "FLASH: Deadline-Aware Flexible LLC Arbitration and Scheduling for Hardware Accelerators",
    "doi": "https://doi.org/10.1145/3757742",
    "publication_date": "2025-07-30",
    "publication_year": 2025,
    "authors": "Ayushi Agarwal; Pulkit Goel; P.J. Joseph; Prokash Ghosh; S. Roy; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "Integrating domain-specific hardware accelerators on modern systems on chips (SoCs) has enabled complex applications, such as vision, natural language processing, autonomous driving, and augmented reality, on small form factors. This leads to challenges in the integration of accelerators, with high memory bandwidth requirements and strict deadlines, on the system’s memory hierarchy. The system-level shared cache, or last-level cache (LLC), is a critical resource shared by multi-core processors, GPUs, and hardware accelerators in modern heterogeneous SoCs. It significantly reduces the bottleneck at the off-chip memory and delivers high performance. With the integration of accelerators on the LLC gaining momentum, the on-chip shared cache management becomes vital. If not managed intelligently, the interference between cache requests from the cores and the accelerators can significantly deteriorate their performance. Given the architectural differences between DRAM and cache systems, the off-chip memory management strategies explored by previous works cannot be extended to the LLC. We propose a deadline-aware flexible LLC arbitration and scheduling framework, FLASH , to dynamically partition the LLC bandwidth between the accelerators and multi-core processors to meet the deadline given for the accelerator while minimizing the impact on the performance of the cores. FLASH arbitrates between the requests from the cores and the accelerators and schedules the requests depending on the accelerator’s progress and its chances of meeting the deadline. We evaluate FLASH across different workloads and hardware accelerator configurations to show that it not only achieves significantly better performance for the cores than other static scheduling policies but also significantly reduces the deadline miss rates of the accelerator.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412756643",
    "type": "article"
  },
  {
    "title": "Catch Non-determinism If You Can: Intermittent Inference of Dynamic Neural Networks",
    "doi": "https://doi.org/10.1145/3757917",
    "publication_date": "2025-07-30",
    "publication_year": 2025,
    "authors": "Chih‐Hsuan Yen; Hashan Roshantha Mendis; Tei‐Wei Kuo; Pi-Cheng Hsiu",
    "corresponding_authors": "",
    "abstract": "Guaranteeing reliable deep neural network (DNN) inference despite intermittent power is the cornerstone of enabling intelligent systems in energy-harvesting environments. Existing intermittent inference approaches support static neural networks with deterministic execution characteristics, accumulating progress across power cycles. However, dynamic neural networks adapt their structures at runtime. We observe that because intermittent inference approaches are unaware of this non-deterministic execution behavior, they suffer from incorrect progress recovery, degrading inference accuracy and performance. This work proposes non-deterministic inference progress accumulation to enable dynamic neural network inference on intermittent systems. Our middleware, NodPA, realizes this methodology by strategically selecting additional progress information to capture the non-determinism of the power-interrupted computation while preserving only the changed portions of the progress information to maintain low runtime overhead. Evaluations are conducted on a Texas Instruments device with both static and dynamic neural networks under time-varying power sources. Compared to intermittent inference approaches reliant on determinism, NodPA is less prone to inference non-termination and achieves an average inference speedup of 1.57 times without compromising accuracy, with greater improvements for highly dynamic networks under weaker power.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412777148",
    "type": "article"
  },
  {
    "title": "Ember: Task Wakeup Sequence–Based Energy Optimization for Mobile Web Browsing",
    "doi": "https://doi.org/10.1145/3757918",
    "publication_date": "2025-08-01",
    "publication_year": 2025,
    "authors": "Seonghoon Park; Jiwon Kim; Je‐Ho Lee; Hojung Cha",
    "corresponding_authors": "",
    "abstract": "Existing Android systems exhibit energy inefficiency during mobile web browsing due to the lack of awareness of application-level context. Inferring such context from system-level data alone is challenging, but one promising opportunity is using the sequence of task wakeup events, where one task activates another. These sequences show correlation with the type of webpage being used. In this paper, we present Ember, a lightweight and responsive power management system for mobile web browsing using only task wakeup sequences. Ember introduces a neural network–based approach to predict optimal CPU clamping values by addressing three key challenges: (1) embedding task names, given as natural-language strings, into meaningful vectors using a Word2Vec-based embedding scheme tailored for task wakeup sequences; (2) minimizing inference overhead with a touch-driven hierarchical inference method that combines lightweight logistic regression with high-accuracy neural networks to balance responsiveness and efficiency; and (3) adapting to within-page interaction dynamics through an interaction-adaptive clamping mechanism that adjusts constraints across different user interaction phases. Implemented on commercial Android smartphones, Ember reduced power consumption by 6.2%–31.2% across a wide range of webpages while maintaining user-perceived quality of experience (QoE).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412841381",
    "type": "article"
  },
  {
    "title": "FORT-GCN: A Fault-tolerant and Adaptive Accelerator Design for Efficient Graph Convolutional Network Inference",
    "doi": "https://doi.org/10.1145/3758094",
    "publication_date": "2025-08-02",
    "publication_year": 2025,
    "authors": "Ke Wang; Yingnan Zhao; Ahmed Louri",
    "corresponding_authors": "",
    "abstract": "Hardware reliability has emerged as a paramount concern for machine learning accelerators, as transient errors and permanent failures occurring during inference can severely compromise accuracy, performance, and service availability. Although fault resilience in traditional machine learning, such as Deep Neural Networks (DNNs), has been extensively studied, graph convolutional networks (GCNs) present unique reliability challenges due to their irregular computation patterns and dynamic data dependencies. Traditional fault mitigation approaches, including hardware redundancy, recomputation, and Hamming code protection, suffer from prohibitive latency and power overheads when applied to GCN accelerators. This paper presents FORT-GCN, a holistic hardware architecture co-optimized for GCN-specific fault resilience. Our solution integrates three key innovations, namely permanent fault tolerance through a novel robust processing element design with runtime reconfiguration and defect-adaptive interconnects, transient error resilience via lightweight selective error correction unit design, and a fault-aware adaptive controller design that dynamically adjusts fault protection strategies based on operational faults and graph characteristics. Experimental evaluation demonstrates 35.4% improvement in fault robustness compared to conventional error-correction and redundancy-based approaches, with minimal timing, area, and power overheads.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412855194",
    "type": "article"
  },
  {
    "title": "Robust LFSR-based Scrambling to Mitigate Stencil Attack on Main Memory",
    "doi": "https://doi.org/10.1145/3758321",
    "publication_date": "2025-08-04",
    "publication_year": 2025,
    "authors": "Gaurav Kumar; Kushal Pravin Nanote; Sohan Lal; Yamuna Prasad; Satyadev Ahlawat",
    "corresponding_authors": "",
    "abstract": "Main memory plays a pivotal role in the storage of computational data in a wide range of applications, including highly sensitive assets such as banking transactions, cryptographic keys, and user credentials. However, memory systems remain vulnerable to advanced physical and side-channel attacks, including cold boot attacks that exploit residual data after power-down. To mitigate such risks, Intel’s DDR3 memory scrambler uses a Linear Feedback Shift Register (LFSR)-based stream cipher to obscure memory contents. Nevertheless, this mechanism has been shown to be susceptible to stencil attack, a cold boot technique that reconstructs the scrambling key by leveraging the linear and periodic nature of the keystream. This article proposes a novel, lightweight, and secure scrambling architecture based on a generic LFSR designed to enhance the security of DDR3 memory against cold boot attacks. The proposed generic LFSR-based mechanism eliminates differential keystream periodicity by introducing an address- and seed-dependent LFSR structure, thereby rendering differential key recovery techniques computationally infeasible. Furthermore, unlike traditional AES-based memory encryption that incurs high latency and area overhead, the proposed approach achieves comparable security guarantees with low hardware complexity and zero access latency. The hardware implementation results on the Xilinx VCU118 FPGA show that the proposed scheme consumes only 252 LUTs, 256 registers and 104 slices, comparable to the Intel DDR3 scrambler, while offering superior resilience against the cold boot, warm boot, and probing attacks. These results demonstrate the practicality of the proposed scheme for secure memory systems in resource-constrained environments.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412891132",
    "type": "article"
  },
  {
    "title": "Towards Efficient Multi-Frame Clustering in Response Time Analysis for Large Object Communication",
    "doi": "https://doi.org/10.1145/3758323",
    "publication_date": "2025-08-05",
    "publication_year": 2025,
    "authors": "Jonas Peeck; Rolf Ernst; Selma Saidi",
    "corresponding_authors": "",
    "abstract": "In autonomous systems, growing sizes of application data, primarily related to perception tasks, have to be transmitted over communication infrastructures that provide higher data rates. Knowledge and exploitation of the clustered structure of multi-frame application data have proven to reduce the interference between different real-time critical communication streams, as recently shown for synchronous systems. However, the accompanying increase in frame numbers will foreseeably make the corresponding analysis impractical due to frame-dependent processing times. As a solution, based on the synchronous example mentioned, we demonstrate how to compose multi-frame transmissions to larger frame clusters in the analysis and decouple the analysis complexity from the application data sizes. Based on an automotive and industrial TSN use case, our results show comparable analytical response times and very low computation times at arbitrary data rates and sizes. It thus enables the deployment of efficient configuration methods that arbitrate large data samples transmitted through the network as one whole frame cluster. In addition, we made the developed analysis openly accessible.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412954184",
    "type": "article"
  },
  {
    "title": "GATE: Graph Attention Neural Networks with Real-Time Edge Construction for Robust Indoor Localization using Mobile Embedded Devices",
    "doi": "https://doi.org/10.1145/3758322",
    "publication_date": "2025-08-05",
    "publication_year": 2025,
    "authors": "Danish Gufran; Sudeep Pasricha",
    "corresponding_authors": "",
    "abstract": "Accurate indoor localization is crucial for enabling spatial context in smart environments and navigation systems. Wi-Fi Received Signal Strength (RSS) fingerprinting is a widely used indoor localization approach due to its compatibility with mobile embedded devices. Deep Learning (DL) models improve accuracy in localization tasks by learning RSS variations across locations, but they assume fingerprint vectors exist in a Euclidean space, failing to incorporate spatial relationships and the non-uniform distribution of real-world RSS noise. This results in poor generalization across heterogeneous mobile devices, where variations in hardware and signal processing distort RSS readings. Graph Neural Networks (GNNs) can improve upon conventional DL models by encoding indoor locations as nodes and modeling their spatial and signal relationships as edges. However, GNNs struggle with non-Euclidean noise distributions and suffer from the GNN blind spot problem, leading to degraded accuracy in environments with dense access points (APs). To address these challenges, we propose GATE, a novel framework that constructs an adaptive graph representation of fingerprint vectors while preserving an indoor state-space topology, modeling the non-Euclidean structure of RSS noise to mitigate environmental noise and address device heterogeneity. GATE introduces 1) a novel Attention Hyperspace Vector (AHV) for enhanced message passing, 2) a novel Multi-Dimensional Hyperspace Vector (MDHV) to mitigate the GNN blind spot, and 3) an new Real-Time Edge Construction (RTEC) approach for dynamic graph adaptation. Extensive real-world evaluations across multiple indoor spaces with varying path lengths, AP densities, and heterogeneous devices demonstrate that GATE achieves 1.6 × to 4.72 × lower mean localization errors and 1.85 × to 4.57 × lower worst-case errors compared to state-of-the-art indoor localization frameworks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412957950",
    "type": "article"
  },
  {
    "title": "A Tree-Shaped Tableau for Checking the Satisfiability of Signal Temporal Logic with Bounded Temporal Operators",
    "doi": "https://doi.org/10.1145/3759917",
    "publication_date": "2025-08-08",
    "publication_year": 2025,
    "authors": "Beatrice Melani; Ezio Bartocci; Michele Chiari",
    "corresponding_authors": "",
    "abstract": "Signal Temporal Logic (STL) is a widely recognized formal specification language to express rigorous temporal requirements on mixed analog signals produced by cyber-physical systems (CPS). A relevant problem in CPS design is how to efficiently and automatically check whether a set of STL requirements is logically consistent. This problem reduces to solving the STL satisfiability problem, which is decidable when we assume that our system operates in discrete time steps dictated by an embedded system’s clock. This paper introduces a novel tree-shaped, one-pass tableau method for satisfiability checking of discrete-time STL with bounded temporal operators. Originally designed to prove the consistency of a given set of STL requirements, this method has a wide range of applications beyond consistency checking. These include synthesizing example signals that satisfy the given requirements, as well as verifying or refuting the equivalence and implications of STL formulas. Our tableau exploits redundancy arising from large time intervals in STL formulas to speed up satisfiability checking, and can also be employed to check Mission-Time Linear Temporal Logic (MLTL) satisfiability. We compare our tableau with Satisfiability Modulo Theories (SMT) and First-Order Logic encodings from the literature on a benchmark suite, partly collected from the literature, and partly provided by an industrial partner. Our experiments show that, in many cases, our tableau outperforms state-of-the-art encodings.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413131612",
    "type": "article"
  },
  {
    "title": "GINA: Exploiting Graph Neural Network Layer Features for Energy Efficient Inferencing in NVM-based PIM Accelerators",
    "doi": "https://doi.org/10.1145/3759918",
    "publication_date": "2025-08-10",
    "publication_year": 2025,
    "authors": "Gaurav Narang; Chukwufumnanya Ogbogu; Biresh Kumar Joardar; Janardhan Rao Doppa; Krishnendu Chakrabarty; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Graph Neural Networks (GNNs) are made up of multiple layers, with each layer comprising of different compute kernels involving weight vectors and adjacency matrices of input graph dataset. These layers exhibit varying features such as sparsity, storage requirement, and impact on predictive accuracy. Non-volatile memory (NVM)-based 3D Processing-In-Memory (PIM) architectures offer a promising approach to accelerate GNN inferencing. However, NVM device-based crossbars suffer from various non-idealities that affect the overall predictive accuracy. In this work, we consider the problem of finding a suitable mapping of GNN layers to PIM-based processing elements (PEs) in a 3D manycore architecture such that the impact of crossbar non-idealities on predictive accuracy is minimized. We develop a framework called GINA, which leverages low-cost, approximate Hessian-based methodology to automatically determine the GNN layers that are critical for accuracy and find a suitable GNN layer to PE mapping. To tackle non-idealities and to exploit sparsity at the crossbar level, a subset of the full crossbar is activated in a cycle, referred to as Operation Unit (OU). However, OU configurations vary with the above-mentioned GNN layer features, time-dependent conductance drift, and input graph dataset. GINA learns to optimize the OU configuration for unseen datasets as a function of GNN layer features and time-dependent conductance drift. Our experimental results demonstrate that GINA-enabled 3D PIM architecture reduces the latency and energy by 7.4 \\times and 13 \\times on an average respectively, compared to state-of-the-art PIM architectures without compromising the predictive accuracy. Finally, we demonstrate the applicability of GINA to Convolutional Neural Networks (CNNs) and Vision Transformers.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413141583",
    "type": "article"
  },
  {
    "title": "Re-thinking Memory-Bound Limitations in CGRAs",
    "doi": "https://doi.org/10.1145/3760386",
    "publication_date": "2025-08-12",
    "publication_year": 2025,
    "authors": "X.P. Liu; Zhe Jiang; Anzhen Zhu; Xiaomeng Han; Mingsong Lyu; Qingxu Deng; Nan Guan",
    "corresponding_authors": "",
    "abstract": "Coarse-Grained Reconfigurable Arrays (CGRAs) are specialized accelerators commonly employed to boost performance in workloads with iterative structures. Existing research typically focuses on compiler or architecture optimizations aimed at improving CGRA performance, energy efficiency, flexibility, and area utilization, under the idealistic assumption that kernels can access all data from Scratchpad Memory (SPM). However, certain complex workloads—particularly in fields like graph analytics, irregular database operations, and specialized forms of high-performance computing (e.g., unstructured mesh simulations)—exhibit irregular memory access patterns that hinder CGRA utilization, sometimes dropping below 1.5%, making the CGRA memory-bound. To address this challenge, we conduct a thorough analysis of the underlying causes of performance degradation, then propose a redesigned memory subsystem and refine the memory model. With both microarchitectural and theoretical optimization, our solution can effectively manage irregular memory accesses through CGRA-specific runahead execution mechanism and cache reconfiguration techniques. Our results demonstrate that we can achieve performance comparable to the original SPM-only system while requiring only 1.27% of the storage size. The runahead execution mechanism achieves an average 3.04 × speedup (up to 6.91 ×), with cache reconfiguration technique providing an additional 6.02% improvement, significantly enhancing CGRA performance for irregular memory access patterns.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413194480",
    "type": "article"
  },
  {
    "title": "GNNmap: A Scalable Framework for GNN Deployment through Co-Optimized Graph Partitioning and Mapping",
    "doi": "https://doi.org/10.1145/3760530",
    "publication_date": "2025-08-12",
    "publication_year": 2025,
    "authors": "Zimeng Fan; Min Peng",
    "corresponding_authors": "",
    "abstract": "Graph Neural Networks (GNNs) have become pivotal for analyzing relational data in embedded intelligent systems such as IOT devices. However, their deployment on resource-constrained devices faces critical barriers: traditional graph partitioning methods induce unbalanced computational loads due to rigid granularity, while hardware mapping strategies cause inefficient resource utilization under dynamic graph structures. These limitations conflict with the requirements of embedded systems for resource efficiency and scalability. To address this, we present GNNmap, a hardware-software co-design framework that synergizes multi-granular graph partitioning with topology-aware GNN mapping. The framework first reconstructs input graphs into balanced kernel groups comprising cohesive supernodes (corresponding to parallelizable subgraphs). By combining coarse-grained partitioning with fine-grained optimization, GNNmap ensures load balance while dramatically reducing cross-subgraph communication. Concurrently, a subgraph-PE mapping based on coarse-grained reconfigurable architectures (CGRAs) enables efficient graph-to-hardware matching through the joint modeling of graph topological features and hardware resource constraints. By dynamically coordinating graph reorganization and hardware resource allocation, GNNmap resolves the intrinsic mismatch between irregular graph computations and static hardware configurations. Experimental results demonstrate that GNNmap achieves improvements over existing works, improving inference performance by 1.47× to 62.8×, resource efficiency by 1.15× to 3.06×, and energy efficiency by 1.34× to 3.50×.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413194491",
    "type": "article"
  },
  {
    "title": "ERGo: Energy-Efficient Hybrid Graph Neural Network Training on Processing-in-Memory Architectures",
    "doi": "https://doi.org/10.1145/3760402",
    "publication_date": "2025-08-12",
    "publication_year": 2025,
    "authors": "Pratyush Dhingra; Chidiebere Ugwu; Janardhan Rao Doppa; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Processing-in-memory (PIM) has been proposed as an alternative computing paradigm for training Deep Neural Networks, including Graph Neural Networks (GNNs). Despite these advancements, training GNN workloads on PIM devices necessitates off-chip memory access. This off-chip access is expensive in terms of performance and energy, thereby impacting the overall energy efficiency of the training process on PIM platforms. In this paper, we propose a novel hybrid training framework called ERGo that automatically switches from a full-parameter phase to a parameter-efficient phase during the training process with negligible loss in predictive accuracy. The parameter-efficient phase employs low-rank representations of GNN weights, effectively reducing the number of trainable parameters. This helps in reducing the off-chip access during the end-to-end training process on PIM architectures, leading to notable improvements in both performance and energy efficiency. ERGo outperforms the conventional full-parameter GNN training on a PIM-based platform by up to 3.15x in speedup and enhances energy efficiency by 10.5x. Furthermore, ERGo offers additional advantages when utilized on heterogeneous architectures incorporating non-volatile memory (NVM) and static random-access memory (SRAM). Training on the heterogeneous NVM-SRAM architecture typically utilizes NVM for the forward-pass and SRAM for the backward-pass. However, NVM cells suffer from low device endurance and repeated write operations due to weight updates can lead to poor lifetime. ERGo improves the lifetime of NVM devices by freezing the weights and preventing weight updates in the parameter-efficient phase. Experimental results demonstrate that ERGo improves the lifetime of heterogeneous NVM-SRAM architecture by up to 33x in comparison to full-parameter implementation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413194511",
    "type": "article"
  },
  {
    "title": "A Formal Approach towards Safe and Stable Schedule Synthesis in Weakly Hard Control Systems",
    "doi": "https://doi.org/10.1145/3760528",
    "publication_date": "2025-08-12",
    "publication_year": 2025,
    "authors": "Debasish Banerjee; Parasara Sridhar Duggirala; B. K. Ghosh; Sumana Ghosh",
    "corresponding_authors": "",
    "abstract": "Real-time scheduling of multiple control tasks in a weakly hard setting is an emerging research direction, as it offers a more flexible and feasible environment for task scheduling. This is especially pertinent for resource-constrained embedded applications where tasks are allowed to miss a few deadlines for prudent sharing of computational resources. However, a control task missing its deadline could result in the system being unsafe or unstable. A significant amount of research efforts have been reported in the literature addressing the schedulability of control tasks while preserving the stability or safety. However, all of them focus on a stable schedule or a safe schedule, but not both the safety and stability aspects together. In this work, we ensure both control stability and control safety to generate a safe and stable schedule for a weakly hard task system. In particular, we gradually endorse stability, safety, and schedulability, where we first synthesize a weakly hard constraint that preserves the desired stability of each control task. Next, we correlate stability with control safety and establish some mathematical results that guarantee control safety for an unbounded time horizon, unlike the existing methods. Finally, by leveraging Satisfiability Modulo Theories (SMT) , we synthesize the schedule that ensures control stability and safety while minimizing the worst-case response time of all the tasks, in a time-efficient way. To our knowledge, this is the first work to address stability, safety, and schedulability together for weakly hard control task systems. We validate our method through extensive experiments using standard automotive benchmarks. In addition, we demonstrate the efficiency of the proposed method in comparison with some of the state-of-the-art techniques, as well as highlight its scalability, thereby establishing its applicability in real-world scenarios.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413194603",
    "type": "article"
  },
  {
    "title": "Luthier: Bridging Auto-Tuning and Vendor Libraries for Efficient Deep Learning Inference",
    "doi": "https://doi.org/10.1145/3759916",
    "publication_date": "2025-08-11",
    "publication_year": 2025,
    "authors": "Yongin Kwon; Jungwon Cha; Sehyeon Oh; Misun Yu; Jeman Park; Jemin Lee",
    "corresponding_authors": "",
    "abstract": "Recent deep learning compilers commonly adopt auto-tuning approaches that search for the optimal kernel configuration in tensor programming from scratch, requiring tens of hours per operation and neglecting crucial optimization factors for parallel computing on asymmetric multicore processors. Meanwhile, hand-optimized inference libraries from hardware vendors provide high performance but lack the flexibility and automation needed for emerging models. To close this gap, we propose Luthier , which significantly narrows the search space by selecting the best kernel from existing inference libraries, and also employs cost model-based profiling to quickly determine the most efficient workload distribution for parallel computing. As a result, Luthier achieves up to 2.0x faster execution on convolution-based vision models and transformer-based language models (BERT, GPT) on both CPUs and GPUs, while reducing average tuning time by 95% compared with ArmNN, AutoTVM, Ansor, ONNXRuntime, and TFLite.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413221792",
    "type": "article"
  },
  {
    "title": "Exploiting LDPC Syndrome for Multidimensional Hard-Decoding Read Retry on NAND Flash",
    "doi": "https://doi.org/10.1145/3760259",
    "publication_date": "2025-08-11",
    "publication_year": 2025,
    "authors": "S.-G. Chen; Shuo-Han Chen",
    "corresponding_authors": "",
    "abstract": "NAND-flash-based solid-state drives (SSDs) are under constant pressure to deliver higher storage density while minimizing power and performance overhead. As the number of bits stored per NAND flash cell has scaled from single-level cells (SLC) to triple-level cells (TLC) and soon to penta-level cells (PLC), the reduced voltage margins between cell states challenge data reliability, requiring stronger decoding techniques. To maintain reliability and correct error data bits, low-density parity-check (LDPC) codes are widely deployed on these high-density devices and can operate in two modes: hard decoding, which uses threshold-based bit decisions and is relatively power-efficient, and soft decoding, which leverages additional reliability information but imposes higher computational and energy costs. In practice, NAND flash controllers initiate soft decoding when hard decoding fails, thereby preserving data integrity at the expense of latency and power overhead. Current approaches employ read-retry tables to adjust reference voltages and maximize hard decoding success rates; however, such tables cannot fully address diverse bit-error patterns, often unnecessarily invoking soft decoding and incurring significant performance overhead. To overcome this limitation, we propose a novel LDPC-syndrome-based loss function that adaptively adjusts multidimensional reference voltages, significantly reducing unnecessary soft decoding triggers without relying on predetermined read-retry tables or iterative voltage adjustments. Experimental results demonstrate that our proposed loss function effectively reduces the soft decoding trigger rate and the number of page reads, substantially minimizing the performance and power costs associated with soft decoding.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413221825",
    "type": "article"
  },
  {
    "title": "RIMMS: Runtime Integrated Memory Management System for Heterogeneous Computing",
    "doi": "https://doi.org/10.1145/3760257",
    "publication_date": "2025-08-11",
    "publication_year": 2025,
    "authors": "Serhan Gener; Aditya Ukarande; S. Narasimha Murthy; Sahil Hassan; Joshua Mack; Chaitali Chakrabarti; Ümit Y. Ogras; Ali Akoglu",
    "corresponding_authors": "",
    "abstract": "Efficient memory management in heterogeneous systems is increasingly challenging due to diverse compute architectures (e.g., CPU, GPU, FPGA) and dynamic task mappings not known at compile time. Existing approaches often require programmers to manage data placement and transfers explicitly, or assume static mappings that limit portability and scalability. This paper introduces RIMMS (Runtime Integrated Memory Management System), a lightweight, runtime-managed, hardware-agnostic memory abstraction layer that decouples application development from low-level memory operations. RIMMS transparently tracks data locations, manages consistency, and supports efficient memory allocation across heterogeneous compute elements without requiring platform-specific tuning or code modifications. We integrate RIMMS into a baseline runtime and evaluate with complete radar signal processing applications across CPU+GPU and CPU+FPGA platforms. RIMMS delivers up to 2.43X speedup on GPU-based and 1.82X on FPGA-based systems over the baseline. Compared to IRIS, a recent heterogeneous runtime system, RIMMS achieves up to 3.08X speedup and matches the performance of native CUDA implementations while significantly reducing programming complexity. Despite operating at a higher abstraction level, RIMMS incurs only 1–2 cycles of overhead per memory management call, making it a low-cost solution. These results demonstrate RIMMS’s ability to deliver high performance and enhanced programmer productivity in dynamic, real-world heterogeneous environments.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413221837",
    "type": "article"
  },
  {
    "title": "STL-GO: Spatio-Temporal Logic with Graph Operators for Distributed Systems with Multiple Network Topologies",
    "doi": "https://doi.org/10.1145/3760258",
    "publication_date": "2025-08-11",
    "publication_year": 2025,
    "authors": "Yiqi Zhao; Xiao Jin Yu; Bardh Hoxha; Georgios Fainekos; Jyotirmoy V. Deshmukh; Lars Lindemann",
    "corresponding_authors": "",
    "abstract": "Multi-agent systems (MASs) consisting of a number of autonomous agents that communicate, coordinate, and jointly sense the environment to achieve complex missions can be found in a variety of applications such as robotics, smart cities, and internet-of-things applications. Modeling and monitoring MAS requirements to guarantee overall mission objectives, safety, and reliability is an important problem. Such requirements implicitly require reasoning about diverse sensing and communication modalities between agents, analysis of the dependencies between agent tasks, and the spatial or virtual distance between agents. To capture such rich MAS requirements, we model agent interactions via multiple directed graphs, and introduce a new logic – Spatio-Temporal Logic with Graph Operators (STL-GO). The key innovation in STL-GO are graph operators that enable us to reason about the number of agents along either the incoming or outgoing edges of the underlying interaction graph that satisfy a given property of interest; for example, the requirement that an agent should sense at least two neighboring agents whose task graphs indicate the ability to collaborate. We then propose novel distributed monitoring conditions for individual agents that use only local information to determine whether or not an STL-GO specification is satisfied. We compare the expressivity of STL-GO against existing spatio-temporal logic formalisms, and demonstrate the utility of STL-GO and our distributed monitors in a bike-sharing and a multi-drone case study.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413221915",
    "type": "article"
  },
  {
    "title": "Duration-Aware Sound Event Detection on Ultra-Low-Power Sensor Devices",
    "doi": "https://doi.org/10.1145/3761806",
    "publication_date": "2025-08-19",
    "publication_year": 2025,
    "authors": "Seonghoon Park; Junick Ahn; Daeyong Kim; Hojung Cha",
    "corresponding_authors": "",
    "abstract": "Sound event detection (SED) based on on-device machine learning (ML) presents considerable energy challenges for ultra-low-power sensor devices. In this paper, we propose DASH, a duration-aware SED system designed for energy-constrained sensor devices in domestic environments. As repeated inferences for continuous sound events lead to unnecessary energy consumption, DASH aims to minimize unnecessary inferences by predicting the duration of sound events. However, the variability of sound event durations across different environments and scenarios poses a major challenge in developing a responsive yet energy-efficient duration-aware SED system. To address this, DASH introduces three key solutions: (1) N-probability distribution-based event duration prediction, which identifies checkpoints where new inferences are likely needed; (2) Affinity-guided event classification, which performs low-energy affinity matching at checkpoints to determine whether ML inference is necessary; and (3) Interrupt blocking-enabling cycle-based device state control, which periodically checks for event presence with minimal energy consumption at non-checkpoint times. We implemented DASH on MSP430-based sensor devices deployed in real home environments. Experimental results demonstrate that DASH reduced energy consumption by approximately 97–98% compared to evaluation baselines, with only a 4.7% error rate.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413308181",
    "type": "article"
  },
  {
    "title": "Rasco: Resource Allocation and Scheduling Co-design for DAG Applications on Multicore",
    "doi": "https://doi.org/10.1145/3761814",
    "publication_date": "2025-08-19",
    "publication_year": 2025,
    "authors": "Abigail Eisenklam; Robert Gifford; Georgiy A. Bondar; Yifan Cai; Tushar Sial; Linh Thi Xuan Phan; Abhishek Halder",
    "corresponding_authors": "",
    "abstract": "As multicore hardware becomes increasingly prevalent in real-time embedded systems, traditional scheduling techniques that assume a single worst-case execution time for each task are no longer adequate, as they fail to account for the impact of shared resources—such as cache and memory bandwidth—on execution time. When tasks execute concurrently on different cores, their execution times can vary substantially with their allocated resources. Moreover, the instruction rate of a task during a job execution varies with time, and this variation pattern differs across tasks. Therefore, to improve performance it is crucial to incorporate the relationship between the resource budget allocated to each task and its time-varying instruction rate in task modeling, resource allocation, and scheduling algorithm design. Yet, no prior work has considered the fine-grained dynamic resource allocation and scheduling problems jointly while also providing hard real-time guarantees. In this paper, we introduce a resource-dependent multi-phase timing model that captures the time-varying instruction rates of a task under different resource allocations and that enables worst-case analysis under dynamic allocation. We present a method for constructing estimates of such a model based on task execution profiles, which can be obtained through measurements. We then present Rasco , a co-design technique for multicore resource allocation and scheduling of real-time DAG applications with end-to-end deadlines. Rasco leverages the resource-dependent multi-phase model of each task to simultaneously allocate resources at a fine granularity and assign task deadlines. This approach maximizes execution progress under resource constraints while providing hard real-time schedulability guarantees. Our evaluation shows that Rasco substantially enhances schedulability and reduces end-to-end latency compared to the state of the art.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413308198",
    "type": "article"
  },
  {
    "title": "DPReF: Decentralized Key Generation Using Physical-Related Functions",
    "doi": "https://doi.org/10.1145/3762187",
    "publication_date": "2025-08-19",
    "publication_year": 2025,
    "authors": "Mohamed Alsharkawy; Hassan Nassar; Jeferson González-Gómez; Xun Xiao; Osama Abboud; Jörg Henkel",
    "corresponding_authors": "",
    "abstract": "Physical Unclonable Functions (PUFs) serve as a lightweight source to generate cryptographic keys utilizing the inherent physical device properties, making them particularly suitable for resource-constrained environments such as Internet of Things (IoT) devices. Recently, Physical-Related Functions (PReFs) extended PUFs to enable multiple devices to generate similar keys without the need to exchange or store them, improving security. However, state-of-the-art PReF implementations rely on a Trusted Third Party (TTP) to identify relative challenges, introducing a potential vulnerability if the TTP is compromised. In this work, we propose the first decentralized PReF protocol, removing reliance on the TTP and mitigating associated security risks. The proposed protocol allows relative challenges to be identified directly between devices in a decentralized manner. Additionally, we formalize a mathematical model to estimate the minimum number of devices required to build a network, based on the sizes of the PUF and the shared Challenge-Response Pair (CRP). We demonstrate the generality of our model by verifying it across different types of state-of-the-art PUFs (Arbiter-based Non-Volatile Memory PUF (ANV-PUF) and Pseudo Linear Feedback Shift Register PUF (PLPUF)). We establish a 128 bit cryptographic key using the proposed protocol that matches the state-of-the-art but in a decentralized manner. Moreover, we prove that our protocol can be used to construct hardware-assisted attestation networks using ANV-PUF and PLPUF implementations with a shared secret of 16 bit that allows for both integrity and identity verification.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413308201",
    "type": "article"
  },
  {
    "title": "ACE-of-SPADEs: Accelerating Spatially Sparse Convolution for 3D Scene Understanding",
    "doi": "https://doi.org/10.1145/3759457",
    "publication_date": "2025-08-19",
    "publication_year": 2025,
    "authors": "Om Ji Omer; Prashant Laddha; Gurpreet S. Kalsi; K. C. S. Pillai; Anirudh Thyagharajan; Abhilasha Devdatta Kulkarni; Anbang Yao; Yurong Chen; Sreenivas Subramoney",
    "corresponding_authors": "",
    "abstract": "Semantic understanding of 3D scenes is fundamental to many applications like robotics, autonomous driving, AR/VR. state-of-the-art methods for different 3D scene understanding tasks use 3D convolutional neural networks (CNNs) operating on point clouds. Convolution on spatially sparse data like point cloud involve irregular data accesses and compute patterns leading to poor utilization and energy efficiency in CPU/GPU implementations. The existing CNN accelerators designed for weight/activation sparsity cannot be efficiently repurposed for 3D spatially sparse CNNs given the fundamental differences in locating non-zero operands and granularity of work-dispatches. To address the dataflow challenges due to spatial sparsity and the need for specialized microarchitecture for spatially sparse convolution we present Ace-of-Spade s (AoS), an algorithm-dataflow-architecture co-designed system. AoS enables the data reuse among spatially proximate points using a locality-aware metadata structure along with a surface orientation aware point cloud reordering algorithm. AoS uses a novel technique for spatial sparsity aware selection of optimal data tiles by modelling the sparsity induced variations in the point cloud with a near-zero latency overheads. To accelerate computation on spatially sparse data, we propose a novel hardware accelerator Ss p nna with a front-end to convert varying number of operations per point into a stream of dense work dispatches to the backend compute engine. The compute engine further exploits weight and input feature data reuse through dynamic systolic grouping and multicast interconnects. The Ss p nna core together with the 64 KB of L1 memory requires 0.31 mm 2 of area in 10nm process at 1 GHz. Overall, AoS achieves speedup/energy savings of 19.9x / 49.9x and 2.2x / 7.1x over the state-of-the-art CPU and GPU implementations respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413308235",
    "type": "article"
  },
  {
    "title": "A Tunable Generic Meta-Heuristic Framework for Balancing Assembly Line Systems in Manufacturing",
    "doi": "https://doi.org/10.1145/3762189",
    "publication_date": "2025-08-16",
    "publication_year": 2025,
    "authors": "Suraj Meshram; Arnab Sarkar; Arijit Mondal",
    "corresponding_authors": "",
    "abstract": "Cyber-Physical Systems controlling assembly line operations are central to manufacturing processes. Assembly line systems have diversified over time, depending on multiple factors, including the products being manufactured, the workstations and resources used, factory layouts, etc. This diversity in assembly line configurations has added layers of complexity to the Assembly Line Balancing Problem (ALBP). While many powerful meta-heuristic techniques exist, their performance can vary significantly depending on the specific characteristics of the ALBP instance, such as the structure of the precedence graph, the distribution of task times, and the number of workstations. Recognizing the need for a more versatile solution, this paper introduces a generic local search strategy called Flexible Meta-Heuristic (FMH), which includes a set of adjustable tuning parameters for adapting to specific scenarios. FMH combines and extends the strengths of Hill Climbing (HC), Simulated Annealing (SA), and Genetic Algorithm (GA), to provide effective solutions across a wide range of problems. Through extensive experiments using standard benchmarks and randomly generated datasets, FMH demonstrates high accuracy, deviating by at most 0.9% from best-known benchmark values. Additionally, FMH is significantly less resource-intensive, solving problems with up to 150 tasks in minutes where exact solvers can take hours, making it more scalable and applicable to large industrial scenarios. Our findings suggest that the algorithm’s flexibility and strategic hyper-parameter tuning contribute significantly to its effectiveness in solving diverse ALBPs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413376852",
    "type": "article"
  },
  {
    "title": "Real-Time Video-Based Human Action Recognition on Embedded Platforms",
    "doi": "https://doi.org/10.1145/3761795",
    "publication_date": "2025-08-16",
    "publication_year": 2025,
    "authors": "Ruiqi Wang; Z. D. Wang; Pengbin Gao; M Li; Jae‐Hwan Jeong; Yihang Xu; Yejin Lee; Carolyn Baum; Lisa Tabor Connor; Chenyang Lu",
    "corresponding_authors": "",
    "abstract": "Advances in computer vision and deep learning have made video-based Human Action Recognition (HAR) increasingly feasible. However, running HAR on live video streams encounters significant delays on embedded platforms due to computational demands. This work addresses real-time HAR performance challenges through four key contributions: 1) an experimental study identifying standard Optical Flow (OF) extraction as the primary latency bottleneck in a state-of-the-art HAR pipeline, 2) an analysis of the latency-accuracy trade-off between traditional and deep learning-based OF methods, underscoring the need for an efficient motion feature extractor with minimal impact on accuracy, 3) the design of Integrated Motion Feature Extractor (IMFE) , a novel unified neural network architecture that substantially reduces motion feature extraction latency, and 4) the development of RT-HARE , a real-time HAR system optimized for embedded platforms. Experiments on three benchmark datasets of various characteristics using the Nvidia Jetson Xavier NX platform demonstrate that RT-HARE achieves real-time HAR with lower and more stable latency, reduced power consumption, and a smaller memory footprint while maintaining recognition accuracy comparable to more complex server-based HAR models.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413376869",
    "type": "article"
  },
  {
    "title": "Lemonade: Learning-based Heterogeneous Metadata Offloading for Disaggregated Memory",
    "doi": "https://doi.org/10.1145/3761807",
    "publication_date": "2025-08-16",
    "publication_year": 2025,
    "authors": "Zhenbing Ma; Jian Zhou; Yu Fu; Xiuquan Ma; Shuhan Bai; Fei Wu",
    "corresponding_authors": "",
    "abstract": "Direct Access (DA) in Disaggregated Memory (DM) is a promising solution that meets the high-performance requirements of AI applications. However, it lacks effective support for metadata management, making metadata operations the major bottleneck. To address this, we propose Lemonade, a l earning-based h e terogeneous m etadata o ffloadi n g for dis a ggregate d m e mory. Lemonade splits the metadata into highly regular and irregular ones, thus offloading the former into the client to avoid remote queries and enabling request redirection in the SmartNIC for the latter to ensure cost-effective correction and updates. Evaluations under microbenchmark and YCSB workloads indicate that Lemonade reduces latency by 72.8% and achieves a 1.43× increase in throughput compared to the state-of-the-art systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413376889",
    "type": "article"
  },
  {
    "title": "ReLoaDing Performance: A Locality-Based Strategy for Rapid Reads in Encrypted Key-Value Systems",
    "doi": "https://doi.org/10.1145/3761810",
    "publication_date": "2025-08-16",
    "publication_year": 2025,
    "authors": "Ching Tsung Hung; Yixiao Liao; Yi-Chao Shih; Tseng‐Yi Chen",
    "corresponding_authors": "",
    "abstract": "In key-value store systems, data security is often prioritized through compression and encryption of stored key-value pairs, ensuring protection against unauthorized access and breaches. However, these security measures introduce significant performance overheads, particularly during read operations, due to the need for decryption and decompression of data packs. This overhead is exacerbated in log-structured merge-tree (LSM-tree) based systems interfaced with NAND flash memory, where read amplification—caused by accessing entire compressed and encrypted units for a small subset of data—degrades performance. To address this challenge, we propose ReLoaD (Repacking Locality Data), a novel locality-based strategy designed to optimize read performance in encrypted key-value systems without compromising security or compression efficiency. ReLoaD leverages dynamic access pattern analysis to reorganize frequently co-accessed key-value pairs into contiguous storage packs, reducing the frequency of costly decryption and decompression operations. By introducing lightweight in-memory data structures—such as the PackInfo and Remapthl mapping tables—and innovative mechanisms like the locality-aware compactor and reloading repacker, ReLoaD enhances data locality within packs, minimizes I/O overhead, and increases the pack read ratio. Experimental evaluations using real-world workloads from Twitter and IBM, executed on the RocksDB platform, demonstrate that ReLoaD achieves up to a 38% improvement in read latency compared to state-of-the-art solutions like TinyEnc, while maintaining minimal impact on write performance. With a memory footprint of less than 3 MB, ReLoaD offers a scalable and practical approach to balancing security and performance, making it well-suited for modern secure storage systems deployed in resource-constrained environments.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413377378",
    "type": "article"
  },
  {
    "title": "<i>SAPar</i> : A Surrogate-Assisted DNN Partitioner for Efficient Inferences on Edge TPU Pipelines",
    "doi": "https://doi.org/10.1145/3761813",
    "publication_date": "2025-08-15",
    "publication_year": 2025,
    "authors": "Binqi Sun; B. S. Zou; Yigong Hu; Tomasz Kloda; Ling Wang; Tarek Abdelzaher; Marco Caccamo",
    "corresponding_authors": "",
    "abstract": "Pipelining deep neural networks (DNNs) across multiple Edge Tensor Processing Units (TPUs) can enhance on-device performance by increasing the capacity for DNN parameters caching and enabling pipeline parallelism. Effective deployment on pipelined Edge TPUs requires a partitioning tool to divide the DNN into segments, each assigned to a different Edge TPU in the pipeline. Achieving balanced workload distribution across these segments is crucial for optimal timing performance. However, workload balancing across Edge TPUs is challenging, as DNN execution time is influenced by proprietary hardware architecture and compiler internals, forming a black-box function inaccessible to partitioning tools. To address this challenge, this paper introduces SAPar , a new surrogate-assisted DNN partitioner that integrates a neighborhood search engine with a surrogate-assisted evaluator for effective and efficient DNN partitioning. The neighborhood search engine systematically explores the decision space, guided by knowledge obtained from empirical insights and neighborhood evaluation feedback provided by the surrogate-assisted evaluator. The evaluator cooperatively applies an accurate yet time-consuming latency profiler and an efficient graph transformer-based surrogate model , achieving both precision and scalability. Experiments on real Edge TPU hardware demonstrate that SAPar achieves significantly better pipeline performance than Google’s current profiling-based partitioner with an 8.82× to 110× speedup in partitioning time. Moreover, SAPar reduces the bottleneck latency by 8.93% to 44.15% across five classic DNN models compared to a state-of-the-art reinforcement learning-based partitioner.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413378398",
    "type": "article"
  },
  {
    "title": "Efficient Algorithm-Level Error Detection for Number-Theoretic Transform Used for Kyber Assessed on FPGAs and ARM",
    "doi": "https://doi.org/10.1145/3762186",
    "publication_date": "2025-08-15",
    "publication_year": 2025,
    "authors": "Kasra Ahmadi; Saeed Aghapour; Mehran Mozaffari Kermani; Reza Azarderakhsh",
    "corresponding_authors": "",
    "abstract": "Polynomial multiplication stands out as a highly demanding arithmetic process in the development of post-quantum cryptosystems. The importance of the number-theoretic transform (NTT) extends beyond post-quantum cryptosystems, proving valuable in enhancing existing security protocols such as digital signature schemes and hash functions. CRYSTALS-KYBER stands out as the sole public key encryption (PKE) algorithm chosen by the National Institute of Standards and Technology (NIST) in its third round selection, making it highly regarded as a leading post-quantum cryptography (PQC) solution. Faults have the potential to disrupt cryptographic systems, compromise data integrity, and enable side-channel attacks, making the incorporation of robust error detection mechanisms essential. This paper introduces algorithm-level fault detection schemes in the NTT multiplication using Negative Wrapped Convolution ( NWC ) and the NTT tailored for Kyber Round 3, representing a significant enhancement compared to previous research. We evaluate this through the simulation of a fault model, ensuring that the conducted assessments accurately mirror the obtained results. Our fault detection scheme is designed to address both malicious fault injection attacks on Kyber and naturally occurring faults. Furthermore, we assessed the effectiveness of the proposed error detection scheme for the NTT implemented in both NWC and Kyber , using AMD/Xilinx Artix-7 FPGA, HLS and processor-based approaches. In our FPGA implementation of NWC , the integration of our error detection approach achieves near-100% fault coverage with minimal area overhead and results in only a 12% increase in latency compared to the original hardware design. Finally, we attained an error detection ratio of nearly 100% for the NTT operation in Kyber , with a clock cycle overhead of 16% on the Cortex-A72 processor.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413378541",
    "type": "article"
  },
  {
    "title": "FC-GPU: Feedback Control GPU Scheduling for Real-time Embedded Systems",
    "doi": "https://doi.org/10.1145/3761812",
    "publication_date": "2025-08-15",
    "publication_year": 2025,
    "authors": "Srinivasan Subramaniyan; Xiaorui Wang",
    "corresponding_authors": "",
    "abstract": "GPUs have recently been adopted in many real-time embedded systems. However, existing GPU scheduling solutions are mostly open-loop and rely on the estimation of worst-case execution time (WCET). Although adaptive solutions, such as feedback control scheduling, have been previously proposed to handle this challenge for CPU-based real-time tasks, they cannot be directly applied to GPU, because GPUs have different and more complex architectures and so schedulable utilization bounds cannot apply to GPUs yet. In this paper, we propose FC-GPU, the first Feedback Control GPU scheduling framework for real-time embedded systems. To model the GPU resource contention among tasks, we analytically derive a multi-input-multi-output (MIMO) system model that captures the impacts of task rate adaptation on the response times of different tasks. Building on this model, we design a MIMO controller that dynamically adjusts task rates based on measured response times. Our extensive hardware testbed results on an Nvidia RTX 3090 GPU and an AMD MI-100 GPU demonstrate that FC-GPU can provide better real-time performance even when the task execution times significantly increase at runtime.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413380271",
    "type": "article"
  },
  {
    "title": "THERMOS: Thermally-Aware Multi-Objective Scheduling of AI Workloads on Heterogeneous Multi-Chiplet PIM Architectures",
    "doi": "https://doi.org/10.1145/3762655",
    "publication_date": "2025-08-22",
    "publication_year": 2025,
    "authors": "Alish Kanani; Lukas Pfromm; Harsh Sharma; Janardhan Rao Doppa; Partha Pratim Pande; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "Chiplet-based integration enables large-scale systems that combine diverse technologies, enabling higher yield, lower costs, and scalability, making them well-suited to AI workloads. Processing-in-Memory (PIM) has emerged as a promising solution for AI inference, leveraging technologies such as ReRAM, SRAM, and FeFET, each offering unique advantages and trade-offs. A heterogeneous chiplet-based PIM architecture can harness the complementary strengths of these technologies to enable higher performance and energy efficiency. However, scheduling AI workloads across such a heterogeneous system is challenging due to competing performance objectives, dynamic workload characteristics, and power and thermal constraints. To address this need, we propose THERMOS, a thermally-aware, multi-objective scheduling framework for AI workloads on heterogeneous multi-chiplet PIM architectures. THERMOS trains a single multi-objective reinforcement learning (MORL) policy that is capable of achieving Pareto-optimal execution time, energy, or a balanced objective at runtime, depending on the target preferences. Comprehensive evaluations show that THERMOS achieves up to 89% faster average execution time and 57% lower average energy consumption than baseline AI workload scheduling algorithms with only 0.14% runtime and 0.022% energy overhead.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413431245",
    "type": "article"
  },
  {
    "title": "SHARP: SHARing-Aware Cache Writeback byPass",
    "doi": "https://doi.org/10.1145/3760746",
    "publication_date": "2025-08-16",
    "publication_year": 2025,
    "authors": "Dinesh Joshi; Aritra Bagchi; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "In modern multi-processor systems-on-chips (MPSoCs), writebacks from the private caches to the shared cache can introduce significant performance bottlenecks, especially because multiple threads from different co-executing programs contend for the shared cache resources. Intelligent cache bypass decisions for writebacks help mitigate such contention and enhance the utilization of the shared cache. Most prior cache bypass strategies account for contention for shared cache capacity by focusing primarily on data reuse, with only recent research beginning to consider bandwidth contention also in dynamic bypass decisions. However, data sharing, a crucial characteristic of modern multithreaded workloads, remains largely overlooked by state-of-the-art cache bypass decisions. Bypassing highly shared cache lines can increase the volume of main memory accesses, potentially resulting in performance bottlenecks. We introduce SHARP, a novel cache bypass policy that incorporates three key factors: data sharing, contention, and data reuse, into its dynamic bypass decisions for cache writebacks. In addition to prioritizing the caching of data with high reuse, we prioritize the caching of data shared across multiple threads to enhance cache utilization. We dynamically modulate our bypass decisions, employing aggressive bypass for writebacks when shared cache contention is high, while employing conservative bypass when contention is low. Experiments across a diverse set of PARSEC workloads demonstrate that SHARP improves overall system throughput by \\(12\\% \\) and \\(8\\% \\) compared to the no-bypass baseline and the state-of-the-art bypass baseline, respectively. SHARP also reduces the overall cache energy consumption by \\(14\\% \\) over the no-bypass baseline.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413446139",
    "type": "article"
  },
  {
    "title": "Star-Set Based Efficient Reachable Set Computation of Anytime Sensing-Based Neural Network-Controlled Dynamical Systems",
    "doi": "https://doi.org/10.1145/3762658",
    "publication_date": "2025-08-23",
    "publication_year": 2025,
    "authors": "Lipsy Gupta; Pavithra Prabhakar",
    "corresponding_authors": "",
    "abstract": "In this paper, we consider the problem of reachable set computation of a closed-loop system with anytime sensor and a neural network controller. We provide a star set data structure-based forward propagation algorithm that uses existing efficient operations on star-sets and a novel convex hull construction. We present rigorous analysis of the space-complexity of the star sets generated during the propagation. Our experimental results show significant improvement with respect to existing methods that use vertex-based representation of polyhedral sets for propagation through closed-loop systems with anytime sensing, as well as the feasibility of the approach on different types of dynamics, control and sensors.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413447510",
    "type": "article"
  },
  {
    "title": "A Discrete Partial Charging Enabled Dynamic Programming Strategy for Optimal Fixed-Route Electric Vehicle Charging",
    "doi": "https://doi.org/10.1145/3762188",
    "publication_date": "2025-08-15",
    "publication_year": 2025,
    "authors": "Dipankar Mandal; Arnab Sarkar; Arijit Mondal",
    "corresponding_authors": "",
    "abstract": "The rapid adoption of Electric Vehicles (EVs), driven by stringent environmental regulations and rising fuel costs, is reshaping the landscape of Vehicle Routing Problems (VRP). This shift has led to the Electric Vehicle Routing Problem (EVRP), which incorporates EV-specific operational constraints such as limited driving range, energy consumption, recharging strategies, and detour-related charging costs. The challenge becomes even more critical in modern mixed fleets , where Electric and Internal Combustion Engine Vehicles (ICEVs) coexist and must be co-routed efficiently. A widely adopted two-step strategy first uses Capacitated VRP (CVRP) algorithms to generate energy-oblivious routes, then makes EV routes energy-feasible via charging station insertion. While VRP and CVRP are extensively studied, methods for efficiently ensuring energy feasibility for EVs on fixed routes remain limited. This paper introduces the Fixed Route Vehicle Charging Problem with Discrete Partial Charging (FRVCP-DPC) , extending FRVCP by allowing partial recharging up to predefined discrete levels. We develop a scalable optimal Dynamic Programming algorithm, Best Energy Feasible Route Generator (BEFRG) , to select detour points, charging stations, and charge levels that minimize total route time while maintaining energy feasibility. To evaluate BEFRG in dynamic traffic conditions, we introduce EFRGen , a traffic-aware EVRP simulator built on Simulation of Urban Mobility (SUMO) and OpenStreetMap (OSM). Experiments on the Montoya benchmark—spanning 120 instances with up to 320 demand points and 38 charging stations—show that BEFRG computes optimal solutions for all cases within one minute.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413470012",
    "type": "article"
  },
  {
    "title": "A Load-Balanced Collaborative Repair Algorithm for Single-Disk Failures in Erasure Coded Storage Systems",
    "doi": "https://doi.org/10.1145/3762648",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Zhijie Huang; Y. Shi; Chengjia Zhao; Haoran Li; Nannan Zhao; Shujie Han; Xiao Zhang",
    "corresponding_authors": "",
    "abstract": "In large-scale cloud data centers and distributed storage systems, erasure coding is usually employed to enhance data availability and storage efficiency. However, with the explosive growth of data volume and the continuous expansion of storage system scale, traditional erasure coding techniques face significant challenges in handling single-disk failures. These challenges are primarily reflected in low data recovery efficiency and imbalanced system load distribution, which ultimately result in excessive I/O load and network bandwidth consumption, severely limiting the overall performance of the system. To address these issues, this paper proposes a load-balanced data repair algorithm for single disk failures in erasure coded storage systems, called MNCR (Multi-Node Cooperative Repair). This algorithm improves data recovery efficiency in single-disk failure scenarios by minimizing data reading and inter-disk data transmission, using a cooperative repair strategy among disks. In addition, the algorithm designs a dynamic load balancing mechanism, which effectively resolves the issue of imbalanced data load distribution among disks during the repair process, thus avoiding performance bottlenecks caused by overloaded disks. Experimental results show that the MNCR algorithm significantly outperforms traditional methods in terms of repair efficiency and load balancing, providing an effective solution for single disk failure recoveries in erasure coding based large-scale storage systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413499141",
    "type": "article"
  },
  {
    "title": "Checking Bounded Reachability of Compositional Linear Hybrid Automata Using Interaction Relations",
    "doi": "https://doi.org/10.1145/3762645",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Yourong Shi; Yin Wu; Lei Bu; Xuandong Li",
    "corresponding_authors": "",
    "abstract": "For compositional linear hybrid automata (CLHA), whose dynamics can be characterized by linear constraints, bounded model checking (BMC) is challenging due to the complexity caused by interactions among member automata. Classical BMC approaches encode CLHA behavior using interleaving semantics, where compositions are handled with Cartesian product; as a result, the encoding is often large and complex, significantly limiting the scalability and efficiency of BMC. To address this problem, we propose three interaction relations to categorize and describe CLHA interactions through shared-label synchronization, discrete-variable read-write, and time-duration read-write. Based on the interaction relations, we devise interaction-oriented synchronization (IOS) semantics for CLHA behavior, which provides for a concise BMC encoding. In BMC, we employ a path-oriented method to check bounded reachability of CLHA, by enumerating candidate paths and checking each path’s feasibility. To prune the search space of candidate paths, we introduce a temporal relation graph (TRG) to quickly rule out infeasible paths via graph-based checking. Our method is implemented into a CLHA bounded reachability checker, BACH . Experiments indicate that it enables significant efficiency improvement over state-of-the-art tools, and performs scalable bounded reachability analysis on practical CLHA cases within seconds.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413499256",
    "type": "article"
  },
  {
    "title": "Cumulative-Time Signal Temporal Logic",
    "doi": "https://doi.org/10.1145/3763237",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Hongkai Chen; Z. Zhang; Shouvik Roy; Ezio Bartocci; Scott A. Smolka; Scott D. Stoller; Shan Lin",
    "corresponding_authors": "",
    "abstract": "Signal Temporal Logic (STL) is a widely adopted specification language for Cyber-Physical Systems that can be used to express critical temporal requirements, such as system safety and response time. STL’s expressivity, however, is not sufficient to capture the cumulative duration during which a property holds within an interval of time. To overcome this limitation, we introduce Cumulative-Time Signal Temporal Logic (CT-STL) which operates over discrete-time signals and extends STL with a new cumulative-time operator. This operator compares the sum of all time steps for which its nested formula is true with a threshold. We present both a qualitative and a quantitative (robustness) semantics for CT-STL and prove the soundness and completeness of the robustness semantics. We also provide an efficient online monitoring algorithm for both semantics. We demonstrate the utility of CT-STL via two case studies: specifying and monitoring cumulative temporal requirements for a microgrid and an artificial pancreas.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413499266",
    "type": "article"
  },
  {
    "title": "Deep Q-Learning-Based Mobile Charger Path Planning in Wireless Powered Communication Networks",
    "doi": "https://doi.org/10.1145/3763235",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Mainak Mondal; Fei Dou; Jinbo Bi; Song Han",
    "corresponding_authors": "",
    "abstract": "Wireless Powered Communication Network (WPCN) is a new paradigm to allow low-power wireless devices to exchange data packets and receive stable energy transfer from a power source and thus support autonomous and sustainable network operations without battery replacements. In recent years, we have witnessed the growing deployment of WPCNs in both industrial and consumer IoT systems to support time-triggered and event-triggered monitoring applications. In this paper, we present a novel reinforcement learning (RL)-based on-demand path planning framework to plan the trajectory of a Mobile Charger (MC) and schedule the charging sequence of wireless devices to sustain the network operations. A modified Deep Q-learning approach is designed to charge the wireless devices by balancing between their residual energy level and the distance from the MC to the device. This approach minimizes the total distance that the MC travels while ensuring that individual residual energy of a given set of devices is above a designated threshold. Extensive experimental results from both the Gazebo-based high-fidelity simulation and Turtlebot-based physical testbed demonstrate that our approach outperforms the classic scheduling methods (e.g., Nearest Job Next and Earliest Deadline First), state-of-the-art scheduling methods(Extended Particle Swarm Optimization, Enhanced Teaching–Learning-Based Optimization Algorithm and Spatiotemporal Optimization for Charging Scheduling), learning-based methods (e.g., Proximal Policy Optimization and Advantage Actor-Critic) with similar sample sizes for training.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413499278",
    "type": "article"
  },
  {
    "title": "FLIP2M: Flexible Intra-layer Parallelism and Inter-layer Pipelining for Multi-model AR/VR Workloads",
    "doi": "https://doi.org/10.1145/3762656",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Gabriele Tombesi; Je Yang; J D Zuckerman; Davide Giri; William Baisi; Luca P. Carloni",
    "corresponding_authors": "",
    "abstract": "Tiled accelerator architectures provide opportunities to optimize the performance of multi-model augmented and virtual reality (AR/VR) applications through intra-layer parallelism and inter-layer pipelining. However, balancing these two strategies is a difficult task that demands a flexible architecture to deploy models and an optimization approach that is capable of selecting an optimal strategy from an enormous mapping space. This paper presents FLIP2M, a holistic solution for mapping multi-model AR/VR workloads on tiled architectures. FLIP2M consists of (1) FLIP, an acceleration fabric that supports a wide variety of optimizations through flexible on-chip communication, and (2) OASIS, an optimization framework based on dynamic and constraint programming that is capable of selecting an efficient strategy for mapping multi-model workloads onto FLIP. We demonstrate FLIP2M on an FPGA prototype of FLIP that features 36 accelerators and 7 DDR4 controllers. Using OASIS-generated mappings for three different multi-model AR/VR workloads, FLIP2M achieves up to 1.94 × improvement in latency, 1.37 × in energy, and 2.59 × in energy-delay product relative to a FLIP baseline without intra-layer resource allocation flexibility and inter-layer pipelining.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413499637",
    "type": "article"
  },
  {
    "title": "LeakyRand: An Efficient High-fidelity Covert Channel in Fully Associative Last-level Caches with Random Eviction",
    "doi": "https://doi.org/10.1145/3761797",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Yashika Verma; Debadatta Mishra; M. Chaudhuri",
    "corresponding_authors": "",
    "abstract": "Recent studies on secure last-level cache (LLC) have advocated the fully associative organization to defend against conflict-based side-channel attacks. In a fully associative LLC, an attacker cannot extract any information about the cache location of the addresses evicted due to cross-core conflict. Use of the random replacement policy further guards against any deterministic eviction patterns. However, the fully associative LLC design remains vulnerable against timing-based covert channel attacks. In this paper, we present LeakyRand , a high-bandwidth covert communication mechanism that exploits the fully associative LLC with random replacement while guaranteeing an ultra-low bit error rate (BER). Our proposal is a union of three unique contributions. First, we present an efficient algorithm with strong analytical guarantees that enables the attacker to quickly occupy nearly the whole LLC with high probability, a prerequisite for achieving high bandwidth and high fidelity. Second, we present a novel covert communication protocol that allows the attacker to maintain high LLC occupancy. Third, our proposal detects error syndromes and efficiently takes corrective measures leading to an ultra-low expected BER. Exploiting a 2 MB fully associative LLC with random replacement policy to set up a covert channel, LeakyRand experiences an average BER of 10 − 4 or less while offering 3.3 × to 5.7 × higher channel bandwidth compared to the recently proposed Stochastic Prime + Probe attack. We also demonstrate that LeakyRand can be adopted to mount high-precision fine-grain fingerprinting attacks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413520728",
    "type": "article"
  },
  {
    "title": "On Improving the Performance of Intra- and Inter-chiplet Interconnection Networks in Multi-chiplet Systems for Accelerating FHE Encrypted Neural Network Applications",
    "doi": "https://doi.org/10.1145/3762995",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Zonghao Lai; Jinhui Ye; Xiaohang Wang; Zheang Fu; Amit Kumar Singh; Yingtao Jiang; Kui Ren; Mei Yang; Sihai Qiu; Xiaodong Li; Xin Tang; Jie Song; Mingzhe Zhang",
    "corresponding_authors": "",
    "abstract": "Fully Homomorphic Encryption (FHE) is regarded as a promising way to protect data privacy with encrypted computation. Due to high computation overhead, hardware based FHE accelerators were proposed to speed up FHE applications. To support complicated FHE-encrypted neural network applications, multi-chiplet based FHE accelerators were further proposed for scaling up system size, whereas one of the challenges is designing efficient intra- and inter-chiplet interconnection networks to accelerate data transfer. Conventional regular topologies like mesh or Kite either lead to high inter-chiplet transmission latency or excessive power consumption as these topologies assume uniform bandwidth or radix for nodes/links, ignoring the highly irregular distribution of inter-chiplet communication volumes. On the other hand, the problem of generating customized intra- and inter-chiplet interconnection networks has high complexity and previous network-on-chip topology generation works cannot efficiently improve the performance of intra- and inter-chiplet interconnection networks. In this paper, the intra- and inter-chiplet interconnection optimization problem is defined, aiming to minimize the execution time of FHE applications under cost and power constraints. To efficiently solve this problem, we propose a bilevel optimization algorithm, which decomposes the problem into three sub-problems: (1) FHE parameters selection, (2) task-to-core mapping, and (3) intra-/inter-chiplet interconnection network topology generation. These sub-problems are then solved iteratively. Experimental results demonstrate that our proposed method reduces execution time by 51.66%, 43.16%, 39.44%, 43.34%, and 27.70% compared to REED and four multi-chiplet based FHE accelerators with mesh, Kite, Butterfly, and Florets as inter-chiplet interconnection networks. Therefore, the proposed method can effectively accelerate FHE applications on large-scale multi-chiplet systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413520821",
    "type": "article"
  },
  {
    "title": "Developing Deadlock-Free Routing Algorithms in Torus NoC: A Formal Approach",
    "doi": "https://doi.org/10.1145/3762650",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Surajit Das; Abhijit Das; Chandan Karfa",
    "corresponding_authors": "",
    "abstract": "Torus is a symmetric Network-on-Chip (NoC) topology with uniform node degree providing very high path diversity between a pair of source and destination. Moreover, the Wraparound Channels (WCs) in the torus can significantly reduce the hop count, thereby reducing overall communication latency. However, the WCs also create cyclic paths that may lead to a NoC deadlock. As a consequence, very few deadlock-free routing algorithms for torus-based NoC exist that do not have significant implementation overhead. Furthermore, the existing routing algorithms do not unlock the full potential of the torus-based NoC topology. In this work, we present a formal modeling-based technique for developing deadlock-free routing algorithms for torus-based NoC. This method systematically combines routing algorithms of mesh with WCs of torus to develop deadlock-free routing algorithms for torus. Using the proposed technique, we develop three novel routing algorithms and verify their deadlock-freedom using Directional Dependency Graph (DDG). We then evaluate the proposed routing algorithms using both synthetic and real traffic patterns. The primary objective of this work is to present a technique that can generate multiple routing algorithms and not the single best routing algorithm. Hence, we do not claim that the three proposed algorithms are the best-performing ones. Nevertheless, we show that they can save hop counts by more than 10% and latency by 8% compared to the competitive methods. The performance of our algorithms is comparable even with state-of-the-art Table-based rout- ing and deadlock recovery-based technique.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413520858",
    "type": "article"
  },
  {
    "title": "CIMFlow: Modelling Dataflow in Cross-Layer Compute-in-Memory Deep Learning Accelerators",
    "doi": "https://doi.org/10.1145/3760780",
    "publication_date": "2025-08-14",
    "publication_year": 2025,
    "authors": "José Cubero-Cascante; Lenka Schneider; Rebecca Pelke; Arunkumar M. Vaidyanathan; Rainer Leupers; Jan Moritz Joseph",
    "corresponding_authors": "",
    "abstract": "Traditional Deep Learning Accelerators (DLAs) rely on off-chip memory to store large weight tensors, leading to high bandwidth demands and energy consumption. Compute-in-Memory (CIM) accelerators mitigate this by integrating high-density, non-volatile memory arrays, enabling a fully weight-stationary (FWS) dataflow. Multi-core CIM systems further enhance efficiency with cross-layer inference, where intermediate tensors stay on-chip, and cores operate in a pipeline. Despite diverse architecture proposals, no existing tool models the dataflow, memory access patterns and timing behaviour of multi-core CIM accelerators. We introduce CIMFlow, a modelling framework for cross-layer CIM architectures. Our flexible Hardware Architecture Model includes CIM and digital cores and leverages the buffets storage idiom for distributed token-based flow control. An Array-OL-based Workload Model captures CNNs’ multidimensional dependencies and applies hardware-aware transformations. These models are transformed into a timed cyclo-static dataflow graph for simulation. CIMFlow delivers latency, energy and traces for core and buffer utilisation. Our case studies on state-of-the-art CNNs show that cross-layer inference reduces latency by up to 52 ×. We also reveal that neglecting memory access delays results in throughput overestimations of up to 308%. To our knowledge, CIMFlow is the first tool focused on FWS cross-layer execution in CIM architectures that explicitly models data movement costs. It serves as a powerful cost model for design space exploration in next-generation CIM accelerators.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413633179",
    "type": "article"
  },
  {
    "title": "TimelyNet: Adaptive Neural Architecture for Autonomous Driving with Dynamic Deadline",
    "doi": "https://doi.org/10.1145/3762652",
    "publication_date": "2025-08-26",
    "publication_year": 2025,
    "authors": "Jiale Chen; Duc Van Le; Yuanchun Li; Yunxin Liu; Rui Tan",
    "corresponding_authors": "",
    "abstract": "To maintain driving safety, the execution of neural network-based autonomous driving pipelines must meet the dynamic deadlines in response to the changing environment and vehicle’s velocity. To this end, this paper proposes a real-time neural architecture adaptation approach, called TimelyNet, which uses a supernet to replace the most compute-intensive neural network module in an existing end-to-end autonomous driving pipeline. From the supernet, TimelyNet samples subnets with varying inference latency levels to meet the dynamic deadlines during run-time driving without fine-tuning. Specifically, TimelyNet employs a one-shot prediction method that jointly uses a lookup table and an invertible neural network to periodically determine the optimal hyperparameters of a subnet to meet its execution deadline while achieving the highest possible accuracy. The lookup table stores multiple subnet architectures with different latencies, while the invertible neural network models the distribution of the optimal subnet architecture given the latency. Extensive evaluation based on hardware-in-the-loop CARLA simulations shows that TimelyNet-integrated driving pipelines achieve the best driving safety, characterized by the lowest wrong-lane driving rate and zero collisions, compared with several baselines, including the state-of-the-art driving pipelines.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413644859",
    "type": "article"
  },
  {
    "title": "<i>VoxDepth</i> : Rectification of Depth Images on Edge Devices",
    "doi": "https://doi.org/10.1145/3763793",
    "publication_date": "2025-08-26",
    "publication_year": 2025,
    "authors": "Yashashwee Chakrabarty; Akanksha Dixit; Smruti R. Sarangi",
    "corresponding_authors": "",
    "abstract": "Autonomous mobile robots like self-flying drones and industrial robots heavily depend on depth images to perform tasks such as 3D reconstruction and visual SLAM. However, the presence of inaccuracies in these depth images can greatly hinder the effectiveness of these applications, resulting in sub-optimal results. Depth images produced by commercially available cameras frequently exhibit noise, which manifests as flickering pixels and erroneous patches. Machine Learning (ML)-based methods to rectify these images are unsuitable for edge devices that have very limited computational resources. Non-ML methods are much faster but have limited accuracy, especially for correcting errors that are a result of occlusion and camera movement. We propose a scheme called VoxDepth that is fast, accurate, and runs very well on edge devices such as the NVIDIA Jetson Nano board. It relies on a host of novel techniques: 3D point cloud construction and fusion, and using it to create a 2D template to fix erroneous depth images. VoxDepth shows superior results on both synthetic and real-world datasets. We specifically demonstrate a \\(31\\% \\) improvement in quality as compared to state-of-the-art methods on real-world depth datasets, while maintaining a competitive frame rate of 27 FPS (frames per second).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413696186",
    "type": "article"
  },
  {
    "title": "FT-DAG: An Efficient Full-Topology DAG Generator with Controllable Parameters",
    "doi": "https://doi.org/10.1145/3760781",
    "publication_date": "2025-08-26",
    "publication_year": 2025,
    "authors": "Yinjie Fang; Liping Yang; Weichen Liu; Guoquan Zhang; Y. D. Gu; Xiang Xiao; Wei Qin; Xiangzhen Ouyang; Wanli Chang",
    "corresponding_authors": "",
    "abstract": "Directed Acyclic Graph (DAG) models are extensively utilized across fields such as automotive, wireless communication, and deep learning, to capture the inherent functional dependencies. Topology of DAG has a significant impact on the performance of scheduling and resource management algorithms applied to it. Hence, it is imperative to generate all DAG topologies within the parameter ranges pertinent to an application domain, for impartial evaluation of such algorithms. Unfortunately, the existing DAG generators that are capable of offering full topology coverage have limited scalability and controllable parameters. This work reports open-source FT-DAG, an efficient and formally verified full-topology DAG generator that is able to control all major parameters, including the longest length, shortest length, width, jump layer, jump level, in-degree, out-degree, shape value as well as the number of nodes and edges. Experiments show that when the number of nodes is larger than 20, FT-DAG provides at least two orders of magnitude speedup compared to the state of the art and more orders to other generators. FT-DAG scales to 100 nodes in a typical industrial case study within hours.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413696205",
    "type": "article"
  },
  {
    "title": "Timetide: A Programming Model for Logically Synchronous Distributed Systems",
    "doi": "https://doi.org/10.1145/3763794",
    "publication_date": "2025-08-26",
    "publication_year": 2025,
    "authors": "Logan Kenwright; Partha S. Roop; Nathan Allen; Călin Caşcaval; Avinash Malik",
    "corresponding_authors": "",
    "abstract": "Massive strides in deterministic models have been made using synchronous languages. They are mainly focused on centralised applications, as the traditional approach is to compile away the concurrency. Time triggered languages such as Giotto and Lingua Franca are suitable for distribution albeit that they rely on physical clock synchronisation, which is both expensive and may suffer from scalability. Hence, deterministic programming of distributed systems remains challenging. We address the challenges of deterministic distribution by developing a novel multiclock semantics of synchronous programs. The developed semantics is amenable to seamless distribution. Moreover, our programming model, Timetide, alleviates the need for physical clock synchronisation by building on the recently proposed logical synchrony model for distributed systems. We discuss the important aspects of distributing computation, such as network communication delays, and explore the formal verification of Timetide programs. To the best of our knowledge, Timetide is the first multiclock synchronous language that is both amenable to distribution and formal verification without the need for physical clock synchronisation or clock gating.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413696238",
    "type": "article"
  },
  {
    "title": "The Case for HW/SW Harmony in Real-Time Systems: Tightening Memory Latency of Streaming Applications",
    "doi": "https://doi.org/10.1145/3762647",
    "publication_date": "2025-08-26",
    "publication_year": 2025,
    "authors": "Abdelrhman M. Abotaleb; Mohamed Hassan",
    "corresponding_authors": "",
    "abstract": "Modern critical cyber-physical systems such as autonomous vehicles, drones, and real-time medical monitoring, demand not only intensive data processing but also stringent adherence to real-time performance constraints. These applications often involve continuous or sequential data streams (e.g., images, videos, and sensor readings), which require frequent memory accesses. Despite advancements in processing power, huge variable interference delay is incurred within the Dynamic Random Access Memory (DRAM) accesses. However, achieving a tight bound of memory latency remains a significant challenge, yet it is essential for ensuring safe and predictable execution of these critical tasks. To address this bottleneck, we propose InterStellarRT , a novel hardware/software harmony methodology that provides data-aware optimizations across the entire memory hierarchy. Leveraging a software layer that communicates data access patterns to the memory controller, InterStellarRT achieves significant reductions in memory access times, ensuring tightly bounded and predictable times. We perform the theoretical analysis of the memory latency bound. Then, we prove that InterStellarRT provides remarkable tighter memory latency bound for in-isolation and interference latencies compared to the state-of-the-art real-time systems based on the Commercial-Off-The-Shelf (COTS) Double Data Rate 4 (DDR4) memory devices and is also applicable to DDR5. We evaluate InterStellarRT on RISC-V based quad-core system on GEM5 and DDR4 in Ramulator. Analyzing benchmark results from Polybench, LAPACK, Phoenix, and HPCG Suites, InterStellarRT achieves a 3.8 × tighter average bound for in-isolation memory latency and 13.5 × for interference latency under affine workloads, while for mixed-affinity workloads, the bounds are 2.15 × and 4 ×, respectively. Moreover, InterStellarRT achieves average 1.72 × end-to-end speedup, and 1.9 × bandwidth improvement, and 14% DRAM energy reduction against the baseline.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413696350",
    "type": "article"
  },
  {
    "title": "Schedule Synthesis for Synchronous Dataflow Models with Lower and Upper Timing Bounds",
    "doi": "https://doi.org/10.1145/3762643",
    "publication_date": "2025-08-26",
    "publication_year": 2025,
    "authors": "Joep van Wanrooij; Twan Basten; Marc Geilen",
    "corresponding_authors": "",
    "abstract": "Homogeneous Synchronous DataFlow Graphs (HSDFGs) have become a popular method for analysing the performance of manufacturing systems. Manufacturing tasks, modelled by actor firings in an HSDFG, are bounded by their earliest possible starting times, determined by the completion of preceding tasks. Taking into account these lower bounds, an HSDFG represents different possible task schedules for these tasks, namely any actor firing scheme that satisfies these lower bounds. However, in some cases, tasks in a manufacturing system must be completed before a deadline, which introduces an upper bound. Additionally, the relative start times between tasks may need to adhere to a lower bound. Such lower and upper bounds are not naturally supported by classical HSDFGs. In such cases, an HSDFG cannot represent all relevant aspects of the behaviour of a manufacturing system. This paper extends the HSDFG model to support the specification of lower- and upper-bound constraints on timing differences between actor-firing starts and completions. The paper then presents a new method for transforming extended HSDFGs into a (max, +) linear system in the form of its state-space matrices. This system can be used to synthesize a task schedule that adheres to the specified lower and upper bounds while achieving the earliest possible execution times, optimizing throughput or makespan. We illustrate the necessity for specifying lower and upper bounds, and the application of our techniques, with a manufacturing system case study.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413696388",
    "type": "article"
  },
  {
    "title": "Efficient Video Redaction at the Edge: Human Motion Tracking for Privacy Protection",
    "doi": "https://doi.org/10.1145/3762994",
    "publication_date": "2025-08-27",
    "publication_year": 2025,
    "authors": "Huijiao Qiao; V. K. Somasekhar Srinivas; Peter A. Dinda; Robert P. Dick",
    "corresponding_authors": "",
    "abstract": "Computationally efficient, camera-based, real-time human position tracking on low-end, edge devices would enable numerous applications, including privacy-preserving video redaction and analysis. Unfortunately, running most deep neural network based models in real time requires expensive hardware, making widespread deployment difficult, particularly on edge devices. Shifting inference to the cloud increases the attack surface, generally requiring that users trust cloud servers, and increases demands on wireless networks in deployment venues. Our goal is to determine the extreme to which edge video redaction efficiency can be taken, with a particular interest in enabling, for the first time, low-cost, real-time deployments with inexpensive commodity hardware. We present an efficient solution to the human detection (and redaction) problem based on singular value decomposition (SVD) background removal and describe a novel time- and energy-efficient sensor-fusion algorithm that leverages human position information in real-world coordinates to enable real-time visual human detection and tracking at the edge. These ideas are evaluated using a prototype built from (resource-constrained) commodity hardware representative of commonly used low-cost IoT edge devices. The speed and accuracy of the system are evaluated via a deployment study, and it is compared with the most advanced relevant alternatives. The multi-modal system operates at a frame rate ranging from 20 FPS to 60 FPS, achieves a wIoU 0.3 score (see Section 5.4) ranging from 0.71 to 0.79, and successfully performs complete redaction of privacy-sensitive pixels with a success rate of 91%–99% in human head regions and 77%–91% in upper body regions, depending on the number of individuals present in the field of view. These results demonstrate that it is possible to achieve adequate efficiency to enable real-time redaction on inexpensive, commodity edge hardware.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413761340",
    "type": "article"
  },
  {
    "title": "Grasp-HGN: Grasping the Unexpected",
    "doi": "https://doi.org/10.1145/3762657",
    "publication_date": "2025-08-27",
    "publication_year": 2025,
    "authors": "Mehrshad Zandigohar; Mallesham Dasari; Gunar Schirner",
    "corresponding_authors": "",
    "abstract": "For transradial amputees, robotic prosthetic hands promise to regain the capability to perform daily living activities. To advance next-generation prosthetic hand control design, it is crucial to address current shortcomings in robustness to out of lab artifacts, and generalizability to new environments. Due to the fixed number of object to interact with in existing datasets, contrasted with the virtually infinite variety of objects encountered in the real world, current grasp models perform poorly on unseen objects, negatively affecting users’ independence and quality of life. To address this: (i) we define semantic projection, the ability of a model to generalize to unseen object types and show that conventional models like YOLO, despite 80% training accuracy, drop to 15% on unseen objects. (ii) we propose Grasp-LLaVA, a Grasp Vision Language Model enabling human-like reasoning to infer the suitable grasp type estimate based on the object’s physical characteristics resulting in a significant 50.2% accuracy over unseen object types compared to 36.7% accuracy of an SOTA grasp estimation model. Lastly, to bridge the performance-latency gap, we propose Hybrid Grasp Network (HGN), an edge-cloud deployment infrastructure enabling fast grasp estimation on edge and accurate cloud inference as a fail-safe, effectively expanding the latency vs. accuracy Pareto. HGN with confidence calibration (DC) enables dynamic switching between edge and cloud models, improving semantic projection accuracy by 5.6% (to 42.3%) with 3.5× speedup over the unseen object types. Over a real-world sample mix, it reaches 86% average accuracy (12.2% gain over edge-only), and 2.2× faster inference than Grasp-LLaVA alone.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413761343",
    "type": "article"
  },
  {
    "title": "ProGIP: Protecting Gradient-based Input Perturbation Approaches for OOD Detection From Soft Errors",
    "doi": "https://doi.org/10.1145/3761796",
    "publication_date": "2025-08-27",
    "publication_year": 2025,
    "authors": "Sumedh Shridhar Joshi; Hwisoo So; S C Park; W. Ko; Jinhyo Jung; Yohan Ko; Uiwon Hwang; Kyoungwoo Lee; Aviral Shrivastava",
    "corresponding_authors": "",
    "abstract": "Undetected out-of-distribution (OOD) inputs pose a significant threat to the reliability of deep learning models, as they may lead to unexpected behaviors during inference. Several studies have proposed effective OOD input detection methods. However, soft errors—another significant threat to reliability-can impact both the classification results of neural network models and the ID/OOD detections of OOD detection methods. To provide a resilient OOD detection solution against soft errors, we analyze the effect of soft errors on neural network models with gradient-based input perturbation (GIP) approaches, which are representative methods for OOD detection. Building on our analysis, we propose ProGIP, which incorporates two software-level range-based fault detectors to protect all execution phases of GIP approaches, including two forward passes and one backward pass. Because it is purely software–based and adds just two scalar comparisons, ProGIP is readily deployable even on resource–constrained embedded platforms. Our ProGIP solution enables GIP approaches to distinguish between ID, OOD, and fault-affected inferences, detecting 97.7% of critical faults with a negligible runtime overhead of only 0.84%. Experimental results with 2.4 million fault injections across various neural networks and OOD detection methods demonstrate ProGIP’s effectiveness in ensuring comprehensive reliability against non-malicious threats.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413761354",
    "type": "article"
  },
  {
    "title": "LazyTick: Lazy and Efficient Management of Job Release in Real-Time Operating Systems",
    "doi": "https://doi.org/10.1145/3762651",
    "publication_date": "2025-08-27",
    "publication_year": 2025,
    "authors": "Kay Heider; Christian Hakert; Kuan-Hsun Chen; Jian-Jia Chen",
    "corresponding_authors": "",
    "abstract": "Releasing jobs and performing scheduling decisions in real-time operating systems (RTOSes) is often realized within tick interrupts. In each tick interrupt, a set of tasks that are waiting to release new jobs, namely the waiting set, is inspected to determine the jobs that should be released at this tick. Such a waiting set is sorted whenever a job has finished, by which the release process can be efficiently achieved. However, the overhead of sorting can vary vastly depending on the task set, which has to be taken into account in the worst-case timing analysis. Moreover, the tick interrupt in common practices is backed by a single hardware timer that is configured to trigger interrupts, either with a fixed period or reconfigured to the next release time (so-called one-shot timer). Since not necessarily at every interrupt a job will be released, several tick interrupts might be redundant. For the one-shot timers, the reconfiguration during runtime also incurs overheads at a variable interval. To reduce such variability and amount of overhead, in this work, we propose LazyTick which partitions the task set and distributes the subsets over multiple timers. Specifically, we propose two job release procedures with constant operations overhead—one for harmonic task sets and one for non-harmonic task sets. We implemented the support for multiple hardware timers in FreeRTOS and conducted intensive experimental evaluations. The evaluation shows that LazyTick can reduce the variability in overhead by up to ≈ 5 × in peak and ≈ 3 × on average in comparison to the default implementation. Additionally, the combined overhead of the job release process is reduced by up to ≈ 6.1 × in peak and ≈ 3.6 × on average.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413761355",
    "type": "article"
  },
  {
    "title": "Runtime Adaptivity for Efficient Neural Network Inference on Autonomous Systems",
    "doi": "https://doi.org/10.1145/3762640",
    "publication_date": "2025-08-27",
    "publication_year": 2025,
    "authors": "Danny Abraham; Biswadip Maity; Bryan Donyanavard; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Neural network pruning and dynamic training have emerged as key techniques for optimizing deep learning models to meet the constraints of resource-limited systems. However, achieving both efficiency and adaptability without compromising safety or performance remains a significant challenge in real-time autonomous applications. We present Back to the Future and USA-Nets , two complementary approaches that address this challenge. Back to the Future combines pruning with dynamic routing to enable latency gains and dynamic reconfiguration at runtime, allowing a pruned model to seamlessly revert to the full model when unsafe or anomalous behavior is detected. USA-Nets extend this concept by enabling runtime adaptability through dynamically trained networks that can adjust their width without requiring additional annotated data or excessive storage overhead. Together, these methods deliver significant performance improvements while maintaining safety and flexibility, as evidenced by experimental results demonstrating that Back to the Future achieves a 32 × faster reversion time compared to loading the full model, and USA-Nets achieve up to \\(85\\% \\) latency reduction with minimal accuracy degradation. These innovations pave the way for efficient, adaptable, and safe deployment of deep learning models in diverse real-time and resource-constrained environments, with future work focusing on advanced pruning techniques and runtime optimizations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413761369",
    "type": "article"
  },
  {
    "title": "Efficient Black-Box Checking with Specification-Guided Abstraction",
    "doi": "https://doi.org/10.1145/3762659",
    "publication_date": "2025-08-27",
    "publication_year": 2025,
    "authors": "T. Matsumoto; Kazuki Watanabe; Kohei Suenaga; Masaki Waga",
    "corresponding_authors": "",
    "abstract": "Cyber-physical systems (CPSs) often contain components whose internal design is unknown, making their verification challenging. Although black-box checking (BBC)—an automated black-box testing method that combines automata learning and model checking—can detect unsafe behaviors without requiring a complete model, it becomes computationally expensive for large or infinite-state systems. To address this problem, we propose a specification-guided abstraction that identifies and merges states in the system’s state space if they are equivalent under the verified specifications. Building on this abstraction, we develop an algorithm that directly learns the resulting abstract Mealy machine, thereby bypassing the need to learn the full system behavior first. We then integrate the new learning procedure with model checking to obtain an enhanced BBC framework that efficiently handles large or infinite-state systems, particularly when verifying multiple properties. Our empirical evaluation demonstrates that specification-guided abstraction improves detection and efficiency in uncovering unsafe behaviors in CPSs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413761426",
    "type": "article"
  },
  {
    "title": "Selective Subarray Isolation for Mitigating RowHammer Attack",
    "doi": "https://doi.org/10.1145/3762996",
    "publication_date": "2025-08-27",
    "publication_year": 2025,
    "authors": "M Praseetha; Madhu Mutyam; Venkata Kalyan Tavva",
    "corresponding_authors": "",
    "abstract": "RowHammer is a severe circuit-level vulnerability in DRAM-based main memories that allows attackers to flip the bits stored in DRAM rows by repeatedly accessing the nearby rows. Due to density scaling, newer generation DRAM chips are found to be increasingly more vulnerable to RowHammer attacks, motivating researchers from both academia and industry to come up with new RowHammer attack patterns and mitigation strategies that can be widely adopted. However, the question remains whether the mitigation strategies available now can secure DRAM-based memory in the future. We propose three approaches to mitigate RowHammer attacks by exploiting subarray isolation. A subarray is a collection of DRAM rows in a DRAM bank where each subarray operates independently. In the first approach, known as Subarray Isolation (SI), data from different domains are allocated to separate subarrays in DRAM. The SI strategy naively allocates subarrays to domains, greatly hampering the bank-level parallelism in memory accesses, leading to a significant performance loss. The second approach, namely Selective Subarray Isolation (SSI), improves this aspect. With the SSI strategy, we allocate only confidential data from different domains to separate subarrays. The non-confidential data of the domains will share the subarrays as in the conventional case. Our evaluations show that the SSI strategy performs better compared to state-of-the-art mitigation strategies when the amount of confidential data is less. To further improve performance, we propose the third approach, namely Finer Selective Subarray Isolation (FSSI), which allocates separate partitions protected with guard rows within a subarray to confidential data from different domains. Our evaluations show that, of the three approaches, the FSSI strategy performs the best. Compared to baseline without any RowHammer protection, the FSSI strategy experiences an average performance drop of \\(0.89\\% \\) for \\(50\\% \\) of confidential data, but for \\(10\\% \\) and \\(20\\% \\) of confidential data, it shows an improvement of \\(1.43\\% \\) and \\(1.28\\% \\) , respectively. We also observe that the FSSI strategy is the most energy efficient among the state-of-the-art RowHammer mitigation techniques. Note that all our proposed strategies do not incur hardware overhead for performing RowHammer mitigation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413761435",
    "type": "article"
  },
  {
    "title": "MERE: Hardware-Software Co-Design for Masking Cache Miss Latency in Embedded Processors",
    "doi": "https://doi.org/10.1145/3762654",
    "publication_date": "2025-08-27",
    "publication_year": 2025,
    "authors": "Da You; Jieyu Jiang; X.J. Wang; Yu Du; Zhihang Tan; Wenbo Xu; Wang Hui; Jiapeng Guan; Ran Wei; Shuai Zhao; Zhe Jiang",
    "corresponding_authors": "",
    "abstract": "Runahead execution is a technique to mask memory latency caused by irregular memory accesses. By pre-executing the application code during occurrences of long-latency operations and prefetching anticipated cache-missed data into the cache hierarchy, runahead effectively masks memory latency for subsequent cache misses and achieves high prefetching accuracy; however, this technique has been limited to superscalar out-of-order and superscalar in-order cores. For implementation in scalar in-order cores, the challenges of area-/energy-constraint and severe cache contention remain. Here, we build the first full-stack system featuring runahead, MERE , from SoC and a dedicated ISA to the OS and programming model. Through this deployment, we show that enabling runahead in scalar in-order cores is possible, with minimal area and power overheads, while still achieving high performance. By re-constructing the sequential runahead employing a hardware/software co-design approach, the system can be implemented on a mature processor and SoC. Building on this, an adaptive runahead mechanism is proposed to mitigate the severe cache contention in scalar in-order cores. Combining this, we provide a comprehensive solution for embedded processors managing irregular workloads. Our evaluation demonstrates that the proposed MERE attains 93.5% of a 2-wide out-of-order core’s performance while constraining area and power overheads below 5%, with the adaptive runahead mechanism delivering an additional 20.1% performance gain through mitigating the severe cache contention issues.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413761444",
    "type": "article"
  },
  {
    "title": "Wasm-IO: Enabling Low-Level Device Interaction in WebAssembly for Industry Automation",
    "doi": "https://doi.org/10.1145/3760387",
    "publication_date": "2025-08-29",
    "publication_year": 2025,
    "authors": "Maximilian L. Seidler; Alexander Lochmann; Peter Ulbrich",
    "corresponding_authors": "",
    "abstract": "Certification on a component level is highly beneficial in industrial automation because it allows for independent verification and updates without compromising the reliability of the overall system. Containerization technologies naturally address this demand by providing isolation between software modules. In particular, WebAssembly-based WebAssembly-based (Wasm) containerization is gaining popularity in industrial automation due to its inherent advantages, including cross-platform interoperability and secure execution of untrusted third-party code. However, Wasm’s strict sandboxing poses a significant limitation as it severely limits interaction with hardware devices, making it difficult to interface with sensors and actuators. This is a substantial barrier to adoption in industrial automation, where real-time and low-level hardware interactions are critical. To address this challenge, we present Wasm-IO , a framework designed to facilitate peripheral I/O operations within WASM containers. Wasm-IO allows the development of isolated device drivers in WASM, explicitly moving hardware interaction to the container level. Our architectural approach facilitates containers with hardware interaction to be independently certified, updated, and maintained without adversely affecting each other. This paper elucidates foundational methodologies and practical implementations supporting synchronous and asynchronous I/O operations and methods for embedding platform-independent peripheral configurations within WASM binaries. Additionally, we present an extended priority model enabling interrupt handling in WASM while maintaining temporal isolation. Our evaluation demonstrates that Wasm-IO significantly reduces latency and overhead compared to existing methods and traditional user-level driver implementations, effectively addressing certification and functional requirements critical to industrial automation systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413830761",
    "type": "article"
  },
  {
    "title": "SecuPilot: A Security Coprocessor-Integrated Platform for Autonomous UAV Security",
    "doi": "https://doi.org/10.1145/3762642",
    "publication_date": "2025-08-29",
    "publication_year": 2025,
    "authors": "Yatharth Agarwal; Vijay Raghunathan",
    "corresponding_authors": "",
    "abstract": "This paper introduces SecuPilot, a Security Coprocessor-integrated platform designed to enhance the resilience and operational security of autonomous Unmanned Aerial Vehicles (UAVs) in increasingly adversarial environments. Recognizing the critical role UAVs play in diverse applications, SecuPilot builds upon established architectures by incorporating a dedicated security module that performs a series of comprehensive preflight checks to establish a robust root of trust. Once airborne, the platform continuously monitors the UAV’s operational state during runtime to infer and maintain its security, ensuring that any anomalies are promptly identified and addressed without disrupting mission-critical functions. We develop a custom Hardware-in-the-Loop (HITL) simulation framework replicating realistic operational scenarios and adversarial conditions to validate the system’s performance and effectiveness. This rigorous evaluation demonstrates that SecuPilot can successfully mitigate potential threats while preserving the essential performance characteristics of the UAV. The results underscore the viability of a scalable, hardware-centric approach to UAV security, paving the way for safer autonomous systems capable of operating in complex, threat-prone environments.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413831013",
    "type": "article"
  },
  {
    "title": "Ferroelectric Memory Technology for Big Data Applications",
    "doi": "https://doi.org/10.1145/3764868",
    "publication_date": "2025-08-30",
    "publication_year": 2025,
    "authors": "Nikhil Shukla; Kai Ni; Samuel Stevenson; Vijaykrishnan Narayanan",
    "corresponding_authors": "",
    "abstract": "Big Data has an insatiable appetite for larger and better-performing memory. While current memory technologies continue to advance, the performance gaps in current memory and storage technology have motivated the exploration of emerging memory technologies capable of providing new functionalities. Ferroelectric memory is one such promising candidate which has recently experienced a revival after the discovery of ferroelectricity in hafnium dioxide (HfO 2 ) – the dielectric of choice in advanced CMOS manufacturing. While the commercial viability of ferroelectric memory technology has made significant progress over the past decade, several challenges related to variation and reliability still stand as a barrier to large-scale commercial implementation. Here, we review some of the outstanding challenges of ferroelectric memory technology along with the recent materials and device innovations that are being considered to overcome them. Moreover, we aim to highlight these challenges as materials and device co-design problems that must be addressed through collaborative efforts that straddle the two disciplines. We identify and provide our perspective on some of the key challenges and opportunities for ferroelectric-based microelectronic technology. Ferroelectrics non-volatile memory, in-memory computation",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413843847",
    "type": "article"
  },
  {
    "title": "Quasi-Static Scheduling for Deterministic Timed Concurrent Models on Multi-Core Hardware",
    "doi": "https://doi.org/10.1145/3762653",
    "publication_date": "2025-09-01",
    "publication_year": 2025,
    "authors": "Shaokai Lin; Erling Jellum; Mirco Theile; Tassilo Tanneberger; Binqi Sun; Chadlia Jerad; Yimo Xu; Guangyu Feng; Magnus Mæhlum; Jian-Jia Chen; Martin Schoeberl; Linh Thi Xuan Phan; Jerónimo Castrillón; Sanjit A. Seshia; Edward A. Lee",
    "corresponding_authors": "",
    "abstract": "To design performant, expressive, and reliable cyber-physical systems (CPSs), researchers extensively perform quasi-static scheduling for concurrent models of computation (MoCs) on multi-core hardware. However, these quasi-static scheduling approaches are developed independently for their corresponding MoCs, despite commonality in the approaches. To help generalize the use of quasi-static scheduling to new and emerging MoCs, this paper proposes a unified approach for a class of deterministic timed concurrent models (DTCMs), including prominent models such as synchronous dataflow (SDF), Boolean-controlled dataflow (BDF), scenario-aware dataflow (SADF), and Logical Execution Time (LET). In contrast to scheduling techniques tailored exclusively to specific MoCs, our unified approach leverages a common intermediate formalism called state space finite automata (SSFA), bridging the gap between high-level MoCs and executable schedules. Once identified as DTCMs, new MoCs can directly adopt SSFA-based scheduling, significantly easing adoption. We show that quasi-static schedules facilitated by SSFA are provably free from timing anomalies and enable straightforward worst-case makespan analysis. We demonstrate the approach using the reactor model—an emerging discrete-event MoC—programmed using the Lingua Franca ( LF ) language. Experiments show that quasi-statically scheduled LF programs exhibit lower runtime overhead compared to the dynamically scheduled LF programs, and that the analyzable worst-case makespans enable compile-time deadline checking.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413876816",
    "type": "article"
  },
  {
    "title": "Unlocking the Full Potential of Dual-Interface SSDs: A Comprehensive Hardware and Software Perspective",
    "doi": "https://doi.org/10.1145/3762153",
    "publication_date": "2025-09-01",
    "publication_year": 2025,
    "authors": "Lok Yee Chow; Yingjia Wang; Liang Yu-hong; Ming-Chang Yang",
    "corresponding_authors": "",
    "abstract": "The legacy block interface for I/O benefits from data locality but faces challenges with I/O amplification due to the frequent small read-write operations common in most applications. Dual-Interface SSDs, which integrate block-interface Flash memory with byte-addressable memory, create opportunities for application redesign by reducing unnecessary read-write amplification on storage devices. However, current Dual-Interface SSD hardware remains limited in terms of size and functionality. Existing software designs for Dual-Interface SSDs often use the byte-addressable space as sequential logs with basic batch reclamation. While this space allows random access, and batch reclamation introduces significant tail latency caused by excessive read and write-back operations. To fully exploit the potential of Dual-Interface SSDs, we have developed a prototype on a hardware-software configurable platform. This publicly accessible Dual-Interface SSD offers realistic and optimized performance, overcoming the size and functionality limitations of previous designs. In addition, we demonstrate the ability of Dual-Interface SSDs to reduce write amplification in a traditional Copy-on-Write B-Tree data store. By employing two key techniques—Tree Pointer Relocation, which decouples indirection from the tree structure, and Tree Node Accommodation, which enables small-sized key-value pair updates to be processed directly in the byte-addressable space—we significantly improve the efficiency of storage operations. Our evaluation reveals that these techniques, when applied to Dual-Interface SSDs, achieve performance gains of 30.5% and 52.5% compared to a CoW B-Tree operating on traditional block-interface SSDs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413876868",
    "type": "article"
  },
  {
    "title": "MEAN: Mixture-of-Experts Neural Receiver - Architecture and Performance Analysis",
    "doi": "https://doi.org/10.1145/3765519",
    "publication_date": "2025-09-01",
    "publication_year": 2025,
    "authors": "Bram Van Bolderik; Vlado Menkovski; Sonia Heemstra de Groot; Manil Dev Gomony",
    "corresponding_authors": "",
    "abstract": "Neural network-based wireless receivers, also known as neural receivers , have demonstrated superior performance over traditional receivers, but come with greater computational complexity. The need to use these networks on energy-conscious edge devices is increasing, necessitating energy-efficient and adaptive neural receivers to function well under varying channel conditions. Transitioning static neural receivers to dynamic models using the concepts of Dynamic Neural Networks (DyNN) could reduce runtime computational complexity and energy consumption. This could be achieved by adapting the network architecture during run-time and exploit the varying channel conditions in a mobile communication system to reduce the computational complexity. This work introduces MEAN, a novel hard-gated Mixture-of-Experts (MOE) based neural receiver architecture. The main idea behind MEAN is to use several smaller Signal-to-Noise-Ratio (SNR) expert networks are used during run-time to create a network that selects the correct expert for the current data input to reduce complexity. The paper consists of the following key contributions. (1) MEAN architecture based on [25]: A hard-gated MoE model that dynamically selects the most suitable expert for each input dynamically based on current channel conditions. (2) Comprehensive system-level performance analysis of MEAN across different code rates and modulation schemes, including validation of expert selection during inference. (3) Loss function optimization for the gating network to promote the activation of specific experts in designated noise regions. This enhancement reduces gating network complexity while improving expert selection accuracy over previous MEAN implementations. (4) Hardware analysis of a gate-level implementation of MEAN synthesized in 22nm FD-SOI technology. The design is generated using a custom High-Level Synthesis (HLS) framework, providing detailed power and area evaluations. The proposed MEAN architecture for a Single Input Multiple Output (SIMO) wireless system achieves a 37.11% reduction in total power consumption with only an 11.04% increase in area, while maintaining accuracy comparable to that of a static neural network.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413876890",
    "type": "article"
  },
  {
    "title": "Designing High-Performance and Thermally Feasible Multi-Chiplet Architectures Enabled by Non-Bendable Glass Interposer",
    "doi": "https://doi.org/10.1145/3762644",
    "publication_date": "2025-09-03",
    "publication_year": 2025,
    "authors": "Harsh Sharma; Janardhan Rao Doppa; Ümit Y. Ogras; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "Multi-chiplet architectures enabled by glass interposer offer superior electrical performance, enable higher bus widths due to reduced crosstalk, and have lower capacitance in the redistribution layer than current silicon interposer-based systems. These advantages result in lower energy per bit, higher communication frequencies, and extended interconnect range. However, deformation of the package (warpage) in glass interposer-based systems becomes a critical challenge as system size increases, leading to severe mechanical stress and reliability concerns. Beyond a certain size, conventional packaging techniques fail to manage warpage effectively, necessitating new approaches to mitigate warpage induced bending with scalable performance for glass interposer based multi-chiplet systems. To address these inter-twined challenges, we propose a thermal-, warpage-, and performance-aware design framework that employs architecture and packaging co-optimization . The proposed framework disintegrates the surface and embedded chiplets to balance conflicting design objectives, ensuring optimal trade-offs between performance, power, and structural reliability. Our experiments demonstrate that optimized multi-chiplet architectures from our design framework achieve up to 64.7% performance improvement and 40% power reduction compared to traditional 2.5D systems to execute deep neural network workloads with lower fabrication costs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414000053",
    "type": "article"
  },
  {
    "title": "Metareasoning for Edge-Cloud Collaborative LLM Planning for Efficient Autonomous Navigation",
    "doi": "https://doi.org/10.1145/3765750",
    "publication_date": "2025-09-05",
    "publication_year": 2025,
    "authors": "Mozhgan Navardi; S. Gao; Mikolaj Walczak; Fernando Camacho; Tinoosh Mohsenin",
    "corresponding_authors": "",
    "abstract": "Cutting-edge Large Language Models (LLMs) play a crucial role in improving autonomous navigation by offering efficient solutions. While LLMs require powerful computers to operate, security concerns and maintaining a stable connection with the cloud can be challenging due to various factors. To address this issue, we propose a metareasoning approach for edge-cloud collaborative LLM planning which leads to an efficient autonomous navigation. The proposed approach allows the system to seamlessly switch between cloud and edge devices to fulfill the mission even in the event of a lost connection or entering a GPS-denied environment. Moreover, we deploy state-of-the-art LLM models on resource-constrained systems like the NVIDIA Jetson Orin Nano 8GB, integrated with ROSMASTER X3. These LLMs have demonstrated exceptional utility in dynamic planning for multi-room or maze environments. A comprehensive LLM profiling of TinyLLM models was performed for five different LLMs. The LLM profiling result shows that while certain models with smaller sizes and lower power consumption were available, their accuracy was insufficient for our application requirements. As a result, LLaMa2-7B is considered the edge LLM model due to its optimal balance of performance and accuracy. The experimental results show that under weak signal conditions (&lt; −50 dB), the metareasoning approach improves energy consumption by up to 4x while the cloud-based implementation exceeds the energy consumption of the onboard LLM implementation. Moreover, with delays of 10-20 seconds, cloud implementation becomes impractical for real-time applications in weak signal environments. This underscores the need for metareasoning, which optimizes energy consumption and response time, providing a balanced solution by adapting to signal strength. A real-world implementation of the proposed approach on ROSMASTER X3 with NVIDIA Jetson Orin Nano board can be found in this video which shows that the mission was completed despite losing the connection with cloud-based LLM.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414018991",
    "type": "article"
  },
  {
    "title": "MaGrIP: Magnitude and Gradient-Informed Pruning for Task-Agnostic Large Language Models",
    "doi": "https://doi.org/10.1145/3766068",
    "publication_date": "2025-09-05",
    "publication_year": 2025,
    "authors": "Uttej Kallakuri; Edward Humes; Hasib-Al Rashid; Tinoosh Mohsenin",
    "corresponding_authors": "",
    "abstract": "Large Language Models (LLMs) have become foundational tools in natural language processing, achieving state-of-the-art performance across a variety of tasks. However, their immense size and computational requirements make them impractical for deployment in resource-constrained environments, such as edge devices and embedded systems. In this work, we introduce Magnitude and Gradient-Informed Pruning (MaGrIP) , a novel framework for task-agnostic pruning and compression of LLMs. MaGrIP employs a dual-threshold strategy combining magnitude- and gradient-based saliency measures to efficiently prune redundant neurons while retaining task performance. Our results demonstrate the effectiveness of MaGrIP in compressing state-of-the-art models. The compression reduced the total computational complexity of the FFN layers from \\(\\mathcal {O}(d \\cdot h) \\) to \\(\\mathcal {O}((d - q) \\cdot h) \\) . In terms of model size, our pruning approach significantly reduces both model parameters and storage requirements while maintaining competitive perplexity scores evaluated on WikiText-2. For the Gemma 7B model, our method reduces the total size from 28 GB to 5 GB, while for Gemma 2B, MaGrIP achieves a size reduction from 8 GB to 1.5 GB. MaGrIP furthermore exhibits robust performance across multiple benchmarks, such as BOOLQ, ARC-E, and CSQA. Specifically, the pruned Gemma 7B model at 50% pruning achieved 59.26% accuracy on ARC-E compared to 81.06% for the baseline, and 64.74% accuracy on BoolQ compared to 59.98% for the baseline. Similarly, the pruned Llama 3 8B at 50% pruning achieved 46.76% accuracy on ARC-E compared to 77.57% for the baseline, reflecting the trade-off between compression and accuracy. LLMs compressed using MaGrIP, when deployed on the Nvidia Jetson Orin Nano, achieved a 2.16 × improvement in throughput and a 2.3 × improvement in performance compared to baseline LLMs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414019041",
    "type": "article"
  },
  {
    "title": "Transfer Schedulability in Periodic Real-Time Systems",
    "doi": "https://doi.org/10.1145/3763236",
    "publication_date": "2025-09-05",
    "publication_year": 2025,
    "authors": "Lars Willemsen; Mario Günzel; Björn B. Brandenburg; Georg von der Brüggen; Ching‐Chi Lin; Jian-Jia Chen",
    "corresponding_authors": "",
    "abstract": "We introduce and study transfer schedulability , a novel concept that describes how properties of a reference schedule derived from a scheduling algorithm \\(\\mathcal {A} \\) are transferred onto another scheduling algorithm \\(\\mathcal {B} \\) for a given task system and fixed arrival times. Specifically, we say schedulability is transferred from \\(\\mathcal {A} \\) to \\(\\mathcal {B} \\) if the task set is schedulable under \\(\\mathcal {B} \\) whenever all deadlines are met in the reference schedule produced by \\(\\mathcal {A} \\) . We identify a sufficient criterion for schedulability to be transferred on uniprocessor systems, which we verify with the Rocq proof assistant, and based on this criterion develop runtime mechanisms that enforce transfer schedulability. We relate transfer schedulability to prior approaches from the literature and demonstrate how the concept can be utilized to avoid timing anomalies and lower runtime scheduling overheads. We demonstrate that transfer schedulability can be utilized to prevent timing anomalies for non-preemptive scheduling, self-suspending tasks, and directed acyclic graph (DAG) tasks where the edges induce delays. Our evaluation on synthesized task sets shows improved schedulability compared to standard scheduling algorithms. We also evaluated the number of interventions necessary to transfer schedulability, and additionally demonstrate that the proposed runtime mechanisms eliminate timing anomalies (like a completely static, fully table-driven approach) while achieving a response-time distribution closely resembling those of classic dynamic, event-driven schedulers like EDF.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414032564",
    "type": "article"
  },
  {
    "title": "System Scenario-Based Design of the Last-Level Cache in Advanced Interconnect-Dominant Technology Nodes",
    "doi": "https://doi.org/10.1145/3762649",
    "publication_date": "2025-09-05",
    "publication_year": 2025,
    "authors": "Mahta Mayahinia; Tommaso Marinelli; Zhenlin Pei; Hsiao-Hsuan Liu; Chenyun Pan; Zsolt Tőkei; Francky Catthoor; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Feature size reduction of the front End of the Line (FEoL) and back End of the Line (BEoL) elements, i.e., transistors and interconnects, has been the main enabler of the next-generation computation systems. The decreasing trend of the cross-sectional area of the interconnect in advanced technology nodes, however, comes along with a drastic increase in the resistive parasitic, substantially impacting the overall energy efficiency and performance of the computer system. Mitigation of the high parasitic resistance within an advanced-node static RAM (SRAM)-based last-level cache (LLC) is the main target of this paper. To achieve this target, we augment the LLC interconnect with some degree of reconfiguration by utilizing a dynamic segmented bus (DSB). With DSB, the interconnect segments that are most actively used for a given workload can be shortened, on average, contributing to a smaller capacitive load. Hence, the efficient reconfiguration of an LLC interconnect strongly depends on the LLC demands of the application. To account for this workload dependency, we design the required microarchitectural support in an end-to-end application-to-technology flow. By optimizing the overhead of DSB switches and additional hardware modules, the SRAM-based LLC with DSB-augmented intra-macro interconnect achieves 33% energy savings and 16% reduction in total access time across eight representative workloads, with a negligible area overhead of less than 0.4%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414032652",
    "type": "article"
  },
  {
    "title": "A Precision-Scalable Accelerator with Sign-Magnitude Representation and Dual Adder Trees",
    "doi": "https://doi.org/10.1145/3767336",
    "publication_date": "2025-09-15",
    "publication_year": 2025,
    "authors": "Xianghong Hu; Ci-Jian Yang; Xueming Li; R. Li; Yuanmiao Lin; Shu Qin Fu; Hongmin Huang; Shuting Cai; Xiaoming Xiong",
    "corresponding_authors": "",
    "abstract": "Currently, there are two mainstream acceleration methods; one is mixed precision and the other is sparsity. Few accelerators support both mixed precision and sparsity, and most enable precision configurations across layers rather than within a single layer. Furthermore, most of accelerators adopt the traditional two’s complement (2C) data representation method, and we found that 2C brings many invalid ”1” when representing signed data, which brings more resources overhead for mixed precision and many invalid operations for bit-level sparsity. Therefore, we propose a high-efficiency accelerator featuring a precision-scalable Sign-Magnitude Processing Element (SM-PE), which adopts a data representation method of SM and can flexibly support various precision calculations (2, 4, 8 bits) and bit-level sparsity. In addition, a dynamic quantization algorithm named DoReFaLike and a bit-level column sparsity (BLCS) technique are proposed to improve the efficiency of SM-PEs. Under the same accuracy constraint, the sparsity rate of the SM scheme is 3.5× higher than that of the 2C format. The accelerator has been synthesized on a 55nm CMOS ASIC platform. When scaled to 28nm, experimental results show that the energy efficiency of the proposed accelerator reaches 15.50, 25.37, 101.54 TOPS/W with 8-bit, 4-bit, and 2-bit input activations, respectively, and weights represented in sparse 8-bit precision, operating at 400 MHz. Compared to state-of-the-art accelerators, the proposed design achieves a performance improvement of 1.1× to 3.9×.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414179488",
    "type": "article"
  },
  {
    "title": "Boosting Cryptographic ICs' Side-Channel Resistance: A Formal Framework for Automatic Identification and Protection of Leaky Paths",
    "doi": "https://doi.org/10.1145/3768154",
    "publication_date": "2025-09-16",
    "publication_year": 2025,
    "authors": "Qizhi Zhang; Ya Gao; Haocheng Ma; Jiaji He; Yiqiang Zhao; Xiaolong Guo",
    "corresponding_authors": "",
    "abstract": "Side-channel analysis (SCA) attacks pose a significant threat to cryptographic integrated circuits (ICs). While designers have endeavored to introduce various countermeasures during the IC development phase, many of these solutions incur substantial overheads in terms of area, power, and performance. Additionally, they often necessitate a full-custom circuit design for effective deployment. This issue arises due to the absence of systematic methodologies and analytical tools for circuit designers to accurately identify the sources of side-channel leakage within the hardware design. In this paper, we propose the concept of side-channel tracking logic and, building upon this foundation, introduce a novel framework that seamlessly integrates with commercial design flows to automatically identify and safeguard leaky paths. Our approach begins by pinpointing partial logic cells that exhibit the highest information leakage using dynamic correlation analysis. Subsequently, formal-based leakage property checking constructs comprehensive leaky paths centered on these cells. In this process, side-channel tracking logic was proposed and applied for the first time to trace and extract side-channel leakage paths. Based on this, an automated formal modeling and leakage property verification tool was designed. Once these paths are discerned, we deploy apt hardware countermeasures, encompassing Boolean masking and random precharge, to eradicate information leakage along these routes. This framework has been experimentally validated across different encryption circuits and the efficacy of our methodology is corroborated through both simulated and real-world measurements on FPGA implementations. Empirical results showcase an enhancement of over 1000 × in side-channel resistance, incurring a modest overhead of less than 6.53% across power, area, and performance metrics.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414245569",
    "type": "article"
  },
  {
    "title": "Optimizing Tensor Train Decomposition in DNNs for RISC-V Architectures Using Design Space Exploration and Compiler Optimizations",
    "doi": "https://doi.org/10.1145/3768624",
    "publication_date": "2025-09-18",
    "publication_year": 2025,
    "authors": "Theologos Anthimopoulos; Milad Kokhazadeh; Vasilios Kelefouras; Benjamin Himpel; Γεώργιος Κεραμίδας",
    "corresponding_authors": "",
    "abstract": "Deep neural networks (DNNs) have become indispensable in many real-life applications like natural language processing, and autonomous systems. However, deploying DNNs on resource-constrained devices, e.g., in RISC-V platforms, remains challenging due to the high computational and memory demands of fully connected (FC) layers, which dominate resource consumption. Low-rank factorization (LRF) offers an effective approach to compressing FC layers, but the vast design space of LRF solutions involves complex trade-offs among FLOPs, memory size, inference time, and accuracy, making the LRF process complex and time-consuming. This paper introduces an end-to-end LRF design space exploration methodology and a specialized design tool for optimizing FC layers on RISC-V processors. Using Tensor Train Decomposition (TTD) offered by TensorFlow T3F library, the proposed work prunes the LRF design space by excluding first, inefficient decomposition shapes and second, solutions with poor inference performance on RISC-V architectures. Compiler optimizations are then applied to enhance custom T3F layer performance, minimizing inference time and boosting computational efficiency. On average, our TT-decomposed layers run 3× faster than IREE and 8× faster than Pluto on the same compressed model. This work provides an efficient solution for deploying DNNs on edge and embedded devices powered by RISC-V architectures.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414344423",
    "type": "article"
  },
  {
    "title": "Optimal Control for Industrial Multi-Component CPS via Path-Encoding-Based Joint Optimization",
    "doi": "https://doi.org/10.1145/3769083",
    "publication_date": "2025-09-22",
    "publication_year": 2025,
    "authors": "Jiawan Wang; W.J Liu; Lei Bu; Xuandong Li",
    "corresponding_authors": "",
    "abstract": "Cyber-physical systems (CPS) have been increasingly deployed in many safety-critical industrial environments, where effective and efficient optimal control synthesis is vital for ensuring reliable system operation. The optimal control problem—aimed at synthesizing an optimal control solution for a given control task—remains a key challenge in CPS, particularly due to the intricate coupling of CPS’s continuous and discrete (hybrid) dynamics. This challenge is further compounded in multi-component industrial systems, where the space of control solutions, including both discrete paths (control mode sequences) and continuous control parameters, is prone to the well-known state explosion problem. In this paper, we propose an efficient path-encoding-based joint optimization method for the optimal control problem in multi-component hybrid systems. Our method jointly encodes paths and control parameters in a structured, integrated space, transforming the control synthesis problem into a well-defined optimization problem that can be efficiently solved by existing derivative-free optimization solvers. To further enhance efficiency, we introduce an optimized local path-encoding strategy, which decomposes the original one-dimensional path space into a multi-dimensional component-wise path space, enabling more effective exploration of paths. This strategy also reduces memory overhead and improves scalability. We implemented our method in a tool called PED, and experimental results show that it efficiently solves the optimal control problem in various complex multi-component hybrid systems. Moreover, the incorporation of our local path-encoding strategy further improves its performance.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414410676",
    "type": "article"
  },
  {
    "title": "ASTRA: A Stochastic Transformer Neural Network Accelerator with Silicon Photonics",
    "doi": "https://doi.org/10.1145/3769092",
    "publication_date": "2025-09-22",
    "publication_year": 2025,
    "authors": "Salma Afifi; Oluwaseun Adewunmi Alo; Ishan Thakkar; Sudeep Pasricha",
    "corresponding_authors": "",
    "abstract": "Transformers have emerged as a dominant architecture in deep learning, demonstrating unparalleled success across a wide range of applications, including natural language processing (NLP), computer vision (CV), and scientific computing. By leveraging the self-attention mechanism, transformers achieve superior performance over traditional models such as recurrent neural networks (RNNs) and convolutional neural networks (CNNs). However, these performance gains come at a cost—high computational complexity and substantial memory requirements, making transformers particularly challenging to deploy efficiently on conventional hardware. To address the increasingly intensive computational demands of attention-based transformers, there is growing interest in developing efficient and high-speed hardware accelerators. Silicon photonics has emerged as a promising alternative to digital electronics, offering high-bandwidth and low-latency computation while improving overall computational and energy efficiency. This work introduces ASTRA, the first optical hardware accelerator that leverages stochastic computing principles for transformer neural networks. ASTRA incorporates novel full-range optical stochastic multipliers and stochastic-analog compute-capable optical-to-electrical transducer units to efficiently handle both static and dynamic tensor computations in attention-based models. Through detailed performance analysis, we demonstrate that ASTRA achieves at least 7.6 × speedup and 1.3 × lower energy consumption compared to state-of-the-art transformer accelerators.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414429435",
    "type": "article"
  },
  {
    "title": "Optimal Split Point Placement for Predictable GPU Wavefront Splitting",
    "doi": "https://doi.org/10.1145/3769118",
    "publication_date": "2025-09-23",
    "publication_year": 2025,
    "authors": "Artem Klashtorny; Mahesh Tripunitara; Hiren Patel",
    "corresponding_authors": "",
    "abstract": "Predictable wavefront splitting (PWS) is an optimization technique for graphics processing units (GPUs) to address the performance and worst-case execution time (WCET) impacts of branch divergence. PWS relies on manual annotation by the GPU programmer; these choices affect the resulting WCET. This work automates this process with two key approaches. First, we formulate the optimal annotation as an integer quadratic programming (IQP) problem such that the solution guarantees the lowest WCET. Second, we show that the problem can be solved with an optimal polynomial-time dynamic programming algorithm that achieves the same solutions as the IQP. We implement our algorithm in a compiler flow for an AMD GPU, and we deploy the annotated executable on a gem5 micro-architectural implementation of the AMD GCN3 GPU. We evaluate our implementation on a benchmark suite provided by AMD and supplement it with an extensive set of synthetic benchmarks. Our evaluation shows that these two approaches are able to reduce the WCET by between 13% and 31% compared to five baseline algorithms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414437046",
    "type": "article"
  },
  {
    "title": "Special Issue on Open Hardware for Embedded System Security and Cryptography",
    "doi": "https://doi.org/10.1145/3747326",
    "publication_date": "2025-09-12",
    "publication_year": 2025,
    "authors": "Michael Tempelmeier; Fabrizio De Santis; Shivam Bhasin; Stefan Mangard",
    "corresponding_authors": "",
    "abstract": "The articles in this special section address embedded systems security and, particularly, security topics that are unique to embedded systems. Embedded computing systems are continuously adopted in a wide range of application areas. These systems are ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414592224",
    "type": "article"
  },
  {
    "title": "An Extensible Thread Throttling Method for Multiple OpenMP Parallel Programs",
    "doi": "https://doi.org/10.1145/3769679",
    "publication_date": "2025-09-30",
    "publication_year": 2025,
    "authors": "Xiaoxuan Luo; Weiwei Lin; Jiachun Li; Fan Chen; Haocheng Zhong; Keqin Li",
    "corresponding_authors": "",
    "abstract": "OpenMP is one of the most popular parallel frameworks in the HPC area. Many researchers have proposed OpenMP thread throttling techniques for searching the optimal configuration of parallelism to improve computational efficiency. However, existing research mainly focuses on the optimal solution and ignores the average performance of the program during the search process. In addition, there are various types of workloads in HPC production environments. The OpenMP configuration needs to be adjusted according to the real-time running status of programs. Otherwise, it may lead to a deviation of the actual improvement in the real-time environment from the theory. In this paper, we propose an OpenMP thread throttling method. The method uses the search results of historical workloads to train the performance vertex prediction model, quickly identifies the approximate range of the optimal number of threads for unknown workloads, and searches in a small range with a neighborhood-sampling-based bidirectional hill-climbing search algorithm. The method improves real-time optimization efficiency in HPC systems with multiple unknown loads. Through experiments, we demonstrate the advantages of our method compared to a variety of commonly used thread throttling methods. With minor differences in the optimal solutions, the average performance and convergence speed of our method during the search can be improved by up to 10.6% and 22.7% compared to the best method.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414626977",
    "type": "article"
  },
  {
    "title": "A Versatile Strategy for Comprehensive Data Collection and Retention in Embedded SoC Memories",
    "doi": "https://doi.org/10.1145/3766550",
    "publication_date": "2025-10-10",
    "publication_year": 2025,
    "authors": "Paolo Bernardi; Giorgio Insinga; M. Battilana; Peter H. Beer; G. Carnevale; M. Coppetta; N. Mautone; Alberto Repele; P. Scaramuzza; Rudolf Ullmann",
    "corresponding_authors": "",
    "abstract": "In modern automotive system-on-chip (SoC) designs, large embedded flash memories have become a standard feature. Since they occupy a significant percentage of the die area, their impact on the SoCs’ overall yield is substantial, making them a critical component in the production process. Embedded memories are then deeply tested to unsure their reliability. The data collected through these tests are fundamental to chip designers and test engineers to iron out their designs and understand the most common failure mechanisms. A common approach for data collection is the generation of bitmaps based on the gathering of individual fail coordinates in a list-based fashion. Other more efficient compaction or compression approaches exist and all these approaches can use dedicated internal memories to store the result of a given test. Unfortunately, all the methods currently found in the literature do not allow diagnostic data retention along multiple tests, requiring constant and time-consuming communications with the external tester, increasing the test cost for the manufacturers. This paper presents an on-chip algorithm to compact and retain diagnostic information from multi-step embedded memories testing. The foundation of this work lies in an efficient shape recognition and encoding algorithm. The collected information is stored in a dedicated nonvolatile on-chip memory. Information about the tests that generated a given set of fault shapes is also encoded in this dedicated diagnostic memory, enabling manufacturers to collect all the diagnostic information at the end of their test flow. Experimental results on over 110 Automotive SoCs made by Infineon TM show that using the proposed approach, 100% of the diagnostic information of devices undergoing a standard automotive-grade test flow is permanently encodable in a limited 24KB diagnostic space while also consistently reducing the total test time of up to 53.8% with respect to traditional list-based approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415028107",
    "type": "article"
  },
  {
    "title": "ACCESS-AV: Adaptive Communication-Computation Codesign for Sustainable Autonomous Vehicle Localization in Smart Factories",
    "doi": "https://doi.org/10.1145/3771770",
    "publication_date": "2025-10-13",
    "publication_year": 2025,
    "authors": "Rajat Bhattacharjya; A. N. Sarkar; Ish Kool; Sabur Baidya; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Autonomous Delivery Vehicles (ADVs) are increasingly used for transporting goods in 5G network-enabled smart factories, with the compute-intensive localization module presenting a significant opportunity for optimization. We propose ACCESS-AV , an energy-efficient Vehicle-to-Infrastructure (V2I) localization framework that leverages existing 5G infrastructure in smart factory environments. By opportunistically accessing the periodically broadcast 5G Synchronization Signal Blocks (SSBs) for localization, ACCESS-AV obviates the need for dedicated Roadside Units (RSUs) or additional onboard sensors to achieve energy efficiency as well as cost reduction. We implement an Angle-of-Arrival (AoA)-based estimation method using the Multiple Signal Classification (MUSIC) algorithm, optimized for resource-constrained ADV platforms through an adaptive communication-computation strategy that dynamically balances energy consumption with localization accuracy based on environmental conditions such as Signal-to-Noise Ratio (SNR) and vehicle velocity. Experimental results demonstrate that ACCESS-AV achieves an average energy reduction of 43.09% compared to non-adaptive systems employing AoA algorithms such as vanilla MUSIC, ESPRIT, and Root-MUSIC. It maintains sub-30 cm localization accuracy while also delivering substantial reductions in infrastructure and operational costs, establishing its viability for sustainable smart factory environments.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415104385",
    "type": "article"
  },
  {
    "title": "Near-Optimal Cache Sharing through Co-Located Parallel Scheduling of Threads",
    "doi": "https://doi.org/10.1145/3770858",
    "publication_date": "2025-10-14",
    "publication_year": 2025,
    "authors": "Corey Tessler; Venkata P. Modekurthy; Nathan Fisher; Abusayeed Saifullah; Alleyn Murphy",
    "corresponding_authors": "",
    "abstract": "For hard-real time systems, cache memory increases execution time variability, increasing the complexity of timing analysis. As such, cache memory is often treated exclusively as a detractor to schedulability. Cache-aware co-located scheduling aims to improve schedulability by carefully scheduling threads to share cached values. Cache sharing between threads potentially reduces task execution times and increases schedulability with fewer resources. Antithetically, co-located scheduling may reduce parallelism, decreasing efficiency. Thus, identifying the optimal set of threads to co-locate that minimizes the resources required while ensuring timing constraints is a complex challenge. This work establishes optimal co-location as NP-Hard in the strong sense. It offers an approximation method for the co-located scheduling of Fork-Join tasks named 3-parm-hd. The approximation has a 3-factor guarantee and a resource augmentation bound of 3. The simulated evaluation shows 3-parm-hd increases schedulability compared to an optimal intractable algorithm (without co-location) scheduling 28% more tasks with 30% fewer cores. Simulated results show 3-parm-hd outperforms a 2-factor approximation for traditional makespan, scheduling 45 % more tasks with 41% fewer cores. An experimental RISC-V evaluation running on a QEMU platform confirms the benefits of 3-parm-hd, scheduling and executing tasks deemed unschedulable by a 2-factor makespan approximation without co-location.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415148288",
    "type": "article"
  },
  {
    "title": "SIMD-CP: SIMD with Redundant Bits Compression and Mixed-Precision Packing for Quantized DNNs",
    "doi": "https://doi.org/10.1145/3771939",
    "publication_date": "2025-10-15",
    "publication_year": 2025,
    "authors": "Hayata Kaneko; Ryuto Ishibashi; Lin Meng",
    "corresponding_authors": "",
    "abstract": "Deploying deep neural networks (DNNs) on edge devices presents notable challenges, including execution time, power consumption, and memory footprint. To address these limitations, the co-design of software-based model compression techniques and dedicated hardware has become crucial for the efficient deployment of DNNs on edge devices. However, the hardware needs to support various model compression techniques, and specific compression formats introduce limitations to the effective use of the conventional SIMD, such as low-bit-width precision, fine-grained mixed precision, and sparse matrices. To overcome these issues, we propose SIMD-CP, a SIMD architecture featuring tag-based precision detection and redundant bit-width compression, which is represented as compression packing. Specifically, we introduce two novel SIMD instructions: (i) a tagged vector load instruction ( tvl ), which fetches quantized vectors from memory while appending bit-width metadata as tags, and (ii) a packing dot-product instruction ( pdotp ), which detects the precision levels of elements and packs them into suitable multipliers. Experimental evaluations show that our approach achieves a 2.0 × MAC/cycle gain on both fine-grained mixed-precision and sparse-matrix formats by a series of instructions, i.e., tvl and pdotp . Furthermore, SIMD-CP obtains a 2.70 ∼ 3.40 × GOPs/W and a 2.31 ∼ 2.42 × OPs/LUT improvement for mixed-precision convolution, outperforming the cutting-edge mixed-precision SIMD. These diverse model compression supports allow 28.8 \\(\\sim 45.5\\% \\) latency reduction for DNN applications, including tiny CNN and edge-aware Vision Transformer, with mitigating accuracy degradation within 1.2 \\(\\sim 2.1\\% \\) . We also provide the scaling of the SIMD-CP architecture, resulting in a 1.8 \\(\\% \\) LUT utilization increase in the small-scale compared with the conventional mixed-precision SIMD.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415207016",
    "type": "article"
  },
  {
    "title": "Dual-Mode Rounding Algorithms and Hardware for Posit-Based DNN Training: The Future of Mixed Precision Frameworks",
    "doi": "https://doi.org/10.1145/3772092",
    "publication_date": "2025-10-17",
    "publication_year": 2025,
    "authors": "Vishesh Mishra; Mahendra Rathor; Urbi Chatterjee",
    "corresponding_authors": "",
    "abstract": "The Posit number system provides a promising alternative to traditional floating-point (FP) formats for deep neural network (DNN) training by offering tapered precision and a wide dynamic range, addressing key limitations of conventional FP formats. While recent research has demonstrated the advantages of Posit-enabled training and inference for fixed-precision applications, the development of mixed-precision frameworks has been hindered by the absence of rounding algorithms for transitioning between Posit formats. This dependency has limited the practical adoption of Posits in DNN workflows. In this paper, we present a Posit-based Mixed Precision Training and Inference (PMP) framework, leveraging Posit32, Posit16, and Posit8 for distinct computational stages. Posit32 ensures numerical stability in critical operations, Posit16 balances precision and efficiency for intermediate computations, and Posit8 significantly reduces memory usage during inference. Specifically, we introduce algorithms for converting Posit32 representations into Posit16 and Posit8 , and vice versa, under two rounding modes: deterministic and stochastic. Stochastic rounding is employed to mitigate precision loss in low-precision arithmetic. Furthermore, we propose a hardware-efficient Posit Multiply-Accumulate (pMAC) Unit that integrates deterministic and stochastic rounding modules, enabling efficient mixed-precision computations. We validate our framework on ResNet-18, ResNet-50, ResNet-152, MobileNet-v2, VGG-16, and EfficientNet-B7 (trained on ImageNet), YOLOv2 (trained on PASCAL VOC 2012), and BERT (trained on WikiText-2). Experimental results demonstrate up to 1.5 × training speedup with Posit16 -based PMP framework and up to 16.5 × training speedup with Posit8 -based PMP framework when compared with fixed-precision FP32 training, while maintaining comparable or superior accuracy. Moreover, hardware results show that the design overhead of integrating proposed deterministic and stochastic rounding modules with the pMAC unit is estimated to be around 4.6% only.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415300750",
    "type": "article"
  },
  {
    "title": "<i>c2mec</i> : Cooperative Multi-split and Multi-hop Edge Computing Based on Deep Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3772281",
    "publication_date": "2025-10-18",
    "publication_year": 2025,
    "authors": "Xiaojie Zhang; Peng Wang; Shima Yousefi; Saptarshi Debroy; Keqin Li",
    "corresponding_authors": "",
    "abstract": "Recent research highlights a critical gap between the computing capabilities of modern IoT devices and the computational demands of Artificial Intelligent (AI) applications. The edge computing paradigm offers a promising solution by providing reliable and fast computing services close to the data source. Due to their inherent resource constraints, a single edge server often cannot handle the heavy computational load from nearby IoT devices, requiring multi-server collaboration. However, achieving efficient cooperation is challenging due to dynamic workload fluctuations and uneven data distribution. To address these issues, this paper presents a novel solution that involves optimizing task execution paths and resource management to enhance the performance of edge servers, particularly in scenarios with unbalanced data or uneven distribution of IoT devices. Our approach not only deploys multiple edge servers, but also focuses on the intelligent allocation and management of computing tasks. Specifically, we propose c2mec , a cooperative multi-split and multi-hop edge computing framework. The proposed c2mec framework uses problem decomposition to efficiently decouple the variables that need to be optimized. In addition, c2mec employs a multi-agent Deep Reinforcement Learning (DRL) based algorithm to mitigate the negative impact of decoupling and provides a flexible data splitting strategy. Finally, c2mec designs an energy-aware training method for IoT devices to reduce their long-term training cost. Through our comprehensive experimental results, we demonstrate how c2mec achieves notable improvement in energy saving across different scenarios compared to existing solutions, such as full and partial task offloading.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415323034",
    "type": "article"
  },
  {
    "title": "Processor-memory coexploration using an architecture description language",
    "doi": "https://doi.org/10.1145/972627.972634",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Prabhat Mishra; Mahesh Mamidipaka; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Memory represents a major bottleneck in modern embedded systems in terms of cost, power, and performance. Traditionally, memory organizations for programmable embedded systems assume a fixed cache hierarchy. With the widening processor--memory gap, more aggressive memory technologies and organizations have appeared, allowing customization of a heterogeneous memory architecture tuned for specific target applications. However, such a processor--memory coexploration approach critically needs the ability to explicitly capture heterogeneous memory architectures. We present in this paper a language-based approach to explicitly capture the memory subsystem configuration, generate a memory-aware software toolkit, and perform coexploration of the processor--memory architectures. We present a set of experiments using our memory-aware architectural description language (ADL) to drive the exploration of the memory subsystem for the TI C6211 processor architecture, demonstrating cost, performance, and energy trade-offs.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2145484885",
    "type": "article"
  },
  {
    "title": "Compiler-directed high-level energy estimation and optimization",
    "doi": "https://doi.org/10.1145/1113830.1113835",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "I. Kadayif; Mahmut Kandemir; Gong Chen; N. Vijaykrishnan; M.J. Irwin; Anand Sivasubramaniam",
    "corresponding_authors": "",
    "abstract": "The demand for high-performance architectures and powerful battery-operated mobile devices has accentuated the need for power optimization. While many power-oriented hardware optimization techniques have been proposed and incorporated in current systems, the increasingly critical power constraints have made it essential to look for software-level optimizations as well. The compiler can play a pivotal role in addressing the power constraints of a system as it wields a significant influence on the application's runtime behavior. This paper presents a novel Energy-Aware Compilation (EAC) framework that estimates and optimizes energy consumption of a given code, taking as input the architectural and technological parameters, energy models, and energy/performance/code size constraints. The framework has been validated using a cycle-accurate architectural-level energy simulator and found to be within 6% error margin while providing significant estimation speedup. The estimation speed of EAC is the key to the number of optimization alternatives that can be explored within a reasonable compilation time. As shown in this paper, EAC allows compiler writers and system designers to investigate power-performance tradeoffs of traditional compiler optimizations and to develop energy-conscious high-level code transformations.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2024507540",
    "type": "article"
  },
  {
    "title": "Dynamic coalescing for 16-bit instructions",
    "doi": "https://doi.org/10.1145/1053271.1053273",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Arvind Krishnaswamy; Rajiv Gupta",
    "corresponding_authors": "",
    "abstract": "In the embedded domain, memory usage and energy consumption are critical constraints.Embedded processors such as the ARM and MIPS provide a 16-bit instruction set, (called Thumb in the case of the ARM family of processors), in addition to the 32-bit instruction set to address these concerns. Using 16-bit instructions one can achieve code size reduction and instruction cache energy savings at the cost of performance. This paper presents a novel approach that enhances the performance of 16-bit Thumb code. We have observed that throughout Thumb code there exist Thumb instruction pairs that are equivalent to a single ARM instruction. We have developed enhancements to the processor microarchitecture and the Thumb instruction set to exploit this property. We enhance the Thumb instruction set by incorporating Augmenting eXtensions (AX). A Thumb instruction pair that can be combined into a single ARM instruction is replaced by an AXThumb instruction pair by the compiler. The AX instruction is coalesced with the immediately following Thumb instruction to generate a single ARM instruction at decode time. The enhanced microarchitecture ensures that coalescing does not introduce pipeline delays or increase cycle time thereby resulting in reduction of both instruction counts and cycle counts. Using AX instructions and coalescing hardware we are also able to support efficient predicated execution in 16-bit mode.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2171175484",
    "type": "article"
  },
  {
    "title": "Dual Flow Nets",
    "doi": "https://doi.org/10.1145/1132357.1132360",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "Mauricio Varea; Bashir M. Al‐Hashimi; Luis Alejandro Cortés; Petru Eles; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "This paper addresses the interrelation between control and data flow in embedded system models through a new design representation, called Dual Flow Net (DFN). A modeling formalism with a very close-fitting control and data flow is achieved by this representation, as a consequence of enhancing its underlying Petri net structure. The work presented in this paper does not only tackle the modeling side in embedded systems design, but also the validation of embedded system models through formal methods. Various introductory examples illustrate the applicability of the DFN principles, whereas the capability of the model to with complex designs is demonstrated through the design and verification of a real-life Ethernet coprocessor.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1989291120",
    "type": "article"
  },
  {
    "title": "Shortest-path algorithms for real-time scheduling of FIFO tasks with minimal energy use",
    "doi": "https://doi.org/10.1145/1113830.1113838",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "Bruno Gaujal; Nicolas Navet; Cormac Walsh",
    "corresponding_authors": "",
    "abstract": "We present an algorithm for scheduling a set of nonrecurrent tasks (or jobs) with FIFO real-time constraints so as to minimize the total energy consumed when the tasks are performed on a dynamically variable voltage processor. Our algorithm runs in linear time and thus, in this case, is an improvement over the classical algorithm of Yao et al. It was inspired by considering the problem as a shortest-path problem. We also propose an algorithm to deal with the case where the processor has only a limited number of clock frequencies. This algorithm gives the optimum schedule with the minimum number of speed changes, which is important when the speed switching overhead cannot be neglected. All our algorithms are linear in the number of tasks if the arrivals and deadlines are sorted and otherwise need O ( N log N ) time. These complexities are shown to be the best possible. Finally, we extend our results to fluid tasks and to nonconvex cost functions.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2041182573",
    "type": "article"
  },
  {
    "title": "Code transformation and instruction set extension",
    "doi": "https://doi.org/10.1145/1550987.1550989",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Alastair Murray; Richard Vincent Bennett; Björn Franke; Nigel Topham",
    "corresponding_authors": "",
    "abstract": "The demand for flexible embedded solutions and short time-to-market has led to the development of extensible processors that allow for customization through user-defined instruction set extensions (ISEs). These are usually identified from plain C sources. In this article, we propose a combined exploration of code transformations and ISE identification. The resulting performance of such a combination has been measured on two benchmark suites. Our results demonstrate that combined code transformations and ISEs can yield average performance improvements of 49%. This outperforms ISEs when applied in isolation, and in extreme cases yields a speed-up of 2.85.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2049159104",
    "type": "article"
  },
  {
    "title": "Throughput-driven synthesis of embedded software for pipelined execution on multicore architectures",
    "doi": "https://doi.org/10.1145/1457255.1457258",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Matin Hashemi; Soheil Ghiasi",
    "corresponding_authors": "",
    "abstract": "We present a methodology for pipelined software synthesis of streaming applications. First, we develop a versatile task assignment algorithm capable of optimizing realistically-arbitrary cost functions for two cores. The algorithm is exact (i.e., theoretically optimal) contrary to existing heuristics. Second, our approximation technique provides an adjustable knob to trade solution quality with algorithm runtime and memory. Third, we develop a recursive heuristic for more cores. FPGA-based emulated experiments validate our theoretical results. The exact algorithm yields 1.7 × throughput improvement. The approximation method offers a range of tradeoff points (e.g., 3 × faster with 20 × less memory) while degrading the throughput only 1% to 5%.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2067600201",
    "type": "article"
  },
  {
    "title": "Application development with the FlexWAFE real-time stream processing architecture for FPGAs",
    "doi": "https://doi.org/10.1145/1596532.1596536",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Amilcar do Carmo Lucas; Henning Sahlbach; Sean Whitty; Sven Heithecker; Rolf Ernst",
    "corresponding_authors": "",
    "abstract": "The challenges posed by complex real-time digital image processing at high resolutions cannot be met by current state-of-the-art general-purpose or DSP processors, due to the lack of processing power. On the other hand, large arrays of FPGA-based accelerators are too inefficient to cover the needs of cost sensitive professional markets. We present a new architecture composed of a network of configurable flexible weakly programmable processing elements, Flexible Weakly programmable Advanced Film Engine (FlexWAFE). This architecture delivers both programmability and high efficiency when implemented on an FPGA basis. We demonstrate these claims using a professional next-generation noise reducer with more than 170G image operations/s at 80% FPGA area utilization on four Virtex II-Pro FPGAs. This article will focus on the FlexWAFE architecture principle and implementation on a PCI-Express board.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2074099885",
    "type": "article"
  },
  {
    "title": "A fast scalable automaton-matching accelerator for embedded content processors",
    "doi": "https://doi.org/10.1145/1509288.1509291",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Kuo-Kun Tseng; Yuan‐Cheng Lai; Ying‐Dar Lin; Tsern‐Huei Lee",
    "corresponding_authors": "",
    "abstract": "Home and office network gateways often employ a cost-effective embedded network processor to handle their network services. Such network gateways have received strong demand for applications dealing with intrusion detection, keyword blocking, antivirus and antispam. Accordingly, we were motivated to propose an appropriate fast scalable automaton-matching (FSAM) hardware to accelerate the embedded network processors. Although automaton matching algorithms are robust with deterministic matching time, there is still plenty of room for improving their average-case performance. FSAM employs novel prehash and root-index techniques to accelerate the matching for the nonroot states and the root state, respectively, in automation based hardware. The prehash approach uses some hashing functions to pretest the input substring for the nonroot states while the root-index approach handles multiple bytes in one single matching for the root state. Also, FSAM is applied in a prevalent automaton algorithm, Aho-Corasick (AC), which is often used in many content-filtering applications. When implemented in FPGA, FSAM can perform at the rate of 11.1Gbps with the pattern set of 32,634 bytes, demonstrating that our proposed approach can use a small logic circuit to achieve a competitive performance, although a larger memory is used. Furthermore, the amount of patterns in FSAM is not limited by the amount of internal circuits and memories. If the high-speed external memories are employed, FSAM can support up to 21,302 patterns while maintaining similar high performance.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2132845419",
    "type": "article"
  },
  {
    "title": "Reliability through redundant parallelism for micro-satellite computing",
    "doi": "https://doi.org/10.1145/1698772.1698784",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Ian McLoughlin; T. Bretschneider",
    "corresponding_authors": "",
    "abstract": "Spacecraft typically employ rare and expensive radiation-tolerant, radiation-hardened, or at least military qualified parts for computational and other mission critical subsystems. Reasons include reliability in the harsh environment of space, and systems compatibility or heritage with previous missions. The overriding reliability concern leads most satellite computing systems to be rather conservative in design, avoiding novel or commercial-off-the-shelf components. This article describes an alternative approach: an FPGA-arbitrated parallel architecture that allows unqualified commercial devices to be incorporated into a computational device with aggregate reliability figures similar to those of traditional space-qualified alternatives. Apart from the obvious cost benefits in moving to commercial-off-the-shelf devices, these are attractive in situations where lower power consumption and/or higher processing performance are required. The latter argument is particularly of major importance at a time when the gap between required and available processing capability in satellites is widening. An analysis compares the proposed architecture to typical alternatives, maintaining risk of failure to within required levels, and discusses key applications for the parallel architecture.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2022950246",
    "type": "article"
  },
  {
    "title": "Sysfier",
    "doi": "https://doi.org/10.1145/1880050.1880055",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Niloofar Razavi; Razieh Behjati; Hamideh Sabouri; Ehsan Khamespanah; Amin Shali; Marjan Sirjani",
    "corresponding_authors": "",
    "abstract": "SystemC is a system-level modeling language that can be used effectively for hardware/software co-design. Since a major goal of SystemC is to enable verification at higher levels of abstraction, the tendency is now directing to introducing formal verification approaches for SystemC. In this article, we propose an approach for formal verification of SystemC designs, and provide the semantics of SystemC using Labeled Transition Systems (LTS) for this purpose. An actor-based language, Rebeca, is used as an intermediate language. SystemC designs are mapped to Rebeca models and then Rebeca verification toolset is used to verify LTL and CTL properties. To tackle the state-space explosion, Rebeca model checkers offer some reduction policies that make them appropriate for SystemC verification. The approach also benefits from the modular verification and program slicing techniques applied on Rebeca models. To show the applicability of our approach, we verified a single-cycle MIPS design and two hardware/software co-designs. The results show that our approach can effectively be used both in hardware and hardware/software co-verification.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2120872535",
    "type": "article"
  },
  {
    "title": "Formal specification and analysis of zeroconf using uppaalS",
    "doi": "https://doi.org/10.1145/1952522.1952527",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Jasper Berendsen; Biniam Gebremichael; Frits Vaandrager; Miaomiao Zhang",
    "corresponding_authors": "",
    "abstract": "The model checker Uppaal is used to formally model and analyze parts of Zeroconf, a protocol for dynamic configuration of IPv4 link-local addresses that has been defined in RFC 3927 of the IETF. Our goal has been to construct a model that (a) is easy to understand by engineers, (b) comes as close as possible to the informal text (for each transition in the model there should be a corresponding piece of text in the RFC), and (c) may serve as a basis for formal verification. Our modeling efforts revealed several errors (or at least ambiguities) in the RFC that no one else spotted before. We present two proofs of the mutual exclusion property for Zeroconf (for an arbitrary number of hosts and IP addresses): a manual, operational proof, and a proof that combines model checking with the application of a new abstraction relation that is compositional with respect to committed locations. The model checking problem has been solved using Uppaal and the abstractions have been checked by hand.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2125436868",
    "type": "article"
  },
  {
    "title": "Momentum",
    "doi": "https://doi.org/10.1145/3281300",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Domenico Balsamo; Benjamin J. Fletcher; Alex S. Weddell; Giorgos Karatziolas; Bashir M. Al‐Hashimi; Geoff V. Merrett",
    "corresponding_authors": "",
    "abstract": "Recent research has looked to supplement or even replace the batteries in embedded computing systems with energy harvesting, where energy is derived from the device’s environment. However, such supplies are generally unpredictable and highly variable, and hence systems typically incorporate large external energy buffers (e.g., supercapacitors) to sustain computation; however, these pose environmental issues and increase system size and cost. This article proposes Momentum , a general power-neutral methodology, with intrinsic system-wide maximum power point tracking, that can be applied to a wide range of different computing systems, where the system dynamically scales its performance (and hence power consumption) to optimize computational progress depending on the power availability. Momentum enables the system to operate around an efficient operating voltage, maximizing forward application execution, without adding any external tracking or control units. This methodology combines at runtime (1) a hierarchical control strategy that utilizes available power management controls (such as dynamic voltage and frequency scaling, and core hot-plugging) to achieve efficient power-neutral operation; (2) a software-based maximum power point tracking scheme (unlike existing approaches, this does not require any additional hardware), which adapts the system power consumption so that it can work at the optimal operating voltage, considering the efficiency of the entire system rather than just the energy harvester; and (3) experimental validation on two different scales of computing system: a low power microcontroller (operating from the already-present 4.7μF decoupling capacitance) and a multi-processor system-on-chip (operating from 15.4mF added capacitance). Experimental results from both a controlled supply and energy harvesting source show that Momentum operates correctly on both platforms and exhibits improvements in forward application execution of up to 11% when compared to existing power-neutral approaches and 46% compared to existing static approaches.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2909920339",
    "type": "article"
  },
  {
    "title": "On the Limitations of Analyzing Worst-Case Dynamic Energy of Processing",
    "doi": "https://doi.org/10.1145/3173042",
    "publication_date": "2018-02-20",
    "publication_year": 2018,
    "authors": "Jeremy Morse; Steve Kerrison; Kerstin Eder",
    "corresponding_authors": "",
    "abstract": "This paper examines dynamic energy consumption caused by data during software execution on deeply embedded microprocessors, which can be significant on some devices. In worst-case energy consumption analysis, energy models are used to find the most costly execution path. Taking each instruction's worst case energy produces a safe but overly pessimistic upper bound. Algorithms for safe and tight bounds would be desirable. We show that finding exact worst-case energy is NP-hard, and that tight bounds cannot be approximated with guaranteed safety. We conclude that any energy model targeting tightness must either sacrifice safety or accept overapproximation proportional to data-dependent energy.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3125838234",
    "type": "article"
  },
  {
    "title": "Predicting the Long-Term Behavior of a Micro-Solar Power System",
    "doi": "https://doi.org/10.1145/2220336.2220347",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Jaein Jeong; David Culler",
    "corresponding_authors": "",
    "abstract": "Micro-solar power system design is challenging because it must address long-term system behavior under highly variable solar energy conditions and consider a large space of design options. Several micro-solar power systems and models have been made, validating particular points in the whole design space. We provide a general architecture of micro-solar power systems---comprising key components and interconnections among the components---and formalize each component in an analytical or empirical model of its behavior. To model the variability of solar energy, we provide three solar radiation models, depending on the degree of information available: an astronomical model for ideal conditions, an obstructed astronomical model for estimating solar radiation under the presence of shadows and obstructions, and a weather-effect model for estimating solar radiation under weather variation. Our solar radiation models are validated with a concrete design, the HydroWatch node, thus achieving small deviation from the long-term measurement. They can be used in combination with other micro-solar system models to improve the utility of the load and estimate the behavior of micro-solar power systems more accurately. Thus, our solar radiation models provide more accurate estimations of solar radiation and close the loop for micro-solar power system modeling.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1965952271",
    "type": "article"
  },
  {
    "title": "Formalization of Measure Theory and Lebesgue Integration for Probabilistic Analysis in HOL",
    "doi": "https://doi.org/10.1145/2406336.2406349",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Tarek Mhamdi; Osman Hasan; Sofiène Tahar",
    "corresponding_authors": "",
    "abstract": "Dynamic systems that exhibit probabilistic behavior represent a large class of man-made systems such as communication networks, air traffic control, and other mission-critical systems. Evaluation of quantitative issues like performance and dependability of these systems is of paramount importance. In this paper, we propose a generalized methodology to formally reason about probabilistic systems within a theorem prover. We present a formalization of measure theory in the HOL theorem prover and use it to formalize basic concepts from the theory of probability. We also use the Lebesgue integration to formalize statistical properties of random variables. To illustrate the practical effectiveness of our methodology, we formally prove classical results from the theories of probability and information and use them in a data compression application in HOL.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2058282107",
    "type": "article"
  },
  {
    "title": "SSI Properties Revisited",
    "doi": "https://doi.org/10.1145/2180887.2180898",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Benoît Boissinot; Philip Brisk; Alain Darte; Fabrice Rastello",
    "corresponding_authors": "",
    "abstract": "The static single information (SSI) form is an extension of the static single assignment (SSA) form, a well-established compiler intermediate representation that has been successfully used for numerous compiler analysis and optimizations. Several interesting results have also been shown for SSI form concerning liveness analysis and the representation of live-ranges of variables, which could make SSI form appealing for just-in-time compilation. Unfortunately, we have uncovered several mistakes in the previous literature on SSI form, which, admittedly, is already quite sparse. This article corrects the mistakes that are most germane to SSI form. We first explain why the two definitions of SSI form proposed in past literature, first by C. S. Ananian, then by J. Singer, are not equivalent. Our main result is then to prove that basic blocks, and thus program points, can be totally ordered so that live-ranges of variables correspond to intervals on a line, a result that holds for both variants of SSI form. In other words, in SSI form, the intersection graph defined by live-ranges is an interval graph, a stronger structural property than for SSA form for which the intersection graph of live-ranges is chordal. Finally, we show how this structure of live-ranges can be used to simplify liveness analysis.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2086814414",
    "type": "article"
  },
  {
    "title": "Reducing Interleaving Semantics Redundancy in Reachability Analysis of Time Petri Nets",
    "doi": "https://doi.org/10.1145/2406336.2406343",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Hanifa Boucheneb; Kamel Barkaoui",
    "corresponding_authors": "",
    "abstract": "The main problem of verification techniques based on exploration of (reachable) state space is the state explosion problem. In timed models, abstract states reached by different interleavings of the same set of transitions are, in general, different and their union is not necessarily an abstract state. To attenuate this state explosion, it would be interesting to reduce the redundancy caused by the interleaving semantics by agglomerating all these abstract states whenever their union is an abstract state. This article considers the time Petri net model and establishes some sufficient conditions that ensure that this union is an abstract state. In addition, it proposes a procedure to compute this union without computing beforehand intermediate abstract states. Finally, it shows how to use this result to improve the reachability analysis.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2093320800",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Sensing with the Low Power, Energy Aware Processing (LEAP) Architecture",
    "doi": "https://doi.org/10.1145/2220336.2220339",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Dustin McIntire; Thanos Stathopoulos; Sasank Reddy; Thomas Schmidt; William J. Kaiser",
    "corresponding_authors": "",
    "abstract": "A broad range of embedded networked sensing (ENS) applications have appeared for large-scale systems, introducing new requirements leading to new embedded architectures, associated algorithms, and supporting software systems. These new requirements include the need for diverse and complex sensor systems that present demands for energy and computational resources, as well as for broadband communication. To satisfy application demands while maintaining critical support for low-energy operation, a new multiprocessor node hardware and software architecture, Low Power Energy Aware Processing (LEAP), has been developed. In this article, we described the LEAP design approach, in which the system is able to adaptively select the most energy-efficient hardware components matching an application’s needs. The LEAP platform supports highly dynamic requirements in sensing fidelity, computational load, storage media, and network bandwidth. It focuses on episodic operation of each component and considers the energy dissipation for each platform task by integrating fine-grained energy-dissipation monitoring and sophisticated power-control scheduling for all subsystems, including sensors. In addition to the LEAP platform’s unique hardware capabilities, its software architecture has been designed to provide an easy way to use power management interface and a robust, fault-tolerant operating environment and to enable remote upgrade of all software components. LEAP platform capabilities are demonstrated by example implementations, such as a network protocol design and a light source event detection algorithm. Through the use of a distributed node testbed, we demonstrate that by exploiting high energy-efficiency components and enabling proper on-demand scheduling, the LEAP architecture may meet both sensing performance and energy dissipation objectives for a broad class of applications.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2118127938",
    "type": "article"
  },
  {
    "title": "Half-Wits",
    "doi": "https://doi.org/10.1145/2465787.2465793",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Mastooreh Salajegheh; Yue Wang; Anxiao Jiang; Erik Learned-Miller; Kevin Fu",
    "corresponding_authors": "",
    "abstract": "This work analyzes the stochastic behavior of writing to embedded flash memory at voltages lower than recommended by a microcontroller’s specifications in order to reduce energy consumption. Flash memory integrated within a microcontroller typically requires the entire chip to operate on a common supply voltage almost twice as much as what the CPU portion requires. Our software approach allows the flash memory to tolerate a lower supply voltage so that the CPU may operate in a more energy-efficient manner. Energy-efficient coding algorithms then cope with flash memory writes that behave unpredictably. Our software-only coding algorithms ( in-place writes, multiple-place writes, RS-Berger codes , and slow writes ) enable reliable storage at low voltages on unmodified hardware by exploiting the electrically cumulative nature of half-written data in write-once bits. For a sensor monitoring application using the MSP430, coding with in-place writes reduces the overall energy consumption by 34%. In-place writes are competitive when the time spent on low-voltage operations such as computation are at least four times greater than the time spent on writes to flash memory. Our evaluation shows that tightly maintaining the digital abstraction for storage in embedded flash memory comes at a significant cost to energy consumption with minimal gain in reliability. We find our techniques most effective for embedded workloads that have significant duty cycling, rare writes, or energy harvesting.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2166098313",
    "type": "article"
  },
  {
    "title": "Exploiting Multiple Write Modes of Nonvolatile Main Memory in Embedded Systems",
    "doi": "https://doi.org/10.1145/3063130",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Pan Chen; Mimi Xie; Chengmo Yang; Yiran Chen; Jingtong Hu",
    "corresponding_authors": "",
    "abstract": "Existing Nonvolatile Memories (NVMs) have many attractive features to be the main memory of embedded systems. These features include low power, high density, and better scalability. Recently, Multilevel Cell (MLC) NVM has gained more and more popularity as it can provide a higher density than the traditional Single-Level Cell (SLC) NVM. However, there are also drawbacks in MLC NVM, namely, limited write endurance and expensive write operation. These two drawbacks have to be overcome before MLC NVM can be practically adopted as the main memory. In MLC Nonvolatile Main Memory (NVMM), two different types of write operations with very diverse data retention times are allowed. The first type maintains data for years but takes a longer time to write and is detrimental to the endurance. The second type maintains data for a short period but takes a shorter time to write. By observing that much of the data written to main memory is temporary and does not need to last long during the execution of a program, in this article, we propose novel task scheduling and write operation selection algorithms to improve MLC NVMM endurance and program efficiency. An Integer Linear Programming (ILP) formulation is first proposed to obtain optimal results. Since ILP takes exponential time to solve, we also propose the Multiwrite Mode-Aware Scheduling (MMAS) algorithm to achieve a near-optimal solution in polynomial time. Additionally, the Dynamical Memory Block Screening (DMS) algorithm is proposed to achieve wear leveling. The experimental results demonstrate that the proposed techniques can greatly improve the lifetime of the MLC NVMM as well as the efficiency of the program.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2613457965",
    "type": "article"
  },
  {
    "title": "Online Scheduling of 2-Re-entrant Flexible Manufacturing Systems",
    "doi": "https://doi.org/10.1145/3126551",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Joost van Pinxten; Umar Waqas; Marc Geilen; Twan Basten; Lou Somers",
    "corresponding_authors": "",
    "abstract": "Online scheduling of operations is essential to optimize productivity of flexible manufacturing systems (FMSs) where manufacturing requests arrive on the fly. An FMS processes products according to a particular flow through processing stations. This work focusses on online scheduling of re-entrant FMSs with flows using processing stations where products pass twice and with limited buffering between processing stations. This kind of FMS is modelled as a re-entrant flow shop with due dates and sequence-dependent set-up times. Such flow shops can benefit from minimization of the time penalties incurred from set-up times. On top of an existing greedy scheduling heuristic we apply a meta-heuristic that simultaneously explores several alternatives considering trade-offs between the used metrics by the scheduling heuristic. We identify invariants to efficiently remove many infeasible scheduling options so that the running time of online implementations is improved. The resulting algorithm is much faster than the state of the art and produces schedules with on average 4.6% shorter makespan.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2748291113",
    "type": "article"
  },
  {
    "title": "Effective Verification for Low-Level Software with Competing Interrupts",
    "doi": "https://doi.org/10.1145/3147432",
    "publication_date": "2017-12-07",
    "publication_year": 2017,
    "authors": "Lihao Liang; Tom Melham; Daniel Kroening; Peter Schrammel; Michael Tautschnig",
    "corresponding_authors": "",
    "abstract": "Interrupt-driven software is difficult to test and debug, especially when interrupts can be nested and subject to priorities. Interrupts can arrive at arbitrary times, leading to an exponential blow-up in the number of cases to consider. We present a new formal approach to verifying interrupt-driven software based on symbolic execution. The approach leverages recent advances in the encoding of the execution traces of interacting, concurrent threads. We assess the performance of our method on benchmarks drawn from embedded systems code and device drivers, and experimentally compare it to conventional approaches that use source-to-source transformations. Our results show that our method significantly outperforms these techniques. To the best of our knowledge, our work is the first to demonstrate effective verification of low-level embedded software with nested interrupts.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2751325934",
    "type": "article"
  },
  {
    "title": "Packet Aggregation Real-Time Scheduling for Large-Scale WIA-PA Industrial Wireless Sensor Networks",
    "doi": "https://doi.org/10.1145/3266228",
    "publication_date": "2018-09-17",
    "publication_year": 2018,
    "authors": "Xi Jin; Nan Guan; Changqing Xia; Jintao Wang; Peng Zeng",
    "corresponding_authors": "",
    "abstract": "The IEC standard WIA-PA is a communication protocol for industrial wireless sensor networks. Its special features, including a hierarchical topology, hybrid centralized-distributed management and packet aggregation make it suitable for large-scale industrial wireless sensor networks. Industrial systems place large real-time requirements on wireless sensor networks. However, the WIA-PA standard does not specify the transmission methods, which are vital to the real-time performance of wireless networks, and little work has been done to address this problem. In this article, we propose a real-time aggregation scheduling method for WIA-PA networks. First, to satisfy the real-time constraints on dataflows, we propose a method that combines the real-time theory with the classical bin-packing method to aggregate original packets into the minimum number of aggregated packets. The simulation results indicate that our method outperforms the traditional bin-packing method, aggregating up to 35% fewer packets, and improves the real-time performance by up to 10%. Second, to make it possible to solve the scheduling problem of WIA-PA networks using the classical scheduling algorithms, we transform the ragged time slots of WIA-PA networks to a universal model. In the simulation, a large number of WIA-PA networks are randomly generated to evaluate the performances of several real-time scheduling algorithms. By comparing the results, we obtain that the earliest deadline first real-time scheduling algorithm is the preferred method for WIA-PA networks.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2891322481",
    "type": "article"
  },
  {
    "title": "Robust Reachable Set",
    "doi": "https://doi.org/10.1145/3358229",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "B. K. Ghosh; Parasara Sridhar Duggirala",
    "corresponding_authors": "",
    "abstract": "Reachable set computation is one of the primary techniques for safety verification of linear dynamical systems. In reality the underlying dynamics have uncertainties like parameter variations or modeling uncertainties. Therefore, the reachable set computation must consider the uncertainties in the dynamics to be useful i.e . the computed reachable set should be over or under approximation if not exact. This paper presents a technique to compute reachable set of linear dynamical systems with uncertainties. First, we introduce a construct called support of a matrix. Using this construct, we present a set of sufficient conditions for which reachable set for uncertain linear system can be computed efficiently; and safety verification can be performed using bi-linear programming. Finally, given a linear dynamical system, we compute robust reachable set, which accounts for all possible uncertainties that can be handled by the sufficient conditions presented. Experimental evaluation on benchmarks reveal that our algorithm is computationally very efficient.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2979419513",
    "type": "article"
  },
  {
    "title": "Generalized Weakly Hard Schedulability Analysis for Real-Time Periodic Tasks",
    "doi": "https://doi.org/10.1145/3404888",
    "publication_date": "2020-12-07",
    "publication_year": 2020,
    "authors": "P Pazzaglia; Youcheng Sun; Marco Di Natale",
    "corresponding_authors": "",
    "abstract": "The weakly hard real-time model is an abstraction for applications, including control systems, that can tolerate occasional deadline misses, but can also be compromised if a sufficiently high number of late terminations occur in a given time window. The weakly hard model allows us to constrain the maximum number of acceptable missed deadlines in any set of consecutive task executions. A big challenge for weakly hard systems is to provide a schedulability analysis that applies to a general task model, while avoiding excessive pessimism. In this work, we develop a general weakly hard analysis based on a Mixed Integer Linear Programming (MILP) formulation. The analysis applies to constrained-deadline periodic real-time systems scheduled with fixed priority and no knowledge of the task activation offsets, while allowing for activation jitter. Our analysis considers two common policies for handling missed deadlines, i.e., (i) letting the job continue until completion or (ii) killing its execution immediately. For this policy, ours is the first and only m-k analysis currently available. Experiments conducted on randomly generated task sets show the applicability and accuracy of the proposed technique as well as the improvements with respect to competing techniques.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3037451871",
    "type": "article"
  },
  {
    "title": "Demystifying Energy Consumption Dynamics in Transiently powered Computers",
    "doi": "https://doi.org/10.1145/3391893",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Saad Ahmed; Muhammad Nawaz; Abu Bakar; Naveed Anwar Bhatti; Muhammad Hamad Alizai; Junaid Haroon Siddiqui; Luca Mottola",
    "corresponding_authors": "",
    "abstract": "Transiently powered computers (TPCs) form the foundation of the battery-less Internet of Things, using energy harvesting and small capacitors to power their operation. This kind of power supply is characterized by extreme variations in supply voltage, as capacitors charge when harvesting energy and discharge when computing. We experimentally find that these variations cause marked fluctuations in clock speed and power consumption . Such a deceptively minor observation is overlooked in existing literature. Systems are thus designed and parameterized in overly conservative ways, missing on a number of optimizations. We rather demonstrate that it is possible to accurately model and concretely capitalize on these fluctuations. We derive an energy model as a function of supply voltage and prove its use in two settings. First, we develop EPIC, a compile-time energy analysis tool. We use it to substitute for the constant power assumption in existing analysis techniques, giving programmers accurate information on worst-case energy consumption of programs. When using EPIC with existing TPC system support, run-time energy efficiency drastically improves, eventually leading up to a 350% speedup in the time to complete a fixed workload. Further, when using EPIC with existing debugging tools, it avoids unnecessary program changes that hurt energy efficiency. Next, we extend the MSPsim emulator and explore its use in parameterizing a different TPC system support. The improvements in energy efficiency yield up to more than 1000% time speedup to complete a fixed workload.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3094538580",
    "type": "article"
  },
  {
    "title": "A TCAM-based Caching Architecture Framework for Packet Classification",
    "doi": "https://doi.org/10.1145/3409109",
    "publication_date": "2020-12-07",
    "publication_year": 2020,
    "authors": "Vegesna S. M. Srinivasavarma; Shiv Vidhyut; Noor Mahammad Sk",
    "corresponding_authors": "",
    "abstract": "Packet Classification is the enabling function for performing many networking applications like Integrated Services, Differentiated Services, Access Control/Firewalls, and Intrusion Detection. To cope with high-speed links and ever-increasing bandwidth requirements, time-efficient solutions are needed for which Ternary Content Addressable Memories (TCAMs) are popularly used. However, high cost, heavy power consumption, and poor scalability limit their use in many commercial switches. In this work, an efficient framework for caching the packet classification rules on TCAMs in accordance with traffic characteristics is proposed. The proposed design will have a two-level classification engine in which level-1 is a TCAM classifier with a smaller rule capacity and level-2 is a software classifier. The classifiers are assisted by a rule update engine that monitors the rule temporal behavior and performs timely updates of the rules onto level-1. Crucial challenges with respect to the proposed framework design are defined and addressed effectively in this work. Simulation results shows that the architecture can achieve a throughput of 250 Gbps on average by caching only 10% of the total rules for rule databases of sizes 10,000. The proposed architecture, to the best of our knowledge, is the only traffic-aware architecture using TCAMs that provides a completely deployable framework and also can scale for speeds beyond 250 Gbps (OC-1920 and beyond).",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3112898938",
    "type": "article"
  },
  {
    "title": "Task scheduling",
    "doi": "https://doi.org/10.1145/2560015",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Martina Maggio; Federico Terraneo; Alberto Leva",
    "corresponding_authors": "",
    "abstract": "This article presents a new approach to the design of task scheduling algorithms, where system-theoretical methodologies are used throughout. The proposal implies a significant perspective shift with respect to mainstream design practices, but yields large payoffs in terms of simplicity, flexibility, solution uniformity for different problems, and possibility to formally assess the results also in the presence of unpredictable run-time situations. A complete implementation example is illustrated, together with various comparative tests, and a methodological treatise of the matter.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1973907900",
    "type": "article"
  },
  {
    "title": "Enhancing Design Space Exploration by Extending CPU/GPU Specifications onto FPGAs",
    "doi": "https://doi.org/10.1145/2656207",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Muhsen Owaida; Gabriel Falcão; João Andrade; Christos D. Antonopoulos; Nikolaos Bellas; Madhura Purnaprajna; David Novo; Georgios Karakonstantis; Andreas Burg; Paolo Ienne",
    "corresponding_authors": "",
    "abstract": "The design cycle for complex special-purpose computing systems is extremely costly and time-consuming. It involves a multiparametric design space exploration for optimization, followed by design verification. Designers of special purpose VLSI implementations often need to explore parameters, such as optimal bitwidth and data representation, through time-consuming Monte Carlo simulations. A prominent example of this simulation-based exploration process is the design of decoders for error correcting systems, such as the Low-Density Parity-Check (LDPC) codes adopted by modern communication standards, which involves thousands of Monte Carlo runs for each design point. Currently, high-performance computing offers a wide set of acceleration options that range from multicore CPUs to Graphics Processing Units (GPUs) and Field Programmable Gate Arrays (FPGAs). The exploitation of diverse target architectures is typically associated with developing multiple code versions, often using distinct programming paradigms. In this context, we evaluate the concept of retargeting a single OpenCL program to multiple platforms, thereby significantly reducing design time. A single OpenCL-based parallel kernel is used without modifications or code tuning on multicore CPUs, GPUs, and FPGAs. We use SOpenCL (Silicon to OpenCL), a tool that automatically converts OpenCL kernels to RTL in order to introduce FPGAs as a potential platform to efficiently execute simulations coded in OpenCL. We use LDPC decoding simulations as a case study. Experimental results were obtained by testing a variety of regular and irregular LDPC codes that range from short/medium (e.g., 8,000 bit) to long length (e.g., 64,800 bit) DVB-S2 codes. We observe that, depending on the design parameters to be simulated, on the dimension and phase of the design, the GPU or FPGA may suit different purposes more conveniently, thus providing different acceleration factors over conventional multicore CPUs.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1990387811",
    "type": "article"
  },
  {
    "title": "A Design and Analysis Framework for Thermal-Resilient Hard Real-Time Systems",
    "doi": "https://doi.org/10.1145/2632154",
    "publication_date": "2014-07-23",
    "publication_year": 2014,
    "authors": "Pradeep M. Hettiarachchi; Nathan Fisher; Masud Ahmed; Le Yi Wang; Shinan Wang; Weisong Shi",
    "corresponding_authors": "",
    "abstract": "We address the challenge of designing predictable real-time systems in an unpredictable thermal environment where environmental temperature may dynamically change (e.g., implantable medical devices). Towards this challenge, we propose a control-theoretic design methodology that permits a system designer to specify a set of hard real-time performance modes under which the system may operate. The system automatically adjusts the real-time performance mode based on the external thermal stress. We show (via analysis, simulations, and a hardware testbed implementation) that our control design framework is stable and control performance is equivalent to previous real-time thermal approaches, even under dynamic temperature changes. A crucial and novel advantage of our framework over previous real-time control is the ability to guarantee hard deadlines even under transitions between modes. Furthermore, our system design permits the calculation of a new metric called thermal resiliency that characterizes the maximum external thermal stress that any hard real-time performance mode can withstand. Thus, our design framework and analysis may be classified as a thermal stress analysis for real-time systems.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2034164792",
    "type": "article"
  },
  {
    "title": "Elon",
    "doi": "https://doi.org/10.1145/2560017",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Wei Dong; Yunhao Liu; Chun Chen; Lin Gu; Xiaofan Wu",
    "corresponding_authors": "",
    "abstract": "We present a new mechanism called Elon for enabling efficient and long-term reprogramming in wireless sensor networks. Elon reduces the transferred code size significantly by introducing the concept of replaceable component. It avoids the cost of hardware reboot with a novel software reboot mechanism. Moreover, it significantly prolongs the reprogrammable lifetime (i.e., the time period during which the sensor nodes can be reprogrammed) by avoiding flash writes for TelosB nodes. Experimental results show that Elon transfers up to 120--389 times less information than Deluge, and 18--42 times less information than Stream. The software reboot mechanism that Elon applies reduces the rebooting cost by 50.4%--53.87% in terms of beacon packets, and 56.83% in terms of unsynchronized nodes. In addition, Elon prolongs the reprogrammable lifetime by a factor of 3.3.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2049011440",
    "type": "article"
  },
  {
    "title": "Diagnosability under Weak Fairness",
    "doi": "https://doi.org/10.1145/2832910",
    "publication_date": "2015-12-08",
    "publication_year": 2015,
    "authors": "Vasileios Germanos; Stefan Haar; Victor Khomenko; Stefan Schwoon",
    "corresponding_authors": "",
    "abstract": "In partially observed Petri nets, diagnosis is the task of detecting whether the given sequence of observed labels indicates that some unobservable fault has occurred. Diagnosability is an associated property of the Petri net, stating that in any possible execution, an occurrence of a fault can eventually be diagnosed. In this article, we consider diagnosability under the weak fairness (WF) assumption, which intuitively states that no transition from a given set can stay enabled forever—it must eventually either fire or be disabled. We show that a previous approach to WF-diagnosability in the literature has a major flaw and present a corrected notion. Moreover, we present an efficient method for verifying WF-diagnosability based on a reduction to LTL-X model checking. An important advantage of this method is that the LTL-X formula is fixed—in particular, the WF assumption does not have to be expressed as a part of it (which would make the formula length proportional to the size of the specification), but rather the ability of existing model checkers to handle weak fairness directly is exploited.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2208727523",
    "type": "article"
  },
  {
    "title": "Thermal-aware memory mapping in 3D designs",
    "doi": "https://doi.org/10.1145/2512457",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Ang-Chih Hsieh; TingTing Hwang",
    "corresponding_authors": "",
    "abstract": "DRAM is usually used as main memory for program execution. The thermal behavior of a memory block in a 3D SIP is affected not only by the power behavior but also the heat dissipating ability of that block. The power behavior of a block is related to the applications run on the system, while the heat dissipating ability is determined by the number of tier and the position the block locates. Therefore, a thermal-aware memory allocator should consider the following two points. First, the allocator should consider not only the power behavior of a logic block but also the physical location during memory mapping and second, the changing temperature of a physical block during execution of programs. In this article, we will propose a memory mapping algorithm taking into consideration these two points. Our technique can be classified as static thermal management to be applied to embedded software designs. Experiments show that for single-core systems, our method can reduce the temperature of memory system by 17.1°C, as compared to a straightforward mapping in the best case, and 13.3°C on average. For systems with four cores, the temperature reductions are 9.9°C and 11.6°C on average when L1 cache of each core is set to 4KB and 8KB, respectively.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2621025942",
    "type": "article"
  },
  {
    "title": "EncoDeep",
    "doi": "https://doi.org/10.1145/3391901",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Mohammad Samragh; Mojan Javaheripi; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "This article proposes EncoDeep, an end-to-end framework that facilitates encoding, bitwidth customization, fine-tuning, and implementation of neural networks on FPGA platforms. EncoDeep incorporates nonlinear encoding to the computation flow of neural networks to save memory. The encoded features demand significantly lower storage compared to the raw full-precision activation values; therefore, the execution flow of EncoDeep hardware engine is completely performed within the FPGA using on-chip streaming buffers with no access to the off-chip DRAM. We further propose a fully automated optimization algorithm that determines the flexible encoding bitwidths across network layers. EncoDeep full-stack framework comprises a compiler that takes a high-level Python description of an arbitrary neural network. The compiler then instantiates the corresponding elements from EncoDeep Hardware library for FPGA implementation. Our evaluations on MNIST, SVHN, and CIFAR-10 datasets demonstrate an average of 4.65× throughput improvement compared to stand-alone weight encoding. We further compare EncoDeep with six FPGA accelerators on ImageNet, showing an average of 3.6× and 2.54× improvement in throughput and performance-per-watt, respectively.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3041178375",
    "type": "article"
  },
  {
    "title": "FLASH: <u>F</u> ast Neura <u>l</u> <u>A</u> rchitecture <u>S</u> earch with <u>H</u> ardware Optimization",
    "doi": "https://doi.org/10.1145/3476994",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Guihong Li; Sumit K. Mandal; Ümit Y. Ogras; Radu Mărculescu",
    "corresponding_authors": "",
    "abstract": "Neural architecture search (NAS) is a promising technique to design efficient and high-performance deep neural networks (DNNs). As the performance requirements of ML applications grow continuously, the hardware accelerators start playing a central role in DNN design. This trend makes NAS even more complicated and time-consuming for most real applications. This paper proposes FLASH, a very fast NAS methodology that co-optimizes the DNN accuracy and performance on a real hardware platform. As the main theoretical contribution, we first propose the NN-Degree, an analytical metric to quantify the topological characteristics of DNNs with skip connections (e.g., DenseNets, ResNets, Wide-ResNets, and MobileNets). The newly proposed NN-Degree allows us to do training-free NAS within one second and build an accuracy predictor by training as few as 25 samples out of a vast search space with more than 63 billion configurations. Second, by performing inference on the target hardware, we fine-tune and validate our analytical models to estimate the latency, area, and energy consumption of various DNN architectures while executing standard ML datasets. Third, we construct a hierarchical algorithm based on simplicial homology global optimization (SHGO) to optimize the model-architecture co-design process, while considering the area, latency, and energy consumption of the target hardware. We demonstrate that, compared to the state-of-the-art NAS approaches, our proposed hierarchical SHGO-based algorithm enables more than four orders of magnitude speedup (specifically, the execution time of the proposed algorithm is about 0.1 seconds). Finally, our experimental evaluations show that FLASH is easily transferable to different hardware architectures, thus enabling us to do NAS on a Raspberry Pi-3B processor in less than 3 seconds.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3200067639",
    "type": "article"
  },
  {
    "title": "Learning to Train CNNs on Faulty ReRAM-based Manycore Accelerators",
    "doi": "https://doi.org/10.1145/3476986",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Biresh Kumar Joardar; Janardhan Rao Doppa; Hai Li; Krishnendu Chakrabarty; Partha Pratim Pande",
    "corresponding_authors": "",
    "abstract": "The growing popularity of convolutional neural networks (CNNs) has led to the search for efficient computational platforms to accelerate CNN training. Resistive random-access memory (ReRAM)-based manycore architectures offer a promising alternative to commonly used GPU-based platforms for training CNNs. However, due to the immature fabrication process and limited write endurance, ReRAMs suffer from different types of faults. This makes training of CNNs challenging as weights are misrepresented when they are mapped to faulty ReRAM cells. This results in unstable training, leading to unacceptably low accuracy for the trained model. Due to the distributed nature of the mapping of the individual bits of a weight to different ReRAM cells, faulty weights often lead to exploding gradients. This in turn introduces a positive feedback in the training loop, resulting in extremely large and unstable weights. In this paper, we propose a lightweight and reliable CNN training methodology using weight clipping to prevent this phenomenon and enable training even in the presence of many faults. Weight clipping prevents large weights from destabilizing CNN training and provides the backpropagation algorithm with the opportunity to compensate for the weights mapped to faulty cells. The proposed methodology achieves near-GPU accuracy without introducing significant area or performance overheads. Experimental evaluation indicates that weight clipping enables the successful training of CNNs in the presence of faults, while also reducing training time by 4 X on average compared to a conventional GPU platform. Moreover, we also demonstrate that weight clipping outperforms a recently proposed error correction code (ECC)-based method when training is carried out using faulty ReRAMs.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3200875582",
    "type": "article"
  },
  {
    "title": "<i>ASTROLABE</i>",
    "doi": "https://doi.org/10.1145/2885498",
    "publication_date": "2016-03-11",
    "publication_year": 2016,
    "authors": "Ayoub Nouri; Marius Bozga; Anca Molnos; Axel Legay; Saddek Bensalem",
    "corresponding_authors": "",
    "abstract": "Building abstract system-level models that faithfully capture performance and functional behavior for embedded systems design is challenging. Unlike functional aspects, performance details are rarely available during the early design phases, and no clear method is known to characterize them. Moreover, once such models are built, they are inherently complex as they mix software models, hardware constraints, and environment abstractions. Their analysis by using traditional performance evaluation methods is reaching the limit. In this article, we present a systematic approach for building stochastic abstract performance models using statistical inference and model calibration, and we propose statistical model checking as a scalable performance evaluation technique for them.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2314322419",
    "type": "article"
  },
  {
    "title": "Near-Static Shading Exploration for Smart Photovoltaic Module Topologies Based on Snake-like Configurations",
    "doi": "https://doi.org/10.1145/2837026",
    "publication_date": "2016-03-11",
    "publication_year": 2016,
    "authors": "Maria-Iro Baka; Francky Catthoor; Dimitrios Soudris",
    "corresponding_authors": "",
    "abstract": "Variable shading due to clouds and nearby objects has a severe impact on the energy yield of photovoltaic installations. Due to the industry's standard of permanently series-connected cells in a photovoltaic (PV) module, partial shading creates mismatches between the Current-Voltage (I-V) characteristics of cells. This article proposes an alternative configurable intramodule cell interconnection topology whereby cell connections can be adapted during operation to allow an optimized power production. The proposed configurable topology outperforms significantly a conventional 10 × 6 module under heavy shade. Moreover, this is achieved in a quite flexible way and with negligible overhead under uniform irradiation conditions.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2322236836",
    "type": "article"
  },
  {
    "title": "Static Analysis of Runtime Errors in Interrupt-Driven Programs via Sequentialization",
    "doi": "https://doi.org/10.1145/2914789",
    "publication_date": "2016-09-01",
    "publication_year": 2016,
    "authors": "Xueguang Wu; Liqian Chen; Antoine Miné; Wei Dong; Ji Wang",
    "corresponding_authors": "",
    "abstract": "Embedded software often involves intensive numerical computations and suffers from a number of runtime errors. The technique of numerical static analysis is of practical importance for checking the correctness of embedded software. However, most of the existing approaches of numerical static analysis consider sequential programs, while interrupts are a commonly used facility that introduces concurrency in embedded systems. Therefore, a numerical static analysis approach is highly desired for embedded software with interrupts. In this article, we propose a static analysis approach specifically for interrupt-driven programs based on sequentialization techniques. We present a method to sequentialize interrupt-driven programs into nondeterministic sequential programs according to the semantics of interrupts. The key benefit of using sequentialization is the ability to leverage the power of state-of-the-art analysis and verification techniques for sequential programs to analyze interrupt-driven programs, for example, the power of numerical abstract interpretation to analyze numerical properties of the sequentialized programs. Furthermore, to improve the analysis precision and scalability, we design specific abstract domains to analyze sequentialized interrupt-driven programs by considering their specific features. Finally, we present encouraging experimental results obtained by our prototype implementation.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2512664867",
    "type": "article"
  },
  {
    "title": "Frequency-Aware ESL Power Estimation for ARM Cortex-A9 Using a Black Box Processor Model",
    "doi": "https://doi.org/10.1145/2987375",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Stefan Schürmans; Gereon Onnebrink; Rainer Leupers; Gerd Ascheid; Xiaotao Chen",
    "corresponding_authors": "",
    "abstract": "Power estimation has become a strongly desired feature in Electronic System Level (ESL) simulations. Most existing power estimation approaches for this abstraction level require component models with observable internals. However, most ESL models of modern processors are delivered as black box components. This work presents a tool-based ESL power estimation methodology for black box models and its extension for multiple clock frequencies. The evaluation uses hardware measurements of the ARM Cortex-A9 subsystem of the OMAP4460 chip for reference. The achieved estimation error is 5% on average for fixed-frequency power models and 7% for multifrequency power models.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2530055915",
    "type": "article"
  },
  {
    "title": "Microarchitectural Exploration of STT-MRAM Last-level Cache Parameters for Energy-efficient Devices",
    "doi": "https://doi.org/10.1145/3490391",
    "publication_date": "2022-01-14",
    "publication_year": 2022,
    "authors": "Tommaso Marinelli; J.I. Gomez; Christian Tenllado; Manu Perumkunnil; Mohit Gupta; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "As the technology scaling advances, limitations of traditional memories in terms of density and energy become more evident. Modern caches occupy a large part of a CPU physical size and high static leakage poses a limit to the overall efficiency of the systems, including IoT/edge devices. Several alternatives to CMOS SRAM memories have been studied during the past few decades, some of which already represent a viable replacement for different levels of the cache hierarchy. One of the most promising technologies is the spin-transfer torque magnetic RAM (STT-MRAM), due to its small basic cell design, almost absent static current and non-volatility as an added value. However, nothing comes for free, and designers will have to deal with other limitations, such as the higher latencies and dynamic energy consumption for write operations compared to reads. The goal of this work is to explore several microarchitectural parameters that may overcome some of those drawbacks when using STT-MRAM as last-level cache (LLC) in embedded devices. Such parameters include: number of cache banks, number of miss status handling registers (MSHRs) and write buffer entries, presence of hardware prefetchers. We show that an effective tuning of those parameters may virtually remove any performance loss while saving more than 60% of the LLC energy on average. The analysis is then extended comparing the energy results from calibrated technology models with data obtained with freely available tools, highlighting the importance of using accurate models for architectural exploration.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4205436102",
    "type": "article"
  },
  {
    "title": "Toward Adversary-aware Non-iterative Model Pruning through <u>D</u> ynamic <u>N</u> etwork <u>R</u> ewiring of DNNs",
    "doi": "https://doi.org/10.1145/3510833",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Souvik Kundu; Yao Fu; Bill Ye; Peter A. Beerel; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "We present a dynamic network rewiring (DNR) method to generate pruned deep neural network (DNN) models that both are robust against adversarially generated images and maintain high accuracy on clean images. In particular, the disclosed DNR training method is based on a unified constrained optimization formulation using a novel hybrid loss function that merges sparse learning with robust adversarial training. This training strategy dynamically adjusts inter-layer connectivity based on per-layer normalized momentum computed from the hybrid loss function. To further improve the robustness of the pruned models, we propose DNR++, an extension of the DNR method where we introduce the idea of sparse parametric Gaussian noise tensor that is added to the weight tensors to yield robust regularization. In contrast to existing robust pruning frameworks that require multiple training iterations, the proposed DNR and DNR++ achieve an overall target pruning ratio with only a single training iteration and can be tuned to support both irregular and structured channel pruning. To demonstrate the efficacy of the proposed method under the no-increased-training-time “free” adversarial training scenario, we finally present FDNR++, a simple yet effective training modification that can yield robust yet compressed models requiring training time comparable to that of an unpruned non-adversarial training. To evaluate the merits of our disclosed training methods, experiments were performed with two widely accepted models, namely VGG16 and ResNet18, on CIFAR-10 and CIFAR-100 as well as with VGG16 on Tiny-ImageNet. Compared to the baseline uncompressed models, our methods provide over 20× compression on all the datasets without any significant drop of either clean or adversarial classification performance. Moreover, extensive experiments show that our methods consistently find compressed models with better clean and adversarial image classification performance than what is achievable through state-of-the-art alternatives. We provide insightful observations to help make various model, parameter density, and prune-type selection choices and have open-sourced our saved models and test codes to ensure reproducibility of our results.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4210697416",
    "type": "article"
  },
  {
    "title": "Energy-efficient and Reliable Inference in Nonvolatile Memory under Extreme Operating Conditions",
    "doi": "https://doi.org/10.1145/3520130",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Salonik Resch; S. Karen Khatamifard; Zamshed I. Chowdhury; Masoud Zabihi; Zhengyang Zhao; Hüsrev Cılasun; Jianping Wang; Sachin S. Sapatnekar; Ulya R. Karpuzcu",
    "corresponding_authors": "",
    "abstract": "Beyond-edge devices can operate outside the reach of the power grid and without batteries. Such devices can be deployed in large numbers in regions that are difficult to access. Using machine learning, these devices can solve complex problems and relay valuable information back to a host. Many such devices deployed in low Earth orbit can even be used as nanosatellites. Due to the harsh and unpredictable nature of the environment, these devices must be highly energy-efficient, be capable of operating intermittently over a wide temperature range, and be tolerant of radiation. Here, we propose a non-volatile processing-in-memory architecture that is extremely energy-efficient, supports minimal overhead checkpointing for intermittent computing, can operate in a wide range of temperatures, and has a natural resilience to radiation.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4214901847",
    "type": "article"
  },
  {
    "title": "Formally Verified Loop-Invariant Code Motion and Assorted Optimizations",
    "doi": "https://doi.org/10.1145/3529507",
    "publication_date": "2022-04-08",
    "publication_year": 2022,
    "authors": "David Monniaux; Cyril Six",
    "corresponding_authors": "",
    "abstract": "We present an approach for implementing a formally certified loop-invariant code motion optimization by composing an unrolling pass and a formally certified yet efficient global subexpression elimination. This approach is lightweight: each pass comes with a simple and independent proof of correctness. Experiments show the approach significantly narrows the performance gap between the CompCert certified compiler and state-of-the-art optimizing compilers. Our static analysis employs an efficient yet verified hashed set structure, resulting in the fast compilation.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4225671692",
    "type": "article"
  },
  {
    "title": "Synaptic Activity and Hardware Footprint of Spiking Neural Networks in Digital Neuromorphic Systems",
    "doi": "https://doi.org/10.1145/3520133",
    "publication_date": "2022-03-21",
    "publication_year": 2022,
    "authors": "Edgar Lemaire; Benoît Miramond; Sébastien Bilavarn; Hadi Saoud; Nassim Abderrahmane",
    "corresponding_authors": "",
    "abstract": "Spiking neural networks are expected to bring high resources, power, and energy efficiency to machine learning hardware implementations. In this regard, they could facilitate the integration of Artificial Intelligence in highly constrained embedded systems, such as image classification in drones or satellites. If their logic resource efficiency is widely accepted in the literature, their energy efficiency still remains debated. In this article, a novel high-level metric is used to characterize the expected energy efficiency gain when using Spiking Neural Networks (SNN) instead of Formal Neural Networks (FNN) for hardware implementation: Synaptic Activity Ratio (SAR). This metric is applied to a selection of classification tasks including images and 1D signals. Moreover, a high-level estimator for logic resources, power usage, execution time, and energy is introduced for neural network hardware implementations on FPGA, based on four existing accelerator architectures covering both sequential and parallel implementation paradigms for both spiking and formal coding domains. This estimator is used to evaluate the reliability of the Synaptic Activity Ratio metric to characterize spiking neural network energy efficiency gain on the proposed dataset benchmark. This study led to the conclusion that spiking domain offers significant power and energy savings in sequential implementations. This study also shows that synaptic activity is a critical factor that must be taken into account when addressing low-energy systems.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4281728207",
    "type": "article"
  },
  {
    "title": "Reconfigurable System-on-Chip Architectures for Robust Visual SLAM on Humanoid Robots",
    "doi": "https://doi.org/10.1145/3570210",
    "publication_date": "2022-11-09",
    "publication_year": 2022,
    "authors": "Maria Rafaela Gkeka; Alexandros Patras; Nikolaos Tavoularis; Stylianos Piperakis; Emmanouil Hourdakis; Panos Trahanias; Christos D. Antonopoulos; Spyros Lalis; Nikolaos Bellas",
    "corresponding_authors": "",
    "abstract": "Visual Simultaneous Localization and Mapping (vSLAM) is the method of employing an optical sensor to map the robot’s observable surroundings while also identifying the robot’s pose in relation to that map. The accuracy and speed of vSLAM calculations can have a very significant impact on the performance and effectiveness of subsequent tasks that need to be executed by the robot, making it a key building component for current robotic designs. The application of vSLAM in the area of humanoid robotics is particularly difficult due to the robot’s unsteady locomotion. This paper introduces a pose graph optimization module based on RGB (ORB) features, as an extension of the KinectFusion pipeline (a well-known vSLAM algorithm), to assist in recovering the robot’s stance during unstable gait patterns when the KinectFusion tracking system fails. We develop and test a wide range of embedded MPSoC FPGA designs, and we investigate numerous architectural improvements, both precise and approximation, to study their impact on performance and accuracy. Extensive design space exploration reveals that properly designed approximations, which exploit domain knowledge and efficient management of CPU and FPGA fabric resources, enable real-time vSLAM at more than 30 fps in humanoid robots with high energy-efficiency and without compromising robot tracking and map construction. This is the first FPGA design to achieve robust, real-time dense SLAM operation targeting specifically humanoid robots. An open source release of our implementations and data can be found in [ 1 ].",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4308650867",
    "type": "article"
  },
  {
    "title": "Risk of Stochastic Systems for Temporal Logic Specifications",
    "doi": "https://doi.org/10.1145/3580490",
    "publication_date": "2023-01-17",
    "publication_year": 2023,
    "authors": "Lars Lindemann; Lejun Jiang; Nikolai Matni; George J. Pappas",
    "corresponding_authors": "",
    "abstract": "The wide availability of data coupled with the computational advances in artificial intelligence and machine learning promise to enable many future technologies such as autonomous driving. While there has been a variety of successful demonstrations of these technologies, critical system failures have repeatedly been reported. Even if rare, such system failures pose a serious barrier to adoption without a rigorous risk assessment. This article presents a framework for the systematic and rigorous risk verification of systems. We consider a wide range of system specifications formulated in signal temporal logic (STL) and model the system as a stochastic process, permitting discrete-time and continuous-time stochastic processes. We then define the STL robustness risk as the risk of lacking robustness against failure . This definition is motivated as system failures are often caused by missing robustness to modeling errors, system disturbances, and distribution shifts in the underlying data generating process. Within the definition, we permit general classes of risk measures and focus on tail risk measures such as the value-at-risk and the conditional value-at-risk. While the STL robustness risk is in general hard to compute, we propose the approximate STL robustness risk as a more tractable notion that upper bounds the STL robustness risk. We show how the approximate STL robustness risk can accurately be estimated from system trajectory data. For discrete-time stochastic processes, we show under which conditions the approximate STL robustness risk can even be computed exactly. We illustrate our verification algorithm in the autonomous driving simulator CARLA and show how a least risky controller can be selected among four neural network lane-keeping controllers for five meaningful system specifications.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4316813665",
    "type": "article"
  },
  {
    "title": "A proven translation from a UML state machine subset to timed automata",
    "doi": "https://doi.org/10.1145/3581771",
    "publication_date": "2023-01-25",
    "publication_year": 2023,
    "authors": "Florent Peres; Mohamed Ghazel",
    "corresponding_authors": "",
    "abstract": "Although Unified Modeling Language (UML) state machines constitute a convenient modeling formalism that is widely used in many applications, the lack of formal semantics impedes carrying out automatic processing, such as formal verification. In this article, we aim to achieve a proven translation from a subset of UML state machines to timed automata. A generic abstract syntax is defined for state machines that allows us to specify state machines as a tree-like structure, explicitly illustrating the hierarchical relationships within the model. Based on this syntax, a formal asynchronous semantics for state machines and systems of state machines is established. Additionally, the semantics of timed automata is specified. Then, a translation relation from the considered set of state machines to timed automata is defined and a strong equivalence relation — namely, a timed bisimulation between the source and target models — is formally proven. The proof is carried out inductively while considering continuous (time) and discrete transitions separately. This proof allows us to demonstrate a strong similitude between these models.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4318041403",
    "type": "article"
  },
  {
    "title": "Online Processing of Vehicular Data on the Edge Through an Unsupervised TinyML Regression Technique",
    "doi": "https://doi.org/10.1145/3591356",
    "publication_date": "2023-04-08",
    "publication_year": 2023,
    "authors": "Pedro Andrade; Ivanovitch Silva; Marianne Diniz; Thommas Kevin Sales Flores; Daniel G. Costa; Eduardo Soares",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) has made it possible to include everyday objects in a connected network, allowing them to intelligently process data and respond to their environment. Thus, it is expected that those objects will gain an intelligent understanding of their environment and be able to process data more efficiently than before. Particularly, such edge computing paradigm has allowed the execution of inference methods on resource-constrained devices such as microcontrollers, significantly changing the way IoT applications have evolved in recent years. However, although this scenario has supported the development of Tiny Machine Learning (TinyML) approaches on such devices, there are still some challenges that require further investigation when optimizing data streaming on the edge. Therefore, this article proposes a new unsupervised TinyML regression technique based on the typicality and eccentricity of the samples to be processed. Moreover, the proposed technique also exploits a Recursive Least Squares (RLS) filter approach. Combining all these features, the proposed method uses similarities between samples to identify patterns when processing data streams, predicting outcomes based on these patterns. The results obtained through the extensive experimentation utilizing vehicular data streams were highly encouraging. The proposed algorithm was meticulously compared with the RLS algorithm and Convolutional Neural Networks (CNN). It exhibited significantly superior performance, with mean squared errors that were 4.68 and 12.02 times lower, respectively, compared to the aforementioned techniques.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4362720532",
    "type": "article"
  },
  {
    "title": "Multi-criteria Optimization of Real-time DAGs on Heterogeneous Platforms under P-EDF",
    "doi": "https://doi.org/10.1145/3592609",
    "publication_date": "2023-04-13",
    "publication_year": 2023,
    "authors": "Tommaso Cucinotta; Alexandre M. Amory; Gabriele Ara; Francesco Paladino; Marco Di Natale",
    "corresponding_authors": "",
    "abstract": "This article tackles the problem of optimal placement of complex real-time embedded applications on heterogeneous platforms. Applications are composed of directed acyclic graphs of tasks, with each directed-acyclic-graph (DAG) having a minimum inter-arrival period for its activation requests and an end-to-end deadline within which all of the computations need to terminate since each activation. The platforms of interest are heterogeneous power-aware multi-core platforms with Dynamic Voltage and Frequency Scaling (DVFS) capabilities, including big.LITTLE Arm architectures and platforms with GPU or FPGA hardware accelerators with Dynamic Partial Reconfiguration capabilities. Tasks can be deployed on CPUs using partitioned EDF-based scheduling. Additionally, some of the tasks may have an alternate implementation available for one of the accelerators on the target platform, which are assumed to serve requests in non-preemptive FIFO order. The system can be optimized by minimizing power consumption, respecting precise timing constraints, maximizing the applications’ slack, respecting given power consumption constraints, or even a combination of these, in a multi-objective formulation. We propose an off-line optimization of the mentioned problem based on mixed-integer quadratic constraint programming (MIQCP). The optimization provides the DVFS configuration of all the CPUs (or accelerators) capable of frequency switching and the placement to be followed by each task in the DAGs, including the software-vs.-hardware implementation choice for tasks that can be hardware accelerated. For relatively big problems, we developed heuristic solvers capable of providing suboptimal solutions in a significantly reduced time compared to the MIQCP strategy, thus widening the applicability of the proposed framework. We validate the approach by running a set of randomly generated DAGs on Linux under SCHED_DEADLINE, deployed onto two real boards, one with Arm big.LITTLE architecture, the other with FPGA acceleration, verifying that the experimental runs meet the theoretical expectations in terms of timing and power optimization goals.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4365451477",
    "type": "article"
  },
  {
    "title": "HMT: A Hardware-centric Hybrid Bonsai Merkle Tree Algorithm for High-performance Authentication",
    "doi": "https://doi.org/10.1145/3595179",
    "publication_date": "2023-04-28",
    "publication_year": 2023,
    "authors": "Rakin Muhammad Shadab; Yu Zou; Sanjay Gandham; Amro Awad; Mingjie Lin",
    "corresponding_authors": "",
    "abstract": "The Bonsai Merkle tree (BMT) is a widely used tree structure for authentication of metadata such as encryption counters in a secure computing system. Common BMT algorithms were designed for traditional Von Neumann architectures with a software-centric implementation in mind and as such, they are predominantly recursive and sequential in nature. However, the modern heterogeneous computing platforms employing Field-Programmable Gate Array (FPGA) devices require concurrency-focused algorithms to fully utilize the versatility and parallel nature of such systems. The recursive nature of traditional BMT algorithms makes them challenging to implement in such hardware-based setups. Our goal for this work is to introduce HMT, a hardware-friendly BMT algorithm that enables the verification and update processes to function independently and provides the benefits of relaxed update while being comparable to the eager update in terms of update complexity. The methodology of HMT contributes both novel algorithmic revisions and innovative hardware techniques to implementing BMT. We mathematically demonstrate the challenges of potentially unbounded recursions in relaxed BMT updates. To solve this problem, we use a partitioned BMT caching scheme that allocates a separate write-back cache for each BMT level—thus allowing for low and fixed upper bounds for dirty evictions compared to the traditional BMT caches. Then we introduce the aforementioned hybrid BMT algorithm that is hardware-targeted, parallel, and relaxes the update depending on BMT cache hit but makes the update conditions more flexible compared to lazy update to save additional write-backs. Deploying this new algorithm, we have designed a new BMT controller with a dataflow architecture including speculative buffers and parallel write-back engines to facilitate performance-enhancing mechanisms (like multiple concurrent authentication and independent updates) that were not possible with the conventional lazy algorithm. Our empirical performance measurements on a Xilinx U200 accelerator FPGA have demonstrated that HMT can achieve up to 7× improvement in bandwidth and 4.5× reduction in latency over lazy-update BMT baseline and up to 14% faster execution in standard benchmarks compared to a state-of-the-art, eager-update BMT solution.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4367313299",
    "type": "article"
  },
  {
    "title": "Model-Based Diagnosis of Real-Time Systems: Robustness Against Varying Latency, Clock Drift, and Out-of-Order Observations",
    "doi": "https://doi.org/10.1145/3597209",
    "publication_date": "2023-05-15",
    "publication_year": 2023,
    "authors": "Maximilian A. Köhl; Holger Hermanns",
    "corresponding_authors": "",
    "abstract": "Online fault diagnosis techniques are a key enabler of effective failure mitigation. For real-time systems, the problem of identifying faults is aggravated by timing imprecisions such as varying latency between events and their observation. This paper tackles the challenge of diagnosing faults based on partial observations which are subject to timing imprecisions and potentially made out-of-order due to latency. In this paper, we develop a theory of robust real-time diagnosis importing well-established notions from timed automata theory and the diagnosis of discrete event systems. The theory itself enables a foundational understanding and investigation of the problem and its intricacies. Based on this theory, we further devise an online diagnosis algorithm consuming observations incrementally as they are made and enabling diagnosis, whenever possible, within a bounded worst-case delay. We prove the correctness of the algorithm and its properties with respect to the theory. Aiming at practical feasibility, we also show how to obtain sound but not necessarily complete diagnosis results with space and time requirements bounded by the size of the system model and independent of the number of observations. Finally, using a prototypical implementation, we report on first empirical results obtained by simulation of a small excerpt of an industrial automation example.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4376615011",
    "type": "article"
  },
  {
    "title": "CIM: A Novel Clustering-based Energy-Efficient Data Imputation Method for Human Activity Recognition",
    "doi": "https://doi.org/10.1145/3609111",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Dina Hussein; Ganapati Bhat",
    "corresponding_authors": "",
    "abstract": "Human activity recognition (HAR) is an important component in a number of health applications, including rehabilitation, Parkinson’s disease, daily activity monitoring, and fitness monitoring. State-of-the-art HAR approaches use multiple sensors on the body to accurately identify activities at runtime. These approaches typically assume that data from all sensors are available for runtime activity recognition. However, data from one or more sensors may be unavailable due to malfunction, energy constraints, or communication challenges between the sensors. Missing data can lead to significant degradation in the accuracy, thus affecting quality of service to users. A common approach for handling missing data is to train classifiers or sensor data recovery algorithms for each combination of missing sensors. However, this results in significant memory and energy overhead on resource-constrained wearable devices. In strong contrast to prior approaches, this paper presents a clustering-based approach (CIM) to impute missing data at runtime. We first define a set of possible clusters and representative data patterns for each sensor in HAR. Then, we create and store a mapping between clusters across sensors. At runtime, when data from a sensor are missing, we utilize the stored mapping table to obtain most likely cluster for the missing sensor. The representative window for the identified cluster is then used as imputation to perform activity classification. We also provide a method to obtain imputation-aware activity prediction sets to handle uncertainty in data when using imputation. Experiments on three HAR datasets show that CIM achieves accuracy within 10% of a baseline without missing data for one missing sensor when providing single activity labels. The accuracy gap drops to less than 1% with imputation-aware classification. Measurements on a low-power processor show that CIM achieves close to 100% energy savings compared to state-of-the-art generative approaches.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386568595",
    "type": "article"
  },
  {
    "title": "MaGNAS: A Mapping-Aware Graph Neural Architecture Search Framework for Heterogeneous MPSoC Deployment",
    "doi": "https://doi.org/10.1145/3609386",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Mohanad Odema; Halima Bouzidi; Hamza Ouarnoughi; Smaïl Niar; Mohammad Abdullah Al Faruque",
    "corresponding_authors": "",
    "abstract": "Graph Neural Networks (GNNs) are becoming increasingly popular for vision-based applications due to their intrinsic capacity in modeling structural and contextual relations between various parts of an image frame. On another front, the rising popularity of deep vision-based applications at the edge has been facilitated by the recent advancements in heterogeneous multi-processor Systems on Chips (MPSoCs) that enable inference under real-time, stringent execution requirements. By extension, GNNs employed for vision-based applications must adhere to the same execution requirements. Yet contrary to typical deep neural networks, the irregular flow of graph learning operations poses a challenge to running GNNs on such heterogeneous MPSoC platforms. In this paper, we propose a novel unified design-mapping approach for efficient processing of vision GNN workloads on heterogeneous MPSoC platforms. Particularly, we develop MaGNAS, a mapping-aware Graph Neural Architecture Search framework. MaGNAS proposes a GNN architectural design space coupled with prospective mapping options on a heterogeneous SoC to identify model architectures that maximize on-device resource efficiency. To achieve this, MaGNAS employs a two-tier evolutionary search to identify optimal GNNs and mapping pairings that yield the best performance trade-offs. Through designing a supernet derived from the recent Vision GNN (ViG) architecture, we conducted experiments on four (04) state-of-the-art vision datasets using both ( i ) a real hardware SoC platform (NVIDIA Xavier AGX) and ( ii ) a performance/cost model simulator for DNN accelerators. Our experimental results demonstrate that MaGNAS is able to provide 1.57 × latency speedup and is 3.38 × more energy-efficient for several vision datasets executed on the Xavier MPSoC vs. the GPU-only deployment while sustaining an average 0.11% accuracy reduction from the baseline.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386568606",
    "type": "article"
  },
  {
    "title": "CABARRE: Request Response Arbitration for Shared Cache Management",
    "doi": "https://doi.org/10.1145/3608096",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Garima Modi; Aritra Bagchi; Neetu Jindal; Ayan Mandal; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "Modern multi-processor systems-on-chip (MPSoCs) are characterized by caches shared by multiple cores. These shared caches receive requests issued by the processor cores. Requests that are subject to cache misses may result in the generation of responses . These responses are received from the lower level of the memory hierarchy and written to the cache. The outstanding requests and responses contend for the shared cache bandwidth. To mitigate the impact of the cache bandwidth contention on the overall system performance, an efficient request and response arbitration policy is needed. Research on shared cache management has neglected the additional cache contention caused by responses, which are written to the cache. We propose CABARRE , a novel request and response arbitration policy at shared caches, so as to improve the overall system performance. CABARRE shows a performance improvement of 23% on average across a set of SPEC workloads compared to straightforward adaptations of state-of-the-art solutions.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386568665",
    "type": "article"
  },
  {
    "title": "<scp>EMS-i</scp> : An Efficient Memory System Design with Specialized Caching Mechanism for Recommendation Inference",
    "doi": "https://doi.org/10.1145/3609384",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Yitu Wang; Shiyu Li; Qilin Zheng; Andrew Chang; Hai Li; Yiran Chen",
    "corresponding_authors": "",
    "abstract": "Recommendation systems have been widely embedded into many Internet services. For example, Meta’s deep learning recommendation model (DLRM) shows high prefictive accuracy of click-through rate in processing large-scale embedding tables. The SparseLengthSum (SLS) kernel of the DLRM dominates the inference time of the DLRM due to intensive irregular memory accesses to the embedding vectors. Some prior works directly adopt near data processing (NDP) solutions to obtain higher memory bandwidth to accelerate SLS. However, their inferior memory hierarchy induces low performance-cost ratio and fails to fully exploit the data locality. Although some software-managed cache policies were proposed to improve the cache hit rate, the incurred cache miss penalty is unacceptable considering the high overheads of executing the corresponding programs and the communication between the host and the accelerator. To address the issues aforementioned, we propose EMS-i , an efficient memory system design that integrates Solide State Drive (SSD) into the memory hierarchy using Compute Express Link (CXL) for recommendation system inference. We specialize the caching mechanism according to the characteristics of various DLRM workloads and propose a novel prefetching mechanism to further improve the performance. In addition, we delicately design the inference kernel and develop a customized mapping scheme for SLS operation, considering the multi-level parallelism in SLS and the data locality within a batch of queries. Compared to the state-of-the-art NDP solutions, EMS-i achieves up to 10.9× speedup over RecSSD and the performance comparable to RecNMP with 72% energy savings. EMS-i also saves up to 8.7× and 6.6 × memory cost w.r.t. RecSSD and RecNMP, respectively.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386568791",
    "type": "article"
  },
  {
    "title": "Probabilistic Reaction Time Analysis",
    "doi": "https://doi.org/10.1145/3609390",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Mario Günzel; Niklas Ueter; Kuan-Hsun Chen; Georg von der Brüggen; Jian-Jia Chen",
    "corresponding_authors": "",
    "abstract": "In many embedded systems, for instance, in the automotive, avionic, or robotics domain, critical functionalities are implemented via chains of communicating recurrent tasks. To ensure safety and correctness of such systems, guarantees on the reaction time, that is, the delay between a cause (e.g., an external activity or reading of a sensor) and the corresponding effect, must be provided. Current approaches focus on the maximum reaction time, considering the worst-case system behavior. However, in many scenarios, probabilistic guarantees on the reaction time are sufficient. That is, it is sufficient to provide a guarantee that the reaction does not exceed a certain threshold with (at least) a certain probability. This work provides such probabilistic guarantees on the reaction time, considering two types of randomness: response time randomness and failure probabilities. To the best of our knowledge, this is the first work that defines and analyzes probabilistic reaction time for cause-effect chains based on sporadic tasks.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386568801",
    "type": "article"
  },
  {
    "title": "Sound Mixed Fixed-Point Quantization of Neural Networks",
    "doi": "https://doi.org/10.1145/3609118",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Debasmita Lohar; Clothilde Jeangoudoux; Anastasia Volkova; Eva Darulová",
    "corresponding_authors": "",
    "abstract": "Neural networks are increasingly being used as components in safety-critical applications, for instance, as controllers in embedded systems. Their formal safety verification has made significant progress but typically considers only idealized real-valued networks. For practical applications, such neural networks have to be quantized, i.e., implemented in finite-precision arithmetic, which inevitably introduces roundoff errors. Choosing a suitable precision that is both guaranteed to satisfy a roundoff error bound to ensure safety and that is as small as possible to not waste resources is highly nontrivial to do manually. This task is especially challenging when quantizing a neural network in fixed-point arithmetic, where one can choose among a large number of precisions and has to ensure overflow-freedom explicitly. This paper presents the first sound and fully automated mixed-precision quantization approach that specifically targets deep feed-forward neural networks. Our quantization is based on mixed-integer linear programming (MILP) and leverages the unique structure of neural networks and effective over-approximations to make MILP optimization feasible. Our approach efficiently optimizes the number of bits needed to implement a network while guaranteeing a provided error bound. Our evaluation on existing embedded neural controller benchmarks shows that our optimization translates into precision assignments that mostly use fewer machine cycles when compiled to an FPGA with a commercial HLS compiler than code generated by (sound) state-of-the-art. Furthermore, our approach handles significantly more benchmarks substantially faster, especially for larger networks.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386580518",
    "type": "article"
  },
  {
    "title": "Improving Worst-case TSN Communication Times of Large Sensor Data Samples by Exploiting Synchronization",
    "doi": "https://doi.org/10.1145/3609120",
    "publication_date": "2023-09-11",
    "publication_year": 2023,
    "authors": "Jonas Peeck; Rolf Ernst",
    "corresponding_authors": "",
    "abstract": "Higher levels of automated driving also require a more sophisticated environmental perception. Therefore, an increasing number of sensors transmit their data samples as frame bursts to other applications for further processing. As a vehicle has to react to its environment in time, such data is subject to safety-critical latency constraints. To keep up with the resulting data rates, there is an ongoing transition to a Time-Sensitive Networking (TSN)-based communication backbone. However, the use of TSN-related industry standards does not match the automotive requirements of large timely sensor data transmission, nor it offers benefits on time-critical transmissions of single control data packets. By using the full data rate of prioritized IEEE 802.1Q Ethernet, giving time guarantees on large data samples is possible, but with strongly degraded results due to data collision. Resolving such collisions with time-aware shaping comes with significant overhead. Hence, rather than optimizing the parameters of the existing protocol, we propose a system design that synchronizes the transmission times of sensor data samples. This limits network protocol complexity and hardware requirements by avoiding tight time synchronization and time-aware shaping. We demonstrate that individual sensor data samples are transmitted without significant interference, exclusively at full Ethernet data rate. We provide a synchronous event model together with a straightforward response time analysis for synchronous multi-frame sample transmissions. The results show that worst-case latencies of such sample communication, in contrast to non-synchronized approaches, are close to their theoretical minimum as well as to simulative results while keeping the overall network utilization high.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386602816",
    "type": "article"
  },
  {
    "title": "Robust Embedded Autonomous Driving Positioning System Fusing LiDAR and Inertial Sensors",
    "doi": "https://doi.org/10.1145/3626098",
    "publication_date": "2023-10-17",
    "publication_year": 2023,
    "authors": "Zhijian He; Bohuan Xue; Xiangcheng Hu; Zhaoyan Shen; Xiangyue Zeng; Ming Liu",
    "corresponding_authors": "",
    "abstract": "Autonomous driving emphasizes precise multi-sensor fusion positioning on limit resource embedded systems. LiDAR-centered sensor fusion system serves as a mainstream navigation system due to its insensitivity to illumination and viewpoint change. However, these types of systems suffer from handling large-scale sequential LiDAR data using limited resources on board, leading LiDAR-centralized sensor fusion unpractical. As a result, hand-crafted features such as plane and edge are leveraged in majority mainstream positioning methods to alleviate this unsatisfaction, triggering a new cornerstone in LiDAR Inertial sensor fusion. However, such super light weight feature extraction, although it achieves real-time constraint in LiDAR-centered sensor fusion, encounters severe vulnerability under high speed rotational or translational perturbation. In this paper, we propose a sparse tensor based LiDAR Inertial fusion method for autonomous driving embedded system. Leveraging the power of sparse tensor, the global geometrical feature is fetched so that the point cloud sparsity defect is alleviated. Inertial sensor is deployed to conquer the time-consuming step caused by the coarse level point-wise inlier matching. We construct our experiments on both representative dataset benchmarks and realistic scenes. The evaluation results show the robustness and accuracy of our proposed solution compared to classical methods.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4387693689",
    "type": "article"
  },
  {
    "title": "Bridging the Abstraction Gap: A Systematic Approach to Rule-Based Transformational Design for Embedded Systems",
    "doi": "https://doi.org/10.1145/3714412",
    "publication_date": "2025-01-21",
    "publication_year": 2025,
    "authors": "Fahimeh Bahrami; Rodolfo Jordão; Ingo Sander; Ingemar Söderquist",
    "corresponding_authors": "",
    "abstract": "Raising the level of abstraction is considered key to addressing the ever-increasing complexity of embedded system design, but it causes additional challenges due to the larger abstraction gap between the initial specification and the final implementation. This paper addresses the current lack of systematic design methods by extending existing design-transformation-based approaches and wrapping them into a rule-based transformational design methodology for heterogeneous multi-processor platforms. The methodology cross-fertilizes embedded system design with program transformation techniques while taking into account the interplay of tight constraints and platform heterogeneity inherent in such systems. It advocates step-wise transformations starting from initial requirements to yield a final refined model that is efficient for implementation. To consider the effect of transformations on different properties of the system at each step, the system is specified with a set of requirements, an application model, a platform model, and a set of mapping decisions; referred to as the RAMP view of the system. The RAMP view and its carefully selected underlying unified abstract graph representation lay the foundations for mechanizing and potentially automating design transformations. A pattern matching technique is introduced and a proof-of-concept tool is implemented that automatically detects all possible transformations by matching the patterns defined by the transformation rules to the abstract graph representation of the system model. The underlying graph representation enables complex transformations on different aspects of the design, resulting in an improved design space definition. The design space can be explored by application-platform co-exploration techniques, yielding the most promising sequence of application transformations alongside the best matching platform. The applicability and potential of the proposed methodology are showcased through the design of both an image processing system and a cloud detection system.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406678354",
    "type": "article"
  },
  {
    "title": "Exploiting Approximation for Run-time Resource Management of Embedded HMPs",
    "doi": "https://doi.org/10.1145/3723357",
    "publication_date": "2025-03-13",
    "publication_year": 2025,
    "authors": "Zain Taufique; Anil Kanduri; Antonio Miele; Amir M. Rahmani; Cristiana Bolchini; Nikil Dutt; Pasi Liljeberg",
    "corresponding_authors": "",
    "abstract": "Run-time resource management (RTM) of multi-programmed workloads on heterogeneous multi-core platforms is challenging due to i) fixed power budget of the device, ii) variable performance requirements of the workloads, and iii) unknown arrival of the applications. Existing RTM solutions lack power-performance coordination, resulting in performance degradation during power actuation or power violations during performance provisioning. Exploiting inherent error-resilience of the applications can address the performance loss incurred in power actuation, by combining run-time approximation with traditional power knobs (including Dynamic Voltage/Frequency Scaling, Task Migration, Degree of Parallelism, and CPU Quota ). In this work, we present an accuracy-aware resource management framework that jointly actuates run-time approximation and traditional power knobs for efficient power-performance management of multi-programmed and multi-threaded workloads running on heterogeneous mobile platforms. Our strategy configures the accuracy of the applications at run-time to exploit accuracy-performance trade-offs, by considering system-wide power-performance dynamics. We use heuristic estimation models to jointly enforce accuracy configuration and traditional power knobs settings at run-time. We evaluated our framework on real-world embedded mobile platforms, including Odroid XU3 and Asus Tinker Edge R boards to demonstrate the efficiency of our proposed approach across multiple workload scenarios. Our approach achieved 25% lower performance violations against the state-of-the-art run-time resource management policies at the cost of 2.2% accuracy loss across six applications.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408412636",
    "type": "article"
  },
  {
    "title": "Wireless Perceptual Space Modeling Method for Cross-Domain Human Activity Recognition",
    "doi": "https://doi.org/10.1145/3724119",
    "publication_date": "2025-03-16",
    "publication_year": 2025,
    "authors": "Zhiyong Tao; Z. Jane Wang; Ying Liu; Yuqing He; Wang Yikai",
    "corresponding_authors": "",
    "abstract": "Existing Wi-Fi perceptual recognition using Doppler Frequency Shift (DFS) can portray human activity and behavioral features, but the method is affected by the user’s movement direction, position, and other factors, resulting in large differences in the spectral modes generated by the same action, which restricts the performance and pervasiveness of the cross-domain recognition system. Based on this, a wireless sensing Spatial Frequency Field (SFF) modeling method is proposed to extract cross-domain human activity features through DFS. The key of this method is to model the wireless sensing space according to the DFS frequency, speculate the human body orientation information and correct the DFS power, calculate the power magnitude of the spatial frequency points to generate the SFF, the spatial power field contains the multilink frequency distributions due to the human body activities and contains the human body orientation information, which unifies the DFS frequency distributions of the same human body activities under the fixed orientation, and finally, design the CNN-RNN deep neural network to classify the SFF. Under the test of multiple datasets and classification tasks, the method proposed in this paper has the advantages of being lightweight, fast, accurate, and universal, in which the average accuracy of intra-domain gesture recognition reaches 95.3%, the average accuracy of cross-domain gesture recognition reaches 82.8%-91.2%, and the accuracy of gait recognition reaches 94.6%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408488495",
    "type": "article"
  },
  {
    "title": "TAFP-ViT: A Transformer Accelerator via QKV Computational Fusion and Adaptive Pruning for Vision Transformer",
    "doi": "https://doi.org/10.1145/3745028",
    "publication_date": "2025-06-21",
    "publication_year": 2025,
    "authors": "Liang Xu; HongRui Song; R.C. Wang; Tian Lan; Zhongfeng Wang; Meiqi Wang",
    "corresponding_authors": "",
    "abstract": "The remarkable progress of Vision Transformer (ViT) models has significantly advanced performance in computer vision tasks. However, the deployment of ViTs in resource-constrained environments remains a challenge, as the attention computation mechanisms within these models form a significant bottleneck, requiring substantial memory and computational resources. To address this challenge, we introduce TAFP-ViT, a tailored hardware-software co-design framework for Vision Transformers. On the software level, TAFP-ViT leverages a learnable compressor to perform multi-head shared compression on feature maps, and fuses decompression reconstruction, QKV generation and QKV processing together for calculation, thereby greatly reducing memory and computation requirements. Furthermore, TAFP-ViT combines dynamic inter-layer token pruning to eliminate unimportant tokens and hardware-friendly intra-block row pruning to diminish redundant computations. The proposed software design converts the calculations before and after SoftMax into dense and sparse triple matrix multiplication (TMM) forms respectively. On the hardware level, TAFP-ViT proposes a configurable systolic array (SA) to efficiently adapt to the QKV fusion computation pattern. The SA has flexible PE units that can effectively support general matrix multiplication (GEMM), dense and sparse TMM. The TMM and flexible dataflows allow TAFP-ViT to avoid handling transpositions and storing intermediate computation results, greatly enhancing computational efficiency. Besides, TAFP-ViT innovatively designs a Top-k engine to support dynamic pruning on the fly with high throughput and low resource consumption. Experiments show that the proposed TAFP-ViT achieves remarkable speedups of 123.91 ×, 29.5 ×, and 3.01 ∼ 20.65 × compared to conventional CPUs, GPUs, and previous state-of-the-art works, respectively. Additionally, TAFP-ViT reaches a throughput of up to 731.5 GOP/s and an impressive energy efficiency of 77.9 GOPS/W.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411505085",
    "type": "article"
  },
  {
    "title": "A Unified Approach to a Secure and Lightweight Mutual Authentication Protocol Using Pre-Characterized COTS SRAM ICs for IoT Applications",
    "doi": "https://doi.org/10.1145/3748328",
    "publication_date": "2025-07-15",
    "publication_year": 2025,
    "authors": "Aranya Gupta; Amit Surpur; Bishnu Prasad Das; S. K. Manhas",
    "corresponding_authors": "",
    "abstract": "Traditional Physical Unclonable Function (PUF)-based authentication protocols are vulnerable to machine learning attacks and evolving cyber threats. Moreover, these protocols lack suitability for resource-constrained IoT devices due to the involvement of heavy cryptographic primitives, error correction modules, and significant computational overhead. This article proposes a mutual authentication protocol and session key agreement utilizing commercial-off-the-shelf (COTS) SRAM integrated circuits (ICs) to extract a secret key. We introduce a block-based lightweight fuzzy extractor to minimize the overhead associated with error correction modules on IoT devices. Our protocol relies only hash, XOR and masking functions for the identity verification for both parties and stores only one challenge-response pair (CRP) on the server, reducing memory overhead on the authentication server. In addition, we perform a rigorous informal security analysis against well-known attacks and formal security analysis using Verifpal tool considering an active attacker in the communication link. Furthermore, the performance evaluation and comparative analysis indicate that the proposed protocol significantly outperforms the state-of-the-art protocols in terms of communication, computational overhead, storage overhead, and energy consumption by up to 69%, 81%, 87.5% and 76.6% respectively. We have implemented the proposed authentication protocol on ESP32 and Raspberry Pi 3 boards to show its applicability and scalability in a real-world IoT framework.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412423683",
    "type": "article"
  },
  {
    "title": "SLIM: A Heterogeneous Accelerator for Edge Inference of Sparse Large Language Model via Adaptive Thresholding",
    "doi": "https://doi.org/10.1145/3750727",
    "publication_date": "2025-07-24",
    "publication_year": 2025,
    "authors": "Weihong Xu; Haein Choi; Po-Kai Hsu; Shimeng Yu; Tajana Rosing",
    "corresponding_authors": "",
    "abstract": "Large language models (LLMs), composed of Transformer decoders, have demonstrated unparalleled proficiency in understanding and generating human language. However, efficient LLM inference on resource-constraint embedded devices remains a challenge because of the sheer model size and memory-intensive operations that arise from feedforward network (FFN) and multi-head attention (MHA) layers. Existing accelerations offload LLM inference to heterogeneous computing systems comprising expensive memory and processing units. However, recent studies show that most hardware resources are not used because LLM exhibits significant sparsity during inference. The sparsity of LLMs provides a good opportunity to perform memory-efficient inference. In this work, we propose SLIM, an algorithm and hardware co-design optimized for sparse LLM serving on the edge. SLIM exploits LLM’s sparsity by only fetching activated neurons to significantly reduce data movement. To this end, the efficient inference algorithm based on adaptive thresholding is proposed to support runtime configurable sparsity at the cost of negligible accuracy loss. Then, we present the SLIM heterogeneous hardware architecture that combines the best of both near-storage processing (NSP) and processing-in-memory (PIM). SLIM stores FFN weights in high-density 3D NAND and computes FFN layers in NSP units, alleviating high memory requirements caused by FFN weights. The memory-intensive MHA with low arithmetic density is processed in the PIM module. By leveraging the inherent sparsity observed in LLM operations and integrating NSP with PIM techniques within SSDs, SLIM significantly reduces memory footprint, data movement, and energy consumption. Meanwhile, we present the software support for integrating design into existing SSD system. Our comprehensive analysis and system-level optimization demonstrate the effectiveness of our sparsity-tailored accelerator, offering 13-18 × throughput improvements over SSD-GPU system and 9-10 × better energy efficiency over DRAM-GPU system while maintaining low latency.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412636554",
    "type": "article"
  },
  {
    "title": "SecureRide: Detecting Safety-Threatening Behavior of E-Scooters Using Battery Information",
    "doi": "https://doi.org/10.1145/3758095",
    "publication_date": "2025-08-02",
    "publication_year": 2025,
    "authors": "Jiwon Kim; Geon Kim; Je‐Ho Lee; Thiemo Voigt; Hojung Cha",
    "corresponding_authors": "",
    "abstract": "Reckless usage of electric (e-) scooters causes many injury accidents, raising critical safety concerns. Despite newly introduced regulations, specifically, speed limits and sidewalk driving prohibitions, the number of accidents increases due to the challenges in enforcement. Therefore, a reliable method to detect safety-threatening illegal behaviors of e-scooters is essential to mitigate this growing problem. In this article, we propose SecureRide, a system that accurately detects illegal e-scooter behaviors, i.e., speeding violation and sidewalk riding, at runtime using only battery information, without the need for additional sensors. To this end, we first design a neural network-based illegal behavior predictor that takes sequences of three battery factors, i.e., voltage, current, and capacity, as inputs. The model architecture is optimized based on time constraints, target accuracy, and resource constraints of the target devices. Next, we devise a runtime detection strategy to achieve both high accuracy and low detection time. SecureRide operates in two modes with different predictors– lightweight-quick and complex-accurate models–depending on the driving situation, ensuring both high accuracy and low detection time. We extensively validate SecureRide based on actual driving experiments. Our results show that SecureRide detects illegal behaviors with an accuracy of up to 99.77% within 1.01 seconds.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412855202",
    "type": "article"
  },
  {
    "title": "Deductive Verification of Cooperative RTOS Applications",
    "doi": "https://doi.org/10.1145/3759251",
    "publication_date": "2025-08-05",
    "publication_year": 2025,
    "authors": "Philip Tasche; Paula Herber; Marieke Huisman",
    "corresponding_authors": "",
    "abstract": "Embedded systems are used in many safety-critical domains, including in medicine, traffic and critical infrastructure. Due to the strict timing requirements such systems usually have to fulfill, they often run on real-time operating systems (RTOS). As the RTOS influences the function and the timing behavior of the system, it becomes important to rigorously ensure the correctness and safety of applications running on them while taking into account the semantics of the operating system. Existing verification approaches are either limited to specific RTOS components or based on explicit state space exploration techniques such as model checking, which do not scale well for concurrent or timed applications. In this paper, we propose a deductive approach to verify crucial safety properties about applications written for the widely-used RTOS FreeRTOS using the VerCors verifier. Our key ideas are threefold: 1) We provide a formalization of a wide variety of FreeRTOS features and an automatic encoding of FreeRTOS applications for verification with VerCors. 2) We adapt and enhance an existing approach for automatic invariant generation to largely automate the typically high-effort verification process. 3) We present a systematic technique to verify both functional and timing-related properties of cooperative RTOS applications. We demonstrate the applicability of our approach on a FreeRTOS demo application as well as an adaptive cruise control system.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412955610",
    "type": "article"
  },
  {
    "title": "HMSA: High-Performance Heterogeneous Mixed-Precision CNN Systolic Array Accelerator on FPGA",
    "doi": "https://doi.org/10.1145/3759458",
    "publication_date": "2025-08-07",
    "publication_year": 2025,
    "authors": "Yongxiang Cao; Hongxu Jiang; Huiyong Li; Yu Tang; Dongping Shi; Guocheng Zhao",
    "corresponding_authors": "",
    "abstract": "In power-constrained and real-time-demanding embedded scenarios, Field-Programmable Gate Arrays (FPGAs) emerge as ideal options for accelerating neural network inference, owing to the reconfigurability, high reliability, and flexibility of FPGAs. Mixed precision quantization technology significantly reduces computational complexity and bandwidth requirements while preserving model accuracy. However, existing FPGA accelerators fail to fully leverage the parallel advantages of mixed precision, which leads to the actual inference speedup being markedly lower than the theoretical prediction. Reviewing existing methods, we found three main drawbacks in enhancing practical computational performance. Firstly, FPGAs primarily rely on DSP slices to achieve high-performance parallel multiplication and accumulation (MAC) in neural network inference. However, the current DSP PE design and data packing methods are not compatible with mixed-precision models. Secondly, the remaining logic resources are not fully utilized to accelerate computations. Thirdly, the mixed-precision quantization bit-width selection method without hardware-guided guidance leads to additional model accuracy loss. To address these challenges, we propose a high-performance heterogeneous mixed-precision systolic array (SA) accelerator, HMSA. It aims to leverage mixed-precision quantization fully, enhancing the practical inference efficiency of neural networks on embedded FPGAs. We propose an optimized DSP data packing method guided by a resource-performance cost model, which enhances the parallel computing performance of accelerators. We propose a heterogeneous convolutional acceleration architecture based on SA architecture with high scalability, enabling efficient utilization of FPGA’s heterogeneous computing resources. In terms of the algorithm, we propose an optimization method for bit-width selection based on FPGA hardware architecture, aiming to avoid accuracy degradation without improving inference speed. Experiments confirm that HMSA on the Xilinx XC7VX690T FPGA reaches a peak throughput of 6.385 TOP/s at W1A8 precision. When inferring mixed precision neural networks, HMSA achieves 3.53×, 5.46×, and 1.58× improvements in actual throughput/DSP compared to state-of-the-art MPA, MSD, and MP-OPU. Compared with the state-of-the-art MBFQuant and Edge-MPQ mixed quantization algorithms, the proposed optimized bit-width selection method effectively reduces the model accuracy loss.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413039156",
    "type": "article"
  },
  {
    "title": "PRINT-SAFE: Printed Ultra-Low-Cost Electronic X-Design with Scalable Adaptive Fault Endurance",
    "doi": "https://doi.org/10.1145/3758096",
    "publication_date": "2025-08-07",
    "publication_year": 2025,
    "authors": "Priyanjana Pal; Tara Gheshlaghi; Haibin Zhao; Michael Hefenbrock; Michael Beigl; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "The demand for next-generation flexible electronics in applications like smart packaging and smart bandages has driven the need for cost-effective solutions. Traditional silicon-based electronics struggle with high costs and rigidity, making them unsuitable for these emerging markets. In this regard, additive printed electronics (PE) offer a viable alternative with their flexibility and ultra-low-cost manufacturing. Printed analog neuromorphic circuits (pNCs) are well-suited for these target applications, especially for classification tasks, as their low device count can efficiently meet the needs of the technology. However, low-cost additive manufacturing comes with higher defect rates, such as misprints, broken connections, and defective components, posing significant challenges to the reliability of printed circuits. This paper presents a novel co-design of training algorithm and hardware for fault-tolerant pNCs using fault-aware training (FAT). The proposed method introduces a fault-tolerant version of printed nonlinear transformation circuits, combined with a bespoke training process that selects different types of printed activation functions (AFs) for different neurons to optimize both fault endurance and hardware costs. Experiments on benchmark datasets demonstrate an improvement in the accuracy of fault-tolerant (FT) pNCs from 62.1% to 79.4% under a 10% fault rate. Moreover, combining both normal and fault-tolerant versions of activation functions (AFs) using gumble-softmax distribution shows acceptable accuracy drop with an average reduction in power and area of 54.5% and 6.54%, respectively, while reducing the training time significantly by 56.2%, compared to only using FT-AFs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413039163",
    "type": "article"
  },
  {
    "title": "Dynamic Layer Routing Defense for Real-Time Embedded Vision",
    "doi": "https://doi.org/10.1145/3762191",
    "publication_date": "2025-08-18",
    "publication_year": 2025,
    "authors": "Zimo Ma; Xiangzhong Luo; Qun Song; Rui Tan",
    "corresponding_authors": "",
    "abstract": "Deep neural networks have advanced the perception and decision-making functions of smart embedded systems, such as car-borne driver assistance. Deploying these embedded neural networks often faces two challenges: (i) security vulnerabilities to adversarial examples that can be deployed in the perceived physical environment; (ii) limited computational resources coupled with dynamic conditions that necessitate real-time adaptation of model execution. However, these two challenges are often addressed separately in existing research. This article presents LeapNet, which aims to address both challenges simultaneously. It comprises two versions: LeapNet-1 and LeapNet-2. LeapNet-1 employs dynamic layer routing to counteract adaptive adversarial-example attacks and reduce computational redundancy. Building upon LeapNet-1, LeapNet-2 further adapts its layer routing configurations in real time to meet the frame processing rate requirements under dynamic conditions while maintaining defense performance. Extensive experiments on various representative datasets, neural network models, and adaptive attacks demonstrate the superiority of LeapNet over existing defense methods. On-road tests with a real-time car-borne traffic sign recognition system validate its effectiveness in maintaining frame processing rate under dynamic conditions.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413286952",
    "type": "article"
  },
  {
    "title": "Timekeepers: ML-Driven SDF Analysis for Power-Wasters Detection in FPGAs",
    "doi": "https://doi.org/10.1145/3761809",
    "publication_date": "2025-08-18",
    "publication_year": 2025,
    "authors": "Mohamed Fathy; Hassan Nassar; Mohamed A. Abd El Ghany; Jörg Henkel",
    "corresponding_authors": "",
    "abstract": "As the integration of FPGAs into cloud computing platforms accelerates, the risk of fault injection attacks - especially through power-wasting designs - becomes increasingly critical. Malicious tenants can upload FPGA designs that, under specific input stimuli, generate excessive power consumption, jeopardizing the integrity of the shared power delivery network (PDN) and enabling denial-of-service or side-channel attacks. Traditional detection techniques relying on netlist and bitstream analysis struggle with generalization and can be evaded through circuit obfuscation and seemingly benign designs. In contrast to these netlist-based approaches, we introduce Timekeepers, a novel detection method that utilizes Standard Delay Format (SDF) timing data combined with machine learning to detect anomalous power behavior in synthesized FPGA designs. Our method trains a decision tree classifier on SDF files generated from both benign and malicious designs, focusing on timing characteristics such as propagation delays and setup/hold violations to identify power wasters at the primitive level. By abstracting away from circuit connectivity and emphasizing timing patterns, our framework is both scalable and robust across different FPGA architectures. The classifier independently evaluates each FPGA component and aggregates the results using a threshold-based voting system to improve detection granularity and reduce false positives. Timekeepers achieves 99.6% accuracy and demonstrates superior performance compared to state-of-the-art solutions. Furthermore, our approach is platform-agnostic and does not require access to netlists or bitstreams, preserving intellectual property confidentiality while enhancing pre-deployment security checks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413286979",
    "type": "article"
  },
  {
    "title": "FARRE: Fairness Aware Request Response Arbitration in Shared Caches",
    "doi": "https://doi.org/10.1145/3761811",
    "publication_date": "2025-08-18",
    "publication_year": 2025,
    "authors": "Garima Modi; Priyanka Singla; Neetu Jindal; Ayan Mandal; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "Contention in shared caches caused by concurrently executing applications can lead to overall performance degradation in multiprocessor systems-on-chip (MPSoCs). To address this issue, various shared cache arbitration techniques have been proposed to manage cache bandwidth contention. These techniques focus on enhancing overall system performance; however, this optimization often comes at the expense of system fairness, leading to some applications experiencing disproportionate slowdowns, or, in the worst case, starvation. Therefore, an effective shared cache bandwidth management policy is needed to optimize performance while ensuring fairness across applications. We propose FARRE , a novel fairness aware request-response arbitration technique for shared caches. FARRE is designed to optimize performance while attempting to maintain a user-defined fairness threshold. We evaluate its effectiveness through extensive simulations including comparisons against state-of-the-art arbitration schemes. The results show that FARRE is able to maintain or exceed the input fairness thresholds, and improves system performance over standard fair scheduling policies such as round-robin; the performance improvement is 14% for lower fairness thresholds such as 0.5, and could even gain 5% performance for aggressive thresholds such as 0.9. Additionally, compared to the best performance optimization techniques, FARRE achieves 81% higher fairness.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413286987",
    "type": "article"
  },
  {
    "title": "A Severe Vulnerability and an Effective Defense Against DFA on Ascon",
    "doi": "https://doi.org/10.1145/3762192",
    "publication_date": "2025-08-18",
    "publication_year": 2025,
    "authors": "Suchanda Das; Amit Jana; Debdeep Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "Differential Fault Attack ( DFA ) is a powerful cryptanalytic technique for recovering cryptographic keys by exploiting computational faults. At Indocrypt 2024, the first DFA on Ascon was introduced using a bit-flip fault model to recover a 64-bit key, followed by a bit-set fault model to extract another 64-bit key. However, this attack lacked practical validation. In this work, we revisit their approach and extend it by generalizing the attack to a more practical and widely accepted random fault model. Given that Ascon is implemented using bit-sliced techniques, we validate our attack through real-world experiments on a ChipWhisperer Lite platform using clock glitching. We demonstrate that the structure of Ascon inherently transforms random register faults into single-bit differences within the S-box operation, making it susceptible to DFA . We evaluate our attack under both nonce-misuse and nonce-respecting scenarios. In the nonce-misuse setting, we recover the first 64-bit key with only 50 random register faults and estimate the fault requirements for key recovery in the nonce-respecting case. Additionally, we identify a structural weakness in the Ascon tag selection process that increases its susceptibility to difference-based fault attacks. To counter this vulnerability, we propose an immediate countermeasure to strengthen its resistance against DFA .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413287028",
    "type": "article"
  },
  {
    "title": "SideDRAM: Integrating SoftSIMD Datapaths near DRAM Banks for Energy-Efficient Variable Precision Computation",
    "doi": "https://doi.org/10.1145/3762641",
    "publication_date": "2025-08-22",
    "publication_year": 2025,
    "authors": "Rafael Medina; Pengbo Yu; Alexandre Levisse; Dwaipayan Biswas; Marina Zapater; Giovanni Ansaloni; Francky Catthoor; David Atienza",
    "corresponding_authors": "",
    "abstract": "By interfacing computing logic directly to the DRAM banks, bank-level Compute-near-Memory (CnM) architectures promise to mitigate the bottleneck at the memory interconnect. While this computation paradigm heavily reduces the energy requirements for data movement across the system, current solutions fail to co-optimize hardware and software to further increase efficiency. Instead, in this manuscript, we present SideDRAM , a co-designed bank-level CnM architecture to enable massively parallel and energy-efficient computations near DRAM. In contrast with past solutions, we support flexible data typing and heterogeneous quantization, relying on the robustness of workloads to employ small bitwidths, and enable a row-wide access to the banks to exploit parallelism and spatial locality. As a result, SideDRAM integrates (1) software-defined SIMD (SoftSIMD) datapaths, supporting low-energy computing with flexible precision, (2) an interface to the banks based on very wide registers (VWRs), enabling asymmetric data access to both utilize the full DRAM bank bandwidth and leverage data locality at the datapath, and (3) a low-overhead distributed control plane, allowing the efficient handling of variable data typing. We benchmark SideDRAM as a near-DRAM solution by analyzing the area, performance, and energy consumption of an HBM2 CnM channel executing heterogeneously quantized machine learning models. The results show that, compared to the state-of-the-art FIMDRAM design, energy improvements of up to 67% are achieved when a DeiT-S inference is executed with a batch size of 16 under the same area constraints, resulting in energy-delay-area product (EDAP) savings that reach 83%. When comparing to a massively parallel mixed-signal CnM solution, SideDRAM consistently obtains similar performance and better energy efficiency results (geomean of 15× improvement across workloads) at a lower area overhead.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413431280",
    "type": "article"
  },
  {
    "title": "Contract Embeddings for Layered Control Architectures",
    "doi": "https://doi.org/10.1145/3764587",
    "publication_date": "2025-08-28",
    "publication_year": 2025,
    "authors": "Nikhil Vijay Naik; Alessandro Pinto; Pierluigi Nuzzo",
    "corresponding_authors": "",
    "abstract": "The design of complex cyber-physical system architectures is often hierarchical. System specifications are mapped to an implementation layer via a stepwise refinement process involving multiple intermediate layers. These layers may capture different functionalities, and the orchestration of a variety of heterogeneous techniques suited to each layer may be required to achieve the overall design objectives. Due to their heterogeneity, ensuring traceability and verifiability of such architectures is a challenging problem. In this paper, we present a correct-by-construction methodology for designing heterogeneous layered architectures. We capture the specifications at each layer with assume-guarantee contracts , a specification paradigm which can encompass a variety of modeling formalisms. We then use the notion of contract embeddings to define specification refinement , rigorously and traceably mapping specifications across layers modeled with heterogeneous formalisms. We instantiate our methodology on the design of layered control architectures (LCAs), resulting in a novel approach that can verifiably orchestrate domain-specific techniques to satisfy both global planning and local safety requirements. In the context of LCAs, we derive necessary conditions for correct specification refinement and results for compositional realization of control safety specifications. We illustrate our design methodology on a motivating example and a case study derived from robotic mission planning and control.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413792065",
    "type": "article"
  },
  {
    "title": "DynHaMo: Dynamic Hardware-Based Monitoring Dedicated to Attacks Detection",
    "doi": "https://doi.org/10.1145/3762646",
    "publication_date": "2025-08-28",
    "publication_year": 2025,
    "authors": "J. Pottier; Maria Méndez Real; Bertrand Le Gal; Sébastien Pillement",
    "corresponding_authors": "",
    "abstract": "Numerous attacks compromising processor security have been developed over decades, including some targeting the microarchitecture, such as side-channel or transient attacks, or control-flow hijacking attacks. As these attacks target processor microarchitectural features and bypass software-level mitigation techniques, they are considered a serious threat. In order to mitigate these attacks while limiting the impact on performance, various detection methods have been proposed. Indeed, detection techniques offer solutions to limit the execution of costly countermeasures, only after attacks detection, limiting the induced performance overhead. However, detection techniques in the literature suffer from several drawbacks, including non-real-time detection, significant increase in execution time, or make the hypothesis of a trusted Operating System (OS). In this work, we introduce DynHaMo that addresses these issues by detecting attacks targeting the microarchitecture, such as Cache-based Side-Channel Attacks (CSCAs) and Return-Oriented Programming (ROP) attacks, at run-time by taking advantage of dynamic instruction insertion at the hardware level. DynHaMo, is a light-weight hardware micro-decoding unit capable of monitoring microarchitectural events on the fly. For evaluation purposes, DynHaMo has been integrated into a RISC-V core, assessed through multiple benchmarks and attack codes, and implemented on an FPGA platform. We evaluated our solution under high workloads to demonstrate the efficiency of the approach and its robustness to noise. The evaluation results show a detection accuracy of 99.3% on average, with 0.7% false negative and 1.2% false positive on average.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413792092",
    "type": "article"
  },
  {
    "title": "Page-Overwrite Data Sanitization in 3D NAND Flash: Challenges, Feasibility, and the PULSE Solution",
    "doi": "https://doi.org/10.1145/3761798",
    "publication_date": "2025-08-28",
    "publication_year": 2025,
    "authors": "Matchima Buddhanoy; Aleksandar Milenković; Sudeep Pasricha; Biswajit Ray",
    "corresponding_authors": "",
    "abstract": "Instant data deletion (or sanitization) in NAND flash devices is essential for achieving data privacy, but it remains challenging due to the mismatch between erase and write granularities, which leads to high overhead and accelerated wear. While page-overwrite-based instant data sanitization has proven effective for 2D NAND, its applicability to 3D NAND is limited due to the unique sub-block architecture. In this study, we experimentally evaluate page-overwrite-based sanitization on commercial 3D NAND flash memory chips and uncover significant threshold voltage disturbances in erased cells on adjacent pages within the same layer but across different sub-blocks. Our key findings reveal that page-overwrite sanitization increases the median raw bit error rate (RBER) beyond correction limits (exceeding 0.93%) in Floating-Gate (FG) Single-Level Cell (SLC) technology, whereas Charge-Trap (CT) SLC 3D NAND flash memories exhibit higher robustness. In Triple-Level Cell (TLC) 3D NAND, page-overwrite sanitization proves impractical, with the median RBER of ∼13% for FG and ∼5% for CT devices. To overcome these challenges, we propose PULSE , a low-disturbance sanitization technique that balances sanitization efficiency ( {{\\eta }_{san}} ) and data integrity (RBER). Experimental results show that PULSE eliminates RBER increases in SLC devices and reduces the median RBER to below 0.57% for FG and 0.79% for CT in fresh TLC blocks, demonstrating its practical viability for 3D NAND flash sanitization.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413792148",
    "type": "article"
  },
  {
    "title": "Large or Small: Harnessing the Erase Duality of Emerging Bit-Alterable NAND Flash to Suppress Tail Latency",
    "doi": "https://doi.org/10.1145/3762154",
    "publication_date": "2025-09-01",
    "publication_year": 2025,
    "authors": "Tsun-Yu Yang; Guangliang Yao; Yingjia Wang; Tseng‐Yi Chen; Ming-Chang Yang",
    "corresponding_authors": "",
    "abstract": "High-density NAND flash has revolutionized the storage ecosystem because of its rapidly decreasing per-bit costs and unprecedented capacities. However, the inherent large block size of modern high-density NAND flash inevitably aggravates the reclamation latency (i.e., the time required to reclaim the storage space occupied by the obsolete data), which subsequently prolongs the tail latency of flash-based storage devices. Inspired by the “erase duality” from the emerging bit-alterable NAND flash, this paper proposes a reclamation latency suppressed (RLS) space management design to synergize the strengths of both block-level erase and page-level erase. Taking into account the data update frequency during runtime, RLS enables proactive adjustment of the dual-granularity erase. Moreover, RLS tightly couples the data cluster allocation strategy with a novel dual-granularity space reclamation design, thereby alleviating the reclamation latency. We extensively examine the benefits of RLS with real-world workloads. Our evaluation results reveal that, with the suppressed space reclamation latency, RLS achieves up to 37.51% improvement for both write and read tail latency (latency at the 99.9th percentile) compared with the state-of-the-art approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413876802",
    "type": "article"
  },
  {
    "title": "A Specification Framework for Mixed-Criticality Scheduling Protocols",
    "doi": "https://doi.org/10.1145/3765522",
    "publication_date": "2025-09-01",
    "publication_year": 2025,
    "authors": "Alan Burns; Cliff B. Jones",
    "corresponding_authors": "",
    "abstract": "This paper presents a general formal framework for describing the relationship between a criticality-aware scheduler, a set of application jobs that are assigned different criticality levels, and an environment that generates both work and faults that the run-time system must control. The proposed formalism extends the rely-guarantee approach, which facilitates formal reasoning about the functional behaviour of concurrent systems, to address real-time properties. The exposition of the general framework is supplemented by a seven step approach that enables it to be instantiated to deliver the formal specification of any proposed mixed-criticality scheduling protocol. The expressive power of the approach is explored via a non-trivial instantiation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413876887",
    "type": "article"
  },
  {
    "title": "Adaptive Computing in Memory Meets Conventional Batteryless Platforms",
    "doi": "https://doi.org/10.1145/3765623",
    "publication_date": "2025-09-01",
    "publication_year": 2025,
    "authors": "Khakim Akhunov; Kasım Sinan Yıldırım; Jongouk Choi; Changhee Jung",
    "corresponding_authors": "",
    "abstract": "Computing In-Memory (CIM) with emerging nonvolatile memory (NVM) technologies is promising for batteryless systems since it removes the need for explicit backup and energy-hungry data transfer between the processor and memory. However, existing CIM solutions are not effective in accelerating memory-bound inference tasks efficiently on batteryless systems. They operate at relatively low frequencies, complicate application development, and do not consider energy harvesting dynamics to optimize their throughput. To address the issues, this paper presents a novel CIM-based batteryless computing platform, called Viadotto, that provides efficient and adaptive acceleration for memory-bound computing workloads. Viadotto meets adaptive CIM and microcontroller-based (MCU-based) conventional batteryless platforms for the first time. Basically, Viadotto exposes a programming model supported by its compiler and a pipelined memory controller, which hides low-level CIM operations from applications. Furthermore, its runtime issues CIM operations in an energy-efficient manner and optimizes throughput in a programmer-transparent way by adapting CIM parallelism to react to ambient power dynamics. Our evaluation shows that Viadotto outperforms existing CIM solutions for batteryless systems by 48%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413876894",
    "type": "article"
  },
  {
    "title": "SATGuard: SAT-Driven Countermeasures for Protecting Approximate Circuits from Hardware Trojan",
    "doi": "https://doi.org/10.1145/3766894",
    "publication_date": "2025-09-08",
    "publication_year": 2025,
    "authors": "Vishesh Mishra; Dipesh; Sparsh Mittal; Urbi Chatterjee",
    "corresponding_authors": "",
    "abstract": "Approximate arithmetic circuits have gained prominence in modern computing systems due to their ability to trade accuracy for improved performance and energy efficiency. However, their susceptibility to stealthy Trojan attacks poses a significant security concern. This work analyzes Trojan attacks on approximate circuits, focusing specifically on approximate adders and multipliers. We propose SATGuard, a boolean satisfiability (SAT)-based methodology to identify Trojan activating inputs (TAIs) for all approximate adder and multiplier families. We also claim that TAIs for approximate circuits are analogous to test input patterns for accurate circuits. Subsequently, we propose design-specific countermeasures to safeguard approximate circuits. The proposed countermeasures nullify the Hardware Trojan Horse (HTH)-based accuracy degradation, thus upholding the application-level accuracy requirements. We conduct experiments where potential Trojans are implanted into various approximate adders and multipliers. We evaluate their impact on the error metrics and the quality of results in real-world applications such as image processing and deep neural networks (DNNs). Our findings demonstrate that the proposed methodology successfully reverses the HTH-based accuracy degradation by \\(99.4\\% \\) , and \\(99.8\\% \\) in approximate adders and multipliers, respectively. This improvement is achieved with an average area overhead of 5.3% and a power-delay-product overhead of 7.6% in approximate adders and 1.7% and 1.9% in multipliers, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414062771",
    "type": "article"
  },
  {
    "title": "Exploring Inevitable Waypoints for Unsolvability Explanation in Hybrid Planning Problems",
    "doi": "https://doi.org/10.1145/3767745",
    "publication_date": "2025-09-15",
    "publication_year": 2025,
    "authors": "Mir Md Sajid Sarwar; R. L. Ray",
    "corresponding_authors": "",
    "abstract": "Explaining unsolvability of planning problems is of significant research interest in Explainable AI Planning. A number of research efforts on generating explanations of solutions to planning problems have been reported in AI planning literature. However, explaining the unsolvability of planning problems remains a largely open and understudied problem. A widely practiced approach to plan generation and automated problem solving, in general, is to decompose tasks into sub-problems that help progressively converge towards the goal. In this paper, we propose to adopt the same philosophy of sub-problem identification as a mechanism for analyzing and explaining unsolvability of planning problems in hybrid systems. In particular, for a given unsolvable planning problem, we propose to identify common waypoints, which are universal obstacles to plan existence, in other words, they appear on every plan from the source to the planning goal. This work envisions such waypoints as sub-problems of the planning problem and the unreachability of any of these waypoints as an explanation for the unsolvability of the original planning problem. We propose a novel method of waypoint identification by casting the problem as an instance of the longest common subsequence problem, a widely popular problem in computer science, typically considered as an illustrative example for the dynamic programming paradigm. Once the waypoints are identified, we perform symbolic reachability analysis on them to identify the earliest unreachable waypoint and report it as the explanation of unsolvability. We present experimental results on unsolvable planning problems in hybrid domains.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414207999",
    "type": "article"
  },
  {
    "title": "A New HW/SW Co-Design Approach for Monitored Systems-on-Chip Development",
    "doi": "https://doi.org/10.1145/3769075",
    "publication_date": "2025-09-20",
    "publication_year": 2025,
    "authors": "Giacomo Valente; Vittoriano Muttillo; Luigi Pomante; Daniele Frigioni; Tania Di Mascio",
    "corresponding_authors": "",
    "abstract": "As embedded systems are required to satisfy increasing functional and non-functional requirements, heterogeneous systems-on-chip architectures are progressively adopted. While these complex systems-on-chip deliver high performance, they require efficient coordination of the tasks they carry out. To tackle this challenge, designers often resort to runtime mechanisms allowing the dynamic alignment of application requirements with platform services. In turn, runtime mechanisms require the adoption of on-chip monitoring systems. The integration of on-chip monitoring systems into a system-on-chip results in a monitored system-on-chip. Notwithstanding, this integration risks driving a re-design and a re-implementation of the whole system-on-chip, potentially driving to a time-to-market deadline miss. In the literature, HW/SW co-design approaches for monitored systems-on-chip have been proposed to overcome the problem. However, the existing HW/SW co-design approaches prevent performing a system-level design-space exploration that involves all the monitoring requirements, and they also prevent adequate reuse of existing on-chip monitoring systems. This paper proposes an approach for efficient HW/SW co-design of monitored systems-on-chip, aiming to comprehensively capture all monitoring requirements at the system-level and to perform a system-level design-space exploration to satisfy them, enforcing the reuse of existing on-chip monitoring systems. The proposed approach is validated through two experimental activities, which demonstrate a 24% reduction in total development time for a monitored system-on-chip implemented on FPGA, compared to the customary approach. The results also show that the approach reduces the risk of missing time-to-market deadlines, supports flexible design choices, and enables the reuse of on-chip monitoring systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414371548",
    "type": "article"
  },
  {
    "title": "<i>CapDYN</i> : Adaptive Self-Scaling Energy Storage for Powering Batteryless IoT",
    "doi": "https://doi.org/10.1145/3737288",
    "publication_date": "2025-07-08",
    "publication_year": 2025,
    "authors": "Maria Doglioni; Eren Yıldız; Matteo Nardello; Khakim Akhunov; Kasım Sinan Yıldırım; Davide Brunelli",
    "corresponding_authors": "",
    "abstract": "Battery-free devices collect the harvested ambient energy in their energy storage capacitors. The size of the storage capacitor is one of the main factors affecting the device’s active time and power failure rate. In fact, a larger capacitor ensures energy autonomy for longer operations, while a smaller capacitor charges faster and shrinks inefficient cold starts. This paper presents CapDYN , a new energy storage architecture that can self-adapt its capacity based on incoming ambient energy. CapDYN automatically reconfigures the size of its capacitor bank to both speed up charging and improve execution rate. CapDYN reduces the startup time by up to 98% and can schedule tasks up to 38% faster, compared to a fixed-size capacitor. CapDYN operates in a fully autonomous manner consuming down to 11.6 µW in its simplest implementation and replaces the power-hungry microcontroller governing the switching operation with a dedicated ultra-low-power circuit built with COTS components. Its power consumption improves the previous state of the art by 73%, all the while featuring uncompromising reactivity. CapDYN can instantly react to sudden power transients without incurring extra power draw by foregoing MCU-driven reconfiguration used in state-of-the-art dynamic energy storages.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414630572",
    "type": "article"
  },
  {
    "title": "A Thread-level Stream Scheduling Method for Accelerating LVMs' Inference on a Resource-constrained Platform",
    "doi": "https://doi.org/10.1145/3771550",
    "publication_date": "2025-10-09",
    "publication_year": 2025,
    "authors": "Yijie Chen; Jiaqi Han; Bin Liu; Xuannan Zhang; Z. Q. Hu; Rongyu Dou; Keqin Li",
    "corresponding_authors": "",
    "abstract": "As a new generation of edge devices, the integrated CPU/GPU architecture has opened up new opportunities for deploying different scale vision models. In order to reduce models’ inference time on the integrated devices, this paper first compresses deep learning models using model quantization. The quantization process greatly reduces the computation requirements of a model, which enables its deployment on embedded development boards. However, quantization also leads to lower GPU resource utilization during inference on integrated devices. This insufficient utilization results in slower inference speed. To address this problem, this paper first depicts the data flow of model inference within an integrated device. Secondly, this paper implements a unified memory management between the CPU and GPU based on managed memory strategy. Finally, this paper designs a thread-level stream scheduling method to improve GPU utilization and throughput during model inference in a pipeline way. Experimental results show that the proposed method achieves a 2x-10x improvement in throughput compared to the TensorRT’s default scheduling method, which is crucial for realizing real-time inference tasks on edge devices.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414982174",
    "type": "article"
  },
  {
    "title": "EStacker: Explaining Battery-Less IoT System Performance with Energy Stacks",
    "doi": "https://doi.org/10.1145/3772371",
    "publication_date": "2025-10-21",
    "publication_year": 2025,
    "authors": "Lukas Liedtke; Per Gunnar Kjeldsberg; Frank Alexander Kraemer; Magnus Jahre",
    "corresponding_authors": "",
    "abstract": "The number of Internet of Things (IoT) devices is increasing exponentially, and it is environmentally and economically unsustainable to power all these devices with batteries. The key alternative is energy harvesting, but battery-less IoT systems require extensive evaluation to demonstrate that they are sufficiently performant across the full range of expected operating conditions. IoT developers thus need an evaluation platform that (i) ensures that each evaluated application and configuration is exposed to exactly the same energy environment and events, and (ii) provides a detailed account of what the application spends the harvested energy on. We therefore developed the EStacker evaluation platform which (i) enables fair and repeatable evaluation, and (ii) generates energy stacks. Energy stacks break down the total energy consumption of an application across hardware components and application activities, thereby explaining what the application specifically uses energy on. We augment EStacker with the ST-SP optimization which, in our experiments, reduces evaluation time by 6.3 × on average while retaining the temporal behavior of the battery-less IoT system (average throughput error of 7.7%) by proportionally scaling time and power. We demonstrate the utility of EStacker through two case studies. In the first case study, we use energy stack profiles to identify a performance problem that, once addressed, improves performance by 3.3 ×. The second case study focuses on ST-SP, and we use it to explore the design space required to dimension the harvester and energy storage sizes of a smart parking application in roughly one week (7.7 days). Without ST-SP, sweeping this design space would have taken well over one month (41.7 days).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415412828",
    "type": "article"
  },
  {
    "title": "Compiling with code-size constraints",
    "doi": "https://doi.org/10.1145/972627.972635",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Mayur Naik; Jens Palsberg",
    "corresponding_authors": "",
    "abstract": "Most compilers ignore the problems of limited code space in embedded systems. Designers of embedded software often have no better alternative than to manually reduce the size of the source code or even the compiled code. Besides being tedious and error prone, such optimization results in obfuscated code that is difficult to maintain and reuse. In this paper, we present a step towards code-size-aware compilation. We phrase register allocation and code generation as an integer linear programming problem where the upper bound on the code size can simply be expressed as an additional constraint. The resulting compiler, when applied to six commercial microcontroller programs, generates code nearly as compact as carefully crafted code.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2036000779",
    "type": "article"
  },
  {
    "title": "A split-mask countermeasure for low-energy secure embedded systems",
    "doi": "https://doi.org/10.1145/1165780.1165783",
    "publication_date": "2006-08-01",
    "publication_year": 2006,
    "authors": "Catherine H. Gebotys",
    "corresponding_authors": "Catherine H. Gebotys",
    "abstract": "Future wireless embedded devices will be increasingly powerful, supporting many more applications, including one of the most crucial---security. Although many embedded devices offer more resistance to bus---probing attacks because of their compact size, susceptibility to power or electromagnetic analysis attacks must be analyzed. This paper presents a new split-mask countermeasure to thwart low-order differential power analysis (DPA) and differential EM analysis (DEMA). For the first time, real-power and EM measurements are used to analyze the difficulty of launching new third-order DPA and DEMA attacks on a popular low-energy 32-bit embedded ARM processor. Results show that the new split-mask countermeasure provides increased security without large overheads of energy dissipation, compared to previous research. With the emergence of security applications in PDAs, cell phones, and other embedded devices, low-energy countermeasures for resistance to low-order DPA/DEMA is crucial for supporting future enabled wireless internet.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2028894887",
    "type": "article"
  },
  {
    "title": "Reducing data cache leakage energy using a compiler-based approach",
    "doi": "https://doi.org/10.1145/1086519.1086529",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Wei Zhang; Mahmut Kandemir; Mustafa Karaköy; Guangyu Chen",
    "corresponding_authors": "",
    "abstract": "Silicon technology advances have made it possible to pack millions of transistors---switching at high clock speeds---on a single chip. While these advances bring unprecedented performance to electronic products, they also pose difficult power/energy consumption problems. For example, large number of transistors in dense on-chip cache memories consume significant static (leakage) power even if the cache is not used by the current computation. While previous compiler research studied code and data restructuring for improving data cache performance, to our knowledge, there exists no compiler-based study that targets data cache leakage power consumption. In this paper, we present code restructuring techniques for array-based and pointer-intensive applications for reducing data cache leakage energy consumption. The idea is to let the compiler analyze the application code and insert instructions that turn off cache lines that keep variables not used by the current computation. This turning-off does not destroy contents of a cache line and waking up the cache line (when it is accessed later) does not incur much overhead. Due to inherent data locality in applications, we find that, at a given time, only a small portion of the data cache needs to be active; the remaining part can be placed into a leakage-saving mode (state); i.e., they can be turned off. Our experimental results indicate that the proposed compiler-based strategy reduces the cache energy consumption significantly. We also demonstrate how different compiler optimizations can increase the effectiveness of our strategy.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2082817761",
    "type": "article"
  },
  {
    "title": "Accurate and fast system-level power modeling",
    "doi": "https://doi.org/10.1145/1347375.1347378",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Ankush Varma; Eric Debes; I. Kozintsev; Paul Klein; Bruce Jacob",
    "corresponding_authors": "",
    "abstract": "Accurate and fast system modeling is central to the rapid design space exploration needed for embedded-system design. With fast, complex SoCs playing a central role in such systems, system designers have come to require MIPS-range simulation speeds and near-cycle accuracy. The sophisticated simulation frameworks that have been developed for high-speed system performance modeling do not address power consumption, although it is a key design constraint. In this paper, we define a simulation-based methodology for extending system performance modeling frameworks to also include power modeling. We demonstrate the use of this methodology with a case study of a real, complex embedded system, comprising the Intel XScale embedded microprocessor, its WMMX SIMD co processor, L1 caches, SDRAM, and the on-board address and data buses. We describe detailed power models for each of these components and validate them against physical measurements from hardware, demonstrating that such frameworks enable designers to model both power and performance at high speeds without sacrificing accuracy. Our results indicate that the power estimates obtained are accurate within 5% of physical measurements from hardware, while simulation speeds consistently exceed a million instructions per second (MIPS).",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4243217195",
    "type": "article"
  },
  {
    "title": "MTSS",
    "doi": "https://doi.org/10.1145/1376804.1376814",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Bhuvan Middha; Matthew Simpson; Rajeev Barua",
    "corresponding_authors": "",
    "abstract": "Out-of-memory errors are a serious source of unreliability in most embedded systems. Applications run out of main memory because of the frequent difficulty of estimating the memory requirement before deployment, either because it depends on input data, or because certain language features prevent estimation. The typical lack of disks and virtual memory in embedded systems has a serious consequence when an out-of-memory error occurs. Without swap space, the system crashes if its memory footprint exceeds the available memory by even 1 byte. This work improves reliability for multitasking embedded systems by proposing MTSS, a multitask stack sharing technique. If a task attempts to overflow the bounds of its allocated stack space, MTSS grows its stack into the stack memory space allocated for other tasks. This technique can avoid the out-of-memory error if the extra space recovered is sufficient to complete execution. Experiments show that MTSS is able to recover an average of 54% of the stack space allocated to the overflowing task in the free space of other tasks. In addition, unlike conventional systems, MTSS detects memory overflows, allowing the possibility of remedial action or a graceful exit if the recovered space is not enough. Alternatively, MTSS can be used for decreasing the required physical memory of an embedded system by reducing the initial memory allocated to each of the tasks and recovering the deficit by sharing stack with other tasks. The overheads of MTSS are low: the runtime and energy overheads are 3.1% and 3.2%, on average. These are tolerable given that reliability is the most important concern in virtually all systems, ahead of other concerns, such as runtime and energy.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1976837639",
    "type": "article"
  },
  {
    "title": "Improving SDRAM access energy efficiency for low-power embedded systems",
    "doi": "https://doi.org/10.1145/1347375.1347377",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Jelena Trajković; Alexander V. Veidenbaum; Arun Kejariwal",
    "corresponding_authors": "",
    "abstract": "DRAM (dynamic random-access memory) energy consumption in low-power embedded systems can be very high, exceeding that of the data cache or even that of the processor. This paper presents and evaluates a scheme for reducing the energy consumption of SDRAM (synchronous DRAM) memory access by a combination of techniques that take advantage of SDRAM energy efficiencies in bank and row access. This is achieved by using small, cachelike structures in the memory controller to prefetch an additional cache block(s) on SDRAM reads and to combine block writes to the same SDRAM row. The results quantify the SDRAM energy consumption of MiBench applications and demonstrate significant savings in SDRAM energy consumption, 23%, on average, and reduction in the energy-delay product, 44%, on average. The approach also improves performance: the CPI is reduced by 26%, on average.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2010855801",
    "type": "article"
  },
  {
    "title": "A novel software framework for embedded multiprocessor smart cameras",
    "doi": "https://doi.org/10.1145/1509288.1509296",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Andreas Doblander; Andreas Zoufal; Bernhard Rinner",
    "corresponding_authors": "",
    "abstract": "Distributed smart cameras (DSC) are an emerging technology for a broad range of important applications including smart rooms, surveillance, entertainment, tracking, and motion analysis. By having access to many views and through cooperation among the individual cameras, these DSCs have the potential to realize many more complex and challenging applications than single-camera systems. This article focuses on the system-level software required for efficient streaming applications on single smart cameras as well as on networks of DSCs. Embedded platforms with limited resources do not provide middleware services well known on general-purpose platforms. Our software framework supports transparent intra- and interprocessor communication while keeping the memory and computation overhead very low. The software framework is based on a publisher--subscriber architecture and provides mechanisms for dynamically loading and unloading software components as well as for graceful degradation in case of software- and hardware-related faults. The software framework has been completely implemented and tested on our embedded smart cameras consisting of an ARM-based network processor and several digital signal processors. Two case studies demonstrate the feasibility of our approach.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1989242507",
    "type": "article"
  },
  {
    "title": "A polynomial algorithm for partitioning problems",
    "doi": "https://doi.org/10.1145/1721695.1721700",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Seyed-Abdoreza Tahaee; Amir Hossein Jahangir",
    "corresponding_authors": "",
    "abstract": "This article takes a theoretical approach to focus on the algorithmic properties of hardware/software partitioning. It proposes a method with polynomial complexity to find the global optimum of an NP-hard model partitioning problem for 75% of occurrences under some practical conditions. The global optimum is approached with a lower bound distance for the remaining 25%. Furthermore, this approach ensures finding the 2-approximate of the global optimum partition in 97% of instances where technical assumptions exist. The strategy is based on intelligently changing the parameters of the polynomial model of the partitioning problem to force it to produce (or approach) the exact solution to the NP-hard model.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1990575324",
    "type": "article"
  },
  {
    "title": "Efficient off-board deployment and customization of virtual machine-based embedded systems",
    "doi": "https://doi.org/10.1145/1698772.1698779",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Alexandre Courbot; Gilles Grimaud; Jean-Jacques Vandewalle",
    "corresponding_authors": "",
    "abstract": "This article presents a new way to deploy and customize embedded virtual machine based operating systems for very restrained devices. Due to the specificity of restrained embedded devices (large usage of read-only memory, very few writable memory available, …), these systems are typically deployed off-board, in a process called romization . However, current romization solutions do not allow a complete deployment to take place outside of the execution device: they are capable of converting system components and applications into their executable form, but are unable to perform any operation that would require the system to be running. This results in a good part of the deployment being performed by the target device, at the cost of longer startup times, bloat with code and data that are only executed once at startup, and suboptimal memory placement of data structures. In this article, we propose a new romization scheme that allows the system to be started within a virtual execution environment, and thus to be fully deployed off-board before being transferred to its real execution support. We then take advantage of all the information provided by the deployed state in order to analyze and customize it, resulting in a very low-footprint, custom-tailored embedded system. The Java platform is used as a support to implement our romization architecture and perform our experiments. For the evaluated set of embedded applications, we were able to obtain embedded systems which memory footprint was lower than their J2ME counterpart, while being based on a full-fledged J2SE environment.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1983550253",
    "type": "article"
  },
  {
    "title": "Randomized Instruction Injection to Counter Power Analysis Attacks",
    "doi": "https://doi.org/10.1145/2345770.2345782",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Jude Angelo Ambrose; Roshan Ragel; Sri Parameswaran",
    "corresponding_authors": "",
    "abstract": "Side-channel attacks in general and power analysis attacks in particular are becoming a major security concern in embedded systems. Countermeasures proposed against power analysis attacks are data and table masking, current flattening, dummy instruction insertion and bit-flips balancing. All these techniques are either susceptible to multi-order power analysis attack, not sufficiently generic to cover all encryption algorithms, or burden the system with high area, run-time or energy cost. In this article, we propose a randomized instruction injection technique ( RIJID ) that overcomes the pitfalls of previous countermeasures. RIJID scrambles the power profile of a cryptographic application by injecting random instructions at random points of execution and therefore protects the system against power analysis attacks. Two different ways of triggering the instruction injection are also presented: (1) softRIJID , a hardware/software approach, where special instructions are used in the code for triggering the injection at runtime; and (2) autoRIJID , a hardware approach, where the code injection is triggered by the processor itself via detecting signatures of encryption routines at runtime. A novel signature detection technique is also introduced for identifying encryption routines within application programs at runtime. Further, a simple obfuscation metric ( RIJIDindex ) based on cross-correlation that measures the scrambling provided by any code injection technique is introduced, which coarsely indicates the level of scrambling achieved. Our processor models cost 1.9% additional area in the hardware/software approach and 1.2% in the hardware approach for a RISC based processor, and costs on average 29.8% in runtime and 27.1% in energy for the former and 25.0% in runtime and 28.5% in energy for the later, for industry standard cryptographic applications.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2006146291",
    "type": "article"
  },
  {
    "title": "Generating Invariant-Based Certificates for Embedded Systems",
    "doi": "https://doi.org/10.1145/2220336.2220346",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Jan Olaf Blech; Michaël Périn",
    "corresponding_authors": "",
    "abstract": "Automatic verification tools, such as model checkers and tools based on static analysis or on abstract interpretation, have become popular in software and hardware development. They increase confidence and potentially provide rich feedback. However, with increasing complexity, verification tools themselves are more likely to contain errors. In contrast to automatic verification tools, higher-order theorem provers use mathematically founded proof strategies checked by a small proof checker to guarantee selected properties. Thus, they enjoy a high level of trustability. Properties of software and hardware systems and their justifications can be encapsulated into a certificate, thereby guaranteeing correctness of the systems, with respect to the properties. These results offer a much higher degree of confidence than results achieved by verification tools. However, higher-order theorem provers are usually slow, due to their general and minimalistic nature. Even for small systems, a lot of human interaction is required for establishing a certificate. In this work, we combine the advantages of automatic verification tools (i.e., speed and automation) with those of higher-order theorem provers (i.e., high level of trustability). The verification tool generates a certificate for each invocation. This is checked by the higher-order theorem prover, thereby guaranteeing the desired property. The generation of certificates is much easier than producing the analysis results of the verification tool in the first place. In our work, we are able to create certificates that come with an algorithmic description of the proof of the desired property as justification. We concentrate on verification tools that generate invariants of systems and certify automatically that these do indeed hold. Our approach is applied to the certification of the verdicts of a deadlock-detection tool for an asynchronous component-based language.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2028104839",
    "type": "article"
  },
  {
    "title": "Efficient asynchronous event handling in the real-time specification for Java",
    "doi": "https://doi.org/10.1145/1814539.1814544",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Minseong Kim; Andy Wellings",
    "corresponding_authors": "",
    "abstract": "The Real-Time Specification for Java (RTSJ) is becoming mature. It has been implemented, formed the basis for research and used in serious applications. Some strengths and weaknesses are emerging. One of the areas that requires further elaboration is asynchronous event handling (AEH). The primary goal for handlers in the RTSJ is to have a lightweight concurrency mechanism. Some implementation will, however, simply map a handler to a real-time thread and this results in undermining the original motivations and introduces performance penalties. However it is generally unclear how to map handlers to real-time threads effectively. Also the support for nonblocking handlers in the RTSJ is criticized as lacking in configurability as implementations are unable to take advantage of them. This article, therefore, examines the AEH techniques used in some popular RTSJ implementations and proposes two efficient AEH models for the RTSJ. We then define formal models of the RTSJ AEH implementations using the automata formalism provided by the UPPAAL model checking tool. Using the automata models, their properties are explored and verified. In the proposed models, blocking and nonblocking handlers are serviced by different algorithms. In this way, it is possible to assign a real-time thread to a handler at the right time in the right place while maintaining the fewest possible threads overall and to give a certain level of configurability to AEH. We also have implemented the proposed models on an existing RTSJ implementation, jRate and executed a set of performance tests that measure their respective dispatch and multiple-handler completion latencies. The results from the tests and the verifications indicate that the proposed models require fewer threads on average with better performance than other approaches.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2052757399",
    "type": "article"
  },
  {
    "title": "Sensor Node Localization with Uncontrolled Events",
    "doi": "https://doi.org/10.1145/2345770.2345777",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Ziguo Zhong; Tian He",
    "corresponding_authors": "",
    "abstract": "Event-driven localization has been proposed as a low-cost solution for node positioning in wireless sensor networks. In order to eliminate the costly requirement for accurate event control in existing methods, we present a practical design using uncontrolled events. The main idea is to estimate both event generation parameters and the location of sensor nodes simultaneously, by processing node sequences that can be easily obtained from event detections. Besides the basic design, we proposed two enhancements to further extract information embedded in node orderings for two scenarios: (i) node density is high; and (ii) abundant events are available. To demonstrate the generality of our design, both straight-line scan and circular wave propagation events are addressed in the article, and we evaluated the design with extensive simulation as well as a testbed implementation with 41 MICAz motes. Results show that with only randomly generated events, our design can effectively localize nodes with great flexibility while adding little extra cost at the resource constrained sensor node side. In addition, localization via uncontrolled events provides a potential option of achieving node positioning through long-term ambient events.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2110349850",
    "type": "article"
  },
  {
    "title": "Performance Analysis of Reconfigurations in Adaptive Real-Time Streaming Applications",
    "doi": "https://doi.org/10.1145/2180887.2180888",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Jun Zhu; Ingo Sander; Axel Jantsch",
    "corresponding_authors": "",
    "abstract": "We propose a performance analysis framework for adaptive real-time synchronous data flow streaming applications on runtime reconfigurable FPGAs. As the main contribution, we present a constraint based approach to capture both streaming application execution semantics and the varying design concerns during reconfigurations. With our event models constructed as cumulative functions on data streams, we exploit a novel compile-time analysis framework based on iterative timing phases. Finally, we implement our framework on a public domain constraint solver, and illustrate its capabilities in the analysis of design trade-offs due to reconfigurations with experiments.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2114353856",
    "type": "article"
  },
  {
    "title": "Efficient hardware-based nonintrusive dynamic application profiling",
    "doi": "https://doi.org/10.1145/1952522.1952525",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "A. P. Nair; Karthik Shankar; Roman Lysecky",
    "corresponding_authors": "",
    "abstract": "Application profiling—the process of monitoring an application to determine the frequency of execution within specific regions—is an essential step within the design process for many software and hardware systems. Profiling is often a critical step within hardware/software partitioning utilized to determine the critical kernels of an application. In this article, we present an innovative, nonintrusive dynamic application profiler (DAProf) capable of profiling an executing application by monitoring the application's short backward branches, function calls, and function returns. The resulting profile information provides an accurate characterization of the frequently executed loops within the application providing a breakdown of loop executions versus loop iterations per execution. DAProf achieves excellent profiling accuracy with an average accuracy of 98% for loop executions, 97% for average iterations per execution, and 95% for percentage of execution time. In addition, the presented dynamic application profiler incurs as little as 11% area overhead compared to an ARM9 microprocessor. DAProf is ideally suited for rapidly profiling software applications and dynamic optimization approaches such as dynamic hardware/software partitioning in which detailed loop execution information is needed to provide accurate performance estimates.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2131575835",
    "type": "article"
  },
  {
    "title": "A Multi-Quadcopter Cooperative Cyber-Physical System for Timely Air Pollution Localization",
    "doi": "https://doi.org/10.1145/3005716",
    "publication_date": "2017-04-28",
    "publication_year": 2017,
    "authors": "Zhaoyan Shen; Zhijian He; Shuai Li; Qixin Wang; Zili Shao",
    "corresponding_authors": "",
    "abstract": "We propose a cyber-physical system of unmanned quadcopters to locate air pollution sources in a timely manner. The system consists of a physical part and a cyber part. The physical part includes unmanned quadcopters equipped with multiple sensors. The cyber part carries out control laws. We simplify the control laws by decoupling the quadcopters’ horizontal-plane motion control from vertical motion control. To control the quadcopter’s horizontal-plane motions, we propose a controller that combines pollutant dynamics with quadcopter physics. To control the quadcopter’s vertical motions, we adopt an anti-windup proportional-integral (PI) controller. We further extend the horizontal-plane control laws from a single quadcopter to multiple quadcopters. The multi-quadcopter control laws are distributed and convergent. We implement a prototype quadcopter and carry out experiments to verify the vertical control laws. We also carry out simulations to evaluate the horizontal-plane control laws. With quadcopter parameters set commensurate with our prototype implementation’s, our simulations show that the control laws can drive quadcopters to locate pollution source(s) in a timely way.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2609174993",
    "type": "article"
  },
  {
    "title": "Timing Analysis of Synchronous Programs using WCRT Algebra",
    "doi": "https://doi.org/10.1145/3126520",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Jiajie Wang; Michael Mendler; Partha S. Roop; Bruno Bodin",
    "corresponding_authors": "",
    "abstract": "Synchronous languages are ideal for designing safety-critical systems. Static Worst-Case Reaction Time (WCRT) analysis is an essential component in the design flow that ensures the real-time requirements are met. There are a few approaches for WCRT analysis, and the most versatile of all is explicit path enumeration. However, as synchronous programs are highly concurrent, techniques based on this approach, such as model checking, suffer from state explosion as the number of threads increases. One observation on this problem is that these existing techniques analyse the program by enumerating a functionally equivalent automaton while WCRT is a non-functional property. This mismatch potentially causes algorithm-induced state explosion. In this paper, we propose a WCRT analysis technique based on the notion of timing equivalence, expressed using WCRT algebra. WCRT algebra can effectively capture the timing behaviour of a synchronous program by converting its intermediate representation Timed Concurrent Control Flow Graph (TCCFG) into a Tick Cost Automaton (TCA), a minimal automaton that is timing equivalent to the original program. Then the WCRT is computed over the TCA. We have implemented our approach and benchmarked it against state-of-the-art WCRT analysis techniques. The results show that the WCRT algebra is 3.5 times faster on average than the fastest published technique.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2754828231",
    "type": "article"
  },
  {
    "title": "Compositional Relational Abstraction for Nonlinear Hybrid Systems",
    "doi": "https://doi.org/10.1145/3126522",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Xin Chen; Sergio Mover; Sriram Sankaranarayanan",
    "corresponding_authors": "",
    "abstract": "We propose techniques to construct abstractions for nonlinear dynamics in terms of relations expressed in linear arithmetic. Such relations are useful for translating the closed loop verification problem of control software with continuous-time, nonlinear plant models into discrete and linear models that can be handled by efficient software verification approaches for discrete-time systems. We construct relations using Taylor model based flowpipe construction and the systematic composition of relational abstractions for smaller components. We focus on developing efficient schemes for the special case of composing abstractions for linear and nonlinear components. We implement our ideas using a relational abstraction system, using the resulting abstraction inside the verification tool NuXMV, which implements numerous SAT/SMT solver-based verification techniques for discrete systems. Finally, we evaluate the application of relational abstractions for verifying properties of time triggered controllers, comparing with the Flow* tool. We conclude that relational abstractions are a promising approach towards nonlinear hybrid system verification, capable of proving properties that are beyond the reach of tools such as Flow*. At the same time, we highlight the need for improvements to existing linear arithmetic SAT/SMT solvers to better support reasoning with large relational abstractions.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2757091317",
    "type": "article"
  },
  {
    "title": "Using Criticality of GPU Accesses in Memory Management for CPU-GPU Heterogeneous Multi-Core Processors",
    "doi": "https://doi.org/10.1145/3126540",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Siddharth Rai; Mainak Chaudhuri",
    "corresponding_authors": "",
    "abstract": "Heterogeneous chip-multiprocessors with CPU and GPU integrated on the same die allow sharing of critical memory system resources among the CPU and GPU applications. Such architectures give rise to challenging resource scheduling problems. In this paper, we explore memory access scheduling algorithms driven by criticality of GPU accesses in such systems. Different GPU access streams originate from different parts of the GPU rendering pipeline, which behaves very differently from the typical CPU pipeline requiring new techniques for GPU access criticality estimation. We propose a novel queuing network model to estimate the performance-criticality of the GPU access streams. If a GPU application performs below the quality of service requirement (e.g., frame rate in 3D scene rendering), the memory access scheduler uses the estimated criticality information to accelerate the critical GPU accesses. Detailed simulations done on a heterogeneous chip-multiprocessor model with one GPU and four CPU cores running heterogeneous mixes of DirectX, OpenGL, and CPU applications show that our proposal improves the GPU performance by 15% on average without degrading the CPU performance much. Extensions proposed for the mixes containing GPGPU applications, which do not have any quality of service requirement, improve the performance by 7% on average for these mixes.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2759306360",
    "type": "article"
  },
  {
    "title": "Efficient Virtual Memory Sharing via On-Accelerator Page Table Walking in Heterogeneous Embedded SoCs",
    "doi": "https://doi.org/10.1145/3126560",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Pirmin Vogel; Andreas Kurth; Johannes Weinbuch; Andrea Marongiu; Luca Benini",
    "corresponding_authors": "",
    "abstract": "Shared virtual memory is key in heterogeneous systems on chip (SoCs) that combine a general-purpose host processor with a many-core accelerator, both for programmability and performance. In contrast to the full-blown, hardware-only solutions predominant in modern high-end systems, lightweight hardware-software co-designs are better suited in the context of more power- and area-constrained embedded systems and provide additional benefits in terms of flexibility and predictability. As a downside, the latter solutions require the host to handle in software synchronization in case of page misses as well as miss handling. This may incur considerable run-time overheads. In this work, we present a novel hardware-software virtual memory management approach for many-core accelerators in heterogeneous embedded SoCs. It exploits an accelerator-side helper thread concept that enables the accelerator to manage its virtual memory hardware autonomously while operating cache-coherently on the page tables of the user-space processes of the host. This greatly reduces overhead with respect to host-side solutions while retaining flexibility. We have validated the design with a set of parameterizable benchmarks and real-world applications covering various application domains. For purely memory-bound kernels, the accelerator performance improves by a factor of 3.8 compared with host-based management and lies within 50% of a lower-bound ideal memory management unit.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2759541633",
    "type": "article"
  },
  {
    "title": "Efficient and Reliable Error Detection Architectures of Hash-Counter-Hash Tweakable Enciphering Schemes",
    "doi": "https://doi.org/10.1145/3159173",
    "publication_date": "2018-01-23",
    "publication_year": 2018,
    "authors": "Mehran Mozaffari Kermani; Reza Azarderakhsh; Ausmita Sarker; Amir Jalali",
    "corresponding_authors": "",
    "abstract": "Through pseudorandom permutation, tweakable enciphering schemes (TES) constitute block cipher modes of operation which perform length-preserving computations. The state-of-the-art research has focused on different aspects of TES, including implementations on hardware [field-programmable gate array (FPGA)/ application-specific integrated circuit (ASIC)] and software (hard/soft-core microcontrollers) platforms, algorithmic security, and applicability to sensitive, security-constrained usage models. In this article, we propose efficient approaches for protecting such schemes against natural and malicious faults. Specifically, noting that intelligent attackers do not merely get confined to injecting multiple faults, one major benchmark for the proposed schemes is evaluation toward biased and burst fault models. We evaluate a variant of TES, i.e., the Hash-Counter-Hash scheme, which involves polynomial hashing as other variants are either similar or do not constitute finite field multiplication which, by far, is the most involved operation in TES. In addition, we benchmark the overhead and performance degradation on the ASIC platform. The results of our error injection simulations and ASIC implementations show the suitability of the proposed approaches for a wide range of applications including deeply embedded systems.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2787685625",
    "type": "article"
  },
  {
    "title": "Compositional Dataflow Circuits",
    "doi": "https://doi.org/10.1145/3274280",
    "publication_date": "2019-01-25",
    "publication_year": 2019,
    "authors": "Stephen A. Edwards; Richard Townsend; Martha Barker; Martha A. Kim",
    "corresponding_authors": "",
    "abstract": "We present a technique for implementing dataflow networks as compositional hardware circuits. We first define an abstract dataflow model with unbounded buffers that supports data-dependent blocks (mux, demux, and nondeterministic merge); we then show how to faithfully implement such networks with bounded buffers and handshaking. Handshaking admits compositionality: our circuits can be connected with or without buffers, and combinational cycles arise only from a completely unbuffered cycle. While bounding buffer sizes can cause the system to deadlock prematurely, the system is guaranteed to produce the same, correct, data before then. Thus, unless the system deadlocks, inserting or removing buffers only affects its performance. We demonstrate how this enables design space to be explored.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2913417348",
    "type": "article"
  },
  {
    "title": "FLORA",
    "doi": "https://doi.org/10.1145/3358202",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Biruk Seyoum; Alessandro Biondi; Giorgio Buttazzo",
    "corresponding_authors": "",
    "abstract": "Floorplanning is a mandatory step in the design of hardware accelerators for FPGA platforms, especially when adopting dynamic partial reconfiguration (DPR). This paper presents FLORA, an automated floorplanner based on optimization via Mixed-Integer Linear Programming (MILP). The floorplanning problem is solved by means of a novel fine-grained modeling strategy of FPGA resources. Furthermore, differently from other proposals, our approach takes into account several realistic Partial Reconfiguration (PR) floorplanning constraints on FPGAs. FLORA was compared against state-of-the-art floorplanners by means of benchmark suites, showing that it is capable of providing better performance in terms of resource consumption, maximum inter-region, wire-length, and running time required to produce the solutions. Finally, FLORA was utilized to generate placements for a partially-reconfigurable video processing engine that was implemented on a Xilinx Zynq-7020.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2979970871",
    "type": "article"
  },
  {
    "title": "Response Time Analysis for Tasks with Fixed Preemption Points under Global Scheduling",
    "doi": "https://doi.org/10.1145/3360513",
    "publication_date": "2019-09-30",
    "publication_year": 2019,
    "authors": "Quan Zhou; Guohui Li; Jianjun Li; Chenggang Deng; Ling Yuan",
    "corresponding_authors": "",
    "abstract": "As an effective method for detecting the schedulability of real-time tasks on multiprocessor platforms, Response time analysis (RTA) has been deeply researched in recent decades. Most of the existing RTA methods are designed for tasks that can be preempted at any time. However, in some real-time systems, a task may have some fixed preemption points (FPPs) that divide its execution into a series of non-preemptive regions (NPRs). In such environments, the task can only be preempted at its FPPs, which makes existing RTA methods for arbitrary preemption tasks not applicable. In this article, we study the schedulability analysis on tasks with FPPs under both global fixed-priority (G-FP) scheduling and global earliest deadline first (G-EDF) scheduling. First, based on the idea of limiting the time interval between two consecutive executions of an NPR, a novel RTA method for tasks with FPPs under G-FP scheduling is proposed. Second, we propose an effective RTA method for tasks with FPPs under G-EDF scheduling. Finally, extensive simulations are conducted and the results validate the effectiveness of the proposed methods.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2980054296",
    "type": "article"
  },
  {
    "title": "Weakly-hard Real-time Guarantees for Earliest Deadline First Scheduling of Independent Tasks",
    "doi": "https://doi.org/10.1145/3356865",
    "publication_date": "2019-11-30",
    "publication_year": 2019,
    "authors": "Zain A. H. Hammadeh; Sophie Quinton; Rolf Ernst",
    "corresponding_authors": "",
    "abstract": "The current trend in modeling and analyzing real-time systems is toward tighter yet safe timing constraints. Many practical real-time systems can de facto sustain a bounded number of deadline-misses, i.e., they have Weakly-Hard Real-Time (WHRT) constraints rather than hard real-time constraints. Therefore, we strive to provide tight Deadline Miss Models (DMMs) in complement to tight response time bounds for such systems. In this work, we bound the distribution of deadline-misses for task sets running on uniprocessors using the Earliest Deadline First (EDF) scheduling policy. We assume tasks miss their deadlines due to transient overload resulting from sporadic jobs, e.g., interrupt service routines. We use Typical Worst-Case Analysis (TWCA) to tackle the problem in this context. Also, we address the sources of pessimism in computing DMMs, and we discuss the limitations of the proposed analysis. This work is motivated by and validated on a realistic case study inspired by industrial practice (satellite on-board software) and on a set of synthetic test cases. The synthetic experiment is dedicated to extensively study the impact of EDF on DMMs by presenting a comparison between DMMs computed under EDF and Rate Monotonic (RM). The results show the usefulness of this approach for temporarily overloaded systems when EDF scheduling is considered. They also show that EDF is especially useful for WHRT tasks.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2996020468",
    "type": "article"
  },
  {
    "title": "Efficient Schedulability Test for Dynamic-Priority Scheduling of Mixed-Criticality Real-Time Systems",
    "doi": "https://doi.org/10.1145/3105922",
    "publication_date": "2017-11-22",
    "publication_year": 2017,
    "authors": "Xiaozhe Gu; Arvind Easwaran",
    "corresponding_authors": "",
    "abstract": "Systems in many safety-critical application domains are subject to certification requirements. In such a system, there are typically different applications providing functionalities that have varying degrees of criticality. Consequently, the certification requirements for functionalities at these different criticality levels are also varying, with very high levels of assurance required for a highly critical functionality, whereas relatively low levels of assurance required for a less critical functionality. Considering the timing assurance given to various applications in the form of guaranteed budgets within deadlines, a theory of real-time scheduling for such multi-criticality systems has been under development in the recent past. In particular, an algorithm called Earliest Deadline First with Virtual Deadlines (EDF-VD) has shown a lot of promise for systems with two criticality levels, especially in terms of practical performance demonstrated through experiment results. In this paper we design a new schedulability test for EDF-VD that extend these performance benefits to multi-criticality systems. We propose a new test based on demand bound functions and also present a novel virtual deadline assignment strategy. Through extensive experiments we show that the proposed technique significantly outperforms existing strategies for a variety of generic real-time systems.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3125202098",
    "type": "article"
  },
  {
    "title": "Verification of Safety and Liveness Properties of Metric Transition Systems",
    "doi": "https://doi.org/10.1145/2331147.2331164",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Antoine Girard; Gang Zheng",
    "corresponding_authors": "",
    "abstract": "We consider verification problems for transition systems enriched with a metric structure. We believe that these metric transition systems are particularly suitable for the analysis of cyber-physical systems in which metrics can be naturally defined on the numerical variables of the embedded software and on the continuous states of the physical environment. We consider verification of bounded and unbounded safety properties, as well as bounded liveness properties. The transition systems we consider are nondeterministic, finitely branching, and with a finite set of initial states. Therefore, bounded safety/liveness properties can always be verified by exhaustive exploration of the system trajectories. However, this approach may be intractable in practice, as the number of trajectories usually grows exponentially with respect to the considered bound. Furthermore, since the system we consider can have an infinite set of states, exhaustive exploration cannot be used for unbounded safety verification. For bounded safety properties, we propose an algorithm which combines exploration of the system trajectories and state space reduction using merging based on a bisimulation metric. The main novelty compared to an algorithm presented recently by Lerda et al. [2008] consists in introducing a tuning parameter that improves the performance drastically. We also establish a procedure that allows us to prove unbounded safety from the result of the bounded safety algorithm via a refinement step. We then adapt the algorithm to handle bounded liveness verification. Finally, the effectiveness of the approach is demonstrated by applying it to the analysis of implementations of an embedded control loop.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1965032334",
    "type": "article"
  },
  {
    "title": "Design and evaluation of random linear network coding Accelerators on FPGAs",
    "doi": "https://doi.org/10.1145/2512469",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Sunwoo Kim; Won Seob Jeong; Won Woo Ro; Jean‐Luc Gaudiot",
    "corresponding_authors": "",
    "abstract": "Network coding is a well-known technique used to enhance network throughput and reliability by applying special coding to data packets. One critical problem in practice, when using the random linear network coding technique, is the high computational overhead. More specifically, using this technique in embedded systems with low computational power might cause serious delays due to the complex Galois field operations and matrix handling. To this end, this article proposes a high-performance decoding logic for random linear network coding using field-programmable gate-array (FPGA) technology. We expect that the inherent reconfigurability of FPGAs will provide sufficient performance as well as programmability to cope with changes in the specification of the coding. The main design motivation was to improve the decoding delay by dividing and parallelizing the entire decoding process. Fast arithmetic operations are achieved by the proposed parallelized GF ALUs, which allow calculations with all the elements of a single row of a matrix to be performed concurrently. To improve the flexibility in the utilization of the FPGA components, two different decoding methods have been designed and compared. The performance of the proposed idea is evaluated by comparing with the performance of the decoding process executed by general-purpose processors through an equivalent software algorithm. Overall, a maximum throughput of 65.98 Mbps is achieved with the proposed FPGA design on an XC5VLX110T Virtex 5 device. In addition, the proposed design provides speedups of up to 13.84 compared to an aggressively parallelized software decoding algorithm run on a quad-core AMD processor. Moreover, the design affords 12 times higher power efficiency in terms of throughput per watt than an ARM Coretex-A9 processor.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1979476966",
    "type": "article"
  },
  {
    "title": "Power Analysis Attack Resistance Engineering by Dynamic Voltage and Frequency Scaling",
    "doi": "https://doi.org/10.1145/2345770.2345774",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Shengqi Yang; Pallav Gupta; Marilyn Wolf; Dimitrios Serpanos; Vijaykrishnan Narayanan; Yuan Xie",
    "corresponding_authors": "",
    "abstract": "This article proposes a novel approach to cryptosystem design to prevent power analysis attacks. Such attacks infer program behavior by continuously monitoring the power supply current going into the processor core. They form an important class of security attacks. Our approach is based on dynamic voltage and frequency scaling (DVFS), which hides processor state to make it harder for an attacker to gain access to a secure system. Three designs are studied to test the efficacy of the DVFS method against power analysis attacks. The advanced realization of our cryptosystem is presented which achieves enough high power and time trace entropies to block various kinds of power analysis attacks in the DES algorithm. We observed 27% energy reduction and 16% time overhead in these algorithms. Finally, DVFS hardness analysis is presented.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1984336675",
    "type": "article"
  },
  {
    "title": "A constraint programming approach for integrated spatial and temporal scheduling for clustered architectures",
    "doi": "https://doi.org/10.1145/2512470",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Mirza Omer Beg; Peter van Beek",
    "corresponding_authors": "",
    "abstract": "Many embedded processors use clustering to scale up instruction-level parallelism in a cost-effective manner. In a clustered architecture, the registers and functional units are partitioned into smaller units and clusters communicate through register-to-register copy operations. Texas Instruments, for example, has a series of architectures for embedded processors which are clustered. Such an architecture places a heavier burden on the compiler, which must now assign instructions to clusters (spatial scheduling), assign instructions to cycles (temporal scheduling), and schedule copy operations to move data between clusters. We consider instruction scheduling of local blocks of code on clustered architectures to improve performance. Scheduling for space and time is known to be a hard problem. Previous work has proposed greedy approaches based on list scheduling to simultaneously perform spatial and temporal scheduling and phased approaches based on first partitioning a block of code to do spatial assignment and then performing temporal scheduling. Greedy approaches risk making mistakes that are then costly to recover from, and partitioning approaches suffer from the well-known phase ordering problem. In this article, we present a constraint programming approach for scheduling instructions on clustered architectures. We employ a problem decomposition technique that solves spatial and temporal scheduling in an integrated manner. We analyze the effect of different hardware parameters—such as the number of clusters, issue-width, and intercluster communication cost—on application performance. We found that our approach was able to achieve an improvement of up to 26%, on average, over a state-of-the-art technique on superblocks from SPEC 2000 benchmarks.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2013962395",
    "type": "article"
  },
  {
    "title": "Mobile query services in a participatory embedded sensing environment",
    "doi": "https://doi.org/10.1145/2423636.2423649",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Agustinus Borgy Waluyo; David Taniar; Bala Srinivasan; Wenny Rahayu",
    "corresponding_authors": "",
    "abstract": "A participatory mobile sensing system is designed to enable clients to voluntarily collect environmental data using embedded sensors and a mobile device while going about their daily activities. Due to the spatio-temporal nature of the data, and the significant benefits of the data to the general public, it is necessary to employ an efficient and effective query processing model for the mobile clients to access the data that can be visualized via an interactive multimedia interface. This article introduces a unified on-demand and data broadcast model to serve queries in the context of a mobile sensing system. The contributions of this article include the following: (i) it presents a novel data structure and indexing method to support the system; (ii) it provides flexibility for the client to issue query using on-demand or broadcast channel according to the server load and broadcast schedule; (iii) it enables new data access and processing for the mobile client; and (iv) it is designed for a multiple channels/receivers environment in a 4G wireless network. The proposed model uses a holistic query processing approach for the mobile sensing system that offers substantial efficiency and autonomy for mobile clients when retrieving data. The results of the experiments undertaken affirm the effectiveness of its performance.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2014719625",
    "type": "article"
  },
  {
    "title": "Adaptive wear-leveling algorithm for PRAM main memory with a DRAM buffer",
    "doi": "https://doi.org/10.1145/2558427",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Sung Kyu Park; Min Kyu Maeng; Ki-Woong Park; Kyu Ho Park",
    "corresponding_authors": "",
    "abstract": "Phase Change RAM (PRAM) is a candidate to replace DRAM main memory due to its low idle power consumption and high scalability. However, its latency and endurance have generated problems in fulfilling its main memory role. The latency can be treated with a DRAM buffer, but the endurance problem remains, with three critical points that need to be improved despite the use of, existing wear-leveling algorithms. First, existing DRAM buffering schemes do not consider write count distribution. Second, swapping and shifting operations are performed statically. Finally, swapping and shifting operations are loosely coupled with a DRAM buffer. As a remedy to these drawbacks, we propose an adaptive wear-leveling algorithm that consists of three novel schemes for PRAM main memory with a DRAM buffer. The PRAM-aware DRAM buffering scheme reduces the write count and prevents skewed writing by considering the write count and clean data based on the least recently used (LRU) scheme. The adaptive multiple swapping and shifting scheme makes the write count even with the dynamic operation timing, the number of swapping pages being based on the workload pattern. Our DRAM buffer-aware swapping and shifting scheme reduces overhead by curbing additional swapping and shifting operations, thus reducing unnecessary write operations. To evaluate the wear-leveling effect, we have implemented a PIN-based wear-leveling simulator. The evaluation confirms that the PRAM lifetime increases from 0.68 years with the previous wear-leveling algorithm to 5.32 years with the adaptive wear-leveling algorithm.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2016362255",
    "type": "article"
  },
  {
    "title": "Application-Focused Energy-Fidelity Scalability for Wireless Motion-Based Health Assessment",
    "doi": "https://doi.org/10.1145/2331147.2331160",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Mark Hanson; Harry Powell; Adam T. Barth; John Lach",
    "corresponding_authors": "",
    "abstract": "Energy-fidelity trade-offs are central to the performance of many technologies, but they are essential in wireless body area sensor networks (BASNs) due to severe energy and processing constraints and the critical nature of certain healthcare applications. On-node signal processing and compression techniques can save energy by greatly reducing the amount of data transmitted over the wireless channel, but lossy techniques, capable of high compression ratios, can incur a reduction in application fidelity. In order to maximize system performance, these trade-offs must be considered at runtime due to the dynamic nature of BASN applications, including sensed data, operating environments, user actuation, etc. BASNs therefore require energy-fidelity scalability, so automated and user-initiated trade-offs can be made dynamically. This article presents a data rate scalability framework within a motion-based health application context which demonstrates the design of efficient and efficacious wireless health systems.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2022383670",
    "type": "article"
  },
  {
    "title": "The Future of Real-Time Security",
    "doi": "https://doi.org/10.1145/2724714",
    "publication_date": "2015-04-30",
    "publication_year": 2015,
    "authors": "Aydın Aysu; Bilgiday Yuce; Patrick Schaumont",
    "corresponding_authors": "",
    "abstract": "Advances in quantum computing have spurred a significant amount of research into public-key cryptographic algorithms that are resistant against postquantum cryptanalysis. Lattice-based cryptography is one of the important candidates because of its reasonable complexity combined with reasonable signature sizes. However, in a postquantum world, not only the cryptography will change but also the computing platforms. Large amounts of resource-constrained embedded systems will connect to a cloud of powerful server computers. We present an optimization technique for lattice-based signature generation on such embedded systems; our goal is to optimize latency rather than throughput. Indeed, on an embedded system, the latency of a single signature for user identification or message authentication is more important than the aggregate signature generation rate. We build a high-performance implementation using hardware/software codesign techniques. The key idea is to partition the signature generation scheme into offline and online phases. The signature scheme allows this separation because a large portion of the computation does not depend on the message to be signed and can be handled before the message is given. Then, we can map complex precomputation operations in software on a low-cost processor and utilize hardware resources to accelerate simpler online operations. To find the optimum hardware architecture for the target platform, we define and explore the design space and implement two design configurations. We realize our solutions on the Altera Cyclone-IV CGX150 FPGA. The implementation consists of a NIOS soft-core processor and a low-latency hash and polynomial multiplication engine. On average, the proposed low-latency architecture can generate a signature with a latency of 96 clock cycles at 40MHz, resulting in a response time of 2.4μs for a signing request. On equivalent platforms, this corresponds to a performance improvement of 33 and 105 times compared to previous hardware and software implementations, respectively.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2040527222",
    "type": "article"
  },
  {
    "title": "A passivity approach for model-based compositional design of networked control systems",
    "doi": "https://doi.org/10.1145/2362336.2362342",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Xenofon Koutsoukos; Nicholas Kottenstette; Joseph Hall; Emeka Eyisi; Heath J. LeBlanc; Joseph Porter; János Sztipanovits",
    "corresponding_authors": "",
    "abstract": "The integration of physical systems through computing and networking has become pervasive, a trend now known as cyber-physical systems (CPS). Functionality in CPS emerges from the interaction of networked computational and physical objects. System design and integration are particularly challenging because fundamentally different physical and computational design concerns intersect. The impact of these interactions is the loss of compositionality which creates tremendous challenges. The key idea in this article is to use passivity for decoupling the control design of networked systems from uncertainties such as time delays and packet loss, thus providing a fundamental simplification strategy that limits the complexity of interactions. The main contribution is the application of the approach to an experimental case study of a networked multi-robot system. We present a networked control architecture that ensures the overall system remains stable in spite of implementation uncertainties such as network delays and data dropouts, focusing on the technical details required for the implementation. We describe a prototype domain-specific modeling language and automated code generation tools for the design of networked control systems on top of passivity that facilitate effective system configuration, deployment, and testing. Finally, we present experimental evaluation results that show decoupling of interlayer interactions.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2046439435",
    "type": "article"
  },
  {
    "title": "A RF4CE-based remote controller with interactive graphical user interface applied to home automation system",
    "doi": "https://doi.org/10.1145/2423636.2423648",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Chin‐Feng Lai; Min Chen; Meikang Qiu; Athanasios V. Vasilakos; Jong Hyuk Park",
    "corresponding_authors": "",
    "abstract": "With the increase in commercial electronic equipment and its complicated control interfaces, how to design an effective and user-friendly control interface has become a topic for many researchers. This research introduces two-directional communication of an interactive graphical user interface on a universal remote control (URC). It is different from current URCs where users must often spend huge amounts of time setting the command codes and encoding each device. With the increase in the number of appliances that the controller needs to manage and the complicated and numerous control buttons, using such controllers often causes difficulties for users. This research employs a cross-platform with integration theories, so when a user wants to connect an appliance, both the appliance end and the controller end will build a two-directional connection through pairing over Radio Frequency for Consumer Electronics (RF4CE). After connection, the system will automatically set the communication protocol between the controller and the device. The appliance will automatically transmit its current state and service in the form of bundles to the controller, then the controller will project it onto an LCD screen. The controller can also show the number of appliances connected to the current position of the user, allowing the user to use one controller to control all home appliances with ease, achieving a simplified and instinctive control interface to build the integrated control environment for commercial appliances.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2072226904",
    "type": "article"
  },
  {
    "title": "Cache-Related Preemption Delay Analysis for Multilevel Noninclusive Caches",
    "doi": "https://doi.org/10.1145/2632156",
    "publication_date": "2014-07-23",
    "publication_year": 2014,
    "authors": "Sudipta Chattopadhyay; Abhik Roychoudhury",
    "corresponding_authors": "",
    "abstract": "With the rapid growth of complex hardware features, timing analysis has become an increasingly difficult problem. The key to solving this problem lies in the precise and scalable modeling of performance-enhancing processor features (e.g., cache). Moreover, real-time systems are often multitasking and use preemptive scheduling, with fixed or dynamic priority assignment. For such systems, cache related preemption delay (CRPD) may increase the execution time of a task. Therefore, CRPD may affect the overall schedulability analysis. Existing works propose to bound the value of CRPD in a single-level cache. In this article, we propose a CRPD analysis framework that can be used for a two-level, noninclusive cache hierarchy. In addition, our proposed framework is also applicable in the presence of shared caches. We first show that CRPD analysis faces several new challenges in the presence of a multilevel, noninclusive cache hierarchy. Our proposed framework overcomes all such challenges and we can formally prove the correctness of our framework. We have performed experiments with several subject programs, including an unmanned aerial vehicle (UAV) controller and an in-situ space debris monitoring instrument. Our experimental results suggest that we can provide sound and precise CRPD estimates using our framework.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2131491528",
    "type": "article"
  },
  {
    "title": "Robust image processing for an omnidirectional camera-based smart car door",
    "doi": "https://doi.org/10.1145/2362336.2362354",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Christian Scharfenberger; Samarjit Chakraborty; Georg Färber",
    "corresponding_authors": "",
    "abstract": "Over the last decade, there has been an increasing emphasis on driver-assistance systems for the automotive domain. In this article, we report our work on designing a camera-based surveillance system embedded in a “smart” car door. Such a camera is used to monitor the ambient environment outside the car, for instance, the presence of obstacles such as approaching cars or cyclists who might collide with the car door if opened—and automatically control the car door operations. This is an enhancement to the currently available side-view mirrors that the driver/passenger checks before opening the car door. The focus of this article is on fast and robust image processing algorithms specifically targeting such a smart car door system. The requirement is to quickly detect traffic objects of interest from grayscale images captured by omnidirectional cameras. While known algorithms for object extraction from the image processing literature rely on color information and are sensitive to shadows and illumination changes, our proposed algorithms are highly robust, can operate on grayscale images (color images are not available in our setup), and output results in real time. We present a number of experimental results based on image sequences captured from real-life traffic scenarios to demonstrate the applicability of our algorithm.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2149160505",
    "type": "article"
  },
  {
    "title": "Exploiting media stream similarity for energy-efficient decoding and resource prediction",
    "doi": "https://doi.org/10.1145/2146417.2146419",
    "publication_date": "2012-03-01",
    "publication_year": 2012,
    "authors": "J. Hamers; Lieven Eeckhout",
    "corresponding_authors": "",
    "abstract": "This article introduces a novel approach to energy-efficient media stream decoding that is based on the notion of media stream similarity. The key idea is that platform-independent scenarios with similar decoding complexity can be identified within and across media streams. A device that decodes a media stream annotated with scenario information can then adjust its processor clock frequency and voltage level based on these scenarios for lower energy consumption. Our evaluation, done using the H.264 AVC decoder and 12 reference video streams, shows an average energy reduction of 44% while missing less than 0.2% of the frame deadlines using scenario-driven video decoding. An additional application of scenario-based media stream annotation is to predict required resources (compute power and energy) for consuming a given service on a given device. Resource prediction is extremely useful in a client-server setup in which the client requests a media service from the server or content provider. The content provider (in cooperation with the client) can then determine what service quality to deliver, given the client's available resources. Scenario-aware resource prediction can predict (compute power and energy) consumption with errors less than 4% (and an overall average 1.4% error).",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2149542474",
    "type": "article"
  },
  {
    "title": "A Principled Approach to Secure Multi-core Processor Design with ReWire",
    "doi": "https://doi.org/10.1145/2967497",
    "publication_date": "2017-01-10",
    "publication_year": 2017,
    "authors": "Adam Procter; William L. Harrison; Ian Graves; Michela Becchi; Gerard Allwein",
    "corresponding_authors": "",
    "abstract": "There is no such thing as high assurance without high assurance hardware. High assurance hardware is essential because any and all high assurance systems ultimately depend on hardware that conforms to, and does not undermine, critical system properties and invariants. And yet, high assurance hardware development is stymied by the conceptual gap between formal methods and hardware description languages used by engineers. This article advocates a semantics-directed approach to bridge this conceptual gap. We present a case study in the design of secure processors, which are formally derived via principled techniques grounded in functional programming and equational reasoning. The case study comprises the development of secure single- and dual-core variants of a single processor, both based on a common semantic specification of the ISA. We demonstrate via formal equational reasoning that the dual-core processor respects a “no-write-down” information flow policy. The semantics-directed approach enables a modular and extensible style of system design and verification. The secure processors require only a very small amount of additional code to specify and implement, and their security verification arguments are concise and readable. Our approach rests critically on ReWire, a functional programming language providing a suitable foundation for formal verification of hardware designs. This case study demonstrates both ReWire’s expressiveness as a programming language and its power as a framework for formal, high-level reasoning about hardware systems.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2567865805",
    "type": "article"
  },
  {
    "title": "Formal Model-Based Synthesis of Application-Specific Static RTOS",
    "doi": "https://doi.org/10.1145/3015777",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Kabland Toussaint Gautier Tigori; Jean-Luc Béchennec; Sébastien Faucou; Olivier Roux",
    "corresponding_authors": "",
    "abstract": "In an embedded system, the specialization of the code of the real-time operating system (RTOS) according to the requirements of the application allows one to remove unused services and other sources of dead code from the binary program. The typical specialization process is based on a mix of precompiler macros and build scripts, both of which are known for being sources of errors. In this article, we present a new model-based approach to the design of application-specific RTOS. Starting with finite state models describing the RTOS and the application requirements, the set of blocks in the RTOS code actually used by the application is automatically computed. This set is used to build an application-specific RTOS model. This model is fed into a code generator to produce the source code of an application-specific RTOS. It is also used to carry on model-based validations and verifications, including the formal verification that the specialization process did not introduce unwanted behaviors or suppress expected ones. To demonstrate the feasibility of this approach, it is applied to specialize Trampoline, an open-source implementation of the AUTOSAR OS standard, to an industrial case study from the automotive domain.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2612596341",
    "type": "article"
  },
  {
    "title": "Modular Compilation of Hybrid Systems for Emulation and Large Scale Simulation",
    "doi": "https://doi.org/10.1145/3126536",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Avinash Malik; Partha S. Roop; Sidharta Andalam; Mark L. Trew; Michael Mendler",
    "corresponding_authors": "",
    "abstract": "Hybrid systems combine discrete controllers with adjoining physical processes. While many approaches exist for simulating hybrid systems, there are few approaches for their emulation, especially when the actual physical plant is not available. This paper develops the first formal framework for emulation along with a new compiler that enables large-scale (1000+ components) simulation. We propose a formal model called Synchronous Emulation Automaton (SEA) specifically for modular compilation and parallel execution. SEA combines Linear Time Invariant (LTI) systems with discrete mode switches and has the following semantic differences with Hybrid Automata: ➀ the Ordinary Differential Equations are solved analytically and the solutions are sampled at the Worst-Case Reaction Time of the model and ➁ we develop a new composition semantics, which allows individual SEAs to execute in parallel with each other. The proposed semantics eliminates: ⓐ the need for dynamic numerical solvers, and ⓑ the Zeno-phenomenon by construction. Experimental results show that process models designed using our tool (Piha) give a 3.6 times execution speedup over Simulink®, and upto 26 times speedup on manycore architectures.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2757974192",
    "type": "article"
  },
  {
    "title": "Using Efficient Path Profiling to Optimize Memory Consumption of On-Chip Debugging for High-Level Synthesis",
    "doi": "https://doi.org/10.1145/3126564",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Pietro Fezzardi; Marco Lattuada; Fabrizio Ferrandi",
    "corresponding_authors": "",
    "abstract": "High-Level Synthesis (HLS) for FPGAs is attracting popularity and is increasingly used to handle complex systems with multiple integrated components. To increase performance and efficiency, HLS flows now adopt several advanced optimization techniques. Aggressive optimizations and system level integration can cause the introduction of bugs that are only observable on-chip. Debugging support for circuits generated with HLS is receiving a considerable attention. Among the data that can be collected on chip for debugging, one of the most important is the state of the Finite State Machines (FSM) controlling the components of the circuit. However, this usually requires a large amount of memory to trace the behavior during the execution. This work proposes an approach that takes advantage of the HLS information and of the structure of the FSM to compress control flow traces and to integrate optimized components for on-chip debugging. The generated checkers analyze the FSM execution on-fly, automatically notifying when a bug is detected, localizing it and providing data about its cause. The traces are compressed using a software profiling technique, called Efficient Path Profiling (EPP), adapted for the debugging of hardware accelerators generated with HLS. With this technique, the size of the memory used to store control flow traces can be reduced up to 2 orders of magnitude, compared to state-of-the-art.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2759267373",
    "type": "article"
  },
  {
    "title": "A DWM-Based Stack Architecture Implementation for Energy Harvesting Systems",
    "doi": "https://doi.org/10.1145/3126543",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Hoda Aghaei Khouzani; Chengmo Yang",
    "corresponding_authors": "",
    "abstract": "Energy harvesting systems tend to use non-volatile processors to conduct computation under intermittent power supplies. While previous implementations of non-volatile processors are based on register architectures, stack architecture, known for its simplicity and small footprint, seems to be a better fit for energy harvesting systems. In this work, Domain Wall Memory (DWM) is used to implement ZPU, the world’s smallest working CPU. Not only does DWM offer ultra-high density and SRAM-comparable access latency, but the sequential access structure of DWM also makes it well suited for a stack whose accesses display high temporal locality. As the performance and energy of DWM are determined by the number of shift operations performed to access the stack, this paper further reduces shift operations through novel data placement and micro-code transformation optimizations. The impact of compiler optimization techniques on the number of shift operations is also investigated so as to select the most effective optimizations for DWM-based stack machine. Experimental studies confirm the effectiveness of the proposed DWM-based stack architectures in improving the performance and energy-efficiency of energy harvesting systems.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2760750485",
    "type": "article"
  },
  {
    "title": "Reducing Energy in GPGPUs through Approximate Trivial Bypassing",
    "doi": "https://doi.org/10.1145/3429440",
    "publication_date": "2021-01-04",
    "publication_year": 2021,
    "authors": "Ehsan Atoofian; Zayan Shaikh; Ali Jannesari",
    "corresponding_authors": "",
    "abstract": "General-purpose computing using graphics processing units (GPGPUs) is an attractive option for acceleration of applications with massively data-parallel tasks. While performance of modern GPGPUs is increasing rapidly, the power consumption of these devices is becoming a major concern. In particular, execution units and register file are among the top three most power-hungry components in GPGPUs. In this work, we exploit trivial instructions to reduce power consumption in GPGPUs. Trivial instructions are those instructions that do not need computations, i.e., multiplication by one. We found that, during the course of a program's execution, a GPGPU executes many trivial instructions. Execution of these instructions wastes power unnecessarily. In this work, we propose trivial bypassing which skips execution of trivial instructions and avoids unnecessary allocation of resources for trivial instructions. By power gating execution units and skipping trivial computing, trivial bypassing reduces both static and dynamic power. Also, trivial bypassing reduces dynamic energy of register file by avoiding access to register file for source and/or destination operands of trivial instructions. While trivial bypassing reduces energy of GPGPUs, it has detrimental impact on performance as a power-gated execution unit requires several cycles to resume its normal operation. Conventional warp schedulers are oblivious to the status of execution units. We propose a new warp scheduler that prioritizes warps based on availability of execution units. We also propose a set of new power management techniques to reduce performance penalty of power gating, further. To increase energy saving of trivial bypassing, we also propose approximating operands of instructions. We offer a set of new techniques to approximate both integer and floating-point instructions and increase the pool of trivial instructions. Our evaluations using a diverse set of benchmarks reveal that our proposed techniques are able to reduce energy of execution units by 11.2% and dynamic energy of register file by 12.2% with minimal performance and quality degradation.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3120587606",
    "type": "article"
  },
  {
    "title": "Tolerating Defects in Low-Power Neural Network Accelerators Via Retraining-Free Weight Approximation",
    "doi": "https://doi.org/10.1145/3477016",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Fateme S. Hosseini; Fanruo Meng; Chengmo Yang; Wujie Wen; Rosario Cammarota",
    "corresponding_authors": "",
    "abstract": "Hardware accelerators are essential to the accommodation of ever-increasing Deep Neural Network (DNN) workloads on the resource-constrained embedded devices. While accelerators facilitate fast and energy-efficient DNN operations, their accuracy is threatened by faults in their on-chip and off-chip memories, where millions of DNN weights are held. The use of emerging Non-Volatile Memories (NVM) further exposes DNN accelerators to a non-negligible rate of permanent defects due to immature fabrication, limited endurance, and aging. To tolerate defects in NVM-based DNN accelerators, previous work either requires extra redundancy in hardware or performs defect-aware retraining, imposing significant overhead. In comparison, this paper proposes a set of algorithms that exploit the flexibility in setting the fault-free bits in weight memory to effectively approximate weight values, so as to mitigate defect-induced accuracy drop. These algorithms can be applied as a one-step solution when loading the weights to embedded devices. They only require trivial hardware support and impose negligible run-time overhead. Experiments on popular DNN models show that the proposed techniques successfully boost inference accuracy even in the face of elevated defect rates in the weight memory.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3199347449",
    "type": "article"
  },
  {
    "title": "Heterogeneity-aware Multicore Synchronization for Intermittent Systems",
    "doi": "https://doi.org/10.1145/3476992",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Wei-Ming Chen; Tei‐Wei Kuo; Pi-Cheng Hsiu",
    "corresponding_authors": "",
    "abstract": "Intermittent systems enable batteryless devices to operate through energy harvesting by leveraging the complementary characteristics of volatile (VM) and non-volatile memory (NVM). Unfortunately, alternate and frequent accesses to heterogeneous memories for accumulative execution across power cycles can significantly hinder computation progress. The progress impediment is mainly due to more CPU time being wasted for slow NVM accesses than for fast VM accesses. This paper explores how to leverage heterogeneous cores to mitigate the progress impediment caused by heterogeneous memories. In particular, a delegable and adaptive synchronization protocol is proposed to allow memory accesses to be delegated between cores and to dynamically adapt to diverse memory access latency. Moreover, our design guarantees task serializability across multiple cores and maintains data consistency despite frequent power failures. We integrated our design into FreeRTOS running on a Cypress device featuring heterogeneous dual cores and hybrid memories. Experimental results show that, compared to recent approaches that assume single-core intermittent systems, our design can improve computation progress at least 1.8x and even up to 33.9x by leveraging core heterogeneity.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3199508312",
    "type": "article"
  },
  {
    "title": "Domain-specific Hybrid Mapping for Energy-efficient Baseband Processing in Wireless Networks",
    "doi": "https://doi.org/10.1145/3476991",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Robert Khasanov; Julian Robledo; Christian Menard; Andrés Goens; Jerónimo Castrillón",
    "corresponding_authors": "",
    "abstract": "Advancing telecommunication standards continuously push for larger bandwidths, lower latencies, and faster data rates. The receiver baseband unit not only has to deal with a huge number of users expecting connectivity but also with a high workload heterogeneity. As a consequence of the required flexibility, baseband processing has seen a trend towards software implementations in cloud Radio Access Networks (cRANs). The flexibility gained from software implementation comes at the price of impoverished energy efficiency. This paper addresses the trade-off between flexibility and efficiency by proposing a domain-specific hybrid mapping algorithm. Hybrid mapping is an established approach from the model-based design of embedded systems that allows us to retain flexibility while targeting heterogeneous hardware. Depending on the current workload, the runtime system selects the most energy-efficient mapping configuration without violating timing constraints. We leverage the structure of baseband processing, and refine the scheduling methodology, to enable efficient mapping of 100s of tasks at the millisecond granularity, improving upon state-of-the-art hybrid approaches. We validate our approach on an Odroid XU4 and virtual platforms with application-specific accelerators on an open-source prototype. On different LTE workloads, our hybrid approach shows significant improvements both at design time and at runtime. At design-time, mappings of similar quality to those obtained by state-of-the-art methods are generated around four orders of magnitude faster. At runtime, multi-application schedules are computed 37.7% faster than the state-of-the-art without compromising on the quality.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3199794819",
    "type": "article"
  },
  {
    "title": "Rtkaller: State-aware Task Generation for RTOS Fuzzing",
    "doi": "https://doi.org/10.1145/3477014",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Yuheng Shen; Hao Sun; Yu Jiang; Heyuan Shi; Yixiao Yang; Wanli Chang",
    "corresponding_authors": "",
    "abstract": "A real-time operating system (RTOS) is an operating system designed to meet certain real-time requirements. It is widely used in embedded applications, and its correctness is safety-critical. However, the validation of RTOS is challenging due to its complex real-time features and large code base. In this paper, we propose Rtkaller , a state-aware kernel fuzzer for the vulnerability detection in RTOS. First, Rtkaller implements an automatic task initialization to transform the syscall sequences into initial tasks with more real-time information. Then, a coverage-guided task mutation is designed to generate those tasks that explore more in-depth real-time related code for parallel execution. Moreover, Rtkaller realizes a task modification to correct those tasks that may hang during fuzzing. We evaluated it on recent versions of rt-Linux, which is one of the most widely used RTOS. Compared to the state-of-the-art kernel fuzzers Syzkaller and Moonshine, Rtkaller achieves the same code coverage at the speed of 1.7X and 1.6X, gains an increase of 26.1% and 22.0% branch coverage within 24 hours respectively. More importantly, Rtkaller has confirmed 28 previously unknown vulnerabilities that are missed by other fuzzers.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3200602700",
    "type": "article"
  },
  {
    "title": "Synergistically Exploiting CNN Pruning and HLS Versioning for Adaptive Inference on Multi-FPGAs at the Edge",
    "doi": "https://doi.org/10.1145/3476990",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Guilherme Korol; Michael Guilherme Jordan; Mateus Beck Rutzig; Antonio Carlos Schneider Beck",
    "corresponding_authors": "",
    "abstract": "FPGAs, because of their energy efficiency, reconfigurability, and easily tunable HLS designs, have been used to accelerate an increasing number of machine learning, especially CNN-based, applications. As a representative example, IoT Edge applications, which require low latency processing of resource-hungry CNNs, offload the inferences from resource-limited IoT end nodes to Edge servers featuring FPGAs. However, the ever-increasing number of end nodes pressures these FPGA-based servers with new performance and adaptability challenges. While some works have exploited CNN optimizations to alleviate inferences’ computation and memory burdens, others have exploited HLS to tune accelerators for statically defined optimization goals. However, these works have not tackled both CNN and HLS optimizations altogether; neither have they provided any adaptability at runtime, where the workload’s characteristics are unpredictable. In this context, we propose a hybrid two-step approach that, first, creates new optimization opportunities at design-time through the automatic training of CNN model variants (obtained via pruning) and the automatic generation of versions of convolutional accelerators (obtained during HLS synthesis); and, second, synergistically exploits these created CNN and HLS optimization opportunities to deliver a fully dynamic Multi-FPGA system that adapts its resources in a fully automatic or user-configurable manner. We implement this two-step approach as the AdaServ Framework and show, through a smart video surveillance Edge application as a case study, that it adapts to the always-changing Edge conditions: AdaServ processes at least 3.37× more inferences (using the automatic approach) and is at least 6.68× more energy-efficient (user-configurable approach) than original convolutional accelerators and CNN Models (VGG-16 and AlexNet). We also show that AdaServ achieves better results than solutions dynamically changing only the CNN model or HLS version, highlighting the importance of exploring both; and that it is always better than the best statically chosen CNN model and HLS version, showing the need for dynamic adaptability.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3200878837",
    "type": "article"
  },
  {
    "title": "Simultaneous hardware and time redundancy with online task scheduling for low energy highly reliable standby-sparing system",
    "doi": "https://doi.org/10.1145/2523781/2560035",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Mohammad Khavari Tavana; Nasibeh Teimouri; Meisam Abdollahi; Maziar Goudarzi",
    "corresponding_authors": "",
    "abstract": "Standby-sparing is one of the common techniques in order to design fault-tolerant safety-critical systems where the high level of reliability is needed. Recently, the minimization of energy consumption in embedded systems has attracted a lot of concerns. Simultaneous considering of high reliability and low energy consumption by DVS is a challenging problem in designing such a system, since using DVS has been shown to reduce the reliability profoundly. In this article, we have studied different schemes of standby-sparing systems from the energy consumption and reliability point of view. Moreover, we propose a new standby-sparing scheme which addresses both reliability and energy consumption jointly together. This scheme uses a simple energy management coupled with an online task scheduler which tries to dispatch those ready tasks which are expected to lead to high reliability and low energy consumption in the system. The effectiveness of the proposed scheme has been shown on TGFF under stochastic workloads. The results show 52% improvement on energy saving compared to the conventional hot standby-sparing system. Moreover, two orders of magnitude higher reliability is obtained on average, while preserving the same level of energy saving as compared to the state-of-the-art low-energy standby-sparing system (LESS).",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2021324492",
    "type": "article"
  },
  {
    "title": "Polynomial Sufficient Conditions of Well-Behavedness and Home Markings in Subclasses of Weighted Petri Nets",
    "doi": "https://doi.org/10.1145/2627349",
    "publication_date": "2014-07-01",
    "publication_year": 2014,
    "authors": "Thomas Hujsa; Jean-Marc Delosme; Alix Munier-Kordon",
    "corresponding_authors": "",
    "abstract": "Join-Free Petri nets, whose transitions have at most one input place, model systems without synchronizations, while Choice-Free Petri nets, whose places have at most one output transition, model systems without conflicts. These classes respectively encompass the state machines (S-systems) and the marked graphs (T-systems). Whereas a structurally bounded and structurally live Petri net is said to be “well-formed”, a bounded and live Petri net is said to be “well-behaved”. Necessary and sufficient conditions for the well-formedness of Join-Free and Choice-Free nets have been known for some time, yet the behavioral properties of these classes are still not well understood. In particular polynomial sufficient conditions for liveness, that is, polynomial in time and with a polynomial initial number of tokens, have not been found until now. Besides, home markings , which can be reached from every reachable marking thus allowing for the construction of systems that can return to their initial data distribution, are not well apprehended either for these subclasses. We extend results on weighted T-systems to the class of weighted Petri nets and present transformations which preserve the language of the system and reduce the initial marking. We introduce a notion of balancing that makes possible the transformation of conservative systems into so-called “token-conservative” systems, whose number of tokens is invariant, while retaining the feasible transition sequences. This transformation is pertinent for all well-formed Petri nets and leads to polynomial sufficient conditions of liveness for well-formed Join-Free and Choice-Free nets. Finally, we also provide polynomial live and home markings for Fork-Attribution systems.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2032749662",
    "type": "article"
  },
  {
    "title": "A Sliding Window Phase-Only Correlation Method for Side-Channel Alignment in a Smartphone",
    "doi": "https://doi.org/10.1145/2783441",
    "publication_date": "2015-09-09",
    "publication_year": 2015,
    "authors": "Catherine H. Gebotys; Brian White",
    "corresponding_authors": "",
    "abstract": "Future wireless embedded devices will be increasingly powerful, supporting many more applications including one of the most crucial, security. Although many embedded devices offer resistance to bus probing attacks due to their compact size and high levels of integration, susceptibility to attacks on their electromagnetic side channel must be analyzed. This side channel is often quite complex to analyze due to the complexities of the embedded device including operating system, interrupts, and so forth. This article presents a new methodology for analyzing a complex system's vulnerability to the EM side channel. The methodology proposes a sliding window phase-only correlation method for aligning electromagnetic emanations from a complex smartphone running native code utilizing an on-chip cache. Unlike previous research, experimental results demonstrate that data written to on-chip cache within an advanced 312MHz 0.13um processor executing AES can be attacked utilizing this new methodology. Furthermore, for the first time, it has been shown that the point of side-channel attack is not a spike of increased EM but an area of low EM amplitude, unlike what is noted in previous findings. This research is important for advancing side-channel analysis understanding in complex embedded processors and ensuring secure implementations in future embedded ubiquitous devices.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2047239861",
    "type": "article"
  },
  {
    "title": "Dynamically Instrumenting the QEMU Emulator for Linux Process Trace Generation with the GDB Debugger",
    "doi": "https://doi.org/10.1145/2678022",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Bojan Mihajlović; Željko Žilić; Warren J. Gross",
    "corresponding_authors": "",
    "abstract": "In software debugging, trace generation techniques are used to resolve highly complex bugs. However, the emulators increasingly used for embedded software development do not yet offer the types of trace generation infrastructure available in hardware. In this article, we make changes to the ARM ISA emulation of the QEMU emulator to allow for continuous instruction-level trace generation. Using a standard GDB client, tracepoints can be inserted to dynamically log registers and memory addresses without altering executing code. The ability to run trace experiments in five different modes allows the scope of trace generation to be narrowed as needed, down to the level of a single Linux process. Our scheme collects the execution traces of a Linux process on average between 9.6x--0.7x the speed of existing QEMU trace capabilities, with 96.7% less trace data volume. Compared to a software-instrumented tracing scheme, our method is both unobtrusive and performs on average between 3--4 orders of magnitude faster.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2070233995",
    "type": "article"
  },
  {
    "title": "Safety and Progress for Distributed Cyber-Physical Systems with Unreliable Communication",
    "doi": "https://doi.org/10.1145/2739046",
    "publication_date": "2015-09-24",
    "publication_year": 2015,
    "authors": "Stanley Bak; Zhenqi Huang; Fardin Abdi Taghi Abad; Marco Caccamo",
    "corresponding_authors": "",
    "abstract": "Cyber-physical systems (CPSs) may interact and manipulate objects in the physical world, and therefore formal guarantees about their behavior are strongly desired. Static-time proofs of safety invariants, however, may be intractable for systems with distributed physical-world interactions. This is further complicated when realistic communication models are considered, for which there may not be bounds on message delays, or even when considering that messages will eventually reach their destination. In this work, we address the challenge of proving safety and progress in distributed CPSs communicating over an unreliable communication layer. We show that for this type of communication model, system safety is closely related to the results of a hybrid system’s reachability computation, which can be computed at runtime. However, since computing reachability at runtime may be computationally intensive, we provide an approach that moves significant parts of the computation to design time. This approach is demonstrated with a case study of a simulation of multiple vehicles moving within a shared environment.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2074833236",
    "type": "article"
  },
  {
    "title": "Anonymous Split E-Cash—Toward Mobile Anonymous Payments",
    "doi": "https://doi.org/10.1145/2783439",
    "publication_date": "2015-09-09",
    "publication_year": 2015,
    "authors": "Marijn Scheir; Josep Balasch; Alfredo Rial; Bart Preneel; Ingrid Verbauwhede",
    "corresponding_authors": "",
    "abstract": "Anonymous E-Cash was first introduced in 1982 as a digital, privacy-preserving alternative to physical cash. A lot of research has since then been devoted to extend and improve its properties, leading to the appearance of multiple schemes. Despite this progress, the practical feasibility of E-Cash systems is still today an open question. Payment tokens are typically portable hardware devices in smart card form, resource constrained due to their size, and therefore not suited to support largely complex protocols such as E-Cash. Migrating to more powerful mobile platforms, for instance, smartphones, seems a natural alternative. However, this implies moving computations from trusted and dedicated execution environments to generic multiapplication platforms, which may result in security vulnerabilities. In this work, we propose a new anonymous E-Cash system to overcome this limitation. Motivated by existing payment schemes based on MTM (Mobile Trusted Module) architectures, we consider at design time a model in which user payment tokens are composed of two modules: an untrusted but powerful execution platform (e.g., smartphone) and a trusted but constrained platform (e.g., secure element). We show how the protocol’s computational complexity can be relaxed by a secure split of computations: nonsensitive operations are delegated to the powerful platform, while sensitive computations are kept in a secure environment. We provide a full construction of our proposed Anonymous Split E-Cash scheme and show that it fully complies with the main properties of an ideal E-Cash system. Finally, we test its performance by implementing it on an Android smartphone equipped with a Java-Card-compatible secure element.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2085751410",
    "type": "article"
  },
  {
    "title": "Fast and Precise Worst-Case Interference Placement for Shared Cache Analysis",
    "doi": "https://doi.org/10.1145/2854151",
    "publication_date": "2016-03-07",
    "publication_year": 2016,
    "authors": "Kartik Nagar; Y. N. Srikant",
    "corresponding_authors": "",
    "abstract": "Real-time systems require a safe and precise estimate of the worst-case execution time (WCET) of programs. In multicore architectures, the precision of a program’s WCET estimate highly depends on the precision of its predicted shared cache behavior. Prediction of shared cache behavior is difficult due to the uncertain timing of interfering shared cache accesses made by programs running on other cores. Given the assignment of programs to cores, the worst-case interference placement (WCIP) technique tries to find the worst-case timing of interfering accesses, which would cause the maximum number of cache misses on the worst case path of the program, to determine its WCET. Although WCIP generates highly precise WCET estimates, the current ILP-based approach is also known to have very high analysis time. In this work, we investigate the WCIP problem in detail and determine its source of hardness. We show that performing WCIP is an NP-hard problem by reducing the 0-1 knapsack problem. We use this observation to make simplifying assumptions, which make the WCIP problem tractable, and we propose an approximate greedy technique for WCIP, whose time complexity is linear in the size of the program. We perform extensive experiments to show that the assumptions do not affect the precision of WCIP but result in significant reduction of analysis time.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2304003964",
    "type": "article"
  },
  {
    "title": "Accurate Prediction of Available Battery Time for Mobile Applications",
    "doi": "https://doi.org/10.1145/2875423",
    "publication_date": "2016-05-23",
    "publication_year": 2016,
    "authors": "Dong-Won Kim; Yohan Chon; Wonwoo Jung; Yungeun Kim; Hojung Cha",
    "corresponding_authors": "",
    "abstract": "Energy consumption in mobile devices is an important issue for both system developers and users. Users are aware of the battery-related information of their mobile devices and tend to take appropriate actions to increase the battery life. In this article, we propose a framework that accurately estimates the remaining battery time of applications at runtime. The framework profiles the power behavior of applications tied with activated hardware components and estimates the remaining battery budget utilizing the battery-related data provided by the device. The experiments validate that our method predicts the remaining battery time for applications with approximately 93% of accuracy.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2406403868",
    "type": "article"
  },
  {
    "title": "Early DSE and Automatic Generation of Coarse-grained Merged Accelerators",
    "doi": "https://doi.org/10.1145/3546070",
    "publication_date": "2022-07-18",
    "publication_year": 2022,
    "authors": "Iulian Brumar; Georgios Zacharopoulos; Yuan Yao; Saketh Rama; David Brooks; Gu-Yeon Wei",
    "corresponding_authors": "",
    "abstract": "Post-Moore’s law area-constrained systems rely on accelerators to deliver performance enhancements. Coarse-grained accelerators can offer substantial domain acceleration, but manual, ad hoc identification of code to accelerate is prohibitively expensive. Because cycle-accurate simulators and high-level synthesis (HLS) flows are so time-consuming, the manual creation of high-utilization accelerators that exploit control and data flow patterns at optimal granularities is rarely successful. To address these challenges, we present AccelMerger, the first automated methodology to create coarse-grained, control- and data-flow-rich merged accelerators. AccelMerger uses sequence alignment matching to recognize similar function call-graphs and loops, and neural networks to quickly evaluate their post-HLS characteristics. It accurately identifies which functions to accelerate, and it merges accelerators to respect an area budget and to accommodate system communication characteristics like latency and bandwidth. Merging two accelerators can save as much as 99% of the area of one. The space saved is used by a globally optimal integer linear program to allocate more accelerators for increased performance. We demonstrate AccelMerger’s effectiveness using HLS flows without any manual effort to fine-tune the resulting designs. On FPGA-based systems, AccelMerger yields application performance improvements of up to 16.7× over software implementations, and 1.91× on average with respect to state-of-the-art early-stage design space exploration tools.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3214146924",
    "type": "article"
  },
  {
    "title": "Securing Pacemakers using Runtime Monitors over Physiological Signals",
    "doi": "https://doi.org/10.1145/3638286",
    "publication_date": "2024-01-06",
    "publication_year": 2024,
    "authors": "Abhinandan Panda; Srinivas Pinisetty; Partha S. Roop",
    "corresponding_authors": "",
    "abstract": "Wearable and implantable medical devices (IMDs) are increasingly deployed to diagnose, monitor, and provide therapy for critical medical conditions. Such medical devices are safety-critical cyber-physical systems (CPSs). These systems support wireless features introducing potential security vulnerabilities. Although these devices undergo rigorous safety certification processes, runtime security attacks are inevitable. Based on published literature, IMDs such as pacemakers and insulin infusion systems can be remotely controlled to inject deadly electric shocks and excess insulin, posing a threat to a patient’s life. While prior works based on formal methods have been proposed to detect potential attack vectors using different forms of static analysis, these have limitations in preventing attacks at runtime. This paper discusses a formal framework for detecting cyber-physical attacks on a pacemaker by monitoring its security policies at runtime. We propose a wearable device that senses the Electrocardiogram (ECG) and Photoplethysmogram (PPG) of the body to detect attacks in a pacemaker. To facilitate the design of this device, we map the security policies of a pacemaker w.r.t ECG and PPG, paving the way for designing formal verification monitors for pacemakers for the first time using multiple physiological signals. The proposed monitoring framework allows the synthesis of parallel monitors from a given set of desired security policies, where all the monitors execute concurrently and generate an alarm to the user in the case of policy violation. Our implementation and the performance evaluation results demonstrate the technical feasibility of designing such a wearable device for attack detection in pacemakers. This device is separate from the pacemaker, ensuring no need for re-certification of pacemakers. Our approach is amenable to the application of security patches when new attack vectors are detected, making the approach ideal for runtime monitoring of medical CPSs.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4390640577",
    "type": "article"
  },
  {
    "title": "Adversarial Transferability in Embedded Sensor Systems: An Activity Recognition Perspective",
    "doi": "https://doi.org/10.1145/3641861",
    "publication_date": "2024-01-22",
    "publication_year": 2024,
    "authors": "Ramesh Kumar Sah; Hassan Ghasemzadeh",
    "corresponding_authors": "",
    "abstract": "Machine learning algorithms are increasingly used for inference and decision-making in embedded systems. Data from sensors are used to train machine learning models for various smart functions of embedded and cyber-physical systems ranging from applications in healthcare, autonomous vehicles, and national security. However, recent studies have shown that machine learning models can be fooled by adding adversarial noise to their inputs. The perturbed inputs are called adversarial examples. Furthermore, adversarial examples designed to fool one machine learning system are also often effective against another system. This property of adversarial examples is called adversarial transferability and has not been explored in wearable systems to date. In this work, we take the first stride in studying adversarial transferability in wearable sensor systems from four viewpoints: (1) transferability between machine learning models; (2) transferability across users/subjects of the embedded system; (3) transferability across sensor body locations; and (4) transferability across datasets used for model training. We present a set of carefully designed experiments to investigate these transferability scenarios. We also propose a threat model describing the interactions of an adversary with the source and target sensor systems in different transferability settings. In most cases, we found high untargeted transferability, whereas targeted transferability success scores varied from 0% to 80%. The transferability of adversarial examples depends on many factors such as the inclusion of data from all subjects, sensor body position, number of samples in the dataset, type of learning algorithm, and the distribution of source and target system dataset. The transferability of adversarial examples decreased sharply when the data distribution of the source and target system became more distinct. We also provide guidelines and suggestions for the community for designing robust sensor systems. Code and dataset used in our analysis is publicly available here. 1",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4391103909",
    "type": "article"
  },
  {
    "title": "Reordering Functions in Mobiles Apps for Reduced Size and Faster Start-Up",
    "doi": "https://doi.org/10.1145/3660635",
    "publication_date": "2024-04-20",
    "publication_year": 2024,
    "authors": "Ellis Hoag; Kyungwoo Lee; Julián Mestre; Sergey Pupyrev; Yongkang Zhu",
    "corresponding_authors": "",
    "abstract": "Function layout, also known as function reordering or function placement, is one of the most effective profile-guided compiler optimizations. By reordering functions in a binary, compilers can improve the performance of large-scale applications or reduce the compressed size of mobile applications. Although the technique has been extensively studied in the context of large-scale binaries, no study has thoroughly investigated function layout algorithms on mobile applications. In this article, we develop the first principled solution for optimizing function layouts in the mobile space. To this end, we identify two key optimization goals: reducing the compressed code size and improving the cold start-up time of a mobile application. Then, we propose a formal model for the layout problem, whose objective closely matches our goals, and a novel algorithm for optimizing the layout. The method is inspired by the classic balanced graph partitioning problem. We have carefully engineered and implemented the algorithm in an open-source compiler, Low-level Virtual Machine (LLVM). An extensive evaluation of the new method on large commercial mobile applications demonstrates improvements in start-up time and compressed size compared to the state-of-the-art approach. 1",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4394975822",
    "type": "article"
  },
  {
    "title": "Optimizing Dilithium Implementation with AVX2/-512",
    "doi": "https://doi.org/10.1145/3687309",
    "publication_date": "2024-08-10",
    "publication_year": 2024,
    "authors": "Runqing Xu; Debiao He; Min Luo; Cong Peng; Xiangyong Zeng",
    "corresponding_authors": "",
    "abstract": "Dilithium is a signature scheme that is currently being standardized to the Module-Lattice-Based Digital Signature Standard by NIST. It is believed to be secure even against attacks from large-scale quantum computers based on lattice problems. The implementation efficiency is important for promoting the migration of current cryptography algorithms to post-quantum cryptography algorithms. In this article, we optimize the implementation of Dilithium with several new approaches proposed. Firstly, we improve the efficiency of parallel NTT implementations. The overhead of shuffling operations is reduced in our implementations, and fewer loading instructions are invoked for the precomputations. Then, we optimize the sampling and bit-packing of polynomial coefficients in Dilithium. We can handle double the number of coefficients within one register using a new approach for the sampling of secret key polynomials. The approaches proposed in this article are applicable to implementations under AVX2 and AVX-512 instruction sets. Take Dilithium2 as an illustration, our AVX2 implementation demonstrates improvements of 22.7%, 16.9%, and 13.5% for KeyGen, Sign, and Verify compared with the previous implementation.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4401482544",
    "type": "article"
  },
  {
    "title": "Unleashing OpenTitan's Potential: a Silicon-Ready Embedded Secure Element for Root of Trust and Cryptographic Offloading",
    "doi": "https://doi.org/10.1145/3690823",
    "publication_date": "2024-09-05",
    "publication_year": 2024,
    "authors": "Maicol Ciani; Emanuele Parisi; Alberto Musa; Francesco Barchi; Andrea Bartolini; Ari Kulmala; Rafail Psiakis; Angelo Garofalo; Andrea Acquaviva; Davide Rossi",
    "corresponding_authors": "",
    "abstract": "The rapid advancement and exploration of open-hardware RISC-V platforms are catalyzing substantial changes across critical sectors, including autonomous vehicles, smart-city infrastructure, and medical devices. Within this technological evolution, OpenTitan emerges as a groundbreaking open-source RISC-V design, renowned for its comprehensive security toolkit and role as a standalone system-on-chip (SoC). OpenTitan encompasses different SoC implementations such as Earl Grey, fully implemented and silicon proven, and Darjeeling, announced but not yet fully implemented. The former targets a stand-alone system-on-chip implementation, the latter oriented towards an integrable implementation. Therefore, the literature currently lacks of a silicon-ready embedded implementation of an open-source Root of Trust, despite the effort put by lowRISC on the Darjeeling implementation of OpenTitan. We address the limitations of existing implementations, focusing on optimizing data transfer latency between memory and cryptographic accelerators to prevent under-utilization and ensure efficient task acceleration. Our contributions include a comprehensive methodology for integrating custom extensions and IPs into the Earl Grey architecture, architectural enhancements for system-level integration, support for varied boot modes, and improved data movement across the platform. These advancements facilitate the deployment of OpenTitan in broader SoCs, even in scenarios lacking specific technology-dependent IPs, providing a deployment-ready research vehicle for the community. We integrated the extended Earl Grey architecture into a reference architecture in 22nm FDX technology node, and then we benchmarked the enhanced architecture’s performance analyzing the latency introduced by the external memory hierarchic levels, presenting significant improvements in cryptographic processing speed, achieving up to 2.7 x speedup for SHA-256/HMAC and 1.6 x for AES accelerators, compared to baseline Earl Grey architecture.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4402269101",
    "type": "article"
  },
  {
    "title": "End-To-End Latency of Cause-Effect Chains: A Tutorial",
    "doi": "https://doi.org/10.1145/3703630",
    "publication_date": "2024-11-11",
    "publication_year": 2024,
    "authors": "Mario Günzel; Harun Teper; Georg von der Brüggen; Jian-Jia Chen",
    "corresponding_authors": "",
    "abstract": "In many applications of cyber-physical systems, a sequence of tasks is necessary to perform a certain functionality. For example, from a sensor to an actuator, the first task reads the sensor value (cause), the second task processes the data, and the third task produces an output for the actuator (an effect is triggered). For such scenarios, the end-to-end timing properties (the so-called end-to-end latency) of the sequence of tasks (the so-called cause-effect chain) are of importance. This tutorial recaps different metrics for the end-to-end latency of cause-effect chains, and summarizes fundamental properties and existing analytical results in a systematic manner. To that end, this tutorial has a special focus on the reaction time (how fast can a reaction be in the worst case) and the data age (how old is the data source of an actuation in the worst case). The goal of this tutorial is to provide a systematic view of the fundamental end-to-end timing properties of cause-effect chains and offer an outlook of possible research directions in the near future. Furthermore, we extend the proof of one fundamental property in the literature to comply with the current state-of-the-art definition of end-to-end latencies.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4404247206",
    "type": "article"
  },
  {
    "title": "A case study of a system-level approach to power-aware computing",
    "doi": "https://doi.org/10.1145/860176.860178",
    "publication_date": "2003-08-01",
    "publication_year": 2003,
    "authors": "Thomas L. Martin; Daniel P. Siewiorek; Asim﻿ Smailagic; Matthew Bosworth; M. Ettus; Jolin Warren",
    "corresponding_authors": "",
    "abstract": "This paper introduces a systematic approach to power awareness in mobile, handheld computers. It describes experimental evaluations of several techniques for improving the energy efficiency of a system, ranging from the network level down to the physical level of the battery. At the network level, a new routing method based upon the power consumed by the network subsystem is shown to improve power consumption by 15% on average and to reduce latency by 75% over methods that consider only the transmitted power. At the boundary between the network and the processor levels, the paper presents the problem of local versus remote processing and derives a figure of merit for determining whether a computation should be completed locally or remotely, one that involves the relative performance of the local and remote system, the transmission bandwidth and power consumption, and the network congestion. At the processor level, the main memory bandwidth is shown to have a significant effect on the relationship between performance and CPU frequency, which in turn determines the energy savings of dynamic CPU speed-setting. The results show that accounting for the main memory bandwidth using Amdahl's law permits the performance speed-up and peak power versus the CPU frequency to be estimated to within 5%. The paper concludes with a technique for mitigating the loss of battery energy capacity with large peak currents, showing an improvement of up to 10% in battery life, albeit at some cost to the size and weight of the system.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1975141330",
    "type": "article"
  },
  {
    "title": "The embedded software consortium of taiwan",
    "doi": "https://doi.org/10.1145/1086519.1086527",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Taiyi Huang; Chung‐Ta King; Youn-Long Steve Lin; Yin‐Tsung Hwang",
    "corresponding_authors": "",
    "abstract": "The advancement of semiconductor manufacturing technology makes it practical to place a traditional board-level embedded system on a single chip. The evolvement of system-on-chip (SoC) techniques presents new challenges for integrated circuit designs as well as embedded software and systems. To address these challenges, the Ministry of Education (MOE) of Taiwan has been running the VLSI Circuits and Systems Education Program since 1996. This program adopts a top-down approach by forming six domain-specific, intercollegiate consortia. The Embedded Software (ESW) consortium addresses the challenges of embedded software for SoC systems. This paper first introduces the six-consortium architecture and the organization and programs of ESW. We next describe the embedded software curriculum developed by ESW. This curriculum will later be implemented in most universities and colleges in Taiwan to promote the capabilities of embedded software design and implementations. Finally, we present an execution summary of ESW 2004.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1971899020",
    "type": "article"
  },
  {
    "title": "Offset assignment using simultaneous variable coalescing",
    "doi": "https://doi.org/10.1145/1196636.1196641",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "Desiree Ottoni; Guilherme Ottoni; Guido Araújo; Rainer Leupers",
    "corresponding_authors": "",
    "abstract": "The generation of efficient addressing code is a central problem in compiling for processors with restricted addressing modes, like digital signal processors (DSPs). Offset assignment (OA) is the problem of allocating scalar variables to memory, so as to minimize the need of addressing instructions. This problem is called simple offset assignment (SOA) when a single address register is available, and general offset assignment (GOA) when more address registers are used. This paper shows how variables' liveness information can be used to dramatically reduce the addressing instructions required to access local variables on the program stack. Two techniques that make effective use of variable coalescing to solve SOA and GOA are described, namely coalescing SOA (CSOA) and coalescing GOA (CGOA). In addition, a thorough comparison between these algorithms and others described in the literature is presented. The experimental results, when compiling MediaBench benchmark programs with the LANCE compiler, reveal a very significant improvement of the proposed techniques over the other available solutions to the problem.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1981718090",
    "type": "article"
  },
  {
    "title": "The implementation and evaluation of dynamic code decompression using DISE",
    "doi": "https://doi.org/10.1145/1053271.1053274",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Marc L. Corliss; E. Christopher Lewis; Amir Roth",
    "corresponding_authors": "",
    "abstract": "Code compression coupled with dynamic decompression is an important technique for both embedded and general-purpose microprocessors. Postfetch decompression , in which decompression is performed after the compressed instructions have been fetched, allows the instruction cache to store compressed code but requires a highly efficient decompression implementation. We propose implementing postfetch decompression using a new hardware facility called dynamic instruction stream editing (DISE). DISE provides a programmable decoder---similar in structure to those in many IA-32 processors---that is used to add functionality to an application by injecting custom code snippets into its fetched instruction stream. We present a DISE-based implementation of postfetch decompression and show that it naturally supports customized program-specific decompression dictionaries, enables parameterized decompression allowing similar-but-not-identical instruction sequences to share dictionary entries, and uses no decompression-specific hardware. We present extensive experimental results showing the virtue of this approach and evaluating the factors that impact its efficacy. We also present implementation-neutral results that give insight into the characteristics of any postfetch decompression technique. Our experiments not only demonstrate significant reduction in code size (up to 35%) but also significant improvements in performance (up to 20%) and energy (up to 10%).",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2005212720",
    "type": "article"
  },
  {
    "title": "Loops in esterel",
    "doi": "https://doi.org/10.1145/1113830.1113832",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "Olivier Tardieu; Robert de Simone",
    "corresponding_authors": "",
    "abstract": "ESTEREL is a synchronous design language for the specification of reactive systems. Thanks to its compact formal semantics, code generation for ESTEREL is essentially provably correct. In practice, due to the many intricacies of an optimizing compiler, an actual proof would be in order. To begin with, we need a precise description of an efficient translation scheme, into some lower-level formalism. We tackle this issue on a specific part of the compilation process: the translation of loop constructs. First, because of instantaneous loops, programs may generate runtime errors, which cannot be tolerated for embedded systems, and have to be predicted and prevented at compile time. Second, because of schizophrenia , loops must be partly unfolded, making C code generation, as well as logic synthesis, nonlinear in general. Clever expansion strategies are required to minimize the unfolding. We first characterize these two difficulties w.r.t. the formal semantics of ESTEREL. We then derive very efficient, correct-by-construction algorithms to verify and transform loops at compile time, using static analysis and program rewriting techniques. With this aim in view, we extend the language with a new gotopause construct, which we use to encode loops. It behaves as a noninstantaneous jump instruction compatible with concurrency.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1981858646",
    "type": "article"
  },
  {
    "title": "A new efficient EDA tool design methodology",
    "doi": "https://doi.org/10.1145/1151074.1151082",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "James Lapalme; E.M. Aboulhamid; Gabriela Nicolescu",
    "corresponding_authors": "",
    "abstract": "New sophisticated EDA tools and methodologies will be needed to make products viable in the future marketplace by simplifying the various design stages. These tools will permit system design at a high abstraction level and enable automatic refinement through several abstraction levels to obtain a final prototype. They will have to be based on representations that are clean, complete, and easy to manipulate. In order to develop these new EDA tools, key features such as standardization, metadata programming, reflectivity, and introspection are needed. This work proposes a .Net Framework-based methodology, which possesses all these required key features. This methodology simplifies specification, synthesis, and validation of systems and enables the efficient creation/customization of EDA tools at low cost and development time. We show the effectiveness of this methodology by presenting its application for the design of a new EDA tool called ESys .Net (Embedded System design with .Net). We emphasize the specification and simulation aspects of this tool.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2053316647",
    "type": "article"
  },
  {
    "title": "Compile-time and instruction-set methods for improving floating- to fixed-point conversion accuracy",
    "doi": "https://doi.org/10.1145/1347375.1347379",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Tor M. Aamodt; Paul Chow",
    "corresponding_authors": "",
    "abstract": "This paper proposes and evaluates compile time and instruction-set techniques for improving the accuracy of signal-processing algorithms run on fixed-point embedded processors. These techniques are proposed in the context of a profile guided floating- to fixed-point compiler-based conversion process. A novel fixed-point scaling algorithm (IRP) is introduced that exploits correlations between values in a program by applying fixed-point scaling, retaining as much precision as possible without causing overflow. This approach is extended into a more aggressive scaling algorithm (IRP-SA) by leveraging the modulo nature of 2's complement addition and subtraction to discard most significant bits that may not be redundant sign-extension bits. A complementary scaling technique (IDS) is then proposed that enables the fixed-point scaling of a variable to be parameterized, depending upon the context of its definitions and uses. Finally, a novel instruction-set enhancement— fractional multiplication with internal left shift (FMLS)—is proposed to further leverage interoperand correlations uncovered by the IRP-SA scaling algorithm. FMLS preserves a different subset of the full product's bits than traditional fractional fixed-point or integer multiplication. On average, FMLS combined with IRP-SA improves accuracy on processors with uniform bitwidth register architectures by the equivalent of 0.61 bits of additional precision for a set of signal-processing benchmarks (up to 2 bits). Even without employing FMLS, the IRP-SA scaling algorithm achieves additional accuracy over two previous fixed-point scaling algorithms by averages of 1.71 and 0.49 bits. Furthermore, as FMLS combines multiplication with a scaling shift, it reduces execution time by an average of 9.8%. An implementation of IDS, specialized to single-nested loops, is found to improve accuracy of a lattice filter benchmark by the equivalent of more than 16-bits of precision.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1987780915",
    "type": "article"
  },
  {
    "title": "Implementing fault-tolerance in real-time programs by automatic program transformations",
    "doi": "https://doi.org/10.1145/1376804.1376813",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Tolga Ayav; Pascal Fradet; Alain Girault",
    "corresponding_authors": "",
    "abstract": "We present a formal approach to implement fault-tolerance in real-time embedded systems. The initial fault-intolerant system consists of a set of independent periodic tasks scheduled onto a set of fail-silent processors connected by a reliable communication network. We transform the tasks such that, assuming the availability of an additional spare processor, the system tolerates one failure at a time (transient or permanent). Failure detection is implemented using heartbeating, and failure masking using checkpointing and rollback. These techniques are described and implemented by automatic program transformations on the tasks' programs. The proposed formal approach to fault-tolerance by program transformations highlights the benefits of separation of concerns. It allows us to establish correctness properties and to compute optimal values of parameters to minimize fault-tolerance overhead. We also present an implementation of our method, to demonstrate its feasibility and its efficiency.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2076167568",
    "type": "article"
  },
  {
    "title": "A design framework for real-time embedded systems with code size and energy constraints",
    "doi": "https://doi.org/10.1145/1331331.1331342",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Sheayun Lee; Insik Shin; Woonseok Kim; Insup Lee; Sang Lyul Min",
    "corresponding_authors": "",
    "abstract": "Real-time embedded systems are typically constrained in terms of three system performance criteria: space, time, and energy. The performance requirements are directly translated into constraints imposed on the system's resources, such as code size, execution time, and energy consumption. These resource constraints often interact or even conflict with each other in a complex manner, making it difficult for a system developer to apply a well-defined design methodology in developing a real-time embedded system. Motivated by this observation, we propose a design framework that can flexibly balance the tradeoff involving the system's code size, execution time, and energy consumption. Given a system specification and an optimization criteria, the proposed technique generates a set of design parameters in such a way that a system cost function is minimized while the given resource constraints are satisfied. Specifically, the technique derives code generation decision for each task so that a specific version of code is selected among a number of different ones that have distinct characteristics in terms of code size and execution time. In addition, the design framework determines the voltage/frequency setting for a variable voltage processor whose supply voltage can be adjusted at runtime in order to minimize the energy consumption while execution performance is degraded accordingly. The proposed technique formulates this design process as a constrained optimization problem. We show that this optimization problem is NP-hard and then provide a heuristic solution to it. We show that these seemingly conflicting design goals can be pursued by using a simple optimization algorithm that works with a single optimization criteria. Moreover, the optimization is driven by an abstract system specification given by the system developer, so that the system development process can be automated. The results from our simulation show that the proposed algorithm finds a solution that is close to the optimal one with the average error smaller than 1.0%.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2114752526",
    "type": "article"
  },
  {
    "title": "High-performance packet classification algorithm for multithreaded IXP network processor",
    "doi": "https://doi.org/10.1145/1331331.1331340",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Duo Liu; Chen Zheng; Bei Hua; Nenghai Yu; Xinan Tang",
    "corresponding_authors": "",
    "abstract": "Packet classification is crucial for the Internet to provide more value-added services and guaranteed quality of service. Besides hardware-based solutions, many software-based classification algorithms have been proposed. However, classifying at 10 Gbps speed or higher is a challenging problem and it is still one of the performance bottlenecks in core routers. In general, classification algorithms face the same challenge of balancing between high classification speed and low memory requirements. This paper proposes a modified recursive flow classification (RFC) algorithm, Bitmap-RFC, which significantly reduces the memory requirements of RFC by applying a bitmap compression technique. To speed up classifying speed, we exploit the multithreaded architectural features in various algorithm development stages from algorithm design to algorithm implementation. As a result, Bitmap-RFC strikes a good balance between speed and space. It can significantly keep both high classification speed and reduce memory space consumption. This paper investigates the main NPU software design aspects that have dramatic performance impacts on any NPU-based implementations: memory space reduction , instruction selection , data allocation , task partitioning , and latency hiding . We experiment with an architecture-aware design principle to guarantee the high performance of the classification algorithm on an NPU implementation. The experimental results show that the Bitmap-RFC algorithm achieves 10 Gbps speed or higher and has a good scalability on Intel IXP2800 NPU.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1984685231",
    "type": "article"
  },
  {
    "title": "On the exploitation of loop-level parallelism in embedded applications",
    "doi": "https://doi.org/10.1145/1457255.1457257",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Arun Kejariwal; Alexander V. Veidenbaum; Alexandru Nicolau; Milind Girkar; Xinmin Tian; Hideki Saito",
    "corresponding_authors": "",
    "abstract": "Advances in the silicon technology have enabled increasing support for hardware parallelism in embedded processors. Vector units, multiple processors/cores, multithreading, special-purpose accelerators such as DSPs or cryptographic engines, or a combination of the above have appeared in a number of processors. They serve to address the increasing performance requirements of modern embedded applications. To what extent the available hardware parallelism can be exploited is directly dependent on the amount of parallelism inherent in the given application and the congruence between the granularity of hardware and application parallelism. This paper discusses how loop-level parallelism in embedded applications can be exploited in hardware and software. Specifically, it evaluates the efficacy of automatic loop parallelization and the performance potential of different types of parallelism, viz., true thread-level parallelism (TLP), speculative thread-level parallelism and vector parallelism, when executing loops. Additionally, it discusses the interaction between parallelization and vectorization. Applications from both the industry-standard EEMBC®, 1 1.1, EEMBC 2.0 and the academic MiBench embedded benchmark suites are analyzed using the Intel® 2 C compiler. The results show the performance that can be achieved today on real hardware and using a production compiler, provide upper bounds on the performance potential of the different types of thread-level parallelism, and point out a number of issues that need to be addressed to improve performance. The latter include parallelization of libraries such as libc and design of parallel algorithms to allow maximal exploitation of parallelism. The results also point to the need for developing new benchmark suites more suitable to parallel compilation and execution. 1 Other names and brands may be claimed as the property of others. 2 Intel is a trademark of Intel Corporation or its subsidiaries in the United States and other countries.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2006406264",
    "type": "article"
  },
  {
    "title": "A framework for flexible scheduling in the RTSJ",
    "doi": "https://doi.org/10.1145/1814539.1814542",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Alexandros Zerzelidis; Andy Wellings",
    "corresponding_authors": "",
    "abstract": "This article presents a viable solution to introducing flexible scheduling in the Real-Time specification for Java (RTSJ), in the form of a flexible scheduling framework. The framework allows the concurrent use of multiple application-defined scheduling policies, each scheduling a subset of the total set of threads. Moreover, all threads, regardless of the policy under which they are scheduled, are permitted to share common resources. Thus, the framework can accommodate a variety of interworking applications (soft, firm, and hard) running under the RTSJ. The proposed approach is a two-level scheduling framework, where the first level is the RTSJ priority scheduler and the second level is under application control. This article describes the framework's protocol, examines the different types of scheduling policies that can be supported, and evaluates the proposed framework by measuring its execution cost. A description of an application-defined Earliest-Deadline-First (EDF) scheduler illustrates how the interface can be used. Minimum backward-compatible changes to the RTSJ specification are discussed to motivate the required interface. The only assumptions made about the underlying real-time operating system is that it supports preemptive priority-based dispatching of threads and that changes to priorities have immediate effect.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2037131197",
    "type": "article"
  },
  {
    "title": "Concentration-Resilient Mixture Preparation with Digital Microfluidic Lab-on-Chip",
    "doi": "https://doi.org/10.1145/3157094",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Sukanta Bhattacharjee; Yi-Ling Chen; Juinn-Dar Huang; Bhargab B. Bhattacharya",
    "corresponding_authors": "",
    "abstract": "Sample preparation plays a crucial role in almost all biochemical applications, since a predominant portion of biochemical analysis time is associated with sample collection, transportation, and preparation. Many sample-preparation algorithms are proposed in the literature that are suitable for execution on programmable digital microfluidic (DMF) platforms. In most of the existing DMF-based sample-preparation algorithms, a fixed target ratio is provided as input, and the corresponding mixing tree is generated as output. However, in many biochemical applications, target mixtures with exact component proportions may not be needed. From a biochemical perspective, it may be sufficient to prepare a mixture in which the input reagents may lie within a range of concentration factors. The choice of a particular valid ratio, however, strongly impacts solution-preparation cost and time. To address this problem, we propose a concentration-resilient ratio-selection method from the input ratio space so that the reactant cost is minimized. We propose an integer linear programming--based method that terminates very fast while producing the optimum solution, considering both uniform and weighted cost of reagents. Experimental results reveal that the proposed method can be used conveniently in tandem with several existing sample-preparation algorithms for improving their performance.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2787751710",
    "type": "article"
  },
  {
    "title": "A Hierarchical Distributed Runtime Resource Management Scheme for NoC-Based Many-Cores",
    "doi": "https://doi.org/10.1145/3182173",
    "publication_date": "2018-04-23",
    "publication_year": 2018,
    "authors": "Vasileios Tsoutsouras; Iraklis Anagnostopoulos; Dimosthenis Masouros; Dimitrios Soudris",
    "corresponding_authors": "",
    "abstract": "As technology constantly strengthens its presence in all aspects of human life, computing systems integrate a high number of processing cores, whereas applications become more complex and greedy for computational resources. Inevitably, this high increase in processing elements combined with the unpredictable resource requirements of executed applications at design time impose new design constraints to resource management of many-core systems, turning the distributed functionality into a necessity. In this work, we present a distributed runtime resource management framework for many-core systems utilizing a network-on-chip (NoC) infrastructure. Specifically, we couple the concept of distributed management with parallel applications by assigning different roles to the available computing resources. The presented design is based on the idea of local controllers and managers, whereas an on-chip intercommunication scheme ensures decision distribution. The evaluation of the proposed framework was performed on an Intel Single-Chip Cloud Computer, an actual NoC-based, many-core system. Experimental results show that the proposed scheme manages to allocate resources efficiently at runtime, leading to gains of up to 30% in application execution latency compared to relevant state-of-the-art distributed resource management frameworks.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2801051386",
    "type": "article"
  },
  {
    "title": "Self-Adaptive Filtering Algorithm with PCM-Based Memory Storage System",
    "doi": "https://doi.org/10.1145/3190856",
    "publication_date": "2018-05-22",
    "publication_year": 2018,
    "authors": "Su-Kyung Yoon; Ji-Tae Yun; Jung-Geun Kim; Shin‐Dug Kim",
    "corresponding_authors": "",
    "abstract": "This article proposes a new phase change memory– (PCM) based memory storage architecture with associated self-adaptive data filtering for various embedded devices to support energy efficiency as well as high computing power. In this approach, PCM-based memory storage can be used as working memory and mass storage layers simultaneously, and a self-adaptive data filtering module composed of small DRAM dual buffers was designed to improve unfavorable PCM features, such as asymmetric read/write access latencies and limited endurance and enhance spatial/temporal localities. In particular, the self-adaptive data filtering algorithm enhances data reusability by screening potentially high reusable data and predicting adequate lifetime of those data depending on current victim time decision value. We also propose the possibility that a small amount of DRAM buffer is embedded into mobile processors, keeping this as small as possible for cost effectiveness and energy efficiency. Experimental results show that by exploiting a small amount of DRAM space for dual buffers and using the self-adaptive filtering algorithm to manage them, the proposed system can reduce execution time by a factor of 1.9 compared to the unified conventional model with same the DRAM capacity and can be considered comparable to 1.5× DRAM capacity.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2803967706",
    "type": "article"
  },
  {
    "title": "DLSpace",
    "doi": "https://doi.org/10.1145/3284749",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Hui Sun; Jianzhong Huang; Xiao Qin; Changsheng Xie",
    "corresponding_authors": "",
    "abstract": "Due to limited numbers of program/erase cycles (i.e., P/Es) of NAND Flash, excessive out-of-place update and erase-before-write operations wear out these P/Es during garbage collections, which adversely shorten solid state disk (i.e., SSD) lifetime. The log space in NAND Flash space of an SSD performs as an updated page ′s buffer, which lowers garbage-collection frequency while reducing consumption of P/Es to extend SSD lifetime. In this article, we propose DLSpace, a novel distributed log space allocation strategy named d istributed l og space , which divides log space into block-level log space and page-level log space to significantly optimize SSD lifetime. DLSpace′s log page space is dedicated to data pages in a data block. Such log page space only buffers page-update operations in this data block; thereby the use of log blocks for postponing garbage collection delays. DLSpace is conducive to fully utilizing pages in data and log blocks to avoid erasures of blocks with free pages. Consequently, DLSpace decreases write amplification by reducing excessive valid page-rewrite and block-erase operations under random-write-intensive workloads. We carried out quantitative research on the extension of SSD lifetime by virtue of three metrics (i.e., write amplification, the number of block-erase operations, and the delay time before the first garbage collection occurring). Experimental results reveal that compared with the existing t raditional allocation strategy for l og space (i.e., TLSpace), DLSpace reduces write amplification and the number of erase operations by up to 55.2% and 64.1% to the most extent, respectively. DLSpace also extends TLSpace′s delay time of garbage collections by 73.3% to optimize SSD lifetime.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2904297721",
    "type": "article"
  },
  {
    "title": "Fault Modeling in Discrete Event Systems Using Petri Nets",
    "doi": "https://doi.org/10.1145/2406336.2406348",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Payam Nazemzadeh; Abbas Dideban; Meisam Zareiee",
    "corresponding_authors": "",
    "abstract": "In this article a model-based controller reconfiguration method for fault-tolerant control of discrete event systems has been introduced. In this method, we model the fault conditions for each specified fault as a new model called fault model. The system then consists of three different models called process, specification and fault. The faulty parts of the system are not permitted to do any job and the controller tries to enforce the specifications by other parts of the system. With this method, the controller reconfiguration problem for fault- tolerant control of discrete event systems converts to the problem of synchronizing the process, specification and fault model. We must synthesize a supervisor that can enforce both specifications and faults status. If this supervisor can be determined, we can achieve a fault-tolerant controller. Implementing both specification and fault models in the system, may lead to a large number of forbidden states and constraints and so on a more complicated forbidden states problem must be solved. The application of constraints simplification methods is shown. By the existing methods for offline simplifying of constraints, we can arrive at a simplified fault tolerant controller.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1980612154",
    "type": "article"
  },
  {
    "title": "Overload provisioning in mixed-criticality cyber-physical systems",
    "doi": "https://doi.org/10.1145/2362336.2362350",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Karthik Lakshmanan; Dionisio de Niz; Ragunathan Rajkumar; Gabriel A. Moreno",
    "corresponding_authors": "",
    "abstract": "Cyber-physical systems are an emerging class of applications that require tightly coupled interaction between the computational and physical worlds. These systems are typically realized using sensor/actuator interfaces connected with processing backbones. Safety is a primary concern in cyber-physical systems since the actuators directly influence the physical world. However, unexpected or unusual conditions in the physical world can manifest themselves as increased workload demands being offered to the computational infrastructure of a cyber-physical system. Guaranteeing system safety under overload conditions is therefore a prime concern in developing and deploying cyber-physical systems. In this work, we study this problem in the context of a radar surveillance system, where tasks have different levels of criticality or influence on system safety . In the face of overloads, we observe that the desirable property in such systems is that the more critical tasks continue to meet their timing requirements. We capture this mixed-criticality overload requirement using a formal overload-tolerance metric called ductility . Using this overload-tolerance metric, we first develop our solution in the context of uniprocessor systems, where we show that Zero-Slack scheduling (ZS) algorithms can be used to improve the overload behavior in mixed-criticality cyber-physical systems compared to existing fixed-priority scheduling algorithms like Rate-Monotonic Scheduling (RMS) and Criticality-As-Priority-Assignment (CAPA). Leveraging these results, we then develop a criticality-aware task allocation algorithm called Compress-on-Overload Packing (COP) for dealing with multiprocessor cyber-physical systems. Evaluation results show that COP achieves up to five times better ductility than traditional load balancing bin-packing algorithms like Worst-Fit Decreasing (WFD). Finally, we apply ZS and COP to the radar surveillance system to demonstrate the resulting improvement in system overload behavior. Our implementation of the Zero-Slack scheduler is available as a part of the Linux/RK project, which provides resource kernel extensions for Linux.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1984102801",
    "type": "article"
  },
  {
    "title": "On-chip memory architecture exploration framework for DSP processor-based embedded system on chip",
    "doi": "https://doi.org/10.1145/2146417.2146422",
    "publication_date": "2012-03-01",
    "publication_year": 2012,
    "authors": "T.S. Rajesh Kumar; R. Govindarajan; C.P. Ravikumar",
    "corresponding_authors": "",
    "abstract": "Today's SoCs are complex designs with multiple embedded processors, memory subsystems, and application specific peripherals. The memory architecture of embedded SoCs strongly influences the power and performance of the entire system. Further, the memory subsystem constitutes a major part (typically up to 70%) of the silicon area for the current day SoC. In this article, we address the on-chip memory architecture exploration for DSP processors which are organized as multiple memory banks, where banks can be single/dual ported with non-uniform bank sizes. In this paper we propose two different methods for physical memory architecture exploration and identify the strengths and applicability of these methods in a systematic way. Both methods address the memory architecture exploration for a given target application by considering the application's data access characteristics and generates a set of Pareto-optimal design points that are interesting from a power, performance and VLSI area perspective. To the best of our knowledge, this is the first comprehensive work on memory space exploration at physical memory level that integrates data layout and memory exploration to address the system objectives from both hardware design and application software development perspective. Further we propose an automatic framework that explores the design space identifying 100's of Pareto-optimal design points within a few hours of running on a standard desktop configuration.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2008437460",
    "type": "article"
  },
  {
    "title": "Managing the Quality vs. Efficiency Trade-off Using Dynamic Effort Scaling",
    "doi": "https://doi.org/10.1145/2465787.2465792",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Vinay K. Chippa; Kaushik Roy; Srimat Chakradhar; Anand Raghunathan",
    "corresponding_authors": "",
    "abstract": "Several current and emerging applications do not have a unique result for a given input; rather, functional correctness is defined in terms of output quality. Recently proposed design techniques exploit the inherent resilience of such applications and achieve improved efficiency (energy or performance) by foregoing correct execution of all the constituent computations. Hardware and software systems that are thus designed may be viewed as scalable effort systems, since they offer the capability to modulate the effort that they expend towards computation, thereby allowing for trade-offs between output quality and efficiency. We propose the concept of Dynamic Effort Scaling (DES), which refers to dynamic management of the control knobs that are exposed by scalable effort systems. We argue the need for DES by observing that the degree of resilience often varies significantly across applications, across datasets, and even within a dataset. We propose a general conceptual framework for DES by formulating it as a feedback control problem, wherein the scaling mechanisms are regulated with the goal of maintaining output quality at or above a specified limit. We present an implementation of Dynamic Effort Scaling for recognition and mining applications and evaluate it for the support vector machines and K-means clustering algorithms under various application scenarios and datasets. Our results clearly demonstrate the benefits of the proposed approach---statically setting the scaling mechanisms leads to either significant error overshoot or significant opportunities for energy savings left on the table unexploited. In contrast, DES is able to effectively regulate the output quality while maximally exploiting the time-varying resiliency in the workload.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2078962259",
    "type": "article"
  },
  {
    "title": "Accelerators for Breast Cancer Detection",
    "doi": "https://doi.org/10.1145/2983630",
    "publication_date": "2017-03-28",
    "publication_year": 2017,
    "authors": "Daniele Jahier Pagliari; Mario R. Casu; Luca P. Carloni",
    "corresponding_authors": "",
    "abstract": "Algorithms used in microwave imaging for breast cancer detection require hardware acceleration to speed up execution time and reduce power consumption. In this article, we present the hardware implementation of two accelerators for two alternative imaging algorithms that we obtain entirely from SystemC specifications via high-level synthesis. The two algorithms present opposite characteristics that stress the design process and the capabilities of commercial HLS tools in different ways: the first is communication bound and requires overlapping and pipelining of communication and computation in order to maximize the application throughput; the second is computation bound and uses complex mathematical functions that HLS tools do not directly support. Despite these difficulties, thanks to HLS, in the span of only 4 months we were able to explore a large design space and derive about 100 implementations with different cost-performance profiles, targeting both a Field-Programmable Gate Array (FPGA) platform and a 32-nm standard-cell Application Specific Integrated Circuit (ASIC) library. In addition, we could obtain results that outperform a previous Register-Transfer Level (RTL) implementation, which confirms the remarkable progress of HLS tools.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2602665985",
    "type": "article"
  },
  {
    "title": "Protecting Caches from Soft Errors",
    "doi": "https://doi.org/10.1145/3063180",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Yohan Ko; Reiley Jeyapaul; Youngbin Kim; Kyoungwoo Lee; Aviral Shrivastava",
    "corresponding_authors": "",
    "abstract": "Soft error is one of the most important design concerns in modern embedded systems with aggressive technology scaling. Among various microarchitectural components in a processor, cache is the most susceptible component to soft errors. Error detection and correction codes are common protection techniques for cache memory due to their design simplicity. In order to design effective protection techniques for caches, it is important to quantitatively estimate the susceptibility of caches without and even with protections. At the architectural level, vulnerability is the metric to quantify the susceptibility of data in caches. However, existing tools and techniques calculate the vulnerability of data in caches through coarse-grained block-level estimation. Further, they ignore common cache protection techniques such as error detection and correction codes. In this article, we demonstrate that our word-level vulnerability estimation is accurate through intensive fault injection campaigns as compared to block-level one. Further, our extensive experiments over benchmark suites reveal several counter-intuitive and interesting results. Parity checking when performed over just reads provides reliable and power-efficient protection than that when performed over both reads and writes. On the other hand, checking error correcting codes only at reads alone can be vulnerable even for single-bit soft errors, while that at both reads and writes provides the perfect reliability.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2612717736",
    "type": "article"
  },
  {
    "title": "Green-Energy-Powered Cognitive Radio Networks",
    "doi": "https://doi.org/10.1145/3092949",
    "publication_date": "2017-08-29",
    "publication_year": 2017,
    "authors": "Chi Xu; Wei Liang; Haibin Yu",
    "corresponding_authors": "",
    "abstract": "This article studies a green-energy-powered cognitive radio network (GCRN) in an underlay paradigm, wherein multiple battery-free secondary users (SUs) capture both the spectrum and the energy of primary users (PUs) to communicate with an access point (AP). By time division multiple access, each SU transmits data to AP in the allocated time and harvests energy from the RF signals of PUs otherwise, all in the same licensed spectrum concurrently with PUs. Thus, the transmit power of each SU is jointly constrained by the peak interference power at PU and the harvested energy of SU. With the formulated green coexistence paradigm, we investigate the sum-throughput maximization problem with respect to time and power allocation, which is non-convex. To obtain the optimal resource allocation, we propose a joint optimal time and power allocation (JOTPA) algorithm that first transforms the original problem into a convex optimization problem with respect to time and energy allocation, and then solve it by iterative Lagrange dual decomposition. To comprehensively evaluate the performance of the GCRN with JOTPA, we deploy the GCRN in three typical scenarios and compare JOTPA with the equal time and optimal power allocation (ETOPA) algorithm. Extensive simulations show that the deployment of the GCRN significantly influences the throughput performance and JOTPA outperforms ETOPA under all considered scenarios.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2753870323",
    "type": "article"
  },
  {
    "title": "An Efficient WCET-Aware Instruction Scheduling and Register Allocation Approach for Clustered VLIW Processors",
    "doi": "https://doi.org/10.1145/3126524",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Xuesong Su; Hui Wu; Jingling Xue",
    "corresponding_authors": "",
    "abstract": "In real-time embedded system design, one major goal is to construct a feasible schedule. Whether a feasible schedule exists depends on the Worst-Case Execution Time (WCET) of each task. Consequently, it is important to minimize the WCET of each task. We investigate the problem of instruction scheduling and register allocation for a program executed on a clustered Very Long Instruction Word (VLIW) processor such that the WCET of the program is minimized, and propose a novel, unified instruction scheduling and register allocation heuristic approach. Our heuristic approach is underpinned by a set of novel techniques, including spanning graph-based WCET-aware live range splitting, WCET-aware dynamic register pressure control, WCET-aware basic block prioritization for performing integrated instruction scheduling and register allocation, and WCET-aware spill code handling. We have implemented our approach in Trimaran 4.0, and compared it with the state-of-the-art approach by using a set of 20 benchmarks. The experimental results show that our approach achieves the maximum WCET improvement of 29.61% and the average WCET improvement of 10.23%, respectively.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2756587144",
    "type": "article"
  },
  {
    "title": "Demystifying Soft-Error Mitigation by Control-Flow Checking -- A New Perspective on its Effectiveness",
    "doi": "https://doi.org/10.1145/3126503",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Simon F. Schuster; Peter Ulbrich; Isabella Stilkerich; Christian Dietrich; Wolfgang Schröder‐Preikschat",
    "corresponding_authors": "",
    "abstract": "Soft errors are a challenging and urging problem in the domain of safety-critical embedded systems. For decades, checking schemes have been investigated and improved to mitigate soft-error effects for the class of control-flow faults, with current industrial standards strongly recommending their use. However, reality looks different: Taking a systems perspective, we implemented four representative Control-Flow Checking (CFC) schemes and put them through their paces in 396 fault-injection campaigns. In contrast to previous work, which typically relied on probability-based vulnerability metrics, we accounted for the influence of memory and time overheads on the fault-space dimensions and applied those in full-scan fault injections. This change in procedure alone severely degraded the perceived effectiveness of CFC. In addition, we expanded the perspective to data-flow faults and their influence on the overall susceptibility, an aspect that so far has been largely ignored. Our results suggest that, without accompanying measures, any improvement regarding control-flow faults is dominated by the increase in data faults caused by the increased attack surface in terms of memory and runtime overhead. Moreover, CFC performance less depended on the detection capabilities than on general aspects of the concrete binary compilation and execution. In conclusion, incorporating CFC is not as straightforward as often assumed and the vulnerability of systems with hardened control-flow may in many cases even be increased by the schemes themselves.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2757242886",
    "type": "article"
  },
  {
    "title": "Minimising Access Conflicts on Shared Multi-Bank Memory",
    "doi": "https://doi.org/10.1145/3126535",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Andreas Tretter; Georgia Giannopoulou; Matthias Baer; Lothar Thiele",
    "corresponding_authors": "",
    "abstract": "A common multi-core pattern consists of processors communicating through shared, multi-banked on-chip memory. Two approaches exist: Interleaved address mapping, which spreads consecutive data over all banks, and contiguous address mapping, which stores consecutive data on a single bank. In this work, we compare both approaches on the Kalray MPPA-256 platform. For contiguous mapping, we propose an algorithm, based on graph colouring techniques, to automatically perform the assignment of data blocks to memory banks with the goal of minimising access collisions and delays. Experiments with representative, parallel real-world benchmarks show that 69% of the tested configurations, when optimised for contiguous mapping by our algorithm, run up to 86% faster on average than with interleaved mapping.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2757501351",
    "type": "article"
  },
  {
    "title": "Combining Software Cache Partitioning and Loop Tiling for Effective Shared Cache Management",
    "doi": "https://doi.org/10.1145/3202663",
    "publication_date": "2018-05-22",
    "publication_year": 2018,
    "authors": "Vasilios Kelefouras; Γεώργιος Κεραμίδας; Nikolaos Voros",
    "corresponding_authors": "",
    "abstract": "One of the biggest challenges in multicore platforms is shared cache management, especially for data-dominant applications. Two commonly used approaches for increasing shared cache utilization are cache partitioning and loop tiling. However, state-of-the-art compilers lack efficient cache partitioning and loop tiling methods for two reasons. First, cache partitioning and loop tiling are strongly coupled together, and thus addressing them separately is simply not effective. Second, cache partitioning and loop tiling must be tailored to the target shared cache architecture details and the memory characteristics of the corunning workloads. To the best of our knowledge, this is the first time that a methodology provides (1) a theoretical foundation in the above-mentioned cache management mechanisms and (2) a unified framework to orchestrate these two mechanisms in tandem (not separately). Our approach manages to lower the number of main memory accesses by an order of magnitude keeping at the same time the number of arithmetic/addressing instructions to a minimal level. We motivate this work by showcasing that cache partitioning, loop tiling, data array layouts, shared cache architecture details (i.e., cache size and associativity), and the memory reuse patterns of the executing tasks must be addressed together as one problem, when a (near)-optimal solution is requested. To this end, we present a search space exploration analysis where our proposal is able to offer a vast deduction in the required search space.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2804647664",
    "type": "article"
  },
  {
    "title": "Memory-Constrained Vectorization and Scheduling of Dataflow Graphs for Hybrid CPU-GPU Platforms",
    "doi": "https://doi.org/10.1145/3157669",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Shuoxin Lin; Jiahao Wu; Shuvra S. Bhattacharyya",
    "corresponding_authors": "",
    "abstract": "The increasing use of heterogeneous embedded systems with multi-core CPUs and Graphics Processing Units (GPUs) presents important challenges in effectively exploiting pipeline, task, and data-level parallelism to meet throughput requirements of digital signal processing applications. Moreover, in the presence of system-level memory constraints, hand optimization of code to satisfy these requirements is inefficient and error prone and can therefore, greatly slow down development time or result in highly underutilized processing resources. In this article, we present vectorization and scheduling methods to effectively exploit multiple forms of parallelism for throughput optimization on hybrid CPU-GPU platforms, while conforming to system-level memory constraints. The methods operate on synchronous dataflow representations, which are widely used in the design of embedded systems for signal and information processing. We show that our novel methods can significantly improve system throughput compared to previous vectorization and scheduling approaches under the same memory constraints. In addition, we present a practical case-study of applying our methods to significantly improve the throughput of an orthogonal frequency division multiplexing receiver system for wireless communications.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2963502161",
    "type": "article"
  },
  {
    "title": "Counterexample Guided Abstraction Refinement for Polyhedral Probabilistic Hybrid Systems",
    "doi": "https://doi.org/10.1145/3358217",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Ratan Lal; Pavithra Prabhakar",
    "corresponding_authors": "",
    "abstract": "We consider the problem of safety analysis of probabilistic hybrid systems, which capture discrete, continuous and probabilistic behaviors. We present a novel counterexample guided abstraction refinement (CEGAR) algorithm for a subclass of probabilistic hybrid systems, called polyhedral probabilistic hybrid systems (PHS), where the continuous dynamics is specified using a polyhedral set within which the derivatives of the continuous executions lie. Developing a CEGAR algorithm for PHS is complex owing to the branching behavior due to the probabilistic transitions, and the infinite state space due to the real-valued variables. We present a practical algorithm by choosing a succinct representation for counterexamples, an efficient validation algorithm and a constructive method for refinement that ensures progress towards the elimination of a spurious abstract counterexample. The technical details for refinement are non-trivial since there are no clear disjoint sets for separation. We have implemented our algorithm in a Python toolbox called Procegar; our experimental analysis demonstrates the benefits of our method in terms of successful verification results, as well as bug finding.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2979598438",
    "type": "article"
  },
  {
    "title": "Unified Testing and Security Framework for Wireless Network-on-Chip Enabled Multi-Core Chips",
    "doi": "https://doi.org/10.1145/3358212",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Abhishek Vashist; Andrew Keats; Sai Manoj Pudukotai Dinakarrao; Amlan Ganguly",
    "corresponding_authors": "",
    "abstract": "On-chip wireless interconnects have been demonstrated to improve the performance and energy consumption of data communication in Network-on-Chips (NoCs). However, the wireless interfaces (WIs) can be defective, rendering these broken links severely affect the performance. This makes manufacturing test of the WIs critical. While analog testing of the transceivers is possible, such methodologies are impractical in a Wireless NoC (WiNoC) due to large overheads. In addition to testing, security is another prominent challenge in WiNoCs, as the security breach can happen due to embedded hardware Trojans or through external attacker exploiting the wireless medium. The typical security measures used in general wireless networks are not practical in a WiNoC due to unique network architectures and performance requirements of such a system. However, both testing and security defense can potentially leverage a basic monitoring framework which, can detect malfunctions or anomalies. Based on this idea, we propose a unified architecture for testing and attack detection and protection of on-chip wireless interconnects. We adopt a Built-In-Self Test (BIST) methodology to enable online monitoring of the wireless interconnects which can also be reused for monitoring the security threats. We focus on manufacturing defects of the WIs for testing and persistent jamming attack for the security measures, as this kind of attack is most likely on wireless communication systems. The BIST methodology is capable of detecting faults in the wireless links with a low aliasing probability of 2.32× 10 −10 . Additionally, the proposed unified architecture is able to detect the persistent jamming with an accuracy of 99.87% and suffer &lt; 3% communication bandwidth degradation even in the presence of attacks from either internal or external sources.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2979782395",
    "type": "article"
  },
  {
    "title": "Efficient Tracing Methodology Using Automata Processor",
    "doi": "https://doi.org/10.1145/3358200",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Minjun Seo; Fadi Kurdahi",
    "corresponding_authors": "",
    "abstract": "Tracing or trace interface has been used in various ways to find system defects or bugs. As embedded systems are increasingly used in safety-critical applications, tracing can provide useful information during system execution at runtime. Non-intrusive tracing that does not affect system performance has become especially important, but unfortunately, the biggest obstacle to this approach was the vast amount of real-time trace data, making it challenging to address complex requirements with relatively limited hardware implementations. Automata processors can be programmed with a memory-like structure of automata and have a structure specific to streaming data, large capacity, and parallel processing functions. This paper promotes the idea of high-level system-on-chip monitoring using automata processors. We used a safety-critical pacemaker application in the experiments, described timed automata (TA)-based requirements, and tested intentionally injected 4,000 random failures. The TA model converted for Automata Processor to monitor system, correctness, and safety properties achieved 100% failure detection rate in the experiment, and the detected failure is reported as fast enough to allow enough extent for failure recovery.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2979875482",
    "type": "article"
  },
  {
    "title": "IGOR, Get Me the Optimum! Prioritizing Important Design Decisions During the DSE of Embedded Systems",
    "doi": "https://doi.org/10.1145/3358204",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Fedor Smirnov; Behnaz Pourmohseni; Michael Glaß; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "Design Space Exploration (DSE) techniques for complex embedded systems must cope with a huge variety of applications and target architectures as well as a wide spectrum of objectives and constraints. In particular, existing design automation approaches are either problem-independent, in that they do not exploit any knowledge about the optimization problem at hand, or are tailored to specific a priori assumptions about the problem and/or a specific set of design objectives. While the latter are only applicable within a very limited scope of design problems, the former may struggle to deliver high-quality solutions for problems with large design spaces and/or complex design objectives. As a remedy, we propose Importance-Guided Order Rearrangement (IGOR) as a novel approach for DSE of embedded systems. Instead of relying on an a priori problem knowledge, IGOR uses a machine-learning-inspired technique to dynamically analyze the importance of design decisions, i.e., the impact that these decisions—within the specific problem that is being optimized—have on the quality of explored problem solutions w.r.t. the given design objectives. Throughout the DSE, IGOR uses this information to guide the optimization towards the most promising regions of the design space. Experimental results for a variety of applications from different domains of embedded computing and for different optimization scenarios give evidence that the proposed approach is both scalable and adaptable, as it can be used for the optimization of systems described by several thousands constraints, where it outperforms both problem-specific and problem-independent optimization approaches and achieves ε-dominance improvements of up to 95%.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2980073402",
    "type": "article"
  },
  {
    "title": "Hardware-Software Collaborative Thermal Sensing in Optical Network-on-Chip--based Manycore Systems",
    "doi": "https://doi.org/10.1145/3362099",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Mengquan Li; Weichen Liu; Nan Guan; Yiyuan Xie; Yaoyao Ye",
    "corresponding_authors": "",
    "abstract": "Continuous technology scaling in manycore systems leads to severe overheating issues. To guarantee system reliability, it is critical to accurately yet efficiently monitor runtime temperature distribution for effective chip thermal management. As an emerging communication architecture for new-generation manycore systems, optical network-on-chip (ONoC) satisfies the communication bandwidth and latency requirements with low power dissipation. Moreover, observation shows that it can be leveraged for runtime thermal sensing. In this article, we propose a brand-new on-chip thermal sensing approach for ONoC-based manycore systems by utilizing the intrinsic thermal sensitivity of optical devices and the inter-processor communications in ONoCs. It requires no extra hardware but utilizes existing optical devices in ONoCs and combines them with lightweight software computation in a hardware-software collaborative manner. The effectiveness of the our approach is validated both at the device level and the system level through professional photonic simulations. Evaluation results based on synthetic communication traces and realistic benchmarks show that our approach achieves an average temperature inaccuracy of only 0.6648 K compared to ground-truth values and is scalable to be applied for large-size ONoCs.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3011506477",
    "type": "article"
  },
  {
    "title": "SPECTRUM",
    "doi": "https://doi.org/10.1145/3400032",
    "publication_date": "2020-09-26",
    "publication_year": 2020,
    "authors": "Vanchinathan Venkataramani; Aditi Kulkarni; Tulika Mitra; Li-Shiuan Peh",
    "corresponding_authors": "",
    "abstract": "Wireless communication standards such as Long-term Evolution (LTE) are rapidly changing to support the high data-rate of wireless devices. The physical layer baseband processing has strict real-time deadlines, especially in the next-generation applications enabled by the 5G standard. Existing basestation transceivers utilize customized DSP cores or fixed-function hardware accelerators for physical layer baseband processing. However, these approaches incur significant non-recurring engineering costs and are inflexible to newer standards or updates. Software-programmable processors offer more adaptability. However, it is challenging to sustain guaranteed worst-case latency and throughput at reasonably low-power on shared-memory many-core architectures featuring inherently unpredictable design choices, such as caches and Network-on-chip (NoC). We propose SPECTRUM , a predictable, software-defined many-core architecture that exploits the massive parallelism of the LTE/5G baseband processing workload. The focus is on designing scalable lightweight hardware that can be programmed and defined by sophisticated software mechanisms. SPECTRUM employs hundreds of lightweight in-order cores augmented with custom instructions that provide predictable timing, a purely software-scheduled NoC that orchestrates the communication to avoid any contention, and per-core software-controlled scratchpad memory with deterministic access latency. Compared to many-core architecture like Skylake-SP (average power 215 W) that drops 14% packets at high-traffic load, 256-core SPECTRUM by definition has zero packet drop rate at significantly lower average power of 24 W. SPECTRUM consumes 2.11× lower power than C66x DSP cores+accelerator platform in baseband processing. We also enable SPECTRUM to handle dynamic workloads with multiple service categories present in 5G mobile network (Enhanced Mobile Broadband (eMBB), Ultra-reliable and Low-latency Communications (URLLC), and Massive Machine Type Communications (mMTC)), using a run-time scheduling and mapping algorithm. Experimental evaluations show that our algorithm performs task/NoC mapping at run-time on fewer cores compared to the static mapping (that reserves cores exclusively for each service category) while still meeting the differentiated latency and reliability requirements.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3089970417",
    "type": "article"
  },
  {
    "title": "SEAMS",
    "doi": "https://doi.org/10.1145/3466875",
    "publication_date": "2021-07-29",
    "publication_year": 2021,
    "authors": "Biswadip Maity; Bryan Donyanavard; Anmol Surhonne; Amir M. Rahmani; Andreas Herkersdorf; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Memory approximation techniques are commonly limited in scope, targeting individual levels of the memory hierarchy. Existing approximation techniques for a full memory hierarchy determine optimal configurations at design-time provided a goal and application. Such policies are rigid: they cannot adapt to unknown workloads and must be redesigned for different memory configurations and technologies. We propose SEAMS: the first self-optimizing runtime manager for coordinating configurable approximation knobs across all levels of the memory hierarchy. SEAMS continuously updates and optimizes its approximation management policy throughout runtime for diverse workloads. SEAMS optimizes the approximate memory configuration to minimize energy consumption without compromising the quality threshold specified by application developers. SEAMS can (1) learn a policy at runtime to manage variable application quality of service ( QoS ) constraints, (2) automatically optimize for a target metric within those constraints, and (3) coordinate runtime decisions for interdependent knobs and subsystems. We demonstrate SEAMS’ ability to efficiently provide functions (1)–(3) on a RISC-V Linux platform with approximate memory segments in the on-chip cache and main memory. We demonstrate SEAMS’ ability to save up to 37% energy in the memory subsystem without any design-time overhead. We show SEAMS’ ability to reduce QoS violations by 75% with &lt; 5% additional energy.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3192236955",
    "type": "article"
  },
  {
    "title": "Chauffeur: Benchmark Suite for Design and End-to-End Analysis of Self-Driving Vehicles on Embedded Systems",
    "doi": "https://doi.org/10.1145/3477005",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Biswadip Maity; Saehanseul Yi; Dongjoo Seo; Leming Cheng; Sung-Soo Lim; Jong-Chan Kim; Bryan Donyanavard; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Self-driving systems execute an ensemble of different self-driving workloads on embedded systems in an end-to-end manner, subject to functional and performance requirements. To enable exploration, optimization, and end-to-end evaluation on different embedded platforms, system designers critically need a benchmark suite that enables flexible and seamless configuration of self-driving scenarios, which realistically reflects real-world self-driving workloads’ unique characteristics. Existing CPU and GPU embedded benchmark suites typically (1) consider isolated applications, (2) are not sensor-driven, and (3) are unable to support emerging self-driving applications that simultaneously utilize CPUs and GPUs with stringent timing requirements. On the other hand, full-system self-driving simulators (e.g., AUTOWARE, APOLLO) focus on functional simulation, but lack the ability to evaluate the self-driving software stack on various embedded platforms. To address design needs, we present Chauffeur, the first open-source end-to-end benchmark suite for self-driving vehicles with configurable representative workloads. Chauffeur is easy to configure and run, enabling researchers to evaluate different platform configurations and explore alternative instantiations of the self-driving software pipeline. Chauffeur runs on diverse emerging platforms and exploits heterogeneous onboard resources. Our initial characterization of Chauffeur on different embedded platforms – NVIDIA Jetson TX2 and Drive PX2 – enables comparative evaluation of these GPU platforms in executing an end-to-end self-driving computational pipeline to assess the end-to-end response times on these emerging embedded platforms while also creating opportunities to create application gangs for better response times. Chauffeur enables researchers to benchmark representative self-driving workloads and flexibly compose them for different self-driving scenarios to explore end-to-end tradeoffs between design constraints, power budget, real-time performance requirements, and accuracy of applications.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3199910043",
    "type": "article"
  },
  {
    "title": "Comparative Analysis and Enhancement of CFG-based Hardware-Assisted CFI Schemes",
    "doi": "https://doi.org/10.1145/3476989",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Stefan Tauner; Mario Telesklav",
    "corresponding_authors": "",
    "abstract": "Subverting the flow of instructions (e.g., by use of code-reuse attacks) still poses a serious threat to the security of today’s systems. Various control flow integrity (CFI) schemes have been proposed as a powerful technique to detect and mitigate such attacks. In recent years, many hardware-assisted implementations of CFI enforcement based on control flow graphs (CFGs) have been presented by academia. Such approaches check whether control flow transfers follow the intended CFG by limiting the valid target addresses. However, these papers all target different platforms and were evaluated with different sets of benchmark applications, which makes quantitative comparisons hardly possible. For this paper, we have implemented multiple promising CFG-based CFI schemes on a common platform comprising a RISC-V within FPGA. By porting almost 40 benchmark applications to this system we can present a meaningful comparison of the various techniques in terms of run-time performance, hardware utilization, and binary size. In addition, we present an enhanced CFI approach that is inspired by what we consider the best concepts and ideas of previously proposed mechanisms. We have made this approach more practical and feature-complete by tackling some problems largely ignored previously. We show with this fine-grained scheme that CFI can be achieved with even less overheads than previously demonstrated.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3199915069",
    "type": "article"
  },
  {
    "title": "RiSA: A Reinforced Systolic Array for Depthwise Convolutions and Embedded Tensor Reshaping",
    "doi": "https://doi.org/10.1145/3476984",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Hyungmin Cho",
    "corresponding_authors": "Hyungmin Cho",
    "abstract": "Depthwise convolutions are widely used in convolutional neural networks (CNNs) targeting mobile and embedded systems. Depthwise convolution layers reduce the computation loads and the number of parameters compared to the conventional convolution layers. Many deep neural network (DNN) accelerators adopt an architecture that exploits the high data-reuse factor of DNN computations, such as a systolic array. However, depthwise convolutions have low data-reuse factor and under-utilize the processing elements (PEs) in systolic arrays. In this paper, we present a DNN accelerator design called RiSA, which provides a novel mechanism that boosts the PE utilization for depthwise convolutions on a systolic array with minimal overheads. In addition, the PEs in systolic arrays can be efficiently used only if the data items ( tensors ) are arranged in the desired layout. Typical DNN accelerators provide various types of PE interconnects or additional modules to flexibly rearrange the data items and manage data movements during DNN computations. RiSA provides a lightweight set of tensor management tasks within the PE array itself that eliminates the need for an additional module for tensor reshaping tasks. Using this embedded tensor reshaping, RiSA supports various DNN models, including convolutional neural networks and natural language processing models while maintaining a high area efficiency. Compared to Eyeriss v2, RiSA improves the area and energy efficiency for MobileNet-V1 inference by 1.91× and 1.31×, respectively.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3200280098",
    "type": "article"
  },
  {
    "title": "ForEVeR",
    "doi": "https://doi.org/10.1145/2514871",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Ritesh Parikh; Valeria Bertacco",
    "corresponding_authors": "",
    "abstract": "As silicon technology scales, modern processor and embedded systems are rapidly shifting towards complex chip multi-processor (CMP) and system-on-chip (SoC) designs. As a side effect of complexity of these designs, ensuring their correctness has become increasingly problematic. Within these domains, Network-on-Chips (NoCs) are a de-facto choice to implement on-chip interconnect; their design is quickly becoming extremely complex in order to keep up with communication performance demands. As a result, design errors in the NoC may go undetected and escape into the final silicon. In this work, we propose ForEVeR, a solution that complements the use of formal methods and runtime verification to ensure functional correctness in NoCs. Formal verification, due to its scalability limitations, is used to verify smaller modules, such as individual router components. To deliver correctness guarantees for the complete network, we propose a network-level detection and recovery solution that monitors the traffic in the NoC and protects it against escaped functional bugs. To this end, ForEVeR augments the baseline NoC with a lightweight checker network that alerts destination nodes of incoming packets ahead of time. If a bug is detected, flagged by missed packet arrivals, our recovery mechanism delivers the in-flight data safely to the intended destination via the checker network. ForEVeR's experimental evaluation shows that it can recover from NoC design errors at only 4.9% area cost for an 8x8 mesh interconnect, over a time interval ranging from 0.5K to 30K cycles per recovery event, and it incurs no performance overhead in the absence of errors. ForEVeR can also protect NoC operations against soft-errors: a growing concern with the scaling of silicon. ForEVeR leverages the same monitoring hardware to detect soft-error manifestations, in addition to design-errors. Recovery of the soft-error affected packets is guaranteed by building resiliency features into our checker network. ForEVeR incurs minimal performance penalty up to a flit error rate of 0.01% in lightly loaded networks.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2017983090",
    "type": "article"
  },
  {
    "title": "Thermal Optimization in Network-on-Chip-Based 3D Chip Multiprocessors Using Dynamic Programming Networks",
    "doi": "https://doi.org/10.1145/2584668",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Nizar Dahir; Ra’ed Al-Dujaily; Terrence Mak; Alex Yakovlev",
    "corresponding_authors": "",
    "abstract": "The substantial silicon density in 3D VLSI, albeit its numerous advantages, introduces serious thermal threats that would lead to faults and system failures. This article introduces a new strategy to effectively diffuse heat from NoC-based 3D CMPs. Runtime Dynamic Programming Network (DPN) is proposed to optimize routing directions and provide silicon temperature moderation. Both on-chip reliability and computational performance have been improved by 63% and 27%, respectively, with the DPN approach. This work enables a new avenue to explore the adaptability for future large-scale 3D integration.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2024901228",
    "type": "article"
  },
  {
    "title": "Failure Semantics for Modal Transition Systems",
    "doi": "https://doi.org/10.1145/2746336",
    "publication_date": "2015-09-09",
    "publication_year": 2015,
    "authors": "Ferenc Bujtor; Walter Vogler",
    "corresponding_authors": "",
    "abstract": "With the aim to preserve deadlock freedom, we define a new refinement preorder for modal transition systems (MTSs), using an MTS-specific variant of testing inspired by De Nicola and Hennessy. We characterize this refinement with a kind of failure semantics and show that it “supports itself,” for example, in the sense of thoroughness—in contrast to standard modal refinements. We present a conjunction operator with respect to our new refinement, which is quite different from existing ones. It always returns an MTS—again in contrast to the case of modal refinement. Finally, we also consider De Nicola’s and Hennessy’s may- and must-testing, where the latter leads to a semantics that is also compositional for hiding.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2039646283",
    "type": "article"
  },
  {
    "title": "Using Network Traffic to Infer Hardware State",
    "doi": "https://doi.org/10.1145/2700094",
    "publication_date": "2015-04-30",
    "publication_year": 2015,
    "authors": "Lanier Watkins; William H. Robinson; Raheem Beyah",
    "corresponding_authors": "",
    "abstract": "In this article, we illustrate that the boundary of a general-purpose node can be extended into the network by extracting information from network traffic generated by that general-purpose node to infer the state of its hardware components. This information is represented in a delay signature latent within the network traffic. In contrast, the traditional approach to determine the internal state of a node’s resources meant that a software application with internal processes had to be resident on the node. The aforementioned delay signature is the keystone that provides a correlation between network traffic and the internal state of the source node. We characterize this delay signature by (1) identifying the different types of assembly language instructions that source this delay and (2) describing how architectural techniques, such as instruction pipelining and caching, give rise to this delay signature. In theory, highly utilized nodes (due to multiple threads) will contain excessive context switching and contention for shared resources. One important shared resource is main memory, and excessive use of this resource by applications and internal processes eventually leads to a decrease in cache efficiency that eventually stalls the instruction pipeline. Our results support this theory; specifically, we have observed that excessive context switching in active applications increases the effective memory access time and wastes precious CPU cycles, thus adding additional delay to the execution of load, store, and other instructions. Because the operating system (OS) kernel accesses memory to send network packets, the delay signature is induced into network traffic in situations where user-level utilization is high. We demonstrate this theory in two case studies: (1) resource discovery in cluster grids and (2) network-based detection of bitcoin mining on compromised nodes.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2041515004",
    "type": "article"
  },
  {
    "title": "Process-variation-aware mapping of best-effort and real-time streaming applications to MPSoCs",
    "doi": "https://doi.org/10.1145/2490819",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Davit Mirzoyan; Benny Åkesson; Kees Goossens",
    "corresponding_authors": "",
    "abstract": "As technology scales, the impact of process variation on the maximum supported frequency (FMAX) of individual cores in a multiprocessor system-on-chip (MPSoC) becomes more pronounced. Task allocation without variation-aware performance analysis can greatly compromise performance and lead to a significant loss in yield , defined as the percentage of manufactured chips satisfying the application timing requirement . We propose variation-aware task allocation for best-effort and real-time streaming applications modeled as task graphs. Our solutions are primarily based on the throughput requirement, which is the most important timing requirement in many real-time streaming applications. The four main contributions of this work are (1) distinguishing best-effort firm real-time and soft real-time application classes, which require different optimization criteria, (2) using dataflow graphs, which are well suited for modeling and analysis of streaming applications, we explicitly model task execution both in terms of clock cycles (which is independent of variation) and seconds (which does depend on the variation of the resource), which we connect by an explicit binding, (3) we present two optimization approaches, which give different improvement results at different costs, (4) we present both exhaustive and heuristic algorithms that implement the optimization approaches. Our variation-aware mapping algorithms are tested on models of seven real applications and are compared to mapping methods that are unaware of hardware variation. Our results demonstrate (1) improvements in the average performance (3% on average) for best-effort applications, and (2) for firm real-time and soft real-time applications, yield improvements of up to 27% with an average of 15%, showing the effectiveness of our approaches.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2051525304",
    "type": "article"
  },
  {
    "title": "Plug&amp;Chip",
    "doi": "https://doi.org/10.1145/2661634",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Dionysios Diamantopoulos; Efstathios Sotiriou-Xanthopoulos; Kostas Siozios; George Economakos; Dimitrios Soudris",
    "corresponding_authors": "",
    "abstract": "In the embedded system domain there is a continuous demand towards providing higher flexibility for application development. This trend strives for virtual prototyping solutions capable of performing fast system simulation. Among other benefits, such a solution supports concurrent hardware/software system design by enabling to start developing, testing, and validating the embedded software substantially earlier than has been possible in the past. Towards this direction, throughout this article we introduce a new framework, named Plug&amp;Chip, targeting to support rapid prototyping of 2D and 3D digital systems. In contrast to other relevant approaches, our solution provides higher flexibility by enabling incremental system design, while also handling platforms developed with the usage of 3D integration technology.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2052548805",
    "type": "article"
  },
  {
    "title": "ColLoc",
    "doi": "https://doi.org/10.1145/2584656",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Xiuming Zhu; Pei-Chi Huang; Jianyong Meng; Song Han; Aloysius K. Mok; Deji Chen; Mark Nixon",
    "corresponding_authors": "",
    "abstract": "Localization in wireless sensor networks is an important functionality that is required for tracking personnel and assets in industrial environments, especially for emergency response. Current commercial localization systems such as GPS suffer from the limitations of either high cost or low availability in many situations (e.g., indoor environments that exclude direct line-of-sight signal reception). The development of industrial wireless sensor networks such as WirelessHART provides an alternative. In this article, we present the design and implementation of ColLoc: a collaborative location and tracking system on WirelessHART as an industrially viable solution. This solution is built upon several technological advances. First, ColLoc adds the roaming functionality to WirelessHART and thus provides a means for keeping mobile WirelessHART devices connected to the network. Second, ColLoc employs a collaborative framework to integrate different types of distance measurements into the location estimation algorithm by weighing them according to their precision levels. ColLoc adopts several novel techniques to improve distance estimation accuracy and decreases the RSSI presurvey cost. These techniques include introducing distance error range constraints to the measurements, judiciously selecting the initial point in location estimation and online updating the signal propagation models in the anchor nodes, integrating Extended Kalman Filter (EKF) with trilateration to track moving objects. Our implementation of ColLoc can be applied to any WirelessHART-conforming network because no modification is needed on the WirelessHART field devices. We have implemented a complete ColLoc system to validate both the design and the effectiveness of our localization algorithm. Our experiments show that the mobile device never drops out of the WirelessHART network while moving around; with the help of even one dependable anchor, using RSSI can yield at least 75% of distance errors below 5 meters, which is quite acceptable for many typical industrial automation applications.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2062081279",
    "type": "article"
  },
  {
    "title": "Utility-Based Resource Overbooking for Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/2660497",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Dionisio de Niz; Lutz Wrage; Anthony Rowe; Ragunathan Rajkumar",
    "corresponding_authors": "",
    "abstract": "Traditional hard real-time scheduling algorithms require the use of the worst-case execution times to guarantee that deadlines will be met. Unfortunately, many algorithms with parameters derived from sensing the physical world suffer large variations in execution time, leading to pessimistic overall utilization, such as visual recognition tasks. In this article, we present ZS-QRAM, a scheduling approach that enables the use of flexible execution times and application-derived utility to tasks in order to maximize total system utility. In particular, we provide a detailed description of the algorithm, the formal proofs for its temporal protection, and a detailed, evaluation. Our evaluation uses the Utility Degradation Resilience (UDR) showing that ZS-QRAM is able to obtain 4× as much UDR as ZSRM, a previous overbooking approach, and almost 2× as much UDR as Rate-Monotonic with Period Transformation (RM/TP). We then evaluate a Linux kernel module implementation of our scheduler on an Unmanned Air Vehicle (UAV) platform. We show that, by using our approach, we are able to keep the tasks that render the most utility by degrading lower-utility ones even in the presence of highly dynamic execution times.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2067348042",
    "type": "article"
  },
  {
    "title": "Python to accelerate embedded SoC design",
    "doi": "https://doi.org/10.1145/2560032",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Evangelos Logaras; Orsalia Hazapis; Ηλίας Σ. Μανωλάκος",
    "corresponding_authors": "",
    "abstract": "We present SysPy (System Python) a tool which exploits the strengths of the popular Python scripting language to boost design productivity of embedded System on Chips for FPGAs. SysPy acts as a “glue” software between mature HDLs, ready-to-use VHDL components and programmable processor soft IP cores. SysPy can be used to: (i) automatically translate hardware components described in Python into synthesizable VHDL, (ii) capture top-level structural descriptions of processor-centric SoCs in Python, (iii) implement all the steps necessary to compile the user's C code for an instruction set processor core and generate processor specific Tcl scripts that import to the design project all the necessary HDL files of the processor's description and instantiate/connect the core to other blocks in a synthesizable top-level Python description. Moreover, we have developed a Hardware Abstraction Layer (HAL) in Python which allows user applications running in a host PC to utilize effortlessly the SoC's resources in the FPGA. SysPy's design capabilities, when complemented with the developed HAL software API, provide all the necessary tools for hw/sw partitioning and iterative design for efficient SoC's performance tuning. We demonstrate how SysPy's design flow and functionalities can be used by building a processor-centric embedded SoC for computational systems biology. The designed SoC, implemented using a Xilinx Virtex-5 FPGA, combines the flexibility of a programmable soft processor core (Leon3) with the high performance of an application specific core to simulate flexibly and efficiently the stochastic behavior of large size biomolecular reaction networks. Such networks are essential for studying the dynamics of complex biological systems consisting of multiple interacting pathways.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2133661715",
    "type": "article"
  },
  {
    "title": "Libra",
    "doi": "https://doi.org/10.1145/2638552",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Xavier Jimenez; David Novo; Paolo Ienne",
    "corresponding_authors": "",
    "abstract": "Hybrid flash storages combine a small Single-Level Cell (SLC) partition with a large Multilevel Cell (MLC) partition. Compared to MLC-only solutions, the SLC partition exploits fast and short local write updates, while the MLC part brings large capacity. On the whole, hybrid storage achieves a tangible performance improvement for a moderate extra cost. Yet, device lifetime is an important aspect often overlooked: in a hybrid system, a large ratio of writes may be directed to the small SLC partition, thus generating a local stress that could exhaust the SLC lifetime significantly sooner than the MLC partition's. To address this issue, we propose Libra , which builds on flash storage made solely of MLC flash and uses the memory devices in SLC mode when appropriate; that is, we exploit the fact that writing a single bit per cell in an MLC provides characteristics close to those of an ordinary SLC. In our scheme, the cell bit-density of a block can be decided dynamically by the flash controller, and the physical location of the SLC partition can now be moved around the whole device, balancing wear across it. This article provides a thorough analysis and characterization of the SLC mode for MLCs and gives evidence that the inherent flexibility provided by Libra simplifies considerably the stress balance on the device. Overall, our technique improves lifetime by up to one order of magnitude at no cost when compared to any hybrid storage that relies on a static SLC-MLC partitioning.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2159935132",
    "type": "article"
  },
  {
    "title": "Combating Software and Sybil Attacks to Data Integrity in Crowd-Sourced Embedded Systems",
    "doi": "https://doi.org/10.1145/2629338",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Akshay Dua; Nirupama Bulusu; Wu-chang Feng; Wen Hu",
    "corresponding_authors": "",
    "abstract": "Crowd-sourced mobile embedded systems allow people to contribute sensor data, for critical applications, including transportation, emergency response and eHealth. Data integrity becomes imperative as malicious participants can launch software and Sybil attacks modifying the sensing platform and data. To address these attacks, we develop (1) a Trusted Sensing Peripheral (TSP) enabling collection of high-integrity raw or aggregated data, and participation in applications requiring additional modalities; and (2) a Secure Tasking and Aggregation Protocol (STAP) enabling aggregation of TSP trusted readings by untrusted intermediaries, while efficiently detecting fabricators. Evaluations demonstrate that TSP and STAP are practical and energy-efficient.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2164064806",
    "type": "article"
  },
  {
    "title": "Power-Aware Design Techniques of Secure Multimode Embedded Systems",
    "doi": "https://doi.org/10.1145/2801152",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Ke Jiang; Petru Eles; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "Nowadays, embedded systems have been widely used in all types of application areas, some of which belong to the safety and reliability critical domains. The functional correctness and design robustness of the embedded systems involved in such domains are crucial for the safety of personal/enterprise property or even human lives. Thereby, a holistic design procedure that considers all the important design concerns is essential. In this article, we approach embedded systems design from an integral perspective. We consider not only the classic real-time and quality of service requirements, but also the emerging security and power efficiency demands. Modern embedded systems are not any more developed for a fixed purpose, but instead designed for undertaking various processing requests. This leads to the concept of multimode embedded systems, in which the number and nature of active tasks change during runtime. Under dynamic situations, providing high performance along with various design concerns becomes a really difficult problem. Therefore, we propose a novel power-aware secure embedded systems design framework that efficiently solves the problem of runtime quality optimization with security and power constraints. The efficiency of our proposed techniques are evaluated in extensive experiments.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2270708983",
    "type": "article"
  },
  {
    "title": "Efficient Code Assignment Techniques for Local Memory on Software Managed Multicores",
    "doi": "https://doi.org/10.1145/2738039",
    "publication_date": "2015-12-08",
    "publication_year": 2015,
    "authors": "Jing Lü; Ke Bai; Aviral Shrivastava",
    "corresponding_authors": "",
    "abstract": "Scaling the memory hierarchy is a major challenge when we scale the number of cores in a multicore processor. Software Managed Multicore (SMM) architectures come up as one of the promising solutions. In an SMM architecture, there are no caches, and each core has only a local scratchpad memory [Banakar et al. 2002]. As the local memory usually is small, large applications cannot be directly executed on it. Code and data of the task mapped to each core need to be managed between global memory and local memory. This article solves the problem of efficiently managing code on an SMM architecture. The primary requirement of generating efficient code assignments is a correct management cost model. In this article, we address this problem by proposing a cost calculation graph. In addition, we develop two heuristics CMSM (Code Mapping for Software Managed multicores) and CMSM_advanced that result in efficient code management execution on the local scratchpad memory. Experimental results collected after executing applications from the MiBench suite [Guthaus et al. 2001] demonstrate that merely by adopting the correct management cost calculation, even using previous code assignment schemes, we can improve performance by an average of 12%. Combining the correct management cost model and a more optimized code mapping algorithm together, our heuristics can reduce runtime in more than 80% of the cases, and by up to 20% on our set of benchmarks, compared to the state-of-the-art code assignment approach [Jung et al. 2010]. When compared with Instruction-level Parallelism (ILP) results, CMSM_advanced performs an average of 5% worse. We also simulate the benchmarks on a cache-based system, and find that the code management overhead on SMM core with our code management is much less than memory latency of a cache-based system.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2294447652",
    "type": "article"
  },
  {
    "title": "Dynamic Logging with Dylog in Networked Embedded Systems",
    "doi": "https://doi.org/10.1145/2807698",
    "publication_date": "2015-12-31",
    "publication_year": 2015,
    "authors": "Wei Dong; Luyao Luo; Chao Huang",
    "corresponding_authors": "",
    "abstract": "Event logging is an important technique for networked embedded systems like wireless sensor networks. It can greatly help developers to understand complex system behaviors and diagnose program bugs. Existing logging facilities do not well satisfy three practical requirements: flexibility , efficiency , and high synchronization accuracy . To simultaneously satisfy these requirements, we present Dylog, a dynamic logging facility for networked embedded systems. Dylog employs several techniques. First, Dylog uses binary instrumentation for dynamically inserting or removing logging statements, enabling flexible and interactive debugging at runtime. Second, Dylog incorporates an efficient storage system and log collection protocol for recording and transferring the logging messages. Third, Dylog employs a lightweight data-driven approach for reconstructing the synchronized time of the logging messages. Dylog uses MAC-layer timestamping and drift compensation to achieve high synchronization accuracy . We implement Dylog on the TinyOS 2.1.1/TelosB platform. Results show the following: (1) Dylog incurs a small overhead. Indirections in Dylog incur an additional execution overhead of less than 1%. Dylog reduces the logging storage size by approximately 50% compared with the standard TinyOS radio printf library. Dylog reduces the patch size by more than 90%, compared with incremental reprogramming. (2) Dylog reduces the synchronization overhead by 78% in terms of transmission cost, compared with a traditional time synchronization protocol, FTSP, and it can achieve a high time synchronization accuracy of 5.4μs. (3) Dylog can help diagnose system problems effectively at the source-code level for three real-world scenarios.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2342048762",
    "type": "article"
  },
  {
    "title": "Image-Content-Aware I/O Optimization for Mobile Virtualization",
    "doi": "https://doi.org/10.1145/2950059",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Renhai Chen; Yi Wang; Jingtong Hu; Duo Liu; Zili Shao; Yong Guan",
    "corresponding_authors": "",
    "abstract": "Mobile virtualization introduces extra layers in software stacks, which leads to performance degradation. Notably, each I/O operation has to pass through several software layers to reach the NAND-flash-based storage systems. This article targets at optimizing I/O for mobile virtualization, since I/O becomes one of major performance bottlenecks that seriously affects the performance of mobile devices. Among all the I/O operations, a large percentage is to update metadata. Frequently updated metadata not only degrade overall I/O performance but also severely reduce flash memory lifetime. In this article, we propose a novel I/O optimization technique to identify the metadata of a guest file system that is stored in a virtual machine image file and frequently updated. Then, these metadata are stored in a small additional non-volatile memory (NVM), which is faster and more endurable to greatly improve flash memory’s performance and lifetime. To the best of our knowledge, this is the first work to identify the file system metadata from regular data in a guest OS image file with NVM optimization. The proposed scheme is evaluated on a real hardware embedded platform. The experimental results show that the proposed techniques can improve write performance to 45.21% in mobile devices with virtualization.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2530586562",
    "type": "article"
  },
  {
    "title": "SPMPool",
    "doi": "https://doi.org/10.1145/2968447",
    "publication_date": "2016-10-23",
    "publication_year": 2016,
    "authors": "Hossein Tajik; Bryan Donyanavard; Nikil Dutt; Janmartin Jahn; Jörg Henkel",
    "corresponding_authors": "",
    "abstract": "Distributed Scratchpad Memories (SPMs) in embedded many-core systems require careful selection of data placement to achieve good performance. Applications mapped to these platforms have varying memory requirements based on their runtime behavior, resulting in under- or overutilization of the local SPMs. We propose SPMPool to share the available on-chip SPMs on many-cores among concurrently executing applications in order to reduce the overall memory access latency. By pooling SPM resources, we can assign underutilized memory resources, due to idle cores or low memory usage, to applications dynamically. SPMPool is the first workload-aware SPM mapping solution for many-cores that dynamically allocates data at runtime—using profiled data—to address the unpredictable set of concurrently executing applications. Our experiments on workloads with varying interapplication memory intensity show that SPMPool can achieve up to 76% reduction in memory access latency for configurations ranging from 16 to 256 cores, compared to the traditional approach that limits executing cores to use their local SPMs.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2536355481",
    "type": "article"
  },
  {
    "title": "Scenario Based Run-Time Switching for Adaptive CNN-Based Applications at the Edge",
    "doi": "https://doi.org/10.1145/3488718",
    "publication_date": "2022-02-08",
    "publication_year": 2022,
    "authors": "Svetlana Minakova; Dolly Sapra; Todor Stefanov; Andy D. Pimentel",
    "corresponding_authors": "",
    "abstract": "Convolutional Neural Networks (CNNs) are biologically inspired computational models that are at the heart of many modern computer vision and natural language processing applications. Some of the CNN-based applications are executed on mobile and embedded devices. Execution of CNNs on such devices places numerous demands on the CNNs, such as high accuracy, high throughput, low memory cost, and low energy consumption. These requirements are very difficult to satisfy at the same time, so CNN execution at the edge typically involves trade-offs (e.g., high CNN throughput is achieved at the cost of decreased CNN accuracy). In existing methodologies, such trade-offs are either chosen once and remain unchanged during a CNN-based application execution, or are adapted to the properties of the CNN input data. However, the application needs can also be significantly affected by the changes in the application environment, such as a change of the battery level in the edge device. Thus, CNN-based applications need a mechanism that allows to dynamically adapt their characteristics to the changes in the application environment at run-time. Therefore, in this article, we propose a scenario-based run-time switching (SBRS) methodology, that implements such a mechanism.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4210835752",
    "type": "article"
  },
  {
    "title": "Efficient-Grad: <u>Efficient</u> Training Deep Convolutional Neural Networks on Edge Devices with <u>Grad</u> ient Optimizations",
    "doi": "https://doi.org/10.1145/3504034",
    "publication_date": "2022-02-08",
    "publication_year": 2022,
    "authors": "Ziyang Hong; C. Patrick Yue",
    "corresponding_authors": "",
    "abstract": "With the prospering of mobile devices, the distributed learning approach, enabling model training with decentralized data, has attracted great interest from researchers. However, the lack of training capability for edge devices significantly limits the energy efficiency of distributed learning in real life. This article describes Efficient-Grad, an algorithm-hardware co-design approach for training deep convolutional neural networks, which improves both throughput and energy saving during model training, with negligible validation accuracy loss. The key to Efficient-Grad is its exploitation of two observations. Firstly, the sparsity has potential for not only activation and weight, but gradients and the asymmetry residing in the gradients for the conventional back propagation (BP). Secondly, a dedicated hardware architecture for sparsity utilization and efficient data movement can be optimized to support the Efficient-Grad algorithm in a scalable manner. To the best of our knowledge, Efficient-Grad is the first approach that successfully adopts a feedback-alignment (FA)-based gradient optimization scheme for deep convolutional neural network training, which leads to its superiority in terms of energy efficiency. We present case studies to demonstrate that the Efficient-Grad design outperforms the prior arts by 3.72x in terms of energy efficiency.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4210961870",
    "type": "article"
  },
  {
    "title": "ARES: Persistently Secure Non-Volatile Memory with Processor-transparent and Hardware-friendly Integrity Verification and Metadata Recovery",
    "doi": "https://doi.org/10.1145/3492735",
    "publication_date": "2022-01-31",
    "publication_year": 2022,
    "authors": "Yu Zou; Kazi Abu Zubair; Mazen Alwadi; Rakin Muhammad Shadab; Sanjay Gandham; Amro Awad; Mingjie Lin",
    "corresponding_authors": "",
    "abstract": "Emerging byte-addressable Non-Volatile Memory (NVM) technology, although promising superior memory density and ultra-low energy consumption, poses unique challenges to achieving persistent data privacy and computing security, both of which are critically important to the embedded and IoT applications. Specifically, to successfully restore NVMs to their working states after unexpected system crashes or power failure, maintaining and recovering all the necessary security-related metadata can severely increase memory traffic, degrade runtime performance, exacerbate write endurance problem, and demand costly hardware changes to off-the-shelf processors. In this article, we designed and implemented ARES, a new FPGA-assisted processor-transparent security mechanism that aims at efficiently and effectively achieving all three aspects of a security triad—confidentiality, integrity, and recoverability—in modern embedded computing. Given the growing prominence of CPU-FPGA heterogeneous computing architectures, ARES leverages FPGA’s hardware reconfigurability to offload performance-critical and security-related functions to the programmable hardware without microprocessors’ involvement. In particular, recognizing that the traditional Merkle tree caching scheme cannot fully exploit FPGA’s parallelism due to its sequential and recursive function calls, we (1) proposed a Merkle tree cache architecture that partitions a unified cache into multiple levels with parallel accesses and (2) further designed a novel Merkle tree scheme that flattened and reorganized the computation in the traditional Merkle tree verification and update processes to fully exploit the parallel cache ports and to fully pipeline time-consuming hashing operations. Beyond that, to accelerate the metadata recovery process, multiple parallel recovery units are instantiated to recover counter metadata and multiple Merkle sub-trees. Our hardware prototype of the ARES system on a Xilinx U200 platform shows that ARES achieved up to 1.4× lower latency and 2.6× higher throughput against the baseline implementation, while metadata recovery time was shortened by 1.8 times. When integrated with an embedded processor, neither hardware changes nor software changes are required. We also developed a theoretical framework to analytically model and explain experimental results.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4211030967",
    "type": "article"
  },
  {
    "title": "Prediction Modeling for Application-Specific Communication Architecture Design of Optical NoC",
    "doi": "https://doi.org/10.1145/3520241",
    "publication_date": "2022-03-26",
    "publication_year": 2022,
    "authors": "Jelena Trajković; Sara Karimi; Samantha Hangsan; Wenlu Zhang",
    "corresponding_authors": "",
    "abstract": "Multi-core systems-on-chip are becoming state-of-the-art. Therefore, there is a need for a fast and energy-efficient interconnect to take full advantage of the computational capabilities. Integration of silicon photonics with a traditional electrical interconnect in a Network-on-Chip (NoC) proposes a promising solution for overcoming the scalability issues of electrical interconnect. In this article, we derive and evaluate prediction modeling techniques for the design space exploration (DSE) of application-specific communication architectures for an Optical Network-on-Chip (ONoC). Our proposed model accurately predicts network packet latency, contention delay, and the static and dynamic energy consumption of the network. This work specifically addresses the challenge of accurately estimating performance metrics of the entire design space without having to perform time-consuming and computationally intensive exhaustive simulations. The proposed technique, based on machine learning (ML), can build accurate prediction models using only 10% to 50% (best case and worst case) of the entire design space. The accuracy, expressed as R 2 (Coefficient of Determination) is 0.99901, 0.99967, 0.99996, and 0.99999 for network packet latency, contention delay, static energy consumption, and dynamic energy consumption, respectively, in six different benchmarks from the Splash-2 benchmark suite, chosen among 6 different machine learning prediction models.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4221017003",
    "type": "article"
  },
  {
    "title": "Vector Extensions in COTS Processors to Increase Guaranteed Performance in Real-Time Systems",
    "doi": "https://doi.org/10.1145/3561054",
    "publication_date": "2022-08-31",
    "publication_year": 2022,
    "authors": "Roger Pujol; Josep Jorba; Hamid Tabani; Leonidas Kosmidis; Enrico Mezzetti; Jaume Abella; Francisco J. Cazorla",
    "corresponding_authors": "",
    "abstract": "The need for increased application performance in high-integrity systems such as those in avionics is on the rise as software continues to implement more complex functionalities. The prevalent computing solution for future high-integrity embedded products is multi-processor systems-on-chip (MPSoC) processors. MPSoCs include central processing unit (CPU) multicores that enable improving performance via thread-level parallelism. MPSoCs also include generic accelerators (graphics processing units [GPUs]) and application-specific accelerators. However, the data processing approach (DPA) required to exploit each of these underlying parallel hardware blocks carries several open challenges to enable the safe deployment in high-integrity domains. The main challenges include the qualification of its associated runtime system and the difficulties in analyzing programs deploying the DPA with out-of-the-box timing analysis and code coverage tools. In this work, we perform a thorough analysis of vector extensions (VExts) in current commercial off-the-shelf (COTS) processors for high-integrity systems. We show that VExts prevent many of the challenges arising with parallel programming models and GPUs. Unlike other DPAs, VExts require no runtime support, prevent design race conditions that might arise with parallel programming models, and have minimum impact on the software ecosystem, enabling the use of existing code coverage and timing analysis tools. We develop vectorized versions of neural network kernels and show that the NVIDIA Xavier VExts provide a reasonable increase in guaranteed application performance of up to 2.7x. Our analysis contends that VExts are the DPA approach with arguably the fastest path for adoption in high-integrity systems.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4293762547",
    "type": "article"
  },
  {
    "title": "Robust Cause-Effect Chains with Bounded Execution Time and System-Level Logical Execution Time",
    "doi": "https://doi.org/10.1145/3573388",
    "publication_date": "2022-12-06",
    "publication_year": 2022,
    "authors": "Leonie Köhler; Phil Hertha; Matthias Beckert; Alex Bendrick; Rolf Ernst",
    "corresponding_authors": "",
    "abstract": "In automotive and industrial real-time software systems, the primary timing constraints relate to cause-effect chains. A cause-effect chain is a sequence of linked tasks and it typically implements the process of reading sensor data, computing algorithms, and driving actuators. The classic timing analysis computes the maximum end-to-end latency of a given cause-effect chain to verify that its end-to-end deadline can be satisfied in all cases. This information is useful but not sufficient in practice: Software is usually evolving and updates may always alter the maximum end-to-end latency. It would be desirable to judge the quality of a software design a priori by quantifying how robust the timing of a given cause-effect chain will be in the presence of software updates. In this article, we derive robustness margins which guarantee that if software extensions stay within certain bounds, then the end-to-end deadline of a cause-effect chain can still be satisfied. Robustness margins are also useful to know if the system model has uncertain parameters. A robust system design can tolerate bounded deviations from the nominal system model without violating timing constraints. The results are applicable to both the bounded execution time programming model and the (system-level) logical execution time programming model. In this article, we study both an industrial use case from the automotive industry and analyze synthetically generated experiments with our open-source tool TORO.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4311644755",
    "type": "article"
  },
  {
    "title": "High-Level Approaches to Hardware Security: A Tutorial",
    "doi": "https://doi.org/10.1145/3577200",
    "publication_date": "2023-01-17",
    "publication_year": 2023,
    "authors": "Hammond Pearce; Ramesh Karri; Benjamin Tan",
    "corresponding_authors": "",
    "abstract": "Designers use third-party intellectual property (IP) cores and outsource various steps in the integrated circuit (IC) design and manufacturing flow. As a result, security vulnerabilities have been rising. This is forcing IC designers and end users to re-evaluate their trust in ICs. If attackers get hold of an unprotected IC, they can reverse engineer the IC and pirate the IP. Similarly, if attackers get hold of a design, they can insert malicious circuits or take advantage of \"backdoors\" in a design. Unintended design bugs can also result in security weaknesses. This tutorial paper provides an introduction to the domain of hardware security through two pedagogical examples of hardware security problems. The first is a walk-through of the scan chain-based side channel attack. The second is a walk-through of logic locking of digital designs. The tutorial material is accompanied by open access digital resources that are linked in this article.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4316813742",
    "type": "article"
  },
  {
    "title": "Lazy Load Scheduling for Mixed-criticality Applications in Heterogeneous MPSoCs",
    "doi": "https://doi.org/10.1145/3587694",
    "publication_date": "2023-03-14",
    "publication_year": 2023,
    "authors": "Tomasz Kloda; Giovani Gracioli; Rohan Tabish; Reza Mirosanlou; Renato Mancuso; Rodolfo Pellizzoni; Marco Caccamo",
    "corresponding_authors": "",
    "abstract": "Newly emerging multiprocessor system-on-a-chip (MPSoC) platforms provide hard processing cores with programmable logic (PL) for high-performance computing applications. In this article, we take a deep look into these commercially available heterogeneous platforms and show how to design mixed-criticality applications such that different processing components can be isolated to avoid contention on the shared resources such as last-level cache and main memory. Our approach involves software/hardware co-design to achieve isolation between the different criticality domains. At the hardware level, we use a scratchpad memory (SPM) with dedicated interfaces inside the PL to avoid conflicts in the main memory. At the software level, we employ a hypervisor to support cache-coloring such that conflicts at the shared L2 cache can be avoided. In order to move the tasks in/out of the SPM memory, we rely on a DMA engine and propose a new CPU-DMA co-scheduling policy, called Lazy Load , for which we also derive the response time analysis. The results of a case study on image processing demonstrate that the contention on the shared memory subsystem can be avoided when running with our proposed architecture. Moreover, comprehensive schedulability evaluations show that the newly proposed Lazy Load policy outperforms the existing CPU-DMA scheduling approaches and is effective in mitigating the main memory interference in our proposed architecture.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4324142396",
    "type": "article"
  },
  {
    "title": "Automatic Generation of Resource and Accuracy Configurable Processing Elements",
    "doi": "https://doi.org/10.1145/3594540",
    "publication_date": "2023-04-25",
    "publication_year": 2023,
    "authors": "Luis G. León-Vega; Eduardo Salazar-Villalobos; Alejandro Rodriguez-Figueroa; J. Castro Godinez",
    "corresponding_authors": "",
    "abstract": "Low-power consumption and scarce computational resources limit the computation at the edge. Besides, the approximate computing paradigm reports promising techniques for designing accelerators to deal with inherent limitations of the edge, and high-level synthesis with C++ opens the opportunity to use meta-programming for specialisable generic design. This work proposes a framework for automatically generating synthesis-time configurable processing elements (PEs) for matrix multiplication-addition (GEMMA) and convolution. To evaluate our work, we perform a design exploration after varying data bit-width, operand sizes, and kernel sizes. Our analyses include resource consumption scaling, clocks-to-solution, design efficiency, and error distribution, presenting a comprehensive view of how the parameters affect the properties of our generic implementations. The GEMMA presented a trade-off between granularity vs efficiency , where large PEs with short data widths are favoured by the design efficiency, achieving, theoretically, up to 75 GMAC/s on a Xilinx XC7Z020 @ 100 MHz with an efficiency of 27%. For design efficiency, we propose a figure of merit to evaluate operations per second and resource utilisation with respect to the maximum achievable by the FPGA. Regarding the convolution PEs, we implemented two algorithms: a window-based spatial convolution and Winograd. The former is the best in terms of performance with 150 GMAC/s, reaching up to 47% of efficiency. Winograd also outperformed numerically using a 3× 3 kernel filter, presenting a mean error of 11.01% in 4-bits operands with a PSNR=16.28 dB, compared to the spatial convolution with 38.2% of mean error and PSNR=5.89 dB. Finally, we discuss how the error is mostly dependent on the PE’s parameters. In the GEMMA, the error depends on the matrix size, causing limitations in the PE scaling but still applicable to accelerators. The PEs developed during this research will lead to further granular approximate accelerator research.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4366985336",
    "type": "article"
  },
  {
    "title": "Optimal Checkpointing Strategy for Real-time Systems with Both Logical and Timing Correctness",
    "doi": "https://doi.org/10.1145/3603172",
    "publication_date": "2023-06-01",
    "publication_year": 2023,
    "authors": "Lin Zhang; Zifan Wang; Fanxin Kong",
    "corresponding_authors": "",
    "abstract": "Real-time systems are susceptible to adversarial factors such as faults and attacks, leading to severe consequences. This paper presents an optimal checkpoint scheme to bolster fault resilience in real-time systems, addressing both logical consistency and timing correctness. First, we partition message-passing processes into a directed acyclic graph (DAG) based on their dependencies, ensuring checkpoint logical consistency. Then, we identify the DAG’s critical path, representing the longest sequential path, and analyze the optimal checkpoint strategy along this path to minimize overall execution time, including checkpointing overhead. Upon fault detection, the system rolls back to the nearest valid checkpoints for recovery. Our algorithm derives the optimal checkpoint count and intervals, and we evaluate its performance through extensive simulations and a case study. Results show a 99.97% and 67.86% reduction in execution time compared to checkpoint-free systems in simulations and the case study, respectively. Moreover, our proposed strategy outperforms prior work and baseline methods, increasing deadline achievement rates by 31.41% and 2.92% for small-scale tasks and 78.53% and 4.15% for large-scale tasks.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4378982095",
    "type": "article"
  },
  {
    "title": "Reg-Tune: A Regression-Focused Fine-Tuning Approach for Profiling Low Energy Consumption and Latency",
    "doi": "https://doi.org/10.1145/3623380",
    "publication_date": "2023-09-08",
    "publication_year": 2023,
    "authors": "Arnab Neelim Mazumder; Farshad Safavi; Maryam Rahnemoonfar; Tinoosh Mohsenin",
    "corresponding_authors": "",
    "abstract": "Fine-tuning deep neural networks is pivotal for creating inference modules that can be suitably imported to edge or field-programmable gate array (FPGA) platforms. Traditionally, exploration of different parameters throughout the layers of deep neural networks has been done using grid search and other brute force techniques. Although these methods lead to the optimal choice of network parameters, the search process can be very time consuming and may not consider deployment constraints across different target platforms. This work addresses this problem by proposing Reg-Tune, a regression-based profiling approach to quickly determine the trend of different metrics in relation to hardware deployment of neural networks on tinyML platforms like FPGAs and edge devices. We start by training a handful of configurations belonging to different combinations of \\(\\mathcal {NN}\\scriptstyle \\langle q (quantization),\\,s (scaling)\\rangle \\displaystyle\\) or \\(\\mathcal {NN}\\scriptstyle \\langle r (resolution),\\,s\\rangle \\displaystyle\\) workloads to generate the accuracy values respectively for their corresponding application. Next, we deploy these configurations on the target device to generate energy/latency values. According to our hypothesis, the most energy-efficient configuration suitable for deployment on the target device is a function of the variables q , r , and s . Finally, these trained and deployed configurations and their related results are used as data points for polynomial regression with the variables q , r , and s to realize the trend for accuracy/energy/latency on the target device. Our setup allows us to choose the near-optimal energy-consuming or latency-driven configuration for the desired accuracy from the contour profiles of energy/latency across different tinyML device platforms. To this extent, we demonstrate the profiling process for three different case studies and across two platforms for energy and latency fine-tuning. Our approach results in at least 5.7 \\(\\times\\) better energy efficiency when compared to recent implementations for human activity recognition on FPGA and 74.6% reduction in latency for semantic segmentation of aerial imagery on edge devices compared to baseline deployments.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386546945",
    "type": "article"
  },
  {
    "title": "A Self-Sustained CPS Design for Reliable Wildfire Monitoring",
    "doi": "https://doi.org/10.1145/3608100",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Yiğit Tuncel; Toygun Başaklar; Dina Carpenter-Graffy; Ümit Y. Ogras",
    "corresponding_authors": "",
    "abstract": "Continuous monitoring of areas nearby the electric grid is critical for preventing and early detection of devastating wildfires. Existing wildfire monitoring systems are intermittent and oblivious to local ambient risk factors, resulting in poor wildfire awareness. Ambient sensor suites deployed near the gridlines can increase the monitoring granularity and detection accuracy. However, these sensors must address two challenging and competing objectives at the same time. First, they must remain powered for years without manual maintenance due to their remote locations. Second, they must provide and transmit reliable information if and when a wildfire starts. The first objective requires aggressive energy savings and ambient energy harvesting, while the second requires continuous operation of a range of sensors. To the best of our knowledge, this paper presents the first self-sustained cyber-physical system that dynamically co-optimizes the wildfire detection accuracy and active time of sensors. The proposed approach employs reinforcement learning to train a policy that controls the sensor operations as a function of the environment (i.e., current sensor readings), harvested energy, and battery level. The proposed cyber-physical system is evaluated extensively using real-life temperature, wind, and solar energy harvesting datasets and an open-source wildfire simulator. In long-term (5 years) evaluations, the proposed framework achieves 89% uptime, which is 46% higher than a carefully tuned heuristic approach. At the same time, it averages a 2-minute initial response time, which is at least 2.5× faster than the same heuristic approach. Furthermore, the policy network consumes 0.6 mJ per day on the TI CC2652R microcontroller using TensorFlow Lite for Micro, which is negligible compared to the daily sensor suite energy consumption.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386568838",
    "type": "article"
  },
  {
    "title": "VADF: <u>V</u> ersatile <u>A</u> pproximate <u>D</u> ata <u>F</u> ormats for Energy-Efficient Computing",
    "doi": "https://doi.org/10.1145/3609106",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Vishesh Mishra; Sparsh Mittal; Neelofar Hassan; Rekha Singhal; Urbi Chatterjee",
    "corresponding_authors": "",
    "abstract": "Approximate computing (AC) techniques provide overall performance gains in terms of power and energy savings at the cost of minor loss in application accuracy. For this reason, AC has emerged as a viable method for efficiently supporting several compute-intensive applications, e.g., machine learning, deep learning, and image processing, that can tolerate bounded errors in computations. However, most prior techniques do not consider the possibility of soft errors or malicious bit-flips in AC systems. These errors may interact with approximation-introduced errors in unforeseen ways, leading to disastrous consequences, such as the failure of computing systems. A recent research effort, FTApprox (DATE’21) proposes an error-resilient approximate data format. FTApprox stores two blocks, starting from the one containing the most significant valid (MSV) bit. It also stores location of the MSV block and protects them using error-correcting bits (ECBs). However, FTApprox has crucial limitations such as lack of flexibility, redundantly storing zeros in the MSV, etc. In this paper, we propose a novel storage format named Versatile Approximate Data Format (VADF) for storing approximate integer numbers while providing resilience to soft errors. VADF prescribes rules for storing, for example, a 32-bit number in either 8-bit, 12-bit or 16-bit numbers. VADF identifies the MSV bit and stores a certain number of bits following the MSV bit. It also stores the location of the MSV bit and protects it by ECBs. VADF does not explicitly store the MSB bit itself and this prevents VADF from accruing significant errors. VADF incurs lower error than both truncation methodologies and FTApprox. We further evaluate five image-processing and machine-learning applications and confirm that VADF provides higher application quality than FTApprox in the presence and absence of soft errors. Finally, VADF allows the use of narrow arithmetic units. For example, instead of using a 32-bit multiplier/adder, one can first use VADF (or FTApprox) to compress the data and then use a 8-bit multiplier/adder. Through this approach, VADF facilitates 95.97% and 79.3% energy savings in multiplication and addition, respectively. However, the subsequent re-conversion of the 8-bit output data to 32-bit data using Inv-VADF(16,3,32) diminishes the energy savings by 9.6% for addition and 0.56% for multiplication operation, respectively. The code is available at https://github.com/CandleLabAI/VADF-ApproximateDataFormat-TECS .",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386574726",
    "type": "article"
  },
  {
    "title": "Mining Hyperproperties using Temporal Logics",
    "doi": "https://doi.org/10.1145/3609394",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Ezio Bartocci; Cristinel Mateis; Eleonora Nesterini; Dejan Ničković",
    "corresponding_authors": "",
    "abstract": "Formal specifications are essential to express precisely systems, but they are often difficult to define or unavailable. Specification mining aims to automatically infer specifications from system executions. The existing literature mainly focuses on learning properties defined on single system executions. However, many system characteristics, such as security policies and robustness, require relating two or more executions, and hence cannot be captured by properties. Hyperproperties address this limitation by allowing simultaneous reasoning about multiple executions with quantification over system traces. In this paper, we propose an effective approach for mining Hyper Signal Temporal Logic (HyperSTL) specifications. Our approach is based on the syntax-guided synthesis framework and allows users to control the amount of prior knowledge embedded in the mining procedure. To the best of our knowledge, this is the first mining method for hyperproperties that does not require a pre-defined template as input and allows for quantifier alternation. We implemented our approach and demonstrated its applicability and versatility in several case studies where we showed that we can use the same method to mine specifications both with and without templates, but also to infer subsets of HyperSTL, including STL, HyperLTL, LTL and non-temporal specifications.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386574778",
    "type": "article"
  },
  {
    "title": "ANV-PUF: Machine-Learning-Resilient NVM-Based Arbiter PUF",
    "doi": "https://doi.org/10.1145/3609388",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Hassan Nassar; Lars Bauer; Jörg Henkel",
    "corresponding_authors": "",
    "abstract": "Physical Unclonable Functions (PUFs) have been widely considered an attractive security primitive. They use the deviations in the fabrication process to have unique responses from each device. Due to their nature, they serve as a DNA-like identity of the device. But PUFs have also been targeted for attacks. It has been proven that machine learning (ML) can be used to effectively model a PUF design and predict its behavior, leading to leakage of the internal secrets. To combat such attacks, several designs have been proposed to make it harder to model PUFs. One design direction is to use Non-Volatile Memory (NVM) as the building block of the PUF. NVM typically are multi-level cells, i.e, they have several internal states, which makes it harder to model them. However, the current state of the art of NVM-based PUFs is limited to ‘weak PUFs’, i.e., the number of outputs grows only linearly with the number of inputs, which limits the number of possible secret values that can be stored using the PUF. To overcome this limitation, in this work we design the Arbiter Non-Volatile PUF (ANV-PUF) that is exponential in the number of inputs and that is resilient against ML-based modeling. The concept is based on the famous delay-based Arbiter PUF (which is not resilient against modeling attacks) while using NVM as a building block instead of switches. Hence, we replace the switch delays (which are easy to model via ML) with the multi-level property of NVM (which is hard to model via ML). Consequently, our design has the exponential output characteristics of the Arbiter PUF and the resilience against attacks from the NVM-based PUFs. Our results show that the resilience to ML modeling, uniqueness, and uniformity are all in the ideal range of 50%. Thus, in contrast to the state-of-the-art, ANV-PUF is able to be resilient to attacks, while having an exponential number of outputs.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386578914",
    "type": "article"
  },
  {
    "title": "AMULET: a Mutation Language Enabling Automatic Enrichment of SysML Models",
    "doi": "https://doi.org/10.1145/3624583",
    "publication_date": "2023-09-16",
    "publication_year": 2023,
    "authors": "Bastien Sultan; Léon Frenot; Ludovic Apvrille; Philippe Jaillon; Sophie Coudert",
    "corresponding_authors": "",
    "abstract": "SysML models are widely used for designing and analyzing complex systems. Model-based design methods often require successive modifications of the models, whether for incrementally refining the design (e.g. in agile development methods) or for testing different design options. Such modifications, or mutations, are also used in mutation-based testing approaches. However, the definition of mutation operators can be a complex issue and applying them to models is sometimes performed by hand: this is time consuming and error prone. The paper addresses this issue thanks to the introduction of AMULET, the first mutation language for SysML. AMULET encompasses the modifications targeting SysML block and state-machine diagrams, and is supported by a compiler the paper presents. This compiler is integrated in TTool, an open-source SysML toolkit, enabling the full support of design methods including model design, mutation and verification tasks in a unique toolkit. The paper also introduces two case-studies providing concrete examples of AMULET use for modeling vulnerabilities and cyber attacks, and highlighting the benefits of AMULET for SysML mutations.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4386803648",
    "type": "article"
  },
  {
    "title": "COBRRA: COntention-aware cache Bypass with Request-Response Arbitration",
    "doi": "https://doi.org/10.1145/3632748",
    "publication_date": "2023-11-17",
    "publication_year": 2023,
    "authors": "Aritra Bagchi; Dinesh Joshi; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "In modern multi-processor systems-on-chip (MPSoCs), requests from different processor cores, accelerators, and their responses from the lower-level memory contend for the shared cache bandwidth, making it a critical performance bottleneck. Prior research on shared cache management has considered requests from cores but has ignored crucial contributions from their responses. Prior cache bypass techniques focused on data reuse and neglected the system-level implications of shared cache contention. We propose COBRRA, a novel shared cache controller policy that mitigates the contention by aggressively bypassing selected responses from the lower-level memory and scheduling the remaining requests and responses to the cache efficiently. COBRRA is able to improve the average performance of a set of 15 SPEC workloads by 49% and 33% compared to the no-bypass baseline and the best-performing state-of-the-art bypass solution, respectively. Furthermore, COBRRA reduces the overall cache energy consumption by 38% and 31% compared to the no-bypass baseline and the most energy-efficient state-of-the-art bypass solution, respectively.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4388763441",
    "type": "article"
  },
  {
    "title": "Scheduling refinement in abstract RTOS models",
    "doi": "https://doi.org/10.1145/1151074.1151079",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Fabiano Hessel; Vitor M. Da Rosa; Carlos Reif; César Marcon; Tatiana G. S. dos Santos",
    "corresponding_authors": "",
    "abstract": "Scheduling decision for real-time embedded software applications has a great impact on system performance and, therefore, is an important issue in RTOS design. Moreover, it is highly desirable to have the system designer able to evaluate and select the right scheduling policy at high abstraction levels, in order to allow faster exploration of the design space. In this paper, we address this problem by introducing an abstract RTOS model, as well as a new approach to refine an unscheduled high-level model to a high-level model with RTOS scheduling. This approach is based on SystemC language and enables the system designer to quickly evaluate different dynamic scheduling policies and make the optimal choice in early design stages. Furthermore, we present a case of study where our model is used to simulate and analyze a telecom system.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2030615970",
    "type": "article"
  },
  {
    "title": "Power macromodeling of MPSoC message passing primitives",
    "doi": "https://doi.org/10.1145/1274858.1274869",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Mirko Loghi; Luca Benini; Massimo Poncino",
    "corresponding_authors": "",
    "abstract": "Estimating the energy consumption of software in multiprocessor systems-on-chip (MPSoCs) is crucial for enabling quick evaluations of both software and hardware optimizations. However, high-level estimations should be applicable at software level, possibly constructing effective power models depending on parameters that can be extracted directly from the application characteristics. We propose a methodology for accurate analysis of power consumption of message-passing primitives in a MPSoC, and, in particular, an energy model which, in spite of its simplicity, allows to model the traffic-dependent nature of energy consumption through the use of a single, abstract parameter, namely, the size of the message exchanged.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2063749661",
    "type": "article"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/1210268.1216577",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "David Whalley",
    "corresponding_authors": "David Whalley",
    "abstract": "No abstract available.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4244044976",
    "type": "editorial"
  },
  {
    "title": "Uniprocessor scheduling under precedence constraints for embedded systems design",
    "doi": "https://doi.org/10.1145/1324969.1324975",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Leonardo Mangeruca; Massimo Baleani; Alberto Ferrari; Alberto Sangiovanni‐Vincentelli",
    "corresponding_authors": "",
    "abstract": "In this paper, we present a novel approach to the constrained scheduling problem, while addressing a more general class of constraints that arise from the timing requirements on real-time embedded controllers. We provide general necessary and sufficient conditions for scheduling under precedence constraints and derive sufficient conditions for two well-known scheduling policies. We define mathematical problems that provide optimum priority and deadline assignments, while ensuring both precedence constraints and system's schedulability. We show how these problems can be relaxed to corresponding integer linear programming (ILP) formulations leveraging on available solvers. The results are demonstrated on a real design case.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2002620973",
    "type": "article"
  },
  {
    "title": "Power-efficient prefetching for embedded processors",
    "doi": "https://doi.org/10.1145/1210268.1210271",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Xiaotong Zhuang; Santosh Pande",
    "corresponding_authors": "",
    "abstract": "Because of stringent power constraints, aggressive latency-hiding approaches, such as prefetching, are absent in the state-of-the-art embedded processors. There are two main reasons that make prefetching power inefficient. First, compiler-inserted prefetch instructions increase code size and, therefore, could increase I-cache power. Second, inaccurate prefetching (especially for hardware prefetching) leads to high D-cache power consumption because of useless accesses. In this work, we show that it is possible to support power-efficient prefetching through bit-differential offset assignment. We target the prefetching of relocatable stack variables with a high degree of precision. By assigning the offsets of stack variables in such a way that most consecutive addresses differ by 1 bit, we can prefetch them with compact prefetch instructions to save I-cache power. The compiler first generates an access graph of consecutive memory references and then attempts a layout of the memory locations in the smallest hypercube. Each dimension of the hypercube represents a 1-bit differential addressing. The embedding is carried out in as compact a hypercube as possible in order to save memory space. Each load/store instruction carries a hint regarding prefetching the next memory reference by encoding its differential address with respect to the current one. To reduce D-cache power cost, we further attempt to assign offsets so that most of the consecutive accesses map to the same cache line. Our prefetching is done using a one entry line buffer [Wilson et al. 1996]. Consequently, many look-ups in D-cache reduce to incremental ones. This results in D-cache activity reduction and power savings. Our prefetcher requires both compiler and hardware support. In this paper, we provide implementation on the processor model close to ARM with small modification to the ISA. We tackle issues such as out-of-order commit, predication, and speculation through simple modifications to the processor pipeline on noncritical paths. Our goal in this work is to boost performance while maintaining/lowering power consumption. Our results show 12% speedup and slight power reduction. The runtime virtual space loss for stack and static data is about 11.8%.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2042687482",
    "type": "article"
  },
  {
    "title": "Probabilistic design of multimedia embedded systems",
    "doi": "https://doi.org/10.1145/1275986.1275987",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Shaoxiong Hua; Gang Qu; Shuvra S. Bhattacharyya",
    "corresponding_authors": "",
    "abstract": "In this paper, we propose the novel concept of probabilistic design for multimedia embedded systems, which is motivated by the challenge of how to design, but not overdesign, such systems while systematically incorporating performance requirements of multimedia application, uncertainties in execution time, and tolerance for reasonable execution failures. Unlike most present techniques that are based on either worst- or average-case execution times of application tasks, where the former guarantees the completion of each execution, but often leads to overdesigned systems, and the latter fails to provide any completion guarantees, the proposed probabilistic design method takes advantage of unique features mentioned above of multimedia systems to relax the rigid hardware requirements for software implementation and avoid overdesigning the system. In essence, this relaxation expands the design space and we further develop an off-line on-line minimum effort algorithm for quick exploration of the enlarged design space at early design stages. This is the first step toward our goal of bridging the gap between real-time analysis and embedded software implementation for rapid and economic multimedia system design. It is our belief that the proposed method has great potential in reducing system resource while meeting performance requirements. The experimental results confirm this as we achieve significant saving in system's energy consumption to provide a statistical completion ratio guarantee (i.e., the expected number of completions over a large number of iterations is greater than a given value).",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2044919843",
    "type": "article"
  },
  {
    "title": "Low-latency time-portable real-time programming with Exotasks",
    "doi": "https://doi.org/10.1145/1457255.1457262",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Joshua Auerbach; David F. Bacon; Daniel Iercan; Christoph Kirsch; V. T. Rajan; Harald Röck; Rainer Trummer",
    "corresponding_authors": "",
    "abstract": "Exotasks are a novel Java programming construct that achieve three important goals. They achieve low latency while allowing the fullest use of Java language features, compared to previous attempts to restrict the Java language for use in the submillisecond domain. They support pluggable schedulers, allowing easy implementation of new scheduling paradigms in a real-time Java system. They can achieve deterministic timing, even in the presence of other Java threads, and across changes of hardware and software platform. To achieve these goals, the program is divided into tasks with private heaps. Tasks may be strongly isolated, communicating only with each other and guaranteeing determinism, or weakly isolated, allowing some communication with the rest of the Java application. Scheduling of the tasks' execution, garbage collection, and value passing is accomplished by the pluggable scheduler. Schedulers that we have written employ logical execution time (LET) in association with strong isolation to achieve time portability. We have also built a quad-rotor model helicopter, the JAviator, which we use to evaluate our implementation of Exotasks in an experimental embedded version of IBM's J9 real-time virtual machine. Our experiments show that we are able to maintain very low scheduling jitter and deterministic behavior in the face of variations in both software load and hardware platform. We also show that Exotasks perform nearly as well as Eventrons on a benchmark audio application.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2041012842",
    "type": "article"
  },
  {
    "title": "Automatic Segmentation and Recognition in Body Sensor Networks Using a Hidden Markov Model",
    "doi": "https://doi.org/10.1145/2331147.2331156",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Eric Guenterberg; Hassan Ghasemzadeh; Roozbeh Jafari",
    "corresponding_authors": "",
    "abstract": "One important application of body sensor networks is action recognition. Action recognition often implicitly requires partitioning sensor data into intervals, then labeling the partitions according to the action that each represents or as a non-action. The temporal partitioning stage is called segmentation, and the labeling is called classification. While many effective methods exist for classification, segmentation remains problematic. We present a technique inspired by continuous speech recognition that combines segmentation and classification using hidden Markov models. This technique is distributed across several sensor nodes. We show the results of this technique and the bandwidth savings over full data transmission.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1981731126",
    "type": "article"
  },
  {
    "title": "A Model Checking Based Approach to Bounding Worst-Case Execution Time for Multicore Processors",
    "doi": "https://doi.org/10.1145/2331147.2331166",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Lan Wu; Wei Zhang",
    "corresponding_authors": "",
    "abstract": "As multicore processors are increasingly adopted in industry, it has become a great challenge to accurately bound the worst-case execution time (WCET) for real-time systems running on multicore chips. This is particularly true because of the inter-thread interferences in accessing shared resources on multicores, such as shared L2 caches, which can significantly affect the performance but are very difficult to be estimated statically. This article proposes an approach to analyzing WCET for multicore processors with shared L2 instruction caches by using a model checking based method. We model each concurrent real-time thread, including the inter-thread cache interferences with a PROMELA process, and derive the WCET by using a binary search algorithm. To reduce the state explosion problem, we propose several techniques for reducing the memory consumption by exploiting domain-specific information. Our experiments indicate that compared to the static analysis technique based on extended ILP (integer linear programming), our approach improves the tightness of WCET estimation by more than 31.1% for the benchmarks we studied. However, due to the inherent complexity of multicore timing analysis and the state explosion problem, the model checking based approach currently can only work with small real-time kernels for dual-core processors.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1997315696",
    "type": "article"
  },
  {
    "title": "Enhancing user experiences by exploiting energy and launch delay trade-off of mobile multimedia applications",
    "doi": "https://doi.org/10.1145/2435227.2435233",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Yi-Fan Chung; Yin-Tsung Lo; Chung‐Ta King",
    "corresponding_authors": "",
    "abstract": "Launch delay has been an important factor affecting users' experiences in mobile multimedia applications. To launch applications quickly, modern mobile systems such as Android usually keep inactive applications in the background and manage them through an LRU-based activity stack. Whenever the user wants to run and interact with a background application again, that application can be switched back into the foreground quickly from the activity stack without delay in initializing the applications anew. Since background multimedia applications often continuously consume the battery power of the smart phone, the challenge is to effect a balance between application launch delay and battery lifetime. In this article, we propose innovative application management strategies that terminate “unbeneficial” background applications to save energy and pre-launch “beneficial” applications to improve the application launch delay. The proposed strategies are evaluated through a trace-driven simulation and a real experiment. The results show that the average application launch delay can be reduced by 15% while the average battery lifetime is increased by 18%.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2001284599",
    "type": "article"
  },
  {
    "title": "Addressing network-on-chip router transient errors with inherent information redundancy",
    "doi": "https://doi.org/10.1145/2485984.2485993",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Qiaoyan Yu; Meilin Zhang; Paul Ampadu",
    "corresponding_authors": "",
    "abstract": "We exploit the inherent information redundancy in the control path of Network-on-Chip (NoC) routers to manage transient errors, preventing packet loss and misrouting. Outputs of the routing arbitration units in NoC routers can be used to determine arbitration failures, because the valid arbitration outputs are a subset of all possible values. This feature is exploited to detect and correct logic and register errors in the router arbitration control path. The proposed method is complementary to other error management methods for NoC routers. An analytical reliability model of our method is provided, including parameters such as logic unit size, different error rates for logic gates and registers, and the location of faulty elements. Compared to triple-modular redundancy (TMR), the proposed method improves the arbiter reliability by two orders of magnitude while reducing the total area and power by 43% and 64%, respectively. In the presented case studies, two traffic traces from the PARSEC benchmark suite are used to evaluate the average latency and energy consumption. Simulations performed on a 4× 4 NoC show that our method reduces the average latency by up to 50% and reduces average energy by up to 70% compared to other methods.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2014670168",
    "type": "article"
  },
  {
    "title": "RCML",
    "doi": "https://doi.org/10.1145/2331147.2331153",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Casey Reardon; Brian Holland; Alan D. George; Greg Stitt; Herman Lam",
    "corresponding_authors": "",
    "abstract": "Reconfigurable computing (RC) is emerging as a promising area for embedded computing, in which complex systems must balance performance, flexibility, cost, and power. The difficulty associated with RC development suggests improved strategic planning and analysis techniques can save significant development time and effort. This article presents a new abstract modeling language and environment, the RC Modeling Language (RCML), to facilitate efficient design space exploration of RC systems at the estimation modeling level, that is, before building a functional implementation. Two integrated analysis tools and case studies, one analytical and one simulative, are presented illustrating relatively accurate automated analysis of systems modeled in RCML.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2022168220",
    "type": "article"
  },
  {
    "title": "Implementation strategy for downgraded flash-memory storage devices",
    "doi": "https://doi.org/10.1145/2435227.2435256",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Jen-Wei Hsieh; Yuan-Hao Chang; Yuan-Sheng Chu",
    "corresponding_authors": "",
    "abstract": "In recent years, low-cost flash-memory devices have contributed greatly to the rapid growth of the flash memory market. Given that the most of the cost of such devices is the cost of the flash-memory chips, many vendors are managing the cost of such devices by using flash-memory chips of low quality, and they will continue to do so in the near future. Recognizing strong market demand, this work presents a set-based mapping strategy with an effective implementation and low hardware resource requirements for making downgraded flash-memory chips useable in products. A configurable management design for managing chips of various qualities with improved lifetime is presented. The effectiveness of the proposed strategy is evaluated by performing a series of experiments and analyzed with reference to popular implementations in industry.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2032017742",
    "type": "article"
  },
  {
    "title": "Exploiting Timing Error Resilience in Processor Architecture",
    "doi": "https://doi.org/10.1145/2465787.2465791",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "John Sartori; Rakesh Kumar",
    "corresponding_authors": "",
    "abstract": "Escalating variations in modern CMOS designs have become a threat to Moore’s law. In light of the increasing costs of standard worst-case design practices, timing speculation has become a popular approach for dealing with static and dynamic non-determinism and increasing yield. Timing speculative architectures allow conservative guardbands to be relaxed, increasing efficiency at the expense of occasional errors, which are corrected or tolerated by an error resilience mechanism. Previous work has proposed circuit- or design-level optimizations that manipulate the error rate behavior of a design to increase the efficiency of timing speculation. In this article, we investigate whether architectural optimizations can also manipulate error rate behavior to significantly increase the effectiveness of timing speculation. To this end, we demonstrate how error rate behavior indeed depends on processor architecture and that architectural optimizations can be used to manipulate the error rate behavior of a processor. Using timing speculation-aware architectural optimizations, we demonstrate enhanced overscaling and up to 29% additional energy savings for processors that employ Razor-based timing speculation.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2044409420",
    "type": "article"
  },
  {
    "title": "An Efficient Finite Field Multiplier Using Redundant Representation",
    "doi": "https://doi.org/10.1145/2220336.2220343",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Ashkan Hosseinzadeh Namin; Huapeng Wu; Majid Ahmadi",
    "corresponding_authors": "",
    "abstract": "An efficient word-level finite field multiplier using redundant representation is proposed. The proposed multiplier has a significantly higher speed, compared to previously proposed word-level architectures using either redundant representation or optimal normal basis type I, at the expense of moderately higher area complexity. Furthermore, the new design out-performs other similar proposals when considering the product of area and delay as a measure of performance. ASIC Realization of the proposed design using TSMC’s .18 um CMOS technology for the binary field size of 163 is also presented.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2072057413",
    "type": "article"
  },
  {
    "title": "Parallelization of Belief Propagation on Cell Processors for Stereo Vision",
    "doi": "https://doi.org/10.1145/2180887.2180889",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Kun-Yuan Hsieh; Chi-Hua Lai; Shang‐Hong Lai; Jenq Kuen Lee",
    "corresponding_authors": "",
    "abstract": "Markov random field models provide a robust formulation for the stereo vision problem of inferring three-dimensional scene geometry from two images taken from different viewpoints. One of the most advanced algorithms for solving the associated energy minimization problem in the formulation is belief propagation (BP). Although BP provides very accurate results in solving stereo vision problems, the high computational cost of the algorithm hinders it from real-time applications. In recent years, multicore architectures have been widely adopted in various industrial application domains. The high computing power of multicore processors provides new opportunities to implement stereo vision algorithms. This article examines and extracts the parallelisms in the BP method for stereo vision on multicore processors. This article shows that parallelism of the algorithm can be efficiently utilized on multicore processors. The results show that parallelization on multicore processors provides a speedup for the BP algorithm of almost 15 times compared to the single-processor implementation on the PPE of the Cell BE. The experimental results also indicate that a frame rate of 6.5 frames/second is possible when implementing the parallelized BP algorithm on the multicore processor of Cell BE with one PPE and six SPEs.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2072574390",
    "type": "article"
  },
  {
    "title": "An analytical model for on-chip interconnects in multimedia embedded systems",
    "doi": "https://doi.org/10.1145/2536747.2536751",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Yulei Wu; Geyong Min; Dakai Zhu; Laurence T. Yang",
    "corresponding_authors": "",
    "abstract": "The traffic pattern has significant impact on the performance of network-on-chip. Many recent studies have shown that multimedia applications can be supported in on-chip interconnects. Driven by the motivation of evaluating on-chip interconnects in multimedia embedded systems, a new analytical model is proposed to investigate the performance of the fat-tree based on-chip interconnection network under bursty multimedia traffic and nonuniform message destinations. Extensive simulation experiments are conducted to validate the accuracy of the model, which is then adopted as a cost-efficient tool to investigate the effects of bursty multimedia traffic with nonuniform destinations on the network performance.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2072920387",
    "type": "article"
  },
  {
    "title": "GALS-HMP",
    "doi": "https://doi.org/10.1145/2435227.2435254",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Zoran Salčić; Avinash Malik",
    "corresponding_authors": "",
    "abstract": "We present a new heterogeneous multiprocessor (GALS-HMP) for the execution of Globally Asynchronous Locally Synchronous (GALS) programming languages. It specifically targets SystemJ GALS language, which extends Java with asynchronous and synchronous concurrency. A SystemJ program is partitioned by a compiler onto data-driven and control-driven parts, which are then allocated for the execution on traditional and reactive processors, which constitute GALS-HMP. The reactive processor is customized to meet the requirements of the control parts of the SystemJ programs. The prototypes developed on an FPGA show significant improvements in code size and execution speed compared to the case of using just traditional processors.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2089063706",
    "type": "article"
  },
  {
    "title": "Reliable and adaptive network-on-chip architectures for cyber physical systems",
    "doi": "https://doi.org/10.1145/2435227.2435247",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Diana Göhringer; L. Meder; Oliver Oey; Jürgen Becker",
    "corresponding_authors": "",
    "abstract": "Reliability in embedded systems is crucial for many application domains. Especially, for safety critical application, as they can be found in the automotive and avionic domain, a high reliability has to be ensured. The technology in chip production undergoes a steady shrinking process from nowadays 25 nanometers. It is proven that coming technologies, which are much smaller, can have a higher defect rate after production, but also at runtime. The physical effects at runtime come from a higher susceptibility for radiation. Since the silicon die of a field programmable gate array (FPGA) includes a high amount of physical wiring, the radiation effect plays here a major role. Therefore, this article describes an approach of a reliable Network-on-Chip (NoC) which can be used for an FPGA-based system. The article describes the concept and the physical realization of this NoC and evaluates its reliability.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2092626669",
    "type": "article"
  },
  {
    "title": "Minimizing Test Suites with Unfoldings of Multithreaded Programs",
    "doi": "https://doi.org/10.1145/3012281",
    "publication_date": "2017-02-03",
    "publication_year": 2017,
    "authors": "Olli Saarikivi; Hernán Ponce-de-León; Kari Kähkönen; Keijo Heljanko; Javier Esparza",
    "corresponding_authors": "",
    "abstract": "This article focuses on computing minimal test suites for multithreaded programs. Based on previous work on test case generation for multithreaded programs using unfoldings, this article shows how this unfolding can be used to generate minimal test suites covering all local states of the program. Generating such minimal test suites is shown to be NP-complete in the size of the unfolding. We propose an SMT encoding for this problem and two methods based on heuristics which only approximate the solution, but scale better in practice. Finally, we apply our methods to compute the minimal test suites for several benchmarks.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2586688512",
    "type": "article"
  },
  {
    "title": "Response Time Analysis for Sporadic Server Based Budget Scheduling in Real Time Virtualization Environments",
    "doi": "https://doi.org/10.1145/3126559",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Matthias Beckert; Rolf Ernst",
    "corresponding_authors": "",
    "abstract": "Virtualization techniques for embedded real-time systems typically employ TDMA scheduling to achieve temporal isolation among different virtualized applications. Recent work already introduced sporadic server based solutions relying on budgets instead of a fixed TDMA schedule. While providing better average-case response times for IRQs and tasks, a formal response time analysis for the worst-case is still missing. In order to confirm the advantage of a sporadic server based budget scheduling, this paper provides a worst-case response time analysis. To improve the sporadic server based budget scheduling even more, we provide a background scheduling implementation which will also be covered by the formal analysis. We show correctness of the analysis approach and compare it against TDMA based systems. In addition to that, we provide response time measurements from a working hypervisor implementation on an ARM based development board.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2759163870",
    "type": "article"
  },
  {
    "title": "Fixed-Priority Scheduling for Two-Phase Mixed-Criticality Systems",
    "doi": "https://doi.org/10.1145/3105921",
    "publication_date": "2017-11-21",
    "publication_year": 2017,
    "authors": "Zheng Li; Shuibing He",
    "corresponding_authors": "",
    "abstract": "In this article, a two-phase execution model is proposed for mixed-criticality (MC) tasks. Different from traditional MC tasks with a computation phase only, the two-phase execution model requires a memory-access phase first to fetch the instructions and data, and then computation. Theoretical foundations are first established for a schedulability test under given memory-access and computation priority assignment. Based on the established theoretical conclusions, a two-stage priority assignment algorithm, which can find the best priority assignment for both memory-access and computation phases under fixed-priority scheduling, is further developed. Extensive experiments have been conducted and the experimental results validate the effectiveness of our proposed approach.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2770759135",
    "type": "article"
  },
  {
    "title": "Compact Software Implementation of Public-Key Cryptography on MSP430X",
    "doi": "https://doi.org/10.1145/3190855",
    "publication_date": "2018-05-22",
    "publication_year": 2018,
    "authors": "Hwajeong Seo",
    "corresponding_authors": "Hwajeong Seo",
    "abstract": "On the low-end embedded processors, the implementations of Elliptic Curve Cryptography (ECC) are considered to be a challenging task due to the limited computation power and storage of the low-end embedded processors. Particularly, the multi-precision multiplication and squaring operations are the most expensive operations for ECC implementations. In order to enhance the performance, many works presented efficient multiplication and squaring routines on the target devices. Recent works show that 128-bit security level ECC is available within a second and this is practically fast enough for IoT services. However, previous approaches missed the other important storage issues (i.e., program size, ROM). Considering that the embedded processors only have a few KB ROM, we need to pay attention to the compact ROM size with reasonable performance. In this article, we present very compact and generic implementations of multiplication and squaring operations on the 16-bit MSP430X processors for the ECC. The implementations utilize the new 32-bit multiplier and advanced multiplication and squaring routines. Since the proposed routines are generic, the arbitrary length of operand is available with high-speed and small code size. With proposed multiplication and squaring routines, we implemented Curve25519 on the MSP430X processors. The scalar multiplication is performed within 6,666,895 clock cycles and 4,054 bytes. Compared with previous works based on the speed-optimized version, our memory-efficient version reduces the code size by 59.8%, sacrificing the execution timing by 20.5%.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2803829010",
    "type": "article"
  },
  {
    "title": "A Mirroring-Assisted Channel-RAID5 SSD for Mobile Applications",
    "doi": "https://doi.org/10.1145/3209625",
    "publication_date": "2018-07-05",
    "publication_year": 2018,
    "authors": "Wen Pan; Tao Xie",
    "corresponding_authors": "",
    "abstract": "Simply applying an existing redundant array of independent disks (RAID) technique to enhance data reliability within a single solid-state drive for safety-critical mobile applications significantly degrades performance. In this article, we first propose a new RAID5 architecture called channel-RAID5 with mirroring (CR5M) to alleviate the performance degradation problem. Next, an associated data reconstruction strategy called mirroring-assisted channel-level reconstruction (MCR) is developed to further shrink the window of vulnerability. Experimental results demonstrate that compared with channel-RAID5 (CR5), CR5M improves performance up to 40.2%. Compared with disk-oriented reconstruction, a traditional data reconstruction scheme, MCR on average improves data recovery speed by 7.5% while delivering a similar performance during reconstruction.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2834137663",
    "type": "article"
  },
  {
    "title": "Declarative Resilience",
    "doi": "https://doi.org/10.1145/3210559",
    "publication_date": "2018-07-24",
    "publication_year": 2018,
    "authors": "Hamza Omar; Qingchuan Shi; Masab Ahmad; Halit Dogan; Omer Khan",
    "corresponding_authors": "",
    "abstract": "To protect multicores from soft-error perturbations, research has explored various resiliency schemes that provide high soft-error coverage. However, these schemes incur high performance and energy overheads. We observe that not all soft-error perturbations affect program correctness, and some soft-errors only affect program accuracy, i.e., the program completes with certain acceptable deviations from error free outcome. Thus, it is practical to improve processor efficiency by trading off resiliency overheads with program accuracy. This article proposes the idea of declarative resilience that selectively applies strong resiliency schemes for code regions that are crucial for program correctness (crucial code) and lightweight resiliency for code regions that are susceptible to program accuracy deviations as a result of soft-errors (non-crucial code). At the application level, crucial and non-crucial code is identified based on its impact on the program outcome. A cross-layer architecture enables efficient resilience along with holistic soft-error coverage. Only program accuracy is compromised in the worst-case scenario of a soft-error strike during non-crucial code execution. For a set of machine-learning and graph analytic benchmarks, declarative resilience reduces performance overhead over a state-of-the-art system that applies strong resiliency for all program code regions from ∼ 1.43× to ∼ 1.2×.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2884118114",
    "type": "article"
  },
  {
    "title": "Scalable Analysis for Multi-Scale Dataflow Models",
    "doi": "https://doi.org/10.1145/3233183",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Hadi Alizadeh Ara; Amir Behrouzian; Martijn Hendriks; Marc Geilen; Dip Goswami; Twan Basten",
    "corresponding_authors": "",
    "abstract": "Multi-scale dataflow models have actors acting at multiple granularity levels, e.g., a dataflow model of a video processing application with operations on frame, line, and pixel level. The state of the art timing analysis methods for both static and dynamic dataflow types aggregate the behaviours across all granularity levels into one, often large iteration, which is repeated without exploiting the structure within such an iteration. This poses scalability issues to dataflow analysis, because behaviour of the large iteration is analysed by some form of simulation that involves a large number of actor firings. We take a fresh perspective of what is happening inside the large iteration. We take advantage of the fact that the iteration is a sequence of smaller behaviours, each captured in a scenario, that are typically repeated many times. We use the (max ,+) linear model of dataflow to represent each of the scenarios with a matrix. This allows a compositional worst-case throughput analysis of the repeated scenarios by raising the matrices to the power of the number of repetitions, which scales logarithmically with the number of repetitions, whereas the existing throughput analysis scales linearly. We moreover provide the first exact worst-case latency analysis for scenario-aware dataflow. This compositional latency analysis also scales logarithmically when applied to multi-scale dataflow models. We apply our new throughput and latency analysis to several realistic applications. The results confirm that our approach provides a fast and accurate analysis.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2888910611",
    "type": "article"
  },
  {
    "title": "A Reconfiguration-Based Fault-Tolerant Anti-Lock Brake-by-Wire System",
    "doi": "https://doi.org/10.1145/3242178",
    "publication_date": "2018-09-30",
    "publication_year": 2018,
    "authors": "Belal H. Sababha; Yazan A. Alqudah",
    "corresponding_authors": "",
    "abstract": "Anti-Lock Braking Systems (ABS) and Brake-by-Wire Systems (BBW) are safety-critical applications by nature. Such systems are required to demonstrate high degrees of dependability. Fault-tolerance is the primary means to achieve dependability at runtime and has been an active research area for decades. Fault-tolerance is usually achieved in traditional embedded computing systems through redundancy and voting methods. In such systems, hardware units, actuators, sensors, and communication networks are replicated where special voters vote against faulty units. In addition to traditional hardware and software redundancy, hybrid and reconfiguration-based approaches to fault-tolerance are evolving. In this article, we present a reconfiguration-based fault-tolerant approach to achieve high dependability in ABS BBW braking systems. The proposed architecture makes use of other components of less safety-critical systems to maintain high dependability in the more safety-critical systems. This is achieved by migrating safety-critical software tasks from embedded computer hardware that runs into a malfunction to other embedded computing hardware running less-critical software tasks. Or by using a different configuration in terms of the used speed sensors and type of ABS. The proposed architecture is on average 20% more reliable than conventional ABS architectures assuming equal reliabilities of different components.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2895044751",
    "type": "article"
  },
  {
    "title": "Combining PUF with RLUTs",
    "doi": "https://doi.org/10.1145/3301307",
    "publication_date": "2019-03-18",
    "publication_year": 2019,
    "authors": "Debapriya Basu Roy; Shivam Bhasin; Ivica Nikolić; Debdeep Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "With the popularity of modern FPGAs, the business of FPGA specific intellectual properties (IP) is expanding rapidly. This also brings in the concern of IP protection. FPGA vendors are making serious efforts toward IP protection, leading to standardization schemes like IEEE P1735. However, efficient techniques to prevent unauthorized overuse of IP still remain an open question. In this article, we propose a two-party IP protection scheme combining the re-configurable look-up table primitive of modern FPGAs with physically unclonable functions (PUF). The proposed scheme works with the assumption that the FPGA vendor provides the assurance of confidentiality and integrity of the developed IP. The proposed scheme is considerably lightweight compared to existing schemes, prevents overuse, and does not involve FPGA vendors or trusted third parties for IP licensing. The validation of the proposed scheme is done on MCNC’91 benchmark and third-party IPs like AES and lightweight MIPS processors.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2921617071",
    "type": "article"
  },
  {
    "title": "Stigmergy-Based Security for SoC Operations From Runtime Performance Degradation of SoC Components",
    "doi": "https://doi.org/10.1145/3301279",
    "publication_date": "2019-03-18",
    "publication_year": 2019,
    "authors": "Krishnendu Guha; Debasri Saha; Amlan Chakrabarti",
    "corresponding_authors": "",
    "abstract": "The semiconductor design industry of the embedded era has embraced the globalization strategy for system on chip (SoC) design. This involves incorporation of various SoC components or intellectual properties (IPs), procured from various third-party IP (3PIP) vendors. However, trust of an SoC is challenged when a supplied IP is counterfeit or implanted with a Hardware Trojan Horse. Both roots of untrust may result in sudden performance degradation at runtime. None of the existing hardware security approaches organize the behavior of the IPs at the low level, to ensure timely completion of SoC operations. However, real-time SoC operations are always associated with a deadline, and a deadline miss due to sudden performance degradation of any of the IPs may jeopardize mission-critical applications. We seek refuge to the stigmergic behavior exhibited in insect colonies to propose a decentralized self-aware security approach. The self-aware security modules attached with each IP works based on the Observe-Decide-Act paradigm and not only detects vulnerability but also organizes behavior of the IPs dynamically at runtime so that the high-level objective of task completion before a deadline is ensured. Experimental validation and low overhead of our proposed security modules over various benchmark IPs and crypto SoCs depict the prospects of our proposed mechanism.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2921755389",
    "type": "article"
  },
  {
    "title": "Chimp",
    "doi": "https://doi.org/10.1145/3309763",
    "publication_date": "2019-03-31",
    "publication_year": 2019,
    "authors": "Abbas Arghavani; Haibo Zhang; Zhiyi Huang; Yawen Chen",
    "corresponding_authors": "",
    "abstract": "Radio links in wireless body area networks (WBANs) commonly experience highly time-varying attenuation due to the dynamic network topology and frequent occlusions caused by body movements, making it challenging to design a reliable, energy-efficient, and real-time communication protocol for WBANs. In this article, we present Chimp, a learning-based power-aware communication protocol in which each sending node can self-learn the channel quality and choose the best transmission power level to reduce energy consumption and interference range while still guaranteeing high communication reliability. Chimp is designed based on learning automata that uses only the acknowledgment packets and motion data from a local gyroscope sensor to infer the real-time channel status. We design a new cost function that takes into account the energy consumption, communication reliability and interference and develop a new learning function that can guarantee to select the optimal transmission power level to minimize the cost function for any given channel quality. For highly dynamic postures such as walking and running, we exploit the correlation between channel quality and motion data generated by a gyroscope sensor to fastly estimate channel quality, eliminating the need to use expensive channel sampling procedures. We evaluate the performance of Chimp through experiments using TelosB motes equipped with the MPU-9250 motion sensor chip and compare it with the state-of-the-art protocols in different body postures. Experimental results demonstrate that Chimp outperforms existing schemes and works efficiently in most common body postures. In high-date-rate scenarios, it achieves almost the same performance as the optimal power assignment scheme in which the optimal power level for each transmission is calculated based on the collected channel measurements in an off-line manner.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2926576867",
    "type": "article"
  },
  {
    "title": "Cache Locking Content Selection Algorithms for ARINC-653 Compliant RTOS",
    "doi": "https://doi.org/10.1145/3358196",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Alexy Torres Aurora Dugo; Jean-Baptiste Lefoul; Felipe Göhring de Magalhães; Dahman Assal; Gabriela Nicolescu",
    "corresponding_authors": "",
    "abstract": "Avionic software is the subject of stringent real time, determinism and safety constraints. Software designers face several challenges, one of them being the interferences that appear in common situations, such as resource sharing. The interferences introduce non-determinism and delays in execution time. One of the main interference prone resources are cache memories. In single-core processors, caches comprise multiple private levels. This breaks the isolation principle imposed by avionic standards, such as the ARINC-653. This standard defines partitioned architectures where one partition should never directly interfere with another one. In cache-based architectures, one partition can modify the cache content of another partition. In this paper, we propose a method based on cache locking to reduce the non-determinism and the contention on lower level memories while improving the time performances.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2979310116",
    "type": "article"
  },
  {
    "title": "Enabling Sequential-write-constrained B <sup>+</sup> -tree Index Scheme to Upgrade Shingled Magnetic Recording Storage Performance",
    "doi": "https://doi.org/10.1145/3358201",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Yu-Pei Liang; Tseng‐Yi Chen; Yuan-Hao Chang; Shuo-Han Chen; Alfred K. Lam; Wei-Hsin Li; Wei‐Kuan Shih",
    "corresponding_authors": "",
    "abstract": "When a shingle magnetic recording (SMR) drive has been widely applied to modern computer systems (e.g., archive file systems, big data computing systems, and large-scale database systems), storage system developers should thoroughly review whether current designs (e.g., index schemes and data placements) are appropriate for an SMR drive because of its sequential write constraint. Through many prior works excellently manage data in an SMR drive by integrating their proposed solutions into the driver layer, an index scheme over an SMR drive has never been optimized by any previous works because managing index over the SMR drive needs to jointly consider the properties of B + -tree and SMR natures (e.g., sequential write constraint and zone partitions) in a host storage system. Moreover, poor index management will result in terrible storage performance because an index manager is extensively used in file systems and database applications. For optimizing the B + -tree index structure over an SMR storage, this work identifies performance overheads caused by the B + -tree index structure in an SMR drive. By such observation, this study proposes a sequential-write-constrained B + -tree index scheme, namely SW-B + tree, which consists of an address redirection data structure, an SMR-aware node allocation mechanism, and a frequency-aware garbage collection strategy. According to our experiments, the SW-B + tree can improve the SMR storage performance 55% on average.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2979861160",
    "type": "article"
  },
  {
    "title": "Adaptive Task Allocation and Scheduling on NoC-based Multicore Platforms with Multitasking Processors",
    "doi": "https://doi.org/10.1145/3408324",
    "publication_date": "2020-12-07",
    "publication_year": 2020,
    "authors": "Suraj Paul; Navonil Chatterjee; Prasun Ghosal; Jean-Philippe Diguet",
    "corresponding_authors": "",
    "abstract": "The application workloads in modern multicore platforms are becoming increasingly dynamic. It becomes challenging when multiple applications need to be executed in parallel in such systems. Mapping and scheduling of these applications are critical for system performance and energy consumption, especially in Network-on-Chip– (NoC) based multicore systems. These systems with multitasking processors offer a better opportunity for parallel application execution. Mapping solutions generated at design time may be inappropriate for dynamic workloads. To improve the utilization of the underlying multicore platform and cope with the dynamism of application workload, often task allocation is carried out dynamically. This article presents a hybrid task allocation and scheduling strategy that exploits the design-time results at runtime. By considering the multitasking capability of the processors, communication energy, and timing characteristics of the tasks, different allocation options are obtained at design time. During runtime, based on the availability of the platform resources and application requirements, the design-time allocations are adapted for mapping and scheduling of tasks, which result in improved runtime performance. Experimental results demonstrate that the proposed approach achieves an on average 11.5%, 22.3%, 28.6%, and 34.6% reduction in communication energy consumption as compared to CAM [18], DEAMS [4], TSMM [38], and CPNN [32], respectively, for NoC-based multicore platforms with multitasking processors. Also, the deadline satisfaction of the tasks of allocated applications improves on an average by 32.8% when compared with the state-of-the-art dynamic resource allocation approaches.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3036604306",
    "type": "article"
  },
  {
    "title": "LAMBDA",
    "doi": "https://doi.org/10.1145/3390855",
    "publication_date": "2020-06-21",
    "publication_year": 2020,
    "authors": "Sai Praveen Kadiyala; Manaar Alam; Yash Shrivastava; Sikhar Patranabis; Muhamed Fauzi Bin Abbas; Arnab Kumar Biswas; Debdeep Mukhopadhyay; Thambipillai Srikanthan",
    "corresponding_authors": "",
    "abstract": "Security is a critical aspect in many of the latest embedded and IoT systems. Malware is one of the severe threats of security for such devices. There have been enormous efforts in malware detection and analysis; however, occurrences of newer varieties of malicious codes prove that it is an extremely difficult problem given the nature of these surreptitious codes. In this article, instead of addressing a general solution, we aim at malware detection for platforms that have more than one core for performance enhancement. We investigate the utility of multiple cores from the point of view of security, where one of the cores operate as a watchdog. We define a notion of a new metric called LAMBDA (Lightweight Assessment of Malware for emBeddeD Architectures), denoted by λ, indicating a conceptual boundary between the programs which are allowed to run on a given platform, with the codes that are suspected as malwares. The metric λ is computed using carefully chosen monitors or features, which are tuples of high-level programs representing OS resources, along with low-level hardware performance counters. In comparison to heavy-weight machine learning techniques, we use an online hypothesis testing, in the form of t -test, to classify a given program-under-test. For applications where security is of prime concern, we propose an additional step based on multivariate analysis to classify the unknown programs that are closer to the threshold with a high degree of confidence. We present experimental results focusing on an ARM-based platform which validate that the proposed approach provides a lightweight, accurate assessment of malware codes for embedded platforms. In addition to it, we also present a security analysis to show the difficulty of a mimicry attack attempting to bypass LAMBDA.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3036736136",
    "type": "article"
  },
  {
    "title": "Optimization of Signal Processing Applications Using Parameterized Error Models for Approximate Adders",
    "doi": "https://doi.org/10.1145/3430509",
    "publication_date": "2021-01-11",
    "publication_year": 2021,
    "authors": "Celia Dharmaraj; V. Vasudevan; Nitin Chandrachoodan",
    "corresponding_authors": "",
    "abstract": "Approximate circuit design has gained significance in recent years targeting error-tolerant applications. In the literature, there have been several attempts at optimizing the number of approximate bits of each approximate adder in a system for a given accuracy constraint. For computational efficiency, the error models used in these routines are simple expressions obtained using regression or by assuming inputs or the error is uniformly distributed. In this article, we first demonstrate that for many approximate adders, these assumptions lead to an inaccurate prediction of error statistics for multi-level circuits. We show that mean error and mean square error can be computed accurately if static probabilities of adders at all stages are taken into account. Therefore, in a system with a certain type of approximate adder, any optimization framework needs to take into account not just the functionality of the adder but also its position in the circuit, functionality of its parents, and the number of approximate bits in the parent blocks. We propose a method to derive parameterized error models for various types of approximate adders. We incorporate these models within an optimization framework and demonstrate that the noise power is computed accurately.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3119974715",
    "type": "article"
  },
  {
    "title": "Beyond Cache Attacks",
    "doi": "https://doi.org/10.1145/3433653",
    "publication_date": "2021-03-18",
    "publication_year": 2021,
    "authors": "Johanna Sepúlveda; Mathieu Gross; Andreas Zankl; Georg Sigl",
    "corresponding_authors": "",
    "abstract": "System-on-Chips (SoCs) are a key enabling technology for the Internet-of-Things (IoT), a hyper-connected world where on- and inter-chip communication is ubiquitous. SoCs usually integrate cryptographic hardware cores for confidentiality and authentication services. However, these components are prone to implementation attacks. During the operation of a cryptographic core, the secret key may passively be inferred through cache observations. Access-driven attacks exploiting these observations are therefore a vital threat to SoCs operating in IoT environments. Previous works have shown the feasibility of these attacks in the SoC context. Yet, the SoC communication structure can be used to further improve access-based cache attacks. The communication attacks are not as well-understood as other micro-architectural attacks. It is important to raise the awareness of SoC designers of such a threat. To this end, we present four contributions. First, we demonstrate an improved Prime+Probe attack on four different AES-128 implementations (original transformation tables, T 0 -Only, T 2KB , and S-Box). As a novelty, this attack exploits the collisions of the bus-based SoC communication to further increase its efficiency. Second, we explore the impact of preloading on the efficiency of our communication-optimized attack. Third, we integrate three countermeasures ( shuffling , mini-tables , and Time-Division Multiple Access (TDMA) bus arbitration ) and evaluate their impact on the attack. Although shuffling and mini-tables countermeasures were proposed in previous work, their application as countermeasures against the bus-based attack was not studied before. In addition, TDMA as a countermeasure for bus-based attacks is an original contribution of this work. Fourth, we further discuss the implications of our work in the SoC design and its perspective with the new cryptographic primitives proposed in the ongoing National Institute of Standard and Technology Lightweight Cryptography competition. The results show that our improved communication-optimized attack is efficient, speeding up full key recovery by up to 400 times when compared to the traditional Prime+Probe technique. Moreover, the protection techniques are feasible and effectively mitigate the proposed improved attack.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3139139957",
    "type": "article"
  },
  {
    "title": "Sense Your Power",
    "doi": "https://doi.org/10.1145/3441643",
    "publication_date": "2021-03-27",
    "publication_year": 2021,
    "authors": "Michel Rottleuthner; Thomas C. Schmidt; Matthias Wählisch",
    "corresponding_authors": "",
    "abstract": "Energy-constrained sensor nodes can adaptively optimize their energy consumption if a continuous measurement is provided. This is of particular importance in scenarios of high dynamics such as with energy harvesting. Still, self-measuring of power consumption at reasonable cost and complexity is unavailable as a generic system service. In this article, we present ECO, a hardware-software co-design that adds autonomous energy management capabilities to a large class of low-end IoT devices. ECO consists of a highly portable hardware shield built from inexpensive commodity components and software integrated into the RIOT operating system. RIOT supports more than 200 popular microcontrollers. Leveraging this flexibility, we assembled a variety of sensor nodes to evaluate key performance properties for different device classes. An overview and comparison with related work shows how ECO fills the gap of in situ power attribution transparently for consumers and how it improves over existing solutions. We also report about two different real-world field trials, which validate our solution for long-term production use.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3144502021",
    "type": "article"
  },
  {
    "title": "UBAR",
    "doi": "https://doi.org/10.1145/3441644",
    "publication_date": "2021-03-27",
    "publication_year": 2021,
    "authors": "Elham Shamsa; Alma Pröbstl; Nima TaheriNejad; Anil Kanduri; Samarjit Chakraborty; Amir M. Rahmani; Pasi Liljeberg",
    "corresponding_authors": "",
    "abstract": "Smartphone users require high Battery Cycle Life (BCL) and high Quality of Experience (QoE) during their usage. These two objectives can be conflicting based on the user preference at run-time. Finding the best trade-off between QoE and BCL requires an intelligent resource management approach that considers and learns user preference at run-time. Current approaches focus on one of these two objectives and neglect the other, limiting their efficiency in meeting users’ needs. In this article, we present UBAR, User- and Battery-aware Resource management, which considers dynamic workload, user preference, and user plug-in/out pattern at run-time to provide a suitable trade-off between BCL and QoE. UBAR personalizes this trade-off by learning the user’s habits and using that to satisfy QoE, while considering battery temperature and State of Charge (SOC) pattern to maximize BCL. The evaluation results show that UBAR achieves 10% to 40% improvement compared to the existing state-of-the-art approaches.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3147707998",
    "type": "article"
  },
  {
    "title": "HW-FlowQ: A Multi-Abstraction Level HW-CNN Co-design Quantization Methodology",
    "doi": "https://doi.org/10.1145/3476997",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Nael Fasfous; Manoj Rohit Vemparala; Alexander Frickenstein; Emanuele Valpreda; Driton Salihu; Nguyen Anh Vu Doan; Christian Unger; Naveen Shankar Nagaraja; Maurizio Martina; Walter Stechele",
    "corresponding_authors": "",
    "abstract": "Model compression through quantization is commonly applied to convolutional neural networks (CNNs) deployed on compute and memory-constrained embedded platforms. Different layers of the CNN can have varying degrees of numerical precision for both weights and activations, resulting in a large search space. Together with the hardware (HW) design space, the challenge of finding the globally optimal HW-CNN combination for a given application becomes daunting. To this end, we propose HW-FlowQ, a systematic approach that enables the co-design of the target hardware platform and the compressed CNN model through quantization. The search space is viewed at three levels of abstraction, allowing for an iterative approach for narrowing down the solution space before reaching a high-fidelity CNN hardware modeling tool, capable of capturing the effects of mixed-precision quantization strategies on different hardware architectures (processing unit counts, memory levels, cost models, dataflows) and two types of computation engines (bit-parallel vectorized, bit-serial). To combine both worlds, a multi-objective non-dominated sorting genetic algorithm (NSGA-II) is leveraged to establish a Pareto-optimal set of quantization strategies for the target HW-metrics at each abstraction level. HW-FlowQ detects optima in a discrete search space and maximizes the task-related accuracy of the underlying CNN while minimizing hardware-related costs. The Pareto-front approach keeps the design space open to a range of non-dominated solutions before refining the design to a more detailed level of abstraction. With equivalent prediction accuracy, we improve the energy and latency by 20% and 45% respectively for ResNet56 compared to existing mixed-precision search methods.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3170004439",
    "type": "article"
  },
  {
    "title": "Killing Processes or Killing Flash? Escaping from the Dilemma Using Lightweight, Compression-Aware Swap for Mobile Devices",
    "doi": "https://doi.org/10.1145/3477021",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Yongxuan Wang; Chung-Hsuan Tsai; Li-Pin Chang",
    "corresponding_authors": "",
    "abstract": "Android apps become increasingly memory-demanding as software vendors add more and more new features to their apps. In the mean time, Android users often launch multiple apps and conveniently switch back and forth among the apps. Although running multiple apps imposes a high pressure on memory management, virtual-memory swap, an essential feature to improve the degree of multitasking, is disabled in fear of premature retirement of flash-based storage devices. Instead, Android employs a termination-based, process-level memory reclaiming method. We observed that process killing is, unfortunately, not effective in memory reclaiming and is highly negative to user experience. In this study, we advocate re-thinking using swap in Android for improved user experience with managed write stress on flash storage. Based on a series of empirical analyses of swap activities, we propose an enhanced page replacement policy and a page-compressing frontswap module. The proposed page replacement policy jointly considers page activeness and compressibility to boost the compression ratio of swap writes. A sampled-based method for page compressibility prediction is introduced so that decisions on page replacement can be made without compressing every page. We also design a frontswap module that strategically organizes compressed pages in the swap space for reducing the overhead of swap I/O operations. Experimental results showed that compared with process killing, our method improved the app launching time and energy consumption by 58% and 19%, respectively; compared with the original swap, our approach reduced the swap write stress by 65%.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3199132816",
    "type": "article"
  },
  {
    "title": "Thermal-aware memory mapping in 3D designs",
    "doi": "https://doi.org/10.1145/2501626.2512457",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Ang-Chih Hsieh; TingTing Hwang",
    "corresponding_authors": "",
    "abstract": "DRAM is usually used as main memory for program execution. The thermal behavior of a memory block in a 3D SIP is affected not only by the power behavior but also the heat dissipating ability of that block. The power behavior of a block is related to the applications run on the system, while the heat dissipating ability is determined by the number of tier and the position the block locates. Therefore, a thermal-aware memory allocator should consider the following two points. First, the allocator should consider not only the power behavior of a logic block but also the physical location during memory mapping and second, the changing temperature of a physical block during execution of programs. In this article, we will propose a memory mapping algorithm taking into consideration these two points. Our technique can be classified as static thermal management to be applied to embedded software designs. Experiments show that for single-core systems, our method can reduce the temperature of memory system by 17.1°C, as compared to a straightforward mapping in the best case, and 13.3°C on average. For systems with four cores, the temperature reductions are 9.9°C and 11.6°C on average when L1 cache of each core is set to 4KB and 8KB, respectively.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4244810284",
    "type": "article"
  },
  {
    "title": "A study on parallelizing XML path filtering using accelerators",
    "doi": "https://doi.org/10.1145/2560040",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Roger Moussalli; Mariam Salloum; Robert J. Halstead; Walid Najjar; Vassilis J. Tsotras",
    "corresponding_authors": "",
    "abstract": "Publish-subscribe systems present the state of the art in information dissemination to multiple users. Such systems have evolved from simple topic-based to the current XML-based systems. XML-based pub-sub systems provide users with more flexibility by allowing the formulation of complex queries on the content as well as the structure of the streaming messages. Messages that match a given user query are forwarded to the user. This article examines how to exploit the parallelism found in XPath filtering. Using an incoming XML stream, parsing and matching thousands of user profiles are performed simultaneously by matching engines. We show the benefits and trade-offs of mapping the proposed filtering approach onto FPGAs, processing streams of XML at wire speed, and GPUs, providing the flexibility of software. This is in contrast to conventional approaches bound by the sequential aspect of software computing, associated with a large memory footprint. By converting XPath expressions into custom stacks, our solution is the first to provide support for complex XPath structural constructs, such as parent-child and ancestor descendant relations, whilst allowing wildcarding and recursion. The measured speedups resulting from the GPU and FPGA accelerations versus single-core CPUs are up to 6.6X and 2.5 orders of magnitude, respectively. The FPGA approaches are up to 31X faster than software running on 12 CPU cores.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2005799478",
    "type": "article"
  },
  {
    "title": "Finite-State-Machine Overlay Architectures for Fast FPGA Compilation and Application Portability",
    "doi": "https://doi.org/10.1145/2700082",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Patrick Cooke; Lü Hao; Greg Stitt",
    "corresponding_authors": "",
    "abstract": "Despite significant advantages, wider usage of field-programmable gate arrays (FPGAs) has been limited by lengthy compilation and a lack of portability. Virtual-architecture overlays have partially addressed these problems, but previous work focuses mainly on heavily pipelined applications with minimal control requirements. We expand previous work by enabling more flexible control via overlay architectures for finite-state machines. Although not appropriate for control-intensive circuits, the presented architectures reduced compilation times of control changes in a convolution case study from 7 hours to less than 1 second, with no performance overhead and an area overhead of 0.2%.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2092213324",
    "type": "article"
  },
  {
    "title": "A Hybrid Storage Access Framework for High-Performance Virtual Machines",
    "doi": "https://doi.org/10.1145/2660493",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Chih-Kai Kang; Yu-Jhang Cai; Chin-Hsien Wu; Pi-Cheng Hsiu",
    "corresponding_authors": "",
    "abstract": "In recent years, advances in virtualization technology have enabled multiple virtual machines to run on a physical machine, such that each virtual machine can perform independently with its own operating system. The IT industry has adopted virtualization technology because of its ability to improve hardware resource utilization, achieve low-power consumption, support concurrent applications, simplify device management, and reduce maintenance costs. However, because of the hardware limitation of storage devices, the I/O capacity could cause performance bottlenecks. To address the problem, we propose a hybrid storage access framework that exploits solid-state drives (SSDs) to improve the I/O performance in a virtualization environment.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2128673382",
    "type": "article"
  },
  {
    "title": "Error Detector Placement for Soft Computing Applications",
    "doi": "https://doi.org/10.1145/2801154",
    "publication_date": "2016-01-13",
    "publication_year": 2016,
    "authors": "Anna Thomas; Karthik Pattabiraman",
    "corresponding_authors": "",
    "abstract": "The scaling of Silicon devices has exacerbated the unreliability of modern computer systems, and power constraints have necessitated the involvement of software in hardware error detection. At the same time, emerging workloads in the form of soft computing applications (e.g., multimedia applications) can tolerate most hardware errors as long as the erroneous outputs do not deviate significantly from error-free outcomes. We term outcomes that deviate significantly from the error-free outcomes as Egregious Data Corruptions (EDCs). In this study, we propose a technique to place detectors for selectively detecting EDC-causing errors in an application. We performed an initial study to formulate heuristics that identify EDC-causing data. Based on these heuristics, we developed an algorithm that identifies program locations for placing high coverage detectors for EDCs using static analysis. Our technique achieves an average EDC coverage of 82%, under performance overheads of 10%, while detecting 10% of the Non-EDC and benign faults. We also evaluate the error resilience of these applications under the 14 compiler optimizations.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2233219228",
    "type": "article"
  },
  {
    "title": "VirtualSoC",
    "doi": "https://doi.org/10.1145/2930665",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Daniele Bortolotti; Andrea Marongiu; Luca Benini",
    "corresponding_authors": "",
    "abstract": "Architectural heterogeneity has proven to be an effective design paradigm to cope with an ever-increasing demand for computational power within tight energy budgets, in virtually every computing domain. Programmable manycore accelerators are currently widely used not only in high-performance computing systems, but also in embedded devices, in which they operate as coprocessors under the control of a general-purpose CPU (the host processor). Clearly, such powerful hardware architectures are paired with sophisticated and complex software ecosystems, composed of operating systems, programming models plus associated runtime engines, and increasingly complex user applications with related libraries. System modeling has always played a key role in early architectural exploration or software development when the real hardware is not available. The necessity of efficiently coping with the huge HW/SW design space provided by the described heterogeneous Systems on Chip (SoCs) calls for advanced full-system simulation methodologies and tools, capable of assessing various metrics for the functional and nonfunctional properties of the target system. In this article, we describe VirtualSoC, a simulation tool targeting the full-system simulation of massively parallel heterogeneous SoCs. We also describe how VirtualSoC has been successfully adopted in several research projects.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2531523496",
    "type": "article"
  },
  {
    "title": "Modeling Distributed Real-Time Systems in TIOA and UPPAAL",
    "doi": "https://doi.org/10.1145/2964202",
    "publication_date": "2016-10-23",
    "publication_year": 2016,
    "authors": "Yusuf Bora Kartal; Ece Güran Schmidt; Klaus Werner Schmidt",
    "corresponding_authors": "",
    "abstract": "The mission- and life-critical properties of distributed real-time systems require concurrent modeling, analysis, and formal verification in the design stage. The timed input/output automata (TIOA) framework and the UPPAAL software package are two widely used modeling and verification tools for this purpose. To this end, we develop the algorithm TUConvert for converting distributed TIOA models to UPPAAL behavioral models and formally prove its correctness. We demonstrate the applicability of our algorithm by the formal verification of a distributed real-time industrial communication protocol that is modeled by TIOA.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2535640593",
    "type": "article"
  },
  {
    "title": "Analysis and Scheduling of a Battery-Less Mixed-Criticality System with Energy Uncertainty",
    "doi": "https://doi.org/10.1145/2964201",
    "publication_date": "2016-10-23",
    "publication_year": 2016,
    "authors": "Sedigheh Asyaban; Mehdi Kargahi; Lothar Thiele; Morteza Mohaqeqi",
    "corresponding_authors": "",
    "abstract": "We consider a battery-less real-time embedded system equipped with an energy harvester. It scavenges energy from an environmental resource according to some stochastic patterns. The success of jobs is threatened in the case of energy shortage, which might be due to lack of harvested energy, losses originated from the super-capacitor self-discharge, as well as power consumption of executed tasks. The periodic real-time tasks of the system follow a dual-criticality model. In addition, each task has a minimum required success ratio that needs to be satisfied in steady state. We analytically evaluate the behavior of such a system in terms of its energy-related success ratio for a given schedule. Based on these results, we propose a scheduling algorithm that satisfies both temporal and success-ratio constraints of the jobs, while respecting task criticalities and corresponding system modes. The accuracy of the analytical method as well as its dependence on the numerical computations and other model assumptions are extensively discussed through comparison with simulation results. Also, the efficacy of the proposed scheduling algorithm is studied through comparison to some existing non-mixed- and mixed-criticality scheduling algorithms.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2538187900",
    "type": "article"
  },
  {
    "title": "Performance and Power Estimation of STT-MRAM Main Memory with Reliable System-level Simulation",
    "doi": "https://doi.org/10.1145/3476838",
    "publication_date": "2022-01-14",
    "publication_year": 2022,
    "authors": "Kazi Asifuzzaman; Rommel Sánchez Verdejo; Petar Radojković",
    "corresponding_authors": "",
    "abstract": "It is questionable whether DRAM will continue to scale and will meet the needs of next-generation systems. Therefore, significant effort is invested in research and development of novel memory technologies. One of the candidates for next-generation memory is Spin-Transfer Torque Magnetic Random Access Memory (STT-MRAM). STT-MRAM is an emerging non-volatile memory with a lot of potential that could be exploited for various requirements of different computing systems. Being a novel technology, STT-MRAM devices are already approaching DRAM in terms of capacity, frequency, and device size. Although STT-MRAM technology got significant attention of various major memory manufacturers, academic research of STT-MRAM main memory remains marginal. This is mainly due to the unavailability of publicly available detailed timing and current parameters of this novel technology, which are required to perform a reliable main memory simulation on performance and power estimation. This study demonstrates an approach to perform a cycle accurate simulation of STT-MRAM main memory, being the first to release detailed timing and current parameters of this technology from academia—essentially enabling researchers to conduct reliable system-level simulation of STT-MRAM using widely accepted existing simulation infrastructure. The results show a fairly narrow overall performance deviation in response to significant variations in key timing parameters, and the power consumption experiments identify the key power component that is mostly affected with STT-MRAM.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4206812385",
    "type": "article"
  },
  {
    "title": "TAB: Unified and Optimized Ternary, Binary, and Mixed-precision Neural Network Inference on the Edge",
    "doi": "https://doi.org/10.1145/3508390",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Shien Zhu; Luan H. K. Duong; Weichen Liu",
    "corresponding_authors": "",
    "abstract": "Ternary Neural Networks (TNNs) and mixed-precision Ternary Binary Networks (TBNs) have demonstrated higher accuracy compared to Binary Neural Networks (BNNs) while providing fast, low-power, and memory-efficient inference. Related works have improved the accuracy of TNNs and TBNs, but overlooked their optimizations on CPU and GPU platforms. First, there is no unified encoding for the binary and ternary values in TNNs and TBNs. Second, existing works store the 2-bit quantized data sequentially in 32/64-bit integers, resulting in bit-extraction overhead. Last, adopting standard 2-bit multiplications for ternary values leads to a complex computation pipeline, and efficient mixed-precision multiplication between ternary and binary values is unavailable. In this article, we propose TAB as a unified and optimized inference method for ternary, binary, and mixed-precision neural networks. TAB includes unified value representation, efficient data storage scheme and novel bitwise dot product pipelines on CPU/GPU platforms. We adopt signed integers for consistent value representation across binary and ternary values. We introduce a bitwidth-last data format that stores the first and second bits of the ternary values separately to remove the bit extraction overhead. We design the ternary and binary bitwise dot product pipelines based on Gated-XOR using up to 40% fewer operations than State-Of-The-Art (SOTA) methods. Theoretical speedup analysis shows that our proposed TAB-TNN is 2.3× fast as the SOTA ternary method RTN, 9.8× fast as 8-bit integer quantization (INT8), and 39.4× fast as 32-bit full-precision convolution (FP32). Experiment results on CPU and GPU platforms show that our TAB-TNN has achieved up to 34.6× speedup and 16× storage size reduction compared with FP32 layers. TBN, Binary-activation Ternary-weight Network (BTN), and BNN in TAB are up to 40.7×, 56.2×, and 72.2× as fast as FP32. TAB-TNN is up to 70.1% faster and 12.8% more power-efficient than RTN on Darknet-19 while keeping the same accuracy. TAB is open source as a PyTorch Extension 1 for easy integration with existing CNN models.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4210486199",
    "type": "article"
  },
  {
    "title": "A Unified Programmable Edge Matrix Processor for Deep Neural Networks and Matrix Algebra",
    "doi": "https://doi.org/10.1145/3524453",
    "publication_date": "2022-04-01",
    "publication_year": 2022,
    "authors": "Biji George; Om Ji Omer; Ziaul Choudhury; V. S. Anoop; Sreenivas Subramoney",
    "corresponding_authors": "",
    "abstract": "Matrix Algebra and Deep Neural Networks represent foundational classes of computational algorithms across multiple emerging applications like Augmented Reality or Virtual Reality, autonomous navigation (cars, drones, robots), data science, and various artificial intelligence-driven solutions. An accelerator-based architecture can provide performance and energy efficiency supporting fixed functions through customized data paths. However, constrained Edge systems requiring multiple applications and diverse matrix operations to be efficiently supported, cannot afford numerous custom accelerators. In this article, we present MxCore, a unified architecture that comprises tightly coupled vector and programmable cores sharing data through highly optimized interconnects along with a configurable hardware scheduler managing the co-execution. We submit MxCore as the generalized approach to facilitate the flexible acceleration of multiple Matrix Algebra and Deep-learning applications across a range of sparsity levels. Unified compute resources improve overall resource utilization and performance per unit area. Aggressive and novel microarchitecture techniques along with block-level sparsity support optimize compute and data-reuse to minimize bandwidth and power requirements enabling ultra-low latency applications for low-power and cost-sensitive Edge deployments. MxCore requires a small silicon footprint of 0.2068 mm 2 , in a modern 7-nm process at 1 GHz and achieves (0.15 FP32 and 0.62 INT8) TMAC/mm 2 , dissipating only 11.66 μW of leakage power. At iso-technology and iso-frequency, MxCore provides an energy efficiency of 651.4×, 159.9×, 104.8×, and 124.2× as compared to the 128-core Nvidia’s Maxwell GPU for dense General Matrix Multiply, sparse Deep Neural Network, Cholesky decomposition, and triangular matrix solve respectively.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4221061712",
    "type": "article"
  },
  {
    "title": "A Framework for Neural Network Architecture and Compile Co-optimization",
    "doi": "https://doi.org/10.1145/3533251",
    "publication_date": "2022-05-10",
    "publication_year": 2022,
    "authors": "Weiwei Chen; Ying Wang; Ying Xu; Chengsi Gao; Cheng Liu; Lei Zhang",
    "corresponding_authors": "",
    "abstract": "The efficiency of deep neural network (DNN) solutions on real hardware devices are mainly decided by the DNN architecture and the compiler-level scheduling strategy on the hardware. When we try to fully exploit the underlying hardware and obtain the optimal tradeoff between DNN accuracy and runtime performance, we discovered that the two optimization goals of DNN architecture and scheduling policy are intimately related to each other. However, current hardware-aware Neural Architecture Search (NAS) methods primarily focus on the DNN architecture search process, ignoring the effects of various compiler-level scheduling strategies (e.g., graph-level optimization, loop transformations, parallelization, etc.) on network candidates being evaluated in the search process. As a result, they may overlook the true-optimal DNN implementations on hardware, which can only be discovered by trying-out different combinations of scheduling strategies and DNN architectures. This work proposes a NAS framework (CHaNAS) that searches for not only the network architecture but also the dedicated compiler-level scheduling policy, as the optimal co-design solution on the target hardware. We propose to use a block-based pre-scheduling methodology to reduce the co-design search space and enable the automatic generation of the optimal co-design, including the network architecture and the tensor programs that practice the scheduling policy. Further, we introduce a new search objective function based on the generalization gap to prevent the selection of architectures that are prone to overfitting. We evaluate CHaNAS on Imagenet on different hardware back-ends against the state-of-the-art hardware-aware search method based on the MobileNet-v3 search space. Experimental results show that the co-design solutions obtained by ChaNAS show up to 1.6×, 1.9×, and 1.7×, 24 performance boost on NVIDIA P100 GPU, Intel Xeon 8163 CPU, and Samsung Note 10 Mobile, respectively, over the baselines of the same-level accuracy.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4280529392",
    "type": "article"
  },
  {
    "title": "Experimental Demonstration of STT-MRAM-based Nonvolatile Instantly On/Off System for IoT Applications: Case Studies",
    "doi": "https://doi.org/10.1145/3546193",
    "publication_date": "2022-07-05",
    "publication_year": 2022,
    "authors": "Yueting Li; Wang Kang; Kunyu Zhou; Keni Qiu; Weisheng Zhao",
    "corresponding_authors": "",
    "abstract": "Energy consumption has been a big challenge for electronic devices, particularly for battery-powered Internet of Things (IoT) equipment. To address such a challenge, on the one hand, low-power electronic design methodologies and novel power management techniques have been proposed, such as nonvolatile memories and instantly on/off systems; on the other hand, the energy harvesting technology by collecting signals from human activity or the environment has attracted widespread attention in the IoT area. However, the system with self-powered energy harvesting may suffer frequent energy failures or fluctuating energy conditions, which degrade system reliability and user experience. Therefore, how to make the system under unreliable power inputs operate correctly and efficiently is one of the most critical issues for energy harvesting technology. In this article, we built an instantly on/off system based on nonvolatile STT-MRAM for IoT applications, which can instantly power on/off under different conditions of the harvested energy. The system powers on and operates normally when the harvested energy is enough (over the preset threshold); otherwise, the system powers off and stores the operational data back to the nonvolatile STT-MRAM. We described implementations of the hardware/software co-designed architecture (with image acquisition as an example) based on the commercialized 32 MB STT-MRAM, and we experimentally demonstrated the system functionality and efficiency under five typical energy harvesting scenarios, including radio frequency, thermal, solar, piezoelectric, and WIFI. Our experimental results show that the power consumption and data restore time were reduced by 15.1% and 714 times, respectively, in comparison with the DRAM-based counterpart.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4283817132",
    "type": "article"
  },
  {
    "title": "On the RTL Implementation of FINN Matrix Vector Unit",
    "doi": "https://doi.org/10.1145/3547141",
    "publication_date": "2022-07-14",
    "publication_year": 2022,
    "authors": "Syed Asad Alam; David Gregg; Giulio Gambardella; Thomas B. Preußer; Michaela Blott",
    "corresponding_authors": "",
    "abstract": "Field-programmable gate array (FPGA)–based accelerators are becoming increasingly popular for deep neural network (DNN) inference due to their ability to scale performance with increasing degrees of specialization with dataflow architectures or custom data type precision. In order to reduce the barrier for software engineers and data scientists to adopt FPGAs, C++- and OpenCL-based design entries with high-level synthesis (HLS) have been introduced. They provide higher abstraction compared with register-transfer level (RTL)–based design. HLS offers faster development time, better maintainability, and more flexibility in code exploration when evaluating several options for multi-dimension tensors, convolutional layers, or different degrees of parallelism. For this reason, HLS has been adopted by DNN accelerator generation frameworks such as FINN and hls4ml. In this article, we present an alternative backend library for FINN, leveraging RTL. We investigate and evaluate, across a spectrum of design dimensions, the pros and cons of an RTL-based implementation versus the original HLS variant. We show that for smaller design parameters, RTL produces significantly smaller circuits as compared with HLS. For larger circuits, however, the look-up table (LUT) count of RTL-based design is slightly higher, up to around 15%. On the other hand, HLS consistently requires more flip-flops (FFs; with an orders-of-magnitude difference for smaller designs) and block RAMs (BRAMs; 2× more). This also impacts the critical path delay, with RTL producing significantly faster circuits, up to around 80%. RTL also benefits from at least a 10× reduction in synthesis time. Finally, the results were validated in practice using two real-world use cases, one of a multi-layer perceptron (MLP) used in network intrusion detection and the other a convolution network called ResNet, used in image recognition. Overall, since HLS frameworks code-generate the hardware design, the benefits of the ease in the design entry is less important. As such, the gained benefits in synthesis time together with some design-dependent resource benefits make the RTL abstraction an attractive alternative.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4285387002",
    "type": "article"
  },
  {
    "title": "Hardware Trojan Detection using Transition Probability with Minimal Test Vectors",
    "doi": "https://doi.org/10.1145/3545000",
    "publication_date": "2022-08-08",
    "publication_year": 2022,
    "authors": "Anindan Mondal; Shubrojyoti Karmakar; Mahabub Hasan Mahalat; Suchismita Roy; Bibhash Sen; Anupam Chattopadhyay",
    "corresponding_authors": "",
    "abstract": "Hardware Trojans (HTs) are malicious manipulations of the standard functionality of an integrated circuit (IC). Sophisticated defense against HT attacks has become the utmost current research endeavor. In particular, the HTs whose operations depend on the rare activation condition are the most critical ones. Among other techniques, logic test by rare net excitation is advocated as one of the viable detection methods due to no extra hardware requirement. However, logic test faces a tremendous challenge of the overhead of testing configuration. This work presents a methodology based on the primary input’s impact over rare nets using transition probability to select the useful test vectors. To generate a test vector, each input’s toggle probability is calculated, which drastically minimizes the search space. The capability of rare-signal generation selects the final list of test vectors. Simulations performed in the presence of different HT triggers on different benchmark circuits, like ISCAS ’85, ISCAS ’89, and ITC ’99, show that the proposed methodology is capable of producing test vectors with significantly improved rare net coverage. Furthermore, compared to an existing technique, the proposed methodology produces average higher rare switching (around 72%) inside a netlist.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4290648705",
    "type": "article"
  },
  {
    "title": "A Write-Related and Read-Related DRAM Allocation Strategy Inside Solid-State Drives (SSDs)",
    "doi": "https://doi.org/10.1145/3561301",
    "publication_date": "2022-09-03",
    "publication_year": 2022,
    "authors": "P. Yeh; Chin-Hsien Wu; Yung-Hsiang Lin; Ming-Yan Wu",
    "corresponding_authors": "",
    "abstract": "Although NAND flash memory has the advantages of small size, low-power consumption, shock resistance, and fast access speed, NAND flash memory still faces the problems of “out-of-place updates,” “garbage collection,” and “unbalanced execution time” due to its hardware limitations. Usually, a flash translation layer (FTL) can maintain the mapping cache (in limited DRAM space) to store the frequently accessed address mapping for “out-of-place updates” and maintain the read/write buffer (in limited DRAM space) to store the frequently accessed data for “garbage collection” and “unbalanced execution time”. In this article, we will propose a write-related and read-related DRAM allocation strategy inside solid-state drives (SSDs). The design idea behind the write-related DRAM allocation method is to calculate the suitable DRAM allocation for the write buffer and the write mapping cache by building a statistical model with a minimum expected value of writes for NAND flash memory. To further reduce reads in NAND flash memory, the design idea behind the read-related DRAM allocation method is to adopt a cost-benefit policy to reallocate the proper DRAM space from the write buffer and the write mapping cache to the read buffer and the read mapping cache, respectively. According to the experimental results, we can demonstrate that the proposed write-related and read-related DRAM allocation strategy can reduce more reads/writes in NAND flash memory than other methods to improve the response time.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4294408872",
    "type": "article"
  },
  {
    "title": "Converging CSP specifications and C++ programming via selective formalism",
    "doi": "https://doi.org/10.1145/1067915.1067919",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "William B. Gardner",
    "corresponding_authors": "William B. Gardner",
    "abstract": "CSP (communicating sequential processes) is a useful algebraic notation for creating a hierarchical behavioral specification for concurrent systems, due to its formal interprocess synchronization and communication semantics. CSP specifications are amenable to simulation and formal verification by model-checking tools. A translator has been created to synthesize C++ code from CSP for execution with an object-oriented framework called CSP++, thereby making CSP specifications directly executable. To overcome the drawback that CSP is neither a full-featured nor popular programming language, an approach called “selective formalism” allows the use of CSP to be limited to specifying the control portion of a system, while the rest of its functionality is supplied in the form of C++ modules. These are activated through association with abstract events in the CSP specification. This is a new means of bringing convergence between a formal method and a popular programming language. It is believed that this methodology can be extended to hardware/software codesign for embedded systems.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2033745143",
    "type": "article"
  },
  {
    "title": "Analyzing data reuse for cache reconfiguration",
    "doi": "https://doi.org/10.1145/1113830.1113836",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "Jie Hu; Mahmut Kandemir; N. Vijaykrishnan; M. Irwin",
    "corresponding_authors": "",
    "abstract": "Classical compiler optimizations assume a fixed cache architecture and modify the program to take best advantage of it. In some cases, this may not be the best strategy because each nest might work best with a different cache configuration and transforming a nest for a given fixed cache configuration may not be possible due to data and control dependences. Working with a fixed cache configuration can also increase energy consumption in loops where the best required configuration is smaller than the default (fixed) one. In this paper, we take an alternate approach and modify the cache configuration for each nest, depending on the access pattern exhibited by the nest. We call this technique compiler-directed cache polymorphism (CDCP). More specifically, in this paper, we make the following contributions. First, we present an approach for analyzing data reuse properties of loop nests. Second, we give algorithms to simulate the footprints of array references in their reuse space. Third, based on our reuse analysis, we present an optimization algorithm to compute the cache configurations for each loop nest. Our experimental results show that CDCP is very effective in finding the near-optimal data cache configurations for different nests in array-intensive applications.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2075002275",
    "type": "article"
  },
  {
    "title": "Optimizing instruction cache performance of embedded systems",
    "doi": "https://doi.org/10.1145/1113830.1113839",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "Sandro Bartolini; Cosimo Antonio Prete",
    "corresponding_authors": "",
    "abstract": "In the embedded domain, the gap between memory and processor performance and the increase in application complexity need to be supported without wasting precious system resources: die size, power, etc. For these reasons, effective exploitation of small and simple cache memories is of the utmost importance. However, programs running on such caches can experience serious inefficiencies due to cache conflicts.We present a new Cache-Aware Code Allocation Technique (CAT), which transforms the structure of programs so that their behavior toward memory can meet the locality features the cache is able to exploit. The proposed approach uses detailed information of program execution to place program areas into memory and employs the new idea of “look-forward estimation” that helps to seek better global layouts during the placement of each area. CAT-optimized programs outperform the original ones achieving the same miss rate on two times, and sometimes four times, smaller caches. Moreover, CAT improves the instruction miss rate by more than 40% if compared to the best procedure-reordering algorithm. CAT performances derive from the increased number of cache lines that support the execution of optimized applications and from a more balanced load on them.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1995395807",
    "type": "article"
  },
  {
    "title": "Energy-efficient embedded software implementation on multiprocessor system-on-chip with multiple voltages",
    "doi": "https://doi.org/10.1145/1151074.1151078",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Shaoxiong Hua; Gang Qu; Shuvra S. Bhattacharyya",
    "corresponding_authors": "",
    "abstract": "This paper develops energy-driven completion ratio guaranteed scheduling techniques for the implementation of embedded software on multiprocessor systems with multiple supply voltages. We leverage application's performance requirements, uncertainties in execution time, and tolerance for reasonable execution failures to scale each processor's supply voltage at run-time to reduce the multiprocessor system's total energy consumption. Specifically, we study how to trade the difference between the system's highest achievable completion ratio Q max and the required completion ratio Q 0 for energy saving. First, we propose a best-effort energy minimization algorithm (BEEM1) that achieves Q max with the provably minimum energy consumption. We then relax its unrealistic assumption on the application's real execution time and develop algorithm BEEM2 that only requires the application's best- and worst-case execution times. Finally, we propose a hybrid offline on-line completion ratio guaranteed energy minimization algorithm (QGEM) that provides the required Q 0 with further energy reduction based on the probabilistic distribution of the application's execution time. We implement the proposed algorithms and verify their energy efficiency on real-life DSP applications and the TGFF random benchmark suite. BEEM1, BEEM2, and QGEM all provide the required completion ratio with average energy reduction of 28.7, 26.4, and 35.8%, respectively.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2005625314",
    "type": "article"
  },
  {
    "title": "Evaluating Network Processors using NetBench",
    "doi": "https://doi.org/10.1145/1151074.1151084",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Gokhan Memik; William H. Mangione-Smith",
    "corresponding_authors": "",
    "abstract": "The Network Processor market is one of the fastest growing segments of the microprocessor industry today. In spite of this increasing market importance, there does not exist a common framework to compare the performance of different Network Processor designs. Our primary goal in this study is to fill this gap by creating the NetBench benchmarking suite. NetBench is designed to represent Network Processor workloads. It contains 11 programs that form 18 different applications. The programs are selected from all levels of packet processing: Small, low-level code fragments as well as large application-level programs are included in the suite. These applications are representative of the Network Processor applications in the market. Using the SimpleScalar simulator to model an ARM processor, we study these programs in detail and compare key characteristics, such as instructions per cycle, instruction distribution, cache behavior, and branch prediction accuracy with the programs from MediaBench. Using statistical analysis, we show that the simulation results for the programs in NetBench have significantly different characteristics than programs in MediaBench. Finally, we present performance measurements from Intel IXP1200 Network Processor to show how NetBench can be utilized.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2058612860",
    "type": "article"
  },
  {
    "title": "VISTA",
    "doi": "https://doi.org/10.1145/1196636.1196640",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "Prasad A. Kulkarni; Wankang Zhao; Stephen Hines; David Whalley; Xin Yuan; Robert van Engelen; Kyle A. Gallivan; Jason D. Hiser; Jack W. Davidson; Baosheng Cai; Mark W. Bailey; Hwashin Moon; Kyunghwan Cho; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "Software designers face many challenges when developing applications for embedded systems. One major challenge is meeting the conflicting constraints of speed, code size, and power consumption. Embedded application developers often resort to hand-coded assembly language to meet these constraints since traditional optimizing compiler technology is usually of little help in addressing this challenge. The results are software systems that are not portable, less robust, and more costly to develop and maintain. Another limitation is that compilers traditionally apply the optimizations to a program in a fixed order. However, it has long been known that a single ordering of optimization phases will not produce the best code for every application. In fact, the smallest unit of compilation in most compilers is typically a function and the programmer has no control over the code improvement process other than setting flags to enable or disable certain optimization phases. This paper describes a new code improvement paradigm implemented in a system called VISTA that can help achieve the cost/performance trade-offs that embedded applications demand. The VISTA system opens the code improvement process and gives the application programmer, when necessary, the ability to finely control it. VISTA also provides support for finding effective sequences of optimization phases. This support includes the ability to interactively get static and dynamic performance information, which can be used by the developer to steer the code improvement process. This performance information is also internally used by VISTA for automatically selecting the best optimization sequence from several attempted. One such feature is the use of a genetic algorithm to search for the most efficient sequence based on specified fitness criteria. We include a number of experimental results that evaluate the effectiveness of using a genetic algorithm in VISTA to find effective optimization phase sequences.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2080756777",
    "type": "article"
  },
  {
    "title": "Reducing dynamic and leakage energy in VLIW architectures",
    "doi": "https://doi.org/10.1145/1132357.1132358",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "Wei Zhang; Y.-F. Tsai; D. Duarte; N. Vijaykrishnan; Mahmut Kandemir; M.J. Irwin",
    "corresponding_authors": "",
    "abstract": "The mobile computing device market has been growing rapidly. This brings the technologies that optimize system energy to the forefront. As circuits continue to scale in the future, it would be important to optimize both leakage and dynamic energy. Effective optimization of leakage and dynamic energy consumption requires a vertical integration of techniques spanning from circuit to software levels. Schedule slacks in codes executing in VLIW architectures present an opportunity for such an integration. In this paper, we present three compiler-directed techniques that take advantage of schedule slacks to optimize leakage and dynamic energy consumption. Integer ALU (IALU) components operating with multiple supply voltages are designed to provide different low-energy versions that possess different operational latencies. The goal of the first technique explored is to maximize the number of operations mapped to IALU components with the lowest energy consumption without extending the schedule length. We also consider a variant of this technique that saves more energy at the cost of some performance loss. The second technique uses two leakage-control mechanisms to reduce leakage energy consumption when no operations are scheduled in the component. Our evaluation of these two approaches, using fifteen benchmarks, shows that based on the number and duration of slacks, the availability of low-energy functional units and the relative magnitude of leakage and dynamic energy, either leakage or dynamic energy consumption, will provide more energy gains. Finally, we provide a unified energy-optimization strategy that integrates both dynamic and leakage energy-reduction schemes. The proposed techniques have been incorporated into a cycle accurate simulator using parameters extracted from circuit-level simulation. Our results show that the unified scheme generates better results than using either of dynamic and leakage energy-reduction techniques independently.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1974402114",
    "type": "article"
  },
  {
    "title": "Classifying interprocess communication in process network representation of nested-loop programs",
    "doi": "https://doi.org/10.1145/1234675.1234680",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Alexandru Turjan; Bart Kienhuis; E. Deprettere",
    "corresponding_authors": "",
    "abstract": "New embedded signal-processing architectures are emerging that are composed of loosely coupled heterogeneous components like CPUs or DSPs, specialized IP cores, reconfigurable units, or memories. We believe that these architectures should be programmed using the process network model of computation. To ease the mapping of applications, we are developing the Compaan compiler that automatically derives a process network (PN) description from an application written in Matlab or C. In this paper, we investigate a particular problem in nested loop programs, which is about classifying the interprocess communication in the PN representation of the nested loop program. The global memory arrays present in the code have to be replaced by a distributed communication structure used for communicating data between the network processes. We show that four types of communication exist, each exhibiting different requirements when realizing them in hardware or software. We first present two compile time tests that are based on integer linear programming to decide the type of the communication. In the second part of this paper, we present alternative classification techniques that have polynomial complexity. However, in some cases, those techniques do not give a definitive answer and the ILP tests have to be applied. All present tests are combined in a hybrid classification scheme that correctly classifies the interprocess communication. In only 5% of the cases to classify, we have to rely on integer linear programming while, in the remaining 95%, the alternative techniques presented in this paper are able to correctly classify each case. The hybrid classification scheme has become an important part of our Compaan compiler.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1985538159",
    "type": "article"
  },
  {
    "title": "ASIP architecture exploration for efficient IPSec encryption",
    "doi": "https://doi.org/10.1145/1234675.1234679",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Hanno Scharwaechter; David W. Kammler; Andreas Wieferink; Manuel Hohenauer; Kingshuk Karuri; Jianjiang Ceng; Rainer Leupers; Gerd Ascheid; H. Meyr",
    "corresponding_authors": "",
    "abstract": "Application-Specific Instruction-Set Processors (ASIPs) are becoming increasingly popular in the world of customized, application-driven System-on-Chip (SoC) designs. Efficient ASIP design requires an iterative architecture exploration loop---gradual refinement of the processor architecture starting from an initial template. To accomplish this task, design automation tools are used to detect bottlenecks in embedded applications, to implement application-specific processor instructions, and to automatically generate the required software tools (such as instruction-set simulator, C-compiler, assembler, and profiler), as well as to synthesize the hardware. This paper describes an architecture exploration loop for an ASIP coprocessor that implements common encryption functionality used in symmetric block cipher algorithms for internet protocol security (IPSec). The coprocessor is accessed via shared memory and, as a consequence, our approach is easily adaptable to arbitrary main processor architectures. This paper presents the extended version of our case study that has been already published on the SCOPES conference in 2004. In both papers, a MIPS architecture is used as the main processor and Blowfish as encryption algorithm.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2013993339",
    "type": "article"
  },
  {
    "title": "System and software architectures of distributed smart cameras",
    "doi": "https://doi.org/10.1145/1721695.1721704",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Chang Hong Lin; Marilyn Wolf; Xenefon Koutsoukos; Sandeep Neema; János Sztipanovits",
    "corresponding_authors": "",
    "abstract": "In this article, we describe a distributed, peer-to-peer gesture recognition system along with a software architecture modeling technique and authority control protocol for ubiquitous cameras. This system performs gesture recognition in real time by combining imagery from multiple cameras without using a central server. We propose a system architecture that uses a network of inexpensive cameras to perform in-network video processing. A methodology for transforming well-designed single-node algorithm to distributed system is also proposed. Applications for ubiquitous cameras can be modeled as the composition of a finite-state machine of the system, functional services, and middleware. A service-oriented software architecture is proposed to dynamically reconfigure services when system state changes. By exchanging data and control messages between neighboring sensors, each node can maintain broader view of the environment with integrated video-processing results. Our prototype system is built on Windows machines, and uses standard video cameras as sensors and local network as a communication channel.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1970844852",
    "type": "article"
  },
  {
    "title": "Energy-efficient encoding techniques for off-chip data buses",
    "doi": "https://doi.org/10.1145/1457255.1457256",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Dinesh C. Suresh; Banit Agrawal; Jun Yang; Walid Najjar",
    "corresponding_authors": "",
    "abstract": "Reducing the power consumption of computing devices has gained a lot of attention recently. Many research works have focused on reducing power consumption in the off-chip buses as they consume a significant amount of total power. Since the bus power consumption is proportional to the switching activity, reducing the bus switching is an effective way to reduce bus power. While numerous techniques exist for reducing bus power in address buses, only a handful of techniques have been proposed for data-bus power reduction, where frequent value encoding (FVE) is the best existing scheme to reduce the transition activity on the data buses. In this article, we propose improved frequent value data bus-encoding techniques aimed at reducing more switching activity and, hence, power consumption. We propose three new schemes and five new variations to exploit bit-wise temporal and spatial locality in the data-bus values. Our techniques just use one external control signal and capture bit-wise locality to efficiently encode data values. For all the embedded and SPEC applications we tested, the overall average switching reduction is 53% over unencoded data and 10% more than the conventional FVE scheme.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2005624096",
    "type": "article"
  },
  {
    "title": "NWSLite",
    "doi": "https://doi.org/10.1145/1347375.1347385",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Selim Gurun; Chandra Krintz; Rich Wolski",
    "corresponding_authors": "",
    "abstract": "Time series-based prediction methods have a wide range of uses in embedded systems. Many OS algorithms and applications require accurate prediction of demand and supply of resources. However, configuring prediction algorithms is not easy, since the dynamics of the underlying data requires continuous observation of the prediction error and dynamic adaptation of the parameters to achieve high accuracy. Current prediction methods are either too costly to implement on resource-constrained devices or their parameterization is static, making them inappropriate and inaccurate for a wide range of datasets. This paper presents NWSLite, a prediction utility that addresses these shortcomings on resource-restricted platforms.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2095697536",
    "type": "article"
  },
  {
    "title": "MEMMU",
    "doi": "https://doi.org/10.1145/1509288.1509295",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Lan Bai; Lei Yang; Robert P. Dick",
    "corresponding_authors": "",
    "abstract": "Random access memory (RAM) is tightly constrained in the least expensive, lowest-power embedded systems such as sensor network nodes and portable consumer electronics. The most widely used sensor network nodes have only 4 to 10KB of RAM and do not contain memory management units (MMUs). It is difficult to implement complex applications under such tight memory constraints. Nonetheless, price and power-consumption constraints make it unlikely that increases in RAM in these systems will keep pace with the increasing memory requirements of applications. We propose the use of automated compile-time and runtime techniques to increase the amount of usable memory in MMU-less embedded systems. The proposed techniques do not increase hardware cost, and require few or no changes to existing applications. We have developed runtime library routines and compiler transformations to control and optimize the automatic migration of application data between compressed and uncompressed memory regions, as well as a fast compression algorithm well suited to this application. These techniques were experimentally evaluated on Crossbow TelosB sensor network nodes running a number of data-collection and signal-processing applications. Our results indicate that available memory can be increased by up to 50% with less than 10% performance degradation for most benchmarks.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2126050136",
    "type": "article"
  },
  {
    "title": "Stop It, and Be Stubborn!",
    "doi": "https://doi.org/10.1145/3012279",
    "publication_date": "2017-01-10",
    "publication_year": 2017,
    "authors": "Antti Valmari",
    "corresponding_authors": "Antti Valmari",
    "abstract": "This publication discusses how automatic verification of concurrent systems can be made more efficient by focusing on always may-terminating systems . First, making a system always may-terminating is a method for meeting a modelling need that exists independently of this publication. It is illustrated that without doing so, non-progress errors may be lost. Second, state explosion is often alleviated with stubborn, ample, and persistent set methods. They use expensive cycle or terminal strong component conditions in many cases. It is proven that for many important classes of properties, if the systems are always may-terminating, then these conditions can be left out.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1530365972",
    "type": "article"
  },
  {
    "title": "Boosting software fault injection for dependability analysis of real-time embedded applications",
    "doi": "https://doi.org/10.1145/1880050.1880060",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Gianpiero Cabodi; Marco Murciano; M. Violante",
    "corresponding_authors": "",
    "abstract": "The design of complex embedded systems deployed in safety-critical or mission-critical applications mandates the availability of methods to validate the system dependability across the whole design flow. In this article we introduce a fault injection approach, based on loadable kernel modules and running under the Linux operating system, which can be adopted as soon as a running prototype of the systems is available. Moreover, for the purpose of decoupling dependability analysis from hardware availability, we also propose the adoption of hardware virtualization. Extensive experimental results show that statistical analysis made on top of virtual prototypes are in good agreement with the information disclosed by fault detection trends of real platforms, even under real-time constraints.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1964612838",
    "type": "article"
  },
  {
    "title": "Profiling and online system-level performance and power estimation for dynamically adaptable embedded systems",
    "doi": "https://doi.org/10.1145/2442116.2442135",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Jingqing Mu; Karthik Shankar; Roman Lysecky",
    "corresponding_authors": "",
    "abstract": "Significant research has demonstrated the performance and power benefits of runtime dynamic reconfiguration of FPGAs and microprocessor/FPGA devices. For dynamically reconfigurable systems, in which the selection of hardware coprocessors to implement within the FPGA is determined at runtime, online estimation methods are needed to evaluate the performance and power consumption impact of the hardware coprocessor selection. In this paper, we present a profile assisted online system-level performance and power estimation framework for estimating the speedup and power consumption of dynamically reconfigurable embedded systems. We evaluate the accuracy and fidelity of our online estimation framework for dynamic hardware kernel selection to maximize performance or minimize the system power consumption.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1964983974",
    "type": "article"
  },
  {
    "title": "Power-aware dynamic memory management on many-core platforms utilizing DVFS",
    "doi": "https://doi.org/10.1145/2536747.2536762",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Iraklis Anagnostopoulos; Jean-Michel Chabloz; Ioannis Koutras; Alexandros Bartzas; Ahmed Hemani; Dimitrios Soudris",
    "corresponding_authors": "",
    "abstract": "Today multicore platforms are already prevalent solutions for modern embedded systems. In the future, embedded platforms will have an even more increased processor core count, composing many-core platforms. In addition, applications are becoming more complex and dynamic and try to efficiently utilize the amount of available resources on the embedded platforms. Efficient memory utilization is a key challenge for application developers, especially since memory is a scarce resource and often becomes the system's bottleneck. To cope with this dynamism and achieve better memory footprint utilization (low memory fragmentation) application developers resort to the usage of dynamic memory (heap) management techniques, by allocating and deallocating data at runtime. Moreover, overall power consumption is another key challenge that needs to be taken into consideration. Towards this, designers employ the usage of Dynamic Voltage and Frequency Scaling (DVFS) mechanisms, adapting to the application's computational demands at runtime. In this article, we propose the combination of dynamic memory management techniques with DVFS ones. This is performed by integrating, within the memory manager, runtime monitoring mechanisms that steer the DVFS mechanisms to adjust clock frequency and voltage supply based on heap performance. The proposed approach has been evaluated on a distributed shared-memory many-core platform composed of multiple LEON3 processors interconnected by a Network-on-Chip infrastructure, supporting DVFS. Experimental results show that by using the proposed method for monitoring and applying DVFS mechanisms the power consumption concerning dynamic memory management was reduced by approximately 37%. In addition we present the trade-offs the proposed approach. Last, by combining the developed method with heap fragmentation-aware dynamic memory managers, we achieve low heap fragmentation values combined with low power consumption.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1970942414",
    "type": "article"
  },
  {
    "title": "Reflexes",
    "doi": "https://doi.org/10.1145/1814539.1814543",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Jesper Honig Spring; Filip Pizlo; Jean Privat; Rachid Guerraoui; Jan Vítek",
    "corresponding_authors": "",
    "abstract": "Achieving submillisecond response times in a managed language environment such as Java or C# requires overcoming significant challenges. In this article, we propose Reflexes, a programming model and runtime system infrastructure that lets developers seamlessly mix highly responsive tasks and timing-oblivious Java applications. Thus enabling gradual addition of real-time features, to a non-real-time application without having to resort to recoding the real-time parts in a different language such as C or Ada. Experiments with the Reflex prototype implementation show that it is possible to run a real-time task with a period of 45 μs with an accuracy of 99.996% (only 0.001% worse than the corresponding C implementation) in the presence of garbage collection and heavy load ordinary Java threads.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1989623126",
    "type": "article"
  },
  {
    "title": "A comparison of compositional schedulability analysis techniques for hierarchical real-time systems",
    "doi": "https://doi.org/10.1145/2501626.2501629",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Madhukar Anand; Sebastian Fischmeister; Insup Lee",
    "corresponding_authors": "",
    "abstract": "Schedulability analysis of hierarchical real-time embedded systems involves defining interfaces that represent the underlying system faithfully and then compositionally analyzing those interfaces. Whereas commonly used abstractions, such as periodic and sporadic tasks and their interfaces, are simple and well studied, results for more complex and expressive abstractions and interfaces based on task graphs and automata are limited. One contributory factor may be the hardness of compositional schedulability analysis with task graphs and automata. Recently, conditional task models, such as the recurring branching task model, have been introduced with the goal of reaching a middle ground in the trade-off between expressivity and ease of analysis. Consequently, techniques for compositional analysis with conditional models have also been proposed, and each offer different advantages. In this work, we revisit those techniques, compare their advantages using an automotive case study, and identify limitations that would need to be addressed before adopting these techniques for use with real-world problems.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2002399871",
    "type": "article"
  },
  {
    "title": "Memory performance estimation of CUDA programs",
    "doi": "https://doi.org/10.1145/2514641.2514648",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Yooseong Kim; Aviral Shrivastava",
    "corresponding_authors": "",
    "abstract": "CUDA has successfully popularized GPU computing, and GPGPU applications are now used in various embedded systems. The CUDA programming model provides a simple interface to program on GPUs, but tuning GPGPU applications for high performance is still quite challenging. Programmers need to consider numerous architectural details, and small changes in source code, especially on the memory access pattern, can affect performance significantly. This makes it very difficult to optimize CUDA programs. This article presents CuMAPz, which is a tool to analyze and compare the memory performance of CUDA programs. CuMAPz can help programmers explore different ways of using shared and global memories, and optimize their program for efficient memory behavior. CuMAPz models several memory-performance-related factors: data reuse, global memory access coalescing, global memory latency hiding, shared memory bank conflict, channel skew, and branch divergence. Experimental results show that CuMAPz can accurately estimate performance with correlation coefficient of 0.96. By using CuMAPz to explore the memory access design space, we could improve the performance of our benchmarks by 30% more than the previous approach [Hong and Kim 2010].",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2006290685",
    "type": "article"
  },
  {
    "title": "An optimal warning-zone-length assignment algorithm for real-time and multiple-QoS on-chip bus arbitration",
    "doi": "https://doi.org/10.1145/1721695.1721701",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Huan-Kai Peng; Youn-Long Lin",
    "corresponding_authors": "",
    "abstract": "In an advanced System-on-Chip (SoC) for real-time applications, the arbiter of its on-chip communication subsystem needs to support multiple QoS criteria while providing a hard real-time guarantee. To fulfill both objectives, the arbitration algorithm must dynamically switch between NonReal-Time (NRT) and Real-Time (RT) modes such that use of the RT mode is minimized to best accommodate the overall QoS criteria. In this article, we define a model for this problem, and propose optimal solutions to its associated problems with static and dynamic warning-zone-length assignment. Compared with previous works, the proposed approach enables a bus arbiter to use much less RT mode in providing a Real-Time (RT) guarantee and, therefore, gives the arbiter more opportunity to employ non-RT modes to achieve better overall QoS. Experimental results show that the proposed approach reduces RT mode usage by as much as 37.1%. Moreover, that reduction in RT mode usage helps cut the execution time by 27.0% when applying our approach to an industrial DRAM controller. Another case study on an AMBA-compliant ultra-high-resolution H.264 decoder IP shows that the proposed approach reduces RT mode usage by 26.4%, which leads to an average reduction of 10.4% in decoding time. Finally, when implementing a 16 master arbiter, it costs only 6.9K and 9.5K gates of overhead using the proposed static and dynamic approach, respectively. Therefore, the proposed approach is suitable for real-time SoC applications.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2062048444",
    "type": "article"
  },
  {
    "title": "A self-adjusting flash translation layer for resource-limited embedded systems",
    "doi": "https://doi.org/10.1145/1721695.1721697",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Chin-Hsien Wu",
    "corresponding_authors": "Chin-Hsien Wu",
    "abstract": "The capacity of flash memory storage systems has been growing at a speed similar to many other storage systems. In order to properly manage the product cost, vendors face serious challenges in resource-limited embedded systems. In this article, a self-adjusting flash translation layer is proposed with low memory requirements. The objective of the design is to provide efficient address mapping and low garbage collection overhead, while controlling main memory usage of the flash translation layer. The capability of the design is evaluated over realistic workloads and benchmarks. System performance is also guaranteed under low memory requirements.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2065373692",
    "type": "article"
  },
  {
    "title": "Hardware architectural support for control systems and sensor processing",
    "doi": "https://doi.org/10.1145/2514641.2514643",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Sudhanshu Vyas; Adwait Gupte; Christopher Gill; Ron K. Cytron; Joseph Zambreno; Phillip H. Jones",
    "corresponding_authors": "",
    "abstract": "The field of modern control theory and the systems used to implement these controls have shown rapid development over the last 50 years. It was often the case that those developing control algorithms could assume the computing medium was solely dedicated to the task of controlling a plant, for example, the control algorithm being implemented in software on a dedicated Digital Signal Processor (DSP), or implemented in hardware using a simple dedicated Programmable Logic Device (PLD). As time progressed, the drive to place more system functionality in a single component (reducing power, cost, and increasing reliability) has made this assumption less often true. Thus, it has been pointed out by some experts in the field of control theory (e.g., Astrom) that those developing control algorithms must take into account the effects of running their algorithms on systems that will be shared with other tasks. One aspect of the work presented in this article is a hardware architecture that allows control developers to maintain this simplifying assumption. We focus specifically on the Proportional-Integral-Derivative (PID) controller. An on-chip coprocessor has been implemented that can scale to support servicing hundreds of plants, while maintaining microsecond-level response times, tight deterministic control loop timing, and allowing the main processor to service noncontrol tasks. In order to control a plant, the controller needs information about the plant's state. Typically this information is obtained from sensors with which the plant has been instrumented. There are a number of common computations that may be performed on this sensor data before being presented to the controller (e.g., averaging and thresholding). Thus in addition to supporting PID algorithms, we have developed a Sensor Processing Unit (SPU) that off-loads these common sensor processing tasks from the main processor. We have prototyped our ideas using Field Programmable Gate Array (FPGA) technology. Through our experimental results, we show our PID execution unit gives orders of magnitude improvement in response time when servicing many plants, as compared to a standard general software implementation. We also show that the SPU scales much better than a general software implementation. In addition, these execution units allow the simplifying assumption of dedicated computing medium to hold for control algorithm development.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2066119977",
    "type": "article"
  },
  {
    "title": "Parallel Sparse Subspace Clustering via Joint Sample and Parameter Blockwise Partition",
    "doi": "https://doi.org/10.1145/3063316",
    "publication_date": "2017-05-09",
    "publication_year": 2017,
    "authors": "Bo Liu; Xiao‐Tong Yuan; Yang Yu; Qingshan Liu; Dimitris Metaxas",
    "corresponding_authors": "",
    "abstract": "Sparse subspace clustering (SSC) is a classical method to cluster data with specific subspace structure for each group. It has many desirable theoretical properties and has been shown to be effective in various applications. However, under the condition of a large-scale dataset, learning the sparse sample affinity graph is computationally expensive. To tackle the computation time cost challenge, we develop a memory-efficient parallel framework for computing SSC via an alternating direction method of multiplier (ADMM) algorithm. The proposed framework partitions the data matrix into column blocks and then decomposes the original problem into parallel multivariate Lasso regression subproblems and samplewise operations. The proposed method allows us to allocate multiple cores/machines for the processing of individual column blocks. We propose a stochastic optimization algorithm to minimize the objective function. Experimental results on real-world datasets demonstrate that the proposed blockwise ADMM framework is substantially more efficient than its matrix counterpart used by SSC, without sacrificing performance in applications. Moreover, our approach is directly applicable to parallel neighborhood selection for Gaussian graphical models structure estimation.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2613003028",
    "type": "article"
  },
  {
    "title": "<i>R</i> <sup>3</sup>",
    "doi": "https://doi.org/10.1145/3070720",
    "publication_date": "2017-09-20",
    "publication_year": 2017,
    "authors": "Dié Wu; Li Lu; Muhammad Jawad Hussain; Songfan Li; Mo Li; Fengli Zhang",
    "corresponding_authors": "",
    "abstract": "Computational Radio Frequency Identification (CRFID) tags operate solely on harvested energy and have emerged as viable platforms for a variety of ubiquitous sensing and computation applications. Due to their battery-less nature, these tags can be permanently deployed in hard-to-reach places where the possibility of tag access is eliminated. In such scenarios, maintaining and upgrading the tag’s firmware becomes infeasible because programming tools, including wired interface and PC-based software, are required to erase, modify, or reprogram the microcontroller unit’s memory. Such limitations necessitate the demand for an over-the-air (OTA) scheme, which can wirelessly reprogram or upgrade the firmware in CRFID tags. In this article, we present R 3 —a reliable OTA reprogramming scheme that is compliant with EPC protocol and requires no hardware upgrade to RFID reader or CRFID tag. We demonstrate our scheme on three platforms, which include both software-defined as well as chip-based CRFID tags, that is, WISP5.1 and Optimized WISP (Opt-WISP), and Spider tag, respectively. The selection also includes both the FLASH- and FRAM-based microcontrollers. We extensively evaluate our scheme in terms of several metrics, including overall system delay, time and energy overhead, and success rate in line with interrogation range. We foresee our endeavor to offer the viability of OTA reprogramming and firmware upgrade for CRFID tokens under practical situations.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2754499892",
    "type": "article"
  },
  {
    "title": "Predictive Retransmissions for Intermittently Connected Sensor Networks with Transmission Diversity",
    "doi": "https://doi.org/10.1145/3092947",
    "publication_date": "2017-09-20",
    "publication_year": 2017,
    "authors": "Md. Majharul Islam Rajib; Asis Nasipuri",
    "corresponding_authors": "",
    "abstract": "Batteryless wireless sensor networks that rely on energy harvested from the environment often exhibit random power outages due to limitations of energy resources, which give rise to intermittent connectivity and long transmission delays. To improve the delay performance in such networks, we consider a design strategy that uses predictive retransmissions to maximize the probability of success for each transmission. This is applied to two different transmission diversity schemes: cooperative relaying over unicast routes and opportunistic routing. Performance evaluations from theoretical models and simulations are presented that show that significant gains can be achieved using the proposed approach in such networks.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2755812461",
    "type": "article"
  },
  {
    "title": "Implementation of Partitioned Mixed-Criticality Scheduling on a Multi-Core Platform",
    "doi": "https://doi.org/10.1145/3126533",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Roman Trüb; Georgia Giannopoulou; Andreas Tretter; Lothar Thiele",
    "corresponding_authors": "",
    "abstract": "Recent industrial trends favor the adoption of multi-core architectures for mixed-criticality applications. Although several mixed-criticality multi-core scheduling approaches have been proposed, currently there are few implementations on hardware that demonstrate efficient resource utilization and the ability to bound interference on shared resources. To address this necessity, we develop a mixed-criticality runtime environment on the Kalray MPPA-256 Andey many-core platform. The runtime environment implements a scheduling policy based on adaptive temporal partitioning. We develop models, methods and implementation principles to implement the necessary scheduling primitives, to achieve high platform utilization and to perform a compositional worst-case execution time analysis. The bounds account for scheduling overheads and for the inter-task interference on the platform’s shared memory. Using realistic benchmarks from avionics and signal processing, we validate the correctness and tightness of the bounds and demonstrate a high platform utilization.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2757059707",
    "type": "article"
  },
  {
    "title": "An Abstraction-Refinement Theory for the Analysis and Design of Real-Time Systems",
    "doi": "https://doi.org/10.1145/3126507",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Philip S. Kurtin; Marco J.G. Bekooij",
    "corresponding_authors": "",
    "abstract": "Component-based and model-based reasonings are key concepts to address the increasing complexity of real-time systems. Bounding abstraction theories allow to create efficiently analyzable models that can be used to give temporal or functional guarantees on non-deterministic and non-monotone implementations. Likewise, bounding refinement theories allow to create implementations that adhere to temporal or functional properties of specification models. For systems in which jitter plays a major role, both best-case and worst-case bounding models are needed. In this paper we present a bounding abstraction-refinement theory for real-time systems. Compared to the state-of-the-art TETB refinement theory, our theory is less restrictive with respect to the automatic lifting of properties from component to graph level and does not only support temporal worst-case refinement, but evenhandedly temporal and functional, best-case and worst-case abstraction and refinement.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2757376342",
    "type": "article"
  },
  {
    "title": "RISE",
    "doi": "https://doi.org/10.1145/3126549",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Bita Darvish Rouhani; Azalia Mirhoseini; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "This paper proposes RISE, an automated Reconfigurable framework for real-time background subtraction applied to Intelligent video SurveillancE. RISE is devised with a new streaming-based methodology that adaptively learns/updates a corresponding dictionary matrix from background pixels as new video frames are captured over time. This dictionary is used to highlight the foreground information in each video frame. A key characteristic of RISE is that it adaptively adjusts its dictionary for diverse lighting conditions and varying camera distances by continuously updating the corresponding dictionary. We evaluate RISE on natural-scene vehicle images of different backgrounds and ambient illuminations. To facilitate automation, we provide an accompanying API that can be used to deploy RISE on FPGA-based system-on-chip platforms. We prototype RISE for end-to-end deployment of three widely-adopted image processing tasks used in intelligent transportation systems: License Plate Recognition (LPR), image denoising/reconstruction, and principal component analysis. Our evaluations demonstrate up to 87-fold higher throughput per energy unit compared to the prior-art software solution executed on ARM Cortex-A15 embedded platform.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2759267666",
    "type": "article"
  },
  {
    "title": "User-aware Frame Rate Management in Android Smartphones",
    "doi": "https://doi.org/10.1145/3126539",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Begum Egilmez; Matthew Schuchhardt; Gokhan Memik; Raid Ayoub; Niranjan Soundararajan; Michael Kishinevsky",
    "corresponding_authors": "",
    "abstract": "Frame rate has a direct impact on the energy consumption of smartphones: the higher the frame rate, the higher the power consumption. Hence, reducing display refreshes will reduce the power consumption. However, it is risky to manipulate frame rate drastically as it can deteriorate user satisfaction with the device. In this work, we introduce a screen management system that controls the frame rate on smartphone displays based on a model that detects user dissatisfaction due to display refreshes. This approach is based on understanding when higher frame rates are necessary, and providing lower frame rates —thus, saving power— if the lower rate is predicted not to cause user dissatisfaction. According to the results of our first user survey with 20 participants, individuals show highly varying requirements: while some users require high frame rates for the highest satisfaction, others are equally satisfied with lower frame rates. Based on this observation, we develop a system that predicts user dissatisfaction on the runtime and either increases or decreases the maximum frame rate setting. For user dissatisfaction predictions, we have compared two different approaches: (1) static model, which uses dissatisfaction characteristics of a fixed group of people, and (2) user-specific model, which is learning only from the specific user. Our second set of experiments with 20 participants shows that users report 32% less dissatisfaction and 4% more dissatisfaction than the default Android system with user-specific and static systems, respectively. These experiments also show that, compared to the default scheme, our mechanisms reduce the power consumption of the phone by 7.2% and 1.8% on average with the user-specific and static models, respectively.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2759477978",
    "type": "article"
  },
  {
    "title": "An Inexact Ultra-low Power Bio-signal Processing Architecture With Lightweight Error Recovery",
    "doi": "https://doi.org/10.1145/3126565",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Soumya Basu; Loris Duch; Rubén Braojos; Giovanni Ansaloni; Laura Pozzi; David Atienza",
    "corresponding_authors": "",
    "abstract": "The energy efficiency of digital architectures is tightly linked to the voltage level (Vdd) at which they operate. Aggressive voltage scaling is therefore mandatory when ultra-low power processing is required. Nonetheless, the lowest admissible Vdd is often bounded by reliability concerns, especially since static and dynamic non-idealities are exacerbated in the near-threshold region, imposing costly guard-bands to guarantee correctness under worst-case conditions. A striking alternative, explored in this paper, waives the requirement for unconditional correctness, undergoing more relaxed constraints. First, after a run-time failure, processing correctly resumes at a later point in time. Second, failures induce a limited Quality-of-Service (QoS) degradation. We focus our investigation on the practical scenario of embedded bio-signal analysis, a domain in which energy efficiency is key, while applications are inherently error-tolerant to a certain degree. Targeting a domain-specific multi-core platform, we present a study of the impact of inexactness on application-visible errors. Then, we introduce a novel methodology to manage them, which requires minimal hardware resources and a negligible energy overhead. Experimental evidence show that, by tolerating 900 errors/hour, the resulting inexact platform can achieve an efficiency increase of up to 24%, with a QoS degradation of less than 3%.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2759875273",
    "type": "article"
  },
  {
    "title": "Symbolic WCET Computation",
    "doi": "https://doi.org/10.1145/3147413",
    "publication_date": "2017-12-07",
    "publication_year": 2017,
    "authors": "Clément Ballabriga; Julien Forget; Giuseppe Lipari",
    "corresponding_authors": "",
    "abstract": "Parametric Worst-case execution time (WCET) analysis of a sequential program produces a formula that represents the worst-case execution time of the program, where parameters of the formula are user-defined parameters of the program (as loop bounds, values of inputs, or internal variables, etc). In this article we propose a novel methodology to compute the parametric WCET of a program. Unlike other algorithms in the literature, our method is not based on Integer Linear Programming (ILP). Instead, we follow an approach based on the notion of symbolic computation of WCET formulae. After explaining our methodology and proving its correctness, we present a set of experiments to compare our method against the state of the art. We show that our approach dominates other parametric analyses and produces results that are very close to those produced by non-parametric ILP-based approaches, while keeping very good computing time.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2775065827",
    "type": "article"
  },
  {
    "title": "Loop-Oriented Pointer Analysis for Automatic SIMD Vectorization",
    "doi": "https://doi.org/10.1145/3168364",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Yulei Sui; Xiaokang Fan; Hao Zhou; Jingling Xue",
    "corresponding_authors": "",
    "abstract": "Compiler-based vectorization represents a promising solution to automatically generate code that makes efficient use of modern CPUs with SIMD extensions. Two main auto-vectorization techniques, superword-level parallelism vectorization (SLP) and loop-level vectorization (LLV), require precise dependence analysis on arrays and structs to vectorize isomorphic scalar instructions (in the case of SLP) and reduce dynamic dependence checks at runtime (in the case of LLV). The alias analyses used in modern vectorizing compilers are either intra-procedural (without tracking inter-procedural data-flows) or inter-procedural (by using field-sensitive models, which are too imprecise in handling arrays and structs). This article proposes an inter-procedural L oop-oriented P ointer A nalysis for C, called L pa , for analyzing arrays and structs to support aggressive SLP and LLV optimizations effectively. Unlike field-insensitive solutions that pre-allocate objects for each memory allocation site, our approach uses a lazy memory model to generate access-based location sets based on how structs and arrays are accessed. L pa can precisely analyze arrays and nested aggregate structures to enable SIMD optimizations for large programs. By separating the location set generation as an independent concern from the rest of the pointer analysis, L pa is designed so that existing points-to resolution algorithms (e.g., flow-insensitive and flow-sensitive pointer analysis) can be reused easily. We have implemented L pa fully in the LLVM compiler infrastructure (version 3.8.0). We evaluate L pa by considering SLP and LLV, the two classic vectorization techniques, on a set of 20 C and Fortran CPU2000/2006 benchmarks. For SLP, L pa outperforms LLVM’s BasicAA and ScevAA by discovering 139 and 273 more vectorizable basic blocks, respectively, resulting in the best speedup of 2.95% for 173.applu. For LLV, LLVM introduces totally 551 and 652 static bound checks under BasicAA and ScevAA, respectively. In contrast, L pa has reduced these static checks to 220, with an average of 15.7 checks per benchmark, resulting in the best speedup of 7.23% for 177.mesa.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2785870245",
    "type": "article"
  },
  {
    "title": "An Analytical Cache Performance Evaluation Framework for Embedded Out-of-Order Processors Using Software Characteristics",
    "doi": "https://doi.org/10.1145/3233182",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Kecheng Ji; Ming Ling; Longxing Shi; Jianping Pan",
    "corresponding_authors": "",
    "abstract": "Utilizing analytical models to evaluate proposals or provide guidance in high-level architecture decisions is been becoming more and more attractive. A certain number of methods have emerged regarding cache behaviors and quantified insights in the last decade, such as the stack distance theory and the memory level parallelism (MLP) estimations. However, prior research normally oversimplified the factors that need to be considered in out-of-order processors, such as the effects triggered by reordered memory instructions, and multiple dependences among memory instructions, along with the merged accesses in the same MSHR entry. These ignored influences actually result in low and unstable precisions of recent analytical models. By quantifying the aforementioned effects, this article proposes a cache performance evaluation framework equipped with three analytical models, which can more accurately predict cache misses, MLPs, and the average cache miss service time, respectively. Similar to prior studies, these analytical models are all fed with profiled software characteristics in which case the architecture evaluation process can be accelerated significantly when compared with cycle-accurate simulations. We evaluate the accuracy of proposed models compared with gem5 cycle-accurate simulations with 16 benchmarks chosen from Mobybench Suite 2.0, Mibench 1.0, and Mediabench II. The average root mean square errors for predicting cache misses, MLPs, and the average cache miss service time are around 4%, 5%, and 8%, respectively. Meanwhile, the average error of predicting the stall time due to cache misses by our framework is as low as 8%. The whole cache performance estimation can be sped by about 15 times versus gem5 cycle-accurate simulations and 4 times when compared with recent studies. Furthermore, we have shown and studied the insights between different performance metrics and the reorder buffer sizes by using our models. As an application case of the framework, we also demonstrate how to use our framework combined with McPAT to find out Pareto optimal configurations for cache design space explorations.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2885732802",
    "type": "article"
  },
  {
    "title": "Single- and Multi-FPGA Acceleration of Dense Stereo Vision for Planetary Rovers",
    "doi": "https://doi.org/10.1145/3312743",
    "publication_date": "2019-03-18",
    "publication_year": 2019,
    "authors": "George Lentaris; Konstantinos Maragos; Dimitrios Soudris; Xenophon Zabulis; Manolis Lourakis",
    "corresponding_authors": "",
    "abstract": "Increased mobile autonomy is a vital requisite for future planetary exploration rovers. Stereo vision is a key enabling technology in this regard, as it can passively reconstruct in three dimensions the surroundings of a rover and facilitate the selection of science targets and the planning of safe routes. Nonetheless, accurate dense stereo algorithms are computationally demanding. When executed on the low-performance, radiation-hardened CPUs typically installed on rovers, slow stereo processing severely limits the driving speed and hence the science that can be conducted in situ . Aiming to decrease execution time while increasing the accuracy of stereo vision embedded in future rovers, this article proposes HW/SW co-design and acceleration on resource-constrained, space-grade FPGAs. In a top-down approach, we develop a stereo algorithm based on the space sweep paradigm, design its parallel HW architecture, implement it with VHDL, and demonstrate feasible solutions even on small-sized devices with our multi-FPGA partitioning methodology. To meet all cost, accuracy, and speed requirements set by the European Space Agency for this system, we customize our HW/SW co-processor by design space exploration and testing on a Mars-like dataset. Implemented on Xilinx Virtex technology, or European NG-MEDIUM devices, the FPGA kernel processes a 1,120 × 1,120 stereo pair in 1.7s−3.1s, utilizing only 5.4−9.3 LUT6 and 200−312 RAMB18. The proposed system exhibits up to 32× speedup over desktop CPUs, or 2,810× over space-grade LEON3, and achieves a mean reconstruction error less than 2cm up to 4m depth. Excluding errors exceeding 2cm (which are less than 4% of the total), the mean error is under 8mm.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2920867622",
    "type": "article"
  },
  {
    "title": "Thermal-aware Real-time Scheduling Using Timed Continuous Petri Nets",
    "doi": "https://doi.org/10.1145/3322643",
    "publication_date": "2019-07-02",
    "publication_year": 2019,
    "authors": "G. Desirena-López; Antonio Ramírez‐Treviño; José Luis Briz; Carlos Renato Vázquez; David Gómez‐Gutiérrez",
    "corresponding_authors": "",
    "abstract": "We present a thermal-aware, hard real-time (HRT) global scheduler for a multiprocessor system designed upon three novel techinques. First, we present a modeling methodology based on Timed Continuous Petri nets (TCPN) that yields a complete state variable model, including job arrivals, CPU usage, power, and thermal behavior. The model is accurate and avoids the calibration stage of RC thermal models. Second, based on this model, a linear programming problem (LPP) determines the existence of a feasible HRT thermal-aware schedule. Last, a sliding-mode controller and an online discretization algorithm implement the global HRT scheduler, which is capable of managing thermal constraints, context switching, migrations, and disturbances.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2955052180",
    "type": "article"
  },
  {
    "title": "T <scp>reble</scp>",
    "doi": "https://doi.org/10.1145/3358237",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Keun Soo Yim; Iliyan Malchev; Andrew Hsieh; Dave Burke",
    "corresponding_authors": "",
    "abstract": "This paper presents our experience with T reble , a two-year initiative to build the modular base in Android, a Java-based mobile platform running on the Linux kernel. Our T reble architecture splits the hardware independent core framework written in Java from the hardware dependent vendor implementations (e.g., user space device drivers, vendor native libraries, and kernel written in C/C++). Cross-layer communications between them are done via versioned, stable inter-process communication interfaces whose backward compatibility is tested by using two API compliance suites. Based on this architecture, we repackage the key Android software components that suffered from crucial post-launch security bugs as separate images. That not only enables separate ownerships but also independent updates of each image by interested ecosystem entities. We discuss our experience of delivering T reble architectural changes to silicon vendors and device makers using a yearly release model. Our experiments and industry rollouts support our hypothesis that giving more freedom to all ecosystem entities and creating an equilibrium are a transformation necessary to further scale the world largest open source ecosystem with over two billion active devices.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2979427478",
    "type": "article"
  },
  {
    "title": "PredictNcool",
    "doi": "https://doi.org/10.1145/3358208",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Lokesh Siddhu; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "Recent research on mitigating thermal problems in 3D memories has covered reactive strategies that reduce memory power consumption, and thereby, performance, when the memory temperature reaches the maximum operating limit. Such techniques could benefit from temperature prediction and avoid unnecessary invocations and state transitions of the thermal management strategy. We develop an accurate steady state temperature predictor for thermal management of 3D memories. We utilize the symmetries in the floorplan, along with other design insights, to reduce the predictor’s model parameters, making it lightweight and suitable for runtime thermal management. Using the temperature prediction, we introduce PredictNcool , a proactive thermal management strategy to reduce application runtime and memory energy. We compare PredictNcool with two recent thermal management strategies and our experiments show that the proposed optimization results in performance improvements of 28% and 5%, and memory subsystem energy reductions of 38% and 12% (on average).",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2979616436",
    "type": "article"
  },
  {
    "title": "Compositional Design of Multi-Robot Systems Control Software on ROS",
    "doi": "https://doi.org/10.1145/3358197",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Stefano Spellini; Michele Lora; Franco Fummi; Sudipta Chattopadhyay",
    "corresponding_authors": "",
    "abstract": "This paper presents a methodology that relies on Assume-Guarantee Contracts to decompose the problem of synthesizing control software for a multi-robot system. Initially, each contract describes either a component ( e.g. , a robot) or an aspect of the system. Then, the design problem is decomposed into different synthesis and verification sub-problems, allowing to tackle the complexity involved in the design process. The design problem is then recomposed by exploiting the rigorousness provided by contracts. This allows us to achieve system-level simulation capable to be used for validating the entire design. Once validated, the software synthesized during the process can be integrated into Robot Operating System (ROS) nodes and executed using state-of-the-practice packages and tools for modern robotic systems. We apply the methodology to generate a control strategy for an autonomous goods transportation system. Our results show a massive reduction of the time required to obtain automatically the control software implementing a multi-robot mission.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2979675173",
    "type": "article"
  },
  {
    "title": "Locking the Design of Building Blocks for Quantum Circuits",
    "doi": "https://doi.org/10.1145/3358184",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Samah Mohamed Saeed; Robert Wille; Ramesh Karri",
    "corresponding_authors": "",
    "abstract": "The research community expects that quantum computers will give economical results for particular problems on which the classical computers break down. Examples include factoring of large numbers, searching in a big database, or simulating chemical reactions to design new drugs. Attempts are ongoing to build up a practical quantum computer. Users (clients) can implement quantum circuits to run on these quantum computers. However, before running the quantum circuit on the quantum computer, the users (clients) should compile, optimize, decompose, and technology map the quantum circuit. In the current embodiment, the resulting quantum circuit runs on a remote and untrusted quantum computer server -- introducing security risks. This study explores the risk of outsourcing the quantum circuit to the quantum computer by focusing on quantum oracles. Quantum oracles are pivotal building blocks and require specialized expertise and means to design. Hence, the designer may protect this proprietary quantum oracle intellectual property (IP) and hide his/her private information. We investigate how to manage that on a quantum computer server using the IBM project QX quantum computer and Qiskit tools as an exemplar.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2979682826",
    "type": "article"
  },
  {
    "title": "Distill-Net",
    "doi": "https://doi.org/10.1145/3360512",
    "publication_date": "2019-09-30",
    "publication_year": 2019,
    "authors": "Mohammad Motamedi; Felix Portillo; Daniel Fong; Soheil Ghiasi",
    "corresponding_authors": "",
    "abstract": "Many Internet-of-Things (IoT) applications demand fast and accurate understanding of a few key events in their surrounding environment. Deep Convolutional Neural Networks (CNNs) have emerged as an effective approach to understand speech, images, and similar high-dimensional data types. Algorithmic performance of modern CNNs, however, fundamentally relies on learning class-agnostic hierarchical features that only exist in comprehensive training datasets with many classes. As a result, fast inference using CNNs trained on such datasets is prohibitive for most resource-constrained IoT platforms. To bridge this gap, we present a principled and practical methodology for distilling a complex modern CNN that is trained to effectively recognize many different classes of input data into an application-dependent essential core that not only recognizes the few classes of interest to the application accurately but also runs efficiently on platforms with limited resources. Experimental results confirm that our approach strikes a favorable balance between classification accuracy (application constraint), inference efficiency (platform constraint), and productive development of new applications (business constraint).",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2979872554",
    "type": "article"
  },
  {
    "title": "RMW-F",
    "doi": "https://doi.org/10.1145/3358210",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Chenlin Ma; Zhaoyan Shen; Lei Han; Zili Shao",
    "corresponding_authors": "",
    "abstract": "Shingled Magnetic Recording (SMR) disks have been proposed as a high-density, non-volatile media and precede traditional hard disk drives in both storing capacity and cost. However, the intrinsic characteristics of SMR disks raise a major performance challenge named read-modify-write operations (RMWs) that are time-consuming and can significantly degrade the overall system performance. Current designs of SMR disks usually adopt a persistent cache to alleviate the negative effect brought by RMWs and the cache is used as a first-level cache to buffer all the incoming writes of the whole SMR storage system. In this paper, we propose to change the functionality of the cache, that is, the cache will no longer serve as a first-level cache like previous. Incoming data are distinguished according to their different write-back behavior and those data which will incur RMWs will be left in our built-in NAND flash cache called RMW-free Cache (RMW-F) to eliminate the need of RMWs. Besides, RMW-F improves the cleaning efficiency by a model that takes both write-back cost and data popularity into considerations. Our experimental results show that RMW-F can achieve both system performance and cleaning efficiency improvements.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2980079482",
    "type": "article"
  },
  {
    "title": "REAL",
    "doi": "https://doi.org/10.1145/3362100",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Sakshi Tiwari; Shreshth Tuli; Isaar Ahmad; Ayushi Agarwal; Preeti Ranjan Panda; Sreenivas Subramoney",
    "corresponding_authors": "",
    "abstract": "Shared last level caches (LLC) of multicore systems-on-chip are subject to a significant amount of contention over a limited bandwidth, resulting in major performance bottlenecks that make the issue a first-order concern in modern multiprocessor systems-on-chip. Even though shared cache space partitioning has been extensively studied in the past, the problem of cache bandwidth partitioning has not received sufficient attention. We demonstrate the occurrence of such contention and the resulting impact on the overall system performance. To address the issue, we perform detailed simulations to study the impact of different parameters and propose a novel cache bandwidth partitioning technique, called REAL , that arbitrates among cache access requests originating from different processor cores. It monitors the LLC access patterns to dynamically assign a priority value to each core. Experimental results on different mixes of benchmarks show up to 2.13× overall system speedup over baseline policies, with minimal impact on energy.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2984287963",
    "type": "article"
  },
  {
    "title": "3PXNet",
    "doi": "https://doi.org/10.1145/3371157",
    "publication_date": "2020-01-31",
    "publication_year": 2020,
    "authors": "Wojciech Romaszkan; Tianmu Li; Puneet Gupta",
    "corresponding_authors": "",
    "abstract": "As the adoption of Neural Networks continues to proliferate different classes of applications and systems, edge devices have been left behind. Their strict energy and storage limitations make them unable to cope with the sizes of common network models. While many compression methods such as precision reduction and sparsity have been proposed to alleviate this, they don’t go quite far enough. To push size reduction to its absolute limits, we combine binarization with sparsity in Pruned-Permuted-Packed XNOR Networks (3PXNet), which can be efficiently implemented on even the smallest of embedded microcontrollers. 3PXNets can reduce model sizes by up to 38X and reduce runtime by up to 3X compared with already compact conventional binarized implementations with less than 3% accuracy reduction. We have created the first software implementation of sparse-binarized Neural Networks, released as open source library targeting edge devices. Our library is complete with training methodology and model generating scripts, making it easy and fast to deploy.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3005087657",
    "type": "article"
  },
  {
    "title": "DSTL",
    "doi": "https://doi.org/10.1145/3391892",
    "publication_date": "2020-07-04",
    "publication_year": 2020,
    "authors": "Yi-Jing Chuang; Shuo-Han Chen; Yuan-Hao Chang; Yu-Pei Liang; Hsin‐Wen Wei; Wei‐Kuan Shih",
    "corresponding_authors": "",
    "abstract": "Shingled magnetic recording (SMR) is regarded as a promising technology for resolving the areal density limitation of conventional magnetic recording hard disk drives. Among different types of SMR drives, drive-managed SMR (DM-SMR) requires no changes on the host software and is widely used in today’s consumer market. DM-SMR employs a shingled translation layer (STL) to hide its inherent sequential-write constraint from the host software and emulate the SMR drive as a block device via maintaining logical to physical block address mapping entries. However, because most existing STL designs do not simultaneously consider the access pattern and the data update frequency of incoming workloads, those mapping entries maintained within the STL cannot be effectively managed, thus inducing unnecessary performance overhead. To resolve the inefficiency of existing STL designs, this article proposes a demand-based STL (DSTL) to simultaneously consider the access pattern and update frequency of incoming data streams to enhance the access performance of DM-SMR. The proposed design was evaluated by a series of experiments, and the results show that the proposed DSTL can outperform other SMR management approach by up to 86.69% in terms of read/write performance.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3040517582",
    "type": "article"
  },
  {
    "title": "Crab-tree",
    "doi": "https://doi.org/10.1145/3396236",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Chundong Wang; Sudipta Chattopadhyay; Gunavaran Brihadiswarn",
    "corresponding_authors": "",
    "abstract": "In recent years, the next-generation non-volatile memory (NVM) technologies have emerged with DRAM-like byte addressability and disk-like durability. Computer architects have proposed to use them to build persistent memory that blurs the conventional boundary between volatile memory and non-volatile storage. However, ARM processors, ones that are widely used in embedded computing systems, start providing architectural supports to utilize NVM since ARMv8. In this article, we consider tailoring B+-tree for NVM operated by a 64-bit ARMv8 processor. We first conduct an empirical study of performance overhead in writing and reading data for a B+-tree with an ARMv8 processor, including the time cost of cache line flushes and memory fences for crash consistency as well as the execution time of binary search compared to that of linear search. We hence identify the key weaknesses in the design of B+-tree with ARMv8 architecture. Accordingly, we develop a new B+-tree variant, namely, &lt;underline&gt;c&lt;/underline&gt; rash &lt;underline&gt;r&lt;/underline&gt; ecoverable &lt;underline&gt;A&lt;/underline&gt; RMv8-oriented &lt;underline&gt;B &lt;/underline&gt;+-tree (Crab-tree). To insert and delete data at runtime, Crab-tree selectively chooses one of two strategies, i.e., copy on write and shifting in place, depending on which one causes less consistency cost. Crab-tree regulates a strict execution order in both strategies and recovers the tree structure in case of crashes. To further improve the performance of Crab-tree, we employ three methods to reduce software overhead, cache misses, and consistency cost, respectively. We have implemented and evaluated Crab-tree in Raspberry Pi 3 Model B+ with emulated NVM. Experiments show that Crab-tree significantly outperforms state-of-the-art B+-trees designed for persistent memory by up to 2.2× and 3.7× in write and read performances, respectively, with both consistency and scalability achieved.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3041442006",
    "type": "article"
  },
  {
    "title": "Applying Multiple Level Cell to Non-volatile FPGAs",
    "doi": "https://doi.org/10.1145/3400885",
    "publication_date": "2020-07-12",
    "publication_year": 2020,
    "authors": "Ke Liu; Mengying Zhao; Lei Ju; Zhiping Jia; Jingtong Hu; Chun Jason Xue",
    "corresponding_authors": "",
    "abstract": "Static random access memory– (SRAM) based field programmable gate arrays (FPGAs) are currently facing challenges of limited capacity and high leakage power. To solve this problem, non-volatile memory (NVM) is proposed as the alternative to build non-volatile FPGAs (NVFPGAs). Even though the feasibility of NVFPGA has been confirmed, the utilization of multiple level cells (MLCs) has not been fully exploited yet. In this article, we study architecture of MLC-based NVFPGAs, and propose five cluster structures. To give detailed comparisons and extensive discussions, we conduct experiments for area, performance and leakage power evaluation. Based on explorations of the characteristics of MLC-based NVFPGAs, we further present MLC-aware timing-driven packing method to improve delay. In critical paths, our proposed method reduces the overhead of the additional delay in slow MLC cells. Experiments show that, compared to SRAM-based FPGAs, the proposed architecture with the proposed CAD flow can reduce the area, critical path delay and leakage power by 31%, 10%, and 95%, respectively.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3042346944",
    "type": "article"
  },
  {
    "title": "An asymmetric dual-processor architecture for low-power information appliances",
    "doi": "https://doi.org/10.1145/2560538",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "François Guimbretière; Liu Shen-wei; Han Wang; Rajit Manohar",
    "corresponding_authors": "",
    "abstract": "As users become increasingly conscious of their energy footprint—either to improve battery life or to respect the environment—improved energy efficiency of systems has gained in importance. This is especially important in the context of information appliances such as e-book readers that are meant to replace books, since their energy efficiency impacts how long the appliance can be used on a single charge of the battery. In this article, we present a new software and hardware architecture for information appliances that provides significant advantages in terms of device lifetime. The architecture combines a low-power microcontroller with a high-performance application processor, where the low-power microcontroller is used to handle simple user interactions (e.g., turning pages, inking, entering text) without waking up the main application processor. We demonstrate how this architecture is easily adapted to the traditional way of building user interfaces using a user interface markup language. We report on our initial measurements using an E Ink-based prototype. When comparing our hybrid architecture to a simpler solution we found that we can increase the battery life by a factor of 1.72 for a reading task and by a factor of 3.23 for a writing task. We conclude by presenting design guidelines aimed at optimizing the overall energy signature of information appliances.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1963786218",
    "type": "article"
  },
  {
    "title": "Task Assignment Algorithms for Heterogeneous Multiprocessors",
    "doi": "https://doi.org/10.1145/2660494",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Gurulingesh Raravi; Vincent Nélis",
    "corresponding_authors": "",
    "abstract": "Consider the problem of assigning implicit-deadline sporadic tasks on a heterogeneous multiprocessor platform comprising a constant number (denoted by t ) of distinct types of processors—such a platform is referred to as a t-type platform . We present two algorithms, LPG IM and LPG NM , each providing the following guarantee. For a given t-type platform and a task set, if there exists a task assignment such that tasks can be scheduled to meet their deadlines by allowing them to migrate only between processors of the same type (intra-migrative), then : (i) LPG IM succeeds in finding such an assignment where the same restriction on task migration applies (intra-migrative) but given a platform in which only one processor of each type is 1 + α × t -1/ t times faster and (ii) LPG NM succeeds in finding a task assignment where tasks are not allowed to migrate between processors (non-migrative) but given a platform in which every processor is 1 + α times faster. The parameter α is a property of the task set; it is the maximum of all the task utilizations that are no greater than one. To the best of our knowledge, for t-type heterogeneous multiprocessors: (i) for the problem of intra-migrative task assignment, no previous algorithm exists with a proven bound and hence our algorithm, LPG IM , is the first of its kind and (ii) for the problem of non-migrative task assignment, our algorithm, LPG NM , has superior performance compared to state-of-the-art.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2021929252",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Real-Time, Embedded and Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/2660488",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Li-Pin Chang; Tei‐Wei Kuo; Chris Gill; Jin Nakazawa",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2025567621",
    "type": "article"
  },
  {
    "title": "A Java Processor IP Design for Embedded SoC",
    "doi": "https://doi.org/10.1145/2629649",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Chun-Jen Tsai; Han-Wen Kuo; Zigang Lin; Zi-Jing Guo; Junfu Wang",
    "corresponding_authors": "",
    "abstract": "In this article, we present a reusable Java processor IP for application processors of embedded systems. For the Java microarchitecture, we propose a low-cost stack memory design that supports a two-fold instruction folding pipeline and a low-complexity Java exception handling hardware. We also propose a mapping between the Java dynamic class loading model and the SoC platform-based design principle so that the Java core can be encapsulated as a reusable IP. To achieve this goal, a two-level method area with two on-chip circular buffers is proposed as an interface between the RISC core and the Java core. The proposed architecture is implemented on a Xilinx Virtex-5 FPGA device. Experimental results show that its performance has some advantages over other Java processors and a Java VM with JIT acceleration on a PowerPC platform.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2045179016",
    "type": "article"
  },
  {
    "title": "Message blinding method requiring no multiplicative inversion for RSA",
    "doi": "https://doi.org/10.1145/2560020",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Hee Seok Kim; Dong‐Guk Han; Seokhie Hong; Jaecheol Ha",
    "corresponding_authors": "",
    "abstract": "This article proposes a new message blinding methods requiring no multiplicative inversion for RSA. Most existing message blinding methods for RSA additionally require the multiplicative inversion, even though computational complexity of this operation is O ( n 3 ) which is equal to that of the exponentiation. Thus, this additional operation is known to be the main drawback of the existing message blinding methods for RSA. In addition to requiring no additional multiplicative inversion, our new countermeasure provides the security against various power analysis attacks as well as general differential power analysis.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2053721513",
    "type": "article"
  },
  {
    "title": "Hybrid compilation and optimization for java-based digital TV platforms",
    "doi": "https://doi.org/10.1145/2506257",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Dong-Heon Jung; Soo‐Mook Moon; Hyeong‐Seok Oh",
    "corresponding_authors": "",
    "abstract": "The Java-based software platform for interactive digital TV (DTV) is composed of the system/middleware class statically installed on the DTV set-top box and the xlet applications dynamically downloaded from the TV stations. The xlet application includes Java classes and image/text files. The xlets are executed only when the TV viewer initiates an interaction, even if the xlets have been completely downloaded. To achieve high performance on this dual-component, user-initiated system, existing just-in-time (JIT) compilation and optimization is not enough; instead, ahead-of-time and idle-time compilation and optimization are also needed, requiring a hybrid compilation and optimization environment. We constructed such a hybrid environment for a commercial DTV software platform and evaluated it using real, on-air xlet applications. Our experimental results show that the proposed hybrid environment can improve the DTV Java performance by more than three times, compared to the JIT-only environment, with little change to other DTV behavior.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2080374450",
    "type": "article"
  },
  {
    "title": "Using a Flexible Fault-Tolerant Cache to Improve Reliability for Ultra Low Voltage Operation",
    "doi": "https://doi.org/10.1145/2629566",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Abbas BanaiyanMofrad; Houman Homayoun; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Caches are known to consume a large part of total microprocessor power. Traditionally, voltage scaling has been used to reduce both dynamic and leakage power in caches. However, aggressive voltage reduction causes process-variation--induced failures in cache SRAM arrays, which compromise cache reliability. In this article, we propose FFT-Cache, a flexible fault-tolerant cache that uses a flexible defect map to configure its architecture to achieve significant reduction in energy consumption through aggressive voltage scaling while maintaining high error reliability. FFT-Cache uses a portion of faulty cache blocks as redundancy—using block-level or line-level replication within or between sets—to tolerate other faulty caches lines and blocks. Our configuration algorithm categorizes the cache lines based on degree of conflict between their blocks to reduce the granularity of redundancy replacement. FFT-Cache thereby sacrifices a minimal number of cache lines to avoid impacting performance while tolerating the maximum amount of defects. Our experimental results on a processor executing SPEC2K benchmarks demonstrate that the operational voltage of both L1/L2 caches can be reduced down to 375 mV, which achieves up to 80% reduction in the dynamic power and up to 48% reduction in the leakage power. This comes with only a small performance loss (&lt;%5) and 13% area overhead.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2084461499",
    "type": "article"
  },
  {
    "title": "Branch Prediction-Directed Dynamic Instruction Cache Locking for Embedded Systems",
    "doi": "https://doi.org/10.1145/2660492",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Keni Qiu; Mengying Zhao; Chun Jason Xue; Alex Orailoğlu",
    "corresponding_authors": "",
    "abstract": "Cache locking is a cache management technique to preclude the replacement of locked cache contents. Cache locking is often adopted to improve cache access predictability in Worst-Case Execution Time (WCET) analysis. Static cache locking methods have been proposed recently to improve Average-Case Execution Time (ACET) performance. This article presents an approach, Branch Prediction-directed Dynamic Cache Locking (BPDCL), to improve system performance through cache conflict miss reduction. In the proposed approach, the control flow graph of a program is first partitioned into disjoint execution regions, then memory blocks worth locking are determined by calculating the locking profit for each region. These two steps are conducted during compilation time. At runtime, directed by branch predictions, locking routines are prefetched into a small high-speed buffer. The predetermined cache locking contents are loaded and locked at specific execution points during program execution. Experimental results show that the proposed BPDCL method exhibits an average improvement of 25.9%, 13.8%, and 8.0% on cache miss rate reduction in comparison to cases with no cache locking, the static locking method, and the dynamic locking method, respectively.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2157490181",
    "type": "article"
  },
  {
    "title": "Learning Hardware-Friendly Classifiers Through Algorithmic Stability",
    "doi": "https://doi.org/10.1145/2836165",
    "publication_date": "2016-01-29",
    "publication_year": 2016,
    "authors": "Luca Oneto; Sandro Ridella; Davide Anguita",
    "corresponding_authors": "",
    "abstract": "Most state-of-the-art machine-learning (ML) algorithms do not consider the computational constraints of implementing the learned model on embedded devices. These constraints are, for example, the limited depth of the arithmetic unit, the memory availability, or the battery capacity. We propose a new learning framework, the Algorithmic Risk Minimization (ARM), which relies on Algorithmic-Stability, and includes these constraints inside the learning process itself. ARM allows one to train advanced resource-sparing ML models and to efficiently deploy them on smart embedded systems. Finally, we show the advantages of our proposal on a smartphone-based Human Activity Recognition application by comparing it to a conventional ML approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2235151955",
    "type": "article"
  },
  {
    "title": "A Collaborative Energy-Aware Sensor Management System Using Team Theory",
    "doi": "https://doi.org/10.1145/2910574",
    "publication_date": "2016-05-23",
    "publication_year": 2016,
    "authors": "Allaa R. Hilal; Otman Basir",
    "corresponding_authors": "",
    "abstract": "With limited battery supply, power is a scarce commodity in wireless sensor networks. Thus, to prolong the lifetime of the network, it is imperative that the sensor resources are managed effectively. This task is particularly challenging in heterogeneous sensor networks for which decisions and compromises regarding sensing strategies are to be made under time and resource constraints. In such networks, a sensor has to reason about its current state to take actions that are deemed appropriate with respect to its mission, its energy reserve, and the survivability of the overall network. Sensor Management controls and coordinates the use of the sensory suites in a manner that maximizes the success rate of the system in achieving its missions. This article focuses on formulating and developing an autonomous energy-aware sensor management system that strives to achieve network objectives while maximizing its lifetime. A team-theoretic formulation based on the Belief-Desire-Intention (BDI) model and the Joint Intention theory is proposed as a mechanism for effective and energy-aware collaborative decision-making. The proposed system models the collective behavior of the sensor nodes using the Joint Intention theory to enhance sensors’ collaboration and success rate. Moreover, the BDI modeling of the sensor operation and reasoning allows a sensor node to adapt to the environment dynamics, situation-criticality level, and availability of its own resources. The simulation scenario selected in this work is the surveillance of the Waterloo International Airport. Various experiments are conducted to investigate the effect of varying the network size, number of threats, threat agility, environment dynamism, as well as tracking quality and energy consumption, on the performance of the proposed system. The experimental results demonstrate the merits of the proposed approach compared to the state-of-the-art centralized approach adapted from Atia et al. [2011] and the localized approach in Hilal and Basir [2015] in terms of energy consumption, adaptability, and network lifetime. The results show that the proposed approach has 12 × less energy consumption than that of the popular centralized approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2400605430",
    "type": "article"
  },
  {
    "title": "Hybrid Montgomery Reduction",
    "doi": "https://doi.org/10.1145/2890502",
    "publication_date": "2016-05-23",
    "publication_year": 2016,
    "authors": "Hwajeong Seo; Zhe Liu; Yasuyuki Nogami; Jongseok Choi; Howon Kim",
    "corresponding_authors": "",
    "abstract": "In this article, we present a hybrid method to improve the performance of the Montgomery reduction by taking advantage of the Karatsuba technique. We divide the Montgomery reduction into two sub-parts, including one for the conventional Montgomery reduction and the other one for Karatsuba-aided multiplication. This approach reduces the multiplication complexity of n -limb Montgomery reduction from θ( n 2 + n ) to asymptotic complexity θ (7 n 2 /8 + n ). Our practical implementation results over an 8-bit microcontroller also show performance enhancements by 11%.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2407031230",
    "type": "article"
  },
  {
    "title": "Evaluation and Improvements of Runtime Monitoring Methods for Real-Time Event Streams",
    "doi": "https://doi.org/10.1145/2890503",
    "publication_date": "2016-05-23",
    "publication_year": 2016,
    "authors": "Biao Hu; Kai Huang; Gang Chen; Long Cheng; Alois Knoll",
    "corresponding_authors": "",
    "abstract": "Runtime monitoring is of great importance as a safeguard to guarantee the correctness of system runtime behaviors. Two state-of-the-art methods, dynamic counters and l -repetitive function, were recently developed to tackle the runtime monitoring for real-time systems. While both are reported to be efficient in monitoring arbitrary events, the monitoring performance between them has not yet been evaluated. This article evaluates both methods in depth, to identify their strengths and weaknesses. New methods are proposed to efficiently monitor the many-to-one connections that are abstracted as AND and OR components on multiple inputs. Representative scenarios are used as our case studies to quantitatively demonstrate the evaluations. Both methods are implemented in hardware F pga . The timing overhead and resource usages of implementing the two methods are evaluated.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2407551549",
    "type": "article"
  },
  {
    "title": "Harmonic Segment-Based Semi-Partitioning Scheduling on Multi-Core Real-Time Systems",
    "doi": "https://doi.org/10.1145/2933388",
    "publication_date": "2016-08-02",
    "publication_year": 2016,
    "authors": "Hadeer A. Hassan; Sameh A. Salem; Ahmed M. Mostafa; E. M. Saad",
    "corresponding_authors": "",
    "abstract": "Nowadays, the issue of scheduling multi-core real-time systems has become the focus of such research in industrial, biomedical, military, and other fields. As a consequence, a new semi-partitioning algorithm that uses a static Rate-Monotonic criterion to schedule real-time tasks on multi-core platforms is proposed. The improvement in the performance of real-time systems is achieved by exploitingthe fact that the utilization boundary of a task set increases to fully utilize the processors if the periods of tasks have harmonic nature among each other. Experimental results on randomly generated datasets and real-world datasets show that the proposed algorithm inevitably outperforms other competitive algorithms.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2489232807",
    "type": "article"
  },
  {
    "title": "Simulating Reconfigurable Multiprocessor Systems-on-Chip with MPSoCSim",
    "doi": "https://doi.org/10.1145/2972952",
    "publication_date": "2016-10-23",
    "publication_year": 2016,
    "authors": "Philipp Wehner; Jens Rettkowski; Tobias Kalb; Diana Göhringer",
    "corresponding_authors": "",
    "abstract": "Upcoming reconfigurable Multiprocessor Systems-on-Chip (MPSoCs) present new challenges for the design and early estimation of technology requirements due to their runtime adaptive hardware architecture. The usage of simulators offers capabilities to overcome these issues. In this article, MPSoCSim, a SystemC simulator for Network-on-Chip (NoC) based MPSoCs is extended to support the simulation of reconfigurable MPSoCs. Processors, such as ARM and MicroBlaze, and peripheral models used within the virtual platform are provided by Imperas/OVP and attached to the NoC. Moreover, traffic generators are available to analyze the system. The virtual platform currently supports mesh topology with wormhole switching and several routing algorithms such as XY-, a minimal West-First algorithm, and an adaptive West-First algorithm. Amongst the impact of routing algorithms regarding performance, reconfiguration processes can be examined using the presented simulator. A mechanism for dynamic partial reconfiguration is implemented that is oriented towards the reconfiguration scheme on real FPGA platforms. It includes the simulation of the undefined behavior of the hardware region during reconfiguration and allows the adjustment of parameters. During runtime, dynamic partial reconfiguration interfaces are used to connect the Network-on-Chip infrastructure with reconfigurable regions. The configuration access ports can be modeled by the controller for the dynamic partial reconfiguration in form of an application programming interface. An additional SystemC component enables the readout of simulation time from within the application. For evaluation of the simulator timing and power consumption of the simulated hardware are estimated and compared with a real hardware implementation on a Xilinx Zynq FPGA. The comparison shows that the simulator improves the development of reconfigurable MPSoCs by early estimation of system requirements. The power estimations show a maximum deviation of 9mW at 1.9W total power consumption.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2537133748",
    "type": "article"
  },
  {
    "title": "Eager Synching",
    "doi": "https://doi.org/10.1145/2930668",
    "publication_date": "2016-12-19",
    "publication_year": 2016,
    "authors": "Li-Pin Chang; Po-Han Sung; Po-Tsang Chen; Po-Hung Chen",
    "corresponding_authors": "",
    "abstract": "Flash storage has been a standard component in Android devices. Recent research has reported that application data management in Android involves frequent fsync() operations. The current fsync() implementations, including those of ext4 and F2FS, have several common drawbacks. Specifically, ext4 commits a transaction every time to sync a file, whereas F2FS commits a checkpoint to sync a directory. Committing a transaction or checkpoint flushes all dirty data from the page cache to the flash storage via many small, random block write requests. The resultant high I/O frequency and excessive write traffic cause a high fsync() latency. This study presents an efficient fsync() method, called eager synching, which is based on a simple idea: write less, and write sequentially. To sync a file, eager synching writes only a subset of all dirty data in the page cache to a sequential log space using a few sequential block write requests. It does not involve transaction or checkpoint committing. We successfully implemented eager synching in ext4 and F2FS, and our experimental results show that, compared with the original fsync() methods of ext4 and F2FS, eager synching reduced the average and maximum fsync() latencies by up to 72% and 91%, respectively, block-level write traffic by up to 35%, and I/O frequency by up to 66%. Through enhanced crash recovery procedures, eager synching can successfully recover all previously synched files while still guaranteeing the file system integrity. We also conducted live application replays using the proposed eager synching approach and observed that this approach significantly improved the application frame updating rate and application execution time.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2565990742",
    "type": "article"
  },
  {
    "title": "Loosely Time-Triggered Architectures",
    "doi": "https://doi.org/10.1145/2932189",
    "publication_date": "2016-08-02",
    "publication_year": 2016,
    "authors": "Guillaume Baudart; Albert Benveniste; Timothy Bourke",
    "corresponding_authors": "",
    "abstract": "Loosely Time-Triggered Architectures (LTTAs) are a proposal for constructing distributed embedded control systems. They build on the quasi-periodic architecture, where computing units execute nearly periodically , by adding a thin layer of middleware that facilitates the implementation of synchronous applications. In this article, we show how the deployment of a synchronous application on a quasi-periodic architecture can be modeled using a synchronous formalism. Then we detail two protocols, Back-Pressure LTTA, reminiscent of elastic circuits, and Time-Based LTTA, based on waiting. Compared to previous work, we present controller models that can be compiled for execution, a simplified version of the Time-Based protocol and optimizations for systems using broadcast communication. We also compare the LTTA approach with architectures based on clock synchronization.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2618616513",
    "type": "article"
  },
  {
    "title": "Efficient Table-based Function Approximation on FPGAs Using Interval Splitting and BRAM Instantiation",
    "doi": "https://doi.org/10.1145/3580737",
    "publication_date": "2023-01-25",
    "publication_year": 2023,
    "authors": "Chetana Pradhan; Martín Letras; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "This article proposes a novel approach for the generation of memory-efficient table-based function approximation circuits for edge devices in general and FPGAs in particular. Given a function f(x) to be approximated in a given interval [ x 0 , x 0+a ) and a maximum approximation error E a , the goal is to determine a function table implementation with a minimized memory footprint, i.e., number of entries that need to be stored. Rather than state-of-the-art work performing an equidistant sampling of the given interval by so-called breakpoints and using linear interpolation between two adjacent breakpoints to determine f(x) at the maximum error bound, we propose and compare three algorithms for splitting the given interval into sub-intervals to reduce the required memory footprint drastically based on the observation that in sub-intervals of low gradient, a coarser sampling grid may be assumed while guaranteeing the maximum interpolation error bound E a . Experiments on elementary mathematical functions show that a large fraction in memory footprint may be saved. Second, a hardware architecture implementing the sub-interval selection, breakpoint lookup, and interpolation at a latency of just 9 clock cycles is introduced. Third, for each generated circuit design, BRAMs are automatically instantiated rather than synthesizing the reduced footprint function table using LUT primitives, providing an additional degree of resource efficiency. The approach presented here for FPGAs can equally be applied to other circuit technologies for fast and, at the same time, memory-optimized function approximation at the edge.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4317935436",
    "type": "article"
  },
  {
    "title": "A Hierarchical Classification Method for High-accuracy Instruction Disassembly with Near-field EM Measurements",
    "doi": "https://doi.org/10.1145/3629167",
    "publication_date": "2023-10-25",
    "publication_year": 2023,
    "authors": "V Iyer; Aditya Thimmaiah; Michael Orshansky; Andreas Gerstlauer; Ali E. Yılmaz",
    "corresponding_authors": "",
    "abstract": "Electromagnetic (EM) fields have been extensively studied as potent side-channel tools for testing the security of hardware implementations. In this work, a low-cost side-channel disassembler that uses fine-grained EM signals to predict a program's execution trace with high accuracy is proposed. Unlike conventional side-channel disassemblers, the proposed disassembler does not require extensive randomized instantiations of instructions to profile them, instead relying on leakage-model-informed sub-sampling of potential architectural states resulting from instruction execution, which is further augmented by using a structured hierarchical approach. The proposed disassembler consists of two phases: (i) In the feature-selection phase, signals are collected with a relatively small EM probe, performing high-resolution scans near the chip surface, as profiling codes are executed. The measured signals from the numerous probe configurations are compiled into a hierarchical database by storing the min-max envelopes of the probed EM fields and differential signals derived from them, a novel dimension that increases the potency of the analysis. The envelope-to-envelope distances are evaluated throughout the hierarchy to identify optimal measurement configurations that maximize the distance between each pair of instruction classes. (ii) In the classification phase, signals measured for unknown instructions using optimal measurement configurations identified in the first phase are compared to the envelopes stored in the database to perform binary classification with majority voting, identifying candidate instruction classes at each hierarchical stage. Both phases of the disassembler rely on a four-stage hierarchical grouping of instructions by their length, size, operands, and functions. The proposed disassembler is shown to recover ∼97–99% of instructions from several test and application benchmark programs executed on the AT89S51 microcontroller.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4387933470",
    "type": "article"
  },
  {
    "title": "Techniques for maintaining connectivity in wireless ad-hoc networks under energy constraints",
    "doi": "https://doi.org/10.1145/1275986.1275988",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Farinaz Koushanfar; Abhijit Davare; David T. Nguyen; Alberto Sangiovanni‐Vincentelli; Miodrag Potkonjak",
    "corresponding_authors": "",
    "abstract": "Distributed wireless systems (DWSs) are emerging as the enabler for next-generation wireless applications. There is a consensus that DWS-based applications, such as pervasive computing, sensor networks, wireless information networks, and speech and data communication networks, will form the backbone of the next technological revolution. Simultaneously, with great economic, industrial, consumer, and scientific potential, DWSs pose numerous technical challenges. Among them, two are widely considered as crucial: autonomous localized operation and minimization of energy consumption. We address the fundamental problem of how to maximize the lifetime of the network using only local information, while preserving network connectivity. We start by introducing the care-free sleep (CS) Theorem that provides provably optimal conditions for a node to go into sleep mode while ensuring that global connectivity is not affected. The CS theorem is the basis for an efficient localized algorithm that decides which nodes will go to into sleep mode and for how long. We have also developed mechanisms for collecting neighborhood information and for the coordination of distributed energy minimization protocols. The effectiveness of the approach is demonstrated using a comprehensive study of the performance of the algorithm over a wide range of network parameters. Another important highlight is the first mathematical and Monte Carlo analysis that establishes the importance of considering nodes within a small number of hops in order to preserve energy.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1991118413",
    "type": "article"
  },
  {
    "title": "Hardware/software IP integration using the ROSES design environment",
    "doi": "https://doi.org/10.1145/1275986.1275989",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Flávio Rech Wagner; W. Cesário; Ahmed Jerraya",
    "corresponding_authors": "",
    "abstract": "Considering current time-to-market pressures, IP reuse is mandatory for the design of complex embedded systems-on-chip (SoC). The integration of IP components into a given design is the most complex task in the whole reuse process. This paper describes the IP integration approach implemented in the ROSES design environment, which presents a unique combination of features that enhance IP reuse: automatic assembly of interfaces between heterogeneous software and hardware IP components; easy adaptation to different on-chip communication structures and bus and core standards; generation of customized and minimal OSs for programmable components; and an architecture-independent high-level API embedded into SystemC that makes application software independent from system implementation. Application code is written by using communication functions available in this API. ROSES automatically assembles wrappers that implement these functions, such that the application code does not need to be modified in order to run in the final synthesized system.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2044203422",
    "type": "article"
  },
  {
    "title": "Slotless module-based reconfiguration of embedded FPGAs",
    "doi": "https://doi.org/10.1145/1596532.1596538",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Cameron Patterson; Peter Athanas; M. Shelburne; John W. Bowen; Jorge Suris; Timothy G. Dunham; Justin L. Rice",
    "corresponding_authors": "",
    "abstract": "The difficult aspect of hardware reconfiguration is not creating the computational blocks, which are generally available from FPGA vendors and third parties, but linking the blocks in a manner that suits each application's unique connectivity, bandwidth, and latency requirements. Our approach uses the standard Xilinx implementation tools to generate dynamic module partial bitstreams, but choosing the module's coordinates and completing connections to other modules are runtime operations. Scripts automatically add interface wrappers to dynamic modules and generate a library of relocatable partial bitstreams. The library is used by an efficient runtime system that completes application requests for instancing and connecting modules, effectively insulating the designer from FPGA reconfiguration complexities. In this way, a large sandbox may be allocated to dynamic modules rather than fixed module slots and interconnect. Application engineers interact with the Wires on Demand (WoD) system through a runtime software API, and do not have to master hardware description languages and implementation tools.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1970262313",
    "type": "article"
  },
  {
    "title": "LPWAN in the TV White Spaces",
    "doi": "https://doi.org/10.1145/3447877",
    "publication_date": "2021-05-13",
    "publication_year": 2021,
    "authors": "M. Rahman; Dali Ismail; Venkata P. Modekurthy; Abusayeed Saifullah",
    "corresponding_authors": "",
    "abstract": "Low-Power Wide-Area Network (LPWAN) is an enabling Internet-of-Things technology that supports long-range, low-power, and low-cost connectivity to numerous devices. To avoid the crowd in the limited ISM band (where most LPWANs operate) and cost of licensed band, the recently proposed Sensor Network over White Spaces (SNOW) is a promising LPWAN platform that operates over the TV white spaces. As it is a very recent technology and is still in its infancy, the current SNOW implementation uses the Universal Software Radio Peripheral devices as LPWAN nodes, which has high costs (≈$750 USD per device) and large form-factors, hindering its applicability in practical deployment. In this article, we implement SNOW using low-cost, low form-factor, low-power, and widely available commercial off-the-shelf (COTS) devices to enable its practical and large-scale deployment. Our choice of the COTS device (TI CC13x0: CC1310 or CC1350) consequently brings down the cost and form-factor of a SNOW node by 25× and 10×, respectively. Such implementation of SNOW on the CC13x0 devices, however, faces a number of challenges to enable link reliability and communication range. Our implementation addresses these challenges by handling peak-to-average power ratio problem, channel state information estimation, carrier frequency offset estimation, and near-far power problem. Our deployment in the city of Detroit, Michigan, demonstrates that CC13x0-based SNOW can achieve uplink and downlink throughputs of 11.2 and 4.8 kbps per node, respectively, over a distance of 1 km. Also, the overall throughput in the uplink increases linearly with the increase in the number of SNOW nodes.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3162449130",
    "type": "article"
  },
  {
    "title": "A Distributed Real-time Scheduling System for Industrial Wireless Networks",
    "doi": "https://doi.org/10.1145/3464429",
    "publication_date": "2021-07-29",
    "publication_year": 2021,
    "authors": "Venkata P. Modekurthy; Abusayeed Saifullah; Sanjay Madria",
    "corresponding_authors": "",
    "abstract": "The concept of Industry 4.0 introduces the unification of industrial Internet-of-Things (IoT), cyber physical systems, and data-driven business modeling to improve production efficiency of the factories. To ensure high production efficiency, Industry 4.0 requires industrial IoT to be adaptable, scalable, real-time, and reliable. Recent successful industrial wireless standards such as WirelessHART appeared as a feasible approach for such industrial IoT. For reliable and real-time communication in highly unreliable environments, they adopt a high degree of redundancy. While a high degree of redundancy is crucial to real-time control, it causes a huge waste of energy, bandwidth, and time under a centralized approach and are therefore less suitable for scalability and handling network dynamics. To address these challenges, we propose DistributedHART—a distributed real-time scheduling system for WirelessHART networks. The essence of our approach is to adopt local (node-level) scheduling through a time window allocation among the nodes that allows each node to schedule its transmissions using a real-time scheduling policy locally and online. DistributedHART obviates the need of creating and disseminating a central global schedule in our approach, thereby significantly reducing resource usage and enhancing the scalability. To our knowledge, it is the first distributed real-time multi-channel scheduler for WirelessHART. We have implemented DistributedHART and experimented on a 130-node testbed. Our testbed experiments as well as simulations show at least 85% less energy consumption in DistributedHART compared to existing centralized approach while ensuring similar schedulability.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3186184510",
    "type": "article"
  },
  {
    "title": "A distributed timing synchronization technique for parallel multi-core instruction-set simulation",
    "doi": "https://doi.org/10.1145/2435227.2435250",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Meng-Huan Wu; Cheng-Yang Fu; Peng-Chih Wang; Ren‐Song Tsay",
    "corresponding_authors": "",
    "abstract": "As multi-core architecture has become the mainstream, the corresponding multi-core instruction-set simulation (MCISS) is also needed to aid system development. Ideally, we may run a MCISS in parallel to enhance the simulation speed. However, the conventional centralized timing synchronization mechanism would greatly constrain the parallelism of a MCISS, so the simulation speed is bounded. To resolve this issue, we propose a new distributed timing synchronization technique which allows higher parallelism for a MCISS. Hence, it accelerates the simulation speed by 9 to 20 times as the number of cores increases in contrast to the centralized synchronization approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1990339798",
    "type": "article"
  },
  {
    "title": "Computer-Aided Recoding to Create Structured and Analyzable System Models",
    "doi": "https://doi.org/10.1145/2180887.2180900",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Pramod Chandraiah; Rainer Dömer",
    "corresponding_authors": "",
    "abstract": "In embedded system design, the quality of the input model has a direct bearing on the effectiveness of the system exploration and synthesis tools. Given a well-written system model, tools today are effective in generating working implementations. However, readily available C reference code is not conducive for immediate system synthesis as it lacks needed features for automatic analysis and synthesis. Among others, the lack of proper structure and the presence of intractable pointers in the reference code are factors that seriously hamper the effectiveness of system design tools. To overcome these deficiencies, we aim to automate the conversion of flat C code into a well-structured system model by applying automated source code transformations. We present a set of computer-aided recoding operations that enable the system designer to mitigate pointer problems and quickly create the necessary structural hierarchy so that the design model becomes easily analyzable and synthesizable. Utilizing the designer’s knowledge, our interactive recoding transformations aid the designer in efficiently creating well-structured system models for rapid design space exploration and successful synthesis. Our estimated and measured experimental results show significant productivity gains through a substantial reduction of the model creation time.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1991376631",
    "type": "article"
  },
  {
    "title": "Hierarchical Benchmark Circuit Generation for FPGA Architecture Evaluation",
    "doi": "https://doi.org/10.1145/2331147.2331152",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Cindy Mark; Scott Y. L. Chin; Lesley Shannon; Steven J. E. Wilton",
    "corresponding_authors": "",
    "abstract": "We describe a stochastic circuit generator that can be used to automatically create benchmark circuits for use in FPGA architecture studies. The circuits consist of a hierarchy of interconnected modules, reflecting the structure of circuits designed using a system-on-chip design flow. Within each level of hierarchy, modules can be connected in a bus, star, or dataflow configuration. Our circuit generator is calibrated based on a careful study of existing system-on-chip circuits. We show that our benchmark circuits lead to more realistic architectural conclusions than circuits generated using previous generators.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2007959382",
    "type": "article"
  },
  {
    "title": "A software-only scheme for managing heap data on limited local memory(LLM) multicore processors",
    "doi": "https://doi.org/10.1145/2501626.2501632",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Ke Bai; Aviral Shrivastava",
    "corresponding_authors": "",
    "abstract": "This article presents a scheme for managing heap data in the local memory present in each core of a limited local memory (LLM) multicore architecture. Although managing heap data semi-automatically with software cache is feasible, it may require modifications of other thread codes. Crossthread modifications are very difficult to code and debug, and will become more complex and challenging as we increase the number of cores. In this article, we propose an intuitive programming interface, which is an automatic and scalable scheme for heap data management. Besides, for embedded applications, where the maximum heap size can be profiled, we propose several optimizations on our heap management to significantly decrease the library overheads. Our experiments on several benchmarks from MiBench executing on the Sony Playstation 3 show that our scheme is natural to use, and if we know the maximum size of heap data, our optimizations can improve application performance by an average of 14%.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2009667616",
    "type": "article"
  },
  {
    "title": "Register allocation for embedded systems to simultaneously reduce energy and temperature on registers",
    "doi": "https://doi.org/10.1145/2539036.2539046",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Tiantian Liu; Alex Orailoğlu; Chun Jason Xue; Minming Li",
    "corresponding_authors": "",
    "abstract": "Energy and thermal issues are two important concerns for embedded system design. Diminished energy dissipation leads to a longer battery life, while reduced temperature hotspots decelerate the physical failure mechanisms. The instruction fetch logic associated with register access has a significant contribution towards the total energy consumption. Meanwhile, the register file has also been previously shown to exhibit the highest temperature compared to the rest of the components in an embedded processor. Therefore, the optimization of energy and the resolution of the thermal issue for register accesses are of great significance. In this article, register allocation techniques are studied to simultaneously reduce energy consumption and heat buildup on register accesses for embedded systems. Contrary to prevailing intuition, we observe that optimizing energy and optimizing temperature on register accesses conflict with each other. We introduce a rotator hardware in the instruction decoder to facilitate a balanced solution for the two conflicting objectives. Algorithms for register allocation and refinement are proposed based on the access patterns and the effects of the rotator. Experimental results show that the proposed algorithms obtain notable improvements of energy and peak temperature for embedded applications.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2009989495",
    "type": "article"
  },
  {
    "title": "A regression test selection technique for embedded software",
    "doi": "https://doi.org/10.1145/2539036.2539043",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Swarnendu Biswas; Rajib Mall; Manoranjan Satpathy",
    "corresponding_authors": "",
    "abstract": "The current approaches for regression test selection of embedded programs are usually based on data- and control-dependency analyses, often augmented with human reasoning. Existing techniques do not take into account additional execution dependencies which may exist among code elements in such programs due to features such as tasks, task deadlines, task precedences, and intertask communications. In this context, we propose a model-based regression test selection technique for such programs. Our technique first constructs a graph model of the program; the proposed graph model has been designed to capture several characteristics of embedded programs, such as task precedence order, priority, intertask communication, timers, exceptions and interrupt handlers, which we consider important for regression-test selection. Our regression test selection technique selects test cases based on an analysis of the constructed graph model. We have implemented our technique to realize a prototype tool. The experimental results obtained using this tool show that, on average, our approach selects about 28.33% more regression test cases than those selected by a traditional approach. We observed that, on average, 36.36% of the fault-revealing test cases were overlooked by the existing regression test selection technique.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2013428665",
    "type": "article"
  },
  {
    "title": "Moths",
    "doi": "https://doi.org/10.1145/2435227.2435252",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Matthew Misler; Natalie Enright Jerger",
    "corresponding_authors": "",
    "abstract": "As the number of cores integrated on a single chip continues to increase, communication has the potential to become a severe bottleneck to overall system performance. The presence of thread sharing and the distribution of data across cache banks on the chip can result in longdistance communication. Long-distance communication incurs substantial latency that impacts performance; furthermore, this communication consumes significant dynamic power when packets are switched over many Network-on-Chip (NoC) links and routers. Thread migration can mitigate problems created by long distance communication. This article presents Moths, an efficient runtime algorithm that responds automatically to dynamic NoC traffic patterns, providing beneficial thread migration to decrease overall traffic volume and average packet latency. Moths reduces on-chip network latency by up to 28.4% (18.0% on average) and traffic volume by up to 24.9% (20.6% on average) across a variety of commercial and scientific benchmarks.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2013795044",
    "type": "article"
  },
  {
    "title": "Mapping of streaming applications considering alternative application specifications",
    "doi": "https://doi.org/10.1145/2435227.2435230",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Jiali Teddy Zhai; Hristo N. Nikolov; Todor Stefanov",
    "corresponding_authors": "",
    "abstract": "Streaming applications often require a parallel Model of Computation (MoC) to specify their application behavior and to facilitate mapping onto Multi-Processor System-on-Chip (MPSoC) platforms. Various performance requirements and resource budgets of embedded systems ask for an efficient design space exploration (DSE) approach to select the best design from a design space consisting of a large number of design choices. However, existing DSE approaches explore the design space that includes only architecture and mapping alternatives for an initial application specification given by the application designer. In this article, we first show that a design often might not be optimal if alternative specifications of a given application are not taken into account. We further argue that the best alternative specification consists of only independent and load-balanced application tasks. Based on the Polyhedral Process Network (PPN) MoC, we present an approach to analyze and transform an initial PPN to an alternative one that contains only independent processes if possible. Finally, by prototyping real-life applications on both FPGA-based MPSoCs and desktop multi-core platforms, we demonstrate that mapping the alternative application specification results in a large performance gain compared to those approaches, in which alternative application specifications are not taken into account.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2018350985",
    "type": "article"
  },
  {
    "title": "Wireless sensor node localization by multisequence processing",
    "doi": "https://doi.org/10.1145/2146417.2146420",
    "publication_date": "2012-03-01",
    "publication_year": 2012,
    "authors": "Ziguo Zhong; Tian He",
    "corresponding_authors": "",
    "abstract": "Wireless Sensor Networks have been proposed for use in many location-dependent applications. Most of these need to identify the locations of sensor nodes, a challenging task because of severe constraints on cost, energy and effective range of sensor devices. To overcome limitations in existing solutions, we present a Multi-Sequence Positioning (MSP) method for large-scale stationary sensor node localization in outdoor environments. The novel idea behind MSP is to reconstruct and estimate two-dimensional location information for each sensor node by processing multiple one-dimensional node sequences, easily obtained through loosely guided event distribution. Starting from a basic MSP design, we propose four optimizations that work together to increase localization accuracy. We address several interesting issues such as incomplete (partial) node sequences and sequence flip, found in the Mirage test-bed we built. We have evaluated the MSP system through theoretical analysis, extensive simulation as well as two physical systems (an indoor version with 46 MICAz motes and an outdoor version with 20 MICAz motes). Evaluation demonstrates that MSP can achieve an accuracy within one foot, requiring neither additional costly hardware on sensor nodes nor precise event distribution. In fact, it provides a nice tradeoff between physical cost (anchors) and soft cost (events) while maintaining localization accuracy.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2031306189",
    "type": "article"
  },
  {
    "title": "Secure reconfiguration of software-defined radio",
    "doi": "https://doi.org/10.1145/2146417.2146427",
    "publication_date": "2012-03-01",
    "publication_year": 2012,
    "authors": "Chunxiao Li; Niraj K. Jha; Anand Raghunathan",
    "corresponding_authors": "",
    "abstract": "Software-defined radio (SDR) implements a radio system in software that executes on a programmable processor. The components of SDR, such as the filters, amplifiers, and modulators, can be easily reconfigured to adapt to the operating environment and user preferences. However, the flexibility of radio reconfiguration brings along the serious security concern of malicious modification of software in the SDR system, leading to radio malfunction and interference with other users' communications. Both the SDR device and the network need to be protected from such malicious radio reconfiguration. In this article, a new architecture targeted at protecting SDR devices from malicious reconfiguration is proposed. The architecture is based on robust separation of the radio operation environment and user application environment, through the use of virtualization. A new radio middleware layer is designed to securely intercept all attempts to reconfigure the radio, and a security policy monitor checks the target configuration against security policies that represent the interests of various parties. Even if the operating system in the user application environment is compromised, the proposed architecture can ensure secure reconfiguration in the radio operation environment. We have prototyped the proposed secure SDR architecture using VMware and the GNU Radio toolkit and demonstrate that overheads incurred by the architecture are small and tolerable. Therefore, we believe that the proposed solution could be applied to address secure SDR reconfiguration in both general-purpose and embedded computing systems.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2037118327",
    "type": "article"
  },
  {
    "title": "Formal Validation of a Deterministic MAC Protocol",
    "doi": "https://doi.org/10.1145/2406336.2406342",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Karen Godary-Dejean; David Andreu",
    "corresponding_authors": "",
    "abstract": "This article deals with the formal validation of STIMAP, a medium access protocol that has been designed to meet the specific requirements of an implantable network-based neuroprosthesis. This article presents the modeling and the validation of its medium access, using model checking on Time Petri Nets. Doing so, we show that existent formal methods and tools are not perfectly suitable for the validation of real systems, especially when some hardware parameters have to be considered. This article then presents how these difficulties have been managed during the modeling and verification phases, and gives the validation results for STIMAP, providing constraints to respect.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2067767842",
    "type": "article"
  },
  {
    "title": "An analytical approach for fast and accurate design space exploration of instruction caches",
    "doi": "https://doi.org/10.1145/2539036.2539039",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Yun Liang; Tulika Mitra",
    "corresponding_authors": "",
    "abstract": "Application-specific system-on-chip platforms create the opportunity to customize the cache configuration for optimal performance with minimal chip area. Simulation, in particular trace-driven simulation, is widely used to estimate cache hit rates. However, simulation is too slow to be deployed in design space exploration, especially when there are hundreds of design points and the traces are huge. In this article, we propose a novel analytical approach for design space exploration of instruction caches. Given the program control flow graph (CFG) annotated only with basic block and control flow edge execution counts, we first model the cache states at each point of the CFG in a probabilistic manner. Then, we exploit the structural similarities among related cache configurations to estimate the cache hit rates for multiple cache configurations in one pass. Experimental results indicate that our analysis is 28--2,500 times faster compared to the fastest known cache simulator while maintaining high accuracy (0.2% average error) in estimating cache hit rates for a large set of popular benchmarks. Moreover, compared to a state-of-the-art cache design space exploration technique, our approach achieves 304--8,086 times speedup and saves up to 62% (average 7%) energy for the evaluated benchmarks.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2067814886",
    "type": "article"
  },
  {
    "title": "Adaptive real-time scheduling for legacy multimedia applications",
    "doi": "https://doi.org/10.1145/2362336.2362353",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Tommaso Cucinotta; Fabio Checconi; Luca Abeni; Luigi Palopoli",
    "corresponding_authors": "",
    "abstract": "Multimedia applications are often executed on standard personal computers. The absence of established standards has hindered the adoption of real-time scheduling solutions in this class of applications. Developers have adopted a wide range of heuristic approaches to achieve an acceptable timing behavior but the result is often unreliable. We propose a mechanism to extend the benefits of real-time scheduling to legacy applications based on the combination of two techniques: (1) a real-time monitor that observes and infers the activation period of the application, and (2) a feedback mechanism that adapts the scheduling parameters to improve its real-time performance.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2070095654",
    "type": "article"
  },
  {
    "title": "Hot-LSNs distributing wear-leveling algorithm for flash memory",
    "doi": "https://doi.org/10.1145/2435227.2435258",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Se Jin Kwon; Tae‐Sun Chung",
    "corresponding_authors": "",
    "abstract": "Flash memory offers attractive features, such as non-volatile, shock resistance, fast access and low power consumption for data storage. However, it has one main drawback of requiring an erase before updating the contents. Furthermore, the flash memory can only be erased for a limited number of times. These characteristics are controlled by a software layer called the flash translation layer (FTL). FTL efficiently manages read, write, and erase operations to enhance the overall performance, and considers wear-leveling to prolong the durability of flash memory. In this article, we identify the logical sector numbers corresponding to random data, termed as hot-LSNs, and distribute them to all available blocks without degrading the performance of the flash memory. From our evaluation, we found that the extra erase operations for distributing the hot-LSNs are very low compared to the overall performance. Even though Hot-LSNs Distributing Wear-Leveling Algorithm (Hot-DL) incorporates wear-leveling in the performance enhancing algorithm, Hot-DL only requires approximately 0.015% of extra erase operations compared to previous well-optimized performance enhancing algorithms, shared buffer scheme.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2072754850",
    "type": "article"
  },
  {
    "title": "Sequential specification of time-aware stream processing applications",
    "doi": "https://doi.org/10.1145/2435227.2435231",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Stefan J. Geuns; Joost P.H.M. Hausmans; Marco J.G. Bekooij",
    "corresponding_authors": "",
    "abstract": "Automatic parallelization of Nested Loop Programs (NLPs) is an attractive method to create embedded real-time stream processing applications for multi-core systems. However, the description and parallelization of applications with a time dependent functional behavior has not been considered in NLPs. In such a description, semantic information about time dependent behavior must be made available for the compiler, such that an optimized time independent implementation can be generated automatically. This article introduces language constructs with temporal semantics to NLPs. Using these language constructs, time dependent applications can be specified and a corresponding data-driven implementation can be generated for use on a multi-core system. Despite that these time-aware language constructs can be data-dependent, the application remains functionally deterministic. Pipelining is exploited to increase the throughput of an application. The media access control (MAC) protocol of an IEEE 802.11p WLAN transceiver is used to illustrate the relevance and applicability of the introduced concepts.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2095520697",
    "type": "article"
  },
  {
    "title": "ENFFiS",
    "doi": "https://doi.org/10.1145/2423636.2423641",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Sang Oh Park; Sung Jo Kim",
    "corresponding_authors": "",
    "abstract": "Since the typical erase cycle limit of a NAND flash memory's block is about 1,000,000, flash memory should be erased as evenly as possible; otherwise, file system hot spots will soon be worn out. This forces a NAND flash memory file system to scan the whole flash memory during its mount rather than saving frequently updated file system information in a fixed area. Since the mount time linearly increases with the size of NAND flash memory, boot times of embedded systems are also linearly increased. In addition, since data loss may occur if a file system terminates abnormally due to unexpected errors, a stability scheme for NAND flash memory file system is in great demand. To resolve these problems, this article suggests an extended logical block called Exblock (Extended Block) and a table called SNode (Snapshot Node) to reduce the mount time and proposes a new journaling scheme to improve stability for an enhanced file system for NAND flash memory storage called ENFFiS (Enhanced NAND Flash memory File System). It also proposes a new cache policy to improve read/write performances. ENFFiS shows better performance than existing file systems in terms of reading, writing, mount time and stability.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2097825820",
    "type": "article"
  },
  {
    "title": "Hardware-Based Load Value Trace Filtering for On-the-Fly Debugging",
    "doi": "https://doi.org/10.1145/2465787.2465799",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Vladimir Uzelac; Aleksandar Milenković",
    "corresponding_authors": "",
    "abstract": "Capturing program and data traces during program execution unobtrusively on-the-fly is crucial in debugging and testing of cyber-physical systems. However, tracing a complete program unobtrusively is often cost-prohibitive, requiring large on-chip trace buffers and wide trace ports. This article describes a new hardware-based load data value filtering technique called Cache First-access Tracking. Coupled with an effective variable encoding scheme, this technique achieves a significant reduction of load data value traces, from 5.86 to 56.39 times depending on the data cache size, thus enabling cost-effective, unobtrusive on-the-fly tracing and debugging.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2098816443",
    "type": "article"
  },
  {
    "title": "Enabling dynamic binary translation in embedded systems with scratchpad memory",
    "doi": "https://doi.org/10.1145/2362336.2399178",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "José A. Baiocchi; Bruce R. Childers; Jack W. Davidson; Jason D. Hiser",
    "corresponding_authors": "",
    "abstract": "Important challenges for embedded systems can be addressed by dynamic binary translation. A dynamic binary translator stores translated instructions in a software-managed code cache, which is usually large to minimize overhead. This article shows how to use a small scratchpad memory for the code cache. A small code cache may require frequent code evictions and retranslation, which degrade performance. We propose techniques to reduce the number of instructions inserted by the translator and a way to form fragments that minimizes translated code size. With our techniques, a much smaller code cache can hold a program's translated code working set.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2108470968",
    "type": "article"
  },
  {
    "title": "Throughput-memory footprint trade-off in synthesis of streaming software on embedded multiprocessors",
    "doi": "https://doi.org/10.1145/2539036.2539042",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Matin Hashemi; Mohammad H. Foroozannejad; Soheil Ghiasi",
    "corresponding_authors": "",
    "abstract": "We study the trade-off between throughput and memory footprint of embedded software that is synthesized from acyclic static dataflow (task graph) specifications targeting distributed memory multiprocessors. We identify iteration overlapping as a knob in the synthesis process by which one can trade application throughput for its memory requirement. Given an initial processor assignment and non-overlapped task schedule, we formally present underlying properties of the problem, such as constraints on a valid iteration overlapping, maximum possible throughput, and minimum memory footprint. Moreover, we develop an effective algorithm for generation of a rich set of design points that provide a range of trade-off options. Experimental results on a number of applications and architectures validate the effectiveness of our approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2140993136",
    "type": "article"
  },
  {
    "title": "Hardware Architectures for Embedded Speaker Recognition Applications",
    "doi": "https://doi.org/10.1145/2975161",
    "publication_date": "2017-04-28",
    "publication_year": 2017,
    "authors": "Hasna Bouraoui; Chadlia Jerad; Anupam Chattopadhyay; Nejib Ben Hadj-Alouane",
    "corresponding_authors": "",
    "abstract": "Authentication technologies based on biometrics, such as speaker recognition, are attracting more and more interest thanks to the elevated level of security offered by these technologies. Despite offering many advantages, such as remote use and low vulnerability, speaker recognition applications are constrained by the heavy computational effort and the hard real-time constraints. When such applications are run on an embedded platform, the problem becomes more challenging, as additional constraints inherent to this specific domain are added. In the literature, different hardware architectures were used/designed for implementing a process with a focus on a given particular metric. In this article, we give a survey of the state-of-the-art works on implementations of embedded speaker recognition applications. Our aim is to provide an overview of the different approaches dealing with acceleration techniques oriented towards speaker and speech recognition applications and attempt to identify the past, current, and future research trends in the area. Indeed, on the one hand, many flexible solutions were implemented, using either General Purpose Processors or Digital Signal Processors. In general, these types of solutions suffer from low area and energy efficiency. On the other hand, high-performance solutions were implemented on Application Specific Integrated Circuits or Field Programmable Gate Arrays but at the expense of flexibility. Based on the available results, we compare the application requirements vis-à-vis the performance achieved by the systems. This leads to the projection of new research trends that can be undertaken in the future.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2609787633",
    "type": "article"
  },
  {
    "title": "Lock-free synchronization for dynamic embedded real-time systems",
    "doi": "https://doi.org/10.1145/1698772.1698781",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Hyeonjoong Cho; Binoy Ravindran; E. Douglas Jensen",
    "corresponding_authors": "",
    "abstract": "We consider lock-free synchronization for dynamic embedded real-time systems that are subject to resource overloads and arbitrary activity arrivals. We model activity arrival behaviors using the unimodal arbitrary arrival model (or UAM). UAM embodies a stronger “adversary” than most traditional arrival models. We derive an upper bound on lock-free retries under the UAM with utility accrual scheduling—the first such result. We establish the tradeoffs between lock-free and lock-based sharing under UAM. These include conditions under which activities' accrued timeliness utility is greater under lock-free than lock-based, and the consequent lower and upper bound on the total accrued utility that is possible with lock-free and lock-based sharing. We confirm our analytical results with a POSIX RTOS implementation.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2621914487",
    "type": "article"
  },
  {
    "title": "Analyzing the Fault Injection Sensitivity of Secure Embedded Software",
    "doi": "https://doi.org/10.1145/3063311",
    "publication_date": "2017-07-28",
    "publication_year": 2017,
    "authors": "Bilgiday Yuce; Nahid Farhady Ghalaty; Chinmay Deshpande; Harika Santapuri; Conor Patrick; Leyla Nazhandali; Patrick Schaumont",
    "corresponding_authors": "",
    "abstract": "Fault attacks on cryptographic software use faulty ciphertext to reverse engineer the secret encryption key. Although modern fault analysis algorithms are quite efficient, their practical implementation is complicated because of the uncertainty that comes with the fault injection process. First, the intended fault effect may not match the actual fault obtained after fault injection. Second, the logic target of the fault attack, the cryptographic software, is above the abstraction level of physical faults. The resulting uncertainty with respect to the fault effects in the software may degrade the efficiency of the fault attack, resulting in many more trial fault injections than the amount predicted by the theoretical fault attack. In this contribution, we highlight the important role played by the processor microarchitecture in the development of a fault attack. We introduce the microprocessor fault sensitivity model to systematically capture the fault response of a microprocessor pipeline. We also propose Microarchitecture-Aware Fault Injection Attack (MAFIA). MAFIA uses the fault sensitivity model to guide the fault injection and to predict the fault response. We describe two applications for MAFIA. First, we demonstrate a biased fault attack on an unprotected Advanced Encryption Standard (AES) software program executing on a seven-stage pipelined Reduced Instruction Set Computer (RISC) processor. The use of the microprocessor fault sensitivity model to guide the attack leads to an order of magnitude fewer fault injections compared to a traditional, blind fault injection method. Second, MAFIA can be used to break known software countermeasures against fault injection. We demonstrate this by systematically breaking a collection of state-of-the-art software fault countermeasures. These two examples lead to the key conclusion of this work, namely that software fault attacks become much more harmful and effective when an appropriate microprocessor fault sensitivity model is used. This, in turn, highlights the need for better fault countermeasures for software.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2742111403",
    "type": "article"
  },
  {
    "title": "Operating Energy-Neutral Real-Time Systems",
    "doi": "https://doi.org/10.1145/3078631",
    "publication_date": "2017-08-29",
    "publication_year": 2017,
    "authors": "Peter Wägemann; Tobias Distler; Heiko Janker; Phillip Raffeck; Volkmar Sieh; Wolfgang Schröder‐Preikschat",
    "corresponding_authors": "",
    "abstract": "Energy-neutral real-time systems harvest the entire energy they use from their environment. In such systems, energy must be treated as an equally important resource as time, which creates the need to solve a number of problems that so far have not been addressed by traditional real-time systems. In particular, this includes the scheduling of tasks with both time and energy constraints, the monitoring of energy budgets, as well as the survival of blackout periods during which not enough energy is available to keep the system fully operational. In this article, we address these issues presenting E n OS, an operating-system kernel for energy-neutral real-time systems. E n OS considers mixed time criticality levels for different energy criticality modes, which enables a decoupling of time and energy constraints when one is considered less critical than the other. When switching the energy criticality mode, the system also changes the set of executed tasks and is therefore able to dynamically adapt its energy consumption depending on external conditions. By keeping track of the energy budget available, E n OS ensures that in case of a blackout the system state is safely stored to persistent memory, allowing operations to resume at a later point when enough energy is harvested again.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2752320758",
    "type": "article"
  },
  {
    "title": "An Automated Security-Aware Approach for Design of Embedded Systems on MPSoC",
    "doi": "https://doi.org/10.1145/3126553",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Benjamin Tan; Morteza Biglari-Abhari; Zoran Salčić",
    "corresponding_authors": "",
    "abstract": "MPSoC-based embedded systems design is becoming increasingly complex. Not only do we need to satisfy multiple design objectives, we increasingly need to address potential security risks. In this work, we propose a security-aware systematic design approach which explores the design space, given a system-level application description, by generating potential architecture configurations of execution platform nodes that are interconnected using a NoC. We then perform automated security analysis to check the generated configurations against designer-specified security constraints. Following the analysis, we use an automated architecture configuration refinement process to generate a list of security additions that are inserted into the initial configuration so that the security constraints are satisfied. By performing this refinement on several candidate configuration options, we can explore the trade-off between resource cost and security. In this paper, we illustrate the proposed approach using a Smart Home Control System application.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2757076939",
    "type": "article"
  },
  {
    "title": "A Program Interference Error Aware LDPC Scheme for Improving NAND Flash Decoding Performance",
    "doi": "https://doi.org/10.1145/3126563",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Fei Wu; Meng Zhang; Yajuan Du; Xubin He; Ping Huang; Changsheng Xie; Jiguang Wan",
    "corresponding_authors": "",
    "abstract": "By scaling down to smaller cell size, NAND flash has significantly increased the storage capacity in order to lower the unit cost down. However, the reliability is sacrificed due to much higher raw bit error rates. As a result, conventional error correction codes (ECCs), such as BCH codes, are not sufficient. Low-density parity check (LDPC) codes with stronger error correction capability are adopted in NAND flash to guarantee data reliability. However, read performance using LDPC is poor because of its decoding complexity. It has been found that flash cells with fewer electrons are more prone to program interference errors. As a result, program interference errors show the characteristic of value dependence. This characteristic can be exploited and translated into extra information facilitating the decoding convergence. Motivated by this observation, we propose PEAL: a flash &lt;underline&gt;p&lt;/underline&gt;rogram interference &lt;underline&gt;e&lt;/underline&gt;rror &lt;underline&gt;a&lt;/underline&gt;ware &lt;underline&gt;L&lt;/underline&gt;DPC scheme to enhance the decoding performance. PEAL integrates the obtained extra information from the value dependence into the soft-to-hard decision process in LDPC decoding to decrease decoding iterations and improve the decoding convergence speed. Simulation results show that decoding iterations are reduced by up to 69.37% and the decoding convergence speed is improved by up to 2.5×, compared with the normalized min-sum (NMS) algorithm with 2KB information lengths at an approximate raw bit error rate of 11.5 × 10 −3 .",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2757574298",
    "type": "article"
  },
  {
    "title": "FlowPaP and FlowReR",
    "doi": "https://doi.org/10.1145/3126532",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Hao Yan; Lei Jiang; Lide Duan; Wei-Ming Lin; Eugene John",
    "corresponding_authors": "",
    "abstract": "Handheld devices, such as smartphones and tablets, currently dominate the semiconductor market. The memory access patterns of CPU and IP cores are dramatically different in a handheld device, making the main memory a critical bottleneck of the entire system. As a result, non-volatile memories, such as spin transfer torque magnetoresistive random-access memory (STT-MRAM), are emerging as a replacement for the existing DRAM-based main memory, achieving a wide variety of advantages. However, replacing DRAM with STT-MRAM also results in new design challenges including read disturbance. A simple read-and-restore scheme preserves data integrity under read disturbance, but incurs significant performance and energy overheads. Consequently, by utilizing unique characteristics of mobile applications, we propose FlowPaP, a flow pattern prediction scheme to dynamically predict the write-to-last-read distances for data frames running on a handheld device. FlowPaP identifies and removes unnecessary memory restores originally required for preventing read disturbance, significantly improving energy efficiency and performance for STT-MRAM-based handheld devices. In addition, we propose a flow-based data retention time reduction scheme named FlowReR to further lower energy consumption of STT-MRAM at the expense of reducing its data retention time. FlowReR imposes a second step that marginally trades off the already improved energy efficiency for performance improvements. Experimental results show that, compared to the original read-and-restore scheme, the application of FlowPaP and FlowReR together can simultaneously improve energy efficiency by 34% and performance by 17% for a set of commonly used Android applications.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2760264276",
    "type": "article"
  },
  {
    "title": "Managing the Performance/Error Tradeoff of Floating-point Intensive Applications",
    "doi": "https://doi.org/10.1145/3126519",
    "publication_date": "2017-10-10",
    "publication_year": 2017,
    "authors": "Ramy Medhat; Michael O. Lam; Barry Rountree; Borzoo Bonakdarpour; Sebastian Fischmeister",
    "corresponding_authors": "",
    "abstract": "Modern embedded systems are becoming more reliant on real-valued arithmetic as they employ mathematically complex vision algorithms and sensor signal processing. Double-precision floating point is the most commonly used precision in computer vision algorithm implementations. A single-precision floating point can provide a performance boost due to less memory transfers, less cache occupancy, and relatively faster mathematical operations on some architectures. However, adopting it can result in loss of accuracy. Identifying which parts of the program can run in single-precision floating point with low impact on error is a manual and tedious process. In this paper, we propose an automatic approach to identify parts of the program that have a low impact on error using shadow-value analysis. Our approach provides the user with a performance/error tradeoff, using which the user can decide how much accuracy can be sacrificed in return for performance improvement. We illustrate the impact of the approach using a well known implementation of Apriltag detection used in robotics vision. We demonstrate that an average 1.3x speedup can be achieved with no impact on tag detection, and a 1.7x speedup with only 4% false negatives.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2761125724",
    "type": "article"
  },
  {
    "title": "Exploiting Approximate MLC-PCM in Low-Power Embedded Systems",
    "doi": "https://doi.org/10.1145/3105926",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "Mohammad Taghi Teimoori Nodeh; Mostafa Bazzaz; Alireza Ejlali",
    "corresponding_authors": "",
    "abstract": "Multi-level cell phase change memory (MLC-PCM), because of its very low leakage power and high density, is promising for embedded systems. Furthermore, for applications with inherent low sensitivity to errors, approximate write operations can be exploited in MLC-PCM to improve endurance and performance. However, data that reside in the approximate MLC-PCM for a rather long time without refreshing are prone to soft errors due to resistance drift phenomenon, while even for an application with inherent low sensitivity to errors, a high soft error rate can degrade its Quality of Result (QoR). The architecture-level approaches to decrease the drift effect incur considerable power overhead (about 100%), which is a prominent issue in embedded systems, and are dependent on the number of logic levels stored in the PCM cell (e.g., most of them are designed for 4LC-PCM). This article, taking a different approach, proposes a drift-aware frequency and voltage management to alleviate the drift-based soft-error rate. To this end, first we characterize the application data based on the degree of being exposed to the drift to identify the drift-prone application data. Then we assign the execution frequency and voltage to different regions of the application considering the drift. This frequency assignment speeds up the application regions wherein the drift-prone data are accessed to shorten the lifetime of the drift-prone data, thereby decreasing the soft error rate. An integer linear programming model implements our proposed Dynamic Voltage Frequency Scaling (DVFS). Also, the proposed approach is independent of the number of levels of PCM cells and can be applied to any MLC-PCM system. To evaluate the approach, the approximate MLC-PCM is simulated using empirical models and is integrated into a full-system simulator as data memory. The experimental results show that, by exploiting the approach, QoR is in the acceptable range, while its power overhead is about 84% (on average) less than that of the architecture-level approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2771761612",
    "type": "article"
  },
  {
    "title": "Design and evaluation of random linear network coding Accelerators on FPGAs",
    "doi": "https://doi.org/10.1145/2501626.2512469",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Sunwoo Kim; Won Seob Jeong; Won Woo Ro; Jean‐Luc Gaudiot",
    "corresponding_authors": "",
    "abstract": "Network coding is a well-known technique used to enhance network throughput and reliability by applying special coding to data packets. One critical problem in practice, when using the random linear network coding technique, is the high computational overhead. More specifically, using this technique in embedded systems with low computational power might cause serious delays due to the complex Galois field operations and matrix handling. To this end, this article proposes a high-performance decoding logic for random linear network coding using field-programmable gate-array (FPGA) technology. We expect that the inherent reconfigurability of FPGAs will provide sufficient performance as well as programmability to cope with changes in the specification of the coding. The main design motivation was to improve the decoding delay by dividing and parallelizing the entire decoding process. Fast arithmetic operations are achieved by the proposed parallelized GF ALUs, which allow calculations with all the elements of a single row of a matrix to be performed concurrently. To improve the flexibility in the utilization of the FPGA components, two different decoding methods have been designed and compared. The performance of the proposed idea is evaluated by comparing with the performance of the decoding process executed by general-purpose processors through an equivalent software algorithm. Overall, a maximum throughput of 65.98 Mbps is achieved with the proposed FPGA design on an XC5VLX110T Virtex 5 device. In addition, the proposed design provides speedups of up to 13.84 compared to an aggressively parallelized software decoding algorithm run on a quad-core AMD processor. Moreover, the design affords 12 times higher power efficiency in terms of throughput per watt than an ARM Coretex-A9 processor.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4245043121",
    "type": "article"
  },
  {
    "title": "ACDC",
    "doi": "https://doi.org/10.1145/2677093",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Juan Segarra; Clemente Rodríguez; Rubén Gran Tejero; Luis Aparicio; Víctor Viñals",
    "corresponding_authors": "",
    "abstract": "In multitasking real-time systems, the worst-case execution time (WCET) of each task and also the effects of interferences between tasks in the worst-case scenario need to be calculated. This is especially complex in the presence of data caches. In this article, we propose a small instruction-driven data cache (256 bytes) that effectively exploits locality. It works by preselecting a subset of memory instructions that will have data cache replacement permission. Selection of such instructions is based on data reuse theory. Since each selected memory instruction replaces its own data cache line, it prevents pollution and performance in tasks becomes independent of the size of the associated data structures. We have modeled several memory configurations using the Lock-MS WCET analysis method. Our results show that, on average, our data cache effectively services 88% of program data of the tested benchmarks. Such results double the worst-case performance of our tested multitasking experiments. In addition, in the worst case, they reach between 75% and 89% of the ideal case of always hitting in instruction and data caches. As well, we show that using partitioning on our proposed hardware only provides marginal benefits in worst-case performance, so using partitioning is discouraged. Finally, we study the viability of our proposal in the MiBench application suite by characterizing its data reuse, achieving hit ratios beyond 90% in most programs.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1982802967",
    "type": "article"
  },
  {
    "title": "Temperature-Aware Data Allocation for Embedded Systems with Cache and Scratchpad Memory",
    "doi": "https://doi.org/10.1145/2629650",
    "publication_date": "2015-03-09",
    "publication_year": 2015,
    "authors": "Zhiping Jia; Yang Li; Yi Wang; Meng Wang; Zili Shao",
    "corresponding_authors": "",
    "abstract": "The hybrid memory architecture that contains both on-chip cache and scratchpad memory (SPM) has been widely used in embedded systems. In this article, we explore this hybrid memory architecture by jointly optimizing time performance and temperature for embedded systems with loops. Our basic idea is to adaptively adjust the workload distribution between cache and SPM based on the current temperature. For a problem in which the workload can be estimated a priori, we present a nonlinear programming formulation to optimally minimize the total execution time of a loop under the constraints of SPM size and temperature. To solve a problem in which the workload is not known a priori, we propose a temperature-aware adaptive loop scheduling algorithm called TALS to dynamically allocate data to cache and SPM at runtime. The experimental results show that our algorithms can effectively achieve both performance and temperature optimization for embedded systems with cache and SPM.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1985057894",
    "type": "article"
  },
  {
    "title": "Multicopy Cache",
    "doi": "https://doi.org/10.1145/2632162",
    "publication_date": "2014-07-23",
    "publication_year": 2014,
    "authors": "Arup Chakraborty; Houman Homayoun; Amin Khajeh; Nikil Dutt; Ahmed M. Eltawil; Fadi Kurdahi",
    "corresponding_authors": "",
    "abstract": "Caches are known to consume a large part of total microprocessor energy. Traditionally, voltage scaling has been used to reduce both dynamic and leakage power in caches. However, aggressive voltage reduction causes process-variation-induced failures in cache SRAM arrays, thus compromising cache reliability. We present MultiCopy Cache (MC 2 ), a new cache architecture that achieves significant reduction in energy consumption through aggressive voltage scaling while maintaining high error resilience (reliability) by exploiting multiple copies of each data item in the cache. Unlike many previous approaches, MC 2 does not require any error map characterization and therefore is responsive to changing operating conditions (e.g., Vdd noise, temperature, and leakage) of the cache. MC 2 also incurs significantly lower overheads compared to other ECC-based caches. Our experimental results on embedded benchmarks demonstrate that MC 2 achieves up to 60% reduction in energy and energy-delay product (EDP) with only 3.5% reduction in IPC and no appreciable area overhead.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1989114188",
    "type": "article"
  },
  {
    "title": "On-chip traffic regulation to reduce coherence protocol cost on a microthreaded many-core architecture with distributed caches",
    "doi": "https://doi.org/10.1145/2567931",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Qiang Yang; Jian Fu; Raphaël Poss; Chris Jesshope",
    "corresponding_authors": "",
    "abstract": "When hardware cache coherence scales to many cores on chip, over saturated traffic of the shared memory system may offset the benefit from massive hardware concurrency. In this article, we investigate the cost of a write-update protocol in terms of on-chip memory network traffic and its adverse effects on the system performance based on a multithreaded many-core architecture with distributed caches. We discuss possible software and hardware solutions to alleviate the network pressure. We find that in the context of massive concurrency, by introducing a write-merging buffer with 0.46% area overhead to each core, applications with good locality and concurrency are boosted up by 18.74% in performance on average. Other applications also benefit from this addition and even achieve a throughput increase of 5.93%. In addition, this improvement indicates that higher levels of concurrency per core can be exploited without impacting performance, thus tolerating latency better and giving higher processor efficiencies compared to other solutions.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1989353530",
    "type": "article"
  },
  {
    "title": "System-Level Performance and Power Optimization for MPSoC",
    "doi": "https://doi.org/10.1145/2656339",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Ye-Jyun Lin; Chia-Lin Yang; Jiao-We Huang; Tay–Jyi Lin; Chih-Wen Hsueh; Naehyuck Chang",
    "corresponding_authors": "",
    "abstract": "As the number of IPs in a multimedia Multi-Processor System-on-Chip (MPSoC) continues to increase, concurrent memory accesses from different IPs increasingly stress memory systems, which presents both opportunities and challenges for future MPSoC design. The impact of such requirements on the system-level design for MPSoC is twofold. First, contention among IPs prolongs memory access time, which exacerbates the persisting memory wall problem. Second, longer memory accesses lead to longer IP stall time, which results in unnecessary leakage waste. In this article, we propose two memory access-aware system-level design approaches for performance and leakage optimization. To alleviate the memory wall problem, we propose a Hierarchical Memory Scheduling (HMS) policy that schedules memory requests from the same IP and application consecutively to reduce interference among memory accesses from different IPs with a fairness guarantee. To reduce IP leakage waste due to long memory access, we propose a memory access-aware power-gating policy. A straightforward power-gating approach is to power gate an IP when it needs to fetch data from memory. However, due to the response time variation among memory accesses, aggressively power gating an IP whenever a memory request occurs may result in incorrect power-gating decisions. The proposed memory access-aware power-gating policy makes these decisions judiciously, based on the predicted memory latency of an individual IP and its energy breakeven time. The experimental results show that the proposed HMS memory scheduling policy improves system throughput by 42% compared to First-Come-First-Serve (FCFS) and by 21% compared to First-Ready First-Come-First-Serve (FR-FCFS) on an MPSoC for mobile phones. For the improvement of fairness, HMS improves fairness by 1.52× compared to FCFS and by 1.23× compared to FRFCFS. In the aspect of leakage optimization, our memory access-aware power-gating mechanism improves energy savings by 3.88× and reduces the performance penalty by 70% compared to conventional timeout-based power gating. We further demonstrate that our HMS memory scheduler can regulate memory access orders, thereby reducing memory response time variation. This leads to more accurate power-down decisions for both conventional timeout power gating and the proposed memory access- aware power gating.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2002364347",
    "type": "article"
  },
  {
    "title": "Monitoring massive appliances by a minimal number of smart meters",
    "doi": "https://doi.org/10.1145/2544375.2544376",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Yongcai Wang; Xiaohong Hao; Lei Song; Chenye Wu; Yuexuan Wang; Changjian Hu; Lu Yu",
    "corresponding_authors": "",
    "abstract": "This article presents a framework for deploying a minimal number of smart meters to accurately track the ON/OFF states of a massive number of electrical appliances which exploits the sparseness feature of simultaneous ON/OFF switching events of the massive appliances. A theoretical bound on the least number of required smart meters is studied by an entropy-based approach, which qualifies the impact of meter deployment strategies to the state tracking accuracy. It motivates a meter deployment optimization algorithm (MDOP) to minimize the number of meters while satisfying given requirements to state tracking accuracy. To accurately decode the real-time ON/OFF states of appliances by the readings of meters, a fast state decoding (FSD) algorithm based on the hidden Markov model (HMM) is presented to track the state sequence of each appliance for better accuracy. Although traditional HMM needs O ( t 2 2 N ) time complexity to conduct online sequence decoding, FSD improves the complexity to O ( tn U+1 ), where n &lt; N and U is an upper bound of the simultaneous switching events. Both MDOP and FSD are verified extensively using simulations and real PowerNet data. The results show that the meter deployment cost can be saved by more than 80% while still getting over 90% state tracking accuracy.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2006740054",
    "type": "article"
  },
  {
    "title": "Parametrised Modal Interface Automata",
    "doi": "https://doi.org/10.1145/2776892",
    "publication_date": "2015-09-09",
    "publication_year": 2015,
    "authors": "Antti Siirtola; Keijo Heljanko",
    "corresponding_authors": "",
    "abstract": "Interface theories (ITs) enable us to analyse the compatibility interfaces and refine them while preserving their compatibility. However, most ITs are for finite state interfaces, whereas computing systems are often parametrised involving components, the number of which cannot be fixed. We present, to our knowledge, the first IT that allows us to specify a parametric number of interfaces. Moreover, we provide a fully algorithmic procedure, implemented in a tool, for checking the compatibility of and refinement between parametrised interfaces. Finally, we show that the restrictions of the technique are necessary; removing any of them renders the refinement checking problem undecidable.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2037776515",
    "type": "article"
  },
  {
    "title": "The Psi-Calculi Workbench",
    "doi": "https://doi.org/10.1145/2682570",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Johannes Borgström; Ramūnas Gutkovas; Ioana Rodhe; Björn Victor",
    "corresponding_authors": "",
    "abstract": "Psi-calculi is a parametric framework for extensions of the pi-calculus with arbitrary data and logic. All instances of the framework inherit machine-checked proofs of the metatheory such as compositionality and bisimulation congruence. We present a generic analysis tool for psi-calculus instances, enabling symbolic execution and (bi)simulation checking for both unicast and broadcast communication. The tool also provides a library for implementing new psi-calculus instances. We provide examples from traditional communication protocols and wireless sensor networks. We also describe the theoretical foundations of the tool, including an improved symbolic operational semantics, with additional support for scoped broadcast communication.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2038139036",
    "type": "article"
  },
  {
    "title": "On the Verification of Concurrent, Asynchronous Programs with Waiting Queues",
    "doi": "https://doi.org/10.1145/2700072",
    "publication_date": "2015-04-30",
    "publication_year": 2015,
    "authors": "Gilles Geeraerts; Alexander Heußner; Jean-François Raskin",
    "corresponding_authors": "",
    "abstract": "Recently, new libraries, such as Grand Central Dispatch (GCD), have been proposed to directly harness the power of multicore platforms and to make the development of concurrent software more accessible to software engineers. When using such a library, the programmer writes so-called blocks , which are chunks of code, and dispatches them using synchronous or asynchronous calls to several types of waiting queues. A scheduler is then responsible for dispatching those blocks among the available cores. Blocks can synchronize via a global memory. In this article, we propose Queue-Dispatch Asynchronous Systems as a mathematical model that faithfully formalizes the synchronization mechanisms and behavior of the scheduler in those systems. We study in detail their relationships to classical formalisms such as pushdown systems, Petri nets, F ifo systems, and counter systems. Our main technical contributions are precise worst-case complexity results for the Parikh coverability problem and the termination problem for several subclasses of our model. We also consider an extension of Q das with a fork-join mechanism. Adding fork-join to any of the subclasses that we have identified leads to undecidability of the coverability problem. This motivates the study of over-approximations. Finally, we consider handmade abstractions as a practical way of verifying programs that cannot be faithfully modeled by decidable subclasses of Q das .",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2073157156",
    "type": "article"
  },
  {
    "title": "Runtime Optimization of System Utility with Variable Hardware",
    "doi": "https://doi.org/10.1145/2656338",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Paul Martin; Lucas Wanner; Mani Srivastava",
    "corresponding_authors": "",
    "abstract": "Increasing hardware variability in newer integrated circuit fabrication technologies has caused corresponding power variations on a large scale. These variations are particularly exaggerated for idle power consumption, motivating the need to mitigate the effects of variability in systems whose operation is dominated by long idle states with periodic active states. In systems where computation is severely limited by anemic energy reserves and where a long overall system lifetime is desired, maximizing the quality of a given application subject to these constraints is both challenging and an important step toward achieving high-quality deployments. This work describes VaRTOS, an architecture and corresponding set of operating system abstractions that provide explicit treatment of both idle and active power variations for tasks running in real-time operating systems. Tasks in VaRTOS express elasticity by exposing individual knobs —shared variables that the operating system can tune to adjust task quality and, correspondingly, task power, maximizing application utility both on a per-task and on a system-wide basis. We provide results regarding online learning of instance-specific sleep power, active power, and task-level power expenditure on simulated hardware with demonstrated effects for several prototypical applications. Our results on networked sensing applications, which are representative of a broader category of applications that VaRTOS targets, show that VaRTOS can reduce variability-induced energy expenditure errors from over 70% in many cases to under 2% in most cases and under 5% in the worst case.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2132952046",
    "type": "article"
  },
  {
    "title": "Exploring Energy Scalability in Coprocessor-Dominated Architectures for Dark Silicon",
    "doi": "https://doi.org/10.1145/2584657",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Qiaoshi Zheng; Nathan Goulding-Hotta; Scott Ricketts; Steven Swanson; Michael Taylor; Jack Sampson",
    "corresponding_authors": "",
    "abstract": "As chip designers face the prospect of increasingly dark silicon, there is increased interest in incorporating energy-efficient specialized coprocessors into general-purpose designs. For specialization to be a viable means of leveraging dark silicon, it must provide energy savings over the majority of execution for large, diverse workloads, and this will require deploying coprocessors in large numbers. Recent work has shown that automatically generated application-specific coprocessors can greatly improve energy efficiency, but it is not clear that current techniques will scale to Coprocessor-Dominated Architectures ( CoDAs ) with hundreds or thousands of coprocessors. We show that scaling CoDAs to include very large numbers of coprocessors is challenging because of the energy cost of interconnects, the memory system, and leakage. These overheads grow with the number of coprocessors and, left unchecked, will squander the energy gains that coprocessors can provide. The article presents a detailed study of energy costs across a wide range of tiled CoDA designs and shows that careful choice of cache configuration, tile size, coarse-grain power management and transistor implementation can limit the growth of these overheads. For multithreaded workloads, designer must also take care to avoid excessive contention for coprocessors, which can significantly increase energy consumption. The results suggest that, for CoDAs that target larger workloads, amortizing shared overheads via multithreading can provide up to 3.8× reductions in energy per instruction, retaining much of the 5.3× potential of smaller designs.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2134314050",
    "type": "article"
  },
  {
    "title": "Parallelizing the Chambolle Algorithm for Performance-Optimized Mapping on FPGA Devices",
    "doi": "https://doi.org/10.1145/2851497",
    "publication_date": "2016-03-07",
    "publication_year": 2016,
    "authors": "Ivan Beretta; Vincenzo Rana; Abdulkadir Akın; Alessandro Antonio Nacci; Donatella Sciuto; David Atienza",
    "corresponding_authors": "",
    "abstract": "The performance and the efficiency of recent computing platforms have been deeply influenced by the widespread adoption of hardware accelerators, such as graphics processing units (GPUs) or field-programmable gate arrays (FPGAs), which are often employed to support the tasks of general-purpose processors (GPPs). One of the main advantages of these accelerators over their sequential counterparts (GPPs) is their ability to perform massive parallel computation. However, to exploit this competitive edge, it is necessary to extract the parallelism from the target algorithm to be executed, which generally is a very challenging task. This concept is demonstrated, for instance, by the poor performance achieved on relevant multimedia algorithms, such as Chambolle, which is a well-known algorithm employed for the optical flow estimation. The implementations of this algorithm that can be found in the state of the art are generally based on GPUs but barely improve the performance that can be obtained with a powerful GPP. In this article, we propose a novel approach to extract the parallelism from computation-intensive multimedia algorithms, which includes an analysis of their dependency schema and an assessment of their data reuse. We then perform a thorough analysis of the Chambolle algorithm, providing a formal proof of its inner data dependencies and locality properties. Then, we exploit the considerations drawn from this analysis by proposing an architectural template that takes advantage of the fine-grained parallelism of FPGA devices. Moreover, since the proposed template can be instantiated with different parameters, we also propose a design metric, the expansion rate, to help the designer in the estimation of the efficiency and performance of the different instances, making it possible to select the right one before the implementation phase. We finally show, by means of experimental results, how the proposed analysis and parallelization approach leads to the design of efficient and high-performance FPGA-based implementations that are orders of magnitude faster than the state-of-the-art ones.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2175508282",
    "type": "article"
  },
  {
    "title": "A Cache-Based Flash Translation Layer for TLC-Based Multimedia Storage Devices",
    "doi": "https://doi.org/10.1145/2820614",
    "publication_date": "2016-01-13",
    "publication_year": 2016,
    "authors": "Se Jin Kwon",
    "corresponding_authors": "Se Jin Kwon",
    "abstract": "Current triple-level cell (TLC)-based solids-tate drives used in multimedia storage devices support multichannel access to increase capacity and throughput. Unfortunately, current state-of-the-art FTL algorithms must employ selective caching for inquiring about the address mapping information, which causes low space utilization, a large flash memory requirement, and performance degradation. In this article, the &lt;u&gt;Ca&lt;/u&gt; che- &lt;u&gt;b&lt;/u&gt; ased Flash Translation Layer (Cab-FTL) is proposed for TLC-based multimedia storage devices. Cab-FTL enhances the read and write performances by achieving high space utilization while reducing the size of the mapping tables to 1.68% compared to DFTL. Despite a caching of the mapping tables in DRAM, Cab-FTL achieves a fast system boot using its fast wake-up mechanism.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2235274889",
    "type": "article"
  },
  {
    "title": "UPDATE",
    "doi": "https://doi.org/10.1145/2889489",
    "publication_date": "2016-03-07",
    "publication_year": 2016,
    "authors": "Yichuan Wang; Xin Liu; Cheng-Hsin Hsu",
    "corresponding_authors": "",
    "abstract": "Existing channel-aware scheduling work has mainly focused on scheduling in small timescales, that is, tens to hundreds of seconds. We propose to use long-term user profiles to provide useful statistical information on future network conditions in large timescales. We design scheduling algorithms based on Markov decision theory. We collect and use a large set of real-life traces from the general public. Extensive trace-driven evaluations show that many real mobile users can benefit from our framework. In addition, we compare our framework against state-of-the-art algorithms and observe significant performance differences because the existing algorithms were not designed for the large timescale scenario.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2294469682",
    "type": "article"
  },
  {
    "title": "An Integrated Exploration and Virtual Platform Framework for Many-Accelerator Heterogeneous Systems",
    "doi": "https://doi.org/10.1145/2866578",
    "publication_date": "2016-03-18",
    "publication_year": 2016,
    "authors": "Efstathios Sotiriou-Xanthopoulos; Sotirios Xydis; Kostas Siozios; George Economakos; Dimitrios Soudris",
    "corresponding_authors": "",
    "abstract": "The recent advent of many-accelerator systems-on-chip (SoC), driven by the need for maximizing throughput and power efficiency, has led to an exponential increase in the hardware/software co-design complexity. The reason of this increase is that the designer has to explore a vast number of architectural parameter combinations for each single accelerator, as well as inter-accelerator configuration combinations under specific area, throughput, and power constraints, given that each accelerator has different computational requirements. In such a case, the design space size explodes. Thus, existing design space exploration (DSE) techniques give poor-quality solutions, as the design space cannot be adequately covered in a fair time. This problem is aggravated by the very long simulation time of the many-accelerator virtual platforms (VPs). This article addresses these design issues by (a) presenting a virtual prototyping solution that decreases the exploration time by enabling the evaluation of multiple configurations per VP simulation and (b) proposing a DSE methodology that efficiently explores the design space of many-accelerator systems. With the use of two fully developed use cases, namely an H.264 decoding server for multiple video streams and a parallelized denoising system for MRI scans, we show that the proposed DSE methodology either leads to Pareto points that dominate over those of a typical DSE scenario or finds new solutions that might not be found by the typical DSE. In addition, the proposed virtual prototyping solution leads to DSE runtime reduction reaching 10 × for H.264 and 5 × for Rician denoise.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2309189702",
    "type": "article"
  },
  {
    "title": "Cross-Layer Opportunistic Scheduling for Device-to-Device Video Multicast Services",
    "doi": "https://doi.org/10.1145/2856034",
    "publication_date": "2016-02-26",
    "publication_year": 2016,
    "authors": "Wen Ji; Bo‐Wei Chen; Xiangdong Wang; Haiyong Luo; Mucheol Kim; Yiqiang Chen",
    "corresponding_authors": "",
    "abstract": "In this article, we address the problem of how to make the wireless device-to-device (D2D) video multicast systems have better quality provision with consideration of internet-of-things (IoT) applications. We propose an opportunistic transmission and fair resource allocation framework, including joint application-layer and physical-layer transmission and optimization. First, we use a parallel subchannels structure by concatenating the Fountain codes and diversity-embedded space-time block codes to provide reliable and flexible transmission in heterogeneous circumstances. Second, we exploit the quality of heterogeneous user experience (quality of experience) metric under D2D video multicast systems, with consideration of various channel states, device capability, video content urgency, and the number of demanding users. Third, we formulate reliable multiple video streams broadcasting to heterogeneous devices as an aggregate maximum utility achieving problem, and we use opportunistic scheduling to select suitable users in each transmission interval to improve the broadcasting utility. Fourth, we use the utility fair scheme to guide rate allocation among multicontent video multicast. Extensive performance comparison and analysis are presented to demonstrate efficiency of the proposed solution.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2325386712",
    "type": "article"
  },
  {
    "title": "Vector Coprocessor Virtualization for Simultaneous Multithreading",
    "doi": "https://doi.org/10.1145/2898364",
    "publication_date": "2016-05-23",
    "publication_year": 2016,
    "authors": "Yaojie Lu; SeyedAmin Rooholamin; Sotirios G. Ziavras",
    "corresponding_authors": "",
    "abstract": "Vector coprocessors (VPs), commonly being assigned exclusively to a single thread/core, are not often performance and energy efficient due to mismatches with the vector needs of individual applications. We present in this article an easy-to-implement VP virtualization technique that, when applied, enables a multithreaded VP to simultaneously execute multiple threads of similar or arbitrary vector lengths to achieve improved aggregate utilization. With a vector register file (VRF) virtualization technique invented to dynamically allocate physical vector registers to threads, our VP virtualization approach improves programmer productivity by providing at runtime a distinct physical register name space to each competing thread, thus eliminating the need to solve register-name conflicts statically. We applied our virtualization technique to a multithreaded VP and prototyped an FPGA-based multicore processor system that supports VP sharing as well as power gating for better energy efficiency. Under the dynamic creation of disparate threads, our benchmarking results show impressive VP speedups of up to 333% and total energy savings of up to 37% with proper thread scheduling and power gating compared to a similar-sized system that allows VP access to just one thread at a time.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2405227380",
    "type": "article"
  },
  {
    "title": "Reducing Power Consumption and Latency in Mobile Devices Using an Event Stream Model",
    "doi": "https://doi.org/10.1145/2964203",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Stephen Marz; Brad Vander Zanden",
    "corresponding_authors": "",
    "abstract": "Most consumer-based mobile devices use asynchronous events to awaken apps. Currently, event handling is implemented in either an application or an application framework such as Java’s virtual machine (VM) or Microsoft’s .NET, and it uses a “polling loop” that periodically queries an event queue to determine if an event has occurred. These loops must awaken the process, check for an event, and then put the process back to sleep many times per second. This constant arousal prevents the CPU from being put into a deep sleep state, which increases power consumption. Additionally, the process cannot check for events while it sleeps, and this delay in handling events increases latency, which is the time that elapses between when an event occurs and when the application responds to the event. We call this model of event handling a “pull” model because it needs to query hardware devices or software queues in order to “pull” events from them. Recent advances in input devices support direct, informative interrupts to the kernel when an event occurs. This allows us to develop a much more efficient event-handling model called the “Event Stream Model” (ESM). This model is a push model that allows a process to sleep as long as no event occurs but then immediately awakens a process when an event occurs. This model eliminates the polling loop, thus eliminating latency-inducing sleep between polls and reducing unnecessary power consumption. To work properly, the ESM model must be implemented in the kernel rather than in the application. In this article, we describe how we implemented the ESM model in Android operating system (OS). Our results show that with the event stream model, power consumption is reduced by up to 23.8% in certain circumstances, and latency is reduced by an average of 13.6ms.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2531288672",
    "type": "article"
  },
  {
    "title": "Reduction in the Number of Fault Injections for Blind Fault Attack on SPN Block Ciphers",
    "doi": "https://doi.org/10.1145/3014583",
    "publication_date": "2016-12-19",
    "publication_year": 2016,
    "authors": "Yang Li; Mengting Chen; Zhe Liu; Jian Wang",
    "corresponding_authors": "",
    "abstract": "In 2014, a new fault analysis called blind fault attack (BFA) was proposed, in which attackers can only obtain the number of different faulty outputs without knowing the public data. The original BFA requires 480,000 fault injections to recover a 128-bit AES key. This work attempts to reduce the number of fault injections under the same attack assumptions. We analyze BFA from an information theoretical perspective and introduce a new probability-based distinguisher. Three approaches are proposed for different attack scenarios. The best one realized a 66.8% reduction of the number of fault injections on AES.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2564266410",
    "type": "article"
  },
  {
    "title": "Embedded Device Forensics and Security",
    "doi": "https://doi.org/10.1145/3015662",
    "publication_date": "2016-12-12",
    "publication_year": 2016,
    "authors": "Kim‐Kwang Raymond Choo; Yunsi Fei; Yang Xiang; Yu Yu",
    "corresponding_authors": "",
    "abstract": "While the increasing digitalization of our society and amalgamation of embedded devices into the ever-increasing facets of our daily life (e.g., in smart and intelligent vehicles, smart cities and smart nations, and critical infrastructure sectors) have resulted in improved productivity and quality of life, the trend has also resulted in a trend of increasing frequency and sophistication of cyber exploitation and cyber threats. Hence, there is a need for coordinated efforts from the research community to address resulting concerns using both cryptographic and non-cryptographic solutions, such as those presented in this special section.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2566170645",
    "type": "article"
  },
  {
    "title": "A Scalable Algebraic Method to Infer Quadratic Invariants of Switched Systems",
    "doi": "https://doi.org/10.1145/2932187",
    "publication_date": "2016-09-01",
    "publication_year": 2016,
    "authors": "Xavier Allamigeon; Stéphane Gaubert; Nikolas Stott; Éric Goubault; Sylvie Putot",
    "corresponding_authors": "",
    "abstract": "We present a new numerical abstract domain based on ellipsoids designed for the formal verification of switched linear systems. Unlike the existing approaches, this domain does not rely on a user-given template. We overcome the difficulty that ellipsoids do not have a lattice structure by exhibiting a canonical operator overapproximating the union. This operator is the only one that permits the performance of analyses that are invariant with respect to a linear transformation of state variables. It provides the minimum volume ellipsoid enclosing two given ellipsoids. We show that it can be computed in O ( n 3 ) elementary algebraic operations. We finally develop a fast nonlinear power-type algorithm, which allows one to determine sound quadratic invariants on switched systems in a tractable way, by solving fixed-point problems over the space of ellipsoids. We test our approach on several benchmarks, and compare it with the standard techniques based on linear matrix inequalities, showing an important speedup on typical instances.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2620844074",
    "type": "article"
  },
  {
    "title": "MaPHeA: A Framework for Lightweight Memory Hierarchy-aware Profile-guided Heap Allocation",
    "doi": "https://doi.org/10.1145/3527853",
    "publication_date": "2022-03-31",
    "publication_year": 2022,
    "authors": "Deok-Jae Oh; Yaebin Moon; Do Kyu Ham; Tae Jun Ham; Yongjun Park; Jae W. Lee; Jung Ho Ahn; Eojin Lee",
    "corresponding_authors": "",
    "abstract": "Hardware performance monitoring units (PMUs) are a standard feature in modern microprocessors, providing a rich set of microarchitectural event samplers. Recently, numerous profile-guided optimization (PGO) frameworks have exploited them to feature much lower profiling overhead compared to conventional instrumentation-based frameworks. However, existing PGO frameworks mainly focus on optimizing the layout of binaries; they overlook rich information provided by the PMU about data access behaviors over the memory hierarchy. Thus, we propose MaPHeA, a lightweight M emory hierarchy- a ware P rofile-guided He ap A llocation framework applicable to both HPC and embedded systems. MaPHeA guides and applies the optimized allocation of dynamically allocated heap objects with very low profiling overhead and without additional user intervention to improve application performance. To demonstrate the effectiveness of MaPHeA, we apply it to optimizing heap object allocation in an emerging DRAM-NVM heterogeneous memory system (HMS), selective huge-page utilization, and controlling the cacheability of the objects with the low temporal locality. In an HMS, by identifying and placing frequently accessed heap objects to the fast DRAM region, MaPHeA improves the performance of memory-intensive graph-processing and Redis workloads by 56.0% on average over the default configuration that uses DRAM as a hardware-managed cache of slow NVM. By identifying large heap objects that cause frequent TLB misses and allocating them to huge pages, MaPHeA increases the performance of the read and update operations of Redis by 10.6% over the transparent huge-page implementation of Linux. Also, by distinguishing the objects that cause cache pollution due to their low temporal locality and applying write-combining to them, MaPHeA improves the performance of STREAM and RADIX workloads by 20.0% on average over the system without cacheability control.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4220665001",
    "type": "article"
  },
  {
    "title": "How Flexible is Your Computing System?",
    "doi": "https://doi.org/10.1145/3524861",
    "publication_date": "2022-03-30",
    "publication_year": 2022,
    "authors": "Shihua Huang; Luc Waeijen; Henk Corporaal",
    "corresponding_authors": "",
    "abstract": "In literature, computer architectures are frequently claimed to be highly flexible , typically implying the existence of trade-offs between flexibility and performance or energy efficiency. Processor flexibility, however, is not very sharply defined, and consequently these claims cannot be validated, nor can such hypothetical relations be fully understood and exploited in the design of computing systems. This paper is an attempt to introduce scientific rigour to the notion of flexibility in computing systems. A survey is conducted to provide an overview of references to flexibility in literature, both in the computer architecture domain, as well as related fields. A classification is introduced to categorize different views on flexibility, which ultimately form the foundation for a qualitative definition of flexibility. Departing from the qualitative definition of flexibility, a generic quantifiable metric is proposed, enabling valid quantitative comparison of the flexibility of various architectures. To validate the proposed method, and evaluate the relation between the proposed metric and the general notion of flexibility, the flexibility metric is measured for 25 computing systems, including CPUs, GPUs, DSPs, and FPGAs, and 40 ASIPs taken from literature. The obtained results provide insights into some of the speculative trade-offs between flexibility and properties such as energy efficiency and area efficiency. Overall the proposed quantitative flexibility metric shows to be commensurate with some generally accepted qualitative notions of flexibility collected in the survey, although some surprising discrepancies can also be observed. The proposed metric and the obtained results are placed into context of the state of the art on compute flexibility, and extensive reflection provides not only a complete overview of the field, but also discusses possible alternative approaches and open issues. Note that this work does not aim to provide a final answer to the definition of flexibility, but rather provides a framework to initiate a broader discussion in the computer architecture society on defining, understanding, and ultimately taking advantage of flexibility.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4220696112",
    "type": "article"
  },
  {
    "title": "Benchmarking and Configuring Security Levels in Intermittent Computing",
    "doi": "https://doi.org/10.1145/3522748",
    "publication_date": "2022-03-31",
    "publication_year": 2022,
    "authors": "Archanaa S. Krishnan; Patrick Schaumont",
    "corresponding_authors": "",
    "abstract": "Intermittent computing derives its name from the intermittent character of the power source used to drive the computing, typically an energy harvester of ambient energy sources. Intermittent computing is characterized by frequent transitions between the powered and the non-powered state. To enable the processor to quickly recover from unexpected power loss, regular checkpoints store the run-time state of the program, including variables, control information, and machine state. In sensitive applications such as logged measurements, checkpoints must be secured against tamper and replay. We investigate the overhead of creating, securing, and restoring checkpoints with respect to the application. We propose a configurable checkpoint security setting that leverages application properties to reduce overhead of checkpoint security and implement the same using a secure checkpointing protocol. We discuss a prototype implementation for a FRAM-based micro-controller, and we characterize the cost of adding and configuring security to traditional checkpointing using a suite of embedded benchmark applications.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4220784314",
    "type": "article"
  },
  {
    "title": "Performance Modeling of Computer Vision-based CNN on Edge GPUs",
    "doi": "https://doi.org/10.1145/3527169",
    "publication_date": "2022-03-26",
    "publication_year": 2022,
    "authors": "Halima Bouzidi; Hamza Ouarnoughi; Smaïl Niar; Abdelhakim Artiba",
    "corresponding_authors": "",
    "abstract": "Convolutional Neural Networks (CNNs) are currently widely used in various fields, particularly for computer vision applications. Edge platforms have drawn tremendous attention from academia and industry due to their ability to improve execution time and preserve privacy. However, edge platforms struggle to satisfy CNNs’ needs due to their computation and energy constraints. Thus, it is challenging to find the most efficient CNN that respects accuracy, time, energy, and memory footprint constraints for a target edge platform. Furthermore, given the size of the design space of CNNs and hardware platforms, performance evaluation of CNNs entails several efforts. Consequently, designers need tools to quickly explore large design space and select the CNN that offers the best performance trade-off for a set of hardware platforms. This article proposes a Machine Learning (ML)–based modeling approach for CNN performances on edge GPU-based platforms for vision applications. We implement and compare five of the most successful ML algorithms for accurate and rapid CNN performance predictions on three different edge GPUs in image classification. Experimental results demonstrate the robustness and usefulness of our proposed methodology. For three of the five ML algorithms — XGBoost, Random Forest, and Ridge Polynomial regression — average errors of 11%, 6%, and 8% have been obtained for CNN inference execution time, power consumption, and memory usage, respectively.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4221014749",
    "type": "article"
  },
  {
    "title": "Hardware-friendly User-specific Machine Learning for Edge Devices",
    "doi": "https://doi.org/10.1145/3524125",
    "publication_date": "2022-03-31",
    "publication_year": 2022,
    "authors": "Vidushi Goyal; Reetuparna Das; Valeria Bertacco",
    "corresponding_authors": "",
    "abstract": "Machine learning (ML) on resource-constrained edge devices is expensive and often requires offloading computation to the cloud, which may compromise the privacy of user data. In contrast, the type of data processed at edge devices is user-specific and limited to a few inference classes. In this work, we explore building smaller, user-specific machine learning models, rather than utilizing a generic, compute-intensive machine learning model that caters to a diverse range of users. We first present a hardware-friendly, lightweight pruning technique to create user-specific models directly on mobile platforms, while simultaneously executing inferences. The proposed technique leverages compute sharing between pruning and inference, customizes the backward pass of training, and chooses a pruning granularity for efficient processing on edge. We then propose architectural support to prune user-specific models on a systolic edge ML inference accelerator. We demonstrate that user-specific models provide a speedup of 2.9× and 2.3× on the mobile CPUs for the ResNet-50 and Inception-V3 models.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4221058856",
    "type": "article"
  },
  {
    "title": "Attack-resilient Fusion of Sensor Data with Uncertain Delays",
    "doi": "https://doi.org/10.1145/3532181",
    "publication_date": "2022-04-18",
    "publication_year": 2022,
    "authors": "Yanfeng Chen; Tianyu Zhang; Fanxin Kong; Lin Zhang; Qingxu Deng",
    "corresponding_authors": "",
    "abstract": "Malicious attackers may disrupt the safety of autonomous systems through compromising sensors to feed wrong measurements to the controller. This article proposes attack-resilient sensor fusion that combines local sensor readings and shared sensing information from multiple sources. The method results in higher resilience against sensor attacks through jointly considering sensing noise and uncertain communication delay. To be specific, we first identify the considerable impact of the delay on determining attacked sensors. Second, we present a novel two-dimensional abstract sensor model, where each measurement is augmented as a probabilistic interval based on the convolution of the noise and delay. Third, we propose a fusion algorithm that admits the fused value with highest joint probability distribution of the intervals to tolerate corrupted measurements. Finally, we demonstrate the effectiveness of our method in a vehicle-platoon case study using extensive simulations and testbed experiments.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4224115426",
    "type": "article"
  },
  {
    "title": "High-performance Reconfigurable DNN Accelerator on a Bandwidth-limited Embedded System",
    "doi": "https://doi.org/10.1145/3530818",
    "publication_date": "2022-05-02",
    "publication_year": 2022,
    "authors": "Xianghong Hu; Hongmin Huang; Xueming Li; Xin Zheng; Qinyuan Ren; Jingyu He; Xiaoming Xiong",
    "corresponding_authors": "",
    "abstract": "Deep convolutional neural networks (DNNs) have been widely used in many applications, particularly in machine vision. It is challenging to accelerate DNNs on embedded systems because real-world machine vision applications should reserve a lot of external memory bandwidth for other tasks, such as video capture and display, while leaving little bandwidth for accelerating DNNs. In order to solve this issue, in this study, we propose a high-throughput accelerator, called reconfigurable tiny neural network accelerator (ReTiNNA), for the bandwidth-limited system and present a real-time object detection system for the high-resolution video image. We first present a dedicated computation engine that takes different data mapping methods for various filter types to improve data reuse and reduce hardware resources. We then propose an adaptive layer-wise tiling strategy that tiles the feature maps into strips to reduce the control complexity of data transmission dramatically and to improve the efficiency of data transmission. Finally, a design space exploration (DSE) approach is presented to explore design space more accurately in the case of insufficient bandwidth to improve the performance of the low-bandwidth accelerator. With a low bandwidth of 2.23 GB/s and a low hardware consumption of 90.261K LUTs and 448 DSPs, ReTiNNA can still achieve a high performance of 155.86 GOPS on VGG16 and 68.20 GOPS on ResNet50, which is better than other state-of-the-art designs implemented on FPGA devices. Furthermore, the real-time object detection system can achieve a high object detection speed of 19 fps for high-resolution video.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4225291778",
    "type": "article"
  },
  {
    "title": "Scheduling in Real-Time Mobile Systems",
    "doi": "https://doi.org/10.1145/3517747",
    "publication_date": "2022-05-28",
    "publication_year": 2022,
    "authors": "Cong Chen; Zhong Hong; Jianmin Jiang",
    "corresponding_authors": "",
    "abstract": "To guarantee the safety and security of a real-time mobile system such as an intelligent transportation system, it is necessary to model and analyze its behaviors prior to actual development. In particular, the mobile objects in such systems must be isolated from each other so that they do not collide with each other. Since isolation means two or more mobile objects must not be located in the same place at the same time, a scheduling policy is required to control and coordinate the movement of such objects. However, traditional scheduling theories are based on task scheduling which is coarse-grained and cannot be directly used for fine-grained isolation controls. In this article, we first propose a fine-grained event-based formal model called a time dependency structure and use it to model and analyze real-time mobile systems. Next, an event-based schedule is defined and the composition of schedules is discussed. Then, we investigate the schedulability of isolation—that is, checking whether a given schedule ensures the isolation relationship among mobile objects or not. After that, we present an automation approach for scheduling generation to guarantee isolation controls in real-time mobile systems. Finally, case studies and simulation experiments demonstrate the usability and effectiveness of our approach.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4281962866",
    "type": "article"
  },
  {
    "title": "ACDSE: A Design Space Exploration Method for CNN Accelerator based on Adaptive Compression Mechanism",
    "doi": "https://doi.org/10.1145/3545177",
    "publication_date": "2022-06-28",
    "publication_year": 2022,
    "authors": "Kaijie Feng; Xiaoya Fan; Jianfeng An; Chuxi Li; Kaiyue Di; Jiangfei Li",
    "corresponding_authors": "",
    "abstract": "Customized accelerators for Convolutional Neural Network (CNN) can achieve better energy efficiency than general computing platforms. However, the design of a high-performance accelerator should take into account a variety of parameters and physical constraints. The increasing parameters and tighter constraints gradually complicate the design space, which poses new challenges to the capacity and efficiency of design space exploration methods. In this paper, we provide a novel design space exploration method named ACDSE for optimizing the design process of CNN accelerators. ACDSE implements the adaptive compression mechanism to dynamically adjust the search range and prune low-value design points according to the exploration states. As a result, it can focus on valuable subspace while also improving exploration capacity and efficiency. Additionally, we implement ACDSE to address the problem of CNN accelerator latency optimization. The experiment indicates that, compared to former DSE methods, ACDSE can reduce latency and increase efficiency by 1.39x-5.07x and 2.07x-43.87x, respectively, under the most stringent constraint conditions, demonstrating its superior adaptability to the complicated design space.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4283706532",
    "type": "article"
  },
  {
    "title": "A Contrastive Plan Explanation Framework for Hybrid System Models",
    "doi": "https://doi.org/10.1145/3561532",
    "publication_date": "2022-09-15",
    "publication_year": 2022,
    "authors": "Mir Md Sajid Sarwar; R. L. Ray; Ansuman Banerjee",
    "corresponding_authors": "",
    "abstract": "In artificial intelligence planning, having an explanation of a plan given by a planner is often desirable. The ability to explain various aspects of a synthesized plan to an end user not only brings in trust on the planner but also reveals insights of the planning domain and the planning process. Contrastive questions such as “Why action A instead of action B?” can be answered with a contrastive explanation that compares properties of the original plan containing A against the contrastive plan containing B. In this article, we explore a set of contrastive questions that a user of a planning tool may raise and propose a re-model and re-plan framework to provide explanations to such questions. Earlier work has reported this framework on planning instances for discrete problem domains described in the Planning Domain Definition Language (PDDL) and its variants. In this article, we propose an extension for planning instances described by PDDL+ for hybrid systems that portray a mix of discrete-continuous dynamics. Specifically, given a mixed discrete-continuous system model in PDDL+ and a plan describing the set of desirable actions on the same to achieve a destined goal, we present a framework that can integrate contrastive questions in PDDL+ and synthesize alternate plans. We present a detailed case study on our approach and propose a comparison metric to compare the original plan with the alternate ones.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4296132066",
    "type": "article"
  },
  {
    "title": "Multi-bit Data Flow Error Detection Method Based on SDC Vulnerability Analysis",
    "doi": "https://doi.org/10.1145/3572838",
    "publication_date": "2022-11-24",
    "publication_year": 2022,
    "authors": "Zujia Yan; Yi Zhuang; Weining Zheng; Jingjing Gu",
    "corresponding_authors": "",
    "abstract": "One of the most difficult data flow errors to detect caused by single-event upsets in space radiation is the Silent Data Corruption (SDC). To solve the problem of multi-bit upsets causing program SDC, an instruction multi-bit SDC vulnerability prediction model based on one-class support vector machine classification is built using SDC vulnerability analysis, which has more accurate vulnerability instruction identification capabilities. By hardening the program with selective instruction redundancy, we propose a multi-bit data flow error detection method for detecting SDC error (SDCVA-OCSVM), aiming to protect the data in the memory or register used by the program. We have also verified the effectiveness of the method through comparative experiments. The method has been verified to have a higher error detection rate and lower code size and time overhead.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4309857285",
    "type": "article"
  },
  {
    "title": "EASYR: <u>E</u> nergy-Efficient <u>A</u> daptive <u>Sy</u> stem <u>R</u> econfiguration for Dynamic Deadlines in Autonomous Driving on Multicore Processors",
    "doi": "https://doi.org/10.1145/3570503",
    "publication_date": "2022-12-13",
    "publication_year": 2022,
    "authors": "Saehanseul Yi; Tae-Wook Kim; Jong-Chan Kim; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "The increasing computing demands of autonomous driving applications have driven the adoption of multicore processors in real-time systems, which in turn renders energy optimizations critical for reducing battery capacity and vehicle weight. A typical energy optimization method targeting traditional real-time systems finds a critical speed under a static deadline, resulting in conservative energy savings that are unable to exploit dynamic changes in the system and environment. We capture emerging dynamic deadlines arising from the vehicle’s change in velocity and driving context for an additional energy optimization opportunity. In this article, we extend the preliminary work for uniprocessors [ 66 ] to multicore processors, which introduces several challenges. We use the state-of-the-art real-time gang scheduling [ 5 ] to mitigate some of the challenges. However, it entails an NP-hard combinatorial problem in that tasks need to be grouped into gangs of tasks, gang formation, which could significantly affect the energy saving result. As such, we present EASYR, an adaptive system optimization and reconfiguration approach that generates gangs of tasks from a given directed acyclic graph for multicore processors and dynamically adapts the scheduling parameters and processor speeds to satisfy dynamic deadlines while consuming as little energy as possible. The timing constraints are also satisfied between system reconfigurations through our proposed safe mode change protocol. Our extensive experiments with randomly generated task graphs show that our gang formation heuristic performs 32% better than the state-of-the-art one. Using an autonomous driving task set from Bosch and real-world driving data, our experiments show that EASYR achieves energy reductions of up to 30.3% on average in typical driving scenarios compared with a conventional energy optimization method with the current state-of-the-art gang formation heuristic in real-time systems, demonstrating great potential for dynamic energy optimization gains by exploiting dynamic deadlines.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4311349856",
    "type": "article"
  },
  {
    "title": "SensiX++: Bringing MLOps and Multi-tenant Model Serving to Sensory Edge Devices",
    "doi": "https://doi.org/10.1145/3617507",
    "publication_date": "2023-09-07",
    "publication_year": 2023,
    "authors": "Chulhong Min; Akhil Mathur; Utku Günay Acer; Alessandro Montanari; Fahim Kawsar",
    "corresponding_authors": "",
    "abstract": "We present SensiX++ - a multi-tenant runtime for adaptive model execution with integrated MLOps on edge devices, e.g., a camera, a microphone, or IoT sensors. SensiX++ operates on two fundamental principles - highly modular componentisation to externalise data operations with clear abstractions and document-centric manifestation for system-wide orchestration. First, a data coordinator manages the lifecycle of sensors and serves models with correct data through automated transformations. Next, a resource-aware model server executes multiple models in isolation through model abstraction, pipeline automation and feature sharing. An adaptive scheduler then orchestrates the best-effort executions of multiple models across heterogeneous accelerators, balancing latency and throughput. Finally, microservices with REST APIs serve synthesised model predictions, system statistics, and continuous deployment. Collectively, these components enable SensiX++ to serve multiple models efficiently with fine-grained control on edge devices while minimising data operation redundancy, managing data and device heterogeneity, reducing resource contention and removing manual MLOps. We benchmark SensiX++ with ten different vision and acoustics models across various multi-tenant configurations on different edge accelerators (Jetson AGX and Coral TPU) designed for sensory devices. We report on the overall throughput and quantified benefits of various automation components of SensiX++ and demonstrate its efficacy to significantly reduce operational complexity and lower the effort to deploy, upgrade, reconfigure and serve embedded models on edge devices.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3198744515",
    "type": "article"
  },
  {
    "title": "Supervisory Control for Dynamic Feature Configuration in Product Lines",
    "doi": "https://doi.org/10.1145/3579644",
    "publication_date": "2023-01-11",
    "publication_year": 2023,
    "authors": "Sander Thuijsman; Michel Reniers",
    "corresponding_authors": "",
    "abstract": "In this paper a framework for engineering supervisory controllers for product lines with dynamic feature configuration is proposed. The variability in valid configurations is described by a feature model. Behavior of system components is achieved using (extended) finite automata and both behavioral and dynamic configuration constraints are expressed by means of requirements as is common in supervisory control theory. Supervisory controller synthesis is applied to compute a behavioral model in which the requirements are adhered to. For the challenges that arise in this setting, multiple solutions are discussed. The solutions are exemplified in the CIF toolset using a model of a coffee machine. A use case of the much larger Body Comfort System product line is performed to showcase feasibility for industrial-sized systems.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4315647149",
    "type": "article"
  },
  {
    "title": "TH-iSSD: Design and Implementation of a Generic and Reconfigurable Near-Data Processing Framework",
    "doi": "https://doi.org/10.1145/3563456",
    "publication_date": "2023-02-20",
    "publication_year": 2023,
    "authors": "Jiwu Shu; Kedong Fang; Youmin Chen; Shuo Wang",
    "corresponding_authors": "",
    "abstract": "We present the design and implementation of TH-iSSD, a near-data processing framework to address the data movement problem. TH-iSSD does not pose any restriction to the hardware selection and is highly reconfigurable—its core components, such as the on-device compute unit (e.g., FPGA, embedded CPUs) and data collectors (e.g., camera, sensors), can be easily replaced to adapt to different use cases. TH-iSSD achieves this goal by incorporating highly flexible computation and data paths. In the data path, TH-iSSD adopts an efficient device-level data switch that exchanges data with both host CPUs and peripheral sensors; it also enables direct accesses between the sensing, computation, and storage hardware components, which completely eliminates the redundant data movement overhead, and thus delivers both high performance and energy efficiency. In the computation path, TH-iSSD provides an abstraction of filestream for developers, which abstracts a collection of data along with the related computation task as a file. Since existing applications are familiar with POSIX-like interfaces, they can be ported on top of our platform with minimal code modification. Moreover, TH-iSSD also introduces mechanisms including pipelined near-data processing and priority-aware I/O scheduling to make TH-iSSD perform more effectively. We deploy TH-iSSD to accelerate two types of applications: the content-based information retrieval system and the edge zero-streaming system. Our experimental results show that TH-iSSD achieves up to 1.6× higher throughput and 36% lower latency than compute-centric designs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4321377969",
    "type": "article"
  },
  {
    "title": "Toward Next Generation Quantum-Safe eIDs and eMRTDs: A Survey",
    "doi": "https://doi.org/10.1145/3585517",
    "publication_date": "2023-03-01",
    "publication_year": 2023,
    "authors": "Nouri Alnahawi; N J Schmitt; Alexander Wiesmaier; Chiara-Marie Zok",
    "corresponding_authors": "",
    "abstract": "Security mechanisms of Electronic Personal Documents (eCards) depend on (asymmetric) cryptography that is and always has been subject to the threat of compromise, be it from conventional attacks or quantum computers. With Post-Quantum Cryptography (PQC), we now have alternative building blocks at hand that can be leveraged to protect against both kind of attacks. Thus, PQC should be incorporated into eCard ecosystems, yet it is not clear how this is done best. In the work at hand, we review the state of currently used crypto-systems for eCard security, as well as their possible quantum-secure replacements. Further, we identify and categorize respective challenges that need to be addressed, present and assess existing approaches for their solution, and formulate research questions for open issues. By providing an overview of the situation, we help unraveling the issue and pave the way toward quantum-safe electronic Identity Documents and electronic Machine-Readable Travel Documents.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4322740616",
    "type": "article"
  },
  {
    "title": "Analysis of EM Fault Injection on Bit-sliced Number Theoretic Transform Software in Dilithium",
    "doi": "https://doi.org/10.1145/3583757",
    "publication_date": "2023-03-31",
    "publication_year": 2023,
    "authors": "Richa Singh; Saad Islam; Berk Sunar; Patrick Schaumont",
    "corresponding_authors": "",
    "abstract": "Bitslicing is a software implementation technique that treats an N -bit processor datapath as N parallel single-bit datapaths. Bitslicing is particularly useful to implement data-parallel algorithms, algorithms that apply the same operation sequence to every element of a vector. Indeed, a bit-wise processor instruction applies the same logical operation to every single-bit slice. A second benefit of bitsliced execution is that the natural spatial redundancy of bitsliced software can support countermeasures against fault attacks. A k -redundant program on an N -bit processor then runs as N/k parallel redundant slices. In this contribution, we combine these two benefits of bitslicing to implement a fault countermeasure for the number-theoretic transform (NTT) . The NTT efficiently implements a polynomial multiplication. The internal symmetry of the NTT algorithm lends itself to a data-parallel implementation, and hence it is a good candidate for the redundantly bitsliced implementation. We implement a redundantly bitsliced NTT on an advanced 667MHz ARM Cortex-A9 processor, and study the fault coverage for the protected NTT under optimized electromagnetic fault injection (EMFI) . Our work brings two major contributions. First, we show for the first time how to develop a redundantly bitsliced version of the NTT. We integrate the protected NTT into a full Dilithium signature sequence. Second, we demonstrate an EMFI analysis on a prototype implementation of the Dilithium signature sequence on ARM Cortex-M9. We perform a detailed EM fault-injection parameter search to optimize the location, intensity and timing of injected EM pulses. We demonstrate that, under optimized fault injection parameters, about 10% of the injected faults become potentially exploitable. However, the redundantly bitsliced NTT design is able to catch the majority of these potentially exploitable faults, even when the remainder of the Dilithium algorithm as well as the control flow is left unprotected. To our knowledge, this is the first demonstration of a bitslice-redundant design of the NTT that offers distributed fault detection throughout the execution of the algorithm.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4362475146",
    "type": "article"
  },
  {
    "title": "Constrained Tiny Machine Learning for Predicting Gas Concentration with I4.0 Low-cost Sensors",
    "doi": "https://doi.org/10.1145/3590956",
    "publication_date": "2023-04-14",
    "publication_year": 2023,
    "authors": "Mohammed El Adoui; Thomas Herpoel; Benoît Frénay‬",
    "corresponding_authors": "",
    "abstract": "Low-cost gas sensors (LCS) often produce inaccurate measurements due to varying environmental conditions that are not consistent with laboratory settings, leading to inadequate productivity levels compared to high-quality sensors. To address this issue, we propose the use of Machine Learning (ML) to predict accurate concentrations of pollutant gases acquired by LCS integrated into an embedded Internet of Things platform. However, a key challenge is to optimize an accurate ML design under low memory and computation power constraints of microcontrollers (MCUs) while maintaining accurate ML scores. After data analysis and pre-processing, we assess and analyze the performance of five ML algorithms to predict the concentration of pollutants gases from multiple specifications (weather, presence of other gases, etc.). To support the experiments, datasets from three sources are used: (1) VOCSens, (2) Belgian Interregional Environment Agency cell, and (3) Visual-Crossing. Once the best model was optimized and validated, multiple hard constraints were added to the selected ML structure to satisfy material and expert requirements. Trained models were ported to be implemented locally in a MCU after comparing several porting libraries. The assembled code obtained is evaluated based on two metrics: storage memory consumption and inference time, relative to the highest attainable capacities. The improved random forest is the best ML model for the used dataset with an R2 score meeting of 0.72 and Root Means Square Error of 0.0028 ppm. The best generated Tiny-ML model needs 3% of RAM and 98% of Flash storage. The empirical results prove that the developed ML algorithm applied to LCS provides high accuracy to predict pollutant gases. This algorithm can also be used to adjust the LCS systems to provide calibrated data in real time, even if the platform being used is not particularly advanced or powerful.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4365509803",
    "type": "article"
  },
  {
    "title": "Real-Time USB Networking and Device I/O",
    "doi": "https://doi.org/10.1145/3604429",
    "publication_date": "2023-06-12",
    "publication_year": 2023,
    "authors": "Richard West; Ahmad Golchin; Anton Njavro",
    "corresponding_authors": "",
    "abstract": "Multicore PC-class embedded systems present an opportunity to consolidate separate microcontrollers as software-defined functions. For instance, an automotive system with more than 100 electronic control units (ECUs) could be replaced with one or, at most, several multicore PCs running software tasks for chassis, body, powertrain, infotainment, and advanced driver assistance system (ADAS) services. However, a key challenge is how to handle real-time device input and output (I/O) and host-level networking as part of sensor data processing and control. A traditional microcontroller would commonly feature one or more Controller Area Network (CAN) buses for real-time I/O. CAN buses are usually absent in PCs, which instead feature higher bandwidth Universal Serial Bus (USB) interfaces. This article shows how to achieve real-time device I/O and host-to-host communication over USB, using suitably written device drivers and a time-aware POSIX-like “tuned pipe” abstraction. This allows developers to establish task pipelines spanning one or more hosts, with end-to-end latency and throughput guarantees for sensor data processing, control, and actuation.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4380323597",
    "type": "article"
  },
  {
    "title": "RegKey: A Register-based Implementation of ECC Signature Algorithms Against One-shot Memory Disclosure",
    "doi": "https://doi.org/10.1145/3604805",
    "publication_date": "2023-06-15",
    "publication_year": 2023,
    "authors": "Yu Fu; Jingqiang Lin; Dengguo Feng; Wei Wang; Mingyu Wang; Wenjie Wang",
    "corresponding_authors": "",
    "abstract": "To ensure the security of cryptographic algorithm implementations, several cryptographic key protection schemes have been proposed to prevent various memory disclosure attacks. Among them, the register-based solutions do not rely on special hardware features and offer better applicability. However, due to the size limitation of register resources, the performance of register-based solutions is much worse than conventional cryptosystem implementations without security enhancements. This paper presents RegKey, an efficient register-based implementation of ECC (elliptic curve cryptography) signature algorithms. Different from other schemes that protect the whole cryptographic operations, RegKey only uses CPU registers to execute simple but critical operations, significantly reducing the usage of register resources and performance overheads. To achieve this goal, RegKey splits the ECC signing into two parts, (1) complex elliptic curve group operations on non-sensitive data in main memory as normal implementations, and (2) simple prime field operations on sensitive data inside CPU registers. RegKey guarantees the plaintext private key and random number used for signing only appear in registers to effectively resist one-shot memory disclosure attacks such as cold-boot attacks and warm-boot attacks, which are usually launched by physically accessing the victim machine to acquire partial or even entire memory data but only once. Compared with existing cryptographic key protection schemes, the performance of RegKey is greatly improved. Regkey is applicable to different platforms because it does not rely on special CPU hardware features. Since RegKey focuses on one-shot memory disclosure instead of persistent software-based attacks, it works as a choice suitable for embedded devices or offline machines where physical attacks are the main threat.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4380677167",
    "type": "article"
  },
  {
    "title": "REPAIRS: Gaussian Mixture Model-based Completion and Optimization of Partially Specified Systems",
    "doi": "https://doi.org/10.1145/3605147",
    "publication_date": "2023-06-19",
    "publication_year": 2023,
    "authors": "Prerit Terway; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Most system optimization techniques focus on finding the values of the system components to achieve the best performance. Searching over all component values gives the search methodology the freedom to explore the entire design space to determine the best system configuration. However, real-world systems often require searching in a restricted space over only a subset of component values while freezing some of the components to fixed values. Rather than optimizing from scratch to search over the subset of components, incorporating the past simulation logs (search performed when all components were allowed to vary) enables the optimization mechanism to utilize knowledge from past system behavior. In addition, when the system gives the same response over different combinations of input values, the designer may prefer one combination over another. Furthermore, real-world data often contain errors. To avoid catastrophic consequences of making decisions based on incorrect data points, we need a mechanism to identify and correct the resulting error. We propose REPAIRS, a methodology to complete/optimize partially specified systems. It also performs data integrity checks and identifies/corrects errors after detecting an anomaly in the data. We use a Gaussian mixture model to learn the joint distribution of the system inputs and the corresponding output response (objectives/constraints). We use the learned model to complete a partially specified system where only a subset of the component values and/or the system response is specified. When the system response exhibits multiple modes (e.g., same response for different combinations of input values), REPAIRS determines the combinations of input values that correspond to the several modes. Using past simulation logs, it searches over various subsets of system inputs to improve the performance of the reference solution. We also present a framework for verifying the integrity of a given data instance. When the integrity check fails, we provide a mechanism to identify the error location and correct the error. REPAIRS provides an explanation for the decision it makes for the different use cases described in this article. We provide results of REPAIRS in the context of completion, partial optimization, and data integrity check of real-world systems. REPAIRS achieves a hypervolume that is better than that obtained using a baseline method by up to 50%. It successfully identifies the error location and predicts the correct value of the erroneous feature with an error less than 0.2%. It detects error locations with a mean accuracy of up to 95% even when three feature values have an error.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4381189793",
    "type": "article"
  },
  {
    "title": "A Granularity-Based Clustering Method for Reducing Write Amplification in Solid-State Drives",
    "doi": "https://doi.org/10.1145/3605779",
    "publication_date": "2023-06-22",
    "publication_year": 2023,
    "authors": "Y.C. Hsu; Chin-Hsien Wu; Y. W. Tsai; Chia-Cheng Liu",
    "corresponding_authors": "",
    "abstract": "In recent years, solid-state drives (SSDs) that adopt NAND flash memory have been widely used as the main storage devices. In particular, NAND flash memory has a special feature of “out-of-place” updates to write the up-to-date data to a free page, and the corresponding old page will become invalid. When the number of free pages in SSDs is insufficient, garbage collection (GC) will be executed to reclaim the invalid pages in a block by erasing the block. Many studies have shown that a good hot/cold data separation (i.e., clustering) can greatly reduce the overhead of GC so as to improve the SSD performance. However, previous clustering methods usually use a static number of clusters or a fixed size of granularity (i.e., a fine-grained or a coarse-grained granularity), so they may not always perform well for different kinds of workloads. Therefore, we propose a granularity-based clustering method to adaptively adjust the size of granularity groups for an appropriate number of clusters at runtime according to the update distances of logical addresses. According to the experimental results, we can improve SSD performance by reducing the overhead of GC and decrease the write amplification. Furthermore, we can show that the proposed method can utilize a fine-grained granularity to retain the record accuracy of update distances and also utilize a coarse-grained granularity to reduce the space required to record update distances.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4381485951",
    "type": "article"
  },
  {
    "title": "BISDU: A Bit-Serial Dot-Product Unit for Microcontrollers",
    "doi": "https://doi.org/10.1145/3608447",
    "publication_date": "2023-07-28",
    "publication_year": 2023,
    "authors": "David Metz; Vineet Kumar; Magnus Själander",
    "corresponding_authors": "",
    "abstract": "Low-precision quantized neural networks (QNNs) reduce the required memory space, bandwidth, and computational power, and hence are suitable for deployment in applications such as IoT edge devices. Mixed-precision QNNs, where weights commonly have lower precision than activations or different precision is used for different layers, can limit the accuracy loss caused by low-bit quantization, while still benefiting from reduced memory footprint and faster execution. Previous multiple-precision functional units supporting 8-bit, 4-bit, and 2-bit SIMD instructions have limitations, such as large area overhead, under-utilization of multipliers, and wasted memory space for low and mixed bit-width operations. This article introduces BISDU, a bit-serial dot-product unit to support and accelerate execution of mixed-precision low-bit QNNs on resource-constrained microcontrollers. BISDU is a multiplier-less dot-product unit, with frugal hardware requirements (a population count unit and 2:1 multiplexers). The proposed bit-serial dot-product unit leverages the conventional logical operations of a microcontroller to perform multiplications, which enables efficient software implementations of binary ( Xnor ), ternary ( Xor ), and mixed-precision [W×A] ( And ) dot-product operations. The experimental results show that BISDU achieves competitive performance compared to two state-of-the-art units, XpulpNN and Dustin, when executing low-bit-width CNNs. We demonstrate the advantage that bit-serial execution provides by enabling trading accuracy against weight footprint and execution time. BISDU increases the area of the ALU by 68% and the ALU power consumption by 42% compared to a baseline 32-bit RISC-V (RV32IC) microcontroller core. In comparison, XpulpNN and Dustin increase the area by 6.9× and 11.1× and the power consumption by 3.8× and 5.97×, respectively. The bit-serial state-of-the-art, based on a conventional popcount instruction, increases the area by 42% and power by 32%, with BISDU providing a 37% speedup over it.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4385342457",
    "type": "article"
  },
  {
    "title": "iAware: Interaction Aware Task Scheduling for Reducing Resource Contention in Mobile Systems",
    "doi": "https://doi.org/10.1145/3609391",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Yongchun Zheng; Changlong Li; Yi Xiong; Weihong Liu; Cheng Ji; Zongwei Zhu; Lichen Yu",
    "corresponding_authors": "",
    "abstract": "To ensure the user experience of mobile systems, the foreground application can be differentiated to minimize the impact of background applications. However, this article observes that system services in the kernel and framework layer, instead of background applications, are now the major resource competitors. Specifically, these service tasks tend to be quiet when people rarely interact with the foreground application and active when interactions become frequent, and this high overlap of busy times leads to contention for resources. This article proposes iAware, an interaction-aware task scheduling framework in mobile systems. The key insight is to make use of the previously ignored idle period and schedule service tasks to run at that period. iAware quantify the interaction characteristic based on the screen touch event, and successfully stagger the periods of frequent user interactions. With iAware, service tasks tend to run when few interactions occur, for example, when the device’s screen is turned off, instead of when the user is frequently interacting with it. iAware is implemented on real smartphones. Experimental results show that the user experience is significantly improved with iAware. Compared to the state-of-the-art, the application launching speed and frame rate are enhanced by 38.89% and 7.97% separately, with no more than 1% additional battery consumption.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386568609",
    "type": "article"
  },
  {
    "title": "Thermal Management for 3D-Stacked Systems via Unified Core-Memory Power Regulation",
    "doi": "https://doi.org/10.1145/3608040",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Yixian Shen; L.C. Schreuders; Anuj Pathania; Andy D. Pimentel",
    "corresponding_authors": "",
    "abstract": "3D-stacked processor-memory systems stack memory (DRAM banks) directly on top of logic (CPU cores) using chiplet-on-chiplet packaging technology to provide the next-level computing performance in embedded platforms. Stacking, however, severely increases the system’s power density without any accompanying increase in the heat dissipation capacity. Consequently, 3D-stacked processor-memory systems suffer more severe thermal issues than their non-stacked counterparts. Nevertheless, 3D-stacked processor-memory systems do inherit power (thermal) management knobs from their non-stacked predecessors - namely Dynamic Voltage and Frequency Scaling (DVFS) for cores and Low Power Mode (LPM) for memory banks. In the context of 3D-stacked processor-memory systems, DVFS and LPM are performance- and power-wise deeply intertwined. Their non-unified independent use on 3D-stacked processor-memory systems results in sub-optimal thermal management. The unified use of DVFS and LPM for thermal management for 3D-stacked processor-memory systems remains unexplored. The lack of implementation of LPM in thermal simulators for 3D-stacked processor-memory systems hinders real-world representative evaluation for a unified approach. We extend the state-of-the-art interval thermal simulator for 3D-stacked processor-memory systems CoMeT with an LPM power management knob for memory banks. We also propose a learning-based thermal management technique for 3D-stacked processor-memory systems that employ DVFS and LPM in a unified manner. Detailed interval thermal simulations with the extended CoMeT framework show a 10.15% average response time improvement with the PARSEC and SPLASH-2 benchmark suites, along with widely-used Deep Neural Network (DNN) workloads against a state-of-the-art thermal management technique for 2.5D processor-memory systems (ported directly to 3D-stacked processor-memory systems) that also proposes unified use of DVFS and LPM.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386568684",
    "type": "article"
  },
  {
    "title": "A Constructive State-based Semantics and Interpreter for a Synchronous Data-flow Language with State Machines",
    "doi": "https://doi.org/10.1145/3609131",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Jean-Louis Colaço; Michael Mendler; Baptiste Pauget; Marc Pouzet",
    "corresponding_authors": "",
    "abstract": "Scade is a domain-specific synchronous functional language used to implement safety-critical real-time software for more than twenty years. Two main approaches have been considered for its semantics: (i) an indirect collapsing semantics based on a source-to-source translation of high-level constructs into a data-flow core language whose semantics is precisely specified and is the entry for code generation; a relational synchronous semantics , akin to Esterel, that applies directly to the source. It defines what is a valid synchronous reaction but hides, on purpose, if a semantics exists, is unique and can be computed; hence, it is not executable. This paper presents, for the first time, an executable , state-based semantics for a language that has the key constructs of Scade all together, in particular the arbitrary combination of data-flow equations and hierarchical state machines. It can apply directly to the source language before static checks and compilation steps. It is constructive in the sense that the language in which the semantics is defined is a statically typed functional language with call-by-value and strong normalization, e.g., it is expressible in a proof-assistant where all functions terminate. It leads to a reference, purely functional, interpreter. This semantics is modular and can account for possible errors, allowing to establish what property is ensured by each static verification performed by the compiler. It also clarifies how causality is treated in Scade compared with Esterel. This semantics can serve as an oracle for compiler testing and validation; to prototype novel language constructs before they are implemented, to execute possibly unfinished models or that are correct but rejected by the compiler; to prove the correctness of compilation steps. The semantics given in the paper is implemented as an interpreter in a purely functional style, in OCaml.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386568751",
    "type": "article"
  },
  {
    "title": "Overflow-free Compute Memories for Edge AI Acceleration",
    "doi": "https://doi.org/10.1145/3609387",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Flavio Ponzina; Marco Rios; Alexandre Levisse; Giovanni Ansaloni; David Atienza",
    "corresponding_authors": "",
    "abstract": "Compute memories are memory arrays augmented with dedicated logic to support arithmetic. They support the efficient execution of data-centric computing patterns, such as those characterizing Artificial Intelligence (AI) algorithms. These architectures can provide computing capabilities as part of the memory array structures (In-Memory Computing, IMC) or at their immediate periphery (Near-Memory Computing, NMC). By bringing the processing elements inside (or very close to) storage, compute memories minimize the cost of data access. Moreover, highly parallel (and, hence, high-performance) computations are enabled by exploiting the regular structure of memory arrays. However, the regular layout of memory elements also constrains the data range of inputs and outputs, since the bitwidths of operands and results stored at each address cannot be freely varied. Addressing this challenge, we herein propose a HW/SW co-design methodology combining careful per-layer quantization and inter-layer scaling with lightweight hardware support for overflow-free computation of dot-vector operations. We demonstrate their use to implement the convolutional and fully connected layers of AI models. We embody our strategy in two implementations, based on IMC and NMC, respectively. Experimental results highlight that an area overhead of only 10.5% (for IMC) and 12.9% (for NMC) is required when interfacing with a 2KB subarray. Furthermore, inferences on benchmark CNNs show negligible accuracy degradation due to quantization for equivalent floating-point implementations.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386568763",
    "type": "article"
  },
  {
    "title": "Modular DFR: Digital Delayed Feedback Reservoir Model for Enhancing Design Flexibility",
    "doi": "https://doi.org/10.1145/3609105",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Sosei Ikeda; Hiromitsu Awano; Takashi Satō",
    "corresponding_authors": "",
    "abstract": "A delayed feedback reservoir (DFR) is a type of reservoir computing system well-suited for hardware implementations owing to its simple structure. Most existing DFR implementations use analog circuits that require both digital-to-analog and analog-to-digital converters for interfacing. However, digital DFRs emulate analog nonlinear components in the digital domain, resulting in a lack of design flexibility and higher power consumption. In this paper, we propose a novel modular DFR model that is suitable for fully digital implementations. The proposed model reduces the number of hyperparameters and allows flexibility in the selection of the nonlinear function, which improves the accuracy while reducing the power consumption. We further present two DFR realizations with different nonlinear functions, achieving 10× power reduction and 5.3× throughput improvement while maintaining equal or better accuracy.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386574781",
    "type": "article"
  },
  {
    "title": "FSIMR: File-system-aware Data Management for Interlaced Magnetic Recording",
    "doi": "https://doi.org/10.1145/3607922",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Yi-Han Lien; Yen-Ting Chen; Yuan-Hao Chang; Yu-Pei Liang; Wei‐Kuan Shih",
    "corresponding_authors": "",
    "abstract": "Interlaced Magnetic Recording (IMR) is an emerging recording technology for hard-disk drives (HDDs) that provides larger storage capacity at a lower cost. By partially overlapping (interlacing) each bottom track with two adjacent top tracks, IMR-based HDDs successfully increase the data density while incurring some hardware write constraints. To update each bottom track, the data on two adjacent top tracks must be read and rewritten to avoid losing their valid data, resulting in additional overhead for performing read-modify-write (RMW) operations. Therefore, researchers have proposed various data management schemes to mitigate such overhead in recent years, aiming at improving the write performance. However, these designs have not taken into account the data characteristics of the file system, which is a crucial layer of operating systems for storing/retrieving data into/from HDDs. Consequently, the write performance improvement is limited due to the unawareness of spatial locality and hotness of data. This paper proposes a file-system-aware data management scheme called FSIMR to improve system write performance. Noticing that data of the same directory may have higher spatial locality and are mostly updated at the same time, FSIMR logically partitions the IMR-based HDD into fixed-sized zones; data belonging to the same directory will be arranged to one zone to reduce the time of seeking to-be-updated data (seek time). Furthermore, cold data within a zone are arranged to bottom tracks and updated in an out-of-place manner to eliminate RMW operations. Our experimental results show that the proposed FSIMR could reduce the seek time by up to 14% without introducing additional RMW operations, compared to existing designs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386580331",
    "type": "article"
  },
  {
    "title": "Stochastic Analysis of Control Systems Subject to Communication and Computation Faults",
    "doi": "https://doi.org/10.1145/3609123",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Nils Vreman; Martina Maggio",
    "corresponding_authors": "",
    "abstract": "Control theory allows one to design controllers that are robust to external disturbances, model simplification, and modelling inaccuracy. Researchers have investigated whether the robustness carries on to the controller’s digital implementation, mostly looking at how the controller reacts to either communication or computational problems. Communication problems are typically modelled using random variables (i.e., estimating the probability that a fault will occur during a transmission), while computational problems are modelled using deterministic guarantees on the number of deadlines that the control task has to meet. These fault models allow the engineer to both design robust controllers and assess the controllers’ behaviour in the presence of isolated faults. Despite being very relevant for the real-world implementations of control system, the question of what happens when these faults occur simultaneously does not yet have a proper answer. In this paper, we answer this question in the stochastic setting, using the theory of Markov Jump Linear Systems to provide stability contracts with almost sure guarantees of convergence. For linear time-invariant Markov jump linear systems, mean square stability implies almost sure convergence – a property that is central to our investigation. Our research primarily emphasises the validation of this property for closed-loop systems that are subject to packet losses and computational overruns, potentially occurring simultaneously. We apply our method to two case studies from the recent literature and show their robustness to a comprehensive set of faults. We employ closed-loop system simulations to empirically derive performance metrics that elucidate the quality of the controller implementation, such as the system settling time and the integral absolute error.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386580544",
    "type": "article"
  },
  {
    "title": "Protection Window Based Security-Aware Scheduling against Schedule-Based Attacks",
    "doi": "https://doi.org/10.1145/3609098",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Jiankang Ren; Chunxiao Liu; Chi Lin; Ran Bi; Simeng Li; Zheng Wang; Yicheng Qian; Zhichao Zhao; Guozhen Tan",
    "corresponding_authors": "",
    "abstract": "With widespread use of common-off-the-shelf components and the drive towards connection with external environments, the real-time systems are facing more and more security problems. In particular, the real-time systems are vulnerable to the schedule-based attacks because of their predictable and deterministic nature in operation. In this paper, we present a security-aware real-time scheduling scheme to counteract the schedule-based attacks by preventing the untrusted tasks from executing during the attack effective window (AEW). In order to minimize the AEW untrusted coverage ratio for the system with uncertain AEW size, we introduce the protection window to characterize the system protection capability limit due to the system schedulability constraint. To increase the opportunity of the priority inversion for the security-aware scheduling, we design an online feasibility test method based on the busy interval analysis. In addition, to reduce the run-time overhead of the online feasibility test, we also propose an efficient online feasibility test method based on the priority inversion budget analysis to avoid online iterative calculation through the offline maximum slack analysis. Owing to the protection window and the online feasibility test, our proposed approach can efficiently provide best-effort protection to mitigate the schedule-based attack vulnerability while ensuring system schedulability. Experiments show the significant security capability improvement of our proposed approach over the state-of-the-art coverage oriented scheduling algorithm.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386580618",
    "type": "article"
  },
  {
    "title": "DaCapo: An On-Device Learning Scheme for Memory-Constrained Embedded Systems",
    "doi": "https://doi.org/10.1145/3609121",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Osama Khan; Gwanjong Park; Euiseong Seo",
    "corresponding_authors": "",
    "abstract": "The use of deep neural network (DNN) applications in microcontroller unit (MCU) embedded systems is getting popular. However, the DNN models in such systems frequently suffer from accuracy loss due to the dataset shift problem. On-device learning resolves this problem by updating the model parameters on-site with the real-world data, thus localizing the model to its surroundings. However, the backpropagation step during on-device learning requires the output of every layer computed during the forward pass to be stored in memory. This is usually infeasible in MCU devices as they are equipped only with a few KBs of SRAM. Given their energy limitation and the timeliness requirements, using flash memory to store the output of every layer is not practical either. Although there have been proposed a few research results to enable on-device learning under stringent memory conditions, they require the modification of the target models or the use of non-conventional gradient computation strategies. This paper proposes DaCapo, a backpropagation scheme that enables on-device learning in memory-constrained embedded systems. DaCapo stores only the output of certain layers, known as checkpoints, in SRAM, and discards the others. The discarded outputs are recomputed during backpropagation from the nearest checkpoint in front of them. In order to minimize the recomputation occurrences, DaCapo optimally plans the checkpoints to be stored in the SRAM area at a particular phase of the backpropagation and thus replaces the checkpoints stored in memory as the backpropagation progresses. We implemented the proposed scheme in an STM32F429ZI board and evaluated it with five representative DNN models. Our evaluation showed that DaCapo improved backpropagation time by up to 22% and saved energy consumption by up to 28% in comparison to AIfES, a machine learning platform optimized for MCU devices. In addition, our proposed approach enabled the training of MobileNet, which the MCU device had been previously unable to train.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386580723",
    "type": "article"
  },
  {
    "title": "Keep in Balance: Runtime-reconfigurable Intermittent Deep Inference",
    "doi": "https://doi.org/10.1145/3607918",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Chih‐Hsuan Yen; Hashan Roshantha Mendis; Tei‐Wei Kuo; Pi-Cheng Hsiu",
    "corresponding_authors": "",
    "abstract": "Intermittent deep neural network (DNN) inference is a promising technique to enable intelligent applications on tiny devices powered by ambient energy sources. Nonetheless, intermittent execution presents inherent challenges, primarily involving accumulating progress across power cycles and having to refetch volatile data lost due to power loss in each power cycle. Existing approaches typically optimize the inference configuration to maximize data reuse. However, we observe that such a fixed configuration may be significantly inefficient due to the fluctuating balance point between data reuse and data refetch caused by the dynamic nature of ambient energy. This work proposes DynBal , an approach to dynamically reconfigure the inference engine at runtime. DynBal is realized as a middleware plugin that improves inference performance by exploring the interplay between data reuse and data refetch to maintain their balance with respect to the changing level of intermittency. An indirect metric is developed to easily evaluate an inference configuration considering the variability in intermittency, and a lightweight reconfiguration algorithm is employed to efficiently optimize the configuration at runtime. We evaluate the improvement brought by integrating DynBal into a recent intermittent inference approach that uses a fixed configuration. Evaluations were conducted on a Texas Instruments device with various network models and under varied intermittent power strengths. Our experimental results demonstrate that DynBal can speed up intermittent inference by 3.26 times, achieving a greater improvement for a large network under high intermittency and a large gap between memory and computation performance.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386580839",
    "type": "article"
  },
  {
    "title": "An Asynchronous Compaction Acceleration Scheme for Near-Data Processing-enabled LSM-Tree-based KV Stores",
    "doi": "https://doi.org/10.1145/3626097",
    "publication_date": "2023-09-29",
    "publication_year": 2023,
    "authors": "Hui Sun; Bendong Lou; Chao Zhao; Deyan Kong; Chaowei Zhang; Jianzhong Huang; Yinliang Yue; Xiao Qin",
    "corresponding_authors": "",
    "abstract": "LSM-tree-based key-value stores (KV stores) convert random-write requests to sequence-write ones to achieve high I/O performance. Meanwhile, compaction operations in KV stores update SSTables in forms of reorganizing low-level data components to high-level ones, thereby guaranteeing an orderly data layout in each component. Repeated writes caused by compaction (a.k.a. write amplification) impacts I/O bandwidth and overall system performance. Near-data processing (NDP) is one of the effective approaches to addressing this write-amplification issue. Most NDP-based techniques adopt synchronous parallel schemes to perform a compaction task on both the host and its NDP-enabled device. In synchronous parallel compaction schemes, the execution time of compaction is determined by a subsystem that has lower compaction performance coupled by under-utilized computing resources in a NDP framework. To solve this problem, we propose an asynchronous parallel scheme named PStore to improve the compaction performance in KV stores. In PStore, we designed a multi-tasks queue and three priority-based scheduling methods. PStore elects proper compaction tasks to be offloaded in host- and device-side compaction modules. Our proposed cross-leveled compaction mechanism mitigates write amplification induced by asynchronous compaction. PStore featured with the asynchronous compaction mechanism fully utilizes computing resources in both host- and device-side subsystems. Compared with the two popular synchronous compaction modes based on KV stores (TStore and LevelDB), our PStore immensely improves the throughput by up to a factor of 14 and 10.52 with an average of a factor of 2.09 and 1.73, respectively.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4387168584",
    "type": "article"
  },
  {
    "title": "Reachability Analysis of Sigmoidal Neural Networks",
    "doi": "https://doi.org/10.1145/3627991",
    "publication_date": "2023-10-17",
    "publication_year": 2023,
    "authors": "Sung Woo Choi; Michael Ivashchenko; Luan Viet Nguyen; Hoang-Dung Tran",
    "corresponding_authors": "",
    "abstract": "This paper extends the star set reachability approach to verify the robustness of feed-forward neural networks (FNNs) with sigmoidal activation functions such as Sigmoid and TanH. The main drawbacks of the star set approach in Sigmoid/TanH FNN verification are scalability, feasibility, and optimality issues in some cases due to the linear programming solver usage. We overcome this challenge by proposing a relaxed star (RStar) with symbolic intervals, which allows the usage of the back-substitution technique in DeepPoly to find bounds when overapproximating activation functions while maintaining the valuable features of a star set. RStar can overapproximate a sigmoidal activation function using four linear constraints (RStar4) or two linear constraints (RStar2), or only the output bounds (RStar0). We implement our RStar reachability algorithms in NNV and compare them to DeepPoly via robustness verification of image classification DNNs benchmarks. The experimental results show that the original star approach (i.e., no relaxation) is the least conservative of all methods yet the slowest. RStar4 is computationally much faster than the original star method and is the second least conservative approach. It certifies up to 40% more images against adversarial attacks than DeepPoly and on average 51 times faster than the star set. Last but not least, RStar0 is the most conservative method, which could only verify two cases for the CIFAR10 small Sigmoid network, δ = 0.014. However, it is the fastest method that can verify neural networks up to 3528 times faster than the star set and up to 46 times faster than DeepPoly in our evaluation.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4387698463",
    "type": "article"
  },
  {
    "title": "PArtNNer: Platform-agnostic Adaptive Edge-Cloud DNN Partitioning for minimizing End-to-End Latency",
    "doi": "https://doi.org/10.1145/3630266",
    "publication_date": "2023-10-27",
    "publication_year": 2023,
    "authors": "Soumendu Kumar Ghosh; Arnab Raha; Vijay Raghunathan; Anand Raghunathan",
    "corresponding_authors": "",
    "abstract": "The last decade has seen the emergence of Deep Neural Networks (DNNs) as the de facto algorithm for various computer vision applications. In intelligent edge devices, sensor data streams acquired by the device are processed by a DNN application running on either the edge device itself or in the cloud. However, “edge-only” and “cloud-only” execution of State-of-the-Art DNNs may not meet an application’s latency requirements due to the limited compute, memory, and energy resources in edge devices, dynamically varying bandwidth of edge-cloud connectivity networks, and temporal variations in the computational load of cloud servers. This work investigates distributed (partitioned) inference across edge devices (mobile/end device) and cloud servers to minimize end-to-end DNN inference latency. We study the impact of temporally varying operating conditions and the underlying compute and communication architecture on the decision of whether to run the inference solely on the edge, entirely in the cloud, or by partitioning the DNN model execution among the two. Leveraging the insights gained from this study and the wide variation in the capabilities of various edge platforms that run DNN inference, we propose PArtNNer , a platform-agnostic adaptive DNN partitioning algorithm that finds the optimal partitioning point in DNNs to minimize inference latency. PArtNNer can adapt to dynamic variations in communication bandwidth and cloud server load without requiring pre-characterization of underlying platforms. Experimental results for six image classification and object detection DNNs on a set of five commercial off-the-shelf compute platforms and three communication standards indicate that PArtNNer results in 10.2× and 3.2× (on average) and up to 21.1× and 6.7× improvements in end-to-end inference latency compared to execution of the DNN entirely on the edge device or entirely on a cloud server, respectively. Compared to pre-characterization-based partitioning approaches, PArtNNer converges to the optimal partitioning point 17.6× faster.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4387968598",
    "type": "article"
  },
  {
    "title": "Modeling and Analysis of ETC Control System with Colored Petri Net and Dynamic Slicing",
    "doi": "https://doi.org/10.1145/3633450",
    "publication_date": "2023-11-27",
    "publication_year": 2023,
    "authors": "Wangyang Yu; Jinming Kong; Zhijun Ding; Xiaojun Zhai; Zhiqiang Li; Qi Guo",
    "corresponding_authors": "",
    "abstract": "Nowadays, Electronic Toll Collection (ETC) control systems have been widely adopted to smoothen traffic flow on highways. However, as it is a complex business interaction system, there are inevitably flaws in its control logic process, such as the problem of vehicle fee evasion. We find that there is more than one way for vehicles to evade fees. This shows that it is difficult to ensure the completeness of its design. Therefore, it is necessary to adopt a novel formal method to model and analyze its design, detect flaws, and modify it. In this article, a Colored Petri net (CPN) is introduced to establish its model. To analyze and modify the system model more efficiently, a dynamic slicing method of CPN is proposed. First, a static slice is obtained from the static slicing criterion by backtracking. Second, considering all binding elements that can be enabled under the initial marking, a forward slice is obtained from the dynamic slicing criterion by traversing. Third, the dynamic slicing of CPN is obtained by taking the intersection of both slices. The proposed dynamic slicing method of CPN can be used to formalize and verify the behavior properties of an ETC control system, and the flaws can be detected effectively. As a case study, the flaw about a vehicle that has not completed the payment following the previous vehicle to pass the railing is detected by the proposed method.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4389057939",
    "type": "article"
  },
  {
    "title": "Application-adaptive intelligent cache memory system",
    "doi": "https://doi.org/10.1145/581888.581893",
    "publication_date": "2002-11-01",
    "publication_year": 2002,
    "authors": "Junghoon Lee; Shin‐Dug Kim; Charles Weems",
    "corresponding_authors": "",
    "abstract": "This article presents the design of a simple hardware-controlled, high performance cache system. The design supports fast access time, optimal utilization of temporal and spatial localities adaptive to given applications, and a simple dynamic fetching mechanism with different fetch sizes. Support for dynamically varying the fetch size makes the cache equally effective for general-purpose as well as multimedia applications. Our cache organization and operational mechanism are especially designed to maximize temporal locality and spatial locality, selectively and adaptively. Simulation shows that the average memory access time of the proposed cache is equal to that of a conventional direct-mapped cache with eight times as much space. In addition, the simulations show that our cache achieves better performance than a 2-way or 4-way set associative cache with twice as much space. The average miss ratio, compared with the victim cache with 32-byte block size, is improved by about 41% or 60% for general applications and multimedia applications, respectively. It is also shown that power consumption of the proposed cache is around 10% to 60% lower than other cache systems that we examine. Our cache system thus offers high performance with low power consumption and low hardware cost.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2091467798",
    "type": "article"
  },
  {
    "title": "Cool-Cache",
    "doi": "https://doi.org/10.1145/860176.860182",
    "publication_date": "2003-08-01",
    "publication_year": 2003,
    "authors": "Osman Ünsal; Raksit Ashok; Israel Koren; C.M. Krishna; Csaba Andras Moritz",
    "corresponding_authors": "",
    "abstract": "The unique characteristics of multimedia/embedded applications dictate media-sensitive architectural and compiler approaches to reduce the power consumption of the data cache. Our goal is exploring energy savings for embedded/multimedia workloads without sacrificing performance. Here, we present two complementary media-sensitive energy-saving techniques that leverage static information. While our first technique is applicable to existing architectures, in our second technique we adopt a more radical approach and propose a new tagless caching architecture by reevaluating the architecture--compiler interface.Our experiments show that substantial energy savings are possible in the data cache. Across a wide range of cache and architectural configurations, we obtain up to 77% energy savings, while the performance varies from 14% improvement to 4% degradation depending on the application.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2146913174",
    "type": "article"
  },
  {
    "title": "Verification of safety properties for parameterized regular systems",
    "doi": "https://doi.org/10.1145/1067915.1067917",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "David Cachera; Katell Morin-Allory",
    "corresponding_authors": "",
    "abstract": "We propose a combination of heuristic methods to prove properties of control signals for regular systems defined by means of affine recurrence equations (AREs). We benefit from the intrinsic regularity of the underlying polyhedral model to handle parameterized systems in a symbolic way. Our techniques apply to safety properties. The general proof process consists in an iteration that alternates two heuristics. We are able to identify the cases when this iteration will stop in a finite number of steps. These techniques have been implemented in a high level synthesis environment based on the polyhedral model.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1989366483",
    "type": "article"
  },
  {
    "title": "Skiing the embedded systems mountain",
    "doi": "https://doi.org/10.1145/1086519.1086523",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Ingrid Verbauwhede; Patrick Schaumont",
    "corresponding_authors": "",
    "abstract": "UCLA teaches students how to master the steep slopes of the embedded systems mountain. The EE201A graduate course connects high-level design specification to embedded implementation. There is a long-standing and wide culture gap between system designers that create those abstract specifications and the system architects that need to implement them. In industry, the culture gap has separated software from hardware teams, and platform creators from platform users. In an embedded context, where these are very tightly connected, this leads to large inefficiencies both in design time and design results. Our course takes students to both sides of the gap and lets them look at this problem from different perspectives. For a given application, it teaches how to select target architectures, tools, and design methods. The course covers a stepwise systematic design process. It includes specification, transformation, and refinement of an application. Specifications enable systematic and structured expression of an application. Transformations rework specifications into ones that are a better match for a given target architecture. Refinements lower the abstraction level toward the target architecture. The embedded systems mountain is traversed in two directions. A vertical refinement axis covers elements such as power-memory-reduction methods or fixed-point refinement. A horizontal exploration axis covers various architecture alternatives including application-specific integrated circuits (ASIC), domain-specific processors, digital signal processors (DSP), embedded cores, programmable processors, and system-on-chip (SOC). During the course, the students also go through an extensive design project to apply the methods learned in this course. A typical embedded application is used to drive the project. In this paper it is illustrated using an embedded version of an image encoder, more specifically a JPEG encoder. Several commercial tools, design environments, and platforms have been used as alternative implementation targets for this application.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2117957786",
    "type": "article"
  },
  {
    "title": "Reducing branch predictor leakage energy by exploiting loops",
    "doi": "https://doi.org/10.1145/1234675.1234678",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Wei Zhang; Bramha Allu",
    "corresponding_authors": "",
    "abstract": "With the scaling of technology, leakage energy will become the dominant source of energy consumption. Besides cache memories, branch predictors are among the largest on-chip array structures and consume nontrivial leakage energy. This paper proposes two cost-effective loop-based strategies to reduce the branch predictor leakage without impacting prediction accuracy or performance. The loop-based approaches exploit the fact that loops usually only contain a small number of instructions and, hence, even fewer branch instructions while taking a significant fraction of the execution time. Consequently, all the nonactive entries of branch predictors can be placed into the low leakage mode during the loop execution in order to reduce leakage energy. Compiler and circuit supports are discussed to implement the proposed leakage-reduction strategies. Compared to the recently proposed decay-based approach, our experimental results show that the loop-based approach can extract 16.2% more dead time of the branch predictor, on average, leading to more leakage energy savings without impacting the branch prediction accuracy and performance.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2025999014",
    "type": "article"
  },
  {
    "title": "Beyond single-appearance schedules: Efficient DSP software synthesis using nested procedure calls",
    "doi": null,
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Ming-Yung Ko; Praveen K. Murthy; Shuvra S. Bhattacharyya",
    "corresponding_authors": "",
    "abstract": "Synthesis of digital signal-processing (DSP) software from dataflow-based formal models is an effective approach for tackling the complexity of modern DSP applications. In this paper, an efficient method is proposed for applying subroutine call instantiation of module functionality when synthesizing embedded software from a dataflow specification. The technique is based on a novel recursive decomposition of subgraphs in a cluster hierarchy that is optimized for low buffer size. Applying this technique, one can achieve significantly lower buffer sizes than what is available for minimum code size inlined schedules, which have been the emphasis of prior work on software synthesis. Furthermore, it is guaranteed that the number of procedure calls in the synthesized program is polynomially bounded in the size of the input dataflow graph, even though the number of module invocations may increase exponentially. This recursive decomposition approach provides an efficient means for integrating subroutine-based module instantiation into the design space of DSP software synthesis. The experimental results demonstrate a significant improvement in buffer cost, especially for more irregular multirate DSP applications, with moderate code and execution time overhead.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2091217489",
    "type": "article"
  },
  {
    "title": "FPGA placement using space-filling curves",
    "doi": "https://doi.org/10.1145/1596543.1596546",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "P. Banerjee; Susmita Sur‐Kolay; Arijit Bishnu; Sandip Das; Subhas C. Nandy; Subhasis Bhattacharjee",
    "corresponding_authors": "",
    "abstract": "Research in VLSI placement, an NP-hard problem, has branched in two different directions. The first one employs iterative heuristics with many tunable parameters to produce a near-optimal solution but without theoretical guarantee on its quality. The other one considers placement as a graph-embedding problem and designs approximation algorithms with provable bounds on the quality of the solution. In this article, we aim at unifying the above two directions. First, we extend the existing approximation algorithms for graph embedding in 1D and 2D grid to those for hypergraphs, which typically model circuits to be placed on a FPGA. We prove an approximation bound of O ( d √log n log log n ) for 1D, that is, linear arrangement and O ( d log n log log n ) for the 2D grid, where d is the maximum degree of hyperedges and n , the number of vertices in the hypergraph. Next, we propose an efficient method based on linear arrangement of the CLBs and the notion of space-filling curves for placing the configurable logic blocks (CLBs) of a netlist on island-style FPGAs with an approximation guarantee of O ( 4 √log n √ kd log log n ), where k is the number of nets. For the set of FPGA placement benchmarks, the running time is near linear in the number of CLBs thus allowing for scalability towards large circuits. We obtained a 33× speed-up, on average, with only 1.31× degradation in the quality of the solution compared to that produced by the popular FPGA tool VPR, thereby demonstrating the suitability of this very fast method for FPGA placement, with a provable performance guarantee.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2045443140",
    "type": "article"
  },
  {
    "title": "Analyzing the worst-case execution time for instruction caches with prefetching",
    "doi": "https://doi.org/10.1145/1457246.1457253",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Jun Yan; Wei Zhang",
    "corresponding_authors": "",
    "abstract": "Time predictability is one of the most important design considerations for real-time systems. In this article, we study the impact of instruction prefetching on the worst-case performance of instruction caches. We extend the static cache simulation technique to model and compute the worst-case instruction cache performance with prefetching. The evaluation results show that instruction prefetching can benefit both the average-case and worst-case performance; however, the degree of the worst-case performance improvement due to instruction prefetching is less than that of the average-case performance. As a result, the time variation of computing is increased by instruction prefetching. Also, our experimental results indicate that the prefetching distance can significantly impact the worst-case performance of instruction caches with instruction prefetching. Specifically, when the prefetching distance is equal to the L1 miss penalty, the worst-case execution time with instruction prefetching is minimized.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2083646761",
    "type": "article"
  },
  {
    "title": "An approximation algorithm for scheduling on heterogeneous reconfigurable resources",
    "doi": "https://doi.org/10.1145/1596532.1596537",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Ani Nahapetian; Philip Brisk; Soheil Ghiasi; Majid Sarrafzadeh",
    "corresponding_authors": "",
    "abstract": "Dynamic reconfiguration imposes significant penalties in terms of performance and energy. Scheduling the execution of tasks on a dynamically reconfigurable device is therefore of critical importance. Likewise, other application domains have cost models that are effectively the same as dynamic reconfiguration; examples include: data transmission across multiprocessor systems; dynamic code updating and reprogramming of motes in sensor networks; and module allocation, wherein the sharing of resources effectively eliminates inherent reconfiguration costs. This article contributes a fully polynomial time approximation algorithm for the problem of scheduling independent tasks onto a fixed number of heterogeneous reconfigurable resources, where each task has a different hardware and software latency on each device; the reconfiguration latencies can also vary between resources. A general-purpose processor and a field programmable gate array were used to experimentally validate the proposed technique using a pair of encryption algorithms. The latencies of the schedules obtained by the approximation scheme were at most 1.1× longer than the optimal solution, which was found using integer linear programming; this result is better than the theoretical worst-case guarantee of the approximation algorithm, which was 1.999×. The length of the schedules obtained using list scheduling, a well-known polynomial time heuristic, were at most 2.6× longer than optimal.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2115638297",
    "type": "article"
  },
  {
    "title": "ShaVe-ICE",
    "doi": "https://doi.org/10.1145/3157667",
    "publication_date": "2018-02-05",
    "publication_year": 2018,
    "authors": "Majid Shoushtari; Bryan Donyanavard; Luis Angel D. Bathen; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Traditional approaches for managing software-programmable memories (SPMs) do not support sharing of distributed on-chip memory resources and, consequently, miss the opportunity to better utilize those memory resources. Managing on-chip memory resources in many-core embedded systems with distributed SPMs requires runtime support to share memory resources between various threads with different memory demands running concurrently. Runtime SPM managers cannot rely on prior knowledge about the dynamically changing mix of threads that will execute and therefore should be designed in a way that enables SPM allocations for any unpredictable mix of threads contending for on-chip memory space. This article proposes ShaVe-ICE , an operating-system-level solution, along with hardware support, to virtualize and ultimately share SPM resources across a many-core embedded system to reduce the average memory latency. We present a number of simple allocation policies to improve performance and energy. Experimental results show that sharing SPMs could reduce the average execution time of the workload up to 19.5% and reduce the dynamic energy consumed in the memory subsystem up to 14%.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2787364211",
    "type": "article"
  },
  {
    "title": "A Hardware Pipeline with High Energy and Resource Efficiency for FMM Acceleration",
    "doi": "https://doi.org/10.1145/3157670",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Tian Huang; Yongxin Zhu; Yajun Ha; Xu Wang; Meikang Qiu",
    "corresponding_authors": "",
    "abstract": "The fast multipole method (FMM) is a promising mathematical technique that accelerates the calculation of long-ranged forces in the large-sized n-body problem. Existing implementations of the FMM on general-purpose processors are energy and resource inefficient. To mitigate these issues, we propose a hardware pipeline that accelerates three key FMM steps. The pipeline improves energy efficiency by exploiting fine-granularity parallelism of the FMM. We reuse the pipeline for different FMM steps to reduce resource usage by 66%. Compared to the state-of-the-art implementations on CPUs and GPUs, our implementation requires 15% less energy and delivers 2.61 times more floating-point operations.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2787735639",
    "type": "article"
  },
  {
    "title": "Dynamic Energy Management of FPGA Accelerators in Embedded Systems",
    "doi": "https://doi.org/10.1145/3182172",
    "publication_date": "2018-05-22",
    "publication_year": 2018,
    "authors": "Mohammad Hosseinabady; Jose Nunez‐Yanez",
    "corresponding_authors": "",
    "abstract": "In this article, we investigate how to utilise an Field-Programmable Gate Array (FPGA) in an embedded system to save energy. For this purpose, we study the energy efficiency of a hybrid FPGA-CPU device that can switch task execution between hardware and software with a focus on periodic tasks. To increase the applicability of this task switching, we also consider the voltage and frequency scaling (VFS) applied to the FPGA to reduce the system energy consumption. We show that in some cases, if the task’s period is higher than a specific level, the FPGA accelerator cannot reduce the energy consumption associated to the task and the software version is the most energy efficient option. We have applied the proposed techniques to a robot map creation algorithm as a case study which shows up to 38% energy reduction compared to the FPGA implementation. Overall, experimental results show up to 48% energy reduction by applying the proposed techniques at runtime on 13 individual tasks.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2803389765",
    "type": "article"
  },
  {
    "title": "Partitioning and Selection of Data Consistency Mechanisms for Multicore Real-Time Systems",
    "doi": "https://doi.org/10.1145/3320271",
    "publication_date": "2019-06-10",
    "publication_year": 2019,
    "authors": "Zaid Al-bayati; Youcheng Sun; Haibo Zeng; Marco Di Natale; Qi Zhu; Brett H. Meyer",
    "corresponding_authors": "",
    "abstract": "Multicore platforms are becoming increasingly popular in real-time systems. One of the major challenges in designing multicore real-time systems is ensuring consistent and timely access to shared resources. Lock-based protection mechanisms such as MPCP and MSRP have been proposed to guarantee mutually exclusive access in multicore systems at the expense of blocking. In this article, we consider partitioning and scheduling in multicore real-time systems with resource sharing. We first propose a resource-aware task partitioning algorithm for systems with lock-based protection. Wait-free methods, which ensure consistent access to shared memory resources with negligible blocking at the expense of additional memory space, are a suitable alternative when the shared resource is a communication buffer. We propose several approaches to solve the joint problem of task partitioning and the selection of a data consistency mechanism (lock-based or wait-free). The problem is first formulated as an Integer Linear Programming (ILP). For large systems where an ILP solution is not scalable, we propose two heuristic algorithms. Experimental results compare the effectiveness of the proposed approaches in finding schedulable systems with low memory cost and show how the use of wait-free methods can significantly improve schedulability.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2949359797",
    "type": "article"
  },
  {
    "title": "Cooperative Cache Transfer-based On-demand Network Coded Broadcast in Vehicular Networks",
    "doi": "https://doi.org/10.1145/3329865",
    "publication_date": "2019-07-18",
    "publication_year": 2019,
    "authors": "G. G. Md. Nawaz Ali; Md. Noor‐A‐Rahim; Md. Ashiqur Rahman; Beshah Ayalew; Peter Han Joo Chong; Yong Liang Guan",
    "corresponding_authors": "",
    "abstract": "Real-time traffic updates, safety and comfort driving, infotainment, and so on, are some envisioned applications in vehicular networks. Unlike traditional broadcast, network-coding-assisted broadcast can satisfy multiple vehicles with different data items in a coded form. However, server side encoding requires the prior knowledge about vehicles’ cache information for the successful decoding at the vehicles’ sides. The explicit cache upload from vehicles to Road Side Unit (RSU) wastes upload bandwidth. In multi-RSU vehicular networks, we propose a Cooperative Cache Transfer-based On-demand Network Coded Broadcast called CCTCB. In the proposed CCTCB approach, vehicles do not need to upload their cache information to the server, rather the RSU server learns the vehicles’ cache intrinsically. We derive a probabilistic model to analyze the coding opportunity in the proposed cooperative cache transfer mechanism incorporating vehicle mobility. The comprehensive simulation results validate the superiority of the proposed approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2962869824",
    "type": "article"
  },
  {
    "title": "Optimization and Implementation of Wavelet-based Algorithms for Detecting High-voltage Spindles in Neuron Signals",
    "doi": "https://doi.org/10.1145/3329864",
    "publication_date": "2019-07-18",
    "publication_year": 2019,
    "authors": "Yu-Chieh Chen; Ching-Chih Chang; Ramesh Perumal; Shih‐Rung Yeh; Yen‐Chung Chang; Hsin Chen",
    "corresponding_authors": "",
    "abstract": "This article presents a microcontroller unit (MCU) based simplified discrete wavelet transform (Sim-DWT) algorithm that can detect high-voltage spindles (HVSs) in local field potential (LFP) signals. The Sim-DWT algorithm operates in an 8-bit MCU, 8MHz operating clock and 16 sample points of buffers to detect HVSs with a frequency range of 5−15Hz. The requirement of only sixteen 8-bit sample points as the window length for calculation and no need for a multiplier render the Sim-DWT easy to implement in an MCU with limited hardware resources. The Sim-DWT is applied in an 8-bit MCU with 6mW power consumption (including IO ports) and was tested for detecting LFP signals in vivo. The design methods and the accuracy of three typical types of mother wavelet functions (Haar, DB4, Morlet) in the Sim-DWT were also tested and compared with those of a PC-based system. The experimental results showed that with appropriately designed cMW functions in the Sim-DWT, HVSs could be detected more accurately than they could be in PC-based software. The present study indicates that the optimized HVS detector (Sim-DWT) can be implemented in an 8-bit MCU with limited hardware resources and is suitable to serve as the digital core in a closed-loop deep brain stimulator microsystem in the future.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2962994391",
    "type": "article"
  },
  {
    "title": "Honey, I Shrunk the ELFs",
    "doi": "https://doi.org/10.1145/3358222",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "A. Ziegler; Julian Geus; Bernhard Heinloth; Timo Hönig; Daniel Lohmann",
    "corresponding_authors": "",
    "abstract": "In the embedded domain, industrial sectors (i.e., automotive industry, avionics) are undergoing radical changes. They broadly adopt commodity hardware and move away from special-purpose control units. During this transition, heterogeneous software components are consolidated to run on commodity operating systems. To efficiently consolidate such components, a modular encapsulation of common functionality into reusable binary files (i.e., shared libraries) is essential. However, shared libraries are often unnecessarily large as they entail a lot of generic functionality that is not required in a narrowly defined scenario. As the source code of proprietary components is often unavailable and the industry is heading towards binary-only distribution, we propose an approach towards lightweight binary tailoring . As demonstrated in the evaluation, lightweight binary tailoring effectively reduces the amount of code in all shared libraries on a Linux-based system by 63 percent and shrinks their files by 17 percent. The reduction in size is beneficial to cut down costs (e.g., lower storage and memory footprint) and eases code analyses that are necessary for code audits.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2979731643",
    "type": "article"
  },
  {
    "title": "ALEXIA",
    "doi": "https://doi.org/10.1145/3362064",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Gnanambikai Krishnakumar; K. A. Reddy; Chester Rebeiro",
    "corresponding_authors": "",
    "abstract": "Illegal use of memory pointers is a serious security vulnerability. A large number of malwares exploit the spatial and temporal nature of these vulnerabilities to subvert execution or glean sensitive data from an application. Recent countermeasures attach metadata to memory pointers, which define the pointer’s capabilities. The metadata is used by the hardware to validate pointer-based memory accesses. However, recent works have considerable overheads. Further, the pointer validation is decoupled from the actual memory access. We show that this could open up vulnerabilities in multithreaded applications and introduce new vulnerabilities due to speculation in out-of-order processors. In this article, we demonstrate that the overheads can be reduced considerably by efficient metadata management. We show that the hardware can be designed in a manner that would remain safe in multithreaded applications and immune to speculative vulnerabilities. We achieve these by ensuring that the pointer validations and the corresponding memory access is always done atomically and in order. To evaluate our scheme, which we call ALEXIA, we enhance an OpenRISC processor to perform the memory validation at runtime and also add compiler support. ALEXIA is the first hardware countermeasure scheme for memory protection that provides such an end-to-end solution. We evaluate the processor on an Altera FPGA and show that the runtime overhead, on average, is 14%, with negligible impact on the processor’s size and clock frequency. There is also a negligible impact on the program’s code and data sizes.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2984882580",
    "type": "article"
  },
  {
    "title": "Pattern Guided Integrated Scheduling and Routing in Multi-Hop Control Networks",
    "doi": "https://doi.org/10.1145/3372134",
    "publication_date": "2020-02-10",
    "publication_year": 2020,
    "authors": "Sumana Ghosh; Soumyajit Dey; Pallab Dasgupta",
    "corresponding_authors": "",
    "abstract": "Executing a set of control loops over a shared multi-hop (wireless) control network (MCN) requires careful co-scheduling of the control tasks and the routing of sensory/actuation messages over the MCN. In this work, we establish pattern guided aperiodic execution of control loops as a resource-aware alternative to traditional fully periodic executions of a set of embedded control loops sharing a computation and the communication infrastructure. We provide a satisfiability modulo theory–based co-design framework that synthesizes loop execution patterns having optimized control cost as the underlying scheduling scheme together with the associated routing solution over the MCN. The routing solution implements the timed movement of the sensory/actuation messages of the control loops, generated according to those loop execution patterns. From the given settling time requirement of the control loops, we compute a control theoretically sound model using matrix inequalities, which gives an upper bound to the number of loop drops within the finite length loop execution pattern. Next, we show how the proposed framework can be useful for evaluating the fault tolerance of a resource-constrained shared MCN subject to communication link failure.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3005927325",
    "type": "article"
  },
  {
    "title": "Energy-efficient Real-time Scheduling on Multicores",
    "doi": "https://doi.org/10.1145/3399413",
    "publication_date": "2020-07-04",
    "publication_year": 2020,
    "authors": "Saad Zia Sheikh; Muhammad Adeel Pasha",
    "corresponding_authors": "",
    "abstract": "With the increasing demand for higher performance, the adoption of multicores has been a major stepping stone in the evolution of hard real-time systems. Though the computational bandwidth is increased due to parallel processing, the indispensable interactivity between the hierarchical memory sub-system and multiple cores has further aggravated the already complex worst case execution time (WCET) analysis of tasks. Furthermore, caches have the biggest influence on task execution time, and the inclusion of shared caches further increases the unpredictability of the system. Cache partitioning techniques have been proposed as a counter-measure to decouple the shared cache latency from the WCET. However, existing energy-efficient scheduling algorithms are oblivious to the unpredictable nature of shared caches or cache partitioning techniques, thus, diminishing their applicability to real-world systems. Without considering inter-task cache contention, directly using existing algorithms or attempting to allocate and schedule a taskset with cache-partition assignments can result in cache violations. To overcome this dilemma, we propose a novel approach to model inter-task cache contention as a dependency graph to be used by well-established algorithms to minimize energy consumption. Extensive simulations demonstrate the effectiveness of our approach to minimize energy consumption while also avoiding cache violations.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3040463379",
    "type": "article"
  },
  {
    "title": "DIAC",
    "doi": "https://doi.org/10.1145/3391895",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Xinyi Li; Lei Zhang; Xipeng Shen",
    "corresponding_authors": "",
    "abstract": "This article tackles the problem of detecting and solving potential conflicts among independently developed apps that are to be installed into an open Internet-of-Things (IoT) environment. It provides a new set of definitions and categorizations of the conflicts to more precisely characterize the nature of the problem, and it proposes a representation named “IA Graphs” for formally representing IoT controls and inter-app interplays. Based on the definitions and representation, it then describes an efficient conflict detection algorithm. Combining conflict categories, seriousness indicator, and conflict frequency, an innovative solution policy for solving various detected conflicts is developed, which also takes into account user preference and interest by providing interactive process. It implements a compiler and runtime software system that integrates all the proposed techniques together into a comprehensive solution. Experiments on SmartThings apps validate its significantly better detection efficacy over prior methods and effectiveness of conflict solution with user preference.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3041309148",
    "type": "article"
  },
  {
    "title": "GMAI",
    "doi": "https://doi.org/10.1145/3391896",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Alejandro J. Calderón; Leonidas Kosmidis; Carlos Fernando Nicolás; Francisco J. Cazorla; Peio Onaindia",
    "corresponding_authors": "",
    "abstract": "Critical real-time systems require strict resource provisioning in terms of memory and timing. The constant need for higher performance in these systems has led industry to recently include GPUs. However, GPU software ecosystems are by their nature closed source, forcing system engineers to consider them as black boxes, complicating resource provisioning. In this work, we reverse engineer the internal operations of the GPU system software to increase the understanding of their observed behaviour and how resources are internally managed. We present our methodology that is incorporated in GMAI (GPU Memory Allocation Inspector), a tool that allows system engineers to accurately determine the exact amount of resources required by their critical systems, avoiding underprovisioning. We first apply our methodology on a wide range of GPU hardware from different vendors showing its generality in obtaining the properties of the GPU memory allocators. Next, we demonstrate the benefits of such knowledge in resource provisioning of two case studies from the automotive domain, where the actual memory consumption is up to 5.6× more than the memory requested by the application.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3041742096",
    "type": "article"
  },
  {
    "title": "Improving the Performance of Hybrid Caches Using Partitioned Victim Caching",
    "doi": "https://doi.org/10.1145/3411368",
    "publication_date": "2020-12-07",
    "publication_year": 2020,
    "authors": "Sukarn Agarwal; Hemangee K. Kapoor",
    "corresponding_authors": "",
    "abstract": "Non-Volatile Memory technologies are coming as a viable option on account of the high density and low-leakage power over the conventional SRAM counterpart. However, the increased write latency reduces their chances as a substitute for SRAM. To attenuate this problem, a hybrid STT-RAM-SRAM architecture is proposed where with large STT-RAM ways, the small SRAM ways are incorporated for handling the write operations. However, the performance gain obtained from such an architecture is not as much as expected on account of the larger miss rate caused by smaller SRAM partition. This, in turn, may limit the amount of cache capacity. This article attempts to reduce the miss penalty and improve the average memory access time by retaining the victims evicted from the hybrid cache in a smaller, fully associative SRAM structure called the victim cache. The victim cache is accessed on a miss in the primary hybrid cache. Hits in the victim cache require an exchange of the block between the main hybrid cache and the victim cache. In such cases, to effectively place the required block in the appropriate region of the main hybrid cache, we propose an access-based block placement technique. Besides, to manage the runtime load and the uneven evictions of the SRAM partition, we also present a dynamic region-based victim cache partitioning method to hold the victims dedicated to each region. Experimental evaluation on a full system simulator shows significant improvement in the performance and execution time along with a reduction in the overall miss rate. The proposed policy also increases the endurance of Hybrid Cache Architectures (HCA) by reducing writes in the STT partition.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3110972457",
    "type": "article"
  },
  {
    "title": "Probabilistic Estimation of Threat Intrusion in Embedded Systems for Runtime Detection",
    "doi": "https://doi.org/10.1145/3432590",
    "publication_date": "2021-01-04",
    "publication_year": 2021,
    "authors": "Nadir Carreón; Sixing Lu; Roman Lysecky",
    "corresponding_authors": "",
    "abstract": "With billions of networked connected embedded systems, the security historically provided by the isolation of embedded systems is no longer sufficient. Millions of new malware are created every month and zero-day attacks are becoming an increasing concern. Therefore, proactive security measures are no longer enough to provide protection to embedded systems. Instead, reactive approaches that detect attacks that can circumvent the proactive defenses and react upon them are needed. Anomaly-based detection is a common reactive approach employed to detect malware by monitoring anomalous deviations in the system execution. Timing-based anomaly detection detects malware by monitoring the system's internal timing, which offers unique protection against mimicry malware compared to sequence-based anomaly detection. However, previous timing-based anomaly detection methods focus on each operation independently at the granularity of tasks, function calls, system calls, or basic blocks. These approaches neither consider the entire software execution path nor provide a quantitative estimate of the presence of malware. This article presents a novel model for specifying the normal timing for execution paths in software applications using cumulative distribution functions of timing data in sliding execution windows. A probabilistic formulation is used to estimate the presence of malware for individual operations and sequences of operations within the paths. Operation and path-based thresholds are determined during the training process to minimize false positives. Finally, the article presents an optimization method to assist system developers in selecting which operations to monitor based on different optimization goals and constraints. Experimental results with a smart connected pacemaker, an unmanned aerial vehicle, and seven sophisticated mimicry malware implemented at different levels demonstrate the effectiveness of the proposed approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3120623256",
    "type": "article"
  },
  {
    "title": "Cooperative Coevolution-based Design Space Exploration for Multi-mode Dataflow Mapping",
    "doi": "https://doi.org/10.1145/3440246",
    "publication_date": "2021-03-27",
    "publication_year": 2021,
    "authors": "Bo Yuan; Xiaofen Lu; Ke Tang; Xin Yao",
    "corresponding_authors": "",
    "abstract": "Some signal processing and multimedia applications can be specified by synchronous dataflow (SDF) models. The problem of SDF mapping to a given set of heterogeneous processors has been known to be NP-hard and widely studied in the design automation field. However, modern embedded applications are becoming increasingly complex with dynamic behaviors changes over time. As a significant extension to the SDF, the multi-mode dataflow (MMDF) model has been proposed to specify such an application with a finite number of behaviors (or modes) and each behavior (mode) is represented by an SDF graph. The multiprocessor mapping of an MMDF is far more challenging as the design space increases with the number of modes. Instead of using traditional genetic algorithm (GA)-based design space exploration (DSE) method that encodes the design space as a whole, this article proposes a novel cooperative co-evolutionary genetic algorithm (CCGA)-based framework to efficiently explore the design space by a new problem-specific decomposition strategy in which the solutions of node mapping for each individual mode are assigned to an individual population. Besides, a problem-specific local search operator is introduced as a supplement to the global search of CCGA for further improving the search efficiency of the whole framework. Furthermore, a fitness approximation method and a hybrid fitness evaluation strategy are applied for reducing the time consumption of fitness evaluation significantly. The experimental studies demonstrate the advantage of the proposed DSE method over the previous GA-based method. The proposed method can obtain an optimization result with 2×−3× better quality using less (1/2−1/3) optimization time.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3140485605",
    "type": "article"
  },
  {
    "title": "Interactive Programmatic Modeling",
    "doi": "https://doi.org/10.1145/3431387",
    "publication_date": "2021-05-18",
    "publication_year": 2021,
    "authors": "David Broman",
    "corresponding_authors": "David Broman",
    "abstract": "Modeling and computational analyses are fundamental activities within science and engineering. Analysis activities can take various forms, such as simulation of executable models, formal verification of model properties, or inference of hidden model variables. Traditionally, tools for modeling and analysis have similar workflows: (i) a user designs a textual or graphical model or the model is inferred from data, (ii) a tool performs computational analyses on the model, and (iii) a visualization tool displays the resulting data. This article identifies three inherent problems with the traditional approach: the recomputation problem, the variable inspection problem, and the model expressiveness problem. As a solution, we propose a conceptual framework called Interactive Programmatic Modeling. We formalize the interface of the framework and illustrate how it can be used in two different domains: equation-based modeling and probabilistic programming.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3162589829",
    "type": "article"
  },
  {
    "title": "Cross-Layer Adaptation with Safety-Assured Proactive Task Job Skipping",
    "doi": "https://doi.org/10.1145/3477031",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Zhilu Wang; Chao Huang; Hyoseung Kim; Wenchao Li; Qi Zhu",
    "corresponding_authors": "",
    "abstract": "During the operation of many real-time safety-critical systems, there are often strong needs for adapting to a dynamic environment or evolving mission objectives, e.g., increasing sampling and control frequencies of some functions to improve their performance under certain situations. However, a system's ability to adapt is often limited by tight resource constraints and rigid periodic execution requirements. In this work, we present a cross-layer approach to improve system adaptability by allowing proactive skipping of task executions, so that the resources can be either saved directly or re-allocated to other tasks for their performance improvement. Our approach includes three novel elements: (1) formal methods for deriving the feasible skipping choices of control tasks with safety guarantees at the functional layer, (2) a schedulability analysis method for assessing system feasibility at the architectural layer under allowed task job skippings, and (3) a runtime adaptation algorithm that efficiently explores job skipping choices and task priorities for meeting system adaptation requirements while ensuring system safety and timing correctness. Experiments demonstrate the effectiveness of our approach in meeting system adaptation needs.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3199498054",
    "type": "article"
  },
  {
    "title": "MSYNC: A Generalized Formal Design Pattern for Virtually Synchronous Multirate Cyber-physical Systems",
    "doi": "https://doi.org/10.1145/3477036",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Kyungmin Bae; Peter Csaba Ölveczky",
    "corresponding_authors": "",
    "abstract": "TTA and PALS are two prominent formal design patterns—with different strengths and weaknesses—for virtually synchronous distributed cyber-physical systems (CPSs). They greatly simplify the design and verification of such systems by allowing us to design and verify their underlying synchronous designs. In this paper we introduce and verify MSYNC as a formal design (and verification) pattern/synchronizer for hierarchical multirate CPSs that generalizes, and combines the advantages of, both TTA and (single-rate and multirate) PALS. We also define an extension of TTA to multirate CPSs as a special case. We show that MSYNC outperforms both TTA and PALS in terms of allowing shorter periods, and illustrate the MSYNC design and verification approach with a case study on a fault-tolerant distributed control system for turning an airplane.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3201026696",
    "type": "article"
  },
  {
    "title": "Exploring Efficient Architectures on Remote In-Memory NVM over RDMA",
    "doi": "https://doi.org/10.1145/3477004",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Qingfeng Zhuge; Hao Zhang; Edwin H.‐M. Sha; Rui Xu; Jun Liu; Shengyu Zhang",
    "corresponding_authors": "",
    "abstract": "Efficiently accessing remote file data remains a challenging problem for data processing systems. Development of technologies in non-volatile dual in-line memory modules (NVDIMMs), in-memory file systems, and RDMA networks provide new opportunities towards solving the problem of remote data access. A general understanding about NVDIMMs, such as Intel Optane DC Persistent Memory (DCPM), is that they expand main memory capacity with a cost of multiple times lower performance than DRAM. With an in-depth exploration presented in this paper, however, we show an interesting finding that the potential of NVDIMMs for high-performance, remote in-memory accesses can be revealed through careful design. We explore multiple architectural structures for accessing remote NVDIMMs in a real system using Optane DCPM, and compare the performance of various structures. Experiments are conducted to show significant performance gaps among different ways of using NVDIMMs as memory address space accessible through RDMA interface. Furthermore, we design and implement a prototype of user-level, in-memory file system, RIMFS, in the device DAX mode on Optane DCPM. By comparing against the DAX-supported Linux file system, Ext4-DAX, we show that the performance of remote reads on RIMFS over RDMA is 11.44 <?TeX $\\times$?> higher than that on a remote Ext4-DAX on average. The experimental results also show that the performance of remote accesses on RIMFS is maintained on a heavily loaded data server with CPU utilization as high as 90%, while the performance of remote reads on Ext4-DAX is significantly reduced by 49.3%, and the performance of local reads on Ext4-DAX is even more significantly reduced by 90.1%. The performance comparisons of writes exhibit the same trends.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3201078632",
    "type": "article"
  },
  {
    "title": "MaxTracker: Continuously Tracking the Maximum Computation Progress for Energy Harvesting ReRAM-based CNN Accelerators",
    "doi": "https://doi.org/10.1145/3477009",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Keni Qiu; Nicholas Jao; Kunyu Zhou; Yongpan Liu; Jack Sampson; Mahmut Kandemir; Vijaykrishnan Narayanan",
    "corresponding_authors": "",
    "abstract": "There is an ongoing trend to increasingly offload inference tasks, such as CNNs, to edge devices in many IoT scenarios. As energy harvesting is an attractive IoT power source, recent ReRAM-based CNN accelerators have been designed for operation on harvested energy. When addressing the instability problems of harvested energy, prior optimization techniques often assume that the load is fixed, overlooking the close interactions among input power, computational load, and circuit efficiency, or adapt the dynamic load to match the just-in-time incoming power under a simple harvesting architecture with no intermediate energy storage. Targeting a more efficient harvesting architecture equipped with both energy storage and energy delivery modules, this paper is the first effort to target whole system, end-to-end efficiency for an energy harvesting ReRAM-based accelerator. First, we model the relationships among ReRAM load power, DC-DC converter efficiency, and power failure overhead. Then, a maximum computation progress tracking scheme ( MaxTracker ) is proposed to achieve a joint optimization of the whole system by tuning the load power of the ReRAM-based accelerator. Specifically, MaxTracker accommodates both continuous and intermittent computing schemes and provides dynamic ReRAM load according to harvesting scenarios. We evaluate MaxTracker over four input power scenarios, and the experimental results show average speedups of 38.4%/40.3% (up to 51.3%/84.4%), over a full activation scheme (with energy storage) and order-of-magnitude speedups over the recently proposed (energy storage-less) ResiRCA technique. Furthermore, we also explore MaxTracker in combination with the Capybara reconfigurable capacitor approach to offer more flexible tuners and thus further boost the system performance.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3201177868",
    "type": "article"
  },
  {
    "title": "Regime Inference for Sound Floating-Point Optimizations",
    "doi": "https://doi.org/10.1145/3477012",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Robert A. Rabe; Anastasiia Izycheva; Eva Darulová",
    "corresponding_authors": "",
    "abstract": "Efficient numerical programs are required for proper functioning of many systems. Today’s tools offer a variety of optimizations to generate efficient floating-point implementations that are specific to a program’s input domain. However, sound optimizations are of an “all or nothing” fashion with respect to this input domain—if an optimizer cannot improve a program on the specified input domain, it will conclude that no optimization is possible. In general, though, different parts of the input domain exhibit different rounding errors and thus have different optimization potential. We present the first regime inference technique for sound optimizations that automatically infers an effective subdivision of a program’s input domain such that individual sub-domains can be optimized more aggressively. Our algorithm is general; we have instantiated it with mixed-precision tuning and rewriting optimizations to improve performance and accuracy, respectively. Our evaluation on a standard benchmark set shows that with our inferred regimes, we can, on average, improve performance by 65% and accuracy by 54% with respect to whole-domain optimizations.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3201278477",
    "type": "article"
  },
  {
    "title": "Model and Program Repair via SAT Solving",
    "doi": "https://doi.org/10.1145/3147426",
    "publication_date": "2017-12-07",
    "publication_year": 2017,
    "authors": "Paul C. Attie; Kinan Dak Albab; Mouhammad Sakr",
    "corresponding_authors": "",
    "abstract": "We consider the subtractive model repair problem : given a finite Kripke structure M and a CTL formula η, determine if M contains a substructure M ′ that satisfies η. Thus, M can be “repaired” to satisfy eta by deleting some transitions and states. We map an instance 〈 M ,η 〉 of model repair to a Boolean formula repair ( M ,η) such that 〈 M ,η 〉 has a solution iff repair ( M ,η) is satisfiable. Furthermore, a satisfying assignment determines which states and transitions must be removed from M to yield a model M ′ of η Thus, we can use any SAT solver to repair Kripke structures. Using a complete SAT solver yields a complete algorithm: it always finds a repair if one exists. We also show that CTL model repair is NP-complete. We extend the basic repair method in three directions: (1) the use of abstraction mappings, that is, repair a structure abstracted from M and then concretize the resulting repair to obtain a repair of M , (2) repair concurrent Kripke structures and concurrent programs: we use the pairwise method of Attie and Emerson to represent and repair the behavior of a concurrent program, as a set of “concurrent Kripke structures”, with only a quadratic increase in the size of the repair formula, and (3) repair hierarchical Kripke structures: we use a CTL formula to summarize the behavior of each “box,” and CTL deduction to relate the box formula with the overall specification.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1574191171",
    "type": "article"
  },
  {
    "title": "Synchronous programming of device drivers for global resource control in embedded operating systems",
    "doi": "https://doi.org/10.1145/2435227.2435235",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Nicolas Berthier; Florence Maraninchi; Laurent Mounier",
    "corresponding_authors": "",
    "abstract": "In embedded systems, controlling a shared resource like a bus, or improving a property like power consumption, may be hard to achieve when programming device drivers individually. In this article, we propose a global resource control approach, based on a centralized view of the devices' states. The solution we propose operates on the hardware/software interface. It involves a simple adaptation of the application level, to communicate with the hardware via a control layer . The control layer itself is built from a set of simple automata: the device drivers, whose states correspond to functional or power consumption modes, and a controller to enforce global properties. All these automata are programmed using a synchronous language, and compiled into a single piece of C code. We take as example the node of a sensor network. We explain the approach in details, demonstrate its use and benefits with an event-driven or multithreading operating system, and draw guidelines for its use in other contexts.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1990933273",
    "type": "article"
  },
  {
    "title": "Using memory profile analysis for automatic synthesis of pointers code",
    "doi": "https://doi.org/10.1145/2442116.2442118",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Yosi Ben-Asher; Nadav Rotem",
    "corresponding_authors": "",
    "abstract": "One of the main advantages of high-level synthesis (HLS) is the ability to synthesize circuits that can access multiple memory banks in parallel. Current HLS systems synthesize parallel memory references based on explicit array declarations in the source code. We consider the need to synthesize not only array references but also memory operations targeting pointers and dynamic data structures. This paper describes Automatic Memory Partitioning, a method for automatically synthesizing general data structures (arrays and pointers) into multiple memory banks for increased parallelism and performance. We use source code instrumentation to collect memory traces in order to detect linear memory access patterns. The memory traces are used to split data structures into disjoint memory regions and determine which segments may benefit from parallel memory access. We present an algorithm for allocating memory segments into multiple memory banks. Experiments show significant improvements in performance while conserving the number of memory banks.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2009628291",
    "type": "article"
  },
  {
    "title": "Nonutilization bounds and feasible regions for arbitrary fixed-priority policies",
    "doi": "https://doi.org/10.1145/1952522.1952524",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Xue Liu; Tarek Abdelzaher",
    "corresponding_authors": "",
    "abstract": "Prior research on schedulability bounds focused primarily on bounding utilization/ as a means to meet deadline constraints. Nontrivial bounds were found for a handful of scheduling policies in which utilization is directly related to the ability of the policy to meet deadlines. Examples include rate-monotonic, deadline-monotonic, and EDF scheduling. For most other scheduling policies, however, utilization is not correlated with schedulability. For example, shortest-job-first can miss deadlines at an arbitrarily low utilization. This raises the question of whether or not some other nonutilization-based metric might be more indicative of schedulability in those cases. This article answers the above question positively by extending the notion of schedulability bounds, in a uniform manner, to arbitrary (fixed) priorities and nonutilization metrics. We present a simple function that generates the schedulability metric to be bounded from the definition of a fixed-priority scheduling policy, and derive a nontrivial schedulability bound on that metric for aperiodic tasks. It is shown that the generated metrics and bounds are valid in that no deadline misses occur when these bounds are not violated. This result allows efficient real-time admission control to be performed in systems with arbitrary fixed-priority scheduling policies. As an example, we illustrate applying schedulability bounds for admission control to shortest-job-first and velocity-monotonic scheduling. While the proposed nonutilization bounds and feasible regions are derived for fixed-priority scheduling policies, the authors are investigating extensions of the results to dynamic-priority scheduling.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2013705016",
    "type": "article"
  },
  {
    "title": "Energy-aware code motion for GPU shader processors",
    "doi": "https://doi.org/10.1145/2539036.2539045",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Yi‐Ping You; Shen-Hong Wang",
    "corresponding_authors": "",
    "abstract": "Graphics processing units (GPUs) are now being widely adopted in system-on-a-chip designs, and they are often used in embedded systems for manipulating computer graphics or even for general-purpose computation. Energy management is of concern to both hardware and software designers. In this article, we present an energy-aware code-motion framework for a compiler to generate concentrated accesses to input and output (I/O) buffers inside a GPU. Our solution attempts to gather the I/O buffer accesses into clusters, thereby extending the time period during which the I/O buffers are clock or power gated. We performed experiments in which the energy consumption was simulated by incorporating our compiler-analysis and code-motion framework into an in-house compiler tool. The experimental results demonstrated that our mechanisms were effective in reducing the energy consumption of the shader processor by an average of 13.1% and decreasing the energy-delay product by 2.2%.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2029294561",
    "type": "article"
  },
  {
    "title": "Heuristic search for adaptive, defect-tolerant multiprocessor arrays",
    "doi": "https://doi.org/10.1145/2435227.2435240",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Vasileios Vasilikos; Georgios Smaragdos; Christos Strydis; Ioannis Sourdis",
    "corresponding_authors": "",
    "abstract": "In this article, new heuristic-search methods and algorithms are presented for enabling highly efficient and adaptive, defect-tolerant multiprocessor arrays. We consider systems where a homogeneous multiprocessor array lies on top of reconfigurable interconnects which allow the pipeline stages of the processors to be connected in all possible configurations. Considering the multiprocessor array partitioned in substitutable units at the granularity of pipeline stages, we employ a variety of heuristic-search methods and algorithms to isolate and replace defective units. The proposed heuristics are designed for off-line execution and aim at minimizing the performance overhead necessarily introduced to the array by the interconnects' latency. An empirical evaluation of the designed algorithms is then carried out, in order to assess the targeted problem and the efficacy of our approach. Our findings indicate this to be a NP-complete computational problem, however, our heuristic-search methods can achieve, for the problem sizes we exhaustively searched, 100% accuracy in finding the optimal solution among 10 19 possible candidates within 2.5 seconds. Alternatively, they can provide near-optimal solutions at an accuracy which consistently exceeds 70% (compared to the optimal solution) in only 10 -4 seconds.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2031192350",
    "type": "article"
  },
  {
    "title": "Variability-tolerant workload allocation for MPSoC energy minimization under real-time constraints",
    "doi": "https://doi.org/10.1145/2362336.2362338",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Francesco Paterna; Andrea Acquaviva; Francesco Papariello; Giuseppe Desoli; Luca Benini",
    "corresponding_authors": "",
    "abstract": "Sub-50nm CMOS technologies are affected by significant variability, which causes power and performance variations among nominally similar cores in MPSoC platforms. This undesired heterogeneity threatens execution predictability and energy efficiency. We propose two techniques to allocate sets of barrier-synchronized tasks. The first technique models allocation as an ILP and achieves optimal results, but requires an offline solver. The second technique adopts a two-stage heuristic approach, and it can be adapted to work online. We tested our approach on the virtual prototype of a next-generation industrial multicore platform. Experimental results demonstrate that our approach minimizes deadline violations while increasing energy efficiency.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2038884827",
    "type": "article"
  },
  {
    "title": "Designing best effort networks-on-chip to meet hard latency constraints",
    "doi": "https://doi.org/10.1145/2485984.2485996",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Ciprian Seiculescu; Dara Rahmati; Srinivasan Murali; Hamid Sarbazi‐Azad; Luca Benini; Giovanni De Micheli",
    "corresponding_authors": "",
    "abstract": "Many classes of applications require Quality of Service (QoS) guarantees from the system interconnect. In Networks-on-Chip (NoC) QoS guarantees usually translate into bandwidth and latency constraints for the traffic flows and require hardware support in the NoC fabric and its interfaces. In this article we present a novel NoC synthesis framework to automatically build networks that meet hard latency constraints of end-to-end traffic streams without requiring specialized hardware for the network components. The hard latency constraints are met by carefully designing the NoC topology and selecting the appropriate routes for flow using lean best-effort network components. We perform experiments on several System on Chip (SoC) benchmarks. We compared against a topology synthesis method with no support for real-time constraints and we show that the proposed method can produce topologies that can meet significantly tighter worst case latency constraints (on average 44%). We also show that the tightest worst case latency can be provided with little overhead on power consumption (on average 8.5%).",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2039968196",
    "type": "article"
  },
  {
    "title": "A lifetime aware buffer assignment method for streaming applications on DRAM/PRAM hybrid memory",
    "doi": "https://doi.org/10.1145/2435227.2435232",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Dae‐Young Lee; Hyunok Oh",
    "corresponding_authors": "",
    "abstract": "This article proposes a lifetime aware buffer assignment method for streaming applications like multimedia specified in a synchronous dataflow (SDF) graph on a DRAM/PRAM hybrid memory in which the endurance of PRAM is limited. We determine whether buffers are assigned to DRAM or PRAM to minimize the writing frequency of PRAM. To solve the problems, we formulate them using Answer Set Programming. Experimental results show that the proposed approach increases the PRAM lifetime by 63% compared with no optimization, and shows the tradeoff between PRAM and DRAM size to guarantee a lifetime constraint.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2041362764",
    "type": "article"
  },
  {
    "title": "Partitioning sporadic task systems upon memory-constrained multiprocessors",
    "doi": "https://doi.org/10.1145/2442116.2442128",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Sanjoy Baruah",
    "corresponding_authors": "Sanjoy Baruah",
    "abstract": "Most prior theoretical research on real-time partitioning algorithms for multiprocessor platforms has focused on ensuring that the cumulative computing requirements of the tasks assigned to each processor does not exceed the processor's processing power. However, computing capacity is often not the only limiting resource: on many multiprocessor platforms each individual computing unit may have limited amounts of multiple additional types of resources (such as local memory) in addition to having limited processing power. We present algorithms for partitioning a collection of sporadic tasks, each characterized by a WCET, a relative deadline, and a period, upon a multiprocessor platform in a manner that is cognizant of such additional constraints as well as the processing capacity constraints.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2042062484",
    "type": "article"
  },
  {
    "title": "A goal-oriented programming framework for grid sensor networks with reconfigurable embedded nodes",
    "doi": "https://doi.org/10.1145/2362336.2362346",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Varun Subramanian; Michael Gilberti; Alex Doboli; Dan Pescaru",
    "corresponding_authors": "",
    "abstract": "Cyber-physical systems (CPS) are large, distributed embedded systems integrated with various sensors and actuators. CPS are rapidly emerging as an important computing paradigm in many modern applications. Developing CPS applications is currently challenging due to the sheer complexity of the related functionality as well as the broad set of constraints and unknowns that must be tackled during operation. This article presents a novel high-level programming model and the supporting optimization and middleware routines for executing applications on physically-distributed networks of reconfigurable embedded systems. The proposed model describes the optimization goals, sensing inputs, actuation outputs, events, and constraints of an application, while leaving to the compiler and execution environment the task of optimally implementing the derived functionality. Experimental results discuss the additional performance optimizations enabled by the proposed model, and the timing and power consumption of the middleware routines, and present a temperature monitoring application implemented on a network of reconfigurable, embedded processors.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2073742390",
    "type": "article"
  },
  {
    "title": "Automated generation of polyhedral process networks from affine nested-loop programs with dynamic loop bounds",
    "doi": "https://doi.org/10.1145/2536747.2536750",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Dmitry Nadezhkin; Hristo N. Nikolov; Todor Stefanov",
    "corresponding_authors": "",
    "abstract": "The Process Networks (PNs) is a suitable parallel model of computation (MoC) used to specify embedded streaming applications in a parallel form facilitating the efficient mapping onto embedded parallel execution platforms. Unfortunately, specifying an application using a parallel MoC is a very difficult and highly error-prone task. To overcome the associated difficulties, we have developed the pn compiler, which derives specific Polyhedral Process Networks (PPN) parallel specifications from sequential static affine nested loop programs (SANLPs). However, there are many applications, for example, multimedia applications (MPEG coders/decoders, smart cameras, etc.) that have adaptive and dynamic behavior which cannot be expressed as SANLPs. Therefore, in order to handle dynamic multimedia applications, in this article we address the important question whether we can relax some of the restrictions of the SANLPs while keeping the ability to perform compile-time analysis and to derive PPNs. Achieving this would significantly extend the range of applications that can be parallelized in an automated way. The main contribution of this article is a first approach for automated translation of affine nested loop programs with dynamic loop bounds into input-output equivalent Polyhedral Process Networks. In addition, we present a method for analyzing the execution overhead introduced in the PPNs derived from programs with dynamic loop bounds. The presented automated translation approach has been evaluated by deriving a PPN parallel specification from a real-life application called Low Speed Obstacle Detection (LSOD) used in the smart cameras domain. By executing the derived PPN, we have obtained results which indicate that the approach we present in this article facilitates efficient parallel implementations of sequential nested loop programs with dynamic loop bounds. That is, our approach reveals the possible parallelism available in such applications, which allows for the utilization of multiple cores in an efficient way.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2080852813",
    "type": "article"
  },
  {
    "title": "Modeling towards incremental early analyzability of networked avionics systems using virtual integration",
    "doi": "https://doi.org/10.1145/2362336.2362348",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Min-Young Nam; Kyungtae Kang; Rodolfo Pellizzoni; Kyung‐Joon Park; Jung-Eun Kim; Lui Sha",
    "corresponding_authors": "",
    "abstract": "With the advance of hardware technology, more features are incrementally added to already existing networked systems. Avionics has a stronger tendency to use preexisting applications due to its complexity and scale. As resource sharing becomes intense among the network and the computing modules, it has become a difficult task for the system designer to make confident architectural decisions even for incremental changes. Providing a tailored environment to model and analyze incremental changes requires a combination of software tools and hardware support. We have built a virtual integration tool called ASIIST which can provide a worst-case end-to-end latency of data that is sent through a network and the internal bus architecture of the end-systems. Also, we have devised a new real-time switching algorithm which guarantees the worst-case network delay of preexisting network traffic under feasible conditions. With the real-time switch support, ASIIST can provide an early modularized analysis of the end-to-end latency to make architectural design choices and incremental changes easier for the user.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2088502728",
    "type": "article"
  },
  {
    "title": "Analyzing an embedded sensor with timed automata in uppaal",
    "doi": "https://doi.org/10.1145/2539036.2539040",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Timothy Bourke; Arcot Sowmya",
    "corresponding_authors": "",
    "abstract": "An infrared sensor is modeled and analyzed in Uppaal. The sensor typifies the sort of component that engineers regularly integrate into larger systems by writing interface hardware and software. In all, three main models are developed. In the first model, the timing diagram of the sensor is interpreted and modeled as a timed safety automaton. This model serves as a specification for the complete system. A second model that emphasizes the separate roles of driver and sensor is then developed. It is validated against the timing diagram model using an existing construction that permits the verification of timed trace inclusion, for certain models, by reachability analysis (i.e., model checking). A transmission correctness property is also stated by means of an auxiliary automaton and shown to be satisfied by the model. A third model is created from an assembly language driver program, using a direct translation from the instruction set of a processor with simple timing behavior. This model is validated against the driver component of the second timing diagram model using the timed trace inclusion validation technique. The approach and its limitations offer insight into the nature and challenges of programming in real time.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2118069185",
    "type": "article"
  },
  {
    "title": "A novel low-power embedded object recognition system working at multi-frames per second",
    "doi": "https://doi.org/10.1145/2435227.2435229",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Antonis Nikitakis; Savvas Papaioannou; Ioannis Papaefstathiou",
    "corresponding_authors": "",
    "abstract": "One very important challenge in the field of multimedia is the implementation of fast and detailed Object Detection and Recognition systems. In particular, in the current state-of-the-art mobile multimedia systems, it is highly desirable to detect and locate certain objects within a video frame in real time. Although a significant number of Object Detection and Recognition schemes have been developed and implemented, triggering very accurate results, the vast majority of them cannot be applied in state-of-the-art mobile multimedia devices; this is mainly due to the fact that they are highly complex schemes that require a significant amount of processing power, while they are also time consuming and very power hungry. In this article, we present a novel FPGA-based embedded implementation of a very efficient object recognition algorithm called Receptive Field Cooccurrence Histograms Algorithm (RFCH). Our main focus was to increase its performance so as to be able to handle the object recognition task of today's highly sophisticated embedded multimedia systems while keeping its energy consumption at very low levels. Our low-power embedded reconfigurable system is at least 15 times faster than the software implementation on a low-voltage high-end CPU, while consuming at least 60 times less energy. Our novel system is also 88 times more energy efficient than the recently introduced low-power multi-core Intel devices which are optimized for embedded systems. This is, to the best of our knowledge, the first system presented that can execute the complete complex object recognition task at a multi frame per second rate while consuming minimal amounts of energy, making it an ideal candidate for future embedded multimedia systems.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2132702645",
    "type": "article"
  },
  {
    "title": "Sequence Control of Essential Siphons for Deadlock Prevention in Petri Nets",
    "doi": "https://doi.org/10.1145/2406336.2406344",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Zhiming Zhang; Weimin Wu",
    "corresponding_authors": "",
    "abstract": "Deadlock prevention is crucial to the modeling of flexible manufacturing systems. In the Petri net framework, deadlock prevention is often addressed by siphon-based control (SC) policies. Recent research results show that SC methods can avoid full siphon enumeration by using mixed integer programming (MIP) to greatly increase the computational efficiency so that it can be applied in large systems in computable time. Besides, maximally permissive control solutions can be obtained by means of iterative siphon control (ISC) approaches and MIP. Then the remaining problems are redundancy and MIP iterations. Redundant controllers make the closed-loop system more complicated and each MIP iteration increases the total computational time. This article proposes a revised ISC deadlock prevention policy which can achieve better results than the other reported methods in terms of redundancy and MIP iterations while maintaining the maximal permissiveness. Several benchmark examples are provided to illustrate the proposed approach and to be compared with the other reported methods.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2136977963",
    "type": "article"
  },
  {
    "title": "Dynamic Data-Cache Locking for Minimizing the WCET of a Single Task",
    "doi": "https://doi.org/10.1145/2994602",
    "publication_date": "2017-01-02",
    "publication_year": 2017,
    "authors": "Wenguang Zheng; Hui Wu",
    "corresponding_authors": "",
    "abstract": "Caches have been widely used in modern embedded processors to bridge the increasing speed gap between processors and off-chip memory. In real-time embedded systems, computing the Worst-Case Execution Time (WCET) of a task is essential for the task scheduler to construct a valid schedule for a task set. Unfortunately, caches make it much harder to compute the WCET of a task. Cache locking has been proposed to alleviate the timing unpredictability problem caused by caches. In this article, we investigate the following WCET-aware data-cache locking problem for a single task. Given a task, select a set of variables as locked cache contents such that the WCET of the task is minimized. We propose two dynamic full cache-locking approaches. The first formulates the problem as a global Integer Linear Programming (ILP) problem that simultaneously selects a minimum set of memory blocks of variables as locked cache contents and allocates them to the data cache. The second iteratively constructs a subgraph of the Control Flow Graph (CFG) of the task in which the lengths of all the paths are close to the longest path length, uses an ILP formulation to select a minimum set of memory blocks of variables in the subgraph as locked cache contents, and allocates the selected memory blocks to the data cache. We also propose two novel, efficient data-cache allocation algorithms for the global ILP approach and the iterative ILP approach, respectively. We have implemented both approaches and compared them with two state-of-the-art approaches, the longest path-based dynamic cache-locking approach and the static WCET analysis approach without cache locking by using a set of benchmarks from the Mälardalen WCET benchmark suite, SNU real-time benchmarks, and Powerstone benchmarks. Compared to the static WCET analysis approach, the average WCET improvements of the first approach range between 11.4% and 26.4%. Compared to the longest path--based, dynamic cache-locking approach, the average WCET improvements of the first approach range between 5.0% and 15.4%. The second approach performs slightly better than the first approach.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2567721824",
    "type": "article"
  },
  {
    "title": "From a Formalized Parallel Action Language to Its Efficient Code Generation",
    "doi": "https://doi.org/10.1145/2990195",
    "publication_date": "2017-01-16",
    "publication_year": 2017,
    "authors": "Ivan Llopard; Christian Fabre; Albert Cohen",
    "corresponding_authors": "",
    "abstract": "Modeling languages propose convenient abstractions and transformations to handle the complexity of today’s embedded systems. Based on the formalism of the Hierarchical State Machine, they enable the expression of hierarchical control parallelism. However, they face two important challenges when it comes to modeling data-intensive applications: no unified approach that also accounts for data-parallel actions and no effective code optimization and generation flows. We propose a modeling language extended with parallel action semantics and hierarchical indexed-state machines suitable for computationally intensive applications. Together with its formal semantics, we present an optimizing model compiler aiming for the generation of efficient data-parallel implementations.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2572499666",
    "type": "article"
  },
  {
    "title": "Corrections to and Discussion of “Implementation and Evaluation of Mixed-criticality Scheduling Approaches for Sporadic Tasks”",
    "doi": "https://doi.org/10.1145/2974020",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Tom Fleming; Huang-Ming Huang; Alan Burns; Chris Gill; Sanjoy Baruah; Chenyang Lu",
    "corresponding_authors": "",
    "abstract": "The AMC-IA mixed-criticality scheduling analysis was proposed as an improvement to the AMC-MAX adaptive mixed-criticality scheduling analysis. However, we have identified several necessary corrections to the AMC-IA analysis. In this article, we motivate and describe those corrections, and discuss and illustrate why the corrected AMC-IA analysis cannot be shown to outperform AMC-MAX.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2619812488",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3087913",
    "publication_date": "2017-07-07",
    "publication_year": 2017,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2729866229",
    "type": "editorial"
  },
  {
    "title": "Serial Arithmetic Strategies for Improving FPGA Throughput",
    "doi": "https://doi.org/10.1145/2996459",
    "publication_date": "2017-07-07",
    "publication_year": 2017,
    "authors": "Aaron Landy; Greg Stitt",
    "corresponding_authors": "",
    "abstract": "Serial arithmetic has been shown to offer attractive advantages in area for field-programmable gate array (FPGA) datapaths but suffers from a significant reduction in throughput compared to traditional bit-parallel designs. In this work, we perform a performance and trade-off analysis that counterintuitively shows that, despite the decreased throughput of individual serial operators, replication of serial arithmetic can provide a 2.1 × average increase in throughput compared to bit-parallel pipelines for common FPGA applications. We complement this analysis with a novel SerDes architecture that enables existing FPGA pipelines to be replaced with serial logic with potentially higher throughput. We also present a serialized sliding-window architecture that improves average throughput 2.4 × compared to existing bit-parallel work.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2731866430",
    "type": "article"
  },
  {
    "title": "Seamless Vision-assisted Placement Calibration for Wearable Inertial Sensors",
    "doi": "https://doi.org/10.1145/3023364",
    "publication_date": "2017-07-07",
    "publication_year": 2017,
    "authors": "Jian Wu; Roozbeh Jafari",
    "corresponding_authors": "",
    "abstract": "Wearable inertial devices are being widely used in the applications of activity tracking, health care, and professional sports, and their usage is on a rapid rise. Signal processing algorithms for these devices are often designed to work with a known location of the wearable sensor on the body. However, in reality, the wearable sensor may be worn at different body locations due to the user's preference or unintentional misplacement. The calibration of the sensor location is important to ensure that the algorithms operate correctly. In this article, we propose an auto-calibration technique for determining the location of wearables on the body by fusing the 3-axis accelerometer data from the devices and three-dimensional camera (i.e., Kinect) information obtained from the environment. The automatic calibration is achieved by a cascade decision-tree-based classifier on top of the minimum least-squares errors obtained by solving Wahba's problem, operating on heterogeneous sensors. The core contribution of our work is that there is no extra burden on the user as a result of this technique. The calibration is done seamlessly, leveraging sensor fusion in an Internet-of-Things setting opportunistically when the user is present in front of an environmental camera performing arbitrary movements. Our approach is evaluated with two different types of movements: simple actions (e.g., sit-to-stand or picking up phone) and complicated tasks (e.g., cooking or playing basketball), yielding 100% and 82.56% recall for simple actions and for complicated tasks, respectively, in determining the correct location of sensors.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2732886465",
    "type": "article"
  },
  {
    "title": "On The Design and Application of Thermal Isolation Servers",
    "doi": "https://doi.org/10.1145/3126512",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Rehan Ahmed; Pengcheng Huang; max Millen; Lothar Thiele",
    "corresponding_authors": "",
    "abstract": "Recently, there has been an increasing trend towards executing real-time applications on multi-core platforms. However, this complicates the design problem, as applications running on different cores can interfere due to shared resources and mediums. In this paper, we focus on thermal interference, where a given task (τ 1 ) heats the processor, resulting in reduced service (due to Dynamic Thermal Management (DTM)) to another task (τ 2 ). In real-time domain, where tasks have deadline constraints, thermal interference is a substantial problem as it directly impacts the Worst Case Execution Time (WCET) of the effected application (τ 2 ). The problem exacerbates as we move to mixed-criticality systems, where the criticality of τ 2 may be greater than the criticality of τ 1 , complicating the certification process. In this paper, we propose a server based strategy (Thermal Isolation Server (TI Server)) which can be used to avoid thermal interference of applications. We also present a heuristic to design TI Servers to meet the timing constraints of all tasks and the thermal constraints of the system. TI Servers are time/space composable, and can be applied to a variety of task models. We also evaluate TI Servers on a hardware test-bed for validation purposes.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2756903735",
    "type": "article"
  },
  {
    "title": "Complete and Practical Universal Instruction Selection",
    "doi": "https://doi.org/10.1145/3126528",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Gabriel Hjort Blindell; Mats Carlsson; Roberto Castañeda Lozano; Christian Schulte",
    "corresponding_authors": "",
    "abstract": "In code generation, instruction selection chooses processor instructions to implement a program under compilation where code quality crucially depends on the choice of instructions. Using methods from combinatorial optimization, this paper proposes an expressive model that integrates global instruction selection with global code motion. The model introduces (1) handling of memory computations and function calls, (2) a method for inserting additional jump instructions where necessary, (3) a dependency-based technique to ensure correct combinations of instructions, (4) value reuse to improve code quality, and (5) an objective function that reduces compilation time and increases scalability by exploiting bounding techniques. The approach is demonstrated to be complete and practical, competitive with LLVM, and potentially optimal (w.r.t. the model) for medium-sized functions. The results show that combinatorial optimization for instruction selection is well-suited to exploit the potential of modern processors in embedded systems.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2760168827",
    "type": "article"
  },
  {
    "title": "Testing Programs with Contextual Unfoldings",
    "doi": "https://doi.org/10.1145/2810000",
    "publication_date": "2017-11-22",
    "publication_year": 2017,
    "authors": "Kari Kähkönen; Keijo Heljanko",
    "corresponding_authors": "",
    "abstract": "In this article, we present a new algorithm that combines contextual unfoldings and dynamic symbolic execution to systematically test multithreaded programs. The approach uses symbolic execution to limit the number of input values and unfoldings to thus limit the number of thread interleavings that are needed to cover reachable local states of threads in the program under test. We show that the use of contextual unfoldings allows interleavings of threads to be succinctly represented. This can in some cases lead to a substantial reduction in the number of needed test executions when compared to previous approaches.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2770783280",
    "type": "article"
  },
  {
    "title": "SCEst",
    "doi": "https://doi.org/10.1145/3063129",
    "publication_date": "2017-12-07",
    "publication_year": 2017,
    "authors": "Steven Smyth; Christian Motika; Karsten Rathlev; Reinhard von Hanxleden; Michael Mendler",
    "corresponding_authors": "",
    "abstract": "The synchronous language Esterel provides determinate concurrency for reactive systems. Determinacy is ensured by the signal coherence rule , which demands that signals have a stable value throughout one reaction cycle. This is natural for the original application domains of Esterel, such as controller design and hardware development; however, it is unnecessarily restrictive for software development. Sequentially Constructive Esterel (SCEst) overcomes this restriction by allowing values to change instantaneously, as long as determinacy is still guaranteed, adopting the recently proposed Sequentially Constructive model of computation. SCEst is grounded in the minimal Sequentially Constructive Language ( scl ), which also provides a novel semantic definition and compilation approach for Esterel.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2771782676",
    "type": "article"
  },
  {
    "title": "Low Overhead CS-Based Heterogeneous Framework for Big Data Acceleration",
    "doi": "https://doi.org/10.1145/3092944",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "Amey Kulkarni; Colin Shea; Tahmid Abtahi; Houman Homayoun; Tinoosh Mohsenin",
    "corresponding_authors": "",
    "abstract": "Big data processing on hardware gained immense interest among the hardware research community to take advantage of fast processing and reconfigurability. Though the computation latency can be reduced using hardware, big data processing cost is dominated by data transfers. In this article, we propose a low overhead framework based on compressive sensing (CS) to reduce data transfers up to 67% without affecting signal quality. CS has two important kernels: “sensing” and “reconstruction.” In this article, we focus on CS reconstruction is using orthogonal matching pursuit (OMP) algorithm. We implement the OMP CS reconstruction algorithm on a domain-specific PENC many-core platform and a low-power Jetson TK1 platform consisting of an ARM CPU and a K1 GPU. Detailed performance analysis of OMP algorithm on each platform suggests that the PENC many-core platform has 15× and 18× less energy consumption and 16× and 8× faster reconstruction time as compared to the low-power ARM CPU and K1 GPU, respectively. Furthermore, we implement the proposed CS-based framework on heterogeneous architecture, in which the PENC many-core architecture is used as an “accelerator” and processing is performed on the ARM CPU platform. For demonstration, we integrate the proposed CS-based framework with a hadoop MapReduce platform for a face detection application. The results show that the proposed CS-based framework with the PENC many-core as an accelerator achieves a 26.15% data storage/transfer reduction, with an execution time and energy consumption overhead of 3.7% and 0.002%, respectively, for 5,000 image transfers. Compared to the CS-based framework implementation on the low-power Jetson TK1 ARM CPU+GPU platform, the PENC many-core implementation is 2.3× faster for the image reconstruction part, while achieving 29% higher performance and 34% better energy efficiency for the complete face detection application on the Hadoop MapReduce platform.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2772478829",
    "type": "article"
  },
  {
    "title": "Fault Injection for Test-Driven Development of Robust SoC Firmware",
    "doi": "https://doi.org/10.1145/3092943",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "Petra R. Maier; Veit B. Kleeberger; Daniel Mueller-Gritschneder; Ulf Schlichtmann",
    "corresponding_authors": "",
    "abstract": "Robustness against errors in hardware must be considered from the very beginning of safety-critical system-on-chip firmware design. Therefore, we present fault injection for test-driven development (TDD) of robust firmware. As TDD is based on instant feedback to the designer, fault injection must execute within few minutes. In contrast to state-of-the-art approaches, we avoid long simulation scenarios and runtimes by injecting faults at the unit level and utilizing host-compiled simulation. Further, three static bit-level analyses of firmware source code and hardware specification reduce the fault set significantly. This accelerates fault injection by several orders of magnitude and enables robustness-aware TDD.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2773286854",
    "type": "article"
  },
  {
    "title": "Evaluating the Design of a VLIW Processor for Real-Time Systems",
    "doi": "https://doi.org/10.1145/2889490",
    "publication_date": "2016-03-07",
    "publication_year": 2016,
    "authors": "Renan Augusto Starke; Andreu Carminati; Rômulo Silva de Oliveira",
    "corresponding_authors": "",
    "abstract": "Nowadays, many real-time applications are very complex and as the complexity and the requirements of those systems become more demanding, more hardware processing capacity is necessary. Unfortunately, the correct functioning of real-time systems depends not only on the logically correct response but also on the time when it is produced. General-purpose processor design fails to deliver analyzability due to their nondeterministic behavior caused by the use of cache memories, dynamic branch prediction, speculative execution, and out-of-order pipelines. In this article, we investigate the pipeline performance of Very Long Instruction Word (VLIW) architectures for real-time systems with an in-order pipeline considering Worst-Case Execution Time (WCET) performance. Techniques on obtaining the WCET of VLIW machines are also considered and we make a quantification on how important are hardware techniques such as static branch prediction, predication, and pipeline speed of complex operations such as memory access and multiplication for high-performance real-time systems. The memory hierarchy is out of the scope of this article and we used a classic deterministic structure formed by a direct mapped instruction cache and a data scratchpad memory. A VLIW prototype was implemented in VHDL from scratch considering the HP VLIW ST231 ISA. We also show some compiler insights and we use a representative subset of the Mälardalen’s WCET benchmarks for validation and performance quantification.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2299668876",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2901293",
    "publication_date": "2016-04-21",
    "publication_year": 2016,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2341502950",
    "type": "editorial"
  },
  {
    "title": "Software-Based Selective Validation Techniques for Robust CGRAs Against Soft Errors",
    "doi": "https://doi.org/10.1145/2843943",
    "publication_date": "2016-01-28",
    "publication_year": 2016,
    "authors": "Yohan Ko; Ji-Hoon Kang; Jongwon Lee; Yong‐Joo Kim; Joonhyun Kim; Hwisoo So; Kyoungwoo Lee; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "Coarse-Grained Reconfigurable Architectures (CGRAs) are drawing significant attention since they promise both performances with parallelism and flexibility with reconfiguration. Soft errors (or transient faults) are becoming a serious design concern in embedded systems including CGRAs since the soft error rate is increasing exponentially as technology is scaling. A recently proposed software-based technique with TMR (Triple Modular Redundancy) implemented on CGRAs incurs extreme overheads in terms of runtime and energy consumption mainly due to expensive voting mechanisms for the outputs from the triplication of every operation. In this article, we propose selective validation mechanisms for efficient modular redundancy techniques in the datapaths on CGRAs. Our techniques selectively validate the results at synchronous operations rather than every operation in order to reduce the expensive performance overhead from the validation mechanism. We also present an optimization technique to further improve the runtime and the energy consumption by minimizing synchronous operations where a validating mechanism needs to be applied. Our experimental results demonstrate that our selective validation-based TMR technique with our optimization on CGRAs can improve the runtime by 41.0% and the energy consumption by 26.2% on average over benchmarks as compared to the recently proposed software-based TMR technique with the full validation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2342088852",
    "type": "article"
  },
  {
    "title": "Correlation-Aware Probabilistic Timing Analysis for the Dynamic Segment of FlexRay",
    "doi": "https://doi.org/10.1145/2870635",
    "publication_date": "2016-05-23",
    "publication_year": 2016,
    "authors": "Bogdan Tanasă; Unmesh D. Bordoloi; Petru Eles; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "We propose an analytical framework for probabilistic timing analysis of the event-triggered Dynamic segment of the FlexRay communication protocol. Specifically, our framework computes the Deadline Miss Ratio of each message. The core problem is formulated as a Mixed Integer Linear Program (MILP). Given the intractability of the problem, we also propose several techniques that help to mitigate the running times of our tool. This includes the re-engineering of the problem to run it on GPUs as well as reformulating the MILP itself. Most importantly, we also show how our framework can handle correlations between the queuing events of messages. This is challenging because one cannot apply the convolution operator in the same way as in the case of independent queuing events.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2401501475",
    "type": "article"
  },
  {
    "title": "FE-SViT",
    "doi": "https://doi.org/10.1145/2930669",
    "publication_date": "2016-08-02",
    "publication_year": 2016,
    "authors": "Kai Xi; Jiankun Hu; B. V. K. Vijaya Kumar",
    "corresponding_authors": "",
    "abstract": "As a promising bio-cryptographic technique, the fuzzy extractor seamlessly binds biometrics and cryptography for template protection and key generation. However, most existing methods hardly solve the following issues simultaneously: (1) Fingerprint registration, (2) Verification accuracy, (3) Security strength, and (4) Computational efficiency. In this article, we introduce a bio-crypto-oriented fingerprint verification scheme - Selective Vertex-indexed Triangulation (SViT) which maps minutia global topology to local triangulation with minimum information loss. Then, a SViT-based fuzzy extractor framework (FE-SViT) is proposed and high verification accuracy is achieved. The FE-SViT is highly parallelizable and efficient which makes it suitable for embedded devices.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2478226929",
    "type": "article"
  },
  {
    "title": "An Efficient Technique of Application Mapping and Scheduling on Real-Time Multiprocessor Systems for Throughput Optimization",
    "doi": "https://doi.org/10.1145/2950051",
    "publication_date": "2016-08-02",
    "publication_year": 2016,
    "authors": "Weichen Liu; Chunhua Xiao",
    "corresponding_authors": "",
    "abstract": "Multiprocessor systems are becoming ubiquitous in today’s embedded systems design. In this article, we address the problem of mapping an application represented by a Homogeneous Synchronous Dataflow (HSDF) graph onto a real-time multiprocessor platform with the objective of maximizing total throughput. We propose that the optimal solution to the problem is composed of three components: actor-to-processor mapping, retiming, and actor ordering on each processor. The entire problem is systematically modeled into a Boolean Satisfiability (SAT) problem such that the optimal solution can be guaranteed theoretically. In order to explore the vast solution space more efficiently, we develop a specific HSDF theory solver based on the special characteristics of the timed HSDF, and integrate it into the general search framework of the SAT solver. Two alternative integration methods based on branch-and-bound are presented to achieve early branch pruning in the search space; thus, the scalability is greatly improved. Extensive performance evaluation on synthetic examples and a case study on the realistic H.264 Video Decoder show that our approach provides as much as 76.9% throughput improvement, and is scalable to industry-sized applications.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2487889324",
    "type": "article"
  },
  {
    "title": "JOM",
    "doi": "https://doi.org/10.1145/2915916",
    "publication_date": "2016-08-02",
    "publication_year": 2016,
    "authors": "Chin-Hsien Wu; Syuan-An Chen",
    "corresponding_authors": "",
    "abstract": "In the storage systems of NAND flash memory, an intermediate software called a Flash Translation Layer (FTL) is adopted to hide the characteristics of NAND flash memory and provide efficient management for NAND flash memory. Current flash translation layers can be classified into a page-mapping FTL, a block-mapping FTL, and a hybrid-mapping FTL. In order to utilize the advantages of the page-mapping FTL and the block-mapping FTL, the hybrid-mapping FTL is proposed to store data to the appropriate mapping mechanism by switching the mapping information between the page-mapping mechanism and the block-mapping mechanism. In the article, we propose a joint operation mechanism to rethink the advantages of the page-mapping FTL, the block-mapping FTL, and the hybrid-mapping FTL. With the joint operation mechanism, a flash translation layer can consider the main memory requirements, improve the system performance, and reduce the garbage collection overhead. The experimental results show that the proposed joint operation mechanism can achieve the goal under realistic workloads and benchmarks.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2506188977",
    "type": "article"
  },
  {
    "title": "Space-Efficient Index Scheme for PCM-Based Multiversion Databases in Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/2950060",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Yuan-Hung Kuan; Yuan-Hao Chang; Tseng‐Yi Chen; Po‐Chun Huang; Alfred K. Lam",
    "corresponding_authors": "",
    "abstract": "In this article, we study the indexing problem of using PCM as the storage medium for embedded multiversion databases in cyber-physical systems (CPSs) . Although the multiversion B + -tree (MVBT) index has been shown to be efficient in managing multiple versions of data items in a database, MVBT is designed for databases residing in traditional block-oriented storage devices. It can have serious performance problems when the databases are on phase-change memory (PCM) . Since the embedded multiversion database in CPSs may have limited storage space and are update intensive, to resolve the problems of MVBT of lack of space efficiency and heavy update cost, we propose a new index scheme, called space-efficient multiversion index (SEMI) , to enhance the space utilization and access performance in serving various types of queries. In SEMI, since the number of keys in the database may be small, instead of using a B -tree index, we propose to use a binary-search tree to organize the index keys. Furthermore, multiple versions of the same data item may be stored consecutively and indexed by a single entry to maximize the space utilization and at the same time to enhance the performance in serving version-range queries. Analytical studies have been conducted on SEMI, and a series of experiments have been performed to evaluate its performance as compared with MVBT under different workloads. The experimental results have demonstrated that SEMI can achieve very high space utilization and has better performance in serving update transactions and range queries as compared with MVBT.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2529867800",
    "type": "article"
  },
  {
    "title": "ScorePlus",
    "doi": "https://doi.org/10.1145/2964200",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Song Tan; Wen‐Zhan Song; Steve Yothment; Junjie Yang; Lang Tong",
    "corresponding_authors": "",
    "abstract": "We present ScorePlus, a software-hardware hybrid and federated experiment environment for Smart Grid. ScorePlus incorporates both a software emulator and hardware testbed, such that they all follow the same architecture, and the same Smart Grid application program can be tested on either of them without any modification; ScorePlus provides a federated environment such that multiple software emulators and hardware testbeds at different locations are able to connect and form a unified Smart Grid system; ScorePlus software is encapsulated as a resource plugin in the OpenStack cloud computing platform, such that it supports massive deployments with large-scale test cases in cloud infrastructure.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2531764821",
    "type": "article"
  },
  {
    "title": "Differential Fault Attack on ITUbee Block Cipher",
    "doi": "https://doi.org/10.1145/2967610",
    "publication_date": "2016-12-19",
    "publication_year": 2016,
    "authors": "Shan Fu; Guoai Xu; Juan Pan; Zongyue Wang; An Wang",
    "corresponding_authors": "",
    "abstract": "Differential Fault Attack (DFA) is a powerful cryptanalytic technique to retrieve secret keys by exploiting the faulty ciphertexts generated during encryption procedure. This article proposes a novel DFA attack that is effective on ITUbee, a software-oriented block cipher for resource-constrained devices. Different from other DFA, our attack makes use of not only faulty values, but also differences between fault-free intermediate values corresponding to 2 plaintexts, which combine traditional differential analysis with DFA. The possible injection positions with different number of faults are discussed. The most efficient attack takes 2 25 round function operations with 4 faults, which is achieved in a few seconds on a PC.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2565697401",
    "type": "article"
  },
  {
    "title": "Preserving Partial-Order Runs in Parametric Time Petri Nets",
    "doi": "https://doi.org/10.1145/3012283",
    "publication_date": "2016-12-19",
    "publication_year": 2016,
    "authors": "Étienne André; Thomas Chatain; César Rodríguez",
    "corresponding_authors": "",
    "abstract": "Parameter synthesis for timed systems aims at deriving parameter valuations satisfying a given property. In this article, we target concurrent systems. We use partial-order semantics for parametric time Petri nets as a way to both cope with the well-known state-space explosion due to concurrency and significantly enhance the result of an existing synthesis algorithm. Given a reference parameter valuation, our approach synthesizes other valuations preserving the partial-order executions of the reference parameter valuation. We show the applicability of our approach using a tool applied to asynchronous circuits.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2567094285",
    "type": "article"
  },
  {
    "title": "Testing Preorders for dMTS",
    "doi": "https://doi.org/10.1145/2984641",
    "publication_date": "2016-12-19",
    "publication_year": 2016,
    "authors": "Ferenc Bujtor; Lev Sorokin; Walter Vogler",
    "corresponding_authors": "",
    "abstract": "Testing preorders on component specifications ensure that replacing a specification by a refined one does not introduce unwanted behavior in an overall system. Considering deadlocks as unwanted, the preorder can be characterized by a failure semantics on Labeled Transition Systems (LTSs). In previous work, we have generalized this to Modal Transition Systems (MTSs) with a new, MTS-specific testing idea. In the present article, we generalize this idea further to DMTS, a subclass of disjunctive MTSs. On the one hand, the testing preorder can be characterized by the same failure semantics, and dMTS have no additional expressivity in our setting. On the other hand, the technical treatment is significantly harder and, surprisingly, the preorder is not compositional. Furthermore, we regard deadlocks and divergence (infinite unobservable runs) as unwanted and characterize the testing preorder with an unusual failure-divergence semantics. This preorder is already on LTSs strictly coarser—and hence arguably better—than the traditional failure-divergence preorder. It is a precongruence on dMTS, also for hiding, and much easier to handle than the deadlock-based preorder. It arises as well from a new variant of De Nicola’s and Hennessy’s must-testing.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2692330100",
    "type": "article"
  },
  {
    "title": "TrustFlow-X",
    "doi": "https://doi.org/10.1145/3398327",
    "publication_date": "2020-09-26",
    "publication_year": 2020,
    "authors": "Cyril Bresch; David Hély; Roman Lysecky; Stéphanie Chollet; Ioannis Parissis",
    "corresponding_authors": "",
    "abstract": "This article addresses the challenges of memory safety in life-critical medical devices. Since the last decade, healthcare manufacturers have embraced the Internet of Things, pushing technological innovations to increase market share. Medical devices, including the most critical ones, tend to be increasingly connected to the Internet. Unfortunately, as critical devices often rely on unsafe programming languages such as C, they are no exception to memory safety issues. Given a memory vulnerability, a skillful attacker can take over a system and perform remote code execution. Combined with the fact that medical devices directly impact the safety of their users, a security vulnerability can lead to disastrous scenarios. To address this issue, this article presents TrustFlow-X, a novel hardware/software co-designed framework that provides efficient fine-grained control-flow integrity protection against memory-based attacks. The TrustFlow-X framework is composed of an LLVM-based compiler toolchain that generates a secure code. This secure code is then executed on an extended RISC-V processor that keeps track of sensitive data using a trusted memory. The obtained results show that the contribution is practical, providing a high level of trust in life-critical embedded systems.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3042120462",
    "type": "article"
  },
  {
    "title": "Access pattern-based memory and connectivity architecture exploration",
    "doi": "https://doi.org/10.1145/605459.605462",
    "publication_date": "2003-02-01",
    "publication_year": 2003,
    "authors": "Peter Grun; Nikil Dutt; Alex Nicolau",
    "corresponding_authors": "",
    "abstract": "Memory accesses represent a major bottleneck in embedded systems power and performance. Traditionally, designers tried to alleviate this problem by relying on a simple cache hierarchy, or a limited use of special purpose memory modules such as stream buffers. Although real-life applications contain a large number of memory references to a diverse set of data structures, a significant percentage of all memory accesses in the application are generated from a few memory instructions that exhibit predictable, well-known access patterns; this creates an opportunity for memory customization, targeting the needs of these access patterns. We present APEX, an approach that extracts, analyzes and clusters the most active access patterns in the application, and aggressively customizes the memory architecture to match the needs of the application. Moreover, though the memory modules are important, the rate at which the memory system can produce the data for the CPU is significantly impacted by the connectivity architecture between the memory subsystem and the CPU. Thus, it is critical to consider the connectivity architecture early in the design flow, in conjunction with the memory architecture. We couple the exploration of memory modules together with their connectivity, to evaluate a wide range of cost, performance, and energy connectivity architectures. We use a heuristic to prune the design space, guiding the exploration towards the most promising designs. We present experiments on a set of large real-life benchmarks, showing significant performance improvements for varied cost and power characteristics, allowing the designer to evaluate customized memory and connectivity configurations for embedded systems.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2021009496",
    "type": "article"
  },
  {
    "title": "PLTL-partitioned model checking for reactive systems under fairness assumptions",
    "doi": "https://doi.org/10.1145/1067915.1067918",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "Samir Chouali; Jacques Julliand; Pierre-Alain Masson; Françoise Bellegarde",
    "corresponding_authors": "",
    "abstract": "We are interested in verifying dynamic properties of finite state reactive systems under fairness assumptions by model checking. The systems we want to verify are specified through a top-down refinement process. In order to deal with the state explosion problem, we have proposed in previous works to partition the reachability graph, and to perform the verification on each part separately. Moreover, we have defined a class, called Bmod, of dynamic properties that are verifiable by parts, whatever the partition. We decide if a property P belongs to Bmod by looking at the form of the Buchi automaton that accepts the negation of P. However, when a property P belongs to Bmod, the property f => P, where f is a fairness assumption, does not necessarily belong to Bmod. In this paper, we propose to use the refinement process in order to build the parts on which the verification has to be performed. We then show that with such a partition, if a property P is verifiable by parts and if f is the expression of the fairness assumptions on a system, then the property f => P is still verifiable by parts. This approach is illustrated by its application to the chip card protocol T=1 using the B engineering design language.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2025726943",
    "type": "article"
  },
  {
    "title": "Selective code transformation for dual instruction set processors",
    "doi": "https://doi.org/10.1145/1234675.1234677",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Sheayun Lee; Jaejin Lee; Chang Yun Park; Sang Lyul Min",
    "corresponding_authors": "",
    "abstract": "Embedded systems are often constrained in terms of both code size and execution time, because of a limited amount of available memory and real-time nature of applications. A dual instruction set processor, which supports a reduced instruction set (16 bits/instruction), in addition to a full instruction set (32 bits/instruction), allows an opportunity for a tradeoff between these two design criteria. Specifically, while the reduced instruction set can be used to reduce code size by providing smaller instructions, a program compiled into the reduced instruction set typically runs slower than the same program compiled into the full instruction set. Motivated by this observation, we propose a code generation technique that exploits this tradeoff relationship by selectively using the two instruction sets for different sections in the program. The proposed technique, called selective code transformation, not only provides a mechanism to enable a flexible tradeoff between a program's code size and its execution time, but also facilitates program optimization toward enhancing its worst case performance. The results from our experiments show that our proposed technique can be effectively used to fine-tune an application program on a spectrum of code size and execution performance, which, in turn, enables a system-wide optimization on memory space and execution speed involving multiple applications.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2058201858",
    "type": "article"
  },
  {
    "title": "Interrupt handler migration and direct interrupt scheduling for rapid scheduling of interrupt-driven tasks",
    "doi": "https://doi.org/10.1145/1721695.1721708",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Jupyung Lee; Kyu Ho Park",
    "corresponding_authors": "",
    "abstract": "In this article, we propose two techniques that aim to minimize the scheduling latency of high-priority interrupt-driven tasks, named the Interrupt Handler Migration (IHM) and Direct Interrupt Scheduling (DIS). The IHM allows the interrupt handler to be migrated from the interrupt handler thread to the corresponding target process so that additional context switch can be avoided and the cache hit ratio with respect to the data generated by the interrupt handler can be improved. In addition, the DIS allows the shortest path reserved for urgent interrupt-process pairs to be laid between the interrupt arrival and target process by dividing a series of interrupt-driven operations into nondeferrable and deferrable operations. Both the IHM and DIS can be combined in a natural way and can operate concurrently. These techniques can be applied to all kinds of interrupt handlers with no modification to them. The proposed techniques not only reduce the scheduling latency, but also resolve the interrupt-driven priority inversion problem. We implemented a prototype in the Linux 2.6.19 kernel after adding real-time patches. Experimental results show that the scheduling latency is significantly reduced by up to 84.2% when both techniques are applied together. When the Linux OS runs on an ARM-based embedded CPU running at 200MHz, the scheduling latency can become as low as 30 μ s, which is much closer to the hardware-specific limitations. By lowering the scheduling latency, the limited CPU cycles can be consumed more for user-level processes and less for system-level tasks, such as interrupt handling and scheduling.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1999950864",
    "type": "article"
  },
  {
    "title": "High-performance operating system controlled online memory compression",
    "doi": "https://doi.org/10.1145/1721695.1721696",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Lei Yang; Robert P. Dick; Haris Lekatsas; Srimat Chakradhar",
    "corresponding_authors": "",
    "abstract": "Online memory compression is a technology that increases the amount of memory available to applications by dynamically compressing and decompressing their working datasets on demand. It has proven extremely useful in embedded systems with tight physical RAM constraints. The technology can be used to increase functionality, reduce size, and reduce cost, without modifying applications or hardware. This article presents a new software-based online memory compression algorithm for embedded systems. In comparison with the best algorithms used in online memory compression, our new algorithm has a competitive compression ratio but is twice as fast. In addition, we describe several practical problems encountered in developing an online memory compression infrastructure and present solutions. We present a method of adaptively managing the uncompressed and compressed memory regions during application execution. This memory management scheme adapts to the predicted memory requirements of applications. It permits efficient compression for a wide range of applications. We have evaluated our techniques on a portable embedded device and have found that the memory available to applications can be increased by 2.5× with negligible performance and power consumption penalties, and with no changes to hardware or applications. Our techniques allow existing applications to execute with less physical memory. They also allow applications with larger working datasets to execute on unchanged embedded system hardware, thereby increasing functionality.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2014253690",
    "type": "article"
  },
  {
    "title": "Introduction to special issue on wireless health",
    "doi": "https://doi.org/10.1145/1814539.1814549",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "William Kaiser; Majid Sarrafzadeh",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2082673938",
    "type": "article"
  },
  {
    "title": "Multi-buffer manager",
    "doi": "https://doi.org/10.1145/1698772.1698786",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Ulpian Cesana; Zhen He",
    "corresponding_authors": "",
    "abstract": "Embedded devices such as personal digital assistants (PDAs), pocket PCs, palmtops, and handheld PCs are increasingly using flash memory for the permanent storage of databases. Databases achieve their fast data access speeds by using a memory manager that manages data pages in a memory buffer. The buffer manager uses a page replacement policy to evict pages when the memory buffer is full. An eviction of a dirty page will result in a write to flash memory. Unfortunately, writing to flash memory consumes a lot more energy than reading. Much of the previous work in page replacement policies has focused on reducing the number of page reads rather than writes. One of the few existing works to consider the effects of flash memory's hardware constraints for database design is Lee et. al.'s in-page Logging (IPL) approach [Lee and Moon 2007]. They demonstrated IPL significantly outperforms traditional disk-based databases when running on flash memory. However, they do not consider the energy efficiency of their approach in terms of the behavior of the page replacement policy. This article addresses this issue by presenting the Multi-Buffer Manager, which is customized for flash databases that use a logging-based approach for managing updates such as IPL. Extensive experiments show the page replacement policy used plays a pivotal role in the performance of the flash database system. In particular, our Multi-Buffer Manager can reduce energy consumption by up to 40% compared to the state-of-the-art clean first flash-based buffer replacement policy (CFLRU).",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2087871855",
    "type": "article"
  },
  {
    "title": "Attitude Fusion of Inertial and Magnetic Sensor under Different Magnetic Filed Distortions",
    "doi": "https://doi.org/10.1145/3157668",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "Zhijian He; Yao Chen; Zhaoyan Shen",
    "corresponding_authors": "",
    "abstract": "By virtue of gravity measurement from a handheld inertial measurement unit (IMU) sensor, current indoor attitude estimation algorithms can provide accurate roll/pitch dimension angles. Acquisition of precise heading is limited by the absence of accurate magnetic reference. Consequently, initial stage magnetometer calibration is deployed to alleviate this bottleneck in attitude fusion. However, available algorithms tackle magnetic distortion based on time-invariant surroundings, casting the post-calibration magnetic data into unchanged ellipsoid centered in the calibration place. Consequently, inaccurate fusion results are formulated in a more common case of random walk in time-varying magnetic indoor environment. This article proposes a new fusion algorithm from various kinds of IMU sensors, namely gyroscope, accelerometer, and magnetometer. Compared to state-of-the-art attitude fusion approaches, this article addresses the indoor time-varying magnetic perturbation problem in a geometric view. We propose an extend Kalman filter--based algorithm based on this detailed geometric model to eliminate the position-dependent effect of a compass sensor. Experimental data demonstrate that, under different indoor magnetic distortion environments, our proposed attitude fusion algorithm has the maximum angle error of 2.02°, outperforming 7.17° of a gradient-declining-based algorithm. Additionally, this attitude fusion result is constructed in a low-cost handheld arduino core--based IMU device, which can be widely applied to embedded systems.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2786814539",
    "type": "article"
  },
  {
    "title": "Application Deployment Strategies for Spatial Isolation on Many-Core Accelerators",
    "doi": "https://doi.org/10.1145/3168383",
    "publication_date": "2018-02-13",
    "publication_year": 2018,
    "authors": "Maria Méndez Real; Philipp Wehner; Vianney Lapôtre; Diana Göhringer; Guy Gogniat",
    "corresponding_authors": "",
    "abstract": "Current cache Side-Channel Attacks (SCAs) countermeasures have not been designed for many-core architectures and need to be revisited in order to be practical for these new technologies. Spatial isolation of resources for sensitive applications has been proposed taking advantage of the large number of resources offered by these architectures. This solution avoids cache sharing with sensitive processes. Consequently, their cache activity cannot be monitored and cache SCAs cannot be performed. This work focuses on the implementation of this technique in order to minimize the induced performance overhead. Different strategies for the management of isolated secure zones are implemented and compared.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2792180045",
    "type": "article"
  },
  {
    "title": "Schedule Adaptation for Ensuring Reliability in RT-WiFi-Based Networked Embedded Systems",
    "doi": "https://doi.org/10.1145/3236011",
    "publication_date": "2018-09-30",
    "publication_year": 2018,
    "authors": "Yi-Hung Wei; Quan Leng; Wei-Ju Chen; Aloysius K. Mok; Song Han",
    "corresponding_authors": "",
    "abstract": "With the ever-growing interests in applying wireless technologies for networked embedded systems to serve as the communication fabric, many real-time wireless technologies have been recently developed to support time-critical sensing and control applications. We proposed in previous work the RT-WiFi protocol that provides real-time high-speed predictable data delivery and enables designs to meet time-critical industrial needs. However, without explicit reliability enforcement mechanisms, our previous RT-WiFi design is either subject to uncontrolled packet loss due to noise and other interferences or may suffer from inefficient communication channel usage. In this article, we explicitly consider interference from both Wi-Fi and non-Wi-Fi based interference sources and propose two sets of effective solutions for reliable data transmissions in RT-WiFi-based networked embedded systems. To improve reliability against general non-Wi-Fi based interference, based on rate adaptation and retransmission techniques, we present an optimal real-time rate adaption algorithm together with a communication link scheduler that has low network management overhead. A novel technique called overbooking is introduced to further improve the schedulability of the communication link scheduler while maintaining the required communication reliability. For Wi-Fi-based interference, we present mechanisms that utilize virtual carrier sensing to provide reliable data transmission while co-existing with regular Wi-Fi networks. We have implemented the proposed algorithms in the RT-WiFi network management framework and demonstrated the system performance with a series of experiments.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2895587829",
    "type": "article"
  },
  {
    "title": "A Lightweight and Secure Data Collection Serverless Protocol Demonstrated in an Active RFIDs Scenario",
    "doi": "https://doi.org/10.1145/3274667",
    "publication_date": "2019-04-02",
    "publication_year": 2019,
    "authors": "Amina Cherif; Malika Belkadi; Damien Sauveron",
    "corresponding_authors": "",
    "abstract": "In the growing Internet of Things context, thousands of computing devices with various functionalities are producing data (from environmental sensors or other sources). However, they are also collecting, storing, processing and transmitting data to eventually communicate them securely to third parties (e.g., owners of devices or cloud data storage). The deployed devices are often battery-powered mobile or static nodes equipped with sensors and/or actuators, and they communicate using wireless technologies. Examples include unmanned aerial vehicles, wireless sensor nodes, smart beacons, and wearable health objects. Such resource-constrained devices include Active Radio Frequency IDentification (RFID) nodes, and these are used to illustrate our proposal. In most scenarios, these nodes are unattended in an adverse environment, so data confidentiality must be ensured from the sensing phase through to delivery to authorized entities: in other words, data must be securely stored and transmitted to prevent attack by active adversaries even if the nodes are captured. However, due to the scarce resources available to nodes in terms of energy, storage, and/or computation, the proposed security solution has to be lightweight. In this article, we propose a serverless protocol to enable Mobile Data Collectors (MDCs), such as drones, to securely collect data from mobile and static Active RFID nodes and then deliver them later to an authorized third party. The whole solution ensures data confidentiality at each step (from the sensing phase, before data collection by the MDC, once data have been collected by MDC, and during final delivery), while fulfilling the lightweight requirements for the resource-limited entities involved. To assess the suitability of the protocol against the performance requirements, it was implemented on the most resource-constrained devices to get the worst possible results. In addition, to prove the protocol fulfills the security requirements, it was analyzed using security games and also formally verified using the AVISPA and ProVerif tools.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2933785074",
    "type": "article"
  },
  {
    "title": "Catching Escapers",
    "doi": "https://doi.org/10.1145/3319615",
    "publication_date": "2019-05-31",
    "publication_year": 2019,
    "authors": "Letian Sha; Fu Xiao; Haiping Huang; Yu Chen; Ruchuan Wang",
    "corresponding_authors": "",
    "abstract": "As the Industry 4.0 or Internet of Things (IoT) era begins, security plays a key role in the Industry Internet of Things (IIoT) due to various threats, which include escape or Distributed Denial of Service (DDoS) attackers in the virtualization layer and vulnerability exploiters in the device layer. A successful cross-VM escape attack in the virtualization layer combined with cross-layer penetration in the device layer, which we define as an Advanced Persistent Escaper (APE), poses a great threat. Therefore, the development of detection and rejection methods for APEs across multiple layers in IIoT is an open issue. To the best of our knowledge, less effective methods are established, especially for vulnerability exploitation in the virtualization layer and backdoor leverage in the device layer. On the basis of this, we propose Escaper Cops (EscaperCOP), a detection method for cross-VM escapers in the virtualization layer and cross-layer penetrators in the device layer. In particular, a new detection method for guest-to-host escapers is proposed for the virtualization layer. Finally, a novel encryption method based on Identity-based Broadcast Encryption (IBBE) is proposed to protect the critical components in EscaperCOP, detection library, and control command library. To verify our method, experimental tests are performed for a large number of APEs in an IIoT framework. The test results have demonstrated the proposed method is effective with an acceptable level of detection ratio.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2952237011",
    "type": "article"
  },
  {
    "title": "Numerical Representation of Directed Acyclic Graphs for Efficient Dataflow Embedded Resource Allocation",
    "doi": "https://doi.org/10.1145/3358225",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Florian Arrestier; Karol Desnos; Eduardo Juárez; Daniel Ménard",
    "corresponding_authors": "",
    "abstract": "Stream processing applications running on Heterogeneous Multi-Processor Systems on Chips (HMPSoCs) require efficient resource allocation and management, both at compile-time and at runtime. To cope with modern adaptive applications whose behavior can not be exhaustively predicted at compile-time, runtime managers must be able to take resource allocation decisions on-the-fly, with a minimum overhead on application performance. Resource allocation algorithms often rely on an internal modeling of an application. Directed Acyclic Graph (DAGs) are the most commonly used models for capturing control and data dependencies between tasks. DAGs are notably often used as an intermediate representation for deploying applications modeled with a dataflow Model of Computation (MoC) on HMPSoCs. Building such intermediate representation at runtime for massively parallel applications is costly both in terms of computation and memory overhead. In this paper, an intermediate representation of DAGs for resource allocation is presented. This new representation shows improved performance for run-time analysis of dataflow graphs with less overhead in both computation time and memory footprint. The performances of the proposed representation are evaluated on a set of computer vision and machine learning applications.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2979729666",
    "type": "article"
  },
  {
    "title": "A Closed-Loop Controller to Ensure Performance and Temperature Constraints for Dynamic Applications",
    "doi": "https://doi.org/10.1145/3343030",
    "publication_date": "2019-09-30",
    "publication_year": 2019,
    "authors": "Michail Noltsis; Nikolaos Zambelis; Francky Catthoor; Dimitrios Soudris",
    "corresponding_authors": "",
    "abstract": "To secure correct system operation, a plethora of Reliability, Availability and Serviceability (RAS) techniques have been deployed by circuit designers. RAS mechanisms however, come with the cost of extra clock cycles. In addition, a wide variety of dynamic workloads and different input conditions often constitute preemptive dependability techniques hard to implement. To this end, we focus on a realistic case study of a closed-loop controller that mitigates performance variation with a reactive response. This concept has been discussed but was only illustrated on small benchmarks. In particular, the extension of the approach to manage performance of dynamic workloads on a target platform has not been shown earlier. We compare our scheme against the version of a Linux CPU frequency governor in terms of timing response and energy consumption. Finally, we move forward and suggest a new flavor of our controller to efficiently manage processor temperature. Again, the concept is illustrated with a realistic case study and compared to a modern temperature manager.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2980098788",
    "type": "article"
  },
  {
    "title": "Aggressive Energy Reduction for Video Inference with Software-only Strategies",
    "doi": "https://doi.org/10.1145/3358174",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Larissa Rozales Gonçalves; Rafael Fão de Moura; Luigi Carro",
    "corresponding_authors": "",
    "abstract": "In the past years, several works have proposed custom hardware and software-based techniques for the acceleration of Convolutional Neural Networks (CNNs). Most of these works focus on saving computations by changing the used precision or modifying frame processing. To reach a more aggressive energy reduction, in this paper we propose software-only modifications to the CNNs inference process. Our approach exploits the inherent locality in videos by replacing entire frame computations with a movement prediction algorithm. Furthermore, when a frame must be processed, we avoid energy-demanding floating-point operations, and at the same time reduce memory accesses by employing look-up tables in place of the original convolutions. Using the proposed approach, one can reach significant energy gains of more than 25× for security cameras, and 12× for moving vehicles applications, with only small software modifications.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2980309519",
    "type": "article"
  },
  {
    "title": "Robust Design and Validation of Cyber-physical Systems",
    "doi": "https://doi.org/10.1145/3362098",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Surinder Sood; Avinash Malik; Partha S. Roop",
    "corresponding_authors": "",
    "abstract": "Co-simulation--based validation of hardware controllers adjoined with plant models, with continuous dynamics, is an important step in model-based design of controllers for Cyber-physical Systems (CPS). Co-simulation suffers from many problems, such as timing delays, skew, race conditions, and so on, making it unsuitable for checking timing properties of CPS. In our approach to validation of controllers, synthesised from their models, the synthesised controller is adjoined with a synthesised hardware plant unit. The synthesised plant and controller are then executed synchronously and Metric Interval Temporal Logic (MITL) properties are validated on the closed-loop system. The clock period is chosen, using robustness estimates, such that all timing properties that hold on the controller guiding the discretised plant model also hold on the original case of the continuous-time plant model guided by the controller. Benchmark results show that real-time MITL properties that are vacuously satisfied or violated due to co-simulation artefacts hold correctly in the proposed closed-loop validation framework.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2989217866",
    "type": "article"
  },
  {
    "title": "Reliable and Secure Design-Space-Exploration for Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3387927",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Saurav Kumar Ghosh; Jaffer Sheriff R C; Vibhor Jain; Soumyajit Dey",
    "corresponding_authors": "",
    "abstract": "Given the widespread deployment of cyber-physical systems and their safety-critical nature, reliability and security guarantees offered by such systems are of paramount importance. While the security of such systems against sensor attacks have garnered significant attention from researchers in recent times, improving the reliability of a control software implementation against transient environmental disturbances need to be investigated further. Scalable formal methods for verification of actual control performance guarantee offered by software implementations of control laws in the face of sensory faults have been explored in recent work [20]. However, the formal verification of the improvement of system reliability by incorporating sensor fault mitigation techniques like Kalman filtering [29] and sensor fusion [18, 52] remains to be explored. Moreover, system designers face complex tradeoff choices for deciding upon the usage of fault and attack mitigation techniques and scheduling them on available system resources as they incur extra computation load. In the present work, our contributions are threefold. We formally analyze the actual performance guarantee of control software implementations enabled with additional fault mitigation techniques. We consider task-level models of such implementations enabled with security and fault tolerance primitives and construct a timed automata-based model which checks for schedulability on heterogeneous multi-core platforms. We leverage these methodologies in the context of a novel Design-Space-Exploration (DSE) framework that considers target reliability and security guarantees for a control system and computes schedulable design options while considering well-known platform-level security improvement and fault mitigation techniques. We validate our contributions over several case studies from the automotive domain.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3030308125",
    "type": "article"
  },
  {
    "title": "Approximate Cache in GPGPUs",
    "doi": "https://doi.org/10.1145/3407904",
    "publication_date": "2020-09-26",
    "publication_year": 2020,
    "authors": "Ehsan Atoofian",
    "corresponding_authors": "Ehsan Atoofian",
    "abstract": "There is a growing number of application domains ranging from multimedia to machine learning where a certain level of inexactness can be tolerated. For these applications, approximate computing is an effective technique that trades off some loss in output data integrity for energy and/or performance gains. In this article, we present the approximate cache, which approximates similar values and saves energy in the L2 cache of general-purpose graphics processing units (GPGPUs). The L2 cache is a critical component in memory hierarchy of GPGPUs, as it accommodates data of thousands of simultaneously executing threads. Simply increasing the size of the L2 cache is not a viable solution to keep up with the growing size of data in many-core applications. This work is motivated by the observation that threads within a warp write values into memory that are arithmetically similar. We exploit this property and propose a low-cost and implementation-efficient hardware to trade off accuracy for energy. The approximate cache identifies similar values during the runtime and allows only one thread writes into the cache in the event of similarity. Since the approximate cache is able to pack more data in a smaller space, it enables downsizing of the data array with negligible impact on cache misses and lower-level memory. The approximate cache reduces both dynamic and static energy. By storing data of a thread into a cache block, each memory instruction requires accessing fewer cache cells, thus reducing dynamic energy. In addition, the approximate cache increases frequency of bank idleness. By power gating idle banks, static energy is reduced. Our evaluations reveal that the approximate cache reduces energy by 52% with minimal quality degradation while maintaining performance of a diverse set of GPGPU applications.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3088770438",
    "type": "article"
  },
  {
    "title": "A Vector-Length Agnostic Compiler for the Connex-S Accelerator with Scratchpad Memory",
    "doi": "https://doi.org/10.1145/3406536",
    "publication_date": "2020-10-03",
    "publication_year": 2020,
    "authors": "Alexandru E. Şuşu",
    "corresponding_authors": "Alexandru E. Şuşu",
    "abstract": "Compiling sequential C programs for Connex-S, a competitive, scalable and customizable, wide vector accelerator for intensive embedded applications with 32 to 4,096 16-bit integer lanes and a limited capacity local scratchpad memory, is challenging. Our compiler toolchain uses the LLVM framework and targets OPINCAA, a JIT vector assembler and coordination C++ library for Connex-S accelerating computations for an arbitrary CPU. Therefore, we address in the compiler middle end aspects of efficient vectorization, communication, and synchronization. We perform quantitative static analysis of the program useful, among others, for the symbolic-size compiler memory allocator and the coordination mechanism of OPINCAA. We also discuss the LLVM back end for the Connex-S processor and the methodology to automatically generate instruction selection code for emulating efficiently arithmetic and logical operations for non-native types such as 32-bit integer and 16-bit floating-point. By using JIT vector assembling and by encoding the vector length of Connex-S as a parameter in the generated OPINCAA program, we achieve vector-length agnosticism to support execution on distinct embedded devices, such as several digital cameras with different resolutions, each equipped with custom-width Connex-S accelerators meant to save energy for the image processing kernels. Since Connex-S has a limited capacity local scratchpad memory of 256 KB normally, we present how we also use the PPCG C-to-C code generator to perform data tiling to minimize the total kernel execution time, subject to fitting larger program data in the local memory. We devise an accurate cost model for the Connex-S accelerator to choose optimal performance tile sizes at compile time. We successfully compile several simple benchmarks frequently used, for example, in high-performance and computer vision embedded applications. We report speedup factors of up to 11.33 when running them on a Connex-S accelerator with 128 16-bit integer lanes w.r.t. the dual-core ARM Cortex A9 host clocked at a frequency 6.67 times higher, with a total of two 128-bit Neon SIMD units.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3092642880",
    "type": "article"
  },
  {
    "title": "Creating Hardware Component Knowledge Bases with Training Data Generation and Multi-task Learning",
    "doi": "https://doi.org/10.1145/3391906",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Luke Hsiao; Sen Wu; Nicholas Chiang; Christopher Ré; Philip Levis",
    "corresponding_authors": "",
    "abstract": "Hardware component databases are vital resources in designing embedded systems. Since creating these databases requires hundreds of thousands of hours of manual data entry, they are proprietary, limited in the data they provide, and have random data entry errors. We present a machine learning based approach for creating hardware component databases directly from datasheets. Extracting data directly from datasheets is challenging because: (1) the data is relational in nature and relies on non-local context, (2) the documents are filled with technical jargon, and (3) the datasheets are PDFs, a format that decouples visual locality from locality in the document. Addressing this complexity has traditionally relied on human input, making it costly to scale. Our approach uses a rich data model, weak supervision, data augmentation, and multi-task learning to create these knowledge bases in a matter of days. We evaluate the approach on datasheets of three types of components and achieve an average quality of 77 F1 points—quality comparable to existing human-curated knowledge bases. We perform application studies that demonstrate the extraction of multiple data modalities including numerical properties and images. We show how different sources of supervision such as heuristics and human labels have distinct advantages that can be utilized together to improve knowledge base quality. Finally, we present a case study to show how this approach changes the way practitioners create hardware component knowledge bases.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3107987915",
    "type": "article"
  },
  {
    "title": "Error-Aware Algorithm/Architecture Coexploration for Video Over Wireless Applications",
    "doi": "https://doi.org/10.1145/2180887.2180892",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Amin Khajeh; Minyoung Kim; Nikil Dutt; Ahmed M. Eltawil; Fadi Kurdahi",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a cross-layer algorithm/architecture coexploration for wireless multimedia systems to coordinate interactions among sublayer optimizers for improvements in energy/QoS/reliability. By exploiting the inherent redundancy in wireless multimedia systems, we generate an expanded design space over traditional layer-specific approaches. Specifically, we control the error resilient encoder at the application layer to provide awareness of architectural exploration at the physical layer allowing new design points with lower power consumption via aggressive voltage scaling. While trying to reduce energy consumption, the fault tolerant technique compensates the effect of the hardware and network errors due to aggressive voltage scaling and lossy transmission, respectively. Our experiments on H.263 video over a WCDMA communication system demonstrate that coexploration enlarges the feasible design space, which results in significant power savings of more than 20% in the WCDMA modem.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1984954851",
    "type": "article"
  },
  {
    "title": "Tractable schedulability analysis and resource allocation for real-time multimodal systems",
    "doi": "https://doi.org/10.1145/2544375.2544385",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Masud Ahmed; Nathan Fisher",
    "corresponding_authors": "",
    "abstract": "Real-time multimedia subsystems often require support for switching between different resource and application execution modes. To ensure that timing constraints are not violated during or after a subsystem mode change, real-time schedulability analysis is required. However, existing time-efficient multimode schedulability analysis techniques for application-only mode changes are not appropriate for subsystems that require changes in the resource execution behavior (e.g., processors with dynamic power modes). Furthermore, all existing multimode schedulability analysis that handles both resource and application mode changes is highly exponential and not scalable for subsystems with a moderate or large number of modes. As a result, the notion of resource optimality is still unaddressed for real-time multimodal systems. In this report, we first address the lack of tractable schedulability analysis for such subsystems by proposing a model for characterizing multiple resource and application modes and by deriving a sufficient schedulability test that has pseudo-polynomial time complexity. Finally, we propose an algorithm which leverages this pseudo-polynomial schedulability analysis to optimize the resource usages (e.g., to minimize peak-power load) of a multimodal real-time system. Simulation results show that our proposed algorithms for schedulability analysis and resource allocation, when compared with previously-proposed approaches, require significantly less time and are just as precise.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1992813231",
    "type": "article"
  },
  {
    "title": "Distributed Reconfigurations of Autonomous IEC61499 Systems",
    "doi": "https://doi.org/10.1145/2406336.2406354",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Mohamed Khalgui",
    "corresponding_authors": "Mohamed Khalgui",
    "abstract": "The article deals with Distributed Multiagent Reconfigurable Embedded Control Systems following the International Industrial Standard IEC61499 in which a Function Block (Abbreviated by FB) is an event-triggered software component owning data and a control system is a network of distributed blocks. We define a multiagent embedded architecture in which a Reconfiguration Agent is affected to each device of the execution environment to apply local reconfigurations, and a Coordination Agent is proposed for coordination between devices in order to guarantee safe and coherent distributed reconfigurations. A Communication Protocol is proposed to handle such coordination by using well-defined Coordination Matrices . A prototype is developed to simulate the whole architecture when faults occur or system’s optimizations are applied. We specify Reconfiguration Agents to be modeled by nested state machines, and the Coordination Agent according to the formalism Net Condition/Event Systems (Abbreviated by NCES) which is an extension of Petri nets. To allow correct and coherent distributed reconfigurations, we check all possible interactions between controllers by verifying that whenever a reconfiguration is applied in a device, the Coordination Agent and other concerned devices react as described in user requirements. We propose finally XML-based implementations of both Coordination and Reconfiguration Agents according the the technology IEC61499. The article’s contributions are applied to two Benchmark Production Systems available in our research laboratory.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1997721171",
    "type": "article"
  },
  {
    "title": "Action Synthesis for Branching Time Logic",
    "doi": "https://doi.org/10.1145/2746337",
    "publication_date": "2015-09-09",
    "publication_year": 2015,
    "authors": "Michał Knapik; Artur Męski; Wojciech Penczek",
    "corresponding_authors": "",
    "abstract": "The article introduces a parametric extension of Action-Restricted Computation Tree Logic called pmARCTL. A symbolic fixed-point algorithm providing a solution to the exhaustive parameter synthesis problem is proposed. The parametric approach allows for an in-depth system analysis and synthesis of the correct parameter values. The time complexity of the problem and the algorithm is provided. An existential fragment of pmARCTL (pmEARCTL) is identified, in which all of the solutions can be generated from a minimal and unique base. A method for computing this base using symbolic methods is provided. The prototype tool SPATULA implementing the algorithm is applied to the analysis of three benchmarks: faulty Train-Gate-Controller, Peterson’s mutual exclusion protocol, and a generic pipeline processing network. The experimental results show efficiency and scalability of our approach compared to the naive solution to the problem.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1999103908",
    "type": "article"
  },
  {
    "title": "Adaptive loop caching using lightweight runtime control flow analysis",
    "doi": "https://doi.org/10.1145/2435227.2435251",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Marisha Rawlins; Ross Gordon",
    "corresponding_authors": "",
    "abstract": "Loop caches provide an effective method for decreasing memory hierarchy energy consumption by storing frequently executed code (critical regions) in a more energy efficient structure than the level one cache. However, due to code structure restrictions or costly design time pre-analysis efforts, previous loop cache designs are not suitable for all applications and system scenarios. We present an adaptive loop cache that is amenable to a wider range of system scenarios, which can provide an additional 20% average instruction cache energy savings (with individual benchmark energy savings as high as 69%) compared to the next best loop cache, the preloaded loop cache.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1999687179",
    "type": "article"
  },
  {
    "title": "Software thread integration for instruction-level parallelism",
    "doi": "https://doi.org/10.1145/2512466",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Won So; Alexander G. Dean",
    "corresponding_authors": "",
    "abstract": "Multimedia applications require a significantly higher level of performance than previous workloads of embedded systems. They have driven digital signal processor (DSP) makers to adopt high-performance architectures like VLIW (Very-Long Instruction Word). Despite many efforts to exploit instruction-level parallelism (ILP) in the application, the speed is a fraction of what it could be, limited by the difficulty of finding enough independent instructions to keep all of the processor's functional units busy. This article proposes Software Thread Integration (STI) for instruction-level parallelism. STI is a software technique for interleaving multiple threads of control into a single implicitly multithreaded one. We use STI to improve the performance on ILP processors by merging parallel procedures into one, increasing the compiler's scope and hence allowing it to create a more efficient instruction schedule. Assuming the parallel procedures are given, we define a methodology for finding the best performing integrated procedure with a minimum compilation time. We quantitatively estimate the performance impact of integration, allowing various integration scenarios to be compared and ranked via profitability analysis. During integration of threads, different ILP-improving code transformations are selectively applied according to the control structure and the ILP characteristics of the code, driven by interactions with software pipelining. The estimated profitability is verified and corrected by an iterative compilation approach, compensating for possible estimation inaccuracy. Our modeling methods combined with limited compilation quickly find the best integration scenario without requiring exhaustive integration.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2006020173",
    "type": "article"
  },
  {
    "title": "Bandwidth allocation for fixed-priority-scheduled compositional real-time systems",
    "doi": "https://doi.org/10.1145/2560038",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Farhana Dewan; Nathan Fisher",
    "corresponding_authors": "",
    "abstract": "Recent research in compositional real-time systems has focused on determination of a component's real-time interface parameters. An important objective in interface-parameter determination is minimizing the bandwidth allocated to each component of the system while simultaneously guaranteeing component schedulability. With this goal in mind, in this article, we explore fixed-priority schedulability in compositional setting. First we derive an efficient exact test based on iterative convergence for sporadic task systems scheduled by fixed-priority (e.g., deadline monotonic, rate monotonic) upon an explicit-deadline periodic (EDP) resource. Then we address the time complexity of the exact test by developing a fully-polynomial-time approximation scheme (FPTAS) for allocating bandwidth to components. Our parametric algorithm takes the task system and an accuracy parameter ε &gt; 0 as input and returns a bandwidth which is guaranteed to be at most a factor (1 + ε) times the optimal minimum bandwidth required to successfully schedule the task system. We perform thorough simulation over synthetically generated task systems to compare the performance of our proposed efficient-exact and the approximate algorithm and observe a significant decrease in runtime and a very small relative error when comparing the approximate algorithm with the exact algorithm and the sufficient algorithm.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2007301955",
    "type": "article"
  },
  {
    "title": "Architecture-Aware Real-Time Compression of Execution Traces",
    "doi": "https://doi.org/10.1145/2766449",
    "publication_date": "2015-09-09",
    "publication_year": 2015,
    "authors": "Bojan Mihajlović; Željko Žilić; Warren J. Gross",
    "corresponding_authors": "",
    "abstract": "In recent years, on-chip trace generation has been recognized as a solution to the debugging of increasingly complex software. An execution trace can be seen as the most fundamentally useful type of trace, allowing the execution path of software to be determined post hoc. However, the bandwidth required to output such a trace can be excessive. Our architecture-aware trace compression (AATC) scheme adds an on-chip branch predictor and branch target buffer to reduce the volume of execution trace data in real time through on-chip compression. Novel redundancy reduction strategies are employed, most notably in exploiting the widespread use of linked branches and the compiler-driven movement of return addresses between link register, stack, and program counter. In doing so, the volume of branch target addresses is reduced by 52%, whereas other algorithmic improvements further decrease trace volume. An analysis of spatial and temporal redundancy in the trace stream allows a comparison of encoding strategies to be made for systematically increasing compression performance. A combination of differential, Fibonacci, VarLen, and Move-to-Front encodings are chosen to produce two compressor variants: a performance-focused xAATC that encodes 56.5 instructions/bit using 24,133 gates and an area-efficient fAATC that encodes 48.1 instructions/bit using only 9,854 gates.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2008180805",
    "type": "article"
  },
  {
    "title": "Application-aware adaptive cache architecture for power-sensitive mobile processors",
    "doi": "https://doi.org/10.1145/2539036.2539037",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Garo Bournoutian; Alex Orailoğlu",
    "corresponding_authors": "",
    "abstract": "Today, mobile smartphones are expected to be able to run the same complex, algorithm-heavy, memory-intensive applications that were originally designed and coded for general-purpose processors. All the while, it is also expected that these mobile processors be power-conscientious as well as of minimal area impact. These devices pose unique usage demands of ultra-portability but also demand an always-on, continuous data access paradigm. As a result, this dichotomy of continuous execution versus long battery life poses a difficult challenge. This article explores a novel approach to mitigating mobile processor power consumption while abating any significant degradation in execution speed. The concept relies on efficiently leveraging both compile-time and runtime application memory behavior to intelligently target adjustments in the cache to significantly reduce overall processor power, taking into account both the dynamic and leakage power footprint of the cache subsystem. The simulation results show a significant reduction in power consumption of approximately 13% to 29%, while only incurring a nominal increase in execution time and area.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2011260455",
    "type": "article"
  },
  {
    "title": "GPU-like on-chip system for decoding LDPC codes",
    "doi": "https://doi.org/10.1145/2538668",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Bertrand Le Gal; Christophe Jégo",
    "corresponding_authors": "",
    "abstract": "Rapid prototyping is an important step in the development and the verification of computationally demanding tasks of digital communication systems, such as Forward Error Correction (FEC) decoding. The goal is to replace time-consuming simulations based on abstract models of the system with real-time experiments under real-world conditions. GPU-like architecture is a promising approach to fully exploit the potential of FPGA-based acceleration platforms. In this article, an application-specific GPU-like architecture and a complete compilation framework for decoding LDPC codes are proposed. The interest in an application-specific GPU in comparison with current GPUs is detailed. Finally, real-time experimentations demonstrate the potential of the GPU-like decoder to investigate both algorithmic and architectural issues.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2023415525",
    "type": "article"
  },
  {
    "title": "Guaranteed Computational Resprinting via Model-Predictive Control",
    "doi": "https://doi.org/10.1145/2724715",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Andrea Tilli; Andrea Bartolini; Matteo Cacciari; Luca Benini",
    "corresponding_authors": "",
    "abstract": "Today and future many-core systems are facing the utilization wall and dark silicon problems, for which not all the processing engines can be powered at the same time as this will lead to a power consumption higher than the Total Design Power (TDP) budget. Recently, computational sprinting approaches addressed the problem by exploiting the intrinsic thermal capacitance of the chip and the properties of common applications, which require intense, but temporary, use of resources. The thermal capacitance, possibly augmented with phase change materials, enables the temporary activation of all the resources simultaneously, although they largely exceed the steady-state thermal design power. In this article, we present an innovative and low-overhead hierarchical model-predictive controller for managing thermally safe sprinting with predictable resprinting rate, which ensures the correct execution of mixed-criticality tasks. Well-targeted simulations, also based on real workload benchmarks, show the applicability and the effectiveness of our solution.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2026069852",
    "type": "article"
  },
  {
    "title": "Dynamic profiling and fuzzy-logic-based optimization of sensor network platforms",
    "doi": "https://doi.org/10.1145/2539036.2539047",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Adrian Lizarraga; Roman Lysecky; Susan Lysecky; Ross Gordon",
    "corresponding_authors": "",
    "abstract": "The commercialization of sensor-based platforms is facilitating the realization of numerous sensor network applications with diverse application requirements. However, sensor network platforms are becoming increasingly complex to design and optimize due to the multitude of interdependent parameters that must be considered. To further complicate matters, application experts oftentimes are not trained engineers, but rather biologists, teachers, or agriculturists who wish to utilize the sensor-based platforms for various domain-specific tasks. To assist both platform developers and application experts, we present a centralized dynamic profiling and optimization platform for sensor-based systems that enables application experts to rapidly optimize a sensor network for a particular application without requiring extensive knowledge of, and experience with, the underlying physical hardware platform. In this article, we present an optimization framework that allows developers to characterize application requirements through high-level design metrics and fuzzy-logic-based optimization. We further analyze the benefits of utilizing dynamic profiling information to eliminate the guesswork of creating a “good” benchmark, present several reoptimization evaluation algorithms used to detect if re-optimization is necessary, and highlight the benefits of the proposed dynamic optimization framework compared to static optimization alternatives.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2030727555",
    "type": "article"
  },
  {
    "title": "Distributed programming framework for fast iterative optimization in networked cyber-physical systems",
    "doi": "https://doi.org/10.1145/2544375.2544386",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Rahul Balani; Lucas Wanner; Mani Srivastava",
    "corresponding_authors": "",
    "abstract": "Large-scale coordination and control problems in cyber-physical systems are often expressed within the networked optimization model. While significant advances have taken place in optimization techniques, their widespread adoption in practical implementations has been impeded by the complexity of internode coordination and lack of programming support for the same. Currently, application developers build their own elaborate coordination mechanisms for synchronized execution and coherent access to shared resources via distributed and concurrent controller processes. However, they typically tend to be error prone and inefficient due to tight constraints on application development time and cost. This is unacceptable in many CPS applications, as it can result in expensive and often irreversible side-effects in the environment due to inaccurate or delayed reaction of the control system. This article explores the design of a distributed shared memory (DSM) architecture that abstracts the details of internode coordination. It simplifies application design by transparently managing routing, messaging, and discovery of nodes for coherent access to shared resources. Our key contribution is the design of provably correct locality-sensitive synchronization mechanisms that exploit the spatial locality inherent in actuation to drive faster and scalable application execution through opportunistic data parallel operation. As a result, applications encoded in the proposed Hotline Application Programming Framework are error free, and in many scenarios, exhibit faster reactions to environmental events over conventional implementations. Relative to our prior work, this article extends Hotline with a new locality-sensitive coordination mechanism for improved reaction times and two tunable iteration control schemes for lower message costs. Our extensive evaluation demonstrates that realistic performance and cost of applications are highly sensitive to the prevalent deployment, network, and environmental characteristics. This highlights the importance of Hotline, which provides user-configurable options to trivially tune these metrics and thus affords time to the developers for implementing, evaluating, and comparing multiple algorithms.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2032765098",
    "type": "article"
  },
  {
    "title": "Plugging Versus Logging",
    "doi": "https://doi.org/10.1145/2629455",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Li-Pin Chang; Yo-Chuan Su; I‐Chen Wu",
    "corresponding_authors": "",
    "abstract": "A promising technique to improve the write performance of solid-state disks (SSDs) is to use a disk write buffer. The goals of a write buffer is not only to reduce the write traffic to the flash chips but also to convert host write patterns into long and sequential write bursts. This study proposes a new buffer design consisting of a replacement policy and a write-back policy. The buffer monitors how the host workload stresses the flash translation layer upon garbage collection. This is used to dynamically adjust its replacement and write-back strategies for a good balance between write sequentiality and write randomness. When the garbage collection overhead is low, the write buffer favors high write sequentiality over low write randomness. When the flash translation layer observes a high overhead of garbage collection, the write buffer favors low write randomness over high write sequentiality. The proposed buffer design outperformed existing approaches by up to 20% under various workloads and flash translation algorithms, as will be shown in experiment results.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2035211082",
    "type": "article"
  },
  {
    "title": "Maintaining real-time application timing similarity for defect-tolerant NoC-based many-core systems",
    "doi": "https://doi.org/10.1145/2544375.2544384",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Zheng Li; Frank Lockom; Shangping Ren",
    "corresponding_authors": "",
    "abstract": "Many-core Network-on-Chip (NoC) processors are emerging in broad application areas, including those with timing requirements, such as real-time and multimedia applications. Typically, these processors employ core-level backup to improve yield. However, when defective cores are replaced by backup ones, the NoC topology changes. Consequently, a fine-tuned application based on timing parameters given by one topology may not meet the expected timing behavior under the new one. We first develop a metric to measure timing similarity of an application on different NoC topologies and then propose mixed binary quadratic programming and greedy algorithms to reconfigure a defect-tolerant many-core NoC.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2039220072",
    "type": "article"
  },
  {
    "title": "A high-throughput pipelined parallel architecture for JPEG XR encoding",
    "doi": "https://doi.org/10.1145/2362336.2362339",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Hiroshi Tsutsui; Koichi Hattori; Hiroyuki Ochi; Yukihiro Nakamura",
    "corresponding_authors": "",
    "abstract": "JPEG XR is an emerging image coding standard, based on HD Photo developed by Microsoft Corporation. It supports high compression performance twice as high as the de facto image coding system, namely, JPEG, and also has an advantage over JPEG 2000 in terms of computational cost. JPEG XR is expected to be widespread for many devices including embedded systems in the near future. In this article, we propose a novel architecture for JPEG XR encoding. In previous architectures, entropy coding was the throughput bottleneck because it was implemented as a sequential algorithm to handle data with dependency. We found that there is no dependency in intra-macroblock data, and we could safely pipeline all the encoding processes including the entropy coding. In addition, each module of our architecture, which can be regarded as a pipeline stage, can be parallelized. As a result, our architecture can achieve 12.8 pixel/cycle at its maximum. To demonstrate our architecture, we designed three versions of our architecture with different degrees of parallelism of one, two, and four. Our four-way parallel architecture achieves 579 Mpixel/sec at 181MHz clock frequency for grayscale images.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2048150299",
    "type": "article"
  },
  {
    "title": "A Multiple-FPGA parallel computing architecture for real-time simulation of soft-object deformation",
    "doi": "https://doi.org/10.1145/2560031",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Behzad Mahdavikhah; Ramin Mafi; Shahin Sirouspour; Nicola Nicolici",
    "corresponding_authors": "",
    "abstract": "Hardware-based parallel computing is proposed for acceleration of finite-element (FE) analysis of linear elastic deformation models. An implementation of the Preconditioned Conjugate Gradient algorithm on N Field Programmable Gate Array (FPGA) devices solves the large linear system of equations arising from the FE discretization. The system employs a large number of customized fixed-point computing units with a high-throughput memory architecture. An implementation of this scalable architecture on four Altera EP3SE110 FPGA devices yields a peak performance of 604 Giga Operations per second. This enables haptic simulation of a 3-dimensional deformable object of 21000 elements at an update rate of 400Hz.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2049882446",
    "type": "article"
  },
  {
    "title": "Embedded RAIDs-on-chip for bus-based chip-multiprocessors",
    "doi": "https://doi.org/10.1145/2533316",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Luis Angel D. Bathen; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "The dual effects of larger die sizes and technology scaling, combined with aggressive voltage scaling for power reduction, increase the error rates for on-chip memories. Traditional on-chip memory reliability techniques (e.g., ECC) incur significant power and performance overheads. In this article, we propose a low-power-and-performance-overhead Embedded RAID (E-RAID) strategy and present Embedded RAIDs-on-Chip (E-RoC), a distributed dynamically managed reliable memory subsystem for bus-based Chip-Multiprocessors. E-RoC achieves reliability through redundancy by optimizing RAID-like policies tuned for on-chip distributed memories. We achieve on-chip reliability of memories through the use of Distributed Dynamic ScratchPad Allocatable Memories (DSPAMs) and their allocation policies. We exploit aggressive voltage scaling to reduce power consumption overheads due to parallel DSPAM accesses, and rely on the E-RoC Manager to automatically handle any resulting voltage-scaling-induced errors. We demonstrate how E-RAIDs can further enhance the fault tolerance of traditional memory reliability approaches by designing E-RAID levels that exploit ECC. Finally, we show the power and flexibility of the E-RoC concept by showing the benefits of having a heterogeneous E-RAID levels that fit each application's needs (fault tolerance, power/energy, performance). Our experimental results on CHStone/Mediabench II benchmarks show that our E-RAID levels converge to 100% error-free data rates much faster than traditional ECC approaches. Moreover, E-RAID levels that exploit ECC can guarantee 99.9% error-free data rates at ultra low Vdd on average, where as traditional ECC approaches were able to attain at most 99.1% error-free data rates. We observe an average of 22% dynamic power consumption increase by using traditional ECC approaches with respect to the baseline (non-voltage scaled SPMs), whereas our E-RAID levels are able to save dynamic power consumption by an average of 27% (w.r.t. the same non-voltage scaled SPMs baseline), while incurring worst-case 2% higher performance overheads than traditional ECC approaches. By voltage scaling the memories, we see that traditional ECC approaches are able to save static energy by 6.4% (average), where as our E-RAID approaches achieve 23.4% static energy savings (average). Finally, we observe that mixing E-RAID levels allows us to further reduce the dynamic power consumption by up to 55.5% at the cost of an average 5.6% increase in execution time over traditional approaches.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2050260120",
    "type": "article"
  },
  {
    "title": "Optimization of Shared High-Performance Reconfigurable Computing Resources",
    "doi": "https://doi.org/10.1145/2220336.2220348",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Melissa C. Smith; Gregory D. Peterson",
    "corresponding_authors": "",
    "abstract": "In the field of high-performance computing, systems harboring reconfigurable devices, such as field-programmable gate arrays (FPGAs), are gaining more widespread interest. Such systems range from supercomputers with tightly coupled reconfigurable hardware to clusters with reconfigurable devices at each node. The use of these architectures for scientific computing provides an alternative for computationally demanding problems and has advantages in metrics, such as operating cost/performance and power/performance. However, performance optimization of these systems can be challenging even with knowledge of the system’s characteristics. Our analytic performance model includes parameters representing the reconfigurable hardware, application load imbalance across the nodes, background user load, basic message-passing communication, and processor heterogeneity. In this article, we provide an overview of the analytical model and demonstrate its application for optimization and scheduling of high-performance reconfigurable computing (HPRC) resources. We examine cost functions for minimum runtime and other optimization problems commonly found in shared computing resources. Finally, we discuss additional scheduling issues and other potential applications of the model.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2055852614",
    "type": "article"
  },
  {
    "title": "legaSCi",
    "doi": "https://doi.org/10.1145/2678018",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Christoph Schumacher; Jan Henrik Weinstock; Rainer Leupers; Gerd Ascheid; Laura Tosoratto; A. Lonardo; Dietmar Petras; Andreas Hoffmann",
    "corresponding_authors": "",
    "abstract": "Architects and developers use virtual prototypes of computer systems to receive early feedback on hardware design decisions as well as to develop and debug system software. This is facilitated by the comprehensive inspection capabilities virtual prototypes offer. For virtual prototypes, execution speed is crucial to support the users' productivity. Parallel simulation techniques are employed to offset the speed impact of the increasing number of cores that need to be simulated in virtual prototypes of parallel and embedded systems. SystemC is the de facto industry standard library for virtual platform modeling. Since currently no parallel SystemC library is commonly available, typical SystemC models are coded for execution in sequential simulation environments. Simply putting such models into parallel simulators may lead to thread-safety issues and may additionally cause nondeterministic simulator behavior. This article proposes a methodology to support simulation creators to face the challenge of integrating such legacy models into parallel SystemC environments. The feasibility of the proposed method is evaluated by parallelizing the latest instance of the EU FP7 project EURETILE embedded platform simulator. Using legaSCi , on four host processor cores a speedup of 2.13× is demonstrated, without having to change the individual models of the simulator.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2064489453",
    "type": "article"
  },
  {
    "title": "Efficient Spilling Reduction for Software Pipelined Loops in Presence of Multiple Register Types in Embedded VLIW Processors",
    "doi": "https://doi.org/10.1145/2043662.2043671",
    "publication_date": "2011-11-01",
    "publication_year": 2011,
    "authors": "Sid‐Ahmed‐Ali Touati; Frédéric Brault; Karine Deschinkel; Benoît Dupont de Dinechin",
    "corresponding_authors": "",
    "abstract": "Integrating register allocation and software pipelining of loops is an active research area. We focus on techniques that precondition the dependence graph before software pipelining in order to ensure that no register spill instructions are inserted by the register allocator in the software pipelined loop. If spilling is not necessary for the input code, preconditioning techniques insert dependence arcs so that the maximum register pressure MAXLIVE achieved by any loop schedule is below the number of available registers, without hurting the initiation interval if possible. When a solution exists, a spill-free software pipeline is guaranteed to exist. Existing preconditioning techniques consider one register type (register class) at a time [Deschinkel and Touati 2008]. In this article, we extend preconditioning techniques so that multiple register types are considered simultaneously. First, we generalize the existing theory of register pressure minimization for cyclic scheduling. Second, we implement our method inside the production compiler of the ST2xx VLIW family, and we demonstrate its efficiency on industry benchmarks (FFMPEG, MEDIABENCH, SPEC2000, SPEC2006). We demonstrate a high spill reduction rate without a significant initiation interval loss.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2085645834",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2820608",
    "publication_date": "2015-10-20",
    "publication_year": 2015,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2088764746",
    "type": "editorial"
  },
  {
    "title": "Demand Paging Techniques for Flash Memory Using Compiler Post-Pass Optimizations",
    "doi": "https://doi.org/10.1145/2043662.2043664",
    "publication_date": "2011-11-01",
    "publication_year": 2011,
    "authors": "Seungkyun Kim; Kiwon Kwon; Chihun Kim; Choonki Jang; Jaejin Lee; Sang Lyul Min",
    "corresponding_authors": "",
    "abstract": "In this article, we propose an application-specific demand paging mechanism for low-end embedded systems that have flash memory as secondary storage. These systems are not equipped with virtual memory. A small memory space called an execution buffer is used to page the code of an application. An application-specific page manager manages the buffer. The page manager is automatically generated by a compiler post-pass optimizer and combined with the application image. The post-pass optimizer analyzes the executable image and transforms function call/return instructions into calls to the page manager. As a result, each function in the code can be loaded into the memory on demand at runtime. To minimize the overhead incurred by the demand paging technique, code clustering algorithms are also presented. We evaluate our techniques with ten embedded applications, and our approach can reduce the code memory size by on average 39.5% with less than 10% performance degradation and on average 14% more energy consumption. Our demand paging technique provides embedded system designers with a trade-off control mechanism between the cost, performance, and energy efficiency in designing embedded systems. Embedded system designers can choose the code memory size depending on their cost, energy, and performance requirements.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2091270106",
    "type": "article"
  },
  {
    "title": "Special issue on embedded systems for interactive multimedia services (ES-IMS)",
    "doi": "https://doi.org/10.1145/2423636.2423637",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Jongsung Kim; Javier Barria; J. Morris Chang; Victor C. M. Leung",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2091804650",
    "type": "article"
  },
  {
    "title": "Reconfigurable vertical profiling framework for the android runtime system",
    "doi": "https://doi.org/10.1145/2544375.2544379",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Tzu-Hsiang Su; Hsiang-Jen Tsai; Keng-Hao Yang; Po-Chun Chang; Tien-Fu Chen; Yiting Zhao",
    "corresponding_authors": "",
    "abstract": "Dalvik virtual machine in the Android system creates a profiling barrier between VM-space applications and Linux user-space libraries. It is difficult for existing profiling tools on the Android system to definitively identify whether a bottleneck occurred in the application level, the Linux user-space level, or the Linux kernel level. Information barriers exist between VM-space applications and Linux native analysis tools due to runtime virtual machines' dynamic memory allocation mechanism. Furthermore, traditional vertical profiling tools targeted for Java virtual machines cannot be simply applied on the Dalvik virtual machine due to its unique design. The proposed the Reconfigurable Vertical Profiling Framework bridges the information gap and streamlines the hardware-software co-design process for the Android runtime system.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2092183783",
    "type": "article"
  },
  {
    "title": "Joint WCET and Update Activity Minimization for Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/2680539",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Yazhi Huang; Mengying Zhao; Chun Jason Xue",
    "corresponding_authors": "",
    "abstract": "A cyber-physical system (CPS) is a desirable computing platform for many industrial and scientific applications, such as industrial process monitoring, environmental monitoring, chemical processes, and battlefield surveillance. The application of CPSs has two challenges: First, CPSs often include a number of sensor nodes. Update of preloaded code on remote sensor nodes powered by batteries is extremely energy consuming. The code update issue in the energy-sensitive CPS must be carefully considered. Second, CPSs are often real-time embedded systems with real-time properties. Worst-case execution time (WCET) is one of the most important metrics in real-time system design. Whereas existing works only consider one of these two challenges at a time, in this article, a compiler optimization—joint WCET and update-conscious compilation, or WUCC—is proposed to jointly consider WCET and code update for CPSs. The novelty of the proposed approach is that the WCET problem and code update problem are considered concurrently such that a balanced solution with minimal WCET and minimal code difference can be achieved. The experimental results show that the proposed technique can minimize WCET and code difference effectively.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2105773529",
    "type": "article"
  },
  {
    "title": "GPU-optimized volume ray tracing for massive numbers of rays in radiotherapy",
    "doi": "https://doi.org/10.1145/2539036.2539038",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Bo Zhou; Kai Xiao; Danny Z. Chen; Xiaobo Sharon Hu",
    "corresponding_authors": "",
    "abstract": "Ray tracing within a uniform grid volume is a fundamental process invoked frequently by many applications, especially radiation-dose calculation methods in radiotherapy. However, the conflicting features between the GPU memory architecture and the memory-accessing patterns of volume ray tracing lead to inefficient usage of GPU memory bandwidth and waste of capability of modern GPUs. To improve the ray tracing performance on GPU, we propose a lookup-table-based ray tracing method which is specially optimized towards the GPU memory system for processing a massive number of rays. The proposed method is based on a key observation that many of these applications normally involves a massive number of rays, but their ray tracing may not need to follow a specific execution order. Therefore, we divide the 3D space into many regions (called pyramids) and group together the rays falling into the same pyramid. For each ray group, the volume is rotated and resampled for their raytracing. This divide-and-rotate strategy allows the memory access of the ray tracing process to adopt a table-lookup approach and leads to better memory coalescing on GPU. Our proposed method was thoroughly evaluated in four volume setups with randomly-generated rays. The collapsed-cone convolution/superposition (CCCS) dose calculation method is also implemented with/without the proposed approach to verify the feasibility of our method. Compared with the direct GPU implementation of the popular 3DDDA algorithm, our method provides a speedup in the range of 1.91--2.94X for the volume settings we used. Major performance factors, including ray origins, volume size, and pyramid size, are also analyzed. The proposed technique was also found to be able to give a speedup of 1.61--2.17X over the original GPU implementation of the CCCS algorithm. Our experiment results indicate that the proposed approach is capable of offering better coalesced memory access which eventually boosts the raytracing performance on GPU. Moreover, our approach is conceptually simple and can be readily included into various applications.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2139987074",
    "type": "article"
  },
  {
    "title": "Communication Optimizations for Multithreaded Code Generation from Simulink Models",
    "doi": "https://doi.org/10.1145/2644811",
    "publication_date": "2015-05-21",
    "publication_year": 2015,
    "authors": "Kai Huang; Min Yu; Rongjie Yan; Xiaomeng Zhang; Xiaolang Yan; Lisane Brisolara; Ahmed Jerraya; Jiong Feng",
    "corresponding_authors": "",
    "abstract": "Communication frequency is increasing with the growing complexity of emerging embedded applications and the number of processors in the implemented multiprocessor SoC architectures. In this article, we consider the issue of communication cost reduction during multithreaded code generation from partitioned Simulink models to help designers in code optimization to improve system performance. We first propose a technique combining message aggregation and communication pipeline methods, which groups communications with the same destinations and sources and parallelizes communication and computation tasks. We also present a method to apply static analysis and dynamic emulation for efficient communication buffer allocation to further reduce synchronization cost and increase processor utilization. The existing cyclic dependency in the mapped model may hinder the effectiveness of the two techniques. We further propose a set of optimizations involving repartition with strongly connected threads to maximize the degree of communication reduction and preprocessing strategies with available delays in the model to reduce the number of communication channels that cannot be optimized. Experimental results demonstrate the advantages of the proposed optimizations with 11--143% throughput improvement.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2201299402",
    "type": "article"
  },
  {
    "title": "Incremental Bisimulation Abstraction Refinement",
    "doi": "https://doi.org/10.1145/2627352",
    "publication_date": "2014-07-01",
    "publication_year": 2014,
    "authors": "Lei Song; Lijun Zhang; Holger Hermanns; Jens Chr. Godskesen",
    "corresponding_authors": "",
    "abstract": "Abstraction refinement techniques in probabilistic model checking are prominent approaches for verification of very large or infinite-state probabilistic concurrent systems. At the core of the refinement step lies the implicit or explicit analysis of a counterexample. This article proposes an abstraction refinement approach for the probabilistic computation tree logic (PCTL), which is based on incrementally computing a sequence of may- and must-quotient automata. These are induced by depth-bounded bisimulation equivalences of increasing depth. The approach is both sound and complete, since the equivalences converge to the genuine PCTL equivalence. Experimental results with a prototype implementation show the effectiveness of the approach.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2660972524",
    "type": "article"
  },
  {
    "title": "Store-n-Learn: Classification and Clustering with Hyperdimensional Computing across Flash Hierarchy",
    "doi": "https://doi.org/10.1145/3503541",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Saransh Gupta; Behnam Khaleghi; Sahand Salamat; Justin Morris; R. Ramkumar; Jeffrey Xu Yu; Aniket Tiwari; Jaeyoung Kang; Mohsen Imani; Barış Akşanlı; Tajana Rosing",
    "corresponding_authors": "",
    "abstract": "Processing large amounts of data, especially in learning algorithms, poses a challenge for current embedded computing systems. Hyperdimensional (HD) computing (HDC) is a brain-inspired computing paradigm that works with high-dimensional vectors called hypervectors . HDC replaces several complex learning computations with bitwise and simpler arithmetic operations at the expense of an increased amount of data due to mapping the data into high-dimensional space. These hypervectors, more often than not, cannot be stored in memory, resulting in long data transfers from storage. In this article, we propose Store-n-Learn, an in-storage computing solution that performs HDC classification and clustering by implementing encoding, training, retraining, and inference across the flash hierarchy. To hide the latency of training and enable efficient computation, we introduce the concept of batching in HDC. We also present on-chip acceleration for HDC encoding in flash planes. This enables us to exploit the high parallelism provided by the flash hierarchy and encode multiple data points in parallel in both batched and non-batched fashion. Store-n-Learn also implements a single top-level FPGA accelerator with novel implementations for HDC classification training, retraining, inference, and clustering on the encoded data. Our evaluation over 10 popular datasets shows that Store-n-Learn is on average 222× (543×) faster than CPU and 10.6× (7.3×) faster than the state-of-the-art in-storage computing solution, INSIDER for HDC classification (clustering).",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4210477058",
    "type": "article"
  },
  {
    "title": "Accelerated Fire Detection and Localization at Edge",
    "doi": "https://doi.org/10.1145/3510027",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Arijit Mukherjee; Jayeeta Mondal; S. Dey",
    "corresponding_authors": "",
    "abstract": "Fire-related incidents continue to be reported as a leading cause of life and property destruction. Automated fire detection and localization (AFDL) systems have grown in importance with the evolution of applied robotics, especially because use of robots in disaster situations can lead to avoidance of human fatality. The importance of AFDL on resource-constrained devices has further grown, as most unmanned vehicles (drones or ground vehicles) are battery operated with limited computational capacity, the disaster situations cannot guarantee uninterrupted communication with high-end resources in the cloud, and yet faster response time is a prime necessity. Traditional computer vision–based techniques require hand-engineered features on a case-by-case basis. Deep Learning –based classifiers perform well for fire/no-fire classification due to the availability of large datasets for training; however, a dearth of good fire localization datasets renders the localization performance below par. We have tried to address both problems with a multi-task learned cascaded model that triggers localization workflow only if the presence of fire is detected, through a strong classifier trained on available large fire datasets. This presents only fire images to a relatively weaker localization model, reducing false positives, false negatives, and thereby improving overall AFDL accuracy. The multi-task learning (MTL) approach for end-to-end training of a stitched classifier and object localizer model on diverse datasets enabled us to build a strong fire classifier and feature extractor. It also resulted in a single unified model, capable of running on “on-board” compute infrastructure without compromising on accuracy. To achieve the target inference rate for the AFDL deployment, we have investigated the effect of quantization and compression due to hardware acceleration on an MTL model. This article presents an approach to automate the hardware-software co-design to find the optimum parameter partitioning for a given MTL problem, especially when some parts of the model are hardware accelerated. We present combined evaluation results showing that our methodology and the corresponding AFDL model strikes a balance between the frames inferred per second and several accuracy metrics. We report fire localization accuracy in terms of mean average precision (object detection), which has not been done earlier for embedded AFDL systems.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4210537645",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Memory and Storage Systems for Embedded and IoT Applications",
    "doi": "https://doi.org/10.1145/3505283",
    "publication_date": "2022-01-31",
    "publication_year": 2022,
    "authors": "Yuan-Hao Chang; Jalil Boukhobza; Song Han",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Issue on Memory and Storage Systems for Embedded and IoT Applications Editors: Yuan-Hao Chang Academia Sinica, Taiwan Academia Sinica, TaiwanView Profile , Jalil Boukhobza ENSTA-Bretagne, Lab-STICC UMR CNRS 6285, France ENSTA-Bretagne, Lab-STICC UMR CNRS 6285, FranceView Profile , Song Han University of Connecticut, United States University of Connecticut, United StatesView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 21Issue 1January 2022 Article No.: 1pp 1–4https://doi.org/10.1145/3505283Online:10 February 2022Publication History 0citation234DownloadsMetricsTotal Citations0Total Downloads234Last 12 Months234Last 6 weeks22 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4211184288",
    "type": "article"
  },
  {
    "title": "Leveraging Computational Storage for Power-Efficient Distributed Data Analytics",
    "doi": "https://doi.org/10.1145/3528577",
    "publication_date": "2022-04-20",
    "publication_year": 2022,
    "authors": "Ali HeydariGorji; Siavash Rezaei; Mahdi Torabzadehkashi; Hossein Bobarshad; V.C. Alves; Pai H. Chou",
    "corresponding_authors": "",
    "abstract": "This article presents a family of computational storage drives (CSDs) and demonstrates their performance and power improvements due to in-storage processing (ISP) when running big data analytics applications. CSDs are an emerging class of solid state drives that are capable of running user code while minimizing data transfer time and energy. Applications that can benefit from in situ processing include distributed training, distributed inferencing, and databases. To achieve the full advantage of the proposed ISP architecture, we propose software solutions for workload balancing before and at runtime for training and inferencing applications. Other applications such as sharding-based databases can readily take advantage of our ISP structure without additional tooling. Experimental results on different capacity and form factors of CSDs show up to 3.1× speedup in processing while reducing the energy consumption and data transfer by up to 67% and 68%, respectively, compared to regular enterprise solid state drives.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4224224219",
    "type": "article"
  },
  {
    "title": "A Fall Detection Network by 2D/3D Spatio-temporal Joint Models with Tensor Compression on Edge",
    "doi": "https://doi.org/10.1145/3531004",
    "publication_date": "2022-04-30",
    "publication_year": 2022,
    "authors": "Shuwei Li; Changhai Man; Ao Shen; Ziyi Guan; Wei Mao; Shaobo Luo; Rumin Zhang; Hao Yu",
    "corresponding_authors": "",
    "abstract": "Falling is ranked highly among the threats in elderly healthcare, which promotes the development of automatic fall detection systems with extensive concern. With the fast development of the Internet of Things (IoT) and Artificial Intelligence (AI), camera vision-based solutions have drawn much attention for single-frame prediction and video understanding on fall detection in the elderly by using Convolutional Neural Network (CNN) and 3D-CNN, respectively. However, these methods hardly supervise the intermediate features with good accurate and efficient performance on edge devices, which makes the system difficult to be applied in practice. This work introduces a fast and lightweight video fall detection network based on a spatio-temporal joint-point model to overcome these hurdles. Instead of detecting fall motion by the traditional CNNs, we propose a Long Short-Term Memory (LSTM) model based on time-series joint-point features extracted from a pose extractor . We also introduce the increasingly mature RGB-D camera and propose 3D pose estimation network to further improve the accuracy of the system. We propose to apply tensor train decomposition on the model to reduce storage and computational consumption so the deployment on edge devices can to realized. Experiments are conducted to verify the proposed framework. For fall detection task, the proposed video fall detection framework achieves a high sensitivity of 98.46% on Multiple Cameras Fall, 100% on UR Fall, and 98.01% on NTU RGB-D 120. For pose estimation task, our 2D model attains 73.3 mAP in the COCO keypoint challenge, which outperforms the OpenPose by 8%. Our 3D model attains 78.6% mAP on NTU RGB-D dataset with 3.6× faster speed than OpenPose.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4225154541",
    "type": "article"
  },
  {
    "title": "RDF: A Reconfigurable Dataflow Model of Computation",
    "doi": "https://doi.org/10.1145/3544972",
    "publication_date": "2022-06-27",
    "publication_year": 2022,
    "authors": "Pascal Fradet; Alain Girault; Ruby Krishnaswamy; Xavier Nicollin; Arash Shafiei",
    "corresponding_authors": "",
    "abstract": "Dataflow Models of Computation (MoCs) are widely used in embedded systems, including multimedia processing, digital signal processing, telecommunications, and automatic control. In a dataflow MoC, an application is specified as a graph of actors connected by FIFO channels. One of the first and most popular dataflow MoCs, Synchronous Dataflow (SDF), provides static analyses to guarantee boundedness and liveness, which are key properties for embedded systems. However, SDF and most of its variants lack the capability to express the dynamism needed by modern streaming applications. In particular, the applications mentioned above have a strong need for reconfigurability to accommodate changes in the input data, the control objectives, or the environment. We address this need by proposing a new MoC called Reconfigurable Dataflow (RDF). RDF extends SDF with transformation rules that specify how and when the topology and actors of the graph may be reconfigured. Starting from an initial RDF graph and a set of transformation rules, an arbitrary number of new RDF graphs can be generated at runtime. A key feature of RDF is that it can be statically analyzed to guarantee that all possible graphs generated at runtime will be consistent and live. We introduce the RDF MoC, describe its associated static analyses, and present its implementation and some experimental results.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4226166295",
    "type": "article"
  },
  {
    "title": "PISCOT: A Pipelined Split-Transaction COTS-Coherent Bus for Multi-Core Real-Time Systems",
    "doi": "https://doi.org/10.1145/3556975",
    "publication_date": "2022-08-22",
    "publication_year": 2022,
    "authors": "Salah Hessien; Mohamed Hassan",
    "corresponding_authors": "",
    "abstract": "Tasks in modern embedded systems such as automotive and avionics communicate among each other using shared data towards achieving the desired functionality of the whole system. In commodity platforms, cores communicate data through the shared memory hierarchy and correctness is maintained by a cache coherence protocol. Recent works investigated the deployment of coherence protocols in real-time systems and showed significant performance improvements. Nonetheless, we find these works to require modifications to commodity coherence protocols, assume simple in-order pipelines, and most importantly suffer from significant latency delays due to coherence interference along with average performance degradation. In this work, we propose PISCOT : a predictable and coherent bus architecture that (i) provides a considerably tighter bound compared to the state-of-the-art predictable coherent solutions (4× tighter bounds in a quad-core system). (ii) It does so with a negligible performance loss compared to conventional high-performance architecture coherence delays (less than 4% for SPLASH-3 benchmarks). This improves average performance by up to 5× (2.8× on average) compared to its predictable coherence counterpart. Finally, (iii) it achieves that without requiring any modifications to conventional coherence protocols. We show this by integrating PISCOT on top of two protocols with a detailed implementation with complete transient states: MSI and MESI.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4292596050",
    "type": "article"
  },
  {
    "title": "Resource-demand Estimation for Edge Tensor Processing Units",
    "doi": "https://doi.org/10.1145/3520132",
    "publication_date": "2022-03-21",
    "publication_year": 2022,
    "authors": "Benedict Herzog; Stefan C. Reif; Judith Hemp; Timo Hönig; Wolfgang Schröder‐Preikschat",
    "corresponding_authors": "",
    "abstract": "Machine learning has shown tremendous success in a large variety of applications. The evolution of machine-learning applications from cloud-based systems to mobile and embedded devices has shifted the focus from only quality-related aspects towards the resource demand of machine learning. For embedded systems, dedicated accelerator hardware promises the energy-efficient execution of neural network inferences. Their precise resource demand in terms of execution time and power demand, however, is undocumented. Developers, therefore, face the challenge to fine-tune their neural networks such that their resource demand matches the available budgets. This article presents Precious , a comprehensive approach to estimate the resource demand of an embedded neural network accelerator. We generate randomised neural networks, analyse them statically, execute them on an embedded accelerator while measuring their actual power draw and execution time, and train estimators that map the statically analysed neural network properties to the measured resource demand. In addition, this article provides an in-depth analysis of the neural networks’ resource demands and the responsible network properties. We demonstrate that the estimation error of Precious can be below 1.5% for both power draw and execution time. Furthermore, we discuss what estimator accuracy is practically achievable and how much effort is required to achieve sufficient accuracy.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4293102214",
    "type": "article"
  },
  {
    "title": "Agile Acceleration of Stateful Hash-based Signatures in Hardware",
    "doi": "https://doi.org/10.1145/3567426",
    "publication_date": "2022-10-11",
    "publication_year": 2022,
    "authors": "Jan Philipp Thoma; Darius Hartlief; Tim Güneysu",
    "corresponding_authors": "",
    "abstract": "With the development of large-scale quantum computers, the current landscape of asymmetric cryptographic algorithms will change dramatically. Today’s standards like RSA, DSA, and ElGamal will no longer provide sufficient security against quantum attackers and need to be replaced with novel algorithms. In the face of these developments, NIST has already started a standardization process for new Key Encapsulation Mechanisms (KEMs) and Digital Signatures (DSs). Moreover, NIST has recommended the two stateful Hash-Based Signatures (HBSs) schemes XMSS and LMS for use in devices with a long expected lifetime and limited capabilities for maintenance. Both schemes are also standardized by the IETF. In this work, we present the first agile hardware implementation that supports both LMS and XMSS. Our design can instantiate either LMS, XMSS, or both schemes using a simple configuration setting. Leveraging the vast similarities of the two schemes, the hardware utilization of the agile design increases by 20% in LUTs and only 3% in Flip Flops (FFs) over a standalone XMSS implementation. Furthermore, our approach can easily be configured with an arbitrary number of hash cores and accelerators for the one-time signatures for different application scenarios. We evaluate our implementation on the Xilinx Artix-7 FPGA platform, which is the recommended target for PQC implementations by NIST. We explore potential tradeoffs in the design space and compare our results to previous work in this field.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4304190164",
    "type": "article"
  },
  {
    "title": "Synchronized Shared Memory and Black-box Procedural Abstraction: Towards a Formal Semantics of Blech",
    "doi": "https://doi.org/10.1145/3571585",
    "publication_date": "2024-08-14",
    "publication_year": 2024,
    "authors": "Friedrich Gretz; Franz-Josef Grosch; Michael Mendler; Stephan Scheele",
    "corresponding_authors": "",
    "abstract": "Traditional imperative synchronous programming languages heavily rely on a strict separation between data memory and communication signals. Signals can be shared between computational units but cannot be overwritten within a synchronous reaction cycle. Memory can be destructively updated but cannot be shared between concurrent threads. This incoherence makes traditional imperative synchronous languages cumbersome for the programmer. The recent definition of sequentially constructive synchronous languages offers an improvement. It removes the separation between data memory and communication signals and unifies both through the notion of clock synchronized shared memory . However, it still depends on global causality analyses, which precludes black-box procedural abstraction. This complicates reuse and composition of software components. This article shows how black-box procedural abstraction can be accommodated inside the sequentially constructive model of computation. We present the Sequentially Constructive Procedural Language ( SCoPL ) and its semantic theory of policy-constructive synchronous processes. SCoPL supports black-box procedural abstractions using policy interfaces to ensure that procedure calls are memory-safe and wait-free and their scheduling is determinate and causal. At the same time, a policy interface constrains the level of freedom for the implementation and subsequent refactoring of a procedure. As a result, policies enable separate compilation and composition of procedures. We present our extensions abstractly as a formal semantics for SCoPL and motivate it concretely in the context of the open-source, embedded, real-time language Blech .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4309287943",
    "type": "article"
  },
  {
    "title": "Customized FPGA Implementation of Authenticated Lightweight Cipher Fountain for IoT Systems",
    "doi": "https://doi.org/10.1145/3643039",
    "publication_date": "2024-01-26",
    "publication_year": 2024,
    "authors": "Zhengyuan Shi; Cheng Chen; Gangqiang Yang; Hongchao Zhou; Hailiang Xiong; Zhiguo Wan",
    "corresponding_authors": "",
    "abstract": "Authenticated Encryption with Associated-Data (AEAD) can ensure both confidentiality and integrity of information in encrypted communication. Distinctive variants are customized from AEAD to satisfy various requirements. In this paper, we take a 128-bit lightweight AEAD stream cipher Fountain as an example. We provide a general cryptographic solution with three Fountain variants. These three variants are for encryption, message authentication code (MAC) generation, and authenticated encryption with associated data, respectively. Besides, we propose area-saved and throughput-improved strategies for the FPGA implementation of Fountain. The conventional paralleled hardware implementation leads to much resource-consuming with higher parallel width. We propose a hybrid architecture with parallel and serial update modes simultaneously. We also analyze the trade-off between area occupation and authentication latency for those two architectures. According to our discussion, hybrid architectures can perform efficiently with higher throughput than most ciphers, including Grain-128 x32. Our Fountain keystream generator occupies 46 slices on Spartan-3 FPGAs, smaller than most ciphers with the same security level, and even smaller than the 80-bit security level cipher Trivium. In summary, the customized Fountain with optimized implementations on FPGA is suitable for various applications in the field of IoT.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4391258660",
    "type": "article"
  },
  {
    "title": "Flexible Updating of Internet of Things Computing Functions through Optimizing Dynamic Partial Reconfiguration",
    "doi": "https://doi.org/10.1145/3643825",
    "publication_date": "2024-02-01",
    "publication_year": 2024,
    "authors": "George Kornaros; Svoronos Leivadaros; Filippos Kolimbianakis",
    "corresponding_authors": "",
    "abstract": "With applications to become increasingly compute- and data-intensive, requiring more processing power, many Internet of Things (IoT) platforms in robots, drones, and autonomous vehicles that implement neural network inference, cryptographic functions or signal processing (e.g., multimedia, communication), employ field programmable gate arrays (FPGAs). At the same time, dynamic partial reconfiguration (DPR) in modern FPGAs enable changing the function of a part of the FPGA by dynamically loading new bitstreams to the logic regions without affecting the function of other parts of the FPGA. This is especially useful to update functions of IoT devices while in operation for bug fixing or functionality adjustments and, more importantly, when these IoT devices integrate low-cost FPGAs that can hardly realize many hard accelerators. To deal with one of the major limitations of using partial reconfiguration in IoT devices, this work introduces techniques to flexibly use DPR, namely, FLEXDPR, by sharing reconfigurable partitions among different accelerator functions and by supporting virtual relocation of these functions. Experimental results on the Xilinx Zynq-7000 platform reveal energy and latency efficiency improvements of about 20%, on average. Overall, the suggested approach can reduce partial reconfiguration overhead while easing the scheduler’s decisions for the deployment of hardware functions throughout time and space in a performance-conscious manner.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4391449155",
    "type": "article"
  },
  {
    "title": "A Space-Grained Cleaning Method to Reduce Long-Tail Latency of DM-SMR Disks",
    "doi": "https://doi.org/10.1145/3643827",
    "publication_date": "2024-02-06",
    "publication_year": 2024,
    "authors": "Chin-Hsien Wu; Cheng-Tze Lee; Yi-Ren Tsai; Cheng-Yen Wu",
    "corresponding_authors": "",
    "abstract": "DM-SMR (device-managed shingled magnetic recording) disks allocate a portion of disk space as the persistent cache (PC) to address the issue of overlapping tracks during data updates. When the PC space becomes insufficient, a space cleaning is triggered to reclaim its invalid space. However, the space cleaning is time-consuming and contributes to the long-tail latency of DM-SMR disks. In the article, we will propose a space-grained cleaning method that leverages various idle periods to effectively reduce the long-tail latency of DM-SMR disks. The objective is to perform a proper space-grained cleaning for a suitable space region at an appropriate time period, thereby preventing delays in subsequent I/O requests and reducing the long-tail latency associated with DM-SMR disks. The experimental results demonstrate a substantial reduction in the long-tail latency of DM-SMR disks through the proposed method.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4391568826",
    "type": "article"
  },
  {
    "title": "SPIMulator: A Spintronic Processing-in-memory Simulator for Racetracks",
    "doi": "https://doi.org/10.1145/3645112",
    "publication_date": "2024-02-08",
    "publication_year": 2024,
    "authors": "Pavia Bera; Stephen Cahoon; Sanjukta Bhanja; Alex K. Jones",
    "corresponding_authors": "",
    "abstract": "In-memory processing is becoming a popular method to alleviate the memory bottleneck of the Von Neumann computing model. With the goal of improving both latency and energy cost associated with such in-memory processing, emerging non-volatile memory technologies, such as Spintronic magnetic memory, are of particular interest, as they can provide a near-SRAM read/write performance and eliminate nearly all static energy without experiencing any endurance limitations. Spintronic Racetrack Memory (RM) further addresses density concerns of spin-transfer torque memory (STT-MRAM). Moreover, it has recently been demonstrated that portions of RM nanowires can function as a polymorphic gate, which can be leveraged to implement multi-operand bulk bitwise operations. With more complex control, they can also be leveraged to build arithmetic integer and floating point processing in memory (PIM) primitives. This article proposes SPIMulator, a Spintronic PIM sim ulator that can simulate the storage and PIM architecture of executing PIM commands in Racetrack memory. SPIMulator functionally models the polymorphic gate properties recently proposed for Racetrack memory, which allows transverse access that determines the number of “1”s in a segment of each Racetrack nanowire. From this simulation, SPIMulator can report real-time performance statistics such as cycle count and energy. Thus, SPIMulator simulates the multi-operand bit-wise logic operations recently proposed and can be easily extended to implement new PIM operations as they are developed. Due to the functional nature of SPIMulator, it can serve as a programming environment that allows development of PIM-based codes for verification of new acceleration algorithms. We demonstrate the value of SPIMulator through the modeling and estimations of performance and energy consumption of a variety of example applications, including the Advanced Encryption Standard (AES) for encryption primarily based on logical and look-up operations; multiplication of matrices, a frequent requirement in scientific, signal processing, and machine learning algorithms; and bitmap indices, a common search table employed for database lookups.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4391653851",
    "type": "article"
  },
  {
    "title": "Toward Energy-efficient STT-MRAM-based Near Memory Computing Architecture for Embedded Systems",
    "doi": "https://doi.org/10.1145/3650729",
    "publication_date": "2024-03-07",
    "publication_year": 2024,
    "authors": "Yueting Li; Xueyan Wang; He Zhang; Biao Pan; Keni Qiu; Wang Kang; Jun Wang; Weisheng Zhao",
    "corresponding_authors": "",
    "abstract": "Convolutional Neural Networks (CNNs) have significantly impacted embedded system applications across various domains. However, this exacerbates the real-time processing and hardware resource-constrained challenges of embedded systems. To tackle these issues, we propose spin-transfer torque magnetic random-access memory (STT-MRAM)-based near memory computing (NMC) design for embedded systems. We optimize this design from three aspects: Fast-pipelined STT-MRAM readout scheme provides higher memory bandwidth for NMC design, enhancing real-time processing capability with a non-trivial area overhead. Direct index compression format in conjunction with digital sparse matrix-vector multiplication (SpMV) accelerator supports various matrices of practical applications that alleviate computing resource requirements. Custom NMC instructions and stream converter for NMC systems dynamically adjust available hardware resources for better utilization. Experimental results demonstrate that the memory bandwidth of STT-MRAM achieves 26.7 GB/s. Energy consumption and latency improvement of digital SpMV accelerator are up to 64× and 1,120× across sparsity matrices spanning from 10% to 99.8%. Single-precision and double-precision elements transmission increased up to 8× and 9.6×, respectively. Furthermore, our design achieves a throughput of up to 15.9× over state-of-the-art designs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392553413",
    "type": "article"
  },
  {
    "title": "REC: REtime Convolutional layers to fully exploit harvested energy for ReRAM-based CNN accelerators",
    "doi": "https://doi.org/10.1145/3652593",
    "publication_date": "2024-03-15",
    "publication_year": 2024,
    "authors": "Kunyu Zhou; Keni Qiu",
    "corresponding_authors": "",
    "abstract": "As the Internet of Things (IoTs) increasingly combines AI technology, it is a trend to deploy neural network algorithms at edges and make IoT devices more intelligent than ever. Moreover, energy-harvesting technology-based IoT devices have shown the advantages of green and low-carbon economy, convenient maintenance, and theoretically infinite lifetime, and so on. However, the harvested energy is often unstable, resulting in low performance due to the fact that a fixed load cannot sufficiently utilize the harvested energy. To address this problem, recent works focusing on ReRAM-based convolutional neural networks (CNN) accelerators under harvested energy have proposed hardware/software optimizations. However, those works have overlooked the mismatch between the power requirement of different CNN layers and the variation of harvested power. Motivated by the above observation, this article proposes a novel strategy, called REC , that retimes convolutional layers of CNN inferences to improve the performance and energy efficiency of energy harvesting ReRAM-based accelerators. Specifically, at the offline stage, REC defines different power levels to fit the power requirements of different convolutional layers. At runtime, instead of sequentially executing the convolutional layers of an inference one by one, REC retimes the execution timeframe of different convolutional layers so as to accommodate different CNN layers to the changing power inputs. What is more, REC provides a parallel strategy to fully utilize very high power inputs. Moreover, a case study is presented to show that REC is effective to improve the real-time accomplishment of periodical critical inferences because REC provides an opportunity for critical inferences to preempt the process window with a high power supply. Our experimental results show that the proposed REC scheme achieves an average performance improvement of 6.1× (up to 16.5×) compared to the traditional strategy without the REC idea. The case study results show that the REC scheme can significantly improve the success rate of periodical critical inferences’ real-time accomplishment.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392849917",
    "type": "article"
  },
  {
    "title": "Characterizing Parameter Scaling with Quantization for Deployment of CNNs on Real-Time Systems",
    "doi": "https://doi.org/10.1145/3654799",
    "publication_date": "2024-03-30",
    "publication_year": 2024,
    "authors": "Calvin B. Gealy; Alan D. George",
    "corresponding_authors": "",
    "abstract": "Modern deep-learning models tend to include billions of parameters, reducing real-time performance. Embedded systems are compute-constrained while frequently used to deploy these models for real-time systems given size, weight, and power requirements. Tools like parameter-scaling methods help to shrink models to ease deployment. This research compares two scaling methods for convolutional neural networks, uniform scaling and NeuralScale, and analyzes their impact on inference latency, memory utilization, and power. Uniform scaling scales the number of filters evenly across a network. NeuralScale adaptively scales the model to theoretically achieve the highest accuracy for a target parameter count. In this study, VGG-11, MobileNetV2, and ResNet-50 models were scaled to four ratios: 0.25×, 0.50×, 0.75×, 1.00×. These models were benchmarked on an ARM Cortex-A72 CPU, an NVIDIA Jetson AGX Xavier GPU, and a Xilinx ZCU104 FPGA. Additionally, quantization was applied to meet real-time objectives. The CIFAR-10 and tinyImageNet datasets were studied. On CIFAR-10, NeuralScale creates more computationally intensive models than uniform scaling for the same parameter count, with relative speeds of 41% on the CPU, 72% on the GPU, and 96% on the FPGA. The additional computational complexity is a tradeoff for accuracy improvements in VGG-11 and MobileNetV2 NeuralScale models but reduced ResNet-50 NeuralScale accuracy. Furthermore, quantization alone achieves similar or better performance on the CPU and GPU devices when compared with models scaled to 0.50×, despite slight reductions in accuracy. On the GPU, quantization reduces latency by 2.7× and memory consumption by 4.3×. Uniform-scaling models are 1.8× faster and use 2.8× less memory. NeuralScale reduces latency by 1.3× and dropped memory by 1.1×. We find quantization to be a practical first tool for improved performance. Uniform scaling can easily be applied for additional improvements. NeuralScale may improve accuracy but tends to negatively impact performance, so more care must be taken with it.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4393342166",
    "type": "article"
  },
  {
    "title": "A Hardware Approach For Accelerating Inductive Learning In Description Logic",
    "doi": "https://doi.org/10.1145/3665277",
    "publication_date": "2024-05-21",
    "publication_year": 2024,
    "authors": "Eyad Algahtani",
    "corresponding_authors": "Eyad Algahtani",
    "abstract": "The employment of Machine Learning (ML) techniques in embedded systems has seen constant growth in recent years, especially for black-box ML techniques (such as Artificial Neural Networks (ANNs)). However, despite the successful employment of ML techniques in embedded environments, their performance potential is constrained by the limited computing resources of their embedded computers. Several hardware-based approaches were developed (e.g., using FPGAs and ASICs) to address the constraints of limited computing resources. The scope of this work focuses on improving the performance for Inductive Logic Programming (ILP) on embedded environments. ILP is a powerful logic-based ML technique that uses logic programming to construct human-interpretable ML models, where those logic-based ML models are capable of describing complex and multi-relational concepts. In this work, we present a hardware-based approach that accelerates the hypothesis evaluation task for ILPs in embedded environments that use Description Logic (DL) languages as their logic-based representation. In particular, we target the \\(\\mathcal {ALCQ}^{\\mathcal {(D)}}\\) language. According to experimental results (through an FPGA implementation), our presented approach has achieved speedups up to 48.7-fold for a disjunction of 32 concepts on 100 M individuals, where the baseline performance is the sequential CPU performance of the Raspberry Pi 4. For role and concrete role restrictions, the FPGA implementation achieved speedups up to 2.4-fold (for MIN cardinality role restriction on 1M role assertions); all FPGA implemented role and concrete role restrictions have achieved similar speedups. In the worst-case scenario, the FPGA implementation achieved either a similar or slightly better performance than the baseline (for all DL operations); the worst-case scenario resulted from using small datasets such as: using conjunction and disjunction on &lt; 100 individuals, and using role and concrete (float/string) role restrictions on &lt; 100,000 assertions.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4398179373",
    "type": "article"
  },
  {
    "title": "Multi-Traffic Resource Optimization for Real-Time Applications with 5G Configured Grant Scheduling",
    "doi": "https://doi.org/10.1145/3664621",
    "publication_date": "2024-05-28",
    "publication_year": 2024,
    "authors": "Yungang Pan; Rouhollah Mahfouzi; Soheil Samii; Petru Eles; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "The fifth-generation (5G) technology standard in telecommunications is expected to support ultra-reliable low latency communication to enable real-time applications such as industrial automation and control. 5G configured grant (CG) scheduling features a pre-allocated periodicity-based scheduling approach, which reduces control signaling time and guarantees service quality. Although this enables 5G to support hard real-time periodic traffics, synthesizing the schedule efficiently and achieving high resource efficiency, while serving multiple communications, are still an open problem. In this work, we study the trade-off between scheduling flexibility and control overhead when performing CG scheduling. To address the CG scheduling problem, we first formulate it using satisfiability modulo theories (SMT) so that an SMT solver can be used to generate optimal solutions. To enhance scalability, we propose two heuristic approaches. The first one as the baseline, Co1, follows the basic idea of the 5G CG scheduling scheme that minimizes the control overhead. The second one, CoU, enables increased scheduling flexibility while considering the involved control overhead. The effectiveness and scalability of the proposed techniques and the superiority of CoU compared to Co1 have been evaluated using a large number of generated benchmarks as well as a realistic case study for industrial automation.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4399084983",
    "type": "article"
  },
  {
    "title": "NIR-sighted: A Programmable Streaming Architecture for Low-Energy Human-Centric Vision Applications",
    "doi": "https://doi.org/10.1145/3672076",
    "publication_date": "2024-06-14",
    "publication_year": 2024,
    "authors": "John Mamish; Rawan Alharbi; Sougata Sen; Shashank Holla; Panchami Kamath; Yaman Sangar; Nabil Alshurafa; Josiah Hester",
    "corresponding_authors": "",
    "abstract": "Human studies often rely on wearable lifelogging cameras that capture videos of individuals and their surroundings to aid in visual confirmation or recollection of daily activities like eating, drinking, and smoking. However, this may include private or sensitive information that may cause some users to refrain from using such monitoring devices. Also, short battery lifetime and large form factors reduce applicability for long-term capture of human activity. Solving this triad of interconnected problems is challenging due to wearable embedded systems’ energy, memory, and computing constraints. Inspired by this critical use case and the unique design problem, we developed NIR-sighted, an architecture for wearable video cameras that navigates this design space via three key ideas: (i) reduce storage and enhance privacy by discarding masked pixels and frames, (ii) enable programmers to generate effective masks with low computational overhead, and (iii) enable the use of small MCUs by moving masking and compression off-chip. Combined together in an end-to-end system, NIR-sighted’s masking capabilities and off-chip compression hardware shrinks systems, stores less data, and enables programmer-defined obfuscation to yield privacy enhancement. The user’s privacy is enhanced significantly as nowhere in the pipeline is any part of the image stored before it is obfuscated. We design a wearable camera called NIR-sightedCam based on this architecture; it is compact and can record IR and grayscale video at 16 and 20+ fps, respectively, for 26 hours nonstop (59 hours with IR disabled) at a fraction of comparable platforms power draw. NIR-sightedCam includes a low-power Field Programmable Gate Array that implements our mJPEG compress/obfuscate hardware, Blindspot. We additionally show the potential for privacy-enhancing function and clinical utility via an in-lab eating study, validated by a nutritionist.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4399678326",
    "type": "article"
  },
  {
    "title": "Performance and Communication Cost of Hardware Accelerators for Hashing in Post-Quantum Cryptography",
    "doi": "https://doi.org/10.1145/3676965",
    "publication_date": "2024-07-09",
    "publication_year": 2024,
    "authors": "Patrick Karl; Jonas Schupp; Georg Sigl",
    "corresponding_authors": "",
    "abstract": "SPHINCS+ is a signature scheme included in the first NIST post-quantum standard, that bases its security on the underlying hash primitive. As most of the runtime of SPHINCS+ is caused by the evaluation of several hash- and pseudo-random functions, offloading this computation to dedicated hardware accelerators is a natural step. In this work, we evaluate different architectures for hardware acceleration of such a hash primitive with respect to its use-case and evaluate them in the context of SPHINCS+. We attach hardware accelerators for different hash primitives (SHAKE128 and Ascon-Xof for both, full and round-reduced versions) to CPU interfaces having different transfer speeds. We show, that for most use-cases, data transfer determines the overall performance if accelerators are equipped with FIFOs and that reducing the number of rounds in the permutation does not necessarily lead to significant performance improvements when using hardware acceleration. This work extends on a conference paper accepted at COSADE’24, first published in [19], and written by the same authors, where different architectures for hardware accelerators of hash functions are benchmarked and evaluated for SPHINCS+ as a case study. In this paper, we provide results for additional parameter sets for SPHINCS+ and improve the performance of one of the accelerators by adding an additional RISC-V instruction for faster absorption. We then extend the performance benchmark by including the algorithms CRYSTALS-Kyber, CRYSTALS-Dilithium and Falcon. Finally we provide a power/energy comparison for the accelerators.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400460429",
    "type": "article"
  },
  {
    "title": "Lightweight Champions of the World: Side-Channel Resistant Open Hardware for Finalists in the NIST Lightweight Cryptography Standardization Process",
    "doi": "https://doi.org/10.1145/3677320",
    "publication_date": "2024-07-17",
    "publication_year": 2024,
    "authors": "Kamyar Mohajerani; Luke Beckwith; Abubakr Abdulgadir; Jens-Peter Kaps; Kris Gaj",
    "corresponding_authors": "",
    "abstract": "Cryptographic competitions played a significant role in stimulating the development and release of open hardware for cryptography. The primary reason was the focus of standardization organizations and other contest organizers on transparency and fairness of hardware benchmarking, which could be achieved only with all source code made available for public scrutiny. Consequently, the number and quality of open-source hardware implementations developed during subsequent major competitions, such as AES, SHA-3, and CAESAR, have steadily increased. However, most of these implementations were still quite far from being used in future products due to the lack of countermeasures against side-channel analysis (SCA). In this paper, we discuss the first coordinated effort at developing SCA-resistant open hardware for all finalists of a cryptographic standardization process. The developed hardware is then evaluated by independent labs for information leakage and resilience to selected attacks. Our target included the ten finalists of the NIST Lightweight Cryptography Standardization Process. The authors’ contributions included formulating detailed requirements, publicizing the submissions, matching open hardware with suitable SCA-evaluation labs, developing a subset of all implementations, serving as one of the six evaluation labs, performing FPGA benchmarking of all protected and unprotected implementations, and summarizing results in the comprehensive report. Our results confirm that NIST made the right decision in selecting Ascon as a future lightweight cryptography standard. They also indicate that at least three other algorithms, Xoodyak, TinyJAMBU, and ISAP, were very strong competitors and outperformed Ascon in at least one of the evaluated performance metrics.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400796959",
    "type": "article"
  },
  {
    "title": "PredATW: Predicting the Asynchronous Time Warp Latency For VR Systems",
    "doi": "https://doi.org/10.1145/3677329",
    "publication_date": "2024-08-14",
    "publication_year": 2024,
    "authors": "Akanksha Dixit; Smruti R. Sarangi",
    "corresponding_authors": "",
    "abstract": "With the advent of low-power ultra-fast hardware and GPUs, virtual reality (VR) has gained a lot of prominence in the past few years and is being used in various areas, such as education, entertainment, scientific visualization, and computer-aided design. VR-based applications are highly interactive, and one of the most important performance metrics for these applications is the motion-to-photon-delay (MPD). MPD is the delay from the user’s head movement to the time at which the image gets updated on the VR screen. Since the human visual system can even detect an error of a few pixels (very spatially sensitive), the MPD should be as small as possible. Popular VR vendors use the GPU-accelerated Asynchronous Time Warp (ATW) algorithm to reduce the MPD. ATW reduces the MPD if and only if the warping operation finishes just before the display refreshes. However, due to the competition between the different constituent applications for the single, shared GPU, the GPU-accelerated ATW algorithm suffers from an unpredictable ATW latency, making it challenging to find the ideal time instance for starting the time warp and ensuring that it completes with the least amount of lag relative to the screen refresh. Hence, the state-of-the-art is to use a separate hardware unit for the time-warping operation. Our approach, PredATW , uses an ML-based hardware predictor to predict the ATW latency for a VR application, and then schedule it as late as possible while running the time-warping operation on the GPU itself. As far as we know, this is the first work to do so. Our predictor achieves an error of only 0.22 ms across several popular VR applications for predicting the ATW latency. As compared to the baseline architecture, we reduce deadline misses by 80.6%.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400829966",
    "type": "article"
  },
  {
    "title": "OffloaD: Detection Failure-based Scheduler for Offloading Object Detection",
    "doi": "https://doi.org/10.1145/3677321",
    "publication_date": "2024-08-28",
    "publication_year": 2024,
    "authors": "Clara Gómez; Davron Patkhullaev; Alejandra C. Hernandez",
    "corresponding_authors": "",
    "abstract": "The current times ask for resource-constrained devices such as drones, light mobile robots, XR glasses, or mobile phones to perform object detection efficiently and in real time. However, when executed on the device, object detection fails to achieve the accuracy requirements. In addition, depending on a powerful edge to offload computation is time-consuming as it requires the transmission of a large amount of data and limits the usage in degraded network conditions. In this article, we propose OffloaD, a novel offloading scheduler based on the detection of failures for object detection. The method addresses the problem of offloading between a resource-constrained device and an edge by leveraging the accuracy of the object detection model at the device and the network conditions. Accuracy is considered through a detection failure metric that consists of introspective, golden, and latency scores. Our main contribution is the offloading scheduler based on the detection of failures of the object detector, which reduces unnecessary data transmission without accuracy degradation. Our method demonstrates that offloading to expensive detectors will not always increase performance and enables detection results and failure estimations even if the network is degraded or unavailable. We implement OffloaD in a physical testbed and perform extensive comparisons against several baselines. The experiments suggest that our approach improves the overall precision-latency performance by reducing the end-to-end latency between 18% and 37% in ideal network conditions and a low latency increase in degraded network conditions while obtaining an accuracy with minimum degradation compared to the baselines. In addition, comparisons to related work methods demonstrate the state-of-the-art performance of OffloaD.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4401123216",
    "type": "article"
  },
  {
    "title": "NeuroTAP: Thermal and Memory Access Pattern-aware Data Mapping on 3D DRAM for Maximizing DNN Performance",
    "doi": "https://doi.org/10.1145/3677178",
    "publication_date": "2024-08-06",
    "publication_year": 2024,
    "authors": "Shailja Pandey; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "Deep neural networks (DNNs) have been widely adopted, owing to break-through performance and high accuracy. DNNs exhibit varying memory behavior involving specific and recognizable memory access patterns and access intensity, depending on the selected data reuse in different layers. Such applications have high memory bandwidth demands due to aggressive computations, performing several billion-floating-point-operations-per-second (BFLOPs). 3D DRAMs, providing very high memory access bandwidth, are extensively employed to break the memory wall , bridging the gap between compute and memory while running DNNs. However, the vertical integration in 3D DRAM introduces serious thermal issues, resulting from high power density and close proximity of memory cells, and requires dynamic thermal management (DTM). To unleash the true potential of 3D DRAM and exploit the enormous bandwidth under thermal constraints, there is a need to intelligently map the DNN application’s data across memory channels, pseudo-channels, and banks, minimizing the effective memory latency and reducing the thermal-induced application slowdown. The specific memory access patterns exhibited by a DNN layer execution are crucial to determine a favorable data mapping method for 3D DRAM dies that potentially causes minimal thermal impact and also maximizes DRAM bandwidth utilization. In this work, we propose an application-aware and thermal-sensitive data mapping that intelligently assigns portions of the 3D DRAM to DNN layers, leveraging the knowledge about layer’s memory access patterns and minimizing DTM-induced performance overheads. Additionally, we also deploy a DRAM low-power states based DTM mechanism to keep the 3D DRAM within safe thermal limits. Using our proposal, we observe a performance improvement of 1% to 61%, and memory energy savings of 1% to 55% for popular DNNs over state-of-the-art DTM strategies while running DNN inference.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4401367577",
    "type": "article"
  },
  {
    "title": "An Operational Quality Model of Embedded Software Aligned with ISO 25000",
    "doi": "https://doi.org/10.1145/3691642",
    "publication_date": "2024-09-10",
    "publication_year": 2024,
    "authors": "Yann Argotti; Yasmine Kenfaoui; Claude Baron; Alain Abran; Philippe Esteban",
    "corresponding_authors": "",
    "abstract": "Embedded systems omnipresent in everyday life and industry are mainly composed of hardware and software that must comply with a number of standards and regulations. However, there is no consensus on the quality characteristics and subcharacteristics of embedded software. This article presents the steps for modeling an operational quality model for embedded software aligned with the ISO 25000 series of quality models for traditional computer systems. From a literature review composed of 40 studies on quality modeling for embedded systems and software, 85 of the most frequent quality characteristics and subcharacteristics were first identified, including a subset of 16 referenced or cited in at least 25% of the literature. Next, the design of a quality model for embedded software aligned with the ISO 25000 series was proposed with 13 characteristics and 27 subcharacteristics. The operational aspect of this quality model for embedded software is addressed next through a set of measures and measurement functions from ISO 25000 to aggregate the results of the quantification of the characteristics and subcharacteristics. A survey involving 25 embedded software specialists is presented next to gauge, using Fleiss's Kappa criteria, their agreement with the proposed quality model. Furthermore, the computed importance weights derived from the survey participants’ individual opinions were compared with those derived from an analysis of 40 embedded software studies, bolstering the credibility of the model. The results of this study suggest that the proposed quality model can serve as a framework for evaluating and understanding the quality characteristics across diverse expertise levels. Furthermore, the convergence between the survey and the literature strengthens the model's credibility by anchoring it in both established literature and practitioners’ agreements.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4402391956",
    "type": "article"
  },
  {
    "title": "Scabbard: An Exploratory Study on Hardware Aware Design Choices of Learning with Rounding-based Key Encapsulation Mechanisms",
    "doi": "https://doi.org/10.1145/3696208",
    "publication_date": "2024-09-20",
    "publication_year": 2024,
    "authors": "Suparna Kundu; Quinten Norga; Angshuman Karmakar; S Gangopadhyay; Jose Maria Bermudo Mera; Ingrid Verbauwhede",
    "corresponding_authors": "",
    "abstract": "Recently, the construction of cryptographic schemes based on hard lattice problems has gained immense popularity. Apart from being quantum resistant, lattice-based cryptography allows a wide range of variations in the underlying hard problem. As cryptographic schemes can work in different environments under different operational constraints such as memory footprint, silicon area, efficiency, power requirement, etc., such variations in the underlying hard problem are very useful for designers to construct different cryptographic schemes. In this work, we explore various design choices of lattice-based cryptography and their impact on performance in the real world. In particular, we propose a suite of key-encapsulation mechanisms based on the learning with rounding problem with a focus on improving different performance aspects of lattice-based cryptography. Our suite consists of three schemes. Our first scheme is Florete, which is designed for efficiency. The second scheme is Espada, which is aimed at improving parallelization, flexibility, and memory footprint. The last scheme is Sable, which can be considered an improved version in terms of key sizes and parameters of the Saber key-encapsulation mechanism, one of the finalists in the National Institute of Standards and Technology’s post-quantum standardization procedure. In this work, we have described our design rationale behind each scheme. Further, to demonstrate the justification of our design decisions, we have provided software and hardware implementations. Our results show Florete is faster than most state-of-the-art KEMs on software platforms. For example, the key-generation algorithm of high-security version Florete outperforms the National Institute of Standards and Technology’s standard Kyber by \\(47\\% \\) , the Federal Office for Information Security’s standard Frodo by \\(99\\% \\) , and Saber by \\(57\\% \\) on the ARM Cortex-M4 platform. Similarly, in hardware, Florete outperforms Frodo and NTRU Prime for all KEM operations. The scheme Espada requires less memory and area than the implementation of most state-of-the-art schemes. For example, the encapsulation algorithm of high-security version Espada uses \\(30\\% \\) less stack memory than Kyber, \\(57\\% \\) less stack memory than Frodo, and \\(67\\% \\) less stack memory than Saber on the ARM Cortex-M4 platform. The implementations of Sable maintain a trade-off between Florete and Espada regarding software performance and memory requirements. Sable outperforms Saber at least by \\(6\\% \\) and Frodo by \\(99\\% \\) . Through an efficient polynomial multiplier design, which exploits the small secret size, Sable outperforms most state-of-the-art KEMs, including Saber, Frodo, and NTRU Prime. The implementations of Sable that use number theoretic transform-based polynomial multiplication (SableNTT) surpass all the state-of-the-art schemes in performance, which are optimized for speed on the Cortext M4 platform. The performance benefit of SableNTT against Kyber lies in between \\(7-29\\% \\) , \\(2-13\\% \\) for Saber, and around \\(99\\% \\) for Frodo.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4402686705",
    "type": "article"
  },
  {
    "title": "AttackDefense Framework (ADF): Enhancing IoT Devices and Lifecycles Threat Modeling",
    "doi": "https://doi.org/10.1145/3698396",
    "publication_date": "2024-10-08",
    "publication_year": 2024,
    "authors": "Tommaso Sacchetti; Márton Bognár; Jesse De Meulemeester; Benedikt Gierlichs; Frank Piessens; Volodymyr Bezsmertnyi; Maria Chiara Molteni; Stefano Cristalli; Arianna Gringiani; Olivier Thomas; Daniele Antonioli",
    "corresponding_authors": "",
    "abstract": "Threat modeling (TM) is essential to manage, prevent, and fix security and privacy issues in our society. TM requires a data model to represent threats and tools to exploit such data. Current TM data models and tools have significant limitations preventing their usage in real-world scenarios. For example, it is challenging to TM embedded devices with current data models and tools as they cannot model their hardware, firmware, and low-level software. Moreover, it is impossible to TM a device lifecycle or security-privacy tradeoffs as these data models and tools were developed for other use cases (e.g., software security or user privacy). We fill this relevant gap by presenting the AttackDefense Framework (ADF), which provides a novel data model and related tools to augment TM. ADF’s building block is the AD object that can be used to represent heterogeneous and complex threats. Moreover, ADF provides automations to process a collection of AD objects, including ways to create sets, maps, chains, trees, and wordclouds of AD objects. We present ADF , a toolkit implementing ADF composed of four modules (Catalog, Parse, Check, and Analyze). We confirm that the data model and tools provided by ADF are useful by running an extensive set of experiments while threat modeling a crypto wallet and its lifecycle. Our experiments involved seven expert groups from academia and industry, each using the ADF on an orthogonal threat class. The evaluation generated 175 high-quality ADs covering ISA/IEC 62433-4-1 SecDev Lifecycle, side-channels, fault injection, microarchitectural attacks, speculative execution, pre-silicon testing, invasive physical chip modifications, Bluetooth protocol and implementation threats, and FIDO2 authentication.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403221959",
    "type": "article"
  },
  {
    "title": "Reducing code size through address register assignment",
    "doi": "https://doi.org/10.1145/1132357.1132365",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "Gong Chen; Mahmut Kandemir; M.J. Irwin; J. Ramanujam",
    "corresponding_authors": "",
    "abstract": "In DSP processors, minimizing the amount of address calculations is critical for reducing code size and improving performance, since studies of programs have shown that instructions that manipulate address registers constitute a significant portion of the overall instruction count (up to 55%). This work presents a compiler-based optimization strategy to “reduce the code size in embedded systems.” Our strategy maximizes the use of indirect addressing modes with postincrement/decrement capabilities available in DSP processors. These modes can be exploited by ensuring that successive references to variables access consecutive memory locations. To achieve this spatial locality, our approach uses both access pattern modification (program code restructuring) and memory storage reordering (data layout restructuring). Experimental results on a set of benchmark codes show the effectiveness of our solution and indicate that our approach outperforms the previous approaches to the problem. In addition to resulting in significant reductions in instruction memory (storage) requirements, the proposed technique improves execution time.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2003725985",
    "type": "article"
  },
  {
    "title": "Instantaneous current modeling in a complex VLIW processor core",
    "doi": "https://doi.org/10.1145/1067915.1067923",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "Radu Mureşan; Catherine H. Gebotys",
    "corresponding_authors": "",
    "abstract": "Measuring and modeling instantaneous current consumption or current dynamics of a processor is important in embedded system designs, wireless communications, low-energy mobile computing, security of communications, and reliability. In this paper, we introduce a new instruction-level based macromodeling approach for instantaneous current consumption in a complex processor core along with new instantaneous current measurement techniques at the instruction and program level. Current consumption and voltage supply waveforms of a processor core were acquired by a sampling oscilloscope through an external interrupt-based setup. Accurate measurements of current, power and energy consumption at the instruction, block, or program level were obtained from analyzing the stored current and voltage waveforms. The current simulation methodology uses elementary functions called atomic functions to approximate the instantaneous current consumption at the instruction level. Based on these atomic functions, a simulated instantaneous current waveform at the program level was built. First, a base waveform of the current simulation was generated by the use of four basic current superposition principles. Secondly, a final waveform of the simulated current was generated from the base waveform by applying a factorial adjustment as a function of the instruction parallelism and sequencing. Step-by-step modeling procedures with numerical examples are presented. The model captured 98% of the variation of the instantaneous current for six complex applications, with an average RMS error of less than 2.2% of the average measured mean. Energy estimates obtained by the use of the simulated current waveforms were within 1.4% of the measured values. This research is important, since for the first time highly accurate instruction-based models of instantaneous current and power for complex processor cores have been developed.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2005521008",
    "type": "article"
  },
  {
    "title": "Secure routing based on distributed key sharing in large-scale sensor networks",
    "doi": "https://doi.org/10.1145/1331331.1331344",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Taejoon Park; Kang G. Shin",
    "corresponding_authors": "",
    "abstract": "Sensor networks, usually built with a large number of small, low-cost sensor nodes, are characterized by their large-scale and unattended deployment, necessitating “secur ” communications between nearby, as well as remote, sensor nodes for their intended applications and services. Key setup/sharing is crucial to the protection of such applications/services from attacks, but existing (public-key, cluster-based, or pairwise) solutions become too expensive (hence, inefficient) when the underlying applications/services require communications between distant sensor nodes. To remedy this inefficiency, we propose a novel distributed key-sharing scheme, in which each participating sensor node shares unique keys with a small number of other sensor nodes—called distributed key servers (DKSs)—chosen according to their geographic distance and communication direction. Using DKSs, we develop two secure routing protocols: (1) secure geographic forwarding that delivers packets by using a chain of DKS lookups, each secured with its own key and forwarded geographically; and (2) key establishment that creates a secure session between two distant sensor nodes based solely on symmetric-ciphers. These protocols enable low-cost, low-power sensors to provide high-level security at a very low cost.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2072198668",
    "type": "article"
  },
  {
    "title": "Static strands",
    "doi": "https://doi.org/10.1145/1274858.1274862",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Peter G. Sassone; D.S. Wills; Gabriel H. Loh",
    "corresponding_authors": "",
    "abstract": "Modern embedded processors are designed to maximize execution efficiency—the amount of performance achieved per unit of energy dissipated while meeting minimum performance levels. To increase this efficiency, we propose utilizing static strands , dependence chains without fan-out, which are exposed by a compiler pass. These dependent instructions are resequenced to be sequential and annotated to communicate their location to the hardware. Importantly, this modified application is binary compatible and functionally identical to the original, allowing transparent execution on a baseline processor. However, these static strands can be easily collapsed and optimized by simple processor modifications, significantly reducing the workload energy. Results show that over 30% of MediaBench and Spec2000int dynamic instructions can be collapsed, reducing issue logic energy by 20%, bypass energy 19%, and register file energy 14%. In addition, by increasing the effective capactity of pipeline resources by almost a third, average IPC can be improved up to 15%. This performance gain can then be traded in for a lower clock frequency to maintain a basline level of performance, further reducing energy.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2699665775",
    "type": "article"
  },
  {
    "title": "Structured Proofs for Adversarial Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3477024",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Rose Bohrer; André Platzer",
    "corresponding_authors": "",
    "abstract": "Many cyber-physical systems (CPS) are safety-critical, so it is important to formally verify them, e.g. in formal logics that show a model’s correctness specification always holds. Constructive Differential Game Logic ( CdGL ) is such a logic for (constructive) hybrid games, including hybrid systems. To overcome undecidability, the user first writes a proof, for which we present a proof-checking tool. We introduce Kaisar , the first language and tool for CdGL proofs, which until now could only be written by hand with a low-level proof calculus. Kaisar’s structured proofs simplify challenging CPS proof tasks, especially by using programming language principles and high-level stateful reasoning. Kaisar exploits CdGL ’s constructivity and refinement relations to build proofs around models of game strategies. The evaluation reproduces and extends existing case studies on 1D and 2D driving. Proof metrics are compared and reported experiences are discussed for the original studies and their reproductions.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3185279362",
    "type": "article"
  },
  {
    "title": "Exploiting Activation Sparsity for Fast CNN Inference on Mobile GPUs",
    "doi": "https://doi.org/10.1145/3477008",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Chanyoung Oh; Junhyuk So; Sumin Kim; Youngmin Yi",
    "corresponding_authors": "",
    "abstract": "Over the past several years, the need for on-device deep learning has been rapidly increasing, and efficient CNN inference on mobile platforms has been actively researched. Sparsity exploitation has been one of the most active research themes, but the studies mostly focus on weight sparsity by weight pruning. Activation sparsity, on the contrary, requires compression at runtime for every input tensor. Hence, the research on activation sparsity mainly targets NPUs that can efficiently process this with their own hardware logic. In this paper, we observe that it is difficult to accelerate CNN inference on mobile GPUs with natural activation sparsity and that the widely used CSR-based sparse convolution is not sufficiently effective due to the compression overhead. We propose several novel sparsification methods that can boost activation sparsity without harming accuracy. In particular, we selectively sparsify some layers with an extremely high sparsity and adopt sparse convolution or dense convolution depending on the layers. Further, we present an efficient sparse convolution method without compression and demonstrate that it can be faster than the CSR implementation. With ResNet-50, we achieved 1.88 <?TeX $\\times$?> speedup compared to TFLite on a Mali-G76 GPU.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3199463158",
    "type": "article"
  },
  {
    "title": "Hardware Performance Counters: Ready-Made vs Tailor-Made",
    "doi": "https://doi.org/10.1145/3476996",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Abraham Peedikayil Kuruvila; Anushree Mahapatra; Ramesh Karri; Kanad Basu",
    "corresponding_authors": "",
    "abstract": "Micro-architectural footprints can be used to distinguish one application from another. Most modern processors feature hardware performance counters to monitor the various micro-architectural events when an application is executing. These ready-made hardware performance counters can be used to create program fingerprints and have been shown to successfully differentiate between individual applications. In this paper, we demonstrate how ready-made hardware performance counters, due to their coarse-grain nature (low sampling rate and bundling of similar events, e.g., number of instructions instead of number of add instructions), are insufficient to this end. This observation motivates exploration of tailor-made hardware performance counters to capture fine-grain characteristics of the programs. As a case study, we evaluate both ready-made and tailor-made hardware performance counters using post-quantum cryptographic key encapsulation mechanism implementations. Machine learning models trained on tailor-made hardwareperformance counter streams demonstrate that they can uniquely identify the behavior of every post-quantum cryptographic key encapsulation mechanism algorithm with at least 98.99% accuracy.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3200750064",
    "type": "article"
  },
  {
    "title": "You Only Traverse Twice: A YOTT Placement, Routing, and Timing Approach for CGRAs",
    "doi": "https://doi.org/10.1145/3477038",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Michael Canesche; Westerley Carvalho; Lucas Reis; Matheus Oliveira; Salles V. G. Magalhães; Peter Jamieson; Jaugusto M. Nacif; Ricardo Ferreira",
    "corresponding_authors": "",
    "abstract": "Coarse-grained reconfigurable architecture (CGRA) mapping involves three main steps: placement, routing, and timing. The mapping is an NP-complete problem, and a common strategy is to decouple this process into its independent steps. This work focuses on the placement step, and its aim is to propose a technique that is both reasonably fast and leads to high-performance solutions. Furthermore, a near-optimal placement simplifies the following routing and timing steps. Exact solutions cannot find placements in a reasonable execution time as input designs increase in size. Heuristic solutions include meta-heuristics, such as Simulated Annealing (SA) and fast and straightforward greedy heuristics based on graph traversal. However, as these approaches are probabilistic and have a large design space, it is not easy to provide both run-time efficiency and good solution quality. We propose a graph traversal heuristic that provides the best of both: high-quality placements similar to SA and the execution time of graph traversal approaches. Our placement introduces novel ideas based on “you only traverse twice” (YOTT) approach that performs a two-step graph traversal. The first traversal generates annotated data to guide the second step, which greedily performs the placement, node per node, aided by the annotated data and target architecture constraints. We introduce three new concepts to implement this technique: I/O and reconvergence annotation, degree matching, and look-ahead placement. Our analysis of this approach explores the placement execution time/quality trade-offs. We point out insights on how to analyze graph properties during dataflow mapping. Our results show that YOTT is 60.6 <?TeX $\\times$?> , 9.7 <?TeX $\\times$?> , and 2.3 <?TeX $\\times$?> faster than a high-quality SA, bounding box SA VPR, and multi-single traversal placements, respectively. Furthermore, YOTT reduces the average wire length and the maximal FIFO size (additional timing requirement on CGRAs) to avoid delay mismatches in fully pipelined architectures.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3200790925",
    "type": "article"
  },
  {
    "title": "Prepare: <u>P</u> owe <u>r</u> -Awar <u>e</u> A <u>p</u> proximate Re <u>a</u> l-time Task Scheduling for Ene <u>r</u> gy-Adaptiv <u>e</u> QoS Maximization",
    "doi": "https://doi.org/10.1145/3476993",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Shounak Chakraborty; Sangeet Saha; Magnus Själander; Klaus D. McDonald-Maier",
    "corresponding_authors": "",
    "abstract": "Achieving high result-accuracy in approximate computing (AC) based real-time applications without violating power constraints of the underlying hardware is a challenging problem. Execution of such AC real-time tasks can be divided into the execution of the mandatory part to obtain a result of acceptable quality, followed by a partial/complete execution of the optional part to improve accuracy of the initially obtained result within the given time-limit. However, enhancing result-accuracy at the cost of increased execution length might lead to deadline violations with higher energy usage. We propose Prepare , a novel hybrid offline-online approximate real-time task-scheduling approach, that first schedules AC-based tasks and determines operational processing speeds for each individual task constrained by system-wide power limit, deadline, and task-dependency. At runtime, by employing fine-grained DVFS, the energy-adaptive processing speed governing mechanism of Prepare reduces processing speed during each last level cache miss induced stall and scales up the processing speed once the stall finishes to a higher value than the predetermined one. To ensure on-chip thermal safety, this higher processing speed is maintained only for a short time-span after each stall, however, this reduces execution times of the individual task and generates slacks. Prepare exploits the slacks either to enhance result-accuracy of the tasks, or to improve thermal and energy efficiency of the underlying hardware, or both. With a 70 - 80% workload, Prepare offers 75% result-accuracy with its constrained scheduling, which is enhanced by 5.3% for our benchmark based evaluation of the online energy-adaptive mechanism on a 4-core based homogeneous chip multi-processor, while meeting the deadline constraint. Overall, while maintaining runtime thermal safety, Prepare reduces peak temperature by up to 8.6 °C for our baseline system. Our empirical evaluation shows that constrained scheduling of Prepare outperforms a state-of-the-art scheduling policy, whereas our runtime energy-adaptive mechanism surpasses two current DVFS based thermal management techniques.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3201261054",
    "type": "article"
  },
  {
    "title": "On-device Prior Knowledge Incorporated Learning for Personalized Atrial Fibrillation Detection",
    "doi": "https://doi.org/10.1145/3476987",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Zhenge Jia; Yiyu Shi; Samir Saba; Jingtong Hu",
    "corresponding_authors": "",
    "abstract": "Atrial Fibrillation (AF), one of the most prevalent arrhythmias, is an irregular heart-rate rhythm causing serious health problems such as stroke and heart failure. Deep learning based methods have been exploited to provide an end-to-end AF detection by automatically extracting features from Electrocardiogram (ECG) signal and achieve state-of-the-art results. However, the pre-trained models cannot adapt to each patient’s rhythm due to the high variability of rhythm characteristics among different patients. Furthermore, the deep models are prone to overfitting when fine-tuned on the limited ECG of the specific patient for personalization. In this work, we propose a prior knowledge incorporated learning method to effectively personalize the model for patient-specific AF detection and alleviate the overfitting problems. To be more specific, a prior-incorporated portion importance mechanism is proposed to enforce the network to learn to focus on the targeted portion of the ECG, following the cardiologists’ domain knowledge in recognizing AF. A prior-incorporated regularization mechanism is further devised to alleviate model overfitting during personalization by regularizing the fine-tuning process with feature priors on typical AF rhythms of the general population. The proposed personalization method embeds the well-defined prior knowledge in diagnosing AF rhythm into the personalization procedure, which improves the personalized deep model and eliminates the workload of manually adjusting parameters in conventional AF detection method. The prior knowledge incorporated personalization is feasibly and semi-automatically conducted on the edge, device of the cardiac monitoring system. We report an average AF detection accuracy of 95.3% of three deep models over patients, surpassing the pre-trained model by a large margin of 11.5% and the fine-tuning strategy by 8.6%.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3201282789",
    "type": "article"
  },
  {
    "title": "REPAIR: Control Flow Protection based on Register Pairing Updates for SW-Implemented HW Fault Tolerance",
    "doi": "https://doi.org/10.1145/3477001",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Uzair Sharif; Daniel Mueller-Gritschneder; Ulf Schlichtmann",
    "corresponding_authors": "",
    "abstract": "Safety-critical embedded systems may either use specialized hardware or rely on Software-Implemented Hardware Fault Tolerance (SIHFT) to meet soft error resilience requirements. SIHFT has the advantage that it can be used with low-cost, off-the-shelf components such as standard Micro-Controller Units. For this, SIHFT methods apply redundancy in software computation and special checker codes to detect transient errors, so called soft errors, that either corrupt the data flow or the control flow of the software and may lead to Silent Data Corruption (SDC). So far, this is done by applying separate SIHFT methods for the data and control flow protection, which leads to large overheads in computation time. This work in contrast presents REPAIR, a method that exploits the checks of the SIHFT data flow protection to also detect control flow errors as well, thereby, yielding higher SDC resilience with less computational overhead. For this, the data flow protection methods entail duplicating the computation with subsequent checks placed strategically throughout the program. These checks assure that the two redundant computation paths, which work on two different parts of the register file, yield the same result. By updating the pairing between the registers used in the primary computation path and the registers in the duplicated computation path using the REPAIR method, these checks also fail with high coverage when a control flow error, which leads to an illegal jumps, occurs. Extensive RTL fault injection simulations are carried out to accurately quantify soft error resilience while evaluating Mibench programs along with an embedded case-study running on an OpenRISC processor. Our method performs slightly better on average in terms of soft error resilience compared to the best state-of-the-art method but requiring significantly lower overheads. These results show that REPAIR is a valuable addition to the set of known SIHFT methods.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3201523465",
    "type": "article"
  },
  {
    "title": "Hardware Acceleration for Embedded Keyword Spotting: Tutorial and Survey",
    "doi": "https://doi.org/10.1145/3474365",
    "publication_date": "2021-10-18",
    "publication_year": 2021,
    "authors": "Juan Sebastian Piedrahita Giraldo; Marian Verhelst",
    "corresponding_authors": "",
    "abstract": "In recent years, Keyword Spotting (KWS) has become a crucial human–machine interface for mobile devices, allowing users to interact more naturally with their gadgets by leveraging their own voice. Due to privacy, latency and energy requirements, the execution of KWS tasks on the embedded device itself instead of in the cloud, has attracted significant attention from the research community. However, the constraints associated with embedded systems, including limited energy, memory, and computational capacity, represent a real challenge for the embedded deployment of such interfaces. In this article, we explore and guide the reader through the design of KWS systems. To support this overview, we extensively survey the different approaches taken by the recent state-of-the-art (SotA) at the algorithmic, architectural, and circuit level to enable KWS tasks in edge, devices. A quantitative and qualitative comparison between relevant SotA hardware platforms is carried out, highlighting the current design trends, as well as pointing out future research directions in the development of this technology.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3205253448",
    "type": "article"
  },
  {
    "title": "Adaptive Computation Reuse for Energy-Efficient Training of Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3487025",
    "publication_date": "2021-10-18",
    "publication_year": 2021,
    "authors": "Jason Servais; Ehsan Atoofian",
    "corresponding_authors": "",
    "abstract": "In recent years, Deep Neural Networks (DNNs) have been deployed into a diverse set of applications from voice recognition to scene generation mostly due to their high-accuracy. DNNs are known to be computationally intensive applications, requiring a significant power budget. There have been a large number of investigations into energy-efficiency of DNNs. However, most of them primarily focused on inference while training of DNNs has received little attention. This work proposes an adaptive technique to identify and avoid redundant computations during the training of DNNs. Elements of activations exhibit a high degree of similarity, causing inputs and outputs of layers of neural networks to perform redundant computations. Based on this observation, we propose Adaptive Computation Reuse for Tensor Cores (ACRTC) where results of previous arithmetic operations are used to avoid redundant computations. ACRTC is an architectural technique, which enables accelerators to take advantage of similarity in input operands and speedup the training process while also increasing energy-efficiency. ACRTC dynamically adjusts the strength of computation reuse based on the tolerance of precision relaxation in different training phases. Over a wide range of neural network topologies, ACRTC accelerates training by 33% and saves energy by 32% with negligible impact on accuracy.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3206990726",
    "type": "article"
  },
  {
    "title": "Measuring and policing blocking times in real-time systems",
    "doi": "https://doi.org/10.1145/1814539.1814541",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Osmar Marchi dos Santos; Andy Wellings",
    "corresponding_authors": "",
    "abstract": "In real-time systems, the execution-time overrun of a thread may lead to a deadline being missed by the thread or even others threads in the system. From a fault tolerance perspective, both execution time overruns and deadline misses can be considered timing errors that could potentially cause a failure in the system's ability to deliver its services in a timely manner. In this context, the ideal is to detect the error in the system as soon as possible, so that the propagation of the error can be limited and error recovery strategies can take place with more accurate information. The run-time support mechanism usually deployed for monitoring the timing requirements of real-time systems is based on deadline monitoring, that is, the system calls specific application code whenever a deadline is violated. Recognizing that deadline monitoring may not be enough for providing an adequate level of fault tolerance for timing errors, major real-time programming standards, like Ada, POSIX and the Real-Time Specification for Java (RTSJ), have proposed different mechanisms for monitoring the execution time of threads. Nevertheless, in order to provide a complete fault tolerance approach for timing errors, the potential blocking time of threads also has to be monitored. In this article, we propose mechanisms for measuring and policing the blocking time of threads in the context of both basic priority inheritance and priority ceiling protocols . The notion of blocking-time clocks and timers for the POSIX standard is proposed, implemented and evaluated in the open-source real-time operating system MaRTE OS. Also, a blocking time monitoring model for measuring and policing blocking times in the RTSJ framework is specified. This model is implemented and evaluated in the (RTSJ-compliant) open-source middleware jRate, running on top of MaRTE OS.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1965342697",
    "type": "article"
  },
  {
    "title": "A cost-effective load-balancing policy for tile-based, massive multi-core packet processors",
    "doi": "https://doi.org/10.1145/1698772.1698782",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Enric Musoll",
    "corresponding_authors": "Enric Musoll",
    "abstract": "Massive multi-core architectures provide a computation platform with high processing throughput, enabling the efficient processing of workloads with a significant degree of thread-level parallelism found in networking environments. Communication-centric workloads, like those in LAN and WAN environments, are fundamentally composed of sets of packets, named flows. The packets within a flow usually have dependencies among them, which reduce the amount of parallelism. However, packets of different flows tend to have very few or no dependencies among them, and thus can exploit thread-level parallelism to its fullest extent. Therefore, in massive tile-based multi-core architectures, it is important that the processing of the packets of a particular flow takes place in a set of cores physically close to each other to minimize the communication latency among those cores. Moreover, it is also desirable to spread out the processing of the different flows across all the cores of the processor in order to minimize the stress on a reduced number of cores, thus minimizing the potential for thermal hotspots and increasing the reliability of the processor. In addition, the burst-like nature of packet-based workloads render most of the cores idle most of the time, enabling large power savings by power gating these idle cores. This work presents a high-level study of the performance, power, and thermal behavior of tile-based architectures with a large number of cores executing flow-based packet workloads, and proposes a load-balancing policy of assigning packets to cores that minimizes the communication latency while featuring a hotspot-free thermal profile.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2008761756",
    "type": "article"
  },
  {
    "title": "Optimizing rapidIO architectures for onboard processing",
    "doi": "https://doi.org/10.1145/1698772.1698776",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "D. Remondo Bueno; Chris Conger; Alan D. George",
    "corresponding_authors": "",
    "abstract": "In this article, we study optimization of a RapidIO network and FPGA-based computation engines to address the taxing requirements of a set of real-time Ground-Moving Target Indicators (GMTI) and Synthetic Aperture Radar (SAR) kernels for Space-Based Radar (SBR). By employing a RapidIO hardware testbed and validated simulation, we determine key trade-offs in design of reconfigurable systems for GMTI and SAR in terms of processing, memory, and network throughput. In addition, we study considerations for timely delivery of latency-sensitive control traffic present in many satellite applications. Based on our results, we propose architectural modifications to further improve performance of SBR systems.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2044119974",
    "type": "article"
  },
  {
    "title": "Recovering from distributable thread failures in distributed real-time Java",
    "doi": "https://doi.org/10.1145/1814539.1814547",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Edward Curley; Binoy Ravindran; Jonathan Anderson; E. Douglas Jensen",
    "corresponding_authors": "",
    "abstract": "We consider the problem of recovering from the failures of distributable threads (“threads”) in distributed real-time systems that operate under runtime uncertainties including those on thread execution times, thread arrivals, and node failure occurrences. When a thread experiences a node failure, the result is a broken thread having an orphan. Under a termination model, the orphans must be detected and aborted, and exceptions must be delivered to the farthest, contiguous surviving thread segment for resuming thread execution. Our application/scheduling model includes the proposed distributable thread programming model for the emerging Distributed Real-Time Specification for Java (DRTSJ), together with an exception-handler model. Threads are subject to time/utility function (TUF) time constraints and an utility accrual (UA) optimality criterion. A key underpinning of the TUF/UA scheduling paradigm is the notion of “best-effort” where higher importance threads are always favored over lower importance ones, irrespective of thread urgency as specified by their time constraints. We present a thread scheduling algorithm called HUA and a thread integrity protocol called TPR. We show that HUA and TPR bound the orphan cleanup and recovery time with bounded loss of the best-effort property. Our implementation experience for HUA/TPR in the Reference Implementation of the proposed programming model for the DRTSJ demonstrates the algorithm/protocol's effectiveness.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2082872139",
    "type": "article"
  },
  {
    "title": "WCET-Aware Function-Level Dynamic Code Management on Scratchpad Memory",
    "doi": "https://doi.org/10.1145/3063383",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Yooseong Kim; David Broman; Aviral Shrivastava",
    "corresponding_authors": "",
    "abstract": "Scratchpad memory (SPM) is a promising on-chip memory choice in real-time and cyber-physical systems where timing is of the utmost importance. SPM has time-predictable characteristics since its data movement between the SPM and the main memory is entirely managed by software. One way of such management is dynamic management. In dynamic management of instruction SPMs, code blocks are dynamically copied from the main memory to the SPM at runtime by executing direct memory access (DMA) instructions. Code management techniques try to minimize the overhead of DMA operations by finding an allocation scheme that leads to efficient utilization. In this article, we present three function-level code management techniques. These techniques perform allocation at the granularity of functions, with the objective of minimizing the impact of DMA overhead to the worst-case execution time (WCET) of a given program. The first technique finds an optimal mapping of each function to a region using integer linear programming (ILP), whereas the second technique is a polynomial-time heuristic that is suboptimal. The third technique maps functions directly to SPM addresses, not using regions, which can further reduce the WCET. Based on ILP, it can also find an optimal mapping. We evaluate our techniques using the Mälardalen WCET suite, MiBench suite, and proprietary automotive applications from industry. The results show that our techniques can significantly reduce the WCET estimates compared to caches with the state-of-the-art cache analysis.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2613407055",
    "type": "article"
  },
  {
    "title": "Schedulability of Bounded-Rate Multimode Systems",
    "doi": "https://doi.org/10.1145/2996797",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Rajeev Alur; Vojtěch Forejt; Salar Moarref; Ashutosh Trivedi",
    "corresponding_authors": "",
    "abstract": "Bounded-rate multimode systems are hybrid systems that switch freely among a finite set of modes, and whose dynamics are specified by a finite number of real-valued variables with mode-dependent rates that vary within given bounded sets. The scheduler repeatedly proposes a time and a mode, while the environment chooses an allowable rate for that mode; the state of the system changes linearly in the direction of the rate. The scheduler aims to keep the state within a safe set, while the environment aims to leave it. We study the problem of existence of a winning scheduler strategy and associated complexity questions.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2617131933",
    "type": "article"
  },
  {
    "title": "Joint Optimization of Sensing and Power Allocation in Energy-Harvesting Cognitive Radio Networks",
    "doi": "https://doi.org/10.1145/3070709",
    "publication_date": "2017-09-20",
    "publication_year": 2017,
    "authors": "Hang Hu; Hang Zhang; Jianxin Guo; Feng Wang",
    "corresponding_authors": "",
    "abstract": "The energy-harvesting cognitive radio (CR) network is proposed to improve the spectrum efficiency and energy efficiency. We focus on the optimization of sensing time and power allocation to maximize the throughput of the energy-harvesting CR network subject to the energy causality constraint and collision constraint. Based on the classification of operating regions, the optimization problem is divided into two sub-problems. Then, the efficient iterative Algorithm 1 and Algorithm 2 are proposed to solve sub-problem (A) and sub-problem (B), respectively. Numerical results show that a significant improvement in the throughput is achieved via joint optimization of sensing time and power allocation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2756465105",
    "type": "article"
  },
  {
    "title": "Round-trip DRAM Access Fairness in 3D NoC-based Many-core Systems",
    "doi": "https://doi.org/10.1145/3126561",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Xiaowen Chen; Zhonghai Lu; Sheng Liu; Shuming Chen",
    "corresponding_authors": "",
    "abstract": "In 3D NoC-based many-core systems, DRAM accesses behave differently due to their different communication distances and the latency gap of different DRAM accesses becomes bigger as the network size increases, which leads to unfair DRAM access performance among different nodes. This phenomenon may lead to high latencies for some DRAM accesses that become the performance bottleneck of the system. The paper addresses the DRAM access fairness problem in 3D NoC-based many-core systems by narrowing the latency difference of DRAM accesses as well as reducing the maximum latency. Firstly, the latency of a round-trip DRAM access is modeled and the factors causing DRAM access latency difference are discussed in detail. Secondly, the DRAM access fairness is further quantitatively analyzed through experiments. Thirdly, we propose to predict the network latency of round-trip DRAM accesses and use the predicted round-trip DRAM access time as the basis to prioritize the DRAM accesses in DRAM interfaces so that the DRAM accesses with potential high latencies can be transferred as early and fast as possible, thus achieving fair DRAM access. Experiments with synthetic and application workloads validate that our approach can achieve fair DRAM access and outperform the traditional First-Come-First-Serve (FCFS) scheduling policy and the scheduling policies proposed by reference [7] and [24] in terms of maximum latency, Latency Standard Deviation (LSD)1 and speedup. In the experiments, the maximum improvement of the maximum latency, LSD, and speedup are 12.8%, 6.57%, and 8.3% respectively. Besides, our proposal brings very small extra hardware overhead (&lt;0.6%) in comparison to the three counterparts.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2756842558",
    "type": "article"
  },
  {
    "title": "Optimization of Real-Time Software Implementing Multi-Rate Synchronous Finite State Machines",
    "doi": "https://doi.org/10.1145/3126515",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Yecheng Zhao; Chao Peng; Haibo Zeng; Zonghua Gu",
    "corresponding_authors": "",
    "abstract": "Model-based design using Synchronous Reactive (SR) models is becoming widespread for control software development in industry. However, software synthesis is challenging for multi-rate SR models consisting of blocks modeled with finite state machines, due to the complexity of validating the system’s real-time schedulability. The existing approach uses the simplified periodic task model to allow an efficient schedulability analysis, which leads to pessimistic and suboptimal solutions. Instead, in this paper, we adopt a more accurate but more complex schedulability analysis. We develop several optimization techniques to improve the algorithm’s efficiency. Experimental results on synthetic systems and an industrial case study show that the proposed optimization framework preserves the solution optimality but is much faster (e.g., 1000× for systems with 15 blocks) than the branch-and-bound algorithm, and it generates better control software than the existing approach.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2758862995",
    "type": "article"
  },
  {
    "title": "Improving Invariant Mining via Static Analysis",
    "doi": "https://doi.org/10.1145/3126504",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Christoph Schulze; Rance Cleaveland",
    "corresponding_authors": "",
    "abstract": "This paper proposes the use of static analysis to improve the generation of invariants from test data extracted from Simulink models. Previous work has shown the utility of such automatically generated invariants as a means for updating and completing system specifications; they also are useful as a means of understanding model behavior. This work shows how the scalability and accuracy of the data mining process can be dramatically improved by using information from data/control flow analysis to reduce the search space of the invariant mining and to eliminate false positives. Comparative evaluations of the process show that the improvements significantly reduce execution time and memory consumption, thereby supporting the analysis of more complex models, while also improving the accuracy of the generated invariants.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2759331286",
    "type": "article"
  },
  {
    "title": "SoftRM",
    "doi": "https://doi.org/10.1145/3126562",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Vasileios Tsoutsouras; Dimosthenis Masouros; Sotirios Xydis; Dimitrios Soudris",
    "corresponding_authors": "",
    "abstract": "Many-core systems are envisioned to leverage the ever-increasing demand for more powerful computing systems. To provide the necessary computing power, the number of Processing Elements integrated on-chip increases and NoC based infrastructures are adopted to address the interconnection scalability. The advent of these new architectures surfaces the need for more sophisticated, distributed resource management paradigms, which in addition to the extreme integration scaling, make the new systems more prone to errors manifested both at hardware and software. In this work, we highlight the need for Run-Time Resource management to be enhanced with fault tolerance features and propose SoftRM, a resource management framework which can dynamically adapt to permanent failures in a self-organized, workload-aware manner. Self-organization allows the resource management agents to recover from a failure in a coordinated way by electing a new agent to replace the failed one, while workload awareness optimizes this choice according to the status of each core. We evaluate the proposed framework on Intel Single-chip Cloud Computer (SCC), a NoC based many-core system and customize it to achieve minimum interference on the resource allocation process. We showcase that its workload-aware features manage to utilize free resources in more that 90% of the conducted experiments. Comparison with relevant state-of-the-art fault tolerant frameworks shows decrease of up to 67% in the imposed overhead on application execution.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2760215247",
    "type": "article"
  },
  {
    "title": "HARP",
    "doi": "https://doi.org/10.1145/2567938",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Ahmad Lashgar; Ahmad Khonsari; Amirali Baniasadi",
    "corresponding_authors": "",
    "abstract": "SIMT accelerators are equipped with thousands of computational resources. Conventional accelerators, however, fail to fully utilize available resources due to branch and memory divergences. This underutilization is manifested in two underlying inefficiencies: pipeline width underutilization and pipeline depth underutilization. Width underutilization occurs when SIMD execution units are not entirely utilized due to branch divergences. This affects lane activity and results in SIMD inefficiency. Depth underutilization takes place when the pipeline runs out of active threads and is forced to leave pipeline stages idle. This work addresses both inefficiencies by harnessing inactive threads available to the pipeline. We introduce Harnessing inActive thReads in many-core Processors (or simply HARP) to improve width and depth utilization in accelerators. We show how using inactive yet ready threads can enhance performance. Moreover, we investigate implementation details and study microarchitectural changes needed to build a HARP-enhanced accelerator. Furthermore, we evaluate HARP under a variety of microarchitectural design points. We measure the area overhead associated with HARP and compare to conventional alternatives. Under Fermi-like GPUs, we show that HARP provides 10% speedup on average (maximum of 1.6X) at the cost of 3.5% area overhead. Our analysis shows that HARP performs better under narrower SIMD and shorter pipelines.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1973806083",
    "type": "article"
  },
  {
    "title": "STM-HRT",
    "doi": "https://doi.org/10.1145/2786979",
    "publication_date": "2015-09-09",
    "publication_year": 2015,
    "authors": "Sylvain Cotard; Audrey Queudet; Jean-Luc Béchennec; Sébastien Faucou; Yvon Trinquet",
    "corresponding_authors": "",
    "abstract": "This article introduces STM-HRT, a nonblocking wait-free software transactional memory (STM) for hard real-time (HRT) multicore embedded systems. Resource access control in HRT systems is usually implemented with lock-based synchronization. However, these mechanisms may lead to deadlocks or starvations and do not scale well with the number of cores. Most existing nonblocking STM are not suitable for HRT systems, because it is not possible to find an upper bound of the execution time for each task. In this article, we show how STM-HRT can be a robust solution for resource sharing in HRT multicore systems. We provide a detailed description of STM-HRT architecture. We propose a set of arguments to establish the functional correctness of its concurrency control protocol. Finally, as part of a real-time analysis, we derive upper bounds on the computations required to access shared data under STM-HRT.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1987180701",
    "type": "article"
  },
  {
    "title": "A Brief Comment on “A Complete Self-Testing and Self-Configuring NoC Infrastructure for Cost-Effective MPSoCs” [ACM Transactions on Embedded Computing Systems 12 (2013) Article 106]",
    "doi": "https://doi.org/10.1145/2668121",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Rimpy Bishnoi; Vijay Laxmi; Manoj Singh Gaur; José Flich; Francisco Antonio García Triviño",
    "corresponding_authors": "",
    "abstract": "In the Ghiribaldi et al. [2013] paper, a complete self-testing and self configuring NoC infrastructure for cost-effective MPSoCs was presented in order to make NoC architecture tolerant to faults. To overcome the complexity involved during the complete reconfiguration of routing instances in the face of most of the usual failure patterns, Ghiribaldi et al. [2013] proposed a fast self-reconfiguration algorithm. The algorithm is based on segment-based routing implemented using Logic-Based Distributed Routing (LBDR) and claimed to have handled the most common NoC faults. The purpose of this comment is to demonstrate the inconsistency of the fast self-configuration method presented in Ghiribaldi et al. [2013]. To handle inconsistency, we present the correct set of LBDR bits and also argue that complete reconfiguration of the routing instance is mandatory to handle some fault combinations. New coverage results of the fast self-reconfiguration algorithm of Ghiribaldi et al. [2013] are also presented.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2003243900",
    "type": "article"
  },
  {
    "title": "NoC-based fault-tolerant cache design in chip multiprocessors",
    "doi": "https://doi.org/10.1145/2567939",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Abbas BanaiyanMofrad; Gustavo Girão; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "Advances in technology scaling increasingly make emerging Chip MultiProcessor (CMP) platforms more susceptible to failures that cause various reliability challenges. In such platforms, error-prone on-chip memories (caches) continue to dominate the chip area. Also, Network-on-Chip (NoC) fabrics are increasingly used to manage the scalability of these architectures. We present a novel solution for efficient implementation of fault-tolerant design of Last-Level Cache (LLC) in CMP architectures. The proposed approach leverages the interconnection network fabric to protect the LLC cache banks against permanent faults in an efficient and scalable way. During an LLC access to a faulty block, the network detects and corrects the faults, returning the fault-free data to the requesting core. Leveraging the NoC interconnection fabric, designers can implement any cache fault-tolerant scheme in an efficient, modular, and scalable manner for emerging multicore/manycore platforms. We propose four different policies for implementing a remapping-based fault-tolerant scheme leveraging the NoC fabric in different settings. The proposed policies enable design trade-offs between NoC traffic (packets sent through the network) and the intrinsic parallelism of these communication mechanisms, allowing designers to tune the system based on design constraints. We perform an extensive design space exploration on NoC benchmarks to demonstrate the usability and efficacy of our approach. In addition, we perform sensitivity analysis to observe the behavior of various policies in reaction to improvements in the NoC architecture. The overheads of leveraging the NoC fabric are minimal: on an 8-core, 16-cache-bank CMP we demonstrate reliable access to LLCs with additional overheads of less than 3% in area and less than 7% in power.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2003451056",
    "type": "article"
  },
  {
    "title": "Interactive Trace-Based Analysis Toolset for Manual Parallelization of C Programs",
    "doi": "https://doi.org/10.1145/2638556",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Mihai T. Lazarescu; Luciano Lavagno",
    "corresponding_authors": "",
    "abstract": "Massive amounts of legacy sequential code need to be parallelized to make better use of modern multiprocessor architectures. Nevertheless, writing parallel programs is still a difficult task. Automated parallelization methods can be effective both at the statement and loop levels and, recently, at the task level, but they are still restricted to specific source code constructs or application domains. We present in this article an innovative toolset that supports developers when performing manual code analysis and parallelization decisions. It automatically collects and represents the program profile and data dependencies in an interactive graphical format that facilitates the analysis and discovery of manual parallelization opportunities. The toolset can be used for arbitrary sequential C programs and parallelization patterns. Also, its program-scope data dependency tracing at runtime can complement the tools based on static code analysis and can also benefit from it at the same time. We also tested the effectiveness of the toolset in terms of time to reach parallelization decisions and of their quality. We measured a significant improvement for several real-world representative applications.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2049770249",
    "type": "article"
  },
  {
    "title": "Provably Good Task Assignment for Two-Type Heterogeneous Multiprocessors Using Cutting Planes",
    "doi": "https://doi.org/10.1145/2660495",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Björn Andersson; Gurulingesh Raravi",
    "corresponding_authors": "",
    "abstract": "Consider scheduling of real-time tasks on a multiprocessor where migration is forbidden. Specifically, consider the problem of determining a task-to-processor assignment for a given collection of implicit-deadline sporadic tasks upon a multiprocessor platform in which there are two distinct types of processors. For this problem, we propose a new algorithm, LPC (task assignment based on solving a Linear Program with Cutting planes). The algorithm offers the following guarantee: for a given task set and a platform, if there exists a feasible task-to-processor assignment, then LPC succeeds in finding such a feasible task-to-processor assignment as well but on a platform in which each processor is 1.5 × faster and has three additional processors. For systems with a large number of processors, LPC has a better approximation ratio than state-of-the-art algorithms. To the best of our knowledge, this is the first work that develops a provably good real-time task assignment algorithm using cutting planes.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2055575985",
    "type": "article"
  },
  {
    "title": "A Hardware Framework for Yield and Reliability Enhancement in Chip Multiprocessors",
    "doi": "https://doi.org/10.1145/2629688",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Abhisek Pan; Rance Rodrigues; Sandip Kundu",
    "corresponding_authors": "",
    "abstract": "Device reliability and manufacturability have emerged as dominant concerns in end-of-road CMOS devices. An increasing number of hardware failures are attributed to manufacturability or reliability problems. Maintaining an acceptable manufacturing yield for chips containing tens of billions of transistors with wide variations in device parameters has been identified as a great challenge. Additionally, today’s nanometer scale devices suffer from accelerated aging effects because of the extreme operating temperature and electric fields they are subjected to. Unless addressed in design, aging-related defects can significantly reduce the lifetime of a product. In this article, we investigate a micro-architectural scheme for improving yield and reliability of homogeneous chip multiprocessors (CMPs). The proposed solution involves a hardware framework that enables us to utilize the redundancies inherent in a multicore system to keep the system operational in the face of partial failures. A micro-architectural modification allows a faulty core in a CMP to use another core’s resources to service any instruction that the former cannot execute correctly by itself. This service improves yield and reliability but may cause loss of performance. The target platform for quantitative evaluation of performance under degradation is a dual-core and a quad-core chip multiprocessor with one or more cores sustaining partial failure. Simulation studies indicate that when a large, high-latency, and sparingly used unit such as a floating-point unit fails in a core, correct execution may be sustained through outsourcing with at most a 16% impact on performance for a floating-point intensive application. For applications with moderate floating-point load, the degradation is insignificant. The performance impact may be mitigated even further by judicious selection of the cores to commandeer depending on the current load on each of the candidate cores. The area overhead is also negligible due to resource reuse.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2074883006",
    "type": "article"
  },
  {
    "title": "A Framework for Supporting Adaptive Fault-Tolerant Solutions",
    "doi": "https://doi.org/10.1145/2629473",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Kostas Siozios; Dimitrios Soudris; Michael Hübner",
    "corresponding_authors": "",
    "abstract": "For decades, computer architects pursued one primary goal: performance. The ever-faster transistors provided by Moore's law were translated into remarkable gains in operation frequency and power consumption. However, the device-level size and architecture complexity impose several new challenges, including a decrease in dependability level due to physical failures. In this article we propose a software-supported methodology based on game theory for adapting the aggressiveness of fault tolerance at runtime. Experimental results prove the efficiency of our solution since it achieves comparable fault masking to relevant solutions, but with significantly lower mitigation cost. More specifically, our framework speeds up the identification of suspicious failure resources on average by 76% as compared to the HotSpot tool. Similarly, the introduced solution leads to average Power×Delay (PDP) savings against an existing TMR approach by 53%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2076842476",
    "type": "article"
  },
  {
    "title": "Factored Planning",
    "doi": "https://doi.org/10.1145/2656215",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Loïg Jezequel; Éric Fabre; Victor Khomenko",
    "corresponding_authors": "",
    "abstract": "Factored planning mitigates the state explosion problem by avoiding the construction of the state space of the whole system and instead working with the system's components. Traditionally, finite automata have been used to represent the components, with the overall system being represented as their product. In this article, we change the representation of components to safe Petri nets. This allows one to use cheap structural operations like transition contractions to reduce the size of the Petri net before its state space is generated, which often leads to substantial savings compared with automata. The proposed approach has been implemented and proved efficient on several factored planning benchmarks. This article is an extended version of our ACSD 2013 paper [Jezequel et al. 2013], with the addition of the proofs and the experimental results of Sections 6 and 7.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2084852987",
    "type": "article"
  },
  {
    "title": "Beyond Cross-Section",
    "doi": "https://doi.org/10.1145/2794148",
    "publication_date": "2015-12-31",
    "publication_year": 2015,
    "authors": "Thiago Santini; Paolo Rech; Gabriel L. Nazar; Flávio Rech Wagner",
    "corresponding_authors": "",
    "abstract": "A computational system employed in safety-critical applications typically has reliability as a primary concern. Thus, the designer focuses on minimizing the device radiation-sensitive area, often leading to performance degradation. In this article, we present a mathematical model to evaluate system reliability in spatial (i.e., radiation-sensitive area) and temporal (i.e., performance) terms and prove that minimizing radiation-sensitive area does not necessarily maximize application reliability. To support our claim, we present an empirical counterexample where application reliability is improved even if the radiation-sensitive area of the device is increased. An extensive radiation test campaign using a 28 nm commercial-off-the-shelf ARM-based SoC was conducted, and experimental results demonstrate that, while executing the considered application at military aircraft altitude, the probability of executing a two-year mission workload without failures is increased by 5.85% if L1 caches are enabled (thus increasing the radiation-sensitive area) when compared to no cache level being enabled. However, if both L1 and L2 caches are enabled, the probability is decreased by 31.59%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2204180393",
    "type": "article"
  },
  {
    "title": "Energy-Efficient and High-Performance Lock Speculation Hardware for Embedded Multicore Systems",
    "doi": "https://doi.org/10.1145/2700097",
    "publication_date": "2015-05-21",
    "publication_year": 2015,
    "authors": "Dimitra Papagiannopoulou; Giuseppe Capodanno; Tali Moreshet; Maurice Herlihy; R. Iris Bahar",
    "corresponding_authors": "",
    "abstract": "Embedded systems are becoming increasingly common in everyday life and like their general-purpose counterparts, they have shifted towards shared memory multicore architectures. However, they are much more resource constrained, and as they often run on batteries, energy efficiency becomes critically important. In such systems, achieving high concurrency is a key demand for delivering satisfactory performance at low energy cost. In order to achieve this high concurrency, consistency across the shared memory hierarchy must be accomplished in a cost-effective manner in terms of performance, energy, and implementation complexity. In this article, we propose Embedded-Spec, a hardware solution for supporting transparent lock speculation, without the requirement for special supporting instructions. Using this approach, we evaluate the energy consumption and performance of a suite of benchmarks, exploring a range of contention management and retry policies. We conclude that for resource-constrained platforms, lock speculation can provide real benefits in terms of improved concurrency and energy efficiency, as long as the underlying hardware support is carefully configured.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2262432081",
    "type": "article"
  },
  {
    "title": "Unified Medium Access Control Architecture for Resource-Constrained Machine-to-Machine Devices",
    "doi": "https://doi.org/10.1145/2876958",
    "publication_date": "2016-03-18",
    "publication_year": 2016,
    "authors": "Eui‐Jik Kim; Jung-Hyok Kwon; Ken Choi; Taeshik Shon",
    "corresponding_authors": "",
    "abstract": "In capillary machine-to-machine (M2M) communications, which is being considered as a feasible network solution for M2M applications, because of physical resource constraints and deployment conditions, an energy-efficient and scalable medium access control (MAC) protocol is crucial for numerous M2M devices to concurrently access wireless channels. Therefore, this paper presents a unified MAC layer architecture for resource-constrained M2M devices in capillary M2M networks [named as resource-constrained MAC architecture (RCMA)], which has a unified (monolithic) framework consisting of essential functional components to support MAC-related operations of M2M devices: multi-channel hybrid MAC (McHM), logical link control (LLC), time synchronizer (TS), and device on--off scheduler (DO2S). McHM provides a baseline MAC protocol for an entire capillary M2M system that combines the benefit of both contention-based carrier sense multiple access and schedule-based time division multiple access schemes, whereas the other three components help in the McHM operations. To demonstrate the effectiveness of the RCMA, we implement the whole stack using the QualNet simulator. Experimental results show that the RCMA outperforms the conventional ZigBee stack in terms of energy efficiency and scalability, even under heavy traffic conditions.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2317796130",
    "type": "article"
  },
  {
    "title": "Byte-Addressable Update Scheme to Minimize the Energy Consumption of PCM-Based Storage Systems",
    "doi": "https://doi.org/10.1145/2910590",
    "publication_date": "2016-06-06",
    "publication_year": 2016,
    "authors": "Ming-Chang Yang; Yuan-Hao Chang; Che-Wei Tsao",
    "corresponding_authors": "",
    "abstract": "In recent years, phase-change memory (PCM) has generated a great deal of interest because of its byte addressability and nonvolatility properties. It is regarded as a good alternative storage medium that can reduce the performance gap between the main memory and the secondary storage in computing systems. However, its high energy consumption on writes is a challenging issue in the design of battery-powered mobile computing systems. To reduce the energy consumption, we exploit the byte addressability and the asymmetric read-write energy/latency of PCM in an energy-efficient update scheme for journaling file systems. We also introduce a concept called the 50% rule to determine/recommend the best update strategy for block updates. The proposed scheme only writes modified data, instead of the whole updated block, to PCM-based storage devices without extra hardware support. Moreover, it guarantees the sanity/integrity of file systems even if the computing system crashes or there is a power failure during the data update process. We implemented the proposed scheme on the Linux system and conducted a series of experiments to evaluate the scheme. The results are very encouraging.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2416684840",
    "type": "article"
  },
  {
    "title": "RunStream",
    "doi": "https://doi.org/10.1145/2891412",
    "publication_date": "2016-06-06",
    "publication_year": 2016,
    "authors": "Ayesha Khalid; Goutam Paul; Anupam Chattopadhyay; Faezeh Abediostad; Syed Imad Ud Din; Muhammad Hassan; Baishik Biswas; Prasanna Ravi",
    "corresponding_authors": "",
    "abstract": "We present RunStream, a rapid prototyping framework for realizing stream cipher implementations based on algorithmic specifications and architectural customizations desired by the users. In the dynamic world of cryptography where newer recommendations are frequently proposed, the need of such tools is imperative. It carries out design validation and generates an optimized software implementation and a synthesizable Register Transfer Level Verilog description. Our framework enables speedy benchmarking against critical resources like area, throughput, power, and latency and allows exploration of alternatives. Using RunStream, we successfully implemented various stream ciphers and benchmarked the quality of results to be at par with published hand-optimized implementations.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2418056502",
    "type": "article"
  },
  {
    "title": "Automatic Parallelization of Multirate Block Diagrams of Control Systems on Multicore Platforms",
    "doi": "https://doi.org/10.1145/2950055",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Cumhur Erkan Tuncali; Georgios Fainekos; Yann-Hang Lee",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of parallelizing model block diagrams for real-time embedded applications on multicore architectures. We describe a Mixed Integer Linear Programming formulation for finding a feasible mapping of the blocks to different CPU cores. For single-rate models, we use an objective function that minimizes the overall worst-case execution time. We introduce a set of heuristics to solve the problem for large models in a reasonable time. For multirate models, we solve the feasibility problem for finding a valid mapping. We study the scalability and efficiency of our approach with synthetic benchmarks and an engine controller from Toyota.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2531132995",
    "type": "article"
  },
  {
    "title": "GPUrpc",
    "doi": "https://doi.org/10.1145/2950056",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Yuki Iida; Yusuke Fujii; Takuya Azumi; Nobuhiko Nishio; Shinpei Kato",
    "corresponding_authors": "",
    "abstract": "Graphics processing units (GPUs) are increasingly used for high-performance computing. Programming frameworks for general-purpose computing on GPUs (GPGPU), such as CUDA and OpenCL, are also maturing. Driving this trend is the recent proliferation of mobile devices such as smartphones and wearable computers. These devices are increasingly incorporating computationally intensive applications that involve some form of environmental recognition such as augmented reality (AR) or voice recognition. However, devices with low computational power cannot satisfy such demanding computing requirements. The CPU load of these devices could be reduced by offloading computation onto GPUs on the cloud. This paper presents GPUrpc, a remote procedure call (RPC) extension to Gdev, which is a rich set of runtime libraries and device drivers for achieving first-class GPU resource management. GPUrpc allows developers to use CUDA for GPGPU development work. Existing research uses RPCs based on the CUDA application programming interfaces (APIs); hence, all CUDA APIs require communication. To reduce communication overhead, we use an RPC based on a low-level API than CUDA API and reduced API that does not require communication. Our evaluation conducted on Linux and NVIDIA GPUs shows that the basic performance of our prototype implementation is reliable in comparison with the existing method. Evaluation using the Rodinia benchmark suite designed for research in heterogeneous parallel computing showed that GPUrpc is effective for applications such as image processing and data mining. GPUrpc also can improve power consumption to approximately 1/6 that of CPU processing for performing 512 × 512 matrix multiplication.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2531734863",
    "type": "article"
  },
  {
    "title": "Cache-Partitioned Preemption Threshold Scheduling",
    "doi": "https://doi.org/10.1145/2950057",
    "publication_date": "2016-10-23",
    "publication_year": 2016,
    "authors": "Zonghua Gu; Chao Wang; Haibo Zeng",
    "corresponding_authors": "",
    "abstract": "For preemptive scheduling with shared cache, different tasks may cause interference in the shared cache, leading to Cache-Related Preemption Overhead (CRPD). Cache partitioning can be used to reduce or eliminate CRPD. We propose integration of cache partitioning and Preemption Threshold Scheduling to optimize schedulability for both Fixed-Priority and Earliest Deadline First scheduling algorithms on a uniprocessor. We let each subset of tasks assigned the same cache partition be a nonpreemptive group by assigning the same preemption threshold to them, which eliminates CRPD both within each cache partition and between different cache partitions.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2537355049",
    "type": "article"
  },
  {
    "title": "Runtime Resource Management with Multiple-Step-Ahead Workload Prediction",
    "doi": "https://doi.org/10.1145/3605213",
    "publication_date": "2023-06-20",
    "publication_year": 2023,
    "authors": "Mina Niknafs; Petru Eles; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "Modern embedded platforms need sophisticated resource managers to utilize their heterogeneous computational resources efficiently. Furthermore, such platforms are subject to fluctuating workloads that are unforeseeable at design time. Predicting the incoming workload could enhance the efficiency of resource management in this situation. But is that the case? And, if so, how substantial is this improvement? Does multiple-step-ahead prediction of the workload contribute to this improvement? How precise must the prediction be to improve decisions rather than cause harm? By proposing a prediction-based resource manager that aims at meeting task deadlines while minimizing energy usage, and by conducting extensive tests, we attempt to provide answers to the aforementioned questions.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4381334338",
    "type": "article"
  },
  {
    "title": "Look-up the Rainbow: Table-based Implementation of Rainbow Signature on 64-bit ARMv8 Processors",
    "doi": "https://doi.org/10.1145/3607140",
    "publication_date": "2023-07-04",
    "publication_year": 2023,
    "authors": "Hyeokdong Kwon; Hyunjun Kim; Minjoo Sim; Wai‐Kong Lee; Hwajeong Seo",
    "corresponding_authors": "",
    "abstract": "The Rainbow Signature Scheme is one of the finalists in the National Institute of Standards and Technology (NIST) Post-Quantum Cryptography (PQC) standardization competition, but failed to win because it has lack of stability in the parameter selection. It is the only signature candidate based on a multivariate quadratic equation. Rainbow signatures have smaller signature sizes compared with other post-quantum cryptography candidates. However, they require expensive tower-field based polynomial multiplications. In this article, we propose an efficient implementation of Rainbow signatures using a look-up table–based multiplication method. The polynomial multiplications in Rainbow signatures are performed on the 𝔽 16 field, which is divided into sub-fields 𝔽 4 and 𝔽 2 under the tower-field method. To accelerate the multiplication process on target processors, we propose a look-up table–based tower-field multiplication technique. In 𝔽 16 , all values are expressed in 4-bit data format and can be implemented using a 256-byte look-up table access. The implementation uses the TBL and TBX instructions of the 64-bit ARMv8 target processor. For Rainbow III and Rainbow V, they are computed on the 𝔽 256 field using an additional 16-byte table instead of creating a new look-up table. The proposed technique uses the vector registers of 64-bit ARMv8 processors and can calculate 16 result values with a single instruction. We also proposed implementations that are resistant to timing attacks. There are two types of implementations. The first one is the cache side-attack resistant implementation, which utilizes the 128-byte cache lines of the M1 processor. In this implementation, cache misses do not occur, and cache hits always occur. The second type is the constant-time implementation. This method takes a step-by-step approach to finding the required look-up table value and ensures that the same number of accesses is made regardless of which look-up table value is called. This implementation is designed to be constant-time, meaning it does not leak timing information. Our experiments on modern Apple M1 processors showed up to 428.73× and 114.16× better performance for finite field multiplications and Rainbow signatures schemes, respectively, compared with previous reference implementations. To the best of our knowledge, this proposed Rainbow implementation is the first optimized Rainbow implementation for 64-bit ARMv8 processors.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4383102393",
    "type": "article"
  },
  {
    "title": "Scalable Binary Neural Network applications in Oblivious Inference",
    "doi": "https://doi.org/10.1145/3607192",
    "publication_date": "2023-07-05",
    "publication_year": 2023,
    "authors": "Xinqiao Zhang; Mohammad Samragh; Siam U. Hussain; Ke Huang; Farinaz Koushanfar",
    "corresponding_authors": "",
    "abstract": "Binary neural network (BNN) delivers increased compute intensity and reduces memory/data requirements for computation. Scalable BNN enables inference in a limited time due to different constraints. This paper explores the application of Scalable BNN in oblivious inference, a service provided by a server to mistrusting clients. Using this service, a client can obtain the inference result on his/her data by a trained model held by the server without disclosing the data or learning the model parameters. Two contributions of this paper are: (1) we devise lightweight cryptographic protocols explicitly designed to exploit the unique characteristics of BNNs. (2) we present an advanced dynamic exploration of the runtime-accuracy tradeoff of scalable BNNs in a single-shot training process. While previous works trained multiple BNNs with different computational complexities (which is cumbersome due to the slow convergence of BNNs), we train a single BNN that can perform inference under various computational budgets. Compared to CryptFlow2, the state-of-the-art technique in the oblivious inference of non-binary DNNs, our approach reaches 3× faster inference while keeping the same accuracy. Compared to XONN, the state-of-the-art technique in the oblivious inference of binary networks, we achieve 2× to 12× faster inference while obtaining higher accuracy.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4383223856",
    "type": "article"
  },
  {
    "title": "Consistency Constraints for Mapping Dataflow Graphs to Hybrid Dataflow/von Neumann Architectures",
    "doi": "https://doi.org/10.1145/3607869",
    "publication_date": "2023-07-08",
    "publication_year": 2023,
    "authors": "Klaus Schneider; Anoop Bhagyanath",
    "corresponding_authors": "",
    "abstract": "Dataflow process networks (DPNs) provide a convenient model of computation that is often used to model system behavior in model-based designs. With fixed sets of nodes, they are also used as dataflow graphs as an intermediate program representation by compilers to uncover instruction-level parallelism of sequential programs. Many recent processor architectures, which are still von Neumann architectures, also use dataflow computing to increase their exploitation of instruction-level parallelism by exposing their datapaths so that the compiler can take care of the allocation of processing units (PUs), the execution schedules of instructions on the PUs, and the communication of intermediate values between PUs. If the communication paths are buffered, these architectures can be abstracted into a DPN architecture whose PUs and interconnection network are DPN nodes. In this article, we introduce a DPN abstraction of hybrid dataflow/von Neumann architectures and consider the mapping of the nodes of a given dataflow graph to the PUs of such a DPN architecture such that there are no conflicts due to the mapping of different nodes to the same PU. We express the allocation and scheduling constraints in terms of propositional logic for the original dataflow graph and for a modified version of the dataflow graph that simplifies the constraints by introducing levels using copy nodes, such that all nodes receive inputs only from nodes of the previous level. We also formulate equisatisfiable SMT constraints using integer variables to reason directly about the parallel runtime. On this basis, we further present alternative SAT constraints that explicitly encode concurrency, and discuss variants of the constraints for a better understanding of the same.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4383621084",
    "type": "article"
  },
  {
    "title": "Power Side-channel Attack Resistant Circuit Designs of ARX Ciphers Using High-level Synthesis",
    "doi": "https://doi.org/10.1145/3609507",
    "publication_date": "2023-07-17",
    "publication_year": 2023,
    "authors": "Saya Inagaki; Mingyu Yang; Yang Li; Kazuo Sakiyama; Yuko Hara–Azumi",
    "corresponding_authors": "",
    "abstract": "In the Internet of Things (IoT) era, edge devices have been considerably diversified and are often designed using high-level synthesis (HLS) for improved design productivity. However, HLS tools were originally developed in a security-unaware manner, resulting in vulnerabilities to power side-channel attacks (PSCAs), which are a serious threat to IoT systems. Currently, the impact and applicability of existing methods to PSCA-resistant designs using HLS are limited. In this article, we propose an effective HLS-based design method for PSCA-resistant ciphers implemented in hardware. In particular, we focus on lightweight block ciphers composed of addition/rotation/XOR (ARX)-based permutations to study the effects of the threshold implementation (which is one of the provably secure countermeasures against PSCAs) to the behavioral descriptions of ciphers along with the changes in HLS scheduling. The results obtained using Welch’s t-test demonstrate that our proposed method can successfully improve the resistance against PSCAs for all ARX-based ciphers used as benchmarks.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4384523572",
    "type": "article"
  },
  {
    "title": "SpikeHard: Efficiency-Driven Neuromorphic Hardware for Heterogeneous Systems-on-Chip",
    "doi": "https://doi.org/10.1145/3609101",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "J.A. St. Clair; Guy Eichler; Luca P. Carloni",
    "corresponding_authors": "",
    "abstract": "Neuromorphic computing is an emerging field with the potential to offer performance and energy-efficiency gains over traditional machine learning approaches. Most neuromorphic hardware, however, has been designed with limited concerns to the problem of integrating it with other components in a heterogeneous System-on-Chip (SoC). Building on a state-of-the-art reconfigurable neuromorphic architecture, we present the design of a neuromorphic hardware accelerator equipped with a programmable interface that simplifies both the integration into an SoC and communication with the processor present on the SoC. To optimize the allocation of on-chip resources, we develop an optimizer to restructure existing neuromorphic models for a given hardware architecture, and perform design-space exploration to find highly efficient implementations. We conduct experiments with various FPGA-based prototypes of many-accelerator SoCs, where Linux-based applications running on a RISC-V processor invoke Pareto-optimal implementations of our accelerator alongside third-party accelerators. These experiments demonstrate that our neuromorphic hardware, which is up to 89× faster and 170× more energy efficient after applying our optimizer, can be used in synergy with other accelerators for different application purposes.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386568676",
    "type": "article"
  },
  {
    "title": "Verified Compilation of Synchronous Dataflow with State Machines",
    "doi": "https://doi.org/10.1145/3608102",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Timothy Bourke; Basile Pesin; Marc Pouzet",
    "corresponding_authors": "",
    "abstract": "Safety-critical embedded software is routinely programmed in block-diagram languages. Recent work in the Vélus project specifies such a language and its compiler in the Coq proof assistant. It builds on the CompCert verified C compiler to give an end-to-end proof linking the dataflow semantics of source programs to traces of the generated assembly code. We extend this work with switched blocks, shared variables, reset blocks, and state machines; define a relational semantics to integrate these block- and mode-based constructions into the existing stream-based model; adapt the standard source-to-source rewriting scheme to compile the new constructions; and reestablish the correctness theorem.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386568743",
    "type": "article"
  },
  {
    "title": "PReFeR : <u>P</u> hysically <u>Re</u> lated <u>F</u> unction bas <u>e</u> d <u>R</u> emote Attestation Protocol",
    "doi": "https://doi.org/10.1145/3609104",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "A Mondal; S Gangopadhyay; Durba Chatterjee; Harishma Boyapally; Debdeep Mukhopadhyay",
    "corresponding_authors": "",
    "abstract": "Remote attestation is a request-response based security service that permits a trusted entity (verifier) to check the current state of an untrusted remote device (prover). The verifier initiates the attestation process by sending an attestation challenge to the prover; the prover responds with its current state, which establishes its trustworthiness. Physically Unclonable Function (PUF) offers an attractive choice for hybrid attestation schemes owing to its low overhead security guarantees. However, this comes with the limitation of secure storage of the PUF model or large challenge-response database on the verifier end. To address these issues, in this work, we propose a hybrid attestation framework, named PReFeR , that leverages a new class of hardware primitive known as Physically Related Function (PReF) to remotely attest low-end devices without the requirement of secure storage or heavy cryptographic operations. It comprises a static attestation scheme that validates the memory state of the remote device prior to code execution, followed by a dynamic run-time attestation scheme that asserts the correct code execution by evaluating the content of special registers present in embedded systems, known as hardware performance counters (HPC). The use of HPCs in the dynamic attestation scheme mitigates the popular class of attack known as the time-of-check-time-of-use (TOCTOU) attack, which has broken several state-of-the-art hybrid attestation schemes. We demonstrate our protocol and present our experimental results using a prototype implementation on Digilent Cora Z7 board, a low-cost embedded platform, specially designed for IoT applications.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386569070",
    "type": "article"
  },
  {
    "title": "SpinBayes: Algorithm-Hardware Co-Design for Uncertainty Estimation Using Bayesian In-Memory Approximation on Spintronic-Based Architectures",
    "doi": "https://doi.org/10.1145/3609116",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Soyed Tuhin Ahmed; Kamal Danouchi; Michael Hefenbrock; Guillaume Prenat; Lorena Anghel; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "Recent development in neural networks (NNs) has led to their widespread use in critical and automated decision-making systems, where uncertainty estimation is essential for trustworthiness. Although conventional NNs can solve many problems accurately, they do not capture the uncertainty of the data or the model during optimization. In contrast, Bayesian neural networks (BNNs), which learn probabilistic distributions for their parameters, offer a sound theoretical framework for estimating uncertainty. However, traditional hardware implementations of BNNs are expensive in terms of computational and memory resources, as they (i) are realized with inefficient von Neumann architectures, (ii) use a significantly large number of random number generators (RNGs) to implement the distributions of BNNs, and (iii) have a substantially greater number of parameters than conventional NNs. Computing-in-memory (CiM) architectures with emerging resistive non-volatile memories (NVMs) are promising candidates for accelerating classical NNs. In particular, spintronic technology, which is distinguished by its low latency and high endurance, aligns very well with these requirements. In the specific context of Bayesian neural networks (BNNs), spintronics technologies are very valuable, thanks to their inherent potential to act as stochastic or as deterministic devices. Consequently, BNNs mapped on spintronic-based CiM architectures could be a highly efficient implementation strategy. However, the direct implementation on CiM hardware of the learned probabilistic distributions of BNN may not be feasible and can incur high overhead. In this work, we propose a new Bayesian neural network topology, named SpinBayes , that is able to perform efficient sampling during the Bayesian inference process. Moreover, a Bayesian approximation method, called in-memory approximation , is proposed that approximates the original probabilistic distributions of BNN with a distribution that can be efficiently mapped to spintronic-based CiM architectures. Compared to state-of-the-art methods, the memory overhead is reduced by 8× and the energy consumption by 80×. Our method has been evaluated on several classification and semantic segmentation tasks and can detect up to 100% of various types of out-of-distribution data, highlighting the robustness of our approach, without any performance sacrifice.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386574794",
    "type": "article"
  },
  {
    "title": "Kryptonite: Worst-Case Program Interference Estimation on Multi-Core Embedded Systems",
    "doi": "https://doi.org/10.1145/3609128",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Nikhilesh Singh; K. Renganathan; Chester Rebeiro; Jithin Jose; Ralph Mader",
    "corresponding_authors": "",
    "abstract": "Due to the low costs and energy needed, cyber-physical systems are adopting multi-core processors for their embedded computing requirements. In order to guarantee safety when the application has real-time constraints, a critical requirement is to estimate the worst-case interference from other executing programs. However, the complexity of multi-core hardware inhibits precisely determining the Worst-Case Program Interference. Existing solutions are either prone to overestimate the interference or are not scalable to different hardware sizes and designs. In this paper we present Kryptonite , an automated framework to synthesize Worst-Case Program Interference (WCPI) environments for multi-core systems. Fundamental to Kryptonite is a set of tiny hardware-specific code gadgets that are crafted to maximize interference locally. The gadgets are arranged using a greedy approach and then molded using a Reinforcement Learning algorithm to create the WCPI environment. We demonstrate Kryptonite on the automotive grade Infineon AURIX TC399 processor with a wide range of programs that includes a commercial real-time automotive application. We show that, while being easily scalable and tunable, Kryptonite creates WCPI environments increasing the runtime by up to 58% for benchmark applications and 26% for the automotive application.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386580597",
    "type": "article"
  },
  {
    "title": "LaDy: Enabling <u>L</u> ocality- <u>a</u> ware <u>D</u> eduplication Technolog <u>y</u> on Shingled Magnetic Recording Drives",
    "doi": "https://doi.org/10.1145/3607921",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "J. Chang; Tzu-Yu Chang; Yi-Chao Shih; Tseng‐Yi Chen",
    "corresponding_authors": "",
    "abstract": "The continuous increase in data volume has led to the adoption of shingled-magnetic recording (SMR) as the primary technology for modern storage drives. This technology offers high storage density and low unit cost but introduces significant performance overheads due to the read-update-write operation and garbage collection (GC) process. To reduce these overheads, data deduplication has been identified as an effective solution as it reduces the amount of written data to an SMR-based storage device. However, deduplication can result in poor data locality, leading to decreased read performance. To tackle this problem, this study proposes a data locality-aware deduplication technology, LaDy, that considers both the overheads of writing duplicate data and the impact on data locality to determine whether the duplicate data should be written. LaDy integrates with DiskSim, an open-source project, and modifies it to simulate an SMR-based drive. The experimental results demonstrate that LaDy can significantly reduce the response time in the best-case scenario by 87.3% compared with CAFTL on the SMR drive. LaDy achieves this by selectively writing duplicate data, which preserves data locality, resulting in improved read performance. The proposed solution provides an effective and efficient method for mitigating the performance overheads associated with data deduplication in SMR-based storage devices.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386580667",
    "type": "article"
  },
  {
    "title": "Proactive Stripe Reconstruction to Improve Cache Use Efficiency of SSD-Based RAID Systems",
    "doi": "https://doi.org/10.1145/3609099",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Zhibing Sha; Jiaojiao Wu; Jun Li; Balazs Gerofi; Zhigang Cai; Jianwei Liao",
    "corresponding_authors": "",
    "abstract": "Solid-State Drives (SSDs) exhibit different failure characteristics compared to conventional hard disk drives. In particular, the Bit Error Rate (BER) of an SSD increases as it bears more writes. Then, Parity-based Redundant Array of Inexpensive Disks (RAID) arrays composed from SSDs are introduced to address correlated failures. In the RAID-5 implementation, specifically, the process of parity generation (or update) associating with a data stripe, consists of read and write operations to the SSDs. Whenever a new update request comes to the RAID system, the related parity must be also updated and flushed onto the RAID component of SSD. Such frequent parity updates result in poor RAID performance and shorten the life-time of the SSDs. Consequently, a DRAM cache is commonly equipped accompanying with the RAID controller, called the parity cache, and used to buffer the parity chunks that are most frequently updated data, for boosting I/O performance. To better improve the use efficiency of the parity cache, this paper proposes a stripe reconstruction approach to minimize the number of parity updates on SSDs, thus boosting I/O performance of the SSD RAID system. When the currently updated stripe has both cold and hot updated data chunks, it will proactively carry out stripe reconstruction if we can find another matched stripe that also includes cold and hot update data chunks on the complementary RAID components. In the reconstruction process, we first group the cold data chunks of two matched stripes, to build a new stripe and flush the parity chunk on the RAID component. After that, the hot data chunks are organized as a new stripe as well, and its parity chunk is buffered in the parity cache. This results in better cache use efficiency, as it can reduce the number of parity updates on RAID components of SSDs, as well as proactively free up cache space for quickly absorbing subsequent write requests. In addition, the proposed method adjusts the target SSD of write requests based on stripe reconstructions through considering the I/O workload balance of all SSDs. Experimental results show that our proposal can reduce the number of parity chunk updates in SSDs by 2.3% and overall I/O latency by 12.2% on average, compared to state-of-the-art parity cache management techniques.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386580691",
    "type": "article"
  },
  {
    "title": "Online Distributed Schedule Randomization to Mitigate Timing Attacks in Industrial Control Systems",
    "doi": "https://doi.org/10.1145/3624584",
    "publication_date": "2023-09-16",
    "publication_year": 2023,
    "authors": "Ankita Samaddar; Arvind Easwaran",
    "corresponding_authors": "",
    "abstract": "Industrial control systems (ICSs) consist of a large number of control applications that are associated with periodic real-time flows with hard deadlines. To facilitate large-scale integration, remote control, and co-ordination, wireless sensor and actuator networks form the main communication framework in most ICSs. Among the existing wireless sensor and actuator network protocols, WirelessHART is the most suitable protocol for real-time applications in ICSs. The communications in a WirelessHART network are time-division multiple access based. To satisfy the hard deadlines of the real-time flows, the schedule in a WirelessHART network is pre-computed. The same schedule is repeated over every hyperperiod (i.e., lowest common multiple of the periods of the flows). However, a malicious attacker can exploit the repetitive behavior of the flow schedules to launch timing attacks (e.g., selective jamming attacks). To mitigate timing attacks, we propose an online distributed schedule randomization strategy that randomizes the time-slots in the schedules at each network device without violating the flow deadlines, while ensuring the closed-loop control stability. To increase the extent of randomization in the schedules further, and to reduce the energy consumption of the system, we incorporate a period adaptation strategy that adjusts the transmission periods of the flows depending on the stability of the control loops at runtime. We use Kullback-Leibler divergence and prediction probability of slots as two metrics to evaluate the performance of our proposed strategy. We compare our strategy with an offline centralized schedule randomization strategy. Experimental results show that the schedules generated by our strategy are 10% to 15% more diverse and 5% to 10% less predictable on average compared to the offline strategy when the number of base schedules and keys vary between 4 and 6 and 12 and 32, respectively, under all slot utilization (number of occupied slots in a hyperperiod). On incorporating period adaptation, the divergence in the schedules reduceat each period increase with 46% less power consumption on average.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386803748",
    "type": "article"
  },
  {
    "title": "Evolution Function Based Reach-Avoid Verification for Time-varying Systems with Disturbances",
    "doi": "https://doi.org/10.1145/3626099",
    "publication_date": "2023-09-28",
    "publication_year": 2023,
    "authors": "Ruiqi Hu; Kairong Liu; Zhikun She",
    "corresponding_authors": "",
    "abstract": "In this work, we investigate the reach-avoid problem of a class of time-varying analytic systems with disturbances described by uncertain parameters. Firstly, by proposing the concepts of maximal and minimal reachable sets, we connect the avoidability and reachability with maximal and minimal reachable sets respectively. Then, for a given disturbance parameter, we introduce the evolution function for exactly describing the reachable set, and find a series representation of this evolution function with its Lie derivatives, which can also be regarded as a series function with respect to the uncertain parameter. Afterward, based on the partial sums of this series, over- and under-approximations of the evolution function are constructed, which can be realized by interval arithmetics with designated precision. Further, we propose sufficient conditions for avoidability and reachability and design a numerical quantifier elimination based algorithm to verify these conditions; moreover, we improve the algorithm with a time-splitting technique. We implement the algorithms and use some benchmarks with comparisons to show that our methodology is both efficient and promising. Finally, we additionally extend our methodology to deal with systems with complex initial sets and time-dependent switchings. The performance of our extended method for these systems is also shown by four examples with comparisons and discussions.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4387130612",
    "type": "article"
  },
  {
    "title": "A Design Flow for Scheduling Spiking Deep Convolutional Neural Networks on Heterogeneous Neuromorphic System-on-Chip",
    "doi": "https://doi.org/10.1145/3635032",
    "publication_date": "2023-12-02",
    "publication_year": 2023,
    "authors": "Anup Das",
    "corresponding_authors": "Anup Das",
    "abstract": "Neuromorphic systems-on-chip (NSoCs) integrate CPU cores and neuromorphic hardware accelerators on the same chip. These platforms can execute spiking deep convolutional neural networks (SDCNNs) with a low energy footprint. Modern NSoCs are heterogeneous in terms of their computing, communication, and storage resources. This makes scheduling SDCNN operations a combinatorial problem of exploring an exponentially-large state space in determining mapping, ordering, and timing of operations to achieve a target hardware performance, e.g., throughput. We propose a systematic design flow to schedule SDCNNs on an NSoC. Our scheduler, called SMART ( S DCNN MA pping, Orde R ing, and T iming), branches the combinatorial optimization problem into computationally-relaxed sub-problems that generate fast solutions without significantly compromising the solution quality. SMART improves performance by efficiently incorporating the heterogeneity in computing, communication, and storage resources. SMART operates in four steps. First, it creates a self-timed execution schedule to map operations to compute resources, maximizing throughput. Second, it uses an optimization strategy to distribute activation and synaptic weights to storage resources, minimizing data communication-related overhead. Third, it constructs an inter-processor communication (IPC) graph with a transaction order for its communication actors. This transaction order is created using a transaction partial order algorithm, which minimizes contention on the shared communication resources. Finally, it schedules this IPC graph to hardware by overlapping communication with the computation, and leveraging operation, pipeline, and batch parallelism. We evaluate SMART using 10 representative image, object, and language-based SDCNNs. Results show that SMART increases throughput by an average 23%, compared to a state-of-the-art scheduler. SMART is implemented entirely in software as a compiler extension. It doesn’t require any change in a neuromorphic hardware or its interface to CPUs. It improves throughput with only a marginal increase in the compilation time. SMART is released under the open-source MIT licensing at https://github.com/drexel-DISCO/SMART to foster future research.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4389269478",
    "type": "article"
  },
  {
    "title": "Hardware support for detecting illegal references in a multiapplication real-time Java environment",
    "doi": "https://doi.org/10.1145/1196636.1196638",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "M. Teresa Higuera‐Toledano",
    "corresponding_authors": "M. Teresa Higuera‐Toledano",
    "abstract": "Our objective is to adapt the Java memory management to an embedded system, e.g., a wireless PDA executing concurrent multimedia applications within a single JVM. This paper provides software, and hardware-based solutions detecting both illegal references across the application memory spaces and dangling pointers within an application space. We give an approach to divide/share the memory among the applications executing concurrently in the system. We introduce and define application-specific memory, building upon the real-time specification for Java (RTSJ) from the real-time Java expert group. The memory model used in RTSJ imposes strict rules for assignment between memory areas, preventing the creation of dangling pointers, and thus maintaining the pointer safety of Java. Our implementation solution to ensure the checking of these rules before each assignment inserts write barriers that use a stack-based algorithm. This solution adversely affects both the performance and predictability of the RTSJ applications, which can be improved by using an existing hardware support.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2086861314",
    "type": "article"
  },
  {
    "title": "Design space exploration using arithmetic-level hardware--software cosimulation for configurable multiprocessor platforms",
    "doi": "https://doi.org/10.1145/1151074.1151080",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Jingzhao Ou; Viktor K. Prasanna",
    "corresponding_authors": "",
    "abstract": "Configurable multiprocessor platforms consist of multiple soft processors configured on FPGA devices. They have become an attractive choice for implementing many computing applications. In addition to the various ways of distributing software execution among the multiple soft processors, the application designer can customize soft processors and the connections between them in order to improve the performance of the applications running on the multiprocessor platform. State-of-the-art design tools rely on low-level simulation to explore the various design trade-offs offered by configurable multiprocessor platforms. These low-level simulation based exploration techniques are too time-consuming and can be a major bottleneck to efficient design space exploration on these platforms. We propose a design space exploration technique for configurable multiprocessor platforms using arithmetic-level cycle-accurate hardware--software cosimulation. Arithmetic-level abstractions of the hardware and software execution platforms are created within the proposed cosimulation environment. The configurable multiprocessor platforms are described using these arithmetic-level abstractions. Hardware and software simulators are tightly integrated to concurrently simulate the arithmetic behavior of the multiprocessor platform. The simulation within the integrated simulators are synchronized to provide cycle-accurate simulation results for the complete multiprocessor platform. By doing so, we significantly speed up the cosimulation process for configurable multiprocessor platforms. Exploration of the various hardware-software design trade-offs provided by configurable multiprocessor platforms can be performed within the proposed cycle-accurate cosimulation environment. After the final designs are identified, the corresponding low-level implementations with the desired cycle-accurate arithmetic behavior are generated automatically. For illustrative purposes, we provide an implementation of our approach based on MATLAB/Simulink. We show the cosimulation of two numerical computation applications and one image-processing application on a popular configurable multiprocessor platform within the MATLAB/Simulink-based cosimulation environment. For these three applications, our arithmetic-level cosimulation approach leads to speed-ups in simulation time of up to more than 800x compared with the low-level simulation approaches. The designs of these applications identified using our arithmetic-level cosimulation approach achieve execution time speed-ups up to 5.6x, compared with other designs considered in our experiments.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2099384028",
    "type": "article"
  },
  {
    "title": "Application-specific workload shaping in multimedia-enabled personal mobile devices",
    "doi": "https://doi.org/10.1145/1331331.1331334",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Balaji Raman; Samarjit Chakraborty",
    "corresponding_authors": "",
    "abstract": "Today, most personal mobile devices (e.g., cell phones and PDAs) are multimedia-enabled and support a variety of concurrently running applications, such as audio/video players, word processors, and web browsers. Media-processing applications are often computationally expensive and most of these devices typically have 100--400-MHz processors. As a result, the user-perceived application response times are often poor when multiple applications are concurrently fired. In this paper, we show that by using application-specific dynamic buffering techniques, the workload of these applications can be suitably “shaped” to fit the available processor bandwidth. Our techniques are analogous to traffic shaping , which is widely used in communication networks to optimally utilize network bandwidth. Such shaping techniques have recently attracted a lot of attention in the context of embedded systems design (e.g., for dynamic voltage scaling). However, they have not been exploited for enhanced schedulability of multiple applications, as we do in this paper.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1964636029",
    "type": "article"
  },
  {
    "title": "Code compression for performance enhancement of variable-length embedded processors",
    "doi": "https://doi.org/10.1145/1347375.1347388",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Rajeev Kumar; Dipankar Das",
    "corresponding_authors": "",
    "abstract": "Most of the work done in the field of code compression pertains to processors with fixed-length instruction encoding. The design of a code-compression scheme for variable-length instruction encodings poses newer design challenges. In this work, we first investigate the scope for code compression on variable-length instruction-set processors whose encodings are already optimized to a certain extent with respect to their usage. For such ISAs instruction boundaries are not known prior to decoding. Another challenging task of designing a code-compression scheme for such ISAs is designing the decompression hardware, which must decompress code postcache so that we gain in performance. We present two dictionary-based code compression schemes. The first algorithm uses a bit-vector; the second one uses reserved instructions to identify code words. We design additional logic for each of the schemes to decompress the code on-the-fly. We test the two algorithms with a variable-length RISC processor. We provide a detailed experimental analysis of the empirical results obtained by extensive simulation-based design space exploration for this system. The optimized decompressor can now execute compressed program faster than the native program. The experiments demonstrate reduction in code size (up to 30%), speed-up (up to 15%), and bus-switching activity (up to 20%). We also implement one decompressor in a hardware description language and synthesize it to illustrate the small overheads associated with the proposed approach.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2083132382",
    "type": "article"
  },
  {
    "title": "Beyond single-appearance schedules",
    "doi": "https://doi.org/10.1145/1234675.1234681",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Ming-Yung Ko; Praveen K. Murthy; Shuvra S. Bhattacharyya",
    "corresponding_authors": "",
    "abstract": "Synthesis of digital signal-processing (DSP) software from dataflow-based formal models is an effective approach for tackling the complexity of modern DSP applications. In this paper, an efficient method is proposed for applying subroutine call instantiation of module functionality when synthesizing embedded software from a dataflow specification. The technique is based on a novel recursive decomposition of subgraphs in a cluster hierarchy that is optimized for low buffer size. Applying this technique, one can achieve significantly lower buffer sizes than what is available for minimum code size inlined schedules, which have been the emphasis of prior work on software synthesis. Furthermore, it is guaranteed that the number of procedure calls in the synthesized program is polynomially bounded in the size of the input dataflow graph, even though the number of module invocations may increase exponentially. This recursive decomposition approach provides an efficient means for integrating subroutine-based module instantiation into the design space of DSP software synthesis. The experimental results demonstrate a significant improvement in buffer cost, especially for more irregular multirate DSP applications, with moderate code and execution time overhead.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2484836085",
    "type": "article"
  },
  {
    "title": "Shared Last-Level Cache Management and Memory Scheduling for GPGPUs with Hybrid Main Memory",
    "doi": "https://doi.org/10.1145/3230643",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Guan Wang; Chuanqi Zang; Lei Ju; Mengying Zhao; Xiaojun Cai; Zhiping Jia",
    "corresponding_authors": "",
    "abstract": "Memory intensive workloads become increasingly popular on general purpose graphics processing units (GPGPUs), and impose great challenges on the GPGPU memory subsystem design. On the other hand, with the recent development of non-volatile memory (NVM) technologies, hybrid memory combining both DRAM and NVM achieves high performance, low power, and high density simultaneously, which provides a promising main memory design for GPGPUs. In this article, we explore the shared last-level cache management for GPGPUs with consideration of the underlying hybrid main memory. To improve the overall memory subsystem performance, we exploit the characteristics of both the asymmetric read/write latency of the hybrid main memory architecture, as well as the memory coalescing feature of GPGPUs. In particular, to reduce the average cost of L2 cache misses, we prioritize cache blocks from DRAM or NVM based on observations that operations to NVM part of main memory have a large impact on the system performance. Furthermore, the cache management scheme also integrates the GPU memory coalescing and cache bypassing techniques to improve the overall system performance. To minimize the impact of memory divergence behaviors among simultaneously executed groups of threads, we propose a hybrid main memory and warp aware memory scheduling mechanism for GPGPUs. Experimental results show that in the context of a hybrid main memory system, our proposed L2 cache management policy and memory scheduling mechanism improve performance by 15.69% on average for memory intensive benchmarks, whereas the maximum gain can be up to 29% and achieve an average memory subsystem energy reduction of 21.27%.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2887950281",
    "type": "article"
  },
  {
    "title": "Exposing Implementation Details of Embedded DRAM Memory Controllers through Latency-based Analysis",
    "doi": "https://doi.org/10.1145/3274281",
    "publication_date": "2018-09-30",
    "publication_year": 2018,
    "authors": "Mohamed Hassan; Anirudh Mohan Kaushik; Hiren Patel",
    "corresponding_authors": "",
    "abstract": "We explore techniques to reverse-engineer DRAM embedded memory controllers (MCs), including page policies, address mapping, and command arbitration. There are several benefits to knowing this information: They allow tightening worst-case bounds of embedded systems and platform-aware optimizations at the operating system, source-code, and compiler levels. We develop a latency-based analysis, which we use to devise algorithms and C programs to extract MC properties. We show the effectiveness of the proposed approach by reverse-engineering the MC details in the XUPV5-LX110T Xilinx platform. Furthermore, to cover a breadth of policies, we use a simulation framework and document our findings.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2900091459",
    "type": "article"
  },
  {
    "title": "The Mechanized Marriage of Effects and Monads with Applications to High-assurance Hardware",
    "doi": "https://doi.org/10.1145/3274282",
    "publication_date": "2019-01-08",
    "publication_year": 2019,
    "authors": "Thomas N. Reynolds; Adam Procter; William L. Harrison; Gerard Allwein",
    "corresponding_authors": "",
    "abstract": "Constructing high-assurance, secure hardware remains a challenge, because to do so relies on both a verifiable means of hardware description and implementation. However, production hardware description languages (HDL) lack the formal underpinnings required by formal methods in security. Still, there is no such thing as high-assurance systems without high-assurance hardware. We present a core calculus of secure hardware description with its formal semantics, security type system, and mechanization in Coq. This calculus is the core of the functional HDL, ReWire, shown in previous work to have useful applications in reconfigurable computing. This work supports a full-fledged, formal methodology for producing high-assurance hardware.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2909399238",
    "type": "article"
  },
  {
    "title": "Self-Adaptive QoS Management of Computation and Communication Resources in Many-Core SoCs",
    "doi": "https://doi.org/10.1145/3328755",
    "publication_date": "2019-06-10",
    "publication_year": 2019,
    "authors": "Marcelo Ruaro; Axel Jantsch; Fernando Moraes",
    "corresponding_authors": "",
    "abstract": "Providing quality of service (QoS) for many-core systems with dynamic application admission is challenging due to the high amount of resources to manage and the unpredictability of computation and communication events. Related works propose a self-adaptive QoS mechanism concerned either in communication or computation resources, lacking, however, a comprehensive QoS management of both. Assuming a many-core system with QoS monitoring, runtime circuit-switching establishment, task migration, and a soft real-time task scheduler, this work fills this gap by proposing a novel self-adaptive QoS management. The contribution of this proposal comes with the following features in the QoS management: ( i ) comprehensiveness, by covering communication and computation resources; ( ii ) online, adopting the ODA (Observe, Decide, Act) runtime closed-loop adaptation; and ( iii ) reactive and proactive decisions, by using a dynamic application profile extraction technique, which enables the QoS management to be aware of the profile of running applications, allowing it to take proactive decisions based on a prediction analysis. The proposed QoS management adopts a decentralized organization by partitioning the system in clusters, each one managed by a dedicated processor, making the proposal scalable. Results show that the proactive feature accurately extracts the applications’ profile, and can prevent future QoS violations. The synergy of reactive and proactive decisions was able to sustain QoS, reducing the deadline miss rate by 99.5% with a severe disturbance in communication and computation levels, and avoiding deadline misses up to 70% of system utilization.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2952509919",
    "type": "article"
  },
  {
    "title": "Efficient Decentralized LTL Monitoring Framework Using Tableau Technique",
    "doi": "https://doi.org/10.1145/3358219",
    "publication_date": "2019-10-11",
    "publication_year": 2019,
    "authors": "Omar Al Bataineh; David S. Rosenblum; Mark Reynolds",
    "corresponding_authors": "",
    "abstract": "This paper presents a novel framework for decentralized monitoring of Linear Temporal Logic (LTL) formulas, under the situation where processes are synchronous and the formula is represented as a tableau. The tableau technique allows one to construct a semantic tree for the input LTL formula, which can be used to optimize the decentralized monitoring of LTL in various ways. Given a system P and an LTL formula φ, we construct a tableau T φ . The tableau T φ is used for two purposes: (a) to synthesize an efficient round-robin communication policy for processes, and (b) to find the minimal ways to decompose the formula and communicate observations of processes in an efficient way. In our framework, processes can propagate truth values of both atomic and compound formulas (non-atomic formulas) depending on the syntactic structure of the input LTL formula and the observation power of processes. We demonstrate that this approach of decentralized monitoring based on tableau construction is more straightforward, more flexible, and more likely to yield efficient solutions than alternative approaches.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2979679948",
    "type": "article"
  },
  {
    "title": "DWMAcc",
    "doi": "https://doi.org/10.1145/3358199",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Zhengguo Chen; Quan Deng; Nong Xiao; Kirk Pruhs; Youtao Zhang",
    "corresponding_authors": "",
    "abstract": "PIM (processing-in-memory) based hardware accelerators have shown great potentials in addressing the computation and memory access intensity of modern CNNs (convolutional neural networks). While adopting NVM (non-volatile memory) helps to further mitigate the storage and energy consumption overhead, adopting quantization, e.g., shift-based quantization, helps to tradeoff the computation overhead and the accuracy loss, integrating both NVM and quantization in hardware accelerators leads to sub-optimal acceleration. In this paper, we exploit the natural shift property of DWM (domain wall memory) to devise DWMAcc, a DWM-based accelerator with asymmetrical storage of weight and input data, to speed up the inference phase of shift-based CNNs. DWMAcc supports flexible shift operations to enable fast processing with low performance and area overhead. We then optimize it with zero-sharing , input-reuse , and weight-share schemes. Our experimental results show that, on average, DWMAcc achieves 16.6× performance improvement and 85.6× energy consumption reduction over a state-of-the-art SRAM based design.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2979894481",
    "type": "article"
  },
  {
    "title": "SWARAM",
    "doi": "https://doi.org/10.1145/3358211",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Ram Prasad Mohanty; Hasindu Gamaarachchi; Andrew Lambert; Sri Parameswaran",
    "corresponding_authors": "",
    "abstract": "Treatment of patients using high-quality precision medicine requires a thorough understanding of the genetic composition of a patient. Ideally, the identification of unique variations in an individual’s genome is needed for specifying the necessary treatment. Variant calling workflow is a pipeline of tools, integrating state of the art software systems aimed at alignment, sorting and variant calling for the whole genome sequencing (WGS) data. This pipeline is utilized for identifying unique variations in an individual’s genome (compared to a reference genome). Currently, such a workflow is implemented on high-performance computers (with additional GPUs or FPGAs) or in cloud computers. Such systems are large, have a high cost, and rely on the internet for genome data transfer which makes the system unusable in remote locations unequipped with internet connectivity. It further raises privacy concerns due to processing being carried out in a different facility. To overcome such limitations, in this paper, for the first time, we present a cost-efficient, offline, scalable, portable, and energy-efficient computing system named SWARAM for variant calling workflow processing. The system uses novel architecture and algorithms to match against partial reference genomes to exploit smaller memory sizes which are typically available in tiny processing systems. Extensive tests on a standard benchmark data-set (NA12878 Illumina platinum genome) confirm that the time consumed for the data transfer and completing variant calling workflow on SWARAM was competitive to that of a 32-core Intel Xeon server with similar accuracy, but costs less than a fifth, and consumes less than 40% of the energy of the server system. The original scripts and code we developed for executing the variant calling workflow on SWARAM are available in the associated Github repository https://github.com/Rammohanty/swaram.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2980022714",
    "type": "article"
  },
  {
    "title": "ECAx",
    "doi": "https://doi.org/10.1145/3358179",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "J. Castro Godinez; Muhammad Shafique; Jörg Henkel",
    "corresponding_authors": "",
    "abstract": "Approximate computing has emerged as a design paradigm amenable to error-tolerant applications. It enables trading the quality of results for efficiency improvement in terms of delay, power, and energy consumption under user-provided tolerable quality degradation. Approximate accelerators have been proposed to expedite frequently executing code sections of error-resilient applications while meeting a defined quality level. However, these accelerators may produce unacceptable errors at run time if the input data changes or dynamic adjustments are made for a defined output quality constraint. State-of-the-art approaches in approximate computing address this issue by correctly re-computing those accelerator invocations that produce unacceptable errors; this is achieved by using the host processor or an alternate exact accelerator, which is activated on-demand. Nevertheless, such approaches can nullify the benefits of approximate computing, especially when input data variations are high at run time and errors due to approximations are above a tolerable threshold. As a robust and general solution to this problem, we propose ECAx, a novel methodology to explore low-overhead error correction in approximate accelerators by selectively correcting most significant errors, in terms of their magnitude, without losing the gains of approximations. We particularly consider the case of approximate accelerators built with approximate functional units such as approximate adders. Our novel methodology reduces the required exact re-computations on the host processor, achieving up to 20% performance gain compared to state-of-the-art approaches.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2980026972",
    "type": "article"
  },
  {
    "title": "Aggregation Strategies in Reachable Set Computation of Hybrid Systems",
    "doi": "https://doi.org/10.1145/3358214",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Parasara Sridhar Duggirala; Stanley Bak",
    "corresponding_authors": "",
    "abstract": "Computing the set of reachable states is a widely used technique for proving that a hybrid system satisfies its safety specification. Flow-pipe construction methods interleave phases of computing continuous successors and phases of computing discrete successors. Directly doing this leads to a combinatorial explosion problem, though, as with each discrete successor there may be an interval of time where the transition can occur, so that the number of paths becomes exponential in the number of discrete transitions. For this reason, most reachable set computation tools implement some form of set aggregation for discrete transitions, such as, performing a template-based overapproximation or convex hull aggregation. These aggregation methods, however, in theory can lead to unbounded error, and in practice are often the root cause of why a safety specification cannot be proven. This paper proposes techniques for improving the accuracy of the aggregation operations performed for reachable set computation. First, we present two aggregation strategies over generalized stars, namely convex hull aggregation and template based aggregation. Second, we perform adaptive deaggregation using a data structure called Aggregated Directed Acyclic Graph (AGGDAG). Our deaggregation strategy is driven by counterexamples and hence has soundness and relative completeness guarantees. We demonstrate the computational benefits of our approach through two case studies involving satellite rendezvous and gearbox meshing.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2980048546",
    "type": "article"
  },
  {
    "title": "Quality Estimation and Optimization of Adaptive Stereo Matching Algorithms for Smart Vehicles",
    "doi": "https://doi.org/10.1145/3372784",
    "publication_date": "2020-02-10",
    "publication_year": 2020,
    "authors": "Fupeng Chen; Heng Yu; Yajun Ha",
    "corresponding_authors": "",
    "abstract": "Stereo matching is a promising approach for smart vehicles to find the depth of nearby objects. Transforming a traditional stereo matching algorithm to its adaptive version has potential advantages to achieve the maximum quality (depth accuracy) in a best-effort manner. However, it is very challenging to support this adaptive feature, since (1) the internal mechanism of adaptive stereo matching (ASM) has to be accurately modeled, and (2) scheduling ASM tasks on multiprocessors to generate the maximum quality is difficult under strict real-time constraints of smart vehicles. In this article, we propose a framework for constructing an ASM application and optimizing its output quality on smart vehicles. First, we empirically convert stereo matching into ASM by exploiting its inherent characteristics of disparity–cycle correspondence and introduce an exponential quality model that accurately represents the quality–cycle relationship. Second, with the explicit quality model, we propose an efficient quadratic programming-based dynamic voltage/frequency scaling (DVFS) algorithm to decide the optimal operating strategy, which maximizes the output quality under timing, energy, and temperature constraints. Third, we propose two novel methods to efficiently estimate the parameters of the quality model, namely location similarity-based feature point thresholding and street scenario-confined CNN prediction. Results show that our DVFS algorithm achieves at least 1.61 times quality improvement compared to the state-of-the-art techniques, and average parameter estimation for the quality model achieves 96.35% accuracy on the straight road.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2995463625",
    "type": "article"
  },
  {
    "title": "A Machine Learning Methodology for Cache Memory Design Based on Dynamic Instructions",
    "doi": "https://doi.org/10.1145/3376920",
    "publication_date": "2020-03-11",
    "publication_year": 2020,
    "authors": "Osvaldo Navarro; Jones Yudi; Javier Hoffmann; Hector Gerardo Muñoz Hernandez; Michael Hübner",
    "corresponding_authors": "",
    "abstract": "Cache memories are an essential component of modern processors and consume a large percentage of their power consumption. Its efficacy depends heavily on the memory demands of the software. Thus, finding the optimal cache for a particular program is not a trivial task and usually involves exhaustive simulation. In this article, we propose a machine learning–based methodology that predicts the optimal cache reconfiguration for any given application, based on its dynamic instructions. Our evaluation shows that our methodology reaches 91.1% accuracy. Moreover, an additional experiment shows that only a small portion of the dynamic instructions (10%) suffices to reach 89.71% accuracy.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3010718100",
    "type": "article"
  },
  {
    "title": "Compiling for the Worst Case",
    "doi": "https://doi.org/10.1145/3381752",
    "publication_date": "2020-03-11",
    "publication_year": 2020,
    "authors": "Arno Luppold; Dominic Oehlert; Heiko Falk",
    "corresponding_authors": "",
    "abstract": "Modern embedded hard real-time systems feature multiple tasks running on multiple processing cores. Schedulability analysis of such systems is usually performed on an abstract system level with each task being represented as a black box with fixed timing properties. If timing constraints are violated, then optimizing the system on a code-level to achieve schedulability is a tedious task. To tackle this issue, we propose an extension to the WCET-aware C Compiler framework WCC. We integrated an optimization framework based on Integer-Linear Programming into the WCC that is able to optimize a multi-core system with multiple tasks running on each core with regards to its schedulability. We evaluate the framework by providing two approaches on a schedulability aware static Scratchpad Memory (SPM) allocation: one based on Integer-Linear Programming (ILP) and one based on a genetic algorithm.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3013361332",
    "type": "article"
  },
  {
    "title": "D <scp>y</scp> VED <scp>eep</scp>",
    "doi": "https://doi.org/10.1145/3372882",
    "publication_date": "2020-05-31",
    "publication_year": 2020,
    "authors": "Sanjay Ganapathy; Swagath Venkataramani; Giridhur Sriraman; Balaraman Ravindran; Anand Raghunathan",
    "corresponding_authors": "",
    "abstract": "Deep Neural Networks (DNNs) have advanced the state-of-the-art in a variety of machine learning tasks and are deployed in increasing numbers of products and services. However, the computational requirements of training and evaluating large-scale DNNs are growing at a much faster pace than the capabilities of the underlying hardware platforms that they are executed upon. To address this challenge, one promising approach is to exploit the error resilient nature of DNNs by skipping or approximating computations that have negligible impact on classification accuracy. Almost all prior efforts in this direction propose static DNN approximations by either pruning network connections, implementing computations at lower precision, or compressing weights. In this work, we propose &lt;u&gt;Dy&lt;/u&gt;namic &lt;u&gt;V&lt;/u&gt;ariable &lt;u&gt;E&lt;/u&gt;ffort &lt;u&gt;Deep&lt;/u&gt; Neural Networks (D y VED eep ) to reduce the computational requirements of DNNs during inference. Complementary to the aforementioned static approaches, DyVEDeep is a dynamic approach that exploits heterogeneity in the DNN inputs to improve their compute efficiency with comparable classification accuracy and without requiring any re-training. D y VED eep equips DNNs with dynamic effort mechanisms that identify computations critical to classifying a given input and focus computational effort only on the critical computations, while skipping or approximating the rest. We propose three dynamic effort mechanisms that operate at different levels of granularity viz. neuron, feature, and layer levels. We build D y VED eep versions of six popular image recognition benchmarks (CIFAR-10, AlexNet, OverFeat, VGG-16, SqueezeNet, and Deep-Compressed-AlexNet) within the Caffe deep-learning framework. We evaluate D y VED eep on two platforms—a high-performance server with a 2.7 GHz Intel Xeon E5-2680 processor and 128 GB memory, and a low-power Raspberry Pi board with an ARM Cortex A53 processor and 1 GB memory. Across all benchmarks, D y VED eep achieves 2.47×--5.15× reduction in the number of scalar operations, which translates to 1.94×--2.23× and 1.46×--3.46× performance improvement over well-optimized baselines on the Xeon server and the Raspberry Pi, respectively, with comparable classification accuracy.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3034779821",
    "type": "article"
  },
  {
    "title": "Application of Logical Sub-networking in Congestion-aware Deadlock-free SDmesh Routing",
    "doi": "https://doi.org/10.1145/3387928",
    "publication_date": "2020-06-21",
    "publication_year": 2020,
    "authors": "Tuhin Subhra Das; Prasun Ghosal; Navonil Chatterjee; Arnab Nath; Akash Banerjee; Subhojyoti Khastagir",
    "corresponding_authors": "",
    "abstract": "An adaptive routing helps in evading early network saturation by steering data packets through the less congested area at the oppressive loaded situation. However, performances of adaptive routing are not always promising under all circumstances. Say for, given more freedom in choosing an alternate route on non-minimal paths for a substantially loaded network even may result in worsening network performances due to following longer route under adaptive routing. Here, underlying topology facilitates routing by offering more alternate short-cut routes on minimal or quasi-minimal paths. This work presents a congestion-aware (CA) adaptive routing for one-hop diagonally connected subnet-based mesh (SDmesh) network aiming to facilitate both performances and routing flexibility simultaneously. Our proposed technique on the selected system facilitates packet routing, offering more options in choosing an output link from minimal or quasi-minimal paths and hence helps in lowering packet delay by shortening the length of traversed traffic under the oppressive loaded situation. Furthermore, we have also employed a congestion-aware virtual input crossbar router aiming to split the entire network into two distinct logically separated sub-networks. It facilitates preserving important routing properties like deadlock, live-lock fairness, and other essential routing constraints. Experiments, conducted over two 8×8- and 12×12-sized networks, show an average improvement of 25--87.5% saturated latency and 60--83% throughput improvement under uniform traffic patterns for the proposed CA routing compared to centralized adaptive XY routing. Experimental results on application-specific PARSEC and SPLASH2 benchmark suites show an average of 22--50% latency and 23--30% throughput improvements by the proposed technique compared to centralized XY routing on the baseline mesh network. Moreover, experiments were also carried out to check the performance of the proposed routing method with different newly proposed deadlock-free adaptive routing approaches over the same subnet-based diagonal mesh (SDmesh) network and reported.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3036464732",
    "type": "article"
  },
  {
    "title": "Development Automation of Real-Time Java",
    "doi": "https://doi.org/10.1145/3391897",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Wanli Chang; Ran Wei; Shuai Zhao; Andy Wellings; Jim Woodcock; Alan Burns",
    "corresponding_authors": "",
    "abstract": "Many applications in emerging scenarios, such as autonomous vehicles, intelligent robots, and industrial automation, are safety-critical with strict timing requirements. However, the development of real-time systems is error prone and highly dependent on sophisticated domain expertise, making it a costly process. This article utilises the principles of model-driven engineering (MDE) and proposes two methodologies to automate the development of real-time Java applications. The first one automatically converts standard time-sharing Java applications to real-time Java applications, using a series of transformations. It is in line with the observed industrial trend, such as for the big data technology, of redeveloping existing software without the real-time notion to realise the real-time features. The second one allows users to automatically generate real-time Java application templates with a lightweight modelling language, which can be used to define the real-time properties—essentially a synthesis process. This article opens up a new research direction on development automation of real-time programming languages and inspires many research questions that can be jointly investigated by the embedded systems, programming languages as well as MDE communities.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3040739360",
    "type": "article"
  },
  {
    "title": "PANDORA",
    "doi": "https://doi.org/10.1145/3391899",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Greg Stitt; D. Campbell",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce a p arallelizing a pproximatio n - d isc o very f ra mework, PANDORA, for automatically discovering application- and architecture-specialized approximations of provided code. PANDORA complements existing compilers and runtime optimizers by generating approximations with a range of Pareto-optimal tradeoffs between performance and error, which enables adaptation to different inputs, different user preferences, and different runtime conditions (e.g., battery life). We demonstrate that PANDORA can create parallel approximations of inherently sequential code by discovering alternative implementations that eliminate loop-carried dependencies. For a variety of functions with loop-carried dependencies, PANDORA generates approximations that achieve speedups ranging from 2.3x to 81x, with acceptable error for many usage scenarios. We also demonstrate PANDORA’s architecture-specialized approximations via FPGA experiments, and highlight PANDORA’s discovery capabilities by removing loop-carried dependencies from a recurrence relation with no known closed-form solution.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3041489962",
    "type": "article"
  },
  {
    "title": "Minimization of WCRT with Recovery Assurance from Hardware Trojans for Tasks on FPGA-based Cloud",
    "doi": "https://doi.org/10.1145/3409479",
    "publication_date": "2020-12-07",
    "publication_year": 2020,
    "authors": "Debasri Saha; Susmita Sur‐Kolay",
    "corresponding_authors": "",
    "abstract": "Dynamic partial reconfiguration (DPR) enabled FPGA-based Cloud architecture acts as a flexible and efficient shared environment to facilitates application support to users’ request at low cost. While on one hand we need to handle a variety of tasks, such as periodic or sporadic, deadline or non-deadline, high or low critical tasks from the point of producing correct results, on the other hand we are constrained to use untrusted FPGA-based application IP blocks procured from various third-party vendors, which may contain hardware Trojan horse (HTH) affecting throughput and reliability of the Cloud. We propose Trojan-aware processing of tasks by monitored execution of a task on different untrusted cores, and then one more execution is done upon detection of hardware Trojan effects. For this stringent scheduling environment, the proposed dynamic scheduling algorithm is also properly extended to guarantee successful recovery from Trojan effects for all accepted tasks. Experimental results show that our algorithm improves worst-case-response-time for all tasks including non-deadline tasks and achieves lower task rejection rate for the deadline tasks, through judicious non-uniform partitioning of FPGAs based on supported jobs and subsequent better resource utilization, compared to that for existing Trojan-aware scheduling techniques.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3111075345",
    "type": "article"
  },
  {
    "title": "Fiat-shamir identification scheme immune to the hardware fault attacks",
    "doi": "https://doi.org/10.1145/2435227.2435261",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Sung-Kyoung Kim; Tae Hyun Kim; Seokhie Hong",
    "corresponding_authors": "",
    "abstract": "The Fiat-Shamir identification scheme is popular for “light” consumer devices, such as smart cards, in a wide range of consumer services. However, it can be vulnerable to fault attacks, even though a cryptographic algorithm is theoretically secure. Thus, a study on cryptanalysis and countermeasures to fault attacks is crucial. This article proposes a secure and practical modification of the Fiat-Shamir identification scheme resistant against fault attacks. A straightforward protection is to check integrity of the intermediate values and outputs at each step. However, this approach may be a bottleneck of the entire scheme and are attained at the expense of increased computational overhead that is similar to the overhead of the identification scheme. The proposed scheme is designed to propagate faults induced in a target variable to other parts without conditional branches. Therefore, a relatively small overhead enables implementation of the proposed scheme in small cryptographic devices such as smart cards.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1976032808",
    "type": "article"
  },
  {
    "title": "A network congestion-aware memory subsystem for manycore",
    "doi": "https://doi.org/10.1145/2485984.2485998",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Dongki Kim; Sungjoo Yoo; Sunggu Lee",
    "corresponding_authors": "",
    "abstract": "The network-on-chip (NoC) plays a crucial role in memory performance due to the fact that it can handle the majority of traffics from/to the DRAM memory controllers. However, there has been little work on the interplay between the NoC and memory controllers. In this article, we address a problem called network congestion-induced memory blocking and propose a novel memory controller, which performs memory access scheduling and network entry control in a network congestion-aware manner. In case of network congestion, in order to avoid performance degradation due to the blocking caused by data bound for congested regions in the NoC, the proposed memory controller favors requests and data associated with uncongested regions. In addition, in order to avoid the fairness problem of such a policy, we also propose a gradual method, which enables a trade-off between performance (in memory utilization) and fairness (in memory access latency). Experimental results show that the proposed method can offer up to 1.76 ∼ 2.99 times improvement in memory utilization in the latency-tolerant designs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1996439613",
    "type": "article"
  },
  {
    "title": "Power minimization for dynamically reconfigurable FPGA partitioning",
    "doi": "https://doi.org/10.1145/2435227.2435248",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Tzu-Chiang Tai; Yen‐Tai Lai",
    "corresponding_authors": "",
    "abstract": "Dynamically reconfigurable FPGA (DRFPGA) implements a given circuit system by partitioning it into stages and then executing each stage sequentially. Traditionally, the number of communication buffers is minimized. In this article, we study the partitioning problem targeting at power minimization for the DRFPGAs that have lookup table (LUT) based logic blocks. We analyze the power consumption caused by the communication buffers in the temporal partitioning. Based on the analysis, we use a flow network to represent a given circuit so that the power consumption of buffers is correctly evaluated and the temporal constraints are satisfied in circuit partitioning. The well known flow-based FBB algorithm is then applied to the network to find the area-balanced partitioning of minimum power consumption. Experimental results show that our method outperforms the conventional partitioning algorithms in terms of power consumption. The problem is then extended to include constraints on the number of communication buffers. We provide a net modeling for this extended problem and present an extension of the FBB algorithm to obtain a power-optimal solution. Experimental results demonstrate the effectiveness of the proposed algorithm in reducing power consumption as compared to the previous partitioning algorithms without exceeding the buffer number limit.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2005379524",
    "type": "article"
  },
  {
    "title": "Combining Formal Methods for the Development of Reactive Systems",
    "doi": "https://doi.org/10.1145/2406336.2406352",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Olfa Mosbahi",
    "corresponding_authors": "Olfa Mosbahi",
    "abstract": "This article deals with the use of two verification approaches: theorem proving and model checking. We focus on the Event-B method by using its associated theorem proving tool (Click_n_Prove), and on the language TLA + by using its model checker TLC. By considering the limitation of the Event-B method to invariance properties, we propose to apply the language TLA + to verify liveness properties on a software behavior. We extend first the expressivity and the semantics of a B model (called temporal B model ) to deal with the specification of fairness and eventuality properties. Second, we give transformation rules from a temporal B model into a TLA + module. We present in particular, our prototype system called B2TLA + , that we have developed to support this transformation; then we can verify these properties thanks to the model checker TLC on finite state systems. For the verification of infinite-state systems, we propose the use of the predicate diagrams. We illustrate our approach on a case study of a parcel sorting system.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2027368875",
    "type": "article"
  },
  {
    "title": "Software-based register file vulnerability reduction for embedded processors",
    "doi": "https://doi.org/10.1145/2536747.2536760",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Jongeun Lee; Aviral Shrivastava",
    "corresponding_authors": "",
    "abstract": "Register File (RF) is extremely vulnerable to soft errors, and traditional redundancy based schemes to protect the RF are prohibitive not only because RF is often in the timing critical path of the processor, but also since it is one of the hottest blocks on the chip. Software approaches would be ideal in this case, but previous approaches based on instruction scheduling are only moderately effective due to local scope. In this article we present a compiler approach, based on interprocedural program analysis, to reduce the vulnerability of registers by temporarily writing live variables to protected memory. We formulate the problem as an integer linear programming problem and also present a very efficient heuristic algorithm. Further we present an iterative optimization method based on Kernighan-Lin's graph partitioning algorithm. Our experiments demonstrate that our proposed techniques can reduce the vulnerability of a RF by 33 ∼ 37% on average and up to 66%, with a small 2% increase in runtime. In addition, our overhead reduction optimization can effectively reduce the code size overhead, by more than 40% on average, to a mere 5 ∼ 6%, compared to highly optimized binaries.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2032173170",
    "type": "article"
  },
  {
    "title": "Combining code reordering and cache configuration",
    "doi": "https://doi.org/10.1145/2362336.2399177",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Ann Gordon-Ross; Frank Vahid; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "The instruction cache is a popular optimization target due to the cache's high impact on system performance and power and because of the cache's predictable temporal and spatial locality. This article is an in depth study on the interaction of code reordering (a long-known technique) and cache configuration (a relatively new technique). Experimental results show that code reordering coupled with cache configuration reveals additional energy savings as high as 10--15% for several benchmarks with reduced cache area as high as 48%. To exploit these additional benefits, we architect and evaluate several design exploration heuristics for combining these two methods.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2046483553",
    "type": "article"
  },
  {
    "title": "EAVE",
    "doi": "https://doi.org/10.1145/2220336.2220349",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Kyoungwoo Lee; Nikil Dutt; Nalini Venkatasubramanian",
    "corresponding_authors": "",
    "abstract": "Energy/QoS provisioning is challenging for video applications over lossy wireless network with power-constrained mobile handheld devices. In this work, we exploit the inherent error tolerance of video data to generate a range of acceptable operating points by controlling the amount of errors in the system. In particular, we propose an error-aware video encoding technique, EAVE , that intentionally injects errors while ensuring acceptable QoS. The expanded trade-off space generated by EAVE allows system designers to comparatively evaluate different operating points with varying QoS and energy consumption by aggressively exploiting error-resilience attributes, and could potentially result in significant energy savings. The novelty of our approach resides in active exploitation of errors to vary the operating conditions for further optimization of system parameters. Moreover, we present the adaptivity of our approach by incorporating the feedback from the decoding side to achieve the QoS requirement under the dynamic network status. Our experiments show that EAVE can reduce the energy consumption for an encoding device by up to 37% for a video conferencing application over a wireless network without quality degradation, compared to a standard video encoding technique over test video streams. Further, our experimental results demonstrate that EAVE can expand the design space by 14 times with respect to energy consumption and by 13 times with respect to video quality (compared to a traditional approach without active error exploitation) on average, over test video streams.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2061237329",
    "type": "article"
  },
  {
    "title": "Analyzing and Visualizing Jump Performance Using Wireless Body Sensors",
    "doi": "https://doi.org/10.1145/2331147.2331157",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Gaurav N. Pradhan; Balakrishnan Prabhakaran",
    "corresponding_authors": "",
    "abstract": "Advancement in technology has led to the deployment of body sensor networks (BSN) to monitor and sense human activity in pervasive environments. Using multiple wireless on-body systems, such as physiological data monitoring and motion capture systems, body sensor network data consists of heterogeneous physiologic and motoric streams that form a multidimensional framework. In this article, we analyze such high-dimensional body sensor network data by proposing an efficient, multidimensional factor analysis technique for quantifying human performance and, at the same time, providing visualization for performances of participants in a low-dimensional space for easier interpretation.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2063008927",
    "type": "article"
  },
  {
    "title": "Artistic image generation for emerging multimedia services by impressionist manner",
    "doi": "https://doi.org/10.1145/2423636.2423640",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Sanghyun Seo; Seung-Taek Ryoo; Kyunghyun Yoon",
    "corresponding_authors": "",
    "abstract": "In this article, we propose the rendering framework for painting-like image generation and general system architecture for mobile device. Especially, we focused on a color division method for generating neo-impressionist images. The French painter, George Seurat, introduced pointillism under the theory that the individual pigments of colors on the canvas are reconstructed on the human retina. Pointillism is a painting technique in which many small brush strokes are combined to form a picture and determines the color of brush strokes based on the optical mixing of juxtaposed colors. In order to express countless separate dots, we form hierarchical points using Wang Tiles contained points. Also palette will be constructed using neo-impressionist colors. Based on this palette, we propose color division algorithm that distributes hierarchical point's color to pointillist colors using probability function. Finally, hierarchical points set that applied proposed color division rule is converted into brush strokes that possesses properties such as shape and direction. This rendering algorithm is performed in our proposed system. Our scheme is able to produce a painting with artistic style and be applied to the various platform having the different computing performance and display resolution. This system also can be extended to various imaging devices (IPTV, camera, smart phone, digital photo frame and so on).",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2067953897",
    "type": "article"
  },
  {
    "title": "Evaluating address register assignment and offset assignment algorithms",
    "doi": "https://doi.org/10.1145/1952522.1952530",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Johnny Huynh; José Nelson Amaral; Paul Berube; Sid‐Ahmed‐Ali Touati",
    "corresponding_authors": "",
    "abstract": "In digital signal processors (DSPs), variables are accessed using k address registers. The problem of finding a memory layout, for a set of variables, that minimizes the address-computation overhead is known as the General Offset Assignment (GOA) problem. The most common approach to this problem is to partition the set of variables into k partitions and to assign each partition to an address register. Thus, effectively decomposing the GOA problem into several Simple Offset Assignment (SOA) problems. Many heuristic-based algorithms are proposed in the literature to approximate solutions to both the variable partitioning and the SOA problems. However, the address-computation overhead of the resulting memory layouts are not accurately evaluated. This article presents an evaluation of memory layouts that uses Gebotys' optimal address-code generation technique. The use of this evaluation method leads to a new optimization problem: the Memory Layout Permutation (MLP) problem. We then use Gebotys' technique and an exhaustive solution to the MLP problem to evaluate heuristic-based offset-assignment algorithms. The memory layouts produced by each algorithm are compared against each other and against the optimal layouts. The results show that even in small access sequences with 12 variables or less, current heuristics may produce memory layouts with address-computation overheads up to two times higher than the overhead of an optimal layout.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2078041678",
    "type": "article"
  },
  {
    "title": "RAID 6 Hardware Acceleration",
    "doi": "https://doi.org/10.1145/2043662.2043667",
    "publication_date": "2011-11-01",
    "publication_year": 2011,
    "authors": "Michael Gilroy; James Irvine; Robert Atkinson",
    "corresponding_authors": "",
    "abstract": "Inexpensive, reliable hard disk storage is increasingly required in both businesses and the home. As disk capacities increase and multiple drives are combined in one system the probability of multiple disk failures increases. Through the adoption of RAID 6 the capability to recover from up to two simultaneous disk failures becomes available. In this article, we present three different RAID 6 implementations each tailored to support different target applications and optimized to reduce overall hardware resource utilization. We present an optimal Reed-Solomon-based RAID 6 implementation for arrays of four disks. We also present the smallest in terms of hardware resource utilization as well having the highest throughput RAID 6 hardware solution for disk arrays of up to 15 drives. Finally, we present an implementation supporting up to 255 disks in a single array.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2158123553",
    "type": "article"
  },
  {
    "title": "Exploring and Predicting the Effects of Microarchitectural Parameters and Compiler Optimizations on Performance and Energy",
    "doi": "https://doi.org/10.1145/2180887.2180901",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Christophe Dubach; Timothy M. Jones; Michael O’Boyle",
    "corresponding_authors": "",
    "abstract": "Embedded processor performance is dependent on both the underlying architecture and the compiler optimizations applied. However, designing both simultaneously is extremely difficult to achieve due to the time constraints designers must work under. Therefore, current methodology involves designing compiler and architecture in isolation, leading to suboptimal performance of the final product. This article develops a novel approach to this codesign space problem. For our specific design space, we demonstrate that we can automatically predict the performance that an optimizing compiler would achieve without actually tuning it for any of the microarchitecture configurations considered. Once trained, a single run of the program compiled with the standard optimization setting is enough to make a prediction on the new microarchitecture with just a 3.2% error rate on average. This allows the designer to accurately choose an architectural configuration with knowledge of how an optimizing compiler will perform on it. We use this to find the best optimizing compiler/architectural configuration in our codesign space and demonstrate that it achieves an average 19% performance improvement and energy savings of 16% compared to the baseline, nearly doubling the energy-efficiency measured as the energy-delay-squared product (EDD).",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2160844513",
    "type": "article"
  },
  {
    "title": "Scheduling of synchronous data flow models onto scratchpad memory-based embedded processors",
    "doi": "https://doi.org/10.1145/2536747.2536752",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Weijia Che; Karam S. Chatha",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a heuristic algorithm for scheduling synchronous data flow (SDF) models on scratch pad memory (SPM) enhanced processors with the objective of minimizing its steady-state execution time. The task involves partitioning the limited on-chip SPM for actor code and data buffer, and executing actors in such a manner that the physical SPM is time shared with different actors and buffers (formally defined as code overlay and data overlay, respectively). In our setup, a traditional minimum buffer schedule could result in very high code overlay overhead and therefore may not be optimal. To reduce the number of direct memory access (DMA) transfers, actors need to be grouped into segments. Prefetching of code and data overlay that overlaps DMA transfers with actor executions also need to be exploited. The efficiency of the our heuristic was evaluated by compiling ten stream applications onto one synergistic processing engine (SPE) of an IBM Cell Broadband Engine. We compare the performance results of our heuristic approach with a minimum buffer scheduling approach and a 3-stage ILP approach, and show that our heuristic is able to generate high quality solutions with fast algorithm run time.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2623295146",
    "type": "article"
  },
  {
    "title": "Special issue on power-aware embedded computing",
    "doi": "https://doi.org/10.1145/860176.860177",
    "publication_date": "2003-08-01",
    "publication_year": 2003,
    "authors": "Margarida F. Jacome; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "article Share on Special issue on power-aware embedded computing Editors: Margarida Jacome View Profile , Francky Catthoor View Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 2Issue 3August 2003 pp 251–254https://doi.org/10.1145/860176.860177Published:01 August 2003Publication History 1citation1,203DownloadsMetricsTotal Citations1Total Downloads1,203Last 12 Months4Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1986669539",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1086519.1086520",
    "publication_date": "2005-08-01",
    "publication_year": 2005,
    "authors": "Alan Burns",
    "corresponding_authors": "Alan Burns",
    "abstract": "editorial Free Access Share on Editorial Author: Alan Burns Alberto Sangiovanni-Vincentelli Alberto Sangiovanni-VincentelliView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 4Issue 3pp 469–471https://doi.org/10.1145/1086519.1086520Published:01 August 2005Publication History 6citation725DownloadsMetricsTotal Citations6Total Downloads725Last 12 Months11Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Publisher SiteeReaderPDF",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4249820615",
    "type": "editorial"
  },
  {
    "title": "Lane Compression",
    "doi": "https://doi.org/10.1145/3431815",
    "publication_date": "2021-03-18",
    "publication_year": 2021,
    "authors": "Yousun Ko; Alex Chadwick; Daniel Bates; Robert Mullins",
    "corresponding_authors": "",
    "abstract": "This article presents Lane Compression, a lightweight lossless compression technique for machine learning that is based on a detailed study of the statistical properties of machine learning data. The proposed technique profiles machine learning data gathered ahead of run-time and partitions values bit-wise into different lanes with more distinctive statistical characteristics. Then the most appropriate compression technique is chosen for each lane out of a small number of low-cost compression techniques. Lane Compression’s compute and memory requirements are very low and yet it achieves a compression rate comparable to or better than Huffman coding. We evaluate and analyse Lane Compression on a wide range of machine learning networks for both inference and re-training. We also demonstrate the profiling prior to run-time and the ability to configure the hardware based on the profiling guarantee robust performance across different models and datasets. Hardware implementations are described and the scheme’s simplicity makes it suitable for compressing both on-chip and off-chip traffic.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3139163275",
    "type": "article"
  },
  {
    "title": "The Predictable Execution Model in Practice",
    "doi": "https://doi.org/10.1145/3465370",
    "publication_date": "2021-07-29",
    "publication_year": 2021,
    "authors": "Björn Forsberg; Marco Solieri; Marko Bertogna; Luca Benini; Andrea Marongiu",
    "corresponding_authors": "",
    "abstract": "Adoption of multi- and many-core processors in real-time systems has so far been slowed down, if not totally barred, due do the difficulty in providing analytical real-time guarantees on worst-case execution times. The Predictable Execution Model (PREM) has been proposed to solve this problem, but its practical support requires significant code refactoring, a task better suited for a compilation tool chain than human programmers. Implementing a PREM compiler presents significant challenges to conform to PREM requirements, such as guaranteed upper bounds on memory footprint and the generation of efficient schedulable non-preemptive regions. This article presents a comprehensive description on how a PREM compiler can be implemented, based on several years of experience from the community. We provide accumulated insights on how to best balance conformance to real-time requirements and performance and present novel techniques that extend the applicability from simple benchmark suites to real-world applications. We show that code transformed by the PREM compiler enables timing predictable execution on modern commercial off-the-shelf hardware, providing novel insights on how PREM can protect 99.4% of memory accesses on random replacement policy caches at only 16% performance loss on benchmarks from the PolyBench benchmark suite. Finally, we show that the requirements imposed on the programming model are well-aligned with current coding guidelines for timing critical software, promoting easy adoption.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3183788589",
    "type": "article"
  },
  {
    "title": "Synthesis-guided Adversarial Scenario Generation for Gray-box Feedback Control Systems with Sensing Imperfections",
    "doi": "https://doi.org/10.1145/3477033",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Liren Yang; Necmiye Özay",
    "corresponding_authors": "",
    "abstract": "In this paper, we study feedback dynamical systems with memoryless controllers under imperfect information. We develop an algorithm that searches for “adversarial scenarios”, which can be thought of as the strategy for the adversary representing the noise and disturbances, that lead to safety violations. The main challenge is to analyze the closed-loop system's vulnerabilities with a potentially complex or even unknown controller in the loop. As opposed to commonly adopted approaches that treat the system under test as a black-box, we propose a synthesis-guided approach, which leverages the knowledge of a plant model at hand. This hence leads to a way to deal with gray-box systems (i.e., with known plant and unknown controller). Our approach reveals the role of the imperfect information in the violation. Examples show that our approach can find non-trivial scenarios that are difficult to expose by random simulations. This approach is further extended to incorporate model mismatch and to falsify vision-in-the-loop systems against finite-time reach-avoid specifications.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3186629482",
    "type": "article"
  },
  {
    "title": "PHiLIP on the HiL: Automated Multi-Platform OS Testing With External Reference Devices",
    "doi": "https://doi.org/10.1145/3477040",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Kevin B. Weiss; Michel Rottleuthner; Thomas C. Schmidt; Matthias Wählisch",
    "corresponding_authors": "",
    "abstract": "Developing an operating systems (OSs) for low-end embedded devices requires continuous adaptation to new hardware architectures and components, while serviceability of features needs to be assured for each individual platform under tight resource constraints. It is challenging to design a versatile and accurate heterogeneous test environment that is agile enough to cover a continuous evolution of the code base and platforms. This mission is even more challenging when organized in an agile open-source community process with many contributors such as for the RIOT OS. Hardware in the Loop (HiL) testing and Continuous Integration (CI) are automatable approaches to verify functionality, prevent regressions, and improve the overall quality at development speed in large community projects. In this paper, we present PHiLIP (Primitive Hardware in the Loop Integration Product), an open-source external reference device together with tools that validate the system software while it controls hardware and interprets physical signals. Instead of focusing on a specific test setting, PHiLIP takes the approach of a tool-assisted agile HiL test process, designed for continuous evolution and deployment cycles. We explain its design, describe how it supports HiL tests, evaluate performance metrics, and report on practical experiences of employing PHiLIP in an automated CI test infrastructure. Our initial deployment comprises 22 unique platforms, each of which executes 98 peripheral tests every night. PHiLIP allows for easy extension of low-cost, adaptive testing infrastructures but serves testing techniques and tools to a much wider range of applications.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3200122441",
    "type": "article"
  },
  {
    "title": "Verified Lustre Normalization with Node Subsampling",
    "doi": "https://doi.org/10.1145/3477041",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Timothy Bourke; Paul Jeanmaire; Basile Pesin; Marc Pouzet",
    "corresponding_authors": "",
    "abstract": "Dataflow languages allow the specification of reactive systems by mutually recursive stream equations, functions, and boolean activation conditions called clocks. Lustre and Scade are dataflow languages for programming embedded systems. Dataflow programs are compiled by a succession of passes. This article focuses on the normalization pass which rewrites programs into the simpler form required for code generation. Vélus is a compiler from a normalized form of Lustre to CompCert’s Clight language. Its specification in the Coq interactive theorem prover includes an end-to-end correctness proof that the values prescribed by the dataflow semantics of source programs are produced by executions of generated assembly code. We describe how to extend Vélus with a normalization pass and to allow subsampled node inputs and outputs. We propose semantic definitions for the unrestricted language, divide normalization into three steps to facilitate proofs, adapt the clock type system to handle richer node definitions, and extend the end-to-end correctness theorem to incorporate the new features. The proofs require reasoning about the relation between static clock annotations and the presence and absence of values in the dynamic semantics. The generalization of node inputs requires adding a compiler pass to ensure the initialization of variables passed in function calls.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3201118699",
    "type": "article"
  },
  {
    "title": "Worst-case Execution Time Calculation for Query-based Monitors by Witness Generation",
    "doi": "https://doi.org/10.1145/3471904",
    "publication_date": "2021-10-18",
    "publication_year": 2021,
    "authors": "Márton Búr; Kristóf Marussy; Brett H. Meyer; Dániel Varró",
    "corresponding_authors": "",
    "abstract": "Runtime monitoring plays a key role in the assurance of modern intelligent cyber-physical systems, which are frequently data-intensive and safety-critical. While graph queries can serve as an expressive yet formally precise specification language to capture the safety properties of interest, there are no timeliness guarantees for such auto-generated runtime monitoring programs, which prevents their use in a real-time setting. While worst-case execution time (WCET) bounds derived by existing static WCET estimation techniques are safe, they may not be tight as they are unable to exploit domain-specific (semantic) information about the input models. This paper presents a semantic-aware WCET analysis method for data-driven monitoring programs derived from graph queries. The method incorporates results obtained from low-level timing analysis into the objective function of a modern graph solver. This allows the systematic generation of input graph models up to a specified size (referred to as witness models) for which the monitor is expected to take the most time to complete. Hence the estimated execution time of the monitors on these graphs can be considered as safe and tight WCET. Additionally, we perform a set of experiments with query-based programs running on a real-time platform over a set of generated models to investigate the relationship between execution times and their estimates, and compare WCET estimates produced by our approach with results from two well-known timing analyzers, aiT and OTAWA.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3206697535",
    "type": "article"
  },
  {
    "title": "IoT-Fog-Cloud Centric Earthquake Monitoring and Prediction",
    "doi": "https://doi.org/10.1145/3487942",
    "publication_date": "2021-11-15",
    "publication_year": 2021,
    "authors": "Kanika Saini; Sheetal Kalra; Sandeep K. Sood",
    "corresponding_authors": "",
    "abstract": "Earthquakes are among the most inevitable natural catastrophes. The uncertainty about the severity of the earthquake has a profound effect on the burden of disaster and causes massive economic and societal losses. Although unpredictable, it can be expected to ameliorate damage and fatalities, such as monitoring and predicting earthquakes using the Internet of Things (IoT). With the resurgence of the IoT, an emerging innovative approach is to integrate IoT technology with Fog and Cloud Computing to augment the effectiveness and accuracy of earthquake monitoring and prediction. In this study, the integrated IoT-Fog-Cloud layered framework is proposed to predict earthquakes using seismic signal information. The proposed model is composed of three layers: (i) at sensor layer, seismic data are acquired, (ii) fog layer incorporates pre-processing, feature extraction using fast Walsh–Hadamard transform (FWHT), selection of relevant features by applying High Order Spectral Analysis (HOSA) to FWHT coefficients, and seismic event classification by K-means accompanied by real-time alert generation, (iii) at cloud layer, an artificial neural network (ANN) is employed to forecast the magnitude of an earthquake. For performance evaluation, K-means classification algorithm is collated with other well-known classification algorithms from the perspective of accuracy and execution duration. Implementation statistics indicate that with chosen HOS features, we have been able to attain high accuracy, precision, specificity, and sensitivity values of 93.30%, 96.65%, 90.54%, and 92.75%, respectively. In addition, the ANN provides an average correct magnitude prediction of 75%. The findings ensured that the proposed framework has the potency to classify seismic signals and predict earthquakes and could therefore further enhance the detection of seismic activities. Moreover, the generation of real-time alerts further amplifies the effectiveness of the proposed model and makes it more real-time compatible.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3212737106",
    "type": "article"
  },
  {
    "title": "GSFAP adaptive filtering using log arithmetic for resource-constrained embedded systems",
    "doi": "https://doi.org/10.1145/1698772.1698787",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "M. Tichý; Jan Schier; David Gregg",
    "corresponding_authors": "",
    "abstract": "Adaptive filters are widely used in many applications of digital signal processing. Digital communications and digital video broadcasting are just two examples. Traditionally, small embedded systems have employed the least computationally intensive filter adaptive algorithms, such as normalized least mean squares (NLMS). This article shows that FPGA devices are a highly suitable platform for more computationally intensive adaptive algorithms. We present an optimized core which implements GSFAP. GSFAP is an algorithm with far superior adaptation properties than NLMS, and with only slightly higher computational complexity. To further optimize resource requirements we use logarithmic arithmetic, rather than conventional floating point, within the custom core. Our design makes effective use of the pipelined logarithmic addition units, and takes advantage of the very low cost of logarithmic multiplication and division. The resulting GSFAP core can be clocked at more than 80MHz on a one million-gate Xilinx XC2V1000-4 device. The core can be used to implement adaptive filters of orders 20 to 1000 performing echo cancellation on speech signals at a sampling rate exceeding 50kHz. For comparison, we implemented a similar NLMS core and found that although it is slightly smaller than the GSFAP core and allows a higher signal sampling rate for the corresponding filter orders, the GSFAP core has adaptation properties that are much superior to NLMS, and that our core can provide very sophisticated adaptive filtering capabilities for resource-constrained embedded systems.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1993374181",
    "type": "article"
  },
  {
    "title": "Modeling and exploiting spatial locality trade-offs in wavelet-based applications under varying resource requirements",
    "doi": "https://doi.org/10.1145/1698772.1698775",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Bert Geelen; V. Ferentinos; Francky Catthoor; Gauthier Lafruit; Diederik Verkest; Rudy Lauwereins; T. Stouraitis",
    "corresponding_authors": "",
    "abstract": "Future dynamic applications will require new mapping strategies to deliver power-efficient performance. Fully static design-time mappings will not be able to optimally address the unpredictably varying application characteristics and system resource requirements. Instead, the platforms will not only need to be programmable in terms of instruction set processors, but also at least partial reconfigurability will be required, while the applications themselves will need to exploit this increased freedom at runtime to adapt to the dynamism. In this context, it is important for applications to optimally exploit the memory hierarchy under varying memory availability. This article presents an analysis of spatial locality trade-offs in wavelet-based applications, to be used in dynamic execution environments: Depending on the encountered runtime conditions, the execution switches to different memory optimized instantiations or localizations, optimally exploiting temporal and spatial locality under these conditions. This is enabled by systematic mapping guidelines, indicating how the miss-rate behavior of a localization is influenced by a specific execution condition, under which conditions a certain localization is optimal and which miss-rate gains may be obtained by switching to that localization.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2059927024",
    "type": "article"
  },
  {
    "title": "Feasibility of semiring-based timing constraints",
    "doi": "https://doi.org/10.1145/1721695.1721699",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Yue Yu; Shangping Ren; Ophir Frieder",
    "corresponding_authors": "",
    "abstract": "Real-time and embedded applications often involve different types of timing constraints, such as precedence constraints and real-time constraints. As real-time and embedded applications further advance, new timing constraint types are emerging as well. Recent research on interval-based timing constraints is an example. Thus, it is important to have a uniformed timing constraint representation so that a generalized approach can be developed to analyze the variant constraint types. A semiring-based timing constraint model is introduced to generalize the representations of different constraint types. Under this model, we develop an algorithm to check the satisfaction feasibility for a given set of semiring-based timing constraints. This algorithm provides better performance in the average case as compared to applying the Bellman-Ford algorithm directly on the constraint set. In addition, for a set of feasible semiring-based timing constraints, event occurrence points that satisfy the constraint set form a (hyperdimension) feasible region. For the given two sets of timing constraints, we develop a necessary and sufficient condition to testify whether the two constraint sets' feasible regions have an inclusion relation. If one feasible region is included in the other, we know that the real-time event occurrences that satisfy the included constraint set will necessarily satisfy the including set.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2061579081",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1550987.1550988",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Zhiyuan Li; Santosh Pande",
    "corresponding_authors": "",
    "abstract": "Publisher Note: This Guest Editorial by Li and Pande describes a number of related articles originally intended as a special issue but which were published in earlier issues as follows: Auerbach et al., \"Low-Latency Time-Portable Real-Time Programming with Exotasks\" , appears in TECS 8(2) Article 15 DOI 10.1145/1457255.1457262 Murray et al., \"Code Transformation and Instruction Set Extension\" , appears in TECS 8(4) Article 26 DOI 10.1145/1550987.1550989 Ahn and Paek, \"Register Coalescing Techniques for Heterogeneous Register Architecture with Copy Sifting\" , appears in TECS 8(2) Article 16 DOI 10.1145/1457255.1457263 Yan and Zhang, \"Analyzing the Worst-Case Execution Time for Instruction Caches with Prefetching\" , appears in TECS 8(1) Article 7 DOI 10.1145/1457246.1457253",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2061852259",
    "type": "editorial"
  },
  {
    "title": "Conserving energy in real-time storage systems with I/O burstiness",
    "doi": "https://doi.org/10.1145/1698772.1698778",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Adam Manzanares; Xiaojun Ruan; Shu Yin; Xiao Qin; Adam Roth; Mais Najim",
    "corresponding_authors": "",
    "abstract": "Energy conservation has become a critical problem for real-time embedded storage systems. Although a variety of approaches for reducing energy consumption have been extensively studied, energy conservation for real-time embedded storage systems is still an open problem. In this article, we propose an energy management strategy, I/O Burstiness for Energy Conservation (IBEC), exploiting the burstiness of real-time embedded storage systems applications. Our approach aims at combining the IBEC energy-management strategy with a Linux-based disk block-scheduling mechanism to conserve the energy of storage systems. Extensive experiments are conducted involving a number of synthetic disk traces as well as real-world data-intensive traces. To evaluate the energy efficiency of IBEC, we compare the performance of IBEC against three existing strategies, namely, PA-EDF, DP-EDF, and EDF. Compared with the alternative strategies, IBEC reduces the power consumption of real-time embedded disks system by up to 60%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2140227178",
    "type": "article"
  },
  {
    "title": "On Static Binary Translation of ARM/Thumb Mixed ISA Binaries",
    "doi": "https://doi.org/10.1145/2996458",
    "publication_date": "2017-03-28",
    "publication_year": 2017,
    "authors": "Jiunn‐Yeu Chen; Wuu Yang; Wei‐Chung Hsu; Bor-Yeh Shen; Quan-Huei Ou",
    "corresponding_authors": "",
    "abstract": "Code discovery has been a main challenge for static binary translation, especially when the source instruction set architecture has variable-length instructions, such as the x86 architectures. Due to embedded data such as PC (program counter)-relative data, jump tables, or paddings in the code section, a binary translator may be misled to translate data as instructions. For variable-length instructions, once a piece of data is mis-translated as instructions, decoding subsequent bytes could also go wrong. We are concerned with static binary translation for the very popular Advanced RISC Machine (ARM) architectures. Although ARM is considered a reduced instruction set computer architecture, it does allow the mix of 32-bit (ARM) instructions and 16-bit (Thumb) instructions in the same executables. In addition to different instruction lengths, the ARM and Thumb instructions are located at 4-byte or 2-byte aligned addresses, respectively. Furthermore, because ARM and Thumb instructions share the same encoding space, a 4-byte word could sometimes be decoded as one ARM instruction or two Thumb instructions. The correct decoding of this 4-byte word is actually determined at runtime by the least-significant bit of the program counter. For unstripped binaries, the mapping symbols can be used to identify ARM code regions and Thumb code regions. However, for stripped binaries, such mapping symbols are unavailable. We propose a novel solution to statically translate stripped ARM/Thumb mixed executables. Our solution is implemented in a static binary translator. The binary translator further generates multiple versions of translated code for the code regions whose types cannot be determined with our solution. One of the code versions is selected during runtime. The binary translator also includes a series of analyses that enable the removal of most useless code versions. Based on the experimental results on stripped ARM/Thumb mixed binaries in the SPEC2006 and Embedded Microprocessor Benchmark Consortium (EEMBC) benchmark suites, our static binary translator achieves impressive performance when migrating them to run on x86 machines and the space overhead is no more than 10%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2603355854",
    "type": "article"
  },
  {
    "title": "On Space Utilization Enhancement of File Systems for Embedded Storage Systems",
    "doi": "https://doi.org/10.1145/2820488",
    "publication_date": "2017-04-11",
    "publication_year": 2017,
    "authors": "Tseng‐Yi Chen; Yuan-Hao Chang; Shuo-Han Chen; Nien-I Hsu; Hsin‐Wen Wei; Wei‐Kuan Shih",
    "corresponding_authors": "",
    "abstract": "Since the mid-2000s, mobile/embedded computing systems conventionally have limited computing power, Random Access Memory (RAM) space, and storage capacity due to the consideration of their cost, energy consumption, and physical size. Recently, some of these systems, such as mobile phone and embedded consumer electronics, have more powerful computing capability, so they manage their data in small flash storage devices (e.g., Embedded Multi Media Card (eMMC) and Secure Digital (SD) cards) with a simple file system. However, the existing file systems usually have low space utilization for managing small files and the tail data of large files. In this work, we thus propose a dynamic tail packing scheme to enhance the space utilization of file systems over flash storage devices in embedded computing systems by dynamically aggregating/packing the tail data of (small) files together. To evaluate the benefits and overheads of the proposed scheme, we theoretically formulate analysis equations for obtaining the best settings in the dynamic tail packing scheme. Additionally, the proposed scheme was implemented in the file system of Linux operating systems to evaluate its capability. The results demonstrate that the proposed scheme could significantly improve the space utilization of existing file systems.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2605834004",
    "type": "article"
  },
  {
    "title": "When Do We Not Need Complex Assume-Guarantee Rules?",
    "doi": "https://doi.org/10.1145/3012280",
    "publication_date": "2017-01-02",
    "publication_year": 2017,
    "authors": "Antti Siirtola; Stavros Tripakis; Keijo Heljanko",
    "corresponding_authors": "",
    "abstract": "We study the need for complex circular assume-guarantee (AG) rules in formalisms that already provide the simple precongruence rule. We first investigate the question for two popular formalisms: Labeled Transition Systems (LTSs) with weak simulation and Interface Automata (IA) with alternating simulation. We observe that, in LTSs, complex circular AG rules cannot always be avoided, but, in the IA world, the simple precongruence rule is all we need. Based on these findings, we introduce modal IA with cut states, a novel formalism that not only generalizes IA and LTSs but also allows for compositional reasoning without complex AG rules.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2654996322",
    "type": "article"
  },
  {
    "title": "Task-FIFO Co-Scheduling of Streaming Applications on MPSoCs with Predictable Memory Hierarchy",
    "doi": "https://doi.org/10.1145/3038484",
    "publication_date": "2017-03-10",
    "publication_year": 2017,
    "authors": "Qi Tang; Twan Basten; Marc Geilen; Sander Stuijk; Jibo Wei",
    "corresponding_authors": "",
    "abstract": "This article studies the scheduling of real-time streaming applications on multiprocessor systems-on-chips with predictable memory hierarchy. An iteration-based task-FIFO co-scheduling framework is proposed for this problem. We obtain FIFO size distributions using Pareto space searching, based on which the task-to-processor mapping is obtained with the potential FIFO allocation being taken into account; then, the FIFO-to-memory allocation is optimized to minimize the total memory access cost; finally, a self-timed throughput analysis method that considers memory and direct memory access controller contention is utilized to analyze the throughput. Our methods are validated by a set of synthesized and practical applications on different platforms.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2691238409",
    "type": "article"
  },
  {
    "title": "A Study of Dynamic Phase Adaptation Using a Dynamic Multicore Processor",
    "doi": "https://doi.org/10.1145/3126523",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Paul-Jules Micolet; A. Gordon Smith; Christophe Dubach",
    "corresponding_authors": "",
    "abstract": "Heterogeneous processors such as ARM’s big.LITTLE have become popular for embedded systems. They offer a choice between running workloads on a high performance core or a low-energy core leading to increased energy efficiency. However, the core configurations are fixed at design time which offers a limited amount of adaptation. Dynamic Multicore Processors (DMPs) bridge the gap between homogeneous and fully reconfigurable systems. Cores can fuse dynamically to adapt the computational resources to the needs of different workloads. There exists multiple examples of DMPs in the literature, yet the focus has mainly been on static partitioning. This paper conducts the first thorough study of the potential for dynamic reconfiguration of DMPs at runtime. We study how performance varies with static partitioning and what software optimizations are required to achieve high performance. We show that energy consumption is reduced considerably when adapting the number of cores to program phases, and introduce a simple online model which predicts the optimal number of cores to use to minimize energy consumption while maintaining high performance. Using the San Diego Vision Benchmark Suite as a use case, the dynamic scheme leads to ∼40% energy savings on average without decreasing performance.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2734822979",
    "type": "article"
  },
  {
    "title": "Runtime Performance and Power Optimization of Parallel Disparity Estimation on Many-Core Platforms",
    "doi": "https://doi.org/10.1145/3133560",
    "publication_date": "2017-11-14",
    "publication_year": 2017,
    "authors": "Charles Leech; C. Ramesh Kumar; Amit Acharyya; Sheng Yang; Geoff V. Merrett; Bashir M. Al‐Hashimi",
    "corresponding_authors": "",
    "abstract": "This article investigates the use of many-core systems to execute the disparity estimation algorithm, used in stereo vision applications, as these systems can provide flexibility between performance scaling and power consumption. We present a learning-based runtime management approach that achieves a required performance threshold while minimizing power consumption through dynamic control of frequency and core allocation. Experimental results are obtained from a 61-core Intel Xeon Phi platform for the aforementioned investigation. The same performance can be achieved with an average reduction in power consumption of 27.8% and increased energy efficiency by 30.04% when compared to Dynamic Voltage and Frequency Scaling control alone without runtime management.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2758151830",
    "type": "article"
  },
  {
    "title": "Operational Models for Piecewise-Smooth Systems",
    "doi": "https://doi.org/10.1145/3126506",
    "publication_date": "2017-10-10",
    "publication_year": 2017,
    "authors": "Andrew Sogokon; Khalil Ghorbal; Taylor T. Johnson",
    "corresponding_authors": "",
    "abstract": "In this article we study ways of constructing meaningful operational models of piecewise-smooth systems (PWS). The systems we consider are described by polynomial vector fields defined on non-overlapping semi-algebraic sets, which form a partition of the state space. Our approach is to give meaning to motion in systems of this type by automatically synthesizing operational models in the form of hybrid automata (HA). Despite appearances, it is in practice often difficult to arrive at satisfactory HA models of PWS. The different ways of building operational models that we explore in our approach can be thought of as defining different semantics for the underlying PWS. These differences have a number of interesting nuances related to phenomena such as chattering, non-determinism, so-called mythical modes and sliding behaviour.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2761407096",
    "type": "article"
  },
  {
    "title": "Fault Recovery Time Analysis for Coarse-Grained Reconfigurable Architectures",
    "doi": "https://doi.org/10.1145/3140944",
    "publication_date": "2017-11-21",
    "publication_year": 2017,
    "authors": "Ganghee Lee; Ediz Cetin; Oliver Diessel",
    "corresponding_authors": "",
    "abstract": "Coarse-grained reconfigurable architectures (CGRAs) have drawn increasing attention due to their performance and flexibility advantages. Typically, CGRAs incorporate many processing elements in the form of an array, which is suitable for implementing spatial redundancy, as used in the design of fault-tolerant systems. This article introduces a recovery time model for transient faults in CGRAs. The proposed fault-tolerant CGRAs are based on triple modular redundancy and coding techniques for error detection and correction. To evaluate the model, several kernels from space computing are mapped onto the suggested architecture. We demonstrate the tradeoff between recovery time, performance, and area. In addition, the average execution time of an application including recovery time is evaluated using area-based error-rate estimates in harsh radiation environments. The results show that task partitioning is important for bounding the recovery time of applications that have long execution times. It is also shown that error-correcting code (ECC) is of limited practical value for tasks with long execution times in high radiation environments, or when the degree of task partitioning is high.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2770211583",
    "type": "article"
  },
  {
    "title": "Symbolic Multi-Level Loop Mapping of Loop Programs for Massively Parallel Processor Arrays",
    "doi": "https://doi.org/10.1145/3092952",
    "publication_date": "2017-12-07",
    "publication_year": 2017,
    "authors": "Alexandru Tanase; Michael Witterauf; Jürgen Teich; Frank Hannig",
    "corresponding_authors": "",
    "abstract": "Today’s MPSoCs (multiprocessor systems-on-chip) have brought up massively parallel processor array accelerators that may achieve a high computational efficiency by exploiting multiple levels of parallelism and different memory hierarchies. Such parallel processor arrays are perfect targets, particularly for the acceleration of nested loop programs due to their regular and massively parallel nature. However, existing loop parallelization techniques are often unable to exploit multiple levels of parallelism and are either I/O or memory bounded. Furthermore, if the number of available processing elements becomes only known at runtime—as in adaptive systems—static approaches fail. In this article, we solve some of these problems by proposing a hybrid compile/runtime multi-level symbolic parallelization technique that is able to: (a) exploit multiple levels of parallelism as well as (b) different memory hierarchies, and (c) to match the I/O or memory capabilities of the target architecture for scenarios where the number of available processing elements is only known at runtime. Our proposed technique consists of two compile-time transformations: (a) symbolic hierarchical tiling followed by (b) symbolic multi-level scheduling. The tiling levels scheduled in parallel exploit different levels of parallelism, whereas the sequential one, different memory hierarchies. Furthermore, by tuning the size of the tiles on the individual levels, a tradeoff between the necessary I/O-bandwidth and memory is possible, which facilitates obeying resource constraints. The resulting schedules are symbolic with respect to the problem size and tile sizes. Thus, the number of processing elements to map onto does not need to be known at compile time. At runtime, when the number of available processors becomes known, a simple prologue chooses a feasible schedule with respect to I/O and memory constraints that is latency-optimal for the chosen tile size. In summary, our approach determines the set of feasible, latency-optimal symbolic loop schedule candidates at compile time, from which one is dynamically selected at runtime. This approach exploits multiple levels of parallelism, is independent of the problem size of the loop nest, and thereby avoids any expensive re-compilation at runtime. This is particularly important for low cost and memory-scarce embedded MPSoC platforms that may not afford to host a just-in-time compiler.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2775543260",
    "type": "article"
  },
  {
    "title": "A Construction Kit for Efficient Low Power Neural Network Accelerator Designs",
    "doi": "https://doi.org/10.1145/3520127",
    "publication_date": "2022-03-07",
    "publication_year": 2022,
    "authors": "Petar Jokic; Erfan Azarkhish; Andrea Bonetti; Marc Pons; Stéphane Emery; Luca Benini",
    "corresponding_authors": "",
    "abstract": "Implementing embedded neural network processing at the edge requires efficient hardware acceleration that combines high computational throughput with low power consumption. Driven by the rapid evolution of network architectures and their algorithmic features, accelerator designs are constantly being adapted to support the improved functionalities. Hardware designers can refer to a myriad of accelerator implementations in the literature to evaluate and compare hardware design choices. However, the sheer number of publications and their diverse optimization directions hinder an effective assessment. Existing surveys provide an overview of these works but are often limited to system-level and benchmark-specific performance metrics, making it difficult to quantitatively compare the individual effects of each utilized optimization technique. This complicates the evaluation of optimizations for new accelerator designs, slowing-down the research progress. In contrast to previous surveys, this work provides a quantitative overview of neural network accelerator optimization approaches that have been used in recent works and reports their individual effects on edge processing performance. The list of optimizations and their quantitative effects are presented as a construction kit, allowing to assess the design choices for each building block individually. Reported optimizations range from up to 10,000× memory savings to 33× energy reductions, providing chip designers with an overview of design choices for implementing efficient low power neural network accelerators.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3173537091",
    "type": "article"
  },
  {
    "title": "Holistic Resource Allocation Under Federated Scheduling for Parallel Real-time Tasks",
    "doi": "https://doi.org/10.1145/3489467",
    "publication_date": "2022-01-14",
    "publication_year": 2022,
    "authors": "Lanshun Nie; Chenghao Fan; Shuang Lin; Li Zhang; Jun Li; Jing Li",
    "corresponding_authors": "",
    "abstract": "With the technology trend of hardware and workload consolidation for embedded systems and the rapid development of edge computing, there has been increasing interest in supporting parallel real-time tasks to better utilize the multi-core platforms while meeting the stringent real-time constraints. For parallel real-time tasks, the federated scheduling paradigm, which assigns each parallel task a set of dedicated cores, achieves good theoretical bounds by ensuring exclusive use of processing resources to reduce interferences. However, because cores share the last-level cache and memory bandwidth resources, in practice tasks may still interfere with each other despite executing on dedicated cores. Such resource interferences due to concurrent accesses can be even more severe for embedded platforms or edge servers, where the computing power and cache/memory space are limited. To tackle this issue, in this work, we present a holistic resource allocation framework for parallel real-time tasks under federated scheduling. Under our proposed framework, in addition to dedicated cores, each parallel task is also assigned with dedicated cache and memory bandwidth resources. Further, we propose a holistic resource allocation algorithm that well balances the allocation between different resources to achieve good schedulability. Additionally, we provide a full implementation of our framework by extending the federated scheduling system with Intel’s Cache Allocation Technology and MemGuard. Finally, we demonstrate the practicality of our proposed framework via extensive numerical evaluations and empirical experiments using real benchmark programs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4205733412",
    "type": "article"
  },
  {
    "title": "L <sup>2</sup> C: Combining Lossy and Lossless Compression on Memory and I/O",
    "doi": "https://doi.org/10.1145/3481641",
    "publication_date": "2022-01-14",
    "publication_year": 2022,
    "authors": "Albin Eldstål-Ahrens; Angelos Arelakis; Ioannis Sourdis",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce L 2 C, a hybrid lossy/lossless compression scheme applicable both to the memory subsystem and I/O traffic of a processor chip. L 2 C employs general-purpose lossless compression and combines it with state-of-the-art lossy compression to achieve compression ratios up to 16:1 and to improve the utilization of chip’s bandwidth resources. Compressing memory traffic yields lower memory access time, improving system performance, and energy efficiency. Compressing I/O traffic offers several benefits for resource-constrained systems, including more efficient storage and networking. We evaluate L 2 C as a memory compressor in simulation with a set of approximation-tolerant applications. L 2 C improves baseline execution time by an average of 50% and total system energy consumption by 16%. Compared to the lossy and lossless current state-of-the-art memory compression approaches, L 2 C improves execution time by 9% and 26%, respectively, and reduces system energy costs by 3% and 5%, respectively. I/O compression efficacy is evaluated using a set of real-life datasets. L 2 C achieves compression ratios of up to 10.4:1 for a single dataset and on average about 4:1, while introducing no more than 0.4% error.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4206341542",
    "type": "article"
  },
  {
    "title": "Reduced Memory Viterbi Decoding for Hardware-accelerated Speech Recognition",
    "doi": "https://doi.org/10.1145/3510028",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Pani Prithvi Raj; Akhil Pakala; Nitin Chandrachoodan",
    "corresponding_authors": "",
    "abstract": "Large Vocabulary Continuous Speech Recognition systems require Viterbi searching through a large state space to find the most probable sequence of phonemes that led to a given sound sample. This needs storing and updating of a large Active State List (ASL) in the on-chip memory (OCM) at regular intervals (called frames), which poses a major performance bottleneck for speech decoding. Most works use hash tables for OCM storage while beam-width pruning to restrict the ASL size. To achieve a decent accuracy and performance, a large OCM, numerous acoustic probability computations, and DRAM accesses are incurred. We propose to use a binary search tree for ASL storage and a max heap data structure to track the worst cost state and efficiently replace it when a better state is found. With this approach, the ASL size can be reduced from over 32K to 512 with minimal impact on recognition accuracy for a 7,000-word vocabulary model. This, combined with a caching technique for acoustic scores, reduced the DRAM data accessed by 31 \\( \\times \\) and the acoustic probability computations by 26 \\( \\times \\) . The approach has also been implemented in hardware on a Xilinx Zynq FPGA at 200 MHz using the Vivado SDS compiler. We study the tradeoffs among the amount of OCM used, word error rate, and decoding speed to show the effectiveness of the approach. The resulting implementation is capable of running faster than real time with 91% lesser block-RAMs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4210328785",
    "type": "article"
  },
  {
    "title": "A Framework for Calculating WCET Based on Execution Decision Diagrams",
    "doi": "https://doi.org/10.1145/3476879",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Zhenyu Bai; Hugues Cassé; Marianne de Michiel; Thomas Carle; Christine Rochange",
    "corresponding_authors": "",
    "abstract": "Due to the dynamic behaviour of acceleration mechanisms such as caches and branch predictors, static Worst-case Execution Time (WCET) analysis methods tend to scale poorly to modern hardware architectures. As a result, a trade-off must be found between the duration and the precision of the analysis, leading to an overestimation of the WCET bounds. In turn, this reduces the schedulability and resource usage of the system. In this article, we present a new data structure to speed up the analysis: the eXecution Decision Diagram (XDD), which is an ad hoc extension of Binary Decision Diagrams tailored for WCET analysis problems. We show how XDDs can be used to represent efficiently execution states in a modern hardware platform. Moreover, we propose a new process to build the Integer Linear Programming system of the Implicit Path Enumeration Technique using XDD. We use benchmark applications to demonstrate how the use of an XDD substantially increases the scalability of WCET analysis and the precision of the obtained WCET.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4210435796",
    "type": "article"
  },
  {
    "title": "Read Refresh Scheduling and Data Reallocation against Read Disturb in SSDs",
    "doi": "https://doi.org/10.1145/3495254",
    "publication_date": "2022-02-08",
    "publication_year": 2022,
    "authors": "Jianwei Liao; Jun Li; Mingwang Zhao; Zhibing Sha; Zhigang Cai",
    "corresponding_authors": "",
    "abstract": "Read disturb is a circuit-level noise in flash-based Solid-State Drives (SSDs), induced by intensive read requests, which may result in unexpected read errors. The approach of read refresh (RR) is commonly adopted to mitigate its negative effects by unconditionally migrating all valid data pages in the RR block to another new block. However, routine RR operations greatly impact the I/O responsiveness of SSDs, because the processing on normal I/O requests must be blocked at the same time. To further reduce the negative effects of read refresh, this article proposes a read refresh scheduling and data reallocation method to deal with two primary issues with respect to an RR operation, including where to place data pages and when to trigger page migrations. Specifically, we first construct a data reallocation model to match the data pages in the RR block and the destination blocks for addressing the issue of where to place the data. The model considers not only the read hotness of pages in the RR block, but also the accumulated read counts of the destination blocks. Moreover, for addressing the issue of when to trigger data migrations, we build a timing decision model to determine the time points for completing page migrations by considering the factors of the intensity of I/Os and the disturb situation on the RR block. Through a series of simulation experiments based on several realistic disk traces, we illustrate that the proposed RR scheduling and data reallocation mechanism can noticeably reduce the read errors by more than 10.3% , on average, and the long-tail latency by between 43.9% and 64.0% at the 99.99th percentile, in contrast to state-of-the-art methods.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4210857047",
    "type": "article"
  },
  {
    "title": "Protecting Network-on-Chip Intellectual Property Using Timing Channel Fingerprinting",
    "doi": "https://doi.org/10.1145/3495565",
    "publication_date": "2022-02-08",
    "publication_year": 2022,
    "authors": "Arnab Kumar Biswas; Biplab Sikdar",
    "corresponding_authors": "",
    "abstract": "The theft of Intellectual property (IP) is a serious security threat for all businesses that are involved in the creation of IP. In this article, we consider such attacks against IP for Network-on-Chip (NoC) that are commonly used as a popular on-chip scalable communication medium for Multiprocessor System-on-Chip. As a protection mechanism, we propose a timing channel fingerprinting method and show its effectiveness by implementing five different solutions using this method. We also provide a formal proof of security of the proposed method. We show that the proposed technique provides better security and requires much lower hardware overhead (64%–74% less) compared to an existing NoC IP security solution without affecting the normal packet latency or degrading the NoC performance.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4210868525",
    "type": "article"
  },
  {
    "title": "Probabilistic Risk-Aware Scheduling with Deadline Constraint for Heterogeneous SoCs",
    "doi": "https://doi.org/10.1145/3489409",
    "publication_date": "2022-02-08",
    "publication_year": 2022,
    "authors": "Xing Chen; Ümit Y. Ogras; Chaitali Chakrabarti",
    "corresponding_authors": "",
    "abstract": "Hardware Trojans can compromise System-on-Chip (SoC) performance. Protection schemes implemented to combat these threats cannot guarantee 100% detection rate and may also introduce performance overhead. This paper defines the risk of running a job on an SoC as a function of the misdetection rate of the hardware Trojan detection methods implemented on the cores in the SoC. Given the user-defined deadlines of each job, our goal is to minimize the job-level risk as well as the deadline violation rate for both static and dynamic scheduling scenarios. We assume that there is no relationship between the execution time and risk of a task executed on a core. Our risk-aware scheduling algorithm first calculates the probability of possible task allocations and then uses it to derive the task-level deadlines. Each task is then allocated to the core with minimum risk that satisfies the task-level deadline. In addition, in dynamic scheduling, where multiple jobs are injected randomly, we propose to explicitly operate with a reduced virtual deadline to avoid possible future deadline violations. Simulations on randomly generated graphs show that our static scheduler has no deadline violations and achieves 5.1%–17.2% lower job-level risk than the popular Earliest Time First (ETF) algorithm when the deadline constraint is 1.2×–3.0× the makespan of ETF. In the dynamic case, the proposed algorithm achieves a violation rate comparable to that of Earliest Deadline First (EDF) , an algorithm optimized for dynamic scenarios. Even when the injection rate is high, it outperforms EDF with 8.4%–10% lower risk when the deadline is 1.5×–3.0× the makespan of ETF.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4210887746",
    "type": "article"
  },
  {
    "title": "DirectNVM: Hardware-accelerated NVMe SSDs for High-performance Embedded Computing",
    "doi": "https://doi.org/10.1145/3463911",
    "publication_date": "2022-01-31",
    "publication_year": 2022,
    "authors": "Yu Zou; Amro Awad; Mingjie Lin",
    "corresponding_authors": "",
    "abstract": "With data-intensive artificial intelligence (AI) and machine learning (ML) applications rapidly surging, modern high-performance embedded systems, with heterogeneous computing resources, critically demand low-latency and high-bandwidth data communication. As such, the newly emerging NVMe (Non-Volatile Memory Express) protocol, with parallel queuing, access prioritization, and optimized I/O arbitration, starts to be widely adopted as a de facto fast I/O communication interface. However, effectively leveraging the potential of modern NVMe storage proves to be nontrivial and demands fine-grained control, high processing concurrency, and application-specific optimization. Fortunately, modern FPGA devices, capable of efficient parallel processing and application-specific programmability, readily meet the underlying physical layer requirements of the NVMe protocol, therefore providing unprecedented opportunities to implementing a rich-featured NVMe middleware to benefit modern high-performance embedded computing. In this article, we present how to rethink existing accessing mechanisms of NVMe storage and devise innovative hardware-assisted solutions to accelerating NVMe data access performance for the high-performance embedded computing system. Our key idea is to exploit the massively parallel I/O queuing capability, provided by the NVMe storage system, through leveraging FPGAs’ reconfigurability and native hardware computing power to operate transparently to the main processor. Specifically, our DirectNVM system aims at providing effective hardware constructs for facilitating high-performance and scalable userspace storage applications through (1) hardening all the essential NVMe driver functionalities, therefore avoiding expensive OS syscalls and enabling zero-copy data access from the application, (2) relying on hardware for the I/O communication control instead of relying on OS-level interrupts that can significantly reduce both total I/O latency and its variance, and (3) exposing cutting-edge and application-specific weighted-round-robin I/O traffic scheduling to the userspace. To validate our design methodology, we developed a complete DirectNVM system utilizing the Xilinx Zynq MPSoC architecture that incorporates a high-performance application processor (APU) equipped with DDR4 system memory and a hardened configurable PCIe Gen3 block in its programmable logic part. We then measured the storage bandwidth and I/O latency of both our DirectNVM system and a conventional OS-based system when executing the standard FIO benchmark suite [ 2 ]. Specifically, compared against the PetaLinux built-in kernel driver code running on a Zynq MPSoC, our DirectNVM has shown to achieve up to 18.4× higher throughput and up to 4.5× lower latency. To ensure the fairness of our performance comparison, we also measured our DirectNVM system against the Intel SPDK [ 26 ], a highly optimized userspace asynchronous NVMe I/O framework running on a X86 PC system. Our experiment results have shown that our DirectNVM, even running on a considerably less powerful embedded ARM processor than a full-scale AMD processor, achieved up to 2.2× higher throughput and 1.3× lower latency. Furthermore, by experimenting with a multi-threading test case, we have demonstrated that our DirectNVM’s weighted-round-robin scheduling can significantly optimize the bandwidth allocation between latency-constraint frontend applications and other backend applications in real-time systems. Finally, we have developed a theoretical framework of performance modeling with classic queuing theory that can quantitatively define the relationship between a system’s I/O performance and its I/O implementation.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4211050422",
    "type": "article"
  },
  {
    "title": "DyCo: Dynamic, Contextualized AI Models",
    "doi": "https://doi.org/10.1145/3520131",
    "publication_date": "2022-03-26",
    "publication_year": 2022,
    "authors": "Yi Yang; Murugan Sankaradas; Srimat Chakradhar",
    "corresponding_authors": "",
    "abstract": "Devices with limited computing resources use smaller AI models to achieve low-latency inferencing. However, model accuracy is typically much lower than the accuracy of a bigger model that is trained and deployed in places where the computing resources are relatively abundant. We describe DyCo, a novel system that ensures privacy of stream data and dynamically improves the accuracy of small models used in devices. Unlike knowledge distillation or federated learning, DyCo treats AI models as black boxes. DyCo uses a semi-supervised approach to leverage existing training frameworks and network model architectures to periodically train contextualized, smaller models for resource-constrained devices. DyCo uses a bigger, highly accurate model in the edge-cloud to auto-label data received from each sensor stream. Training in the edge-cloud (as opposed to the public cloud) ensures data privacy, and bespoke models for thousands of live data streams can be designed in parallel by using multiple edge-clouds. DyCo uses the auto-labeled data to periodically re-train, stream-specific, bespoke small models. To reduce the periodic training costs, DyCo uses different policies that are based on stride, accuracy, and confidence information. We evaluate our system, and the contextualized models, by using two object detection models for vehicles and people, and two datasets (a public benchmark and another real-world proprietary dataset). Our results show that DyCo increases the mAP accuracy measure of small models by an average of 16.3% (and up to 20%) for the public benchmark and an average of 19.0% (and up to 64.9%) for the real-world dataset. DyCo also decreases the training costs for contextualized models by more than an order of magnitude.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4220782210",
    "type": "article"
  },
  {
    "title": "A Segmented Adaptive Router for Near Energy-Proportional Networks-on-Chip",
    "doi": "https://doi.org/10.1145/3529106",
    "publication_date": "2022-04-12",
    "publication_year": 2022,
    "authors": "Maxime France-Pillois; Abdoulaye Gamatié; Gilles Sassatelli",
    "corresponding_authors": "",
    "abstract": "A Network-on-Chip (NoC) is an essential component of a chip multiprocessor (CMP) which however contributes to a large fraction of system energy. The unpredictability of traffic across a NoC frequently involves an expensive over-sizing of NoC resources which in turn leads to a significant contribution to the CMP power consumption. There exists a body of work addressing this issue, however so far solutions fall short when aiming for power reduction whilst maintaining high NoC performance. This paper proposes to combine router architecture optimizations with smart resource management to overcome this limitation. Based on a fully segmented architecture, we present an online adaptive router adjusting its active routing resources to meet the current traffic demand. This enhanced power-gating strategy significantly decreases both static and dynamic power consumption of the NoC, up to 70% for synthetic traffic patterns and up to 58% for real traffic workloads, while preserving NoC latency and throughput. Thanks to these adaptive power-saving mechanisms the proposed segmented NoC router provides near energy-proportional operation across the range of used benchmarks.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4223468750",
    "type": "article"
  },
  {
    "title": "HLS-based High-throughput and Work-efficient Synthesizable Graph Processing Template Pipeline",
    "doi": "https://doi.org/10.1145/3529256",
    "publication_date": "2022-04-20",
    "publication_year": 2022,
    "authors": "Hamzeh Ahangari; Muhammet Mustafa Özdal; Özcan Öztürk",
    "corresponding_authors": "",
    "abstract": "Hardware systems composed of diverse execution resources are being deployed to cope with the complexity and performance requirements of Artificial Intelligence (AI) and Machine Learning (ML) applications. With the emergence of new hardware platforms, system-wide programming support has become much more important. While this is true for various devices ranging from CPUs to GPUs, it is especially critical for specific neural network accelerators implemented on FPGAs. For example, Intel’s recent HARP platform encompasses a Xeon CPU and an FPGA, which requires an intense software stack to be used effectively. Programming such a hybrid system will be a challenge for most of the non-expert users. High-level language solutions such as Intel OpenCL for FPGA try to address the problem. However, as the abstraction level increases, the efficiency of implementation decreases, depicting two opposing requirements. In this work, we propose a framework to generate HLS-based, FPGA-accelerated, high-throughput/work-efficient, synthesizable, and template-based graph-processing pipeline. While a fixed and clock-wise precisely designed deep-pipeline architecture, written in SystemC, is responsible for processing graph vertices, the user implements the intended iterative graph algorithm by implementing/modifying only a single module in C/C++. This way, efficiency and high performance can be achieved with better programmability and productivity. With similar programming efforts, it is shown that the proposed template outperforms a high-throughput OpenCL baseline by up to 50% in terms of edge throughput. Furthermore, the novel work-efficient design significantly improves execution time and power consumption by up to 100×.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4224253714",
    "type": "article"
  },
  {
    "title": "OnSRAM: Efficient Inter-Node On-Chip Scratchpad Management in Deep Learning Accelerators",
    "doi": "https://doi.org/10.1145/3530909",
    "publication_date": "2022-04-27",
    "publication_year": 2022,
    "authors": "Subhankar Pal; Swagath Venkataramani; V. Srinivasan; Kailash Gopalakrishnan",
    "corresponding_authors": "",
    "abstract": "Hardware acceleration of Artificial Intelligence (AI) workloads has gained widespread popularity with its potential to deliver unprecedented performance and efficiency. An important challenge remains in how AI accelerators are programmed to sustain high utilization without impacting end-user productivity. Prior software optimizations start with an input graph and focus on node-level optimizations, viz. dataflows and hierarchical tiling, and graph-level optimizations such as operation fusion. However, little effort has been devoted to inter-node on-chip scratchpad memory (SPM) management in Deep Learning (DL) accelerators, whose significance is bolstered by the recent trends in complex network topologies and the emergence of eager execution in DL frameworks. We characterize and show that there exists up to a 5.2× performance gap in DL inference to be bridged using SPM management and propose OnSRAM, a novel SPM management framework integrated with the compiler runtime of a DL accelerator. We develop two variants, viz. OnSRAM-Static, which works on static graphs to identify data structures that can be lucratively held on-chip based on their size, liveness and significance, and OnSRAM-Eager, which targets an eager execution model (no graph) and uses a history-based speculative scheme to hold/discard data structures. We integrate OnSRAM with TensorFlow and analyze it on multiple accelerator configurations. Across a suite of 12 images, objects, and language networks, on a 3 TFLOP system with a 2 MB SPM and 32 GBps external memory bandwidth, OnSRAM-Static and OnSRAM-Eager achieve 1.02–4.8× and 1.02–3.1× reduction in inference latency (batch size of 1), over a baseline with no SPM management. In terms of energy savings, we observe average reductions of 1.51× (up to 4.1×) and 1.23× (up to 2.9×) for the static and eager execution scenarios, respectively.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4224937757",
    "type": "article"
  },
  {
    "title": "An Efficient and Flexible Stochastic CGRA Mapping Approach",
    "doi": "https://doi.org/10.1145/3550071",
    "publication_date": "2022-07-21",
    "publication_year": 2022,
    "authors": "Satyajit Das; Kévin Martin; Thomas Peyret; Philippe Coussy",
    "corresponding_authors": "",
    "abstract": "Coarse-Grained Reconfigurable Array (CGRA) architectures are promising high-performance and power-efficient platforms. However, mapping applications efficiently on CGRA is a challenging task. This is known to be an NP complete problem. Hence, finding good mapping solutions for a given CGRA architecture within a reasonable time is complex. Additionally, finding scalability in compilation time and memory footprint for large heterogeneous CGRAs is also a well known problem. In this article, we present a stochastic mapping approach that can efficiently explore the architecture space and allows finding best of solutions while having limited and steady use of memory footprint. Experimental results show that our compilation flow allows to reach performances with low-complexity CGRA architectures that are as good as those obtained with more complex ones thanks to the better exploration of the mapping solution space. Parameters considered in our experiments are number of tiles, Register File (RF) size, number of load/store (LS) units, network topologies, and so on. Our results demonstrate that high-quality compilation for a wide range of applications is possible within reasonable run-times. Experiments with several DSP benchmarks show that the best CGRA configuration from the architectural exploration surpasses an ultra low-power DSP optimized RISC-V CPU to achieve up to 15.28× (with an average of 6× and minimum of 3.4×) performance gain and 29.7× (with an average of 13.5× and minimum of 6.3×) energy gain with an area overhead of 1.5× only.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4286489560",
    "type": "article"
  },
  {
    "title": "SHARP: An Adaptable, Energy-Efficient Accelerator for Recurrent Neural Networks",
    "doi": "https://doi.org/10.1145/3552513",
    "publication_date": "2022-08-12",
    "publication_year": 2022,
    "authors": "Reza Yazdani Aminabadi; Olatunji Ruwase; Minjia Zhang; Yuxiong He; José-María Arnau; Antonio González",
    "corresponding_authors": "",
    "abstract": "The effectiveness of Recurrent Neural Networks (RNNs) for tasks such as Automatic Speech Recognition has fostered interest in RNN inference acceleration. Due to the recurrent nature and data dependencies of RNN computations, prior work has designed customized architectures specifically tailored to the computation pattern of RNN, getting high computation efficiency for certain chosen model sizes. However, given that the dimensionality of RNNs varies a lot for different tasks, it is crucial to generalize this efficiency to diverse configurations. In this work, we identify adaptiveness as a key feature that is missing from today’s RNN accelerators. In particular, we first show the problem of low resource utilization and low adaptiveness for the state-of-the-art RNN implementations on GPU, FPGA, and ASIC architectures. To solve these issues, we propose an intelligent tiled-based dispatching mechanism for increasing the adaptiveness of RNN computation, in order to efficiently handle the data dependencies. To do so, we propose Sharp as a hardware accelerator, which pipelines RNN computation using an effective scheduling scheme to hide most of the dependent serialization. Furthermore, Sharp employs dynamic reconfigurable architecture to adapt to the model’s characteristics. Sharp achieves 2×, 2.8×, and 82× speedups on average, considering different RNN models and resource budgets, compared to the state-of-the-art ASIC, FPGA, and GPU implementations, respectively. Furthermore, we provide significant energy reduction with respect to the previous solutions, due to the low power dissipation of Sharp (321 GFLOPS/Watt).",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4291141759",
    "type": "article"
  },
  {
    "title": "Dataflow Driven Partitioning of Machine Learning Applications for Optimal Energy Use in Batteryless Systems",
    "doi": "https://doi.org/10.1145/3520135",
    "publication_date": "2022-03-21",
    "publication_year": 2022,
    "authors": "Andres Gomez; Andreas Tretter; Pascal Alexander Hager; Praveenth Sanmugarajah; Luca Benini; Lothar Thiele",
    "corresponding_authors": "",
    "abstract": "Sensing systems powered by energy harvesting have traditionally been designed to tolerate long periods without energy. As the Internet of Things (IoT) evolves toward a more transient and opportunistic execution paradigm, reducing energy storage costs will be key for its economic and ecologic viability. However, decreasing energy storage in harvesting systems introduces reliability issues. Transducers only produce intermittent energy at low voltage and current levels, making guaranteed task completion a challenge. Existing ad hoc methods overcome this by buffering enough energy either for single tasks, incurring large data-retention overheads, or for one full application cycle, requiring a large energy buffer. We present Julienning : an automated method for optimizing the total energy cost of batteryless applications. Using a custom specification model, developers can describe transient applications as a set of atomically executed kernels with explicit data dependencies. Our optimization flow can partition data- and energy-intensive applications into multiple execution cycles with bounded energy consumption. By leveraging interkernel data dependencies, these energy-bounded execution cycles minimize the number of system activations and nonvolatile data transfers, and thus the total energy overhead. We validate our methodology with two batteryless cameras running energy-intensive machine learning applications. Using a solar testbed, we replay real-world illuminance traces to experimentally demonstrate optimized batteryless execution with a transducer-to-application energy efficiency of 74.5%. Partitioning results demonstrate that compared to ad hoc solutions, our method can reduce the required energy storage by over 94% while only incurring a 0.12% energy overhead.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4293101794",
    "type": "article"
  },
  {
    "title": "FD-CNN: A Frequency-Domain FPGA Acceleration Scheme for CNN-Based Image-Processing Applications",
    "doi": "https://doi.org/10.1145/3559105",
    "publication_date": "2022-09-13",
    "publication_year": 2022,
    "authors": "Xiaoyang Wang; Zhe Zhou; Zhihang Yuan; Jingchen Zhu; Yulong Cao; Yao Zhang; Kangrui Sun; Guangyu Sun",
    "corresponding_authors": "",
    "abstract": "In the emerging edge-computing scenarios, FPGAs have been widely adopted to accelerate convolutional neural network (CNN)–based image-processing applications, such as image classification, object detection, and image segmentation, and so on. A standard image-processing pipeline first decodes the collected compressed images from Internet of Things (IoTs) to RGB data, then feeds them into CNN engines to compute the results. Previous works mainly focus on optimizing the CNN inference parts. However, we notice that on the popular ZYNQ FPGA platforms, image decoding can also become the bottleneck due to the poor performance of embedded ARM CPUs. Even with a hardware accelerator, the decoding operations still incur considerable latency. Moreover, conventional RGB-based CNNs have too few input channels at the first layer, which can hardly utilize the high parallelism of CNN engines and greatly slows down the network inference. To overcome these problems, in this article, we propose FD-CNN, a novel CNN accelerator leveraging the partial-decoding technique to accelerate CNNs directly in the frequency domain. Specifically, we omit the most time-consuming IDCT (Inverse Discrete Cosine Transform) operations of image decoding and directly feed the DCT coefficients (i.e., the frequency data) into CNNs. By this means, the image decoder can be greatly simplified. Moreover, compared to the RGB data, frequency data has a narrower input resolution but has 64× more channels. Such an input shape is more hardware friendly than RGB data and can substantially reduce the CNN inference time. We then systematically discuss the algorithm, architecture, and command set design of FD-CNN. To deal with the irregularity of different CNN applications, we propose an image-decoding-aware design-space exploration (DSE) workflow to optimize the pipeline. We further propose an early stopping strategy to tackle the time-consuming progressive JPEG decoding. Comprehensive experiments demonstrate that FD-CNN achieves, on average, 3.24×, 4.29× throughput improvement, 2.55×, 2.54× energy reduction and 2.38×, 2.58× lower latency on ZC-706 and ZCU-102 platforms, respectively, compared to the baseline image-processing pipelines.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4296131359",
    "type": "article"
  },
  {
    "title": "Evaluating Controlled Memory Request Injection for Efficient Bandwidth Utilization and Predictable Execution in Heterogeneous SoCs",
    "doi": "https://doi.org/10.1145/3548773",
    "publication_date": "2022-09-19",
    "publication_year": 2022,
    "authors": "Gianluca Brilli; Roberto Cavicchioli; Marco Solieri; Paolo Valente; Andrea Marongiu",
    "corresponding_authors": "",
    "abstract": "High-performance embedded platforms are increasingly adopting heterogeneous systems-on-chip (HeSoC) that couple multi-core CPUs with accelerators such as GPU, FPGA, or AI engines. Adopting HeSoCs in the context of real-time workloads is not immediately possible, though, as contention on shared resources like the memory hierarchy—and in particular the main memory (DRAM)—causes unpredictable latency increase. To tackle this problem, both the research community and certification authorities mandate (i) that accesses from parallel threads to the shared system resources (typically, main memory) happen in a mutually exclusive manner by design, or (ii) that per-thread bandwidth regulation is enforced. Such arbitration schemes provide timing guarantees, but make poor use of the memory bandwidth available in a modern HeSoC. Controlled Memory Request Injection (CMRI) is a recently-proposed bandwidth limitation concept that builds on top of a mutually-exclusive schedule but still allows the threads currently not entitled to access memory to use as much of the unused bandwidth as possible without losing the timing guarantee. CMRI has been discussed in the context of a multi-core CPU, but the same principle applies also to a more complex system such as an HeSoC. In this article, we introduce two CMRI schemes suitable for HeSoCs: Voluntary Throttling via code refactoring and Bandwidth Regulation via dynamic throttling. We extensively characterize a proof-of-concept incarnation of both schemes on two HeSoCs: an NVIDIA Tegra TX2 and a Xilinx UltraScale+, highlighting the benefits and the costs of CMRI for synthetic workloads that model worst-case DRAM access. We also test the effectiveness of CMRI with real benchmarks, studying the effect of interference among the host CPU and the accelerators.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4296371102",
    "type": "article"
  },
  {
    "title": "High-Performance Implementation of the Identity-Based Signature Scheme in IEEE P1363 on GPU",
    "doi": "https://doi.org/10.1145/3564784",
    "publication_date": "2022-09-27",
    "publication_year": 2022,
    "authors": "Xinyi Hu; Debiao He; Min Luo; Cong Peng; Qi Feng; Xinyi Huang",
    "corresponding_authors": "",
    "abstract": "Identity-based cryptography is proposed to solve the complicated certificate management of traditional public-key cryptography. The pairing computation and high-level tower extension field arithmetic turn out to be the performance bottleneck of pairing-based signature schemes. Graphics processing units have been increasingly popular for general-purpose computing in recent years. They have shown a lot of promise in speeding up cryptographic schemes such as AES, RSA, and ECDSA. However, to our knowledge, the research on parallel implementation of pairings and identity-based cryptographic schemes on graphics processing units is somewhat outdated. Therefore, in this article, we implement the identity-based signature scheme in the IEEE P1363 Standard on a modern NVIDIA RTX 3060 card. We convert the pairing computation in signature verification into a product of pairings with fixed arguments and therefore avoid the scalar multiplication in 𝔾 2 . Then we employ the precomputation technique to improve the elliptic curve scalar multiplication, exponentiation in \\(\\mathbb {F}_{p^{12}}\\) and the pairing computation. We also apply PTX ISA to multiple-precision arithmetic. Experiments demonstrate that our implementation can perform 43,856/46,753/39,798 pairings/sec for the Optimal Ate pairing, the pairing with a fixed argument, and two pairings with fixed arguments, respectively. Peak throughputs of signature generation and verification can achieve 322.6 and 40.6 kops/sec over the BN254 curve.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4297320272",
    "type": "article"
  },
  {
    "title": "System synthesis of synchronous multimedia applications",
    "doi": "https://doi.org/10.1145/605459.605463",
    "publication_date": "2003-02-01",
    "publication_year": 2003,
    "authors": "Gang Qu; Miodrag Potkonjak",
    "corresponding_authors": "",
    "abstract": "Modern system design is being increasingly driven by applications such as multimedia and wireless sensing and communications, which have intrinsic quality of service (QoS) requirements, such as throughput, error-rate, and resolution. One of the most crucial QoS guarantees that the system has to provide is the timing constraint among the interacting media (synchronization) and within each media (latency). We have developed the first framework for system design with timing QoS guarantees. In particular, we address how to design system-on-chip with minimum silicon area to meet both latency and synchronization constraints. The proposed design methodology consists of two phases: hardware configuration selection and on-chip memory/storage minimization. In the first phase, we use silicon area and system performance as criteria to identify all the competitive hardware configurations (i.e., Pareto points) that facilitate the needs of synchronous applications. In the second phase, we determine the minimum on-chip memory requirement to meet the timing constraints for each Pareto point. An overall system evaluation is conducted to select the best system configuration. We have developed optimal algorithms that schedule a priori specified applications to meet their synchronization requirements with the minimum size of memory. We have also implemented on-line heuristics for real-time applications. The effectiveness of our algorithms has been demonstrated on a set of simulated MPEG streams from popular movies.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2057430095",
    "type": "article"
  },
  {
    "title": "A reprogrammable customization framework for efficient branch resolution in embedded processors",
    "doi": "https://doi.org/10.1145/1067915.1067924",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "П. П. Петров; Alex Orailoğlu",
    "corresponding_authors": "",
    "abstract": "We present a customization framework for embedded processors which employs the utilization of application-specific information, thus specializing the processor's microarchitecture to the application needs. The increased processor utilization leads to a low-cost system implementation with no sacrifice in performance requirements and to reduced custom hardware in a typical SOC. We illustrate these ideas through the branch resolution problem, known to impose severe performance degradation on control-dominated embedded applications. A customization approach for early branch resolution and subsequent folding is presented. The application-specific information is captured by the microarchitecture through a low-cost reprogrammable hardware, thus attaining the twin benefits of processor standardization and application-specific customization. Experimental results show that for a representative set of control-dominated applications a reduction in the range of 3--22% in processor cycles can be achieved, thus extending the scope of low-cost embedded processors in complex codesigns for control intensive systems.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1963888661",
    "type": "article"
  },
  {
    "title": "A transformational perspective into the core of an abstract class loader for the SSP",
    "doi": "https://doi.org/10.1145/1196636.1196639",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "Victor Winter; Jason Beranek; Fares Fraij; Steve Roach; Greg Wickstrom",
    "corresponding_authors": "",
    "abstract": "The SSP is a hardware implementation of a subset of the JVM for use in high-consequence embedded applications. In this context, a majority of the activities belonging to class loading, as it is defined in the specification of the JVM, can be performed statically. Static class loading has the net result of dramatically simplifying the design of the SSP, as well as increasing its performance. Because of the high consequence nature of its applications, strong evidence must be provided that all aspects of the SSP have been implemented correctly. This includes the class loader. This article explores the possibility of formally verifying a class loader for the SSP implemented in the strategic programming language TL. Specifically, an implementation of the core activities of an abstract class loader is presented and its verification in ACL2 is considered.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2009514841",
    "type": "article"
  },
  {
    "title": "Information flow in hybrid systems",
    "doi": "https://doi.org/10.1145/1027794.1027799",
    "publication_date": "2004-11-01",
    "publication_year": 2004,
    "authors": "Ruggero Lanotte; Andrea Maggiolo–Schettini; Simone Tini",
    "corresponding_authors": "",
    "abstract": "Our aim is to study the information flow problem in hybrid systems, namely systems consisting of a discrete program with an analog environment. Information flows compromise the security of a system because they cause leakage of protected information. In order to tackle information flow in real-life systems, we introduce new classes of hybrid systems that extend the known ones while preserving their properties. Then, we define a logic to specify information flow. By means of some examples, we show that, by this logic, we are able to express information flows in hybrid systems and to certify that some suspect behaviors of these systems do not give rise to any information flow. We give a model checking procedure for our logic, and we prove that it gives a correct answer whenever it terminates. Moreover, for a particular class of hybrid systems, we give a version of the procedure that always terminates.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2058182389",
    "type": "article"
  },
  {
    "title": "Shared heap management for memory-limited java virtual machines",
    "doi": "https://doi.org/10.1145/1331331.1331337",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Yoonseo Choi; Hwansoo Han",
    "corresponding_authors": "",
    "abstract": "One scarce resource in embedded systems is memory. Multitasking makes the lack of memory problem even worse. Most current embedded systems, which do not provide virtual memory, simply divide physical memory and evenly assign contiguous memory chunks to multiple applications. Such simple memory management can frequently cause the lack of available memory for some applications, while others are not using the full amount of assigned memory. To overcome inefficiency in current memory management, we present an efficient heap management scheme that allows multiple applications to share heap space. To reduce overall heap memory usage, applications adaptively acquire subheaps out of shared pool of memory and release surplus subheaps to shared pool. As a result, applications see noncontiguous multiple subheaps as a heap in their address space. We target Java applications to implement our heap-sharing scheme in the KVM from Sun Microsystems. To protect fragmented heap space with a limited number of regions in memory protection unit (MPU), we maintain only a limited number of subheaps. We experimentally evaluate our heap management scheme with J2ME MIDP applications. Our static and dynamic schemes reduce heap memory usage, on average, by 30 and 27%, respectively. For both schemes, overheads are kept low. The execution times in our schemes are increased only by 0.01% for static scheme and 0.35% for dynamic scheme, on average.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1987930502",
    "type": "article"
  },
  {
    "title": "Prefabrication and postfabrication architecture exploration for partially reconfigurable VLIW processors",
    "doi": "https://doi.org/10.1145/1376804.1376808",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Anupam Chattopadhyay; Harold Ishebabi; X. Chen; Z. Rakosi; Kingshuk Karuri; David W. Kammler; Rainer Leupers; Gerd Ascheid; H. Meyr",
    "corresponding_authors": "",
    "abstract": "Modern application-specific instruction-set processors (ASIPs) face the daunting task of delivering high performance for a wide range of applications. For enhancing the performance, architectural features, for example, pipelining, VLIW, are often employed in ASIPs, leading to high design complexity. Integrated ASIP design environments, like template-based approaches and language-driven approaches, provide an answer to this growing design complexity. At the same time, increasing hardware design costs have motivated the processor designers to introduce high flexibility in the processor. Flexibility, in its most effective form, can be introduced to the ASIP by coupling a reconfigurable unit to the base processor. Because of its obvious benefits, several reconfigurable ASIPs (rASIPs) have been designed for years. This design paradigm gained momentum with the advent of coarse-grained FPGAs, where the lack of domain-specific performance common in general-purpose FPGAs are largely overcome by choosing application-dependent basic functional units. These rASIP designs lack a generic flow from high-level specification, resulting in intuitive design decisions and hard-to-retarget processor design tools. Although partial, template-based approaches for rASIP design is existent, a clear design methodology especially for the prefabrication architecture exploration is not present. In order to address this issue, a high-level specification and design methodology for partially reconfigurable VLIW processors is proposed in this article. To show the benefit of this approach, a commercial VLIW processor is used as the base architecture and two domains of applications are studied for potential performance gain.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1991685745",
    "type": "article"
  },
  {
    "title": "Modeling and analysis of core-centric network processors",
    "doi": "https://doi.org/10.1145/1376804.1376809",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Yi-Neng Lin; Ying‐Dar Lin; Yuan‐Cheng Lai; Kuo-Kun Tseng",
    "corresponding_authors": "",
    "abstract": "Network processors can be categorized into two types, the coprocessors-centric model in which data-plane is handled by coprocessors, and the core-centric model in which the core processes most of the data-plane packets yet offloading some tasks to coprocessors. While the former has been properly explored over various applications, research regarding the latter remain limited. Based on the previous experience of prototyping the virtual private network (VPN) over the IXP425 network processor, this work aims to derive design implications for the core-centric model performing computational intensive applications. From system and IC vendors' perspectives, the continuous-time Markov chain and Petri net simulations are adopted to explore this architecture. Analytical results prove to be quite inline with those of the simulation and implementation. With subsequent investigation, we find that appropriate process run lengths can improve the effective core utilization by 2.26 times, and by offloading the throughput boosts 7.5 times. The results also suggest single-process programming, since context-switch overhead impacts considerably on the performance.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2124656225",
    "type": "article"
  },
  {
    "title": "OpenCL-based Virtual Prototyping and Simulation of Many-Accelerator Architectures",
    "doi": "https://doi.org/10.1145/3242179",
    "publication_date": "2018-09-24",
    "publication_year": 2018,
    "authors": "Efstathios Sotiriou-Xanthopoulos; Leonard Masing; Sotirios Xydis; Kostas Siozios; Jürgen Becker; Dimitrios Soudris",
    "corresponding_authors": "",
    "abstract": "Heterogeneous architectures featuring multiple hardware accelerators have been proposed as a promising solution for meeting the ever-increasing performance and power requirements of embedded systems. However, the existence of numerous design parameters may result in different architectural schemes and thus in extra design effort. To address this issue, OpenCL-based frameworks have been recently utilized for FPGA programming, to enable the portability of a source code to multiple architectures. However, such OpenCL frameworks focus on RTL design, thus not enabling rapid prototyping and abstracted modeling of complex systems. Virtual Prototyping aims to overcome this problem by enabling the system modeling in higher abstraction levels. This article combines the benefits of OpenCL and Virtual Prototyping, by proposing an OpenCL-based prototyping framework for data-parallel many-accelerator systems, which (a) creates a SystemC Virtual Platform from OpenCL, (b) provides a co-simulation environment for the host and the Virtual Platform, (c) offers memory and interconnection models for parallel data processing, and (d) enables the system evaluation with alternative real number representations (e.g., fixed-point or 16-bit floating-point).",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2894471651",
    "type": "article"
  },
  {
    "title": "GroupSense",
    "doi": "https://doi.org/10.1145/3295747",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Amin Abken; Seng W. Loke; Arkady Zaslavsky; Wenny Rahayu",
    "corresponding_authors": "",
    "abstract": "Human activity recognition using embedded mobile and embedded sensors is becoming increasingly important. Scaling up from individuals to groups, that is, Group Activity Recognition (GAR), has attracted significant attention recently. This article proposes a model and modeling language for GAR called GroupSense-L and a novel distributed middleware called GroupSense for mobile GAR. We implemented and tested GroupSense using smartphone sensors, smartwatch sensors, and embedded sensors in things, where we have a protocol for these different devices to exchange information required for GAR. A range of continuous group activities (from simple to fairly complex) illustrates our approach and demonstrates the feasibility of our model and richness of the proposed specialization. We then conclude with lessons learned for GAR and future work.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2909770857",
    "type": "article"
  },
  {
    "title": "Ensuring Secure Application Execution and Platform-Specific Execution in Embedded Devices",
    "doi": "https://doi.org/10.1145/3284361",
    "publication_date": "2019-04-02",
    "publication_year": 2019,
    "authors": "Robert P. Lee; Konstantinos Markantonakis; Raja Naeem Akram",
    "corresponding_authors": "",
    "abstract": "The Internet of Things (IoT) is expanding at a large rate, with devices found in commercial and domestic settings from industrial sensors to home appliances. However, as the IoT market grows, so does the number of attacks made against it with some reports claiming an increase of 600% in 2017. This work seeks to prevent code replacement, injection, and exploitation attacks by ensuring correct and platform specific application execution. This combines two previously studied problems: secure application execution and binding hardware and software. We present descriptions of both problems and requirements for ensuring both simultaneously. We then propose a scheme extending previous work that meets these requirements, and describe our implementation of the soft-core Secure Execution Processor developed and tested on Xilinx Spartan-6 FPGA. Finally, we analyse the scheme and our implementation according to performance and the requirements listed.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2930731635",
    "type": "article"
  },
  {
    "title": "A Task Failure Rate Aware Dual-Channel Solar Power System for Nonvolatile Sensor Nodes",
    "doi": "https://doi.org/10.1145/3320270",
    "publication_date": "2019-07-02",
    "publication_year": 2019,
    "authors": "Fang Su; Yongpan Liu; Sheng Xiao; Hyung Gyu Lee; Naehyuck Chang; Huazhong Yang",
    "corresponding_authors": "",
    "abstract": "In line with the rapid development of the Internet of Things (IoT), the maintenance of on-board batteries for a trillion sensor nodes has become prohibitive both in time and costs. Energy harvesting is a promising solution to this problem. However, conventional energy-harvesting systems with storage suffer from low efficiency because of conversion loss and storage leakage. Direct supply systems without energy buffer provide higher efficiency, but fail to satisfy quality of service (QoS) due to mismatches between input power and workloads. Recently, a novel dual-channel photovoltaic power system has paved the way to achieve both high energy efficiency and QoS guarantee. This article focuses on the design-time and run-time co-optimization of the dual-channel solar power system. At the design stage, we develop a task failure rate estimation framework to balance design costs and failure rate. At run-time, we propose a task failure rate aware QoS tuning algorithm to further enhance energy efficiency. Through the experiments on both a simulation platform and a prototype board, this study demonstrates a 27% task failure rate reduction compared with conventional architectures with identical design costs. And the proposed online QoS tuning algorithm brings up to 30% improvement in energy efficiency with nearly zero failure rate penalty.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2953723783",
    "type": "article"
  },
  {
    "title": "Code-Inherent Traffic Shaping for Hard Real-Time Systems",
    "doi": "https://doi.org/10.1145/3358215",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Dominic Oehlert; Selma Saidi; Heiko Falk",
    "corresponding_authors": "",
    "abstract": "Modern hard real-time systems evolved from isolated single-core architectures to complex multi-core architectures which are often connected in a distributed manner. With the increasing influence of interconnections in hard real-time systems, the access behavior to shared resources of single tasks or cores becomes a crucial factor for the system’s overall worst-case timing properties. Traffic shaping is a powerful technique to decrease contention in a network and deliver guarantees on network streams. In this paper we present a novel approach to automatically integrate a traffic shaping behavior into the code of a program for different traffic shaping profiles while being as least invasive as possible. As this approach is solely depending on modifying programs on a code-level, it does not rely on any additional hardware or operating system-based functions. We show how different traffic shaping profiles can be implemented into programs using a greedy heuristic and an evolutionary algorithm, as well as their influences on the modified programs. It is demonstrated that the presented approaches can be used to decrease worst-case execution times in multi-core systems and lower buffer requirements in distributed systems.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2979574741",
    "type": "article"
  },
  {
    "title": "Quality/Latency-Aware Real-time Scheduling of Distributed Streaming IoT Applications",
    "doi": "https://doi.org/10.1145/3358209",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Kamyar Mirzazad Barijough; Zhuoran Zhao; Andreas Gerstlauer",
    "corresponding_authors": "",
    "abstract": "Embedded systems are increasingly networked and distributed, often, such as in the Internet of Things (IoT), over open networks with potentially unbounded delays. A key challenge is the need for real-time guarantees over such inherently unreliable and unpredictable networks. Generally, timeouts are used to provide timing guarantees while trading off data losses and quality. The schedule of distributed task executions and network timeouts thereby determines a fundamental latency-quality trade-off that is, however, not taken into account by existing scheduling algorithms. In this paper, we propose an approach for scheduling of distributed, real-time streaming applications under quality-latency goals. We formulate this as a problem of analytically deriving a static worst-case schedule of a given distributed dataflow graph that minimizes quality loss while meeting guaranteed latency constraints. Towards this end, we first develop a quality model that estimates SNR of distributed streaming applications under given network characteristics and an overall linearity assumption. Using this quality model, we then formulate and solve the scheduling of distributed dataflow graphs as a numerical optimization problem. Simulation results with random graphs show that quality/latency-aware scheduling improves SNR over a baseline schedule by 50% on average. When applied to a distributed neural network application for handwritten digit recognition, our scheduling methodology can improve classification accuracy by 10% over a naive distribution under tight latency constraints.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2979830437",
    "type": "article"
  },
  {
    "title": "Blocking-Aware Partitioned Real-Time Scheduling for Uniform Heterogeneous Multicore Platforms",
    "doi": "https://doi.org/10.1145/3366683",
    "publication_date": "2020-01-31",
    "publication_year": 2020,
    "authors": "Jian-Jun Han; Sunlu Gong; Zhenjiang Wang; Wen Cai; Dakai Zhu; Laurence T. Yang",
    "corresponding_authors": "",
    "abstract": "Heterogeneous multicore processors have recently become de facto computing engines for state-of-the-art embedded applications. Nonetheless, very little research focuses on the scheduling of periodic (implicit-deadline) real-time tasks upon heterogeneous multicores under the requirements of task synchronization, which is stemmed from resource access conflicts and can greatly affect the schedulability of tasks. In view of partitioned Earliest Deadline First and Multiprocessor Stack Resource Policy, we first discuss the blocking-aware utilization bound for uniform heterogeneous multicores and then illustrate its non-monotonicity, where the bound may decrease with more deployed cores. Following the insights obtained from the bound analysis, taking the system heterogeneity into consideration, we propose a Synchronization-Aware Task Partitioning Algorithm for Heterogeneous Multicores (SA-TPA-HM)). Several resource-guided and heterogeneity-oriented mapping heuristics are incorporated to reduce the negative impacts of blocking interferences for better schedulability performance of tasks and balanced workload distribution across cores. The extensive simulation results show that SA-TPA-HM can obtain the schedulability ratios approximate to an Integer Non-Linear Programming--based solution, and much higher (e.g., 60% more) in contrast to the existing partitioning algorithms targeted at homogeneous multicores. The measurement results in Linux kernel further reveal the practical viability of SA-TPA-HM that can experience lower runtime overhead (e.g., 15% less) when compared to other mapping schemes.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3004790525",
    "type": "article"
  },
  {
    "title": "Network-level Design Space Exploration of Resource-constrained Networks-of-Systems",
    "doi": "https://doi.org/10.1145/3387918",
    "publication_date": "2020-06-21",
    "publication_year": 2020,
    "authors": "Zhuoran Zhao; Kamyar Mirzazad Barijough; Andreas Gerstlauer",
    "corresponding_authors": "",
    "abstract": "Driven by recent advances in networking and computing technologies, distributed application scenarios are increasingly deployed on resource-constrained processing platforms. This includes networked embedded and cyber-physical systems as well as edge computing in mobile applications and the Internet of Things (IoT). In such resource-constrained Networks-of-Systems (NoS), computation and communication workloads need to be carefully co-optimized yet are tightly coupled. How to optimally partition and schedule application tasks among an appropriately designed NoS architecture requires a simultaneous consideration of design parameters from applications and processing platforms all the way to network configurations. Traditionally, however, systems and networks are designed in isolation and combined in an ad hoc manner, which ignores joint effects and optimization opportunities. To systematically explore and optimize NoS design spaces, a higher level of design abstraction on top of traditional system and network design is required. In this article, we propose a novel network-level design methodology for resource-constrained NoS optimization and design space exploration. A key component in such a design flow is fast yet accurate network/system co-simulation to rapidly evaluate NoS parameters with high fidelity. We first introduce a novel NoS simulator (NoSSim) that integrates source-level simulation models of applications with a host-compiled system simulation platform and a reconfigurable network simulation backplane to accurately capture system and network interactions. The co-simulation platform is further combined with model generation tools and a multi-objective genetic search algorithm to provide a comprehensive and fully automated NoS design space exploration framework. Finally, we apply our network-level design flow on several state-of-art IoT/mobile design case studies. Results show that NoSSim can achieve more than 86% simulation accuracy on average as compared to a real-world edge device cluster, where sensitivities to various design parameters are faithfully captured with high fidelity. When applying our network-level design space exploration methodology, design decisions are automatically optimized, where non-obvious NoS configurations are discovered outperforming manually designed solutions by more than 45%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3008754456",
    "type": "article"
  },
  {
    "title": "Formal Verification of Spacecraft Control Programs",
    "doi": "https://doi.org/10.1145/3391900",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Georgy Lukyanov; Andrey Mokhov; Jakob Lechner",
    "corresponding_authors": "",
    "abstract": "Verification of correctness of control programs is an essential task in the development of space electronics; it is difficult and typically outweighs design and programming tasks in terms of development hours. This article presents a verification approach designed to help spacecraft engineers reduce the effort required for formal verification of low-level control programs executed on custom hardware. The verification approach is demonstrated on an industrial case study. We present a REDuced instruction set for Fixed-point and INteger arithmetic (REDFIN), a processing core used in space missions, and its formal semantics expressed using the proposed metalanguage for state transformers, followed by examples of verification of simple control programs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3033746640",
    "type": "article"
  },
  {
    "title": "Exploring Impact of Profile Data on Code Quality in the HotSpot JVM",
    "doi": "https://doi.org/10.1145/3391894",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "April W. Wade; Prasad A. Kulkarni; Michael R. Jantz",
    "corresponding_authors": "",
    "abstract": "Managed language virtual machines (VM) rely on dynamic or just-in-time (JIT) compilation to generate optimized native code at run-time to deliver high execution performance. Many VMs and JIT compilers collect profile data at run-time to enable profile-guided optimizations (PGO) that customize the generated native code to different program inputs. PGOs are generally considered integral for VMs to produce high-quality and performant native code. In this work, we study and quantify the performance benefits of PGOs, understand the importance of profiling data quantity and quality/accuracy to effectively guide PGOs, and assess the impact of individual PGOs on VM performance. The insights obtained from this work can be used to understand the current state of PGOs, develop strategies to more efficiently balance the cost and exploit the potential of PGOs, and explore the implications of and challenges for the alternative ahead-of-time (AOT) compilation model used by VMs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3040941732",
    "type": "article"
  },
  {
    "title": "Optimizing Tensor Contractions for Embedded Devices with Racetrack and DRAM Memories",
    "doi": "https://doi.org/10.1145/3396235",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Asif Ali Khan; Norman A. Rink; Fazal Hameed; Jerónimo Castrillón",
    "corresponding_authors": "",
    "abstract": "Tensor contraction is a fundamental operation in many algorithms with a plethora of applications ranging from quantum chemistry over fluid dynamics and image processing to machine learning. The performance of tensor computations critically depends on the efficient utilization of on-chip/off-chip memories. In the context of low-power embedded devices, efficient management of the memory space becomes even more crucial, in order to meet energy constraints. This work aims at investigating strategies for performance- and energy-efficient tensor contractions on embedded systems, using racetrack memory (RTM)-based scratch-pad memory (SPM) and DRAM-based off-chip memory. Compiler optimizations such as the loop access order and data layout transformations paired with architectural optimizations such as prefetching and preshifting are employed to reduce the shifting overhead in RTMs. Optimizations for off-chip memory such as memory access order, data mapping and the choice of a suitable memory access granularity are employed to reduce the contention in the off-chip memory. Experimental results demonstrate that the proposed optimizations improve the SPM performance and energy consumption by 32% and 73%, respectively, compared to an iso-capacity SRAM. The overall DRAM dynamic energy consumption improvements due to memory optimizations amount to 80%.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3041117144",
    "type": "article"
  },
  {
    "title": "RVSDG",
    "doi": "https://doi.org/10.1145/3391902",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Nico Reißmann; Jan Christian Meyer; Helge Bahmann; Magnus Själander",
    "corresponding_authors": "",
    "abstract": "Intermediate Representations (IRs) are central to optimizing compilers as the way the program is represented may enhance or limit analyses and transformations. Suitable IRs focus on exposing the most relevant information and establish invariants that different compiler passes can rely on. While control-flow centric IRs appear to be a natural fit for imperative programming languages, analyses required by compilers have increasingly shifted to understand data dependencies and work at multiple abstraction layers at the same time. This is partially evidenced in recent developments such as the Multi-Level Intermediate Representation (MLIR) proposed by Google. However, rigorous use of data flow centric IRs in general purpose compilers has not been evaluated for feasibility and usability as previous works provide no practical implementations. We present the Regionalized Value State Dependence Graph (RVSDG) IR for optimizing compilers. The RVSDG is a data flow centric IR where nodes represent computations, edges represent computational dependencies, and regions capture the hierarchical structure of programs. It represents programs in demand-dependence form, implicitly supports structured control flow, and models entire programs within a single IR. We provide a complete specification of the RVSDG, construction and destruction methods, as well as exemplify its utility by presenting Dead Node and Common Node Elimination optimizations. We implemented a prototype compiler and evaluate it in terms of performance, code size, compilation time, and representational overhead. Our results indicate that the RVSDG can serve as a competitive IR in optimizing compilers while reducing complexity.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3041574905",
    "type": "article"
  },
  {
    "title": "Experiences with context management in emergency medicine",
    "doi": "https://doi.org/10.1145/2485984.2485988",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Rita H. Wouhaybi; Mark Yarvis; Sangita Sharma; Philip Muse; Chieh‐Yih Wan; S. K. Prasad; Lenitra Durham; Ritu Sahni; Robert L. Norton; Merlin Curry; Holly Jimison; R.J. Harper; Robert A. Lowe",
    "corresponding_authors": "",
    "abstract": "In emergency medicine, patient care is intense and stressful, often requiring paramedics to consult with remote physicians to convey the patient's condition. We present a framework for context-management in telemedicine developed in collaboration between engineers, physicians, and paramedics. We describe a mobile platform and embedded wireless sensors to capture physiological and audio context into a comprehensive patient record, accessible locally and remotely. We describe a first evaluation of this technology by trained paramedics in simulated scenarios and evaluate key aspects of system performance. Early results suggest that wireless sensing can provide reliable and low latency data both locally and to remote physicians. In addition, audio context capture is a promising approach to capturing a comprehensive patient record, with a low rate of medically important errors.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1963898566",
    "type": "article"
  },
  {
    "title": "L24",
    "doi": "https://doi.org/10.1145/2512465",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Phillip Stanley‐Marbell",
    "corresponding_authors": "Phillip Stanley‐Marbell",
    "abstract": "Networks of sensors must process large amounts of intermittently-available data in situ. This motivates the investigation of means for achieving high performance when required, but ultra-low-power dissipation when idle. One approach to this challenge is the use of embedded multiprocessor systems, leading to trade-offs between parallelism, performance, energy efficiency, and cost. To evaluate these trade-offs and to gain insight for future system designs, this article presents the design, implementation, and evaluation of a miniature, energy-scalable, 24-processor module, L24 , for use in embedded sensor systems. Analytic results and empirical evidence motivating such embedded multiprocessors is provided, and a parallel fixed-point fast Fourier transform implementation is presented. This application is used as a challenging but realistic evaluator of the presented hardware platform. Through a combination of hardware measurements, instruction-level microarchitectural simulation, and analytic modeling, it is demonstrated that the platform provides idle power dissipation over an order of magnitude lower than systems employing a monolithic processor of equivalent performance, while dynamic power dissipation remains competitive. Taking into account both application computation and interprocessor communication demands, it is shown that there may exist an optimum operating voltage that minimizes either time-to-solution, energy usage, or the energy-delay product. This optimum operating point is formulated analytically, calibrated with system measurements, and evaluated for the hardware platform and application presented.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1974035733",
    "type": "article"
  },
  {
    "title": "High-performance and low-energy buffer mapping method for multiprocessor DSP systems",
    "doi": "https://doi.org/10.1145/2442116.2442132",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Dongwon Lee; Marilyn Wolf; Shuvra S. Bhattacharyya",
    "corresponding_authors": "",
    "abstract": "When implementing digital signal processing (DSP) applications onto multiprocessor systems, one significant problem in the viewpoints of performance is the memory wall. In this paper, to help alleviate the memory wall problem, we propose a novel, high-performance buffer mapping policy for SDF-represented DSP applications on bus-based multiprocessor systems that support the shared-memory programming model. The proposed policy exploits the bank concurrency of the DRAM main memory system according to the analysis of hierarchical parallelism. Energy consumption is also a critical parameter, especially in battery-based embedded computing systems. In this paper, we apply a synchronization back-off scheme on the top of the proposed high-performance buffer mapping policy to reduce energy consumption. The energy saving is attained by minimizing the number of non-essential synchronization transactions. We measure throughput and energy consumption on both synthetic and real benchmarks. The simulation results show that the proposed buffer mapping policy is very useful in terms of performance, especially in memory-intensive applications where the total execution time of computational tasks is relatively small compared to that of memory operations. In addition, the proposed synchronization back-off scheme provides a reduction in the number of synchronization transactions without degrading performance, which results in system energy saving.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1977891035",
    "type": "article"
  },
  {
    "title": "Modeling and Analyzing Dataflow Applications on NoC-Based Many-Core Architectures",
    "doi": "https://doi.org/10.1145/2700081",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Jean-Vivien Millo; Émilien Kofman; Robert de Simone",
    "corresponding_authors": "",
    "abstract": "The advent of chip-level parallel architectures prompted a renewal of interest into dataflow process networks. The trend is to model an application independently from the architecture, then the model is morphed to best fit the target architecture. One downplayed aspect is the mapping of communications through the on-chip topology. The cost of such communications is often prevalent with regard to computations. This article establishes a dataflow process network called K-periodically Routed Graph (KRG), which serves the role of representing the various routing decisions during the transformation of a genuine application into a architecture-aware version for this application.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1983196862",
    "type": "article"
  },
  {
    "title": "The benefits of using variable-length pipelined operations in high-level synthesis",
    "doi": "https://doi.org/10.1145/2539036.2539048",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Yosi Ben-Asher; Nadav Rotem",
    "corresponding_authors": "",
    "abstract": "Current high-level synthesis systems synthesize arithmetic units of a fixed known number of stages, and the scheduler mainly determines when units are activated. We focus on scheduling techniques for the high-level synthesis of pipelined arithmetic units where the number of stages of these operations is a free parameter of the synthesis. This problem is motivated by the ability to automatically create pipelined functional units, such as multipliers, with different pipe lengths. These units have different characteristics in terms of parallelism level, clock latency, frequency, etc. This article presents the Variable-length Pipeline Scheduler (VPS). The ability to synthesize variable-length pipelined units expands the known scheduling problem of high-level synthesis to include a search for a minimal number of hardware units (operations) and their desired number of stages. The proposed search procedure is based on algorithms that find a local minima in a d -dimensional grid, thus avoiding the need to evaluate all possible points in the space. We have implemented a C language compiler for VPS targeting FPGAs. Our results demonstrate that using variable-length pipeline units can reduce the overall resource usage and improve the execution time when synthesized onto an FPGA. The proposed search is sufficiently fast, taking only a few seconds, allowing an interactive mode of work. A comparison with xPilot shows a significant saving of hardware resources while maintaining comparable execution times of the resulting circuits. This work is an extension of a previous paper [Ben-Asher and Rotem 2008]",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1984950360",
    "type": "article"
  },
  {
    "title": "A systematic approach for optimized bypass configurations for application-specific embedded processors",
    "doi": "https://doi.org/10.1145/2514641.2514645",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Thorsten Jungeblut; Boris Hübener; Mario Porrmann; Ulrich Rückert",
    "corresponding_authors": "",
    "abstract": "The diversity of today's mobile applications requires embedded processor cores with a high resource efficiency, that means, the devices should provide a high performance at low area requirements and power consumption. The fine-grained parallelism supported by multiple functional units of VLIW architectures offers a high throughput at reasonable low clock frequencies compared to single-core RISC processors. To efficiently utilize the processor pipeline, common system architectures have to cope with data hazards due to data dependencies between consecutive operations. On the one hand, such hazards can be resolved by complex forwarding circuits (i.e., a pipeline bypass) which forward intermediate results to a subsequent instruction. On the other hand, the pipeline bypass can strongly affect or even dominate the total resource requirements and degrade the maximum clock frequency. In this work the CoreVA VLIW architecture is used for the development and the analysis of application-specific bypass configurations. It is shown that many paths of a comprehensive bypass system are rarely used and may not be required for certain applications. For this reason, several strategies have been implemented to enhance the efficiency of the total system by introducing application-specific bypass configurations. The configuration can be carried out statically by only implementing required paths or at runtime by dynamically reconfiguring the hardware. An algorithm is proposed which derives an optimized configuration by iteratively disabling single bypass paths. The adaptation of these application-specific bypass configurations allows for a reduction of the critical path by 26%. As a result, the execution time and energy requirements could be reduced by up to 21.5%. Using Dynamic Frequency Scaling (DFS) and dynamic deactivation/reactivation of bypass paths allows for a runtime reconfiguration of the bypass system. This ensures the highest efficiency while processing varying applications.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1987324743",
    "type": "article"
  },
  {
    "title": "PAIS",
    "doi": "https://doi.org/10.1145/2567934",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Yuho Jin; Timothy M. Pinkston",
    "corresponding_authors": "",
    "abstract": "Multicore processors have the potential to deliver scalable performance by distributing computation across multiple cores. However, the communication cost of parallel application thread execution may significantly limit the performance achievable due to latency and contention on shared resources in the on-chip network of multicores experienced by packets from critical threads. We present PAIS, Parallelism-Aware Interconnect Scheduling, that bolsters performance and energy efficiency of parallel applications. PAIS dynamically detects thread execution progress based on communication latency and scheduling, and it accelerates communication for slowly executing threads by prioritizing packets from those threads with flow control and priority-based arbitration.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1988656518",
    "type": "article"
  },
  {
    "title": "A low-power instruction replay mechanism for design of resilient microprocessors",
    "doi": "https://doi.org/10.1145/2560034",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Rance Rodrigues; Arunachalam Annamalai; Sandip Kundu",
    "corresponding_authors": "",
    "abstract": "There is a growing concern about the increasing rate of defects in computing substrates. Traditional redundancy solutions prove to be too expensive for commodity microprocessor systems. Modern microprocessors feature multiple execution units to take advantage of instruction level parallelism. However, most workloads do not exhibit the level of instruction level parallelism that a typical microprocessor is resourced for. This offers an opportunity to reexecute instructions using idle execution units. But, relying solely on idle resources will not provide full instruction coverage and there is a need to explore other alternatives. To that end, we propose and evaluate two instruction replay schemes within the same core for online testing of the execution units. One scheme (RER) reexecutes only the retired instructions, while the other (REI) reexecutes all the issued instructions. The complete proposed solution requires a comparator and minor modifications to control logic, resulting in negligible hardware overhead. Both soft and hard error detection are considered and the performance and energy impact of both schemes are evaluated and compared against previously proposed redundant execution schemes. Results show that even though the proposed schemes result in a small performance penalty when compared to previous work, the energy overhead is significantly reduced.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1990319673",
    "type": "article"
  },
  {
    "title": "Worst-case guarantees on a processor with temperature-based feedback control of speed",
    "doi": "https://doi.org/10.1145/2584611",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Pratyush Kumar; Lothar Thiele",
    "corresponding_authors": "",
    "abstract": "On-chip temperatures continue to rise, in spite of design efforts towards more efficient cooling and novel low-power technologies. Run-time thermal management techniques, such as speed scaling and system throttling, constitute a standard component in today's processors. One such technique is the feedback control of the processing speed based on the on-chip temperature. If suitably designed, such a controller can ensure that the temperature of the processor does not exceed a given bound, independent of the application. Such isolation of needs is encouraging. However, from the application's stand-point, such a processor must provide performance guarantees; in particular, the guarantee that real-time jobs do not have worst-case delays larger than their relative deadlines. For applications which exhibit variability, such as bursty arrival patterns, computing such guarantees is not apparent. As key enablers in such a computation, for the specific setting of First-Come-First-Serve (FCFS) scheduling, we (a) define and prove a monotonicity principle satisfied by the processor with the said controller, and (b) propose a thermally clipped processor model. We identify the worst-case trace simulating which on a suitably chosen thermally clipped processor provides the tight upper-bound on the worst-case delay. These results hold for general models of (a) the power consumption of the processor, (b) its thermal model, (c) the speed scaling law, and (d) the task model. For this modelling scope, we show that the same worst-case trace also leads to the worst-case temperature of the processor. This is useful to characterise tasks which do not load the processor sufficiently to hit the given peak temperature bound. We demonstrate the utility of this calculation by designing a shaper to delay the arrival times of jobs and thereby restrict the observed worst-case temperature while still meeting the task's deadlines.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1996702472",
    "type": "article"
  },
  {
    "title": "Energy- and Thermal-Aware Video Coding via Encoder/Decoder Workload Balancing",
    "doi": "https://doi.org/10.1145/2465787.2465798",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Domenic Forte; Ankur Srivastava",
    "corresponding_authors": "",
    "abstract": "Video coding and compression are essential components of multimedia services but are known to be computationally intensive and energy demanding. Traditional video coding paradigms, predictive and distributed video coding (PVC and DVC), result in excessive computation at either the encoder (PVC) or decoder (DVC). Several recent papers have proposed a hybrid PVC/DVC codec which shares the video coding workload between encoder and decoder. In this article, we propose a controller for such hybrid coders that considers energy and temperature to dynamically split the coding workload of a system comprised of one encoder and one decoder. We also present two heuristic algorithms for determining safe operating temperatures in the controller solution: (1) stable state thermal modeling algorithm, which focuses on long term temperatures, and (2) transient thermal modeling algorithm, which is better for short-term thermal behavior. Results show that the proposed algorithms result in more balanced energy utilization, improve overall system lifetime, and reduce operating temperatures when compared to strictly PVC and DVC systems.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1998534147",
    "type": "article"
  },
  {
    "title": "Introduction for Embedded Platforms for Cryptography in the Coming Decade",
    "doi": "https://doi.org/10.1145/2745710",
    "publication_date": "2015-04-21",
    "publication_year": 2015,
    "authors": "Patrick Schaumont; Máire O’Neill; Tim Güneysu",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Introduction for Embedded Platforms for Cryptography in the Coming Decade Editors: Patrick Schaumont Virginia Tech, USA Virginia Tech, USAView Profile , Maire O'Neill Queen's University Belfast, United Kingdom Queen's University Belfast, United KingdomView Profile , Tim Güneysu Ruhr University Bochum, Germany Ruhr University Bochum, GermanyView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 14Issue 3May 2015 Article No.: 40pp 1–3https://doi.org/10.1145/2745710Published:21 April 2015Publication History 2citation284DownloadsMetricsTotal Citations2Total Downloads284Last 12 Months15Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2001342385",
    "type": "article"
  },
  {
    "title": "Enabling power efficiency through dynamic rerouting on-chip",
    "doi": "https://doi.org/10.1145/2485984.2485999",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Frank Olaf Sem-Jacobsen; Samuel Rodrigo; Alessandro Strano; Tor Skeie; Davide Bertozzi; Francisco Jurado Gilabert",
    "corresponding_authors": "",
    "abstract": "Networks-on-chip (NoCs) are key components in many-core chip designs. Dynamic power-awareness is a new challenge present in NoCs that must be efficiently handled by the routing functionality as it introduces irregularities in the commonly used 2-D meshes. In this article, we propose a logic-based routing algorithm, iFDOR, oriented towards dynamic powering down one region within every application partition on the chip through dynamic rerouting, with low implementation costs. Results show that we can successfully shutdown an arbitrary rectangular region within an application partition without significant impact on network performance.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2002547729",
    "type": "article"
  },
  {
    "title": "Dynamic task partition for video decoding on heterogeneous dual-core platforms",
    "doi": "https://doi.org/10.1145/2435227.2435249",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Chun-Jen Tsai; Tsung-Fan Shen; Pei-Ching Liao",
    "corresponding_authors": "",
    "abstract": "This article presents the design of a video decoder using dynamic task partition approach on a heterogeneous dual-core embedded platform. For such systems, static task partition between the two cores at design time is a typical approach for application development. In this article, we propose a runtime dynamic task partition model and implement an MPEG-4 Simple Profile video decoder using this approach on a TI OMAP 5912 platform. Comparing with a traditional mobile video decoder optimized for the same DSP core, the performance gain from dynamic task partition is 38.4% on average. More importantly, the gain is achieved with the design constraint that the implementation effort for the dynamic task partition decoder is about the same as the effort using design-time task partition model. Unlike common belief that the inter-processor communication overhead would be too high to justify intense cooperation between two heterogeneous cores, this paper shows that it is indeed beneficial to adopt dynamic task partition model on commercially available heterogeneous multi-core platforms.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2020528055",
    "type": "article"
  },
  {
    "title": "Accelerating radiation dose calculation",
    "doi": "https://doi.org/10.1145/2536747.2536755",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Bo Zhou; Xiaobo Sharon Hu; Danny Z. Chen; C Yu",
    "corresponding_authors": "",
    "abstract": "Remarkable progress has been made in the past few decades in various aspects of radiation therapy (RT). However, some of these promising technologies, such as image-guided online replanning and arc therapy, rely heavily on the availability of fast dose calculation. In this article, based on a popular dose calculation algorithm, the Collapsed-Cone Convolution/Superposition (CCCS) algorithm, we present a multi-FPGA accelerator to speed up radiation dose calculation. Our performance-driven design strategy yields a fully pipelined architecture, which includes a resource-economic raytracing engine and high-performance energy deposition pipeline. An evaluation based on a set of clinical treatment planning cases confirms that our FPGA design almost fully utilizes the available external memory bandwidth and achieves close to the best possible performance for the CCCS algorithm while using less resource. Compared with an existing FPGA design which aimed to accelerate the identical algorithm, the proposed design achieved 1.9X speedup by providing better memory bandwidth utilization (81.7% v.s. 43% of the available external memory bandwidth), higher working frequency (90MHz v.s. 70MHz) and less logic resource usage (25K v.s. 55K logic cells). Furthermore, it obtains a speedup of 20X over a commercial multithreaded software on a quad-core system and 15X performance improvement over closely related results. In terms of accuracy, the measured less than 1% statistical fluctuation indicates that our solution is practical in real medical scenarios.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2036046367",
    "type": "article"
  },
  {
    "title": "MultiMaKe",
    "doi": "https://doi.org/10.1145/2435227.2435255",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Luis Angel D. Bathen; Yongjin Ahn; Sudeep Pasricha; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "The increasing demand for low-power and high-performance multimedia embedded systems has motivated the need for effective solutions to satisfy application bandwidth and latency requirements under a tight power budget. As technology scales, it is imperative that applications are optimized to take full advantage of the underlying resources and meet both power and performance requirements. We propose MultiMaKe, an application mapping design flow capable of discovering and enabling parallelism opportunities via code transformations, efficiently distributing the computational load across resources, and minimizing unnecessary data transfers. Our approach decomposes the application's tasks into smaller units of computations called kernels, which are distributed and pipelined across the different processing resources. We exploit the ideas of inter-kernel data reuse to minimize unnecessary data transfers between kernels, early execution edges to drive performance, and kernel pipelining to increase system throughput. Our experimental results on JPEG and JPEG2000 show up to 97% off-chip memory access reduction, and up to 80% execution time reduction over standard mapping and task-level pipelining approaches.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2042647384",
    "type": "article"
  },
  {
    "title": "Exploring demand flexibility in heterogeneous aggregators",
    "doi": "https://doi.org/10.1145/2544375.2544377",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Chenye Wu; Yiyu Shi; Soummya Kar",
    "corresponding_authors": "",
    "abstract": "With the proposed penetration of electric vehicles and advanced metering technology, the demand side is foreseen to play a major role in flexible energy consumption scheduling. On the other hand, the past several years have witnessed utility companies' growing interests to integrate more renewable energy resources. These renewable resources, for example, wind or solar, due to their intermittent nature, brought great uncertainty to the power grid system. In this article, we propose a mechanism that attempts to mitigate the grid operational uncertainty induced by renewable energies by properly exploiting demand flexibility with the help of advanced smart-metering technology. To address the challenge, we develop a novel locational marginal price (LMP)-based pricing scheme that involves active demand-side participation by casting the network objective as a two-stage Stackelberg game between the local grid operator and several aggregators. In contrast to the conventional notion that generation follows load, our game formulation provides more flexibility for the operators and tries to provide adequate incentives for the loads to follow the (stochastic renewable) generation. We use the solution concept of subgame perfect equilibrium to analyze the resulting game. Subsequently, we discuss the optimal real-time conventional capacity planning for the local grid operator to achieve the minimal mismatch between supply and demand with the wind power integration. Finally, we assess our proposed scheme with field data. The simulation results show that our proposed scheme works reasonably well in the long term, even with simple heuristics.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2045358068",
    "type": "article"
  },
  {
    "title": "Does the Sharing of Execution Units Improve Performance/Power of Multicores?",
    "doi": "https://doi.org/10.1145/2680543",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Rance Rodrigues; Israel Koren; Sandip Kundu",
    "corresponding_authors": "",
    "abstract": "Several studies and recent real-world designs have promoted sharing of underutilized resources between cores in a multicore processor to achieve better performance/power. It has been argued that when utilization of such resources is low, sharing has a negligible impact on performance while offering considerable area and power benefits. In this article, we investigate the performance and performance/watt implications of sharing large and underutilized resources between pairs of cores in a multicore. We first study sharing of the entire floating-point datapath (including reservation stations and execution units) by two cores, similar to AMD’s Bulldozer. We find that while this architecture results in power savings for certain workload combinations, it also results in significant performance loss of up to 28%. Next, we study an alternative sharing architecture where only the floating-point execution units are shared, while the individual cores retain their reservation stations. This reduces the highest performance loss to 14%. We then extend the study to include sharing of other large execution units that are used infrequently, namely, the integer multiply and divide units. Subsequently, we analyze the impact of sharing hardware resources in Simultaneously Multithreaded (SMT) processors where multiple threads run concurrently on the same core. We observe that sharing improves performance/watt at a negligible performance cost only if the shared units have high throughput. Sharing low-throughput units reduces both performance and performance/watt. To increase the throughput of the shared units, we propose the use of Dynamic Voltage and Frequency Boosting (DVFB) of only the shared units that can be placed on a separate voltage island. Our results indicate that the use of DVFB improves both performance and performance/watt by as much as 22% and 10%, respectively.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2045466259",
    "type": "article"
  },
  {
    "title": "DLIC",
    "doi": "https://doi.org/10.1145/2512464",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Ji Gu; Hui Guo; Tohru Ishihara",
    "corresponding_authors": "",
    "abstract": "With the explosive proliferation of embedded systems, especially through countless portable devices and wireless equipment used, embedded systems have become indispensable to the modern society and people's life. Those devices are often battery driven. Therefore, low energy consumption in embedded processors is important and becomes critical in step with the system complexity. The on-chip instruction cache (I-cache) is usually the most energy-consuming component on the processor chip due to its large size and frequent access operations. To reduce such energy consumption, the existing loop cache approaches use a tiny decoded cache to filter the I-cache access and instruction decode activity for repeated loop iterations. However, such designs are effective for small and simple loops, and only suitable for DSP kernel-like applications. They are not effectual for many embedded applications where complex loops are common. In this article, we propose a decoded loop instruction cache (DLIC) that is small, hence energy efficient, yet can capture most loops, including large nested ones with branch executions, so that a significant amount of I-cache accesses and instruction decoding can be eradicated. The experiments on a set of embedded benchmarks show that our proposed DLIC scheme can reduce energy consumption by up to 87% as compared to normal cache-only design. On average, 66% energy can be saved on instruction fetching and decoding, while at a performance overhead of only 1.4%.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2059418619",
    "type": "article"
  },
  {
    "title": "Contextual partitioning for speech recognition",
    "doi": "https://doi.org/10.1145/2501626.2501639",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Christopher Grant Kent; JoAnn M. Paul",
    "corresponding_authors": "",
    "abstract": "Many multicore computers are single-user devices, creating the potential to partition by situational usage contexts, similar to how the human brain is organized. Contextual partitioning (CP) permits multiple simplified versions of the same task to exist in parallel, with selection tied to the context in use. We introduce CP for speech recognition, specifically targeted at user interfaces in handheld embedded devices. Contexts are drawn from webpage interactions. CP results in 61% fewer decoding errors, 97% less training for vocabulary changes, near-linear scaling potential with increasing core counts, and up to a potential 90% reduction in power usage.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2059656888",
    "type": "article"
  },
  {
    "title": "Predictable and configurable component-based scheduling in the C <scp>omposite</scp> OS",
    "doi": "https://doi.org/10.1145/2536747.2536754",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Gabriel Parmer; Richard West",
    "corresponding_authors": "",
    "abstract": "This article presents the design of user-level scheduling hierarchies in the C omposite component-based system. The motivation for this is centered around the design of a system that is both dependable and predictable, and which is configurable to the needs of specific applications. Untrusted application developers can safely develop services and policies, that are isolated in protection domains outside the kernel. To ensure predictability, C omposite enforces timing control over user-space services. Moreover, it must provide a means by which asynchronous events, such as interrupts, are handled in a timely manner without jeopardizing the system. Towards this end, we describe the features of C omposite that allow user-defined scheduling policies to be composed for the purposes of combined interrupt and task management. A significant challenge arises from the need to synchronize access to shared data structures (e.g., scheduling queues), without allowing untrusted code to disable interrupts. Additionally, efficient upcall mechanisms are needed to deliver asynchronous event notifications in accordance with policy-specific priorities, without undue recourse to schedulers. We show how these issues are addressed in C omposite , by comparing several hierarchies of scheduling polices, to manage both tasks and the interrupts on which they depend. Studies show how it is possible to implement guaranteed differentiated services as part of the handling of I/O requests from a network device while diminishing livelock. Microbenchmarks indicate that the costs of implementing and invoking user-level schedulers in C omposite are on par with, or less than, those in other systems, with thread switches more than twice as fast as in Linux.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2090840864",
    "type": "article"
  },
  {
    "title": "Automatic generation of high-speed accurate TLM models for out-of-order pipelined bus",
    "doi": "https://doi.org/10.1145/2536747.2536759",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Chen-Kang Lo; Mao‐Lin Li; Li-Chun Chen; Yi-Shan Lu; Ren‐Song Tsay; Hsu-Yao Huang; Jen-Chieh Yeh",
    "corresponding_authors": "",
    "abstract": "Although pipelined/out-of-order (PL/OO) execution features are commonly supported by the state-of-the-art bus designs, no existing manual Transaction-Level-Modeling (TLM) approaches can effectively construct fast and accurate simulation models for PL/OO buses. Mainly, the inherent high design complexity of concurrent PL/OO behaviors makes the manual approaches tedious and error-prone. To tackle the complicated modeling task, this article presents an automatic approach that performs systematic abstraction and generation of fast-and-accurate simulation models. The experimental results show that our approach reduces 21 times modeling efforts, while our generated models perform simulation an order of magnitude faster than Cycle-Accurate models with the same PL/OO transaction execution cycle counts preserved.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2118865988",
    "type": "article"
  },
  {
    "title": "Gana",
    "doi": "https://doi.org/10.1145/2485984.2485997",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Eitan Zahavi; Israel Cidon; Avinoam Kolodny",
    "corresponding_authors": "",
    "abstract": "Similar to off-chip networks, current NoC architectures are based on the store and forward of uncoordinated end-to-end packet transmissions through autonomous buffered routers. However, the monolithic nature and the small physical dimensions of on chip networks open up the opportunity for much more tightly controlled architectures. We present GANA, a new Global Arbiter NoC Architecture. In GANA, the transmission of end-to-end data is timed by a global arbiter in a way that avoids any queuing in the network. The arbitration takes into account the complete transfer of the end-to-end packets through the entire network path, avoiding any intermediate queuing and hop-by-hop packet arbitration. Consequently, buffers and arbiters are no longer required in the routers, resulting in smaller area and low power consumption. It is demonstrated through detailed design and synthesis that the additional area of the central arbiter and the control path are negligible in comparison to the provided area saving. For example, an 8× 8 GANA consumes only 16% of the area of an equivalent autonomous NoC while providing a better end-to-end throughput. The end-to-end performance of GANA at high network loads is typically much better than in a distributed-control NOC, because resource contention and queuing in the network are avoided. This comes at the cost of a few percentage increase in latency at light loads due to the additional arbitration phase. GANA architecture combines the inherent benefits of a network (parallelism and spatial reuse of links) with the inherent benefits of high integration (global view of the system state, central control, and synchronization). The scalability of GANA is evaluated analytically, showing that it can be superior to fully-distributed networks in systems up to a size of about 100 modules manufactured in 45nm technology, which can be used today as well as in the foreseeable future.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2127260923",
    "type": "article"
  },
  {
    "title": "Providing reliable and real-time delivery in the presence of body shadowing in breadcrumb systems",
    "doi": "https://doi.org/10.1145/2557633",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Hengchang Liu; Pan Hui; Zhiheng Xie; Jingyuan Li; David Siu; Gang Zhou; Liusheng Huang; John A. Stankovic",
    "corresponding_authors": "",
    "abstract": "The primary goal of breadcrumb trail sensor networks is to transmit in real-time users' physiological parameters that measure life-critical functions to an incident commander through reliable multihop communication. In applications using breadcrumb solutions, there are often many users working together, and this creates a well-known body shadowing effect (BSE). In this article, we first measure the characteristics of body shadowing for 2.4GHz sensor nodes. Our empirical results show that the body shadowing effect leads to severe packet loss and consequently very poor real-time performance. Then we develop a novel Intentional Forwarding solution. This solution accurately detects the shadowing mode and enables selected neighbors to forward data packets. Experimental results from a fully implemented testbed demonstrate that Intentional Forwarding is able to improve the end-to-end average packet delivery ratio (PDR) from 58% to 93% and worst-case PDR from 45% to 85%, and is able to meet soft real-time requirements even under severe body shadowing problems.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2137077073",
    "type": "article"
  },
  {
    "title": "Adaptive scheduling of real-time systems cosupplied by renewable and nonrenewable energy sources",
    "doi": "https://doi.org/10.1145/2536747.2536758",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Morteza Mohaqeqi; Mehdi Kargahi; Maryam Dehghan",
    "corresponding_authors": "",
    "abstract": "Energy management is an important issue in today's real-time systems due to the high costs of energy supplying. Using renewable, like wave, wind, and solar energy sources seem promising methods to address this issue. However, because of the existing contrast between the critical nature of hard real-time systems and the unpredictable nature of renewable energies, some supplementary energy source like electricity grid or battery is needed. In this paper, we consider hard real-time systems with two renewable and nonrenewable energy sources. In order to reduce the costs, we present two dynamic voltage scaling controllers to minimize the energy attained from the latter source. In order to handle variations of the environmental energy and workload, the model predictive control approach is employed. One nonlinear approach beside one fast linear piecewise affine explicit controller are proposed. The efficacies of the proposed approaches have been investigated through extensive simulations. Comparisons to an ideal clairvoyant controller as a baseline show that, in the studied scenarios, the proposed controllers guarantee at least 78% of the baseline performance.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2141695926",
    "type": "article"
  },
  {
    "title": "Design of a High-Performance CDMA-Based Broadcast-Free Photonic Multi-Core Network on Chip",
    "doi": "https://doi.org/10.1145/2839301",
    "publication_date": "2016-01-13",
    "publication_year": 2016,
    "authors": "Soumyajit Poddar; Prasun Ghosal; Hafizur Rahaman",
    "corresponding_authors": "",
    "abstract": "Present-day focus on multicore research has not only increased computing power but also power- and bandwidth-efficient communication among cores. On-chip communication networks have become popular today because of their low energy use and modular structure compared to bus-based interconnects. Silicon photonics has further boosted the performance of on-chip interconnection networks with its low energy-delay product and high reliability. In current multicore Network-on-Chip (NoC) architectures, photonics is playing an important role in transferring large volumes of data both on- and off-chip. The problem addressed in this work is the issue of broadcast traffic arising due to invalidation requests from on-chip cache memories. Although such traffic is typically less than 1% of total traffic, it can easily present a high load on network resources, creating congestion and degrading performance. In this article, we propose a CDMA-based, secure, scalable, and energy-efficient technique to eliminate broadcast invalidations and increase overall performance. Experimental results indicate a performance boost up to 22.2% over a competing Photonic NoC and up to 57.4% over Electrical Mesh-based NoC when the proposed technique is used. Additional hardware deployed has an area overhead of less than 1%, whereas total energy consumed is at par with other state-of-the-art techniques.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2235780347",
    "type": "article"
  },
  {
    "title": "RQNoC",
    "doi": "https://doi.org/10.1145/2846097",
    "publication_date": "2016-02-17",
    "publication_year": 2016,
    "authors": "Alirad Malek; Ioannis Sourdis; Stavros Tzilis; Yifan He; Gerard Rauwerda",
    "corresponding_authors": "",
    "abstract": "In this article, we describe RQNoC, a service-oriented Network-on-Chip (NoC) resilient to permanent faults. We characterize the network resources based on the particular service that they support and, when faulty, bypass them, allowing the respective traffic class to be redirected. We propose two alternatives for service redirection, each having different advantages and disadvantages. The first one, Service Detour, uses longer alternative paths through resources of the same service to bypass faulty network parts, keeping traffic classes isolated. The second approach, Service Merge, uses resources of other services providing shorter paths but allowing traffic classes to interfere with each other. The remaining network resources that are common for all services employ additional mechanisms for tolerating faults. Links tolerate faults using additional spare wires combined with a flit-shifting mechanism, and the router control is protected with Triple-Modular-Redundancy (TMR). The proposed RQNoC network designs are implemented in 65nm technology and evaluated in terms of performance, area, power consumption, and fault tolerance. Service Detour requires 9% more area and consumes 7.3% more power compared to a baseline network, not tolerant to faults. Its packet latency and throughput is close to the fault-free performance at low-fault densities, but fault tolerance and performance drop substantially for 8 or more network faults. Service Merge requires 22% more area and 27% more power than the baseline and has a 9% slower clock. Compared to a fault-free network, a Service Merge RQNoC with up to 32 faults has increased packet latency up to 1.5 to 2.4× and reduced throughput to 70% or 50%. However, it delivers substantially better fault tolerance, having a mean network connectivity above 90% even with 32 network faults versus 41% of a Service Detour network. Combining Serve Merge and Service Detour improves fault tolerance, further sustaining a higher number of network faults and reduced packet latency.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2280491315",
    "type": "article"
  },
  {
    "title": "Scalable Global Power Management Policy Based on Combinatorial Optimization for Multiprocessors",
    "doi": "https://doi.org/10.1145/2811404",
    "publication_date": "2015-12-08",
    "publication_year": 2015,
    "authors": "Gung-Yu Pan; Jed Yang; Jing-Yang Jou; Bo‐Cheng Lai",
    "corresponding_authors": "",
    "abstract": "Multiprocessors have become the main architecture trend in modern systems due to the superior performance; nevertheless, the power consumption remains a critical challenge. Global power management (GPM) aims at dynamically finding the power state combination that satisfies the power budget constraint while maximizing the overall performance (or vice versa). Due to the increasing number of cores in a multiprocessor system, the scalability of GPM policies has become critical when searching satisfactory state combinations within acceptable time. This article proposes a highly scalable policy based on combinatorial optimization with theoretical proofs, whereas previous works take exhaustive search or heuristic methods. The proposed policy first applies an optimum algorithm to construct a state combination table in pseudo--polynomial time using dynamic programming. Then, the state combination is assigned to cores with minimum transition cost in linear time by mapping to the network flow problem. Simulation results show that the proposed policy achieves better system performance for any given power budget when compared to the state-of-the-art heuristic. Furthermore, the proposed policy demonstrates its prominent scalability with 125 times faster policy runtime for 512 cores.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2294850950",
    "type": "article"
  },
  {
    "title": "Incremental Analysis of Cyclo-Static Synchronous Dataflow Graphs",
    "doi": "https://doi.org/10.1145/2792981",
    "publication_date": "2015-12-08",
    "publication_year": 2015,
    "authors": "Robert de Groote; Philip K. F. Hölzenspies; Jan Kuper; Gerard J.M. Smit",
    "corresponding_authors": "",
    "abstract": "In this article, we present a mathematical characterisation of admissible schedules of cyclo-static dataflow ( csdf ) graphs. We demonstrate how algebra ic manipulation of this characterization is related to unfolding csdf actors and how this manipulation allows csdf graphs to be transformed into mrsdf graphs that are equivalent , in the sense that they admit the same set of schedules. The presented transformation allows the rich set of existing analysis techniques for mrsdf graphs to be applied to csdf graphs and generalizes the well-known transformations from csdf and mrsdf into hsdf . Moreover, it gives rise to an incremental approach to the analysis of csdf graphs, where approximate analyses are combined with exact transformations. We show the applicability of this incremental approach by demonstrating its effectiveness on the problem of optimizing buffer sizes under a throughput constraint.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2294906028",
    "type": "article"
  },
  {
    "title": "Designing Parameterizable Hardware IPs in a Model-Based Design Environment for High-Level Synthesis",
    "doi": "https://doi.org/10.1145/2871737",
    "publication_date": "2016-02-26",
    "publication_year": 2016,
    "authors": "Shahzad Ahmad Butt; Mehdi Roozmeh; Luciano Lavagno",
    "corresponding_authors": "",
    "abstract": "Model-based hardware design allows one to map a single model to multiple hardware and/or software architectures, essentially eliminating one of the major limitations of manual coding in C or RTL. Model-based design for hardware implementation has traditionally offered a limited set of microarchitectures, which are typically suitable only for some application scenarios. In this article we illustrate how digital signal processing (DSP) algorithms can be modeled as flexible intellectual property blocks to be used within the popular Simulink model-based design environment. These blocks are written in C and are designed for both functional simulation and hardware implementation, including architectural design space exploration and hardware implementation through high-level synthesis. A key advantage of our modeling approach is that the very same bit-accurate model is used for simulation and high-level synthesis. To prove the feasibility of our proposed approach, we modeled a fast Fourier transform (FFT) algorithm and synthesized it for different DSP applications with very different performance and cost requirements. We also implemented a high-level-synthesis (HLS) intellectual property (IP) generator that can generate flexible FFT HLS-IP blocks that can be mapped to multiple micro-/macroarchitectures, to enable design space exploration as well as being used for functional simulation in the Simulink environment.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2313278055",
    "type": "article"
  },
  {
    "title": "Structure Design of Wireless Sensor Nodes with Energy and Cost Awareness for Multichannel Signal Measurement",
    "doi": "https://doi.org/10.1145/2790300",
    "publication_date": "2016-02-20",
    "publication_year": 2016,
    "authors": "Zhenhuan Zhu; S. Olutunde Oyadiji",
    "corresponding_authors": "",
    "abstract": "This article aims to develop a design pattern of a wireless sensor node working in multichannel signal measurement for effectively lowering energy consumption and cost. The proposed design pattern enables the architecture of a wireless sensor node to adapt to application requirements, thus to significantly reduce system redundancy. Two multisensor structures are parameterized regarding frequency response, power consumption, and cost. The system design pattern provides flexibility through three proposed interface circuits that bridge between multisensor structures and the microprocessors inside sensor nodes. It also allows adjusting time the delay parameter that can enlarge the selection range of main electronic components, and thereby increases the robustness of the model for practical implementations. A virtual case study is provided to demonstrate how to apply this model into an application design.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2340113724",
    "type": "article"
  },
  {
    "title": "Integrated Exploration Methodology for Data Interleaving and Data-to-Memory Mapping on SIMD Architectures",
    "doi": "https://doi.org/10.1145/2894754",
    "publication_date": "2016-05-23",
    "publication_year": 2016,
    "authors": "Iason Filippopoulos; Namita Sharma; Francky Catthoor; Per Gunnar Kjeldsberg; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "This work presents a methodology for efficient exploration of data interleaving and data-to-memory mapping options for Single Instruction Multiple Data (SIMD) platform architectures. The system architecture consists of a reconfigurable clustered scratch-pad memory and a SIMD functional unit, which performs the same operation on multiple input data in parallel. The memory accesses contribute substantially to the overall energy consumption of an embedded system executing a data intensive task. The scope of this work is the reduction of the overall energy consumption by increasing the utilization of the functional units and decreasing the number of memory accesses. The presented methodology is tested using a number of benchmark applications with holes in their access scheme. Potential gains are calculated based on the energy models, both for the processing and the memory part of the system. The reduction in energy consumption after efficient interleaving and mapping of data is between 40% and 80% for the complete system and the studied benchmarks.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2403325771",
    "type": "article"
  },
  {
    "title": "A Novel Embedded Interpolation Algorithm with Negative Squared Distance for Real-Time Endomicroscopy",
    "doi": "https://doi.org/10.1145/2905367",
    "publication_date": "2016-09-01",
    "publication_year": 2016,
    "authors": "Wei Ming Chiew; Feng Lin; Hock Soon Seah",
    "corresponding_authors": "",
    "abstract": "Interpolation is the most executed operation and one of the main bottlenecks in embedded imaging, registration, and rendering systems. Existing methods either lack parallelization and scalability capabilities or are too computationally complex to execute efficiently. Acknowledging that improving execution time leads to degradation in image quality, we formulate a novel Negative Squared Distance (NSD) interpolation method that exhibits excellent performance by exploiting Look-Up Table (LUT) optimization for Field Programmable Gate Array (FPGA) speedup, with a balanced trade-off in quality in our embedded endomicroscopic imaging system. Quantitative analysis on performance and resource utilization of NSD against existing methods is reported through an implementation on a Xilinx ML605 platform. Functional validation using practical image resizing and rotation applications to compare qualitative performance against existing algorithms is performed and presented with visual and numerical results. Our method is shown to have a smaller design size and produces a maximum throughput of over twofold against trilinear interpolation with on-par image quality as the baseline method.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2514804537",
    "type": "article"
  },
  {
    "title": "A Scriptable Standard-Compliant Reporting and Logging Framework for SystemC",
    "doi": "https://doi.org/10.1145/2983623",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Rolf Meyer; Jan Wagner; Bastian Farkas; Sven Alexander Horsinka; Patrick Siegl; Rainer Buchty; Mladen Bereković",
    "corresponding_authors": "",
    "abstract": "With the ever-increasing complexity of digital designs, debugging and evaluation face likewise increasing challenges. While recent advances in hardware/software co-simulation have been made, solutions for corresponding debugging and evaluation did not mature and improve in a similar fashion. In this article, we present a dedicated solution to ease the debugging and evaluation efforts, particularly focusing on full-system simulation. Improving significantly over existing solutions, the presented approach features a standards-compliant powerful and flexible method of deriving, logging, and filtering detailed status information from SystemC-based models. At the core of this approach are flexible scripting capabilities that may change all logging parameters during runtime, thus not requiring re-compiling the to-be-simulated model, as in many competing solutions. The approach is tested and benchmarked with a real-world full-system example, demonstrating the overall benefits. The presented solution is published as open source via github (see text) and, by strictly adhering to existing standards, is generally compatible with existing SystemC simulation environments.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2531090817",
    "type": "article"
  },
  {
    "title": "Sleep-Mode Voltage Scaling",
    "doi": "https://doi.org/10.1145/2950054",
    "publication_date": "2016-11-03",
    "publication_year": 2016,
    "authors": "Hrishikesh Jayakumar; Arnab Raha; Vijay Raghunathan",
    "corresponding_authors": "",
    "abstract": "In heavily duty-cycled embedded systems, the energy consumed by the microcontroller in idle mode is often the bottleneck for battery lifetime. Existing solutions address this problem by placing the microcontroller in a low-power (sleep) mode when idle and preserving application state either by retaining the data in situ in Static Random Access Memory (SRAM) or by checkpointing it to F lash . However, both of these approaches have notable drawbacks. In situ data retention requires the SRAM to remain powered in sleep mode, while checkpointing to F lash involves significant energy and time overheads. This article proposes a new ultra-low-power sleep mode for microcontrollers that overcomes the limitations of both of these approaches. Our technique, H ypnos , is based on the key observation that the on-chip SRAM in a microcontroller exhibits 100% data retention even at a much lower supply voltage (as much as 10× lower) than the typical operating voltage of the microcontroller. H ypnos exploits this observation by performing extreme voltage scaling when the microcontroller is in sleep mode. We implement and evaluate H ypnos for the TI MSP430G2452 microcontroller and show that the Microcontroller (MCU) draws only 26nA in the proposed sleep mode, which is 4× lower than a baseline sleep mode that preserves SRAM contents. Further, to reduce the overheads associated with performing the voltage scaling, we propose the use of an energy harvesting source for providing the scaled supply voltage and demonstrate (using a light sensing photodiode) that the current consumption in the proposed sleep mode can be reduced to 1nA, which is 100× lower than the current consumption in the baseline low-power mode. We also show that the decrease in sleep-mode power consumption translates to a reduction in application-level energy consumption by as much as 6.45×. By decreasing the average power consumption to such minuscule levels, H ypnos takes a significant step forward in making perpetual systems a reality through the use of energy harvesting.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2548301520",
    "type": "article"
  },
  {
    "title": "Software thread integration for instruction-level parallelism",
    "doi": "https://doi.org/10.1145/2501626.2512466",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Won So; Alexander G. Dean",
    "corresponding_authors": "",
    "abstract": "Multimedia applications require a significantly higher level of performance than previous workloads of embedded systems. They have driven digital signal processor (DSP) makers to adopt high-performance architectures like VLIW (Very-Long Instruction Word). Despite many efforts to exploit instruction-level parallelism (ILP) in the application, the speed is a fraction of what it could be, limited by the difficulty of finding enough independent instructions to keep all of the processor's functional units busy.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4230590677",
    "type": "article"
  },
  {
    "title": "Leveraging speculative architectures for runtime program validation",
    "doi": "https://doi.org/10.1145/2501626.2512456",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Juan Carlos Martínez-Santos; Yunsi Fei",
    "corresponding_authors": "",
    "abstract": "Program execution can be tampered with by malicious attackers through exploiting software vulnerabilities. Changing the program behavior by compromising control data and decision data has become the most serious threat in computer system security. Although several hardware approaches have been presented to validate program execution, they either incur great hardware overhead or introduce false alarms. We propose a new hardware-based approach by leveraging the existing speculative architectures for runtime program validation. The on-chip branch target buffer (BTB) is utilized as a cache of the legitimate control flow transfers stored in a secure memory region. In addition, the BTB is extended to store the correct program path information. At each indirect branch site, the BTB is used to validate the decision history of previous conditional branches and monitor the following execution path at runtime. Implementation of this approach is transparent to the upper operating system and programs. Thus, it is applicable to legacy code. Because of good code locality of the executable programs and effectiveness of branch prediction, the frequency of control-flow validations against the secure off-chip memory is low. Our experimental results show a negligible performance penalty and small storage overhead.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4254300323",
    "type": "article"
  },
  {
    "title": "Coscheduling of processor voltage and control task period for energy-efficient control systems",
    "doi": "https://doi.org/10.1145/1698772.1698773",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Hyung Sun Lee; Byung Kook Kim",
    "corresponding_authors": "",
    "abstract": "The Dynamic Voltage Scaling (DVS) technique has been widely studied for energy-constrained real-time systems; however, its application to control systems has not been studied in a variety of aspects. This article presents a novel method to simultaneously schedule processor voltage and control-task periods online, considering energy-efficiency of control systems as a whole. A new performance index is proposed, which contains both control performance and processor energy terms. Then, an online scheduler assigning processor voltage and control-task periods that maximizes the performance index is proposed. The performance of the proposed scheduler under varying control workload is verified using MATLAB simulations and experiments on an actual DVS hardware platform.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1985622104",
    "type": "article"
  },
  {
    "title": "Dynamic alteration schemes of real-time schedules for I/O device energy efficiency",
    "doi": "https://doi.org/10.1145/1880050.1880059",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Euiseong Seo; Sangwon Kim; Seonyeong Park; Joonwon Lee",
    "corresponding_authors": "",
    "abstract": "Many I/O devices provide multiple power states known as the dynamic power management (DPM) feature. However, activating from sleep state requires significant transition time and this obstructs utilizing DPM in nonpreemptive real-time systems. This article suggests nonpreemptive real-time task scheduling schemes maximizing the effectiveness of the I/O device DPM support. First, we introduce a runtime schedulability check algorithm for nonpreemptive real-time systems that can check whether a modification from a valid schedule is still valid. By using this, we suggest three heuristic algorithms. The first algorithm reorders the execution sequence of tasks according to the similarity of their required device sets. The second one gathers dispersed short idle periods into one long idle period to extend sleeping state of I/O devices and the last one inserts an idle period between two consecutively scheduled tasks to prepare the required devices of a task right before the starting time of the task. The suggested schemes were evaluated for both the real-world task sets and the hypothetical task sets with simulation and the results showed that the suggested algorithms produced better energy efficiency than the existing comparative algorithms.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2002062006",
    "type": "article"
  },
  {
    "title": "Unequal Error Protection Based on DVFS for JSCD in Low-Power Portable Multimedia Systems",
    "doi": "https://doi.org/10.1145/2220336.2220342",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Yoon Seok Yang; Gwan Choi",
    "corresponding_authors": "",
    "abstract": "This article presents a low-power decoder design for joint source-channel decoding (JSCD) based on a novel unequal error protection (UEP) scheme over additive white gaussian noise (AWGN) channels. Conventional JSCD schemes, adopting low-density parity check (LDPC) codes for multimedia devices, typically operate at a fixed-time decoding loop, regardless of the quality of data received. We present a JSCD scheme that achieves reduction in power through minimum energy decoding and dynamic voltage and frequency scaling (DVFS). Consequently, up to 39% power reduction is achieved in Foreman, Akiyo, and Mobile video streams without performance degradation in reconstructed video quality.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2092898860",
    "type": "article"
  },
  {
    "title": "A Variability-Aware Robust Design Space Exploration Methodology for On-Chip Multiprocessors Subject to Application-Specific Constraints",
    "doi": "https://doi.org/10.1145/2220336.2220341",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Gianluca Palermo; Cristina Silvano; Vittorio Zaccaria",
    "corresponding_authors": "",
    "abstract": "Manufacturing process variation is dramatically becoming one of the most important challenges related to power and performance optimization for sub-90nm CMOS technologies. Process variability impacts the optimization of the target system metrics, that is, performance and energy consumption by introducing fluctuations and unpredictability. Besides, it impacts the parametric yield of the chip with respect to application level constraints by reducing the number of devices working within normal operating conditions. The impact of variability on systems with stringent application-specific requirements (such as portable multimedia and critical embedded systems) is much greater than on general-purpose systems given the emphasis on predictability and reduced operating margins. In this market segment, failing to address such a problem within the early design stages of the chip may lead to missing market deadlines and suffering greater economic losses. In the context of a design space exploration framework for supporting the platform-based design approach, we address the problem of robustness with respect to manufacturing process variations. First, we apply Response Surface Modeling (RSM) techniques to enable an efficient evaluation of the statistical measures of execution time and energy consumption for each system configuration. Then, we apply a robust design space exploration framework to afford the problem of the impact of manufacturing process variations onto the system-level metrics and consequently onto the application-level constraints. We finally provide a comparison of our design space exploration technique with conventional approaches on two different case studies.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2098381545",
    "type": "article"
  },
  {
    "title": "Link layer driver architecture for unified radio power management in wireless sensor networks",
    "doi": "https://doi.org/10.1145/1721695.1721707",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Kevin Klues; Guoliang Xing; Chenyang Lu",
    "corresponding_authors": "",
    "abstract": "Wireless Sensor Networks (WSNs) represent a new generation of networked embedded systems that must achieve long lifetimes on scarce amounts of energy. Since radio communication accounts for the primary source of power drain in these networks, a large number of different radio power management protocols have been proposed. However, the lack of operating system support for flexibly integrating them with a diverse set of applications and network platforms has made them difficult to use. This article focuses on providing link layer support toward realizing a unified power management architecture (UPMA) for WSNs. In contrast to existing monolithic approaches, we provide (i) a set of standard interfaces that separate link layer power management protocols from common MAC level functionality, (ii) an architectural framework that allows applications to easily swap out different power-management protocols depending on its needs, and (iii) a mechanism for coordinating multiple applications with different power management requirements. We have implemented our approach on both the Mica2 and Telosb radio drivers in TinyOS-2.0, the second generation of the de facto standard operating system for WSNs. Microbenchmark results show that our approach can coordinate the power-management requirements of multiple applications in a platform independent fashion while incurring negligible overhead.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2119455266",
    "type": "article"
  },
  {
    "title": "Evaluation of hardware and software schedulers for embedded switches",
    "doi": "https://doi.org/10.1145/1027794.1027798",
    "publication_date": "2004-11-01",
    "publication_year": 2004,
    "authors": "Dimitrios Serpanos; Poluxeni Mountrouidou; M. Gamvrili",
    "corresponding_authors": "",
    "abstract": "High-speed packet switches become increasingly important to embedded systems because they provide multiple parallel data paths necessary in emerging systems such as embedded multiprocessors, multiprotocol communication processors, and so on. The most promising architecture for embedded switches is the one that uses multiple input queues, due to its low-cost integration in conventional embedded systems, which include memory management subsystems. Such switches require high-speed schedulers, in order to resolve conflicts among packet destinations and to achieve low latency, high bandwidth communication, while providing fairness guarantees. In general, these schedulers are categorized as centralized or distributed, depending on their operation. In this paper, we evaluate hardware and software implementations of two schedulers: 2-dimensional round-robin and FIRM, which are centralized and distributed, respectively. The evaluation is performed for embedded system implementation, on a system that includes an FPGA and an embedded processor on-chip. The performance results show that, in contrast to expectations, centralized schedulers provide better performance than distributed ones in hardware implementations. In software implementations for embedded processors, surprisingly, distributed schedulers achieve better performance, due to better management of the processor's limited resources and simpler code; our experiments have shown that compilers for embedded systems are quite limited and require significant improvement. Finally, we evaluate the scalability of the schedulers, in terms of throughput, circuit complexity, and power consumption, based on implementation technology, considering the dramatic improvements expected in the availability of high-speed programmable logic and embedded processors on the same chip.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2069618865",
    "type": "article"
  },
  {
    "title": "Software thread integration for embedded system display applications",
    "doi": "https://doi.org/10.1145/1132357.1132362",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "Alexander G. Dean",
    "corresponding_authors": "Alexander G. Dean",
    "abstract": "Embedded systems require control of many concurrent real-time activities, leading to system designs that feature a variety of hardware peripherals, with each providing a specific, dedicated service. These peripherals increase system size, cost, weight, and design time. Software thread integration (STI) provides low-cost thread concurrency on general-purpose processors by automatically interleaving multiple threads of control into one. This simplifies hardware to software migration (which eliminates dedicated hardware) and can help embedded system designers meet design constraints, such as size, weight and cost. We have developed concepts for performing STI and have implemented many in our automated postpass compiler Thrint. Here we present the transformations and examine how well the compiler integrates threads for two display applications. We examine the integration procedure, the processor load, and code memory expansion. Integration allows reclamation of CPU idle time, allowing run-time speedups of 1.6x to 3.6x.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2094247811",
    "type": "article"
  },
  {
    "title": "Efficient External Sorting for Memory-Constrained Embedded Devices with Flash Memory",
    "doi": "https://doi.org/10.1145/3446976",
    "publication_date": "2021-03-26",
    "publication_year": 2021,
    "authors": "Riley Jackson; Jonathan Gresl; Ramon Lawrence",
    "corresponding_authors": "",
    "abstract": "Embedded devices are ubiquitous in areas of industrial and environmental monitoring, health and safety, and consumer appliances. A common use case is data collection, processing, and performing actions based on data analysis. Although many Internet of Things (IoT) applications use the embedded device simply for data collection, there are benefits to having more data processing done closer to data collection to reduce network transmissions and power usage and provide faster response. This work implements and evaluates algorithms for sorting data on embedded devices with specific focus on the smallest memory devices. In devices with less than 4 KB of available RAM, the standard external merge sort algorithm has limited application as it requires a minimum of three memory buffers and is not flash-aware. The contribution is a memory-optimized external sorting algorithm called no output buffer sort (NOBsort) that reduces the minimum memory required for sorting, has excellent performance for sorted or near-sorted data, and sorts on external memory such as SD cards or raw flash chips. When sorting large datasets, no output buffer sort reduces I/O and execution time by between 20% to 35% compared to standard external merge sort.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3143434767",
    "type": "article"
  },
  {
    "title": "SIKE in 32-bit ARM Processors Based on Redundant Number System for NIST Level-II",
    "doi": "https://doi.org/10.1145/3439733",
    "publication_date": "2021-03-27",
    "publication_year": 2021,
    "authors": "Hwajeong Seo; Pakize Sanal; Reza Azarderakhsh",
    "corresponding_authors": "",
    "abstract": "We present an optimized implementation of the post-quantum Supersingular Isogeny Key Encapsulation (SIKE) for 32-bit ARMv7-A processors supporting NEON engine (i.e., SIMD instruction). Unlike previous SIKE implementations, finite field arithmetic is efficiently implemented in a redundant representation, which avoids carry propagation and pipeline stall. Furthermore, we adopted several state-of-the-art engineering techniques as well as hand-crafted assembly implementation for high performance. Optimized implementations are ported to Microsoft SIKE library written in “a non-redundant representation” and evaluated in high-end 32-bit ARMv7-A processors, such as ARM Cortex-A5, A7, and A15. A full key-exchange execution of SIKEp503 is performed in about 109 million cycles on ARM Cortex-A15 processors (i.e., 54.5 ms @2.0 GHz), which is about 1.58× faster than previous state-of-the-art work presented in CHES’18.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3147389018",
    "type": "article"
  },
  {
    "title": "Code-size-aware Scheduling of Synchronous Dataflow Graphs on Multicore Systems",
    "doi": "https://doi.org/10.1145/3440034",
    "publication_date": "2021-03-27",
    "publication_year": 2021,
    "authors": "Mingze Ma; Rizos Sakellariou",
    "corresponding_authors": "",
    "abstract": "Synchronous dataflow graphs are widely used to model digital signal processing and multimedia applications. Self-timed execution is an efficient methodology for the analysis and scheduling of synchronous dataflow graphs. In this article, we propose a communication-aware self-timed execution approach to solve the problem of scheduling synchronous dataflow graphs on multicore systems with communication delays. Based on this communication-aware self-timed execution approach, four communication-aware scheduling algorithms are proposed using different allocation rules. Furthermore, a code-size-aware mapping heuristic is proposed and jointly used with a proposed scheduling algorithm to reduce the code size of SDFGs on multicore systems. The proposed scheduling algorithms are experimentally evaluated and found to perform better than existing algorithms in terms of throughput and runtime for several applications. The experiments also show that the proposed code-size-aware mapping approach can achieve significant code size reduction with limited throughput degradation in most cases.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3151650113",
    "type": "article"
  },
  {
    "title": "Integrated Hardware Garbage Collection",
    "doi": "https://doi.org/10.1145/3450147",
    "publication_date": "2021-07-09",
    "publication_year": 2021,
    "authors": "Andrés Amaya García; David May; Ed Nutting",
    "corresponding_authors": "",
    "abstract": "Garbage collected programming languages, such as Python and C#, have accelerated software development. These modern languages increase productivity and software reliability as they provide high-level data representation and control structures. Modern languages are widely used in software development for mobile, desktop, and server devices, but their adoption is limited in real-time embedded systems. There is clear interest in supporting modern languages in embedded devices as emerging markets, like the Internet of Things, demand ever smarter and more reliable products. Multiple commercial and open-source projects, such as Zerynth and MicroPython, are attempting to provide support. But these projects rely on software garbage collectors that impose high overheads and introduce unpredictable pauses, preventing their use in many embedded applications. These limitations arise from the unsuitability of conventional processors for performing efficient, predictable garbage collection. We propose the Integrated Hardware Garbage Collector (IHGC); a garbage collector tightly coupled with the processor that runs continuously in the background. Further, we introduce a static analysis technique to guarantee that real-time programs are never paused by the collector. Our design allocates a memory cycle to the collector when the processor is not using the memory. The IHGC achieves this by careful division of collection work into single-memory-access steps that are interleaved with the processor’s memory accesses. As a result, our collector eliminates run-time overheads and enables real-time program analysis. The principles behind the IHGC can be used in conjunction with existing architectures. For example, we simulated the IHGC alongside the ARMv6-M architecture. Compared to a conventional processor, our experiments indicate that the IHGC offers 1.5–7 times better performance for programs that rely on garbage collection. The IHGC delivers the benefits of garbage-collected languages with real-time performance but without the complexity and overheads inherent in software collectors.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3183127856",
    "type": "article"
  },
  {
    "title": "Symbolic Loop Compilation for Tightly Coupled Processor Arrays",
    "doi": "https://doi.org/10.1145/3466897",
    "publication_date": "2021-07-29",
    "publication_year": 2021,
    "authors": "Michael Witterauf; Dominik Walter; Frank Hannig; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "Tightly Coupled Processor Arrays (TCPAs), a class of massively parallel loop accelerators, allow applications to offload computationally expensive loops for improved performance and energy efficiency. To achieve these two goals, executing a loop on a TCPA requires an efficient generation of specific programs as well as other configuration data for each distinct combination of loop bounds and number of available processing elements (PEs). Since both these parameters are generally unknown at compile time—the number of available PEs due to dynamic resource management, and the loop bounds, because they depend on the problem size—both the programs and configuration data must be generated at runtime. However, pure just-in-time compilation is impractical, because mapping a loop program onto a TCPA entails solving multiple NP-complete problems. As a solution, this article proposes a unique mixed static/dynamic approach called symbolic loop compilation. It is shown that at compile time, the NP-complete problems (modulo scheduling, register allocation, and routing) can still be solved to optimality in a symbolic way resulting in a so-called symbolic configuration , a space-efficient intermediate representation parameterized in the loop bounds and number of PEs. This phase is called symbolic mapping . At runtime, for each requested accelerated execution of a loop program with given loop bounds and known number of available PEs, a concrete configuration , including PE programs and configuration data for all other components, is generated from the symbolic configuration according to these parameter values. This phase is called instantiation . We describe both phases in detail and show that instantiation runs in polynomial time with its most complex step, program instantiation, not directly depending on the number of PEs and thus scaling to arbitrary sizes of TCPAs. To validate the efficiency of this mixed static/dynamic compilation approach, we apply symbolic loop compilation to a set of real-world loop programs from several domains, measuring both compilation time and space requirements. Our experiments confirm that a symbolic configuration is a space-efficient representation suited for systems with little memory—in many cases, a symbolic configuration is smaller than even a single concrete configuration instantiated from it—and that the times for the runtime phase of program instantiation and configuration loading are negligible and moreover independent of the size of the available processor array. To give an example, instantiating a configuration for a matrix-matrix multiplication benchmark takes equally long for 4× 4 and 32× 32 PEs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3186527763",
    "type": "article"
  },
  {
    "title": "A Hierarchical Hybrid Locking Protocol for Parallel Real-Time Tasks",
    "doi": "https://doi.org/10.1145/3477017",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Zewei Chen; Hang Lei; Maolin Yang; Yong Liao; Lei Qiao",
    "corresponding_authors": "",
    "abstract": "Parallel tasks have been paid growing attention in recent years, and the scheduling with shared resources is of significant importance to real-time systems. As an efficient mechanism to provide mutual exclusion for parallel processing, spin-locks are ubiquitous in multi-processor real-time systems. However, the spin-locks suffer the scalability problem, and the intra-task parallelism further exacerbates the analytical pessimism. To overcome such deficiencies, we propose a Hierarchical Hybrid Locking Protocol (H2LP) under federated scheduling. The proposed H2LP integrates the classical Multiprocessor Stack Resource Policy (MSRP) and uses a token mechanism to reduce global contentions. We provide a complete analysis framework supporting both heavy and light tasks under federated scheduling and develop a blocking analysis with the state-of-the-art linear optimization technique. Empirical evaluations showed that the H2LP outperformed the other state-of-the-art locking protocols in at least <?TeX $85.9\\%$?> configurations when considering exclusive clustering. Furthermore, our partitioned approach for light tasks can substantially improve schedulability by mitigating the over-provisioning problem.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3199060385",
    "type": "article"
  },
  {
    "title": "HEART: <u>H</u> ybrid Memory and <u>E</u> nergy- <u>A</u> ware <u>R</u> eal- <u>T</u> ime Scheduling for Multi-Processor Systems",
    "doi": "https://doi.org/10.1145/3477019",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Mario Günzel; Christian Hakert; Kuan-Hsun Chen; Jian-Jia Chen",
    "corresponding_authors": "",
    "abstract": "Dynamic power management (DPM) reduces the power consumption of a computing system when it idles, by switching the system into a low power state for hibernation. When all processors in the system share the same component, e.g., a shared memory, powering off this component during hibernation is only possible when all processors idle at the same time. For a real-time system, the schedulability property has to be guaranteed on every processor, especially if idle intervals are considered to be actively introduced. In this work, we consider real-time systems with hybrid shared-memory architectures, which consist of shared volatile memory (VM) and non-volatile memory (NVM). Energy-efficient execution is achieved by applying DPM to turn off all memories during the hibernation mode. Towards this, we first explore the hybrid memory architectures and suggest a task model, which features configurable hibernation overheads. We propose a multi-processor procrastination algorithm (HEART), based on partitioned earliest-deadline-first (pEDF) scheduling. Our algorithm facilitates reducing the energy consumption by actively enlarging the hibernation time. It enforces all processors to idle simultaneously without violating the schedulability condition, such that the system can enter the hibernation state, where shared memories are turned off. Throughout extensive evaluation of HEART, we demonstrate (1) the increase in potential hibernation time, respectively the decrease in energy consumption, and (2) that our algorithm is not only more general but also has better performance than the state of the art with respect to energy efficiency in most cases.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3200878650",
    "type": "article"
  },
  {
    "title": "Verifying Stochastic Hybrid Systems with Temporal Logic Specifications via Model Reduction",
    "doi": "https://doi.org/10.1145/3483380",
    "publication_date": "2021-11-15",
    "publication_year": 2021,
    "authors": "Yu Wang; Nima Roohi; Matthew West; Mahesh Viswanathan; Geir E. Dullerud",
    "corresponding_authors": "",
    "abstract": "We present a scalable methodology to verify stochastic hybrid systems for inequality linear temporal logic (iLTL) or inequality metric interval temporal logic (iMITL). Using the Mori–Zwanzig reduction method, we construct a finite-state Markov chain reduction of a given stochastic hybrid system and prove that this reduced Markov chain is approximately equivalent to the original system in a distributional sense. Approximate equivalence of the stochastic hybrid system and its Markov chain reduction means that analyzing the Markov chain with respect to a suitably strengthened property allows us to conclude whether the original stochastic hybrid system meets its temporal logic specifications. Based on this, we propose the first statistical model checking algorithms to verify stochastic hybrid systems against correctness properties, expressed in iLTL or iMITL. The scalability of the proposed algorithms is demonstrated by a case study.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3214002615",
    "type": "article"
  },
  {
    "title": "Reconfiguration of IIR filters in response to computer resource availability",
    "doi": "https://doi.org/10.1145/1596532.1596534",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Bonnie Ferri; Aldo A. Ferri",
    "corresponding_authors": "",
    "abstract": "This article explores methods to reconfigure infinite impulse response (IIR) filters in processes that utilize computer resource management. A high-performance mode uses a full-length IIR filter, while low resources or a desire to conserve power triggers a low-performance mode where a smaller length filter is used. Two alternatives for algorithms are explored: switching between filter banks of varying lengths, and anytime filters where the later stages can be skipped if computational resources are scarce. Two main challenges are addressed in this article. The first is how to configure an IIR filter as an anytime algorithm, and the second is how to initialize the states of the filters in order to mitigate transients induced by reconfiguration. The performance and feasibility of several common transient management schemes are investigated for use in this application. It is found that an anytime IIR filter outperforms the filter banks in almost every case studied due to its inherently smaller transients and the fact that the reconfiguration happens at the speed of resource management and not at a lower speed typically associated with reconfiguration due to physical system properties.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2089494736",
    "type": "article"
  },
  {
    "title": "Detecting Software Cache Coherence Violations in MPSoC Using Traces Captured on Virtual Platforms",
    "doi": "https://doi.org/10.1145/2990193",
    "publication_date": "2017-01-02",
    "publication_year": 2017,
    "authors": "Marcos Aurélio Pinto Cunha; Omayma Matoussi; Frédéric Pétrot",
    "corresponding_authors": "",
    "abstract": "Software cache coherence schemes tend to be the solution of choice in dedicated multi/many core systems on chip, as they make the hardware much simpler and predictable. However, despite the developers’ effort, it is hard to make sure that all preventive measurements are taken to ensure coherence. In this work, we propose a method to identify the potential cache coherence violations using traces obtained from virtual platforms. These traces contain causality relations among events, which allow first to simplify the analysis, and second to avoid relying on timestamps. Our method identifies potential violations that may occur during a given execution for write-through and write-back cache policies. Therefore, it is independent of the software coherence protocol. We conducted experiments on parallel applications running on a lightweight SMP operating system, and we were able to detect coherence issues that we could then solve.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2562038174",
    "type": "article"
  },
  {
    "title": "Multi-valued Simulation and Abstraction Using Lattice Operations",
    "doi": "https://doi.org/10.1145/3012282",
    "publication_date": "2017-01-02",
    "publication_year": 2017,
    "authors": "Stefan Vijzelaar; Wan Fokkink",
    "corresponding_authors": "",
    "abstract": "Abstractions can cause spurious results, which need to be verified in the concrete system to gain conclusive results. Verification based on a multi-valued logic can distinguish between conclusive and inconclusive results, provides increased precision, and allows for encoding additional information into the model. To ensure a correct abstraction, one can use a mixed simulation [Meller et al. 2009]. We extend mixed simulation to include inconsistent values, thereby resolving an asymmetry and allowing for abstractions with increased precision when inconsistent values are available. In addition, we present a set of abstraction rules, compatible with the extended notion, for constructing abstract models.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2566367683",
    "type": "article"
  },
  {
    "title": "A Load-Balancing Divide-and-Conquer SVM Solver",
    "doi": "https://doi.org/10.1145/3005347",
    "publication_date": "2017-05-09",
    "publication_year": 2017,
    "authors": "Xiaogang Chen; Zhan Wang; Xiangyang Ji",
    "corresponding_authors": "",
    "abstract": "Scaling up kernel support vector machine (SVM) training has been an important topic in recent years. Despite its theoretical elegance, training kernel SVM is impractical when facing millions of data. The divide-and-conquer (DC) strategy is a natural framework of handling gigantic problems, and the divide-and-conquer solver for kernel SVM (DC-SVM) is able to train kernel SVM with millions of data with limited time cost. However, there are some drawbacks of the DC-SVM approach. First, it used an unsupervised clustering method to partition the whole problem, which is prone to construct singular subsets, and, second, it is hard to balance the computation load between sub-problems. To address these issues, this article proposed a load-balancing partition method for kernel SVM. First, it clusters sample from one class and then assigns data samples to the cluster centers by a distance measure and construct sub-problems; in this way, it is able to control the computation load and avoid singular problems. Experimental results show that the proposed method has better load-balancing performance than DC-SVM, which implies that it is suitable for distributed and embedding systems.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2612977878",
    "type": "article"
  },
  {
    "title": "Refining Cache Behavior Prediction Using Cache Miss Paths",
    "doi": "https://doi.org/10.1145/3035541",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Kartik Nagar; Y. N. Srikant",
    "corresponding_authors": "",
    "abstract": "Worst-Case Execution Time (WCET) is an important metric for programs running on real-time systems, and finding precise estimates of a program’s WCET is crucial to avoid wastage of hardware resources and to improve the schedulability of task sets. Caches have a major impact on a program’s execution time, and accurate estimation of a program’s cache behavior can lead to significant reduction in its estimated WCET. The traditional approach to cache analysis generally targets the worst-case cache behavior of individual cache accesses and provides a safe hit-miss classification for every individual access. In this work, we show that these classifications are not sufficient to precisely capture cache behavior, since they apply to individual accesses, and often, more precise predictions can be made about groups of accesses. Further, memory accesses inside loops may show the worst-case behavior only for a subset of the iteration space. In order to predict such behavior in a scalable fashion, we use the fact that the cache behavior of an access mostly depends only on the memory accesses made in the immediate vicinity, and hence we analyze a small, fixed-size neighborhood of every access with complete precision and summarize the resulting information in the form of cache miss paths. A variety of analyses are then performed on the cache miss paths to make precise predictions about cache behavior. We also demonstrate precision issues in Abstract Interpretation-based Must and Persistence cache analysis that can be easily solved using cache miss paths. Experimental results over a wide range of benchmarks demonstrate precision improvement in WCET of multipath programs over previous approaches, and we also show how to integrate our approach with other microarchitectural analysis such as pipeline analysis.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2613442617",
    "type": "article"
  },
  {
    "title": "Efficient Automated Code Partitioning for Microcontrollers with Switchable Memory Banks",
    "doi": "https://doi.org/10.1145/3055511",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Michał Ciszewski; Konrad Iwanicki",
    "corresponding_authors": "",
    "abstract": "Switching active memory banks at runtime allows a processor with a narrow address bus to access memory that exceeds ranges normally addressable via the bus. Switching code memory banks is regaining interest in microcontrollers for the Internet of Things (IoT), which have to run continuously growing software, while at the same time consuming ultra-small amounts of energy. To make use of bank switching, such software must be partitioned among the available banks and augmented with bank-switching instructions. In contrast to the augmenting, which is done automatically by a compiler, today the partitioning is normally done manually by programmers. However, since IoT software is cross-compiled on much more powerful machines than its target microcontrollers, it becomes possible to partition it automatically during compilation. In this article, we thus study the problem of partitioning program code among banks such that the resulting runtime performance of the program is maximized. We prove that the problem is NP -hard and propose a heuristic algorithm with a low complexity, so it enables fast compilation and hence interactive software development. The algorithm decomposes the problem into three subproblems and introduces a heuristic for each of them: (1) which pieces of code to partition, (2) which of them to assign to permanently mapped banks, and (3) how to divide the remaining ones among switchable banks. We integrate the algorithm, together with earlier ones, in an open-source compiler and test the resulting solution on synthetic as well as actual commercial IoT software bases, thereby demonstrating its advantages and drawbacks. In particular, the results show that the performance of partitions produced by our algorithm comes close to that of partitions created manually by programmers with expert knowledge on the partitioned code.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2618077195",
    "type": "article"
  },
  {
    "title": "Nucleus",
    "doi": "https://doi.org/10.1145/3126544",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Ilias Vougioukas; Andreas Sandberg; Stephan Diestelhorst; Bashir M. Al‐Hashimi; Geoff V. Merrett",
    "corresponding_authors": "",
    "abstract": "Heterogeneous multi-processors are designed to bridge the gap between performance and energy efficiency in modern embedded systems. This is achieved by pairing Out-of-Order (OoO) cores, yielding performance through aggressive speculation and latency masking, with In-Order (InO) cores, that preserve energy through simpler design. By leveraging migrations between them, workloads can therefore select the best setting for any given energy/delay envelope. However, migrations introduce execution overheads that can hurt performance if they happen too frequently. Finding the optimal migration frequency is critical to maximize energy savings while maintaining acceptable performance. We develop a simulation methodology that can 1) isolate the hardware effects of migrations from the software, 2) directly compare the performance of different core types, 3) quantify the performance degradation and 4) calculate the cost of migrations for each case. To showcase our methodology we run mibench, a microbenchmark suite, and show that migrations can happen as fast as every 100k instructions with little performance loss. We also show that, contrary to numerous recent studies, hypothetical designs do not need to share all of their internal components to be able to migrate at that frequency. Instead, we propose a feasible system that shares level 2 caches and a translation lookaside buffer that matches performance and efficiency. Our results show that there are phases comprising up to 10% that a migration to the OoO core leads to performance benefits without any additional energy cost when running on the InO core, and up to 6% of phases where a migration to the InO core can save energy without affecting performance. When considering a policy that focuses on improving the energy-delay product, results show that on average 66% of the phases can be migrated to deliver equal or better system operation without having to aggressively share the entire memory system or to revert to migration periods finer than 100k instructions.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2755231432",
    "type": "article"
  },
  {
    "title": "P-BMS",
    "doi": "https://doi.org/10.1145/3126550",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Hong Seok Kim; Eyee Hyun Nam; Ji Hyuck Yun; Sheayun Lee; Sang Lyul Min",
    "corresponding_authors": "",
    "abstract": "Flash memory is used as a main data storage medium in increasingly large areas of applications, rapidly replacing hard disk drives because of its low power consumption, fast random access, and high shock resistance. Such flash-based storage devices generally incorporate multiple flash memory chips to meet the ever growing capacity demands. Using multiple chips in a single storage device, at the same time, opens an opportunity to boost the performance based on multi-unit parallelism. However, parallel execution of multiple flash operations introduces complications when bad blocks occur, which is unavoidable due to flash memory’s physical characteristics. The situation gets even worse when bad block occurrences are accompanied by sudden power failures. We propose a bad block management scheme called P-BMS that can fully utilize flash-level parallelism, while guaranteeing provably correct block replacement. Experiments show that our P-BMS achieves a throughput that is more than 95% of the maximum bandwidth of the flash controller, even with bad block occurrences far heavier than in real flash memory.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2757223513",
    "type": "article"
  },
  {
    "title": "Formal Verification of a Timing Enforcer Implementation",
    "doi": "https://doi.org/10.1145/3126517",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Sagar Chaki; Dionisio de Niz",
    "corresponding_authors": "",
    "abstract": "A timing enforcer is a scheduler that not only allocates CPU cycles to threads, but also uses timers to enforce time budgets. An approach for verifying safety properties of timing enforcers at the source code level is presented. We assume that the enforcer is implemented as a set of “enforcer” functions that are executed atomically on critical system-level events, such as the arrival and departure of jobs, and triggering of timers. The key idea is to express the safety property as an invariant, and prove that it is inductive across all the enforcer functions. A formal semantics of timing enforcers is presented, including the semantics of functions used to read the system clock and set timers. Using this semantics, the verification approach is presented, and its soundness proved. Further, the approach also takes into consideration the periodicity of tasks. It is validated by proving the correctness of the enforcement of CPU cycle budgets for tasks by the Zero-Slack Rate Monotonic ( zsrm ) scheduler, which is implemented in C as a Linux kernel module. The inductiveness of the necessary zsrm invariants is proved by expressing them as function contracts using the acsl specification language, and verifying the contracts using the frama-c tool.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2758078094",
    "type": "article"
  },
  {
    "title": "A Fast Method to Compute Disjunctive Quadratic Invariants of Numerical Programs",
    "doi": "https://doi.org/10.1145/3126502",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Xavier Allamigeon; Stéphane Gaubert; Éric Goubault; Sylvie Putot; Nikolas Stott",
    "corresponding_authors": "",
    "abstract": "We introduce a new method to compute non-convex invariants of numerical programs, which includes the class of switched affine systems with affine guards. We obtain disjunctive and non-convex invariants by associating different partial execution traces with different ellipsoids. A key ingredient is the solution of non-monotone fixed points problems over the space of ellipsoids with a reduction to small size linear matrix inequalities. This allows us to analyze instances that are inaccessible in terms of expressivity or scale by earlier methods based on semi-definite programming.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2758313174",
    "type": "article"
  },
  {
    "title": "The CURE",
    "doi": "https://doi.org/10.1145/3126527",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Vignyan Reddy Kothinti Naresh; Dibakar Gope; Mikko H. Lipasti",
    "corresponding_authors": "",
    "abstract": "VLIW processors typically deliver high performance on limited budget making them ideal for a variety of communication and signal processing solutions. These processors typically need large multi-ported register files that can have side effects of increased cycle time and high power consumption. The access delay and energy of these register files can also become prohibitive when increasing the register count or the access ports, thus limiting the overall performance of the processor. Most prior art circumvent this problem by using multiple clusters with private register files, to lower the access delay and reduce energy consumption. However, clustering artifacts, like increased inter--cluster communication operations and spill-recovery code, result in a performance penalty. This paper proposes CURE — a novel technique to considerably reduce the negative effects of clustering. CURE augments the ISA to expose the communication registers to the compilers to increase availability of architectural register state to all functional units. The inter--cluster communication operations are integrated into regular ALU and memory operations to improve instruction encoding efficiency. We also propose a new code scheduling heuristic to handle the ISA changes, and to realize the improvements in processor’s performance and energy consumption. Our quantitative analysis estimates that CURE, when compared to the baseline 8--issue uni--cluster processor, boosts average performance by 61% while reducing the average register dynamic energy by 77%.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2758907782",
    "type": "article"
  },
  {
    "title": "Coverage Preservation with Rapid Forwarding in Energy-Harvesting Wireless Sensor Networks for Critical Rare Events",
    "doi": "https://doi.org/10.1145/3140961",
    "publication_date": "2017-12-07",
    "publication_year": 2017,
    "authors": "David C. Harrison; Winston K.G. Seah; Ramesh Rayudu",
    "corresponding_authors": "",
    "abstract": "Wireless sensor networks for rarely occurring critical events must maintain sensing coverage and low-latency network connectivity to ensure event detection and subsequent rapid propagation of notification messages. Few algorithms have been proposed that address both coverage and forwarding and those that do are either unconcerned with rapid propagation or are not optimised to handle the constant changes in topology observed in duty-cycled networks. This article proposes an algorithm for Coverage Preservation with Rapid Forwarding (CPRF). The algorithm is shown to deliver perfect coverage maintenance and low-latency guaranteed message propagation whilst allowing stored-charge conservation via collaborative duty cycling in energy-harvesting networks. Favourable comparisons are made against established and recently proposed algorithms in both sparse planned and dense random distributions. Further, an implementation for commercially available wireless sensing devices is evaluated for detection and notification of damage to highway light poles caused by vortex shedding.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2771281336",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3194944",
    "publication_date": "2018-03-31",
    "publication_year": 2018,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2799417712",
    "type": "editorial"
  },
  {
    "title": "PTAT",
    "doi": "https://doi.org/10.1145/3182174",
    "publication_date": "2018-05-22",
    "publication_year": 2018,
    "authors": "Jiutian Zhang; Yuhang Liu; Haifeng Li; Xiaojing Zhu; Mingyu Chen",
    "corresponding_authors": "",
    "abstract": "As the memory access footprints of applications in areas like data analytics increase, the latency overhead of translation lookaside buffer (TLB) misses increases. Thus, the efficiency of TLB becomes increasingly critical for overall system performance. Analyzing TLB miss traces is useful for hardware architecture design and software application optimization. Utilizing cycle-accurate simulators or instrumentation tools is very time-consuming and/or inaccurate for tracing and profiling TLB misses. In this article, we propose an efficient and precise tool to collect and profile last-level TLB misses. This tool utilizes a novel software method called Page Table Access Tracing (PTAT), storing last-level page table entries of certain workload processes into a reserved uncached memory region. Therefore, each last-level TLB miss incurred by user process corresponds to one uncached page table access to main memory, which can be captured and recorded by a hardware memory bus monitor. The detected information is then dumped into offline storage. In this manner, full TLB miss traces are collected and can be analyzed flexibly. Compared to previous software-based methods, this method achieves higher performance. Experiments show that, compared with a state-of-the-art kernel instrumentation method (BadgerTrap), which lacks complete dumping trace function, the speedup is still up to 3.88-fold for memory-intensive benchmarks. Due to the improved efficiency and completeness of tracing, case studies validate that more flexible profiling can be conducted, which is of great significance for TLB performance optimization. The accuracy of PTAT is verified by both dedicated sequence and performance counters.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2803947607",
    "type": "article"
  },
  {
    "title": "Providing Accountability in Heterogeneous Systems-on-Chip",
    "doi": "https://doi.org/10.1145/3241048",
    "publication_date": "2018-09-17",
    "publication_year": 2018,
    "authors": "Rajshekar Kalayappan; Smruti R. Sarangi",
    "corresponding_authors": "",
    "abstract": "When modern systems-on-chip (SoCs), containing designs from different organizations, miscompute or underperform in the field, discerning the responsible component is a non-trivial task. A perfectly accountable system is one in which the on-chip component at fault is always unambiguously detected. The achievement of accountability can be greatly aided by the collection of runtime information that captures the events in the system that led to the error. Such information collection must be fair and impartial to all parties. In this article, we prove that logging messages communicated between components from different organizations is sufficient to provide accountability, provided the logs are authentic. We then construct a solution based on this premise, with an on-chip trusted auditing system to authenticate the logs. We present a thorough design of the auditing system, and demonstrate that its performance overhead is a mere 0.49%, and its area overhead is a mere 0.194% (in a heterogeneous 48 core, 400 mm 2 chip). We also demonstrate the viability of this solution using three representative bugs found in popular commercial SoCs.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2891571247",
    "type": "article"
  },
  {
    "title": "iotプロセッサ上のARXベースブロック暗号のコンパクトな実装【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Seo Hwajeong; Jeong Ilwoong; Lee Jungkeun; Woo-Hwan Kim",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3216750862",
    "type": "article"
  },
  {
    "title": "Modeling and analysis of core-centric network processors",
    "doi": "https://doi.org/10.1145/1457255.1457260",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Yi-Neng Lin; Ying‐Dar Lin; Kuo-Kun Tseng; Yuan‐Cheng Lai",
    "corresponding_authors": "",
    "abstract": "Network processors can be categorized into two types, the coprocessors-centric model in which the data-plane is handled by coprocessors, and the core-centric model in which the core processes most of the data-plane packets yet offloading some tasks to coprocessors. While the former has been properly explored over various applications, researches regarding the latter remain limited. Based on the previous experience of prototyping the virtual private network (VPN) over the IXP425 network processor, this work aims to derive design implications for the core-centric model performing computational intensive applications. From system and IC vendors' perspectives, the continuous-time Markov chain and Petri net simulations are adopted to explore this architecture. Analytical results prove to be quite inline with those of the simulation and implementation. With subsequent investigation we find that appropriate process run lengths can improve the effective core utilization by 2.26 times, and by offloading the throughput boosts 7.5 times. The results also suggest single process programming since context switch overhead impacts considerably on the performance.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4229569040",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3145508",
    "publication_date": "2017-10-10",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4253033963",
    "type": "paratext"
  },
  {
    "title": "Energy optimal speed control of a producer--consumer device pair",
    "doi": "https://doi.org/10.1145/1274858.1274868",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Ravishankar Rao; Sarma Vrudhula",
    "corresponding_authors": "",
    "abstract": "We propose a modular approach for minimizing the total energy consumed by a pair of generic communicating devices (producer--consumer scenario) by jointly controlling their speed profiles. Each device (like a CPU, or disk drive) is assumed to have a controllable variable called its speed (e.g., a CPU's clock frequency, a disk drive's spindle motor speed) that affects its power consumption and performance (e.g., throughput, data transfer rate). The device and task models we analyzed were inspired by applications like CD recording (hard drive to CD drive data transfer) and data processing (disk drive to CPU data transfer). The proposed solution can be used for any pair of devices with convex (for continuous speed sets) or W-convex (a discrete version of a convex function for discrete speed sets) power--speed relationships. For discrete speed sets, the method operates directly on the power--speed values and does not require an analytical relationship between power and speed. The key to solving the two-device optimization problem was the observation that it could be split into two single device parametric optimization problems, where the parameters correspond to the common task that both the devices must execute. The following divide-and-conquer approach is proposed: [divide] the optimal speed policy and energy consumption of each device is derived as an analytical function of its task parameters; [conquer] the optimal values of these parameters are found by minimizing the sum of the parameterized energy functions and plugged back into the parameterized speed profiles. The main advantage of this approach is that each device can be characterized independently and this allows system designers to mix and match manufacturer-supplied device energy curves to evaluate and optimize different application scenarios. We demonstrate our approach using three device characterization examples (for a CD drive, hard drive, and a CPU) and two application scenarios (CD recording, MD5 checksum computation).",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2052245202",
    "type": "article"
  },
  {
    "title": "Interactive schedulability analysis",
    "doi": "https://doi.org/10.1145/1324969.1324976",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "Unmesh D. Bordoloi; Samarjit Chakraborty",
    "corresponding_authors": "",
    "abstract": "A typical design process for real-time embedded systems involves choosing the values of certain system parameters and performing a schedulability analysis to determine whether all deadline constraints can be satisfied. If such an analysis returns a negative answer, then some of the parameters are modified and the analysis is invoked once again. This iteration is repeated until a schedulable design is obtained. However, the schedulability analysis problem for most task models is intractable (usually co-NP hard) and, hence, such an iterative design process is often very expensive. To get around this problem, we introduce the concept of “interactive” schedulability analysis. It is based on the observation that if only a small number of system parameters are changed, then it is not necessary to rerun the full schedulability analysis algorithm, thereby making the iterative design process considerably faster. We refer to this analysis as being “interactive” because it is supposed to be run in an interactive mode. This concept is fairly general and can be applied to a wide variety of task models. In this paper, we have chosen the recurring real-time task model, because it can be used to represent realistic applications from the embedded systems domain (containing conditional branches and fine-grained deadline constraints). Our experimental results show that using our scheme can lead to more than 20× speedup for each invocation of the schedulability analysis algorithm, compared to the case where the full algorithm is run.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2124717221",
    "type": "article"
  },
  {
    "title": "EACAN",
    "doi": "https://doi.org/10.1145/3301309",
    "publication_date": "2019-01-31",
    "publication_year": 2019,
    "authors": "Tae-Ju Park; Kang G. Shin",
    "corresponding_authors": "",
    "abstract": "Worst-case-based timing verification for the controller area network (CAN) has been the bottleneck to efficient use of its bandwidth. Especially, this inefficiency comes from the worst-case transmission error rate (WCTER) when transmission errors are accounted for. To alleviate this inefficiency, we propose a runtime adaptation scheme, error-adaptive CAN (EACAN). EACAN observes the behavior of transmission errors at runtime, and reconfigures the message period based on the observation to meet the timing-failure requirement. We experimentally evaluate the bandwidth utilization of both EACAN- and WCTER-based verification, showing that the former improves the bandwidth utilization by 14% over the latter.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2914858007",
    "type": "article"
  },
  {
    "title": "Contention-Detectable Mechanism for Receiver-Initiated MAC",
    "doi": "https://doi.org/10.1145/3317683",
    "publication_date": "2019-06-10",
    "publication_year": 2019,
    "authors": "Daibo Liu; Zhichao Cao; Mingyan Liu; Mengshu Hou; Hongbo Jinag",
    "corresponding_authors": "",
    "abstract": "The energy efficiency and delivery robustness are two critical issues for low duty-cycled wireless sensor networks. The asynchronous receiver-initiated duty-cycling media access control (MAC) protocols have shown their effectiveness through various studies. In receiver-initiated MACs, packet transmission is triggered by the probe of receiver. However, it suffers from the performance degradation incurred by packet collision, especially under bursty traffic. Several protocols have been proposed to address this problem, but their performance is restricted by the unnecessary backoff time and long negotiation process. In this article, we present CD-MAC, an energy-efficient and robust contention-detectable mechanism for addressing the collision-catching problem in receiver-initiated MACs. By exploring the temporal diversity of the acknowledgments, a receiver recognizes the potential senders and subsequently polls individual senders one by one. On that basis, CD-MAC can successfully avoid packet collision even though multiple senders have data packets to transmit to the same receiver. We implement CD-MAC in TinyOS and evaluate its performance on an indoor testbed with single-hop and multi-hop network scenarios. The results show that CD-MAC can significantly improve throughput by 1.72 times compared with the state-of-the-art receiver-initiated MAC protocol under bursty traffic loads. The results also demonstrate that CD-MAC can effectively mitigate the influence of hidden terminal problem and adapt to network dynamics well.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2952407108",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3325115",
    "publication_date": "2019-05-31",
    "publication_year": 2019,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2965197714",
    "type": "editorial"
  },
  {
    "title": "Memory-Efficient Mixed-Precision Implementations for Robust Explicit Model Predictive Control",
    "doi": "https://doi.org/10.1145/3358223",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Mahmoud Salamati; Rocco Salvia; Eva Darulová; Sadegh Soudjani; Rupak Majumdar",
    "corresponding_authors": "",
    "abstract": "We propose an optimization for space-efficient implementations of explicit model-predictive controllers (MPC) for robust control of linear time-invariant (LTI) systems on embedded platforms. We obtain an explicit-form robust model-predictive controller as a solution to a multi-parametric linear programming problem. The structure of the controller is a polyhedral decomposition of the control domain, with an affine map for each domain. While explicit MPC is suited for embedded devices with low computational power, the memory requirements for such controllers can be high. We provide an optimization algorithm for a mixed-precision implementation of the controller, where the deviation of the implemented controller from the original one is within the robustness margin of the robust control problem. The core of the mixed-precision optimization is an iterative static analysis that co-designs a robust controller and a low-bitwidth approximation that is statically guaranteed to always be within the robustness margin of the original controller. We have implemented our algorithm and show on a set of benchmarks that our optimization can reduce space requirements by up to 20.9% and on average by 12.6% compared to a minimal uniform precision implementation of the original controller.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2979330738",
    "type": "article"
  },
  {
    "title": "Sample Essentiality and Its Application to Modeling Attacks on Arbiter PUFs",
    "doi": "https://doi.org/10.1145/3344148",
    "publication_date": "2019-09-30",
    "publication_year": 2019,
    "authors": "Siwen Zhu; Yi Tang; Junxiang Zheng; Yongzhi Cao; Hanpin Wang; Yu Huang; Marian Margraf",
    "corresponding_authors": "",
    "abstract": "Physically Unclonable Functions (PUFs), as an alternative hardware-based security method, have been challenged by some modeling attacks. As is known to all, samples are significant in modeling attacks on PUFs, and thus, some efforts have been made to expand sample sets therein to improve modeling attacks. A closer examination, however, reveals that not all samples contribute to modeling attacks equally. Therefore, in this article, we introduce the concept of sample essentiality for describing the contribution of a sample in modeling attacks and point out that any sample without sample essentiality cannot enhance some modeling attacks on PUFs. As a by-product, we find theoretically and empirically that the samples expanded by the procedures proposed by Chatterjee et al. do not satisfy our sample essentiality. Furthermore, we propose the notion of essential sample sets for datasets and discuss its basic properties. Finally, we demonstrate that our results about sample essentiality can be used to reduce samples efficiently and benefit sample selection in modeling attacks on arbiter PUFs.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2979568796",
    "type": "article"
  },
  {
    "title": "Multi-objective Exploration for Practical Optimization Decisions in Binary Translation",
    "doi": "https://doi.org/10.1145/3358185",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Sunghyun Park; Youfeng Wu; Janghaeng Lee; Amir Aupov; Scott Mahlke",
    "corresponding_authors": "",
    "abstract": "In the design of mobile systems, hardware/software (HW/SW) co-design has important advantages by creating specialized hardware for the performance or power optimizations. Dynamic binary translation (DBT) is a key component in co-design. During the translation, a dynamic optimizer in the DBT system applies various software optimizations to improve the quality of the translated code. With dynamic optimization, optimization time is an exposed run-time overhead and useful analyses are often restricted due to their high costs. Thus, a dynamic optimizer needs to make smart decisions with limited analysis information, which complicates the design of optimization decision models and often causes failures in human-made heuristics. In mobile systems, this problem is even more challenging because of strict constraints on computing capabilities and memory size. To overcome the challenge, we investigate an opportunity to build practical optimization decision models for DBT by using machine learning techniques. As the first step, loop unrolling is chosen as the representative optimization. We base our approach on the industrial strength DBT infrastructure and conduct evaluation with 17,116 unrollable loops collected from 200 benchmarks and real-life programs across various domains. By utilizing all available features that are potentially important for loop unrolling decision, we identify the best classification algorithm for our infrastructure with consideration for both prediction accuracy and cost. The greedy feature selection algorithm is then applied to the classification algorithm to distinguish its significant features and cut down the feature space. By maintaining significant features only, the best affordable classifier, which satisfies the budgets allocated to the decision process, shows 74.5% of prediction accuracy for the optimal unroll factor and realizes an average 20.9% reduction in dynamic instruction count during the steady-state translated code execution. For comparison, the best baseline heuristic achieves 46.0% prediction accuracy with an average 13.6% instruction count reduction. Given that the infrastructure is already highly optimized and the ideal upper bound for instruction reduction is observed at 23.8%, we believe this result is noteworthy.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2979633330",
    "type": "article"
  },
  {
    "title": "AuthCropper",
    "doi": "https://doi.org/10.1145/3358195",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Jihye Kim; Jiwon Lee; Hankyung Ko; Donghwan Oh; Semin Han; Gwonho Jeong; Hyunok Oh",
    "corresponding_authors": "",
    "abstract": "As surveillance systems are popular, the privacy of the recorded video becomes more important. On the other hand, the authenticity of video images should be guaranteed when used as evidence in court. It is challenging to satisfy both (personal) privacy and authenticity of a video simultaneously, since the privacy requires modifications (e.g., partial deletions) of an original video image while the authenticity does not allow any modifications of the original image. This paper proposes a novel method to convert an encryption scheme to support partial decryption with a constant number of keys and construct a privacy-aware authentication scheme by combining with a signature scheme. The security of our proposed scheme is implied by the security of the underlying encryption and signature schemes. Experimental results show that the proposed scheme can handle the UHD video stream with more than 17 fps on a real embedded system, which validates the practicality of the proposed scheme.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2979950163",
    "type": "article"
  },
  {
    "title": "Analyzing Variable Entanglement for Parallel Simulation of SystemC TLM-2.0 Models",
    "doi": "https://doi.org/10.1145/3358194",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Zhongqi Cheng; Rainer Dömer",
    "corresponding_authors": "",
    "abstract": "The SystemC TLM-2.0 standard is widely used in modern electronic system level design for better interoperability and higher simulation speed. However, TLM-2.0 has been identified as an obstacle for parallel SystemC simulation due to the disappearance of channels. Without a containment construct, simulation threads are permitted to directly access data of other modules and that makes it difficult to synchronize such accesses as required by the SystemC execution semantics. In this paper, we propose a compile time approach to statically analyze potential conflicts among threads in SystemC TLM-2.0 loosely- and approximately-timed models. We introduce a new Socket Call Path technique which provides the compiler with socket binding information for precise static analysis. We also propose an algorithm to analyze entangled variable pairs. Experimental results show that our approach is able to support automatically safe parallel simulation of SystemC models with TLM-2.0 Blocking Transport Interface, Direct Memory Interface and Non-blocking Transport Interface, resulting in impressive simulation speeds.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2980132578",
    "type": "article"
  },
  {
    "title": "MxU",
    "doi": "https://doi.org/10.1145/3358224",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Runyu Pan; Gabriel Parmer",
    "corresponding_authors": "",
    "abstract": "The advanced functionality requirements of modern embedded and Internet of Things (IoT) devices -- from autonomous vehicles, to city and power-grid management -- are driving an ever-increasing software complexity. At the same time, the pervasive internet connections of these systems necessitate the fundamental design of security into these devices. The isolation of complex features from those that are critical through protection domains is an effective means to constrain the scope of faults and security breaches. Common hardware-provided memory facilities to enforce protection domains through memory access control -- including Memory Management Units (MMUs) usually found in microprocessors, and Memory Protection Units (MPUs) usually found in microcontrollers -- must meet the goals of enabling flexible, efficient and dynamic management of memory , and must enable tight bounds on the worst-case execution of critical code. Unfortunately, current system memory management facilities are ill-prepared to handle this challenge: MMUs that use extensive caches to achieve strong average-case performance suffer from debilitating worst-case and even average-case behavior under hefty interference, while MPUs struggle to provide flexible memory management. This paper details MxU, a memory protection and allocation abstraction that integrates temporal specifications into the memory management subsystem, to enable portable code to achieve both predictable, tightly-bounded execution and dynamic management across both MMU- and MPU-based systems. We implement MxU in the Composite microkernel, and evaluate its flexibility and predictability over two different architectures: a MPU-based Cortex-M7 microcontroller and a MMU-based Cortex-A9 microprocessor using a suite of modern applications including neural network-based inference, SQLite, and a javascript runtime. For MMU-based systems, MxU reduces application TLB stall by up to 68.0%. For MPU-based systems, MxU enables flexible dynamic memory management often with application overheads of 1%, increasing to 6.1% under significant interference.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2980240007",
    "type": "article"
  },
  {
    "title": "Output-based Intermediate Representation for Translation of Test-pattern Program",
    "doi": "https://doi.org/10.1145/3358186",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Minsu Kim; Jeong-Keun Park; Sungyeol Kim; Insu Yang; Hyun-Soo Jung; Soo‐Mook Moon",
    "corresponding_authors": "",
    "abstract": "An Intermediate Representation (IR) used by compilers is normally generated statically , as a result of parsing or analyzing the source program. This paper proposes a completely different type of IR, generated as a result of running the source program, the output-based IR . There is a practical translation problem where such an IR is useful, in the domain of test-pattern programs . Test-pattern programs run on ATE (automatic test equipment), a special embedded system to test semiconductors such as DRAMs. They generate a pattern for each clock, a bit vector input to the pins of the chip. One issue is that different ATEs require different programming since each ATE manufacturer has its own programming language. Nonetheless, we should be able to test a memory chip on different ATEs as long as they generate the same patterns with the same speed. Therefore, a memory chipmaker wants to make a pattern program portable across ATEs, to fully utilize their ATE resources. One solution is translating between pattern programs, for which we need an IR since there are multiple source ATEs and target ATEs. Instead of a conventional, static IR, we propose using the output pattern itself as an IR. Since the pattern is independent of ATEs and easily obtainable, the output-based IR obviates designing a static IR considering all ATE programming languages and hardware differences. Moreover, we might synthesize a better target program from the IR, more optimized to the target ATE. However, the full pattern generated by a product-level pattern program is huge, so we propose using an IR of abbreviated patterns, annotated with the repetition information obtained while executing the source program. Our experimental results with product-level pattern programs show that our approach is feasible.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3001428362",
    "type": "article"
  },
  {
    "title": "Automated Model-Based Optimization of Data-Adaptable Embedded Systems",
    "doi": "https://doi.org/10.1145/3372142",
    "publication_date": "2020-01-31",
    "publication_year": 2020,
    "authors": "Adrian Lizarraga; Jonathan Sprinkle; Roman Lysecky",
    "corresponding_authors": "",
    "abstract": "Dynamic data-driven applications such as object tracking, surveillance, and other sensing and decision applications are largely dependent on the characteristics of the data streams on which they operate. The underlying models and algorithms of data-driven applications must continually adapt at runtime to changes in data quality and availability to meet both functional and designer-specified performance requirements. Given the dynamic nature of these applications, point solutions produced by traditional design tools cannot be expected to perform adequately across varying execution scenarios. Additionally, the increasing diversity and interdependence of application requirements complicates the design and optimization process. To assist designers of data-driven applications, we present a modeling and optimization framework that enables developers to model an application's data sources, tasks, and exchanged data tokens; specify application requirements through high-level design metrics and fuzzy logic--based optimization rules; and define an estimation framework to automatically optimize the application at runtime. We demonstrate the modeling and optimization process via an example application for video-based vehicle tracking and collision avoidance. We analyze the benefits of runtime optimization by comparing the performance of static point solutions to dynamic solutions over five distinct execution scenarios, showing improvements of up to 74% for dynamic over static configurations. Further, we show the benefits of using fuzzy logic--based rules over traditional weighted functions for the specification and evaluation of competing high-level metrics in optimization.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3009175151",
    "type": "article"
  },
  {
    "title": "Adapting Recursive Sinusoidal Software Oscillators for Low-power Fixed-point Processors",
    "doi": "https://doi.org/10.1145/3378559",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Hugues Smeets; Matteo Ceriotti; Pedro José Marrón",
    "corresponding_authors": "",
    "abstract": "The growing field of the Internet of Things relies at the bottom on components with very scarce computing resources that currently do not allow complex processing of sensed data. Any computation involving Fast Fourier Transforms (FFT), Wavelet Transforms (WT), or simple sines and cosines is considered impractical on low-end devices due to the lack of floating point and math libraries. This article presents new techniques that make it possible to use these functions also on severely constrained target platforms. Current literature abounds with schemes to compute sine and cosine functions, with focus on speed, hardware footprint, software size, target type, or precision. Even so, there is no practical exploration of the design space available for embedded devices with limited resources, in particular when only integer operations are possible. We select an efficient set of recursive sine and cosine generators and measure the frequency, amplitude, and phase error over a wide parameter range. We show that their simplicity allows them to be implemented on the most bare targets with good precision, reducing power consumption and size while being the fastest on integer-only processors. We also introduce specially tailored FFT and WT algorithms and show that they are usable in practice while having an extremely small code footprint, good precision, and high speed.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3028645234",
    "type": "article"
  },
  {
    "title": "Firmness Analysis of Real-time Tasks",
    "doi": "https://doi.org/10.1145/3398328",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Amir Behrouzian; Hadi Alizadeh Ara; Marc Geilen; Dip Goswami; Twan Basten",
    "corresponding_authors": "",
    "abstract": "( m , k )-firm real-time tasks require meeting the deadline of at least m jobs out of any k consecutive jobs. When compared to hard real-time tasks, ( m , k )$-firm tasks open up the possibility of tighter resource-dimensioning in implementations. Firmness analysis verifies the satisfaction of ( m , k )-firmness conditions. Scheduling policies under which a set of periodic tasks runs on a resource influence the number of deadline missed jobs. Therefore, the nature of the firmness analysis problem depends on scheduling policies. In this work, we present Firmness Analysis (FAn) methods for three common scheduling policies—synchronous and asynchronous Static Priority Preemptive (SPP) policies and Time Division Multiple Access (TDMA). We first introduce the Balloon and Rake problem—the problem of striking the maximum number of balloons in a balloon line with a rake. We show that the common core of firmness analysis problems can be abstracted as the Balloon and Rake problem. Next, we prove that the Finite Point method is a solution to the Balloon and Rake problem. We illustrate how existing FAn methods for the TDMA and asynchronous SPP policies can be adapted to use the same solution framework for the Balloon and Rake problem. Using the solution of the Balloon and Rake problem, we adapt the existing FAn methods to synchronous SPP scheduling policies. The scalability of the FAn methods is compared with that of a timed-automata approach, a brute-force approach, and a Mixed Integer Linear Programing method. The FAn methods scale substantially better to firmness analysis problem instances with a large k and a high number of tasks.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3040881072",
    "type": "article"
  },
  {
    "title": "ATCN: Resource-efficient Processing of Time Series on Edge",
    "doi": "https://doi.org/10.1145/3524070",
    "publication_date": "2022-03-21",
    "publication_year": 2022,
    "authors": "Mohammadreza Baharani; Hamed Tabkhi",
    "corresponding_authors": "",
    "abstract": "This paper presents a scalable deep learning model called Agile Temporal Convolutional Network (ATCN) for high-accurate fast classification and time series prediction in resource-constrained embedded systems. ATCN is a family of compact networks with formalized hyperparameters that enable application-specific adjustments to be made to the model architecture. It is primarily designed for embedded edge devices with very limited performance and memory, such as wearable biomedical devices and real-time reliability monitoring systems. ATCN makes fundamental improvements over the mainstream temporal convolutional neural networks, including residual connections to increase the network depth and accuracy, and the incorporation of separable depth-wise convolution to reduce the computational complexity of the model. As part of the present work, two ATCN families, namely T0, and T1 are also presented and evaluated on different ranges of embedded processors - Cortex-M7 and Cortex-A57 processor. An evaluation of the ATCN models against the best-in-class InceptionTime and MiniRocket shows that ATCN almost maintains accuracy while improving the execution time on a broad range of embedded and cyber-physical applications with demand for real-time processing on the embedded edge. At the same time, in contrast to existing solutions, ATCN is the first time-series classifier based on deep learning that can be run bare-metal on embedded microcontrollers (Cortex-M7) with limited computational performance and memory capacity while delivering state-of-the-art accuracy.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3187648707",
    "type": "article"
  },
  {
    "title": "Design and Scaffolded Training of an Efficient DNN Operator for Computer Vision on the Edge",
    "doi": "https://doi.org/10.1145/3511212",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Vinod Ganesan; Pratyush Kumar",
    "corresponding_authors": "",
    "abstract": "Massively parallel systolic arrays and resource-efficient depthwise separable convolutions are two promising hardware and software techniques to accelerate DNN inference on the edge. Interestingly, their combination is inefficient: Computational patterns of depthwise separable convolutions do not exhibit a rhythmic systolic flow and lack sufficient data reuse to saturate systolic arrays. In this article, we formally analyse this inefficiency and propose an efficient operator, an optimal hardware dataflow, and a superior training methodology towards alleviating this. The efficient operator, called Fully-Separable Convolutions (FuSeConv) , 1 is a drop-in replacement for depthwise-separable convolutions. FuSeConv generalizes factorization of convolution fully along their spatial and depth dimensions. The resultant computation is systolic and efficiently maps to systolic arrays. The optimal hardware dataflow, called Spatial-Tiled Output Stationary (ST-OS) , maximizes the efficiency of FuSeConv on systolic arrays. It maps independent convolutions to rows of the systolic array to maximise resource-utilization with negligible VLSI overheads. Neural Operator Scaffolding (NOS) scaffolds the training of FuSeConv operators by distilling knowledge from the more expensive depthwise separable convolution operation. This bridges the accuracy gap between FuSeConv networks and networks with depthwise-separable convolutions. Additionally, NOS can be combined with Neural Architecture Search (NAS) to trade off latency and accuracy. The hardware-software co-design of FuSeConv with ST-OS achieves a significant speedup of 4.1-9.25× with state-of-the-art efficient networks for the ImageNet dataset. The parameter efficiency of FuSeConv and its significant superiority over depthwise-separable convolutions on systolic arrays illustrates their promise as a strong solution on the edge. Training FuSeConv networks with NOS achieves accuracy comparable to the depthwise-separable convolution baselines. Further, by combining NOS with NAS, we design networks that define state-of-the-art models improving on both accuracy and latency for computer vision on systolic arrays.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3195227524",
    "type": "article"
  },
  {
    "title": "How to Enable Index Scheme for Reducing the Writing Cost of DNA Storage on Insertion and Deletion",
    "doi": "https://doi.org/10.1145/3516482",
    "publication_date": "2022-03-02",
    "publication_year": 2022,
    "authors": "Yi‐Syuan Lin; Yu-Pei Liang; Tseng‐Yi Chen; Yuan-Hao Chang; Shuo-Han Chen; Hsin‐Wen Wei; Wei‐Kuan Shih",
    "corresponding_authors": "",
    "abstract": "Recently, the requirement of storing digital data has been growing rapidly; however, the conventional storage medium cannot satisfy these huge demands. Fortunately, thanks to biological technology development, storing digital data into deoxyribonucleic acid (DNA) has become possible in recent years. Furthermore, because of the attractive features (e.g., high storing density, long-term durability, and stability), DNA storage has been regarded as a potential alternative storage medium to store massive digital data in the future. Nevertheless, reading and writing digital data over DNA requires a series of extremely time-consuming processes (i.e., DNA sequencing and DNA synthesis). More specifically, among the two costs, the writing cost is the predominant cost of a DNA data storage system. Therefore, to enable efficient DNA storage, this article proposes an index management scheme for reducing the number of accesses to DNA storage. Additionally, this article introduces a new DNA data encoding format with VERA (Version Editing Recovery Approach) to reduce the total writing bits while inserting and deleting the data. To the best of our knowledge, this work is the first work to provide a total data management solution for DNA storage. According to the experimental results, the proposed design with VERA can reduce the cost by 77% and improve the performance by 71% compared to the append-only methods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4214862664",
    "type": "article"
  },
  {
    "title": "WasmAndroid: A Cross-Platform Runtime for Native Programming Languages on Android",
    "doi": "https://doi.org/10.1145/3530286",
    "publication_date": "2022-04-14",
    "publication_year": 2022,
    "authors": "Elliott Wen; Gerald Weber; Suranga Nanayakkara",
    "corresponding_authors": "",
    "abstract": "Open source hardware such as RISC-V has been gaining substantial momentum. Recently, they have begun to embrace Google’s Android operating system to leverage its software ecosystem. Despite the encouraging progress, a challenging issue arises: a majority of Android applications are written in native languages and need to be recompiled to target new hardware platforms. Unfortunately, this recompilation process is not scalable because of the explosion of new hardware platforms. To address this issue, we present WasmAndroid, a high-performance cross-platform runtime for native Android applications. With WasmAndroid, developers can compile their source code to WebAssembly, an efficient and portable bytecode format that can be executed everywhere without additional reconfiguration. Developers can also transpile existing application binaries to WebAssembly when source code is not available. WebAssembly’s language model is very different from other common languages. This mismatch leads to many unique implementation challenges. In this article, we provide workable solutions and conduct a thorough system evaluation. We show that WasmAndroid provides acceptable performance to execute native applications in a cross-platform manner.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4223913900",
    "type": "article"
  },
  {
    "title": "EdgeWise: Energy-efficient CNN Computation on Edge Devices under Stochastic Communication Delays",
    "doi": "https://doi.org/10.1145/3530908",
    "publication_date": "2022-04-20",
    "publication_year": 2022,
    "authors": "Mehdi Ghasemi; Daler Rakhmatov; Carole-Jean Wu; Sarma Vrudhula",
    "corresponding_authors": "",
    "abstract": "This article presents a framework to enable the energy-efficient execution of convolutional neural networks (CNNs) on edge devices. The framework consists of a pair of edge devices connected via a wireless network: a performance and energy-constrained device D as the first recipient of data and an energy-unconstrained device N as an accelerator for D . Device D decides on-the-fly how to distribute the workload with the objective of minimizing its energy consumption while accounting for the inherent uncertainty in network delay and the overheads involved in data transfer. These challenges are tackled by adopting the data-driven modeling framework of Markov Decision Processes, whereby an optimal policy is consulted by D in O (1) time to make layer-by-layer assignment decisions. As a special case, a linear-time dynamic programming algorithm is also presented for finding optimal layer assignment at once, under the assumption that the network delay is constant throughout the execution of the application. The proposed framework is demonstrated on a platform comprised of a Raspberry PI 3 as D and an NVIDIA Jetson TX2 as N . An average improvement of 31% and 23% in energy consumption is achieved compared to the alternatives of executing the CNNs entirely on D and N . Two state-of-the-art methods were also implemented and compared with the proposed methods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4224292997",
    "type": "article"
  },
  {
    "title": "wfspan: Wait-free Dynamic Memory Management",
    "doi": "https://doi.org/10.1145/3533724",
    "publication_date": "2022-05-04",
    "publication_year": 2022,
    "authors": "Xiangzhen Ouyang; Yian Zhu",
    "corresponding_authors": "",
    "abstract": "Dynamic memory allocation plays a vital role in modern application programs. Modern lock-free memory allocators based on hardware atomic primitives usually provide good performance. However, threads may starve in these lock-free implementations, leading to unbounded worst-case execution time that is not allowed in real-time embedded systems. This article presents decentralized dynamic memory management, wfspan, based on non-linearizable wait-free lists. It employs a helping mechanism to ensure no starvation in the lock-free implementation. From the perspective of design tradeoff, wfspan guarantees bounded execution steps in both allocation and deallocation procedure, at the cost of increasing bounded worst-case memory footprint. The results of running benchmarks on an x86/64 and an aarch64 machine illustrate that wfspan achieves competitive performance and memory footprint compared to lock-based and lock-free practical memory allocators while showing superior to other allocators in terms of worst-case execution time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4228997814",
    "type": "article"
  },
  {
    "title": "Early SoCs Information Flow Policies Validation using SystemC-based Virtual Prototypes at the ESL",
    "doi": "https://doi.org/10.1145/3544780",
    "publication_date": "2022-06-22",
    "publication_year": 2022,
    "authors": "Mehran Goli; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "Virtual Prototypes (VPs) at the Electronic System Level (ESL) are being increasingly adopted by the semiconductor industry and play an important role in modernizing the System-on-Chips (SoCs) design flow to raise design productivity and reduce time-to-market constraints. Due to their early availability and significantly faster simulation speed in comparison to Register Transfer Level (RTL) designs, VPs are used as reference models for lower levels of abstraction. Leveraging VPs and extending their use cases for early security validation are shown as a promising direction. As the cost of fixing any security flaws increases with the stage of development, VP-based security validation can significantly avoid costly iterations. In this article, we present a novel VP-based dynamic information flow analysis approach at the ESL, consisting of three main phases which are runtime behavior extraction (in terms of transactions), transactions transformation, and security validation. The proposed approach empowers designers to validate the information flow policies of a given VP-based SoC against the most occurring security threat models which are information leakage (confidentiality) and unauthorized access to data in a memory (integrity). Experimental results including an extensive set of standard benchmarks and two real-world VP-based SoCs demonstrate the scalability and applicability of the proposed approach.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4283327031",
    "type": "article"
  },
  {
    "title": "From Lustre to Graphical Models and SCCharts",
    "doi": "https://doi.org/10.1145/3544973",
    "publication_date": "2022-07-29",
    "publication_year": 2022,
    "authors": "Lena Grimm; Steven Smyth; Alexander Schulz-Rosengarten; Reinhard von Hanxleden; Marc Pouzet",
    "corresponding_authors": "",
    "abstract": "We introduce a systematic approach for automatically creating a visual diagram, akin to the graphical Safety Critical Application Development Environment (SCADE) model, from a Lustre program. This not only saves tedious manual drawing effort but also enables modeling software to automatically provide the developer with different meaningful views for the same program. We also extend the Sequentially Constructive Charts (SCCharts) language with data-flow constructs that adhere to the Lustre semantics, which permits a translation from Lustre to graphical SCCharts. This allows using the SCCharts code generation, simulation, and visualization tooling also for Lustre programs, in addition to the already existing Lustre compilation techniques. Furthermore, we investigate how the sequentially constructive model of computation, used in SCCharts and other synchronous languages, can be used to conservatively extend Lustre. We have implemented and validated this work with the Eclipse-based open-source Kiel Integrated Environment for Layout Eclipse Rich Client (KIELER) framework.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4288708931",
    "type": "article"
  },
  {
    "title": "K-Periodic Scheduling for Throughput-Buffering Trade-Off Exploration of CSDF",
    "doi": "https://doi.org/10.1145/3559760",
    "publication_date": "2022-09-14",
    "publication_year": 2022,
    "authors": "Jaime Koh; Bruno Bodin",
    "corresponding_authors": "",
    "abstract": "The design of time-critical embedded systems often requires static models of computation such as cyclo-static dataflow. These models enable performance guarantees, execution correctness, and optimized memory usage. Nonetheless, determining optimal buffer sizing of dataflow applications remains difficult: existing methods offer either approximate solutions or fail to provide solutions for complex instances. We propose a throughput-buffering trade-off exploration that uses K-periodic scheduling to direct a design-space exploration—providing optimal solutions while significantly reducing the search space compared to existing methodologies. We compare this strategy against previous approaches and demonstrate search-space reductions over two benchmark suites, resulting in significant improvements in computation times while retaining optimal results.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4295678840",
    "type": "article"
  },
  {
    "title": "Toward Optimal Softcore Carry-aware Approximate Multipliers on Xilinx FPGAs",
    "doi": "https://doi.org/10.1145/3564243",
    "publication_date": "2022-09-21",
    "publication_year": 2022,
    "authors": "Muhammad Awais; Ali Zahir; Syed Ayaz Ali Shah; Pedro Reviriego; Anees Ullah; Nasim Ullah; Adam Khan; Hazrat Ali",
    "corresponding_authors": "",
    "abstract": "Domain-specific accelerators for signal processing, image processing, and machine learning are increasingly being implemented on SRAM-based field-programmable gate arrays (FPGAs). Owing to the inherent error tolerance of such applications, approximate arithmetic operations, in particular, the design of approximate multipliers, have become an important research problem. Truncation of lower bits is a widely used approximation approach; however, analyzing and limiting the effects of carry-propagation due to this approximation has not been explored in detail yet. In this article, an optimized carry-aware approximate radix-4 Booth multiplier design is presented that leverages the built-in slice look-up tables (LUTs) and carry-chain resources in a novel configuration. The proposed multiplier simplifies the computation of the upper and lower bits and provides significant benefits in terms of FPGA resource usage (LUTs saving 38.5%–42.9%), Power Delay Product (PDP saving 49.4%–53%), performance metric (LUTs × critical path delay (CPD) × PDP saving 68.9%–73.1%) and errors (70% improvement in mean relative error distance) compared to the latest state-of-the-art designs. Therefore, the proposed designs are an attractive choice to implement multiplication on FPGA-based accelerators.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4296712235",
    "type": "article"
  },
  {
    "title": "A Methodology for Fault-tolerant Pareto-optimal Approximate Designs of FPGA-based Accelerators",
    "doi": "https://doi.org/10.1145/3568021",
    "publication_date": "2022-10-14",
    "publication_year": 2022,
    "authors": "Ioannis Tsounis; Dimitris Agiakatsikas; Mihalis Psarakis",
    "corresponding_authors": "",
    "abstract": "Approximate Computing Techniques (ACTs) take advantage of resilience computing applications to trade off among output precision, area, power, and performance. ACTs can lead to significant gains at affordable costs when efficiently implemented on Field Programmable Gate Array– (FPGA) based accelerators. Although several novel ACTs works have been proposed for FPGA accelerators, their applicability to high-assurance systems has not been explored as much. ACTs are becoming necessary in many critical Edge computing systems, such as self-driving cars and Earth observation satellites, to increase computational efficiency. However, an important question comes to mind when targeting critical systems: Does ACT optimization negatively affect the reliability of the system and how can one find optimal design architectures that blend classic mitigation techniques like Triple Modular Redundancy with approximation- and precise-based arithmetic hardware units to achieve the best possible computational efficiency without compromising dependability? This work aims to solve this research problem by introducing a Design Space Exploration (DSE) methodology that employs ACTs in arithmetic units of the design and identifies Pareto-optimal microarchitectures that balance all relevant gains of ACTs, such as area, speed, power, failure rate, and precision, by inserting the correct amount of approximation in the design. In a nutshell, our DSE methodology has formulated the DSE with a Multi-Objective Optimization Problem (MOP). Each Pareto-optimal solution of our tool finds which arithmetic units of the design to implement with precise and approximate circuits and which units to selectively triplicate to remove single points of failure that compromise system reliability below acceptable thresholds. We also suggest another formulation of the DSE into a Single-Objective constraint Optimization Problem (ScOP) producing a single optimal point, and that the user may demand, as a less time-consuming alternative to the MOP if a complete Pareto-front is not needed. Our methodology generates fault-tolerant versions of the Pareto-optimal approximate designs (or simple optimized approximate designs if the ScOP choice is picked) by selectively applying mitigation techniques in a way that the overheads of redundant resources for fault-tolerance do not negate the gains of approximation in comparison to the fault-tolerant versions of the precise design. We evaluate our method on two FPGA-based accelerators: a JPEG encoder and an H.264/Advanced Video Coding decoder. Our experimental results show significant gains in area, frequency, and power consumption without compromising output quality and system reliability compared to classic solutions that replicate all or a part of the resources of the precise design to increase dependability metrics.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4306174625",
    "type": "article"
  },
  {
    "title": "AQuA: A New Image Quality Metric for Optimizing Video Analytics Systems",
    "doi": "https://doi.org/10.1145/3568423",
    "publication_date": "2022-11-12",
    "publication_year": 2022,
    "authors": "Sibendu Paul; Utsav Drolia; Yuanming Hu; Srimat Chakradhar",
    "corresponding_authors": "",
    "abstract": "Millions of cameras at the edge are being deployed to power a variety of different deep learning applications. However, the frames captured by these cameras are not always pristine—they can be distorted due to lighting issues, sensor noise, compression etc. Such distortions not only deteriorate visual quality, they impact the accuracy of deep learning applications that process such video streams. In this work, we introduce AQuA, to protect application accuracy against such distorted frames by scoring the level of distortion in the frames. It takes into account the analytical quality of frames, not the visual quality, by learning a novel metric, classifier opinion score , and uses a lightweight, CNN-based, object-independent feature extractor. AQuA accurately scores distortion levels of frames and generalizes to multiple different deep learning applications. When used for filtering poor-quality frames at edge, it reduces high-confidence errors for analytics applications by 17%. Through filtering, and due to its low overhead (14 ms), AQuA can also reduce computation time and average bandwidth usage by 25%. Finally, we discuss numerous new avenues of optimizations of video analytics pipelines enabled by AQuA.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4309072534",
    "type": "article"
  },
  {
    "title": "Challenges and Opportunities of Security-Aware EDA",
    "doi": "https://doi.org/10.1145/3576199",
    "publication_date": "2022-12-14",
    "publication_year": 2022,
    "authors": "Jakob Feldtkeller; Pascal Sasdrich; Tim Güneysu",
    "corresponding_authors": "",
    "abstract": "The foundation of every digital system is based on hardware in which security, as a core service of many applications, should be deeply embedded. Unfortunately, the knowledge of system security and efficient hardware design is spread over different communities and, due to the complex and ever-evolving nature of hardware-based system security, state-of-the-art security is not always implemented in state-of-the-art hardware. However, automated security-aware hardware design seems to be a promising solution to bridge the gap between the different communities. In this work, we systematize state-of-the-art research with respect to security-aware Electronic Design Automation (EDA) and identify a modern security-aware EDA framework. As part of this work, we consider threats in the form of information flow, timing and power side channels, and fault injection, which are the fundamental building blocks of more complex hardware-based attacks. Based on the existing research, we provide important observations and research questions to guide future research in support of modern, holistic, and security-aware hardware design infrastructures.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4311476810",
    "type": "article"
  },
  {
    "title": "Crenel-Interval-Based Dynamic Power Management for Periodic Real-Time Systems",
    "doi": "https://doi.org/10.1145/2744197",
    "publication_date": "2015-09-24",
    "publication_year": 2015,
    "authors": "Guohui Li; Yi Zhang; Jianjun Li",
    "corresponding_authors": "",
    "abstract": "In order to save the energy consumption of real-time embedded systems, the integration of Dynamic Voltage and Frequency Scaling (DVFS) and Device Power Management (DPM) techniques has been well studied. In this article, we propose a new energy management scheme for periodic real-time tasks with implicit deadlines. We mainly focus on the DPM part by presenting a novel approach to the real-time DPM problem. Specifically, we first identify intervals for each device, which we refer to as Crenel Intervals, by partitioning the Earliest Deadline First (EDF) schedule of the tasks that need to access the device into successive intervals. The principle for identifying Crenel Intervals is that for each task, there is only one deadline located in each Crenel Interval. Next, targeting at a single device model and a multiple device model, respectively, we propose the CI-EDF and CI-EDF m algorithms to schedule task instances in each Crenel Interval, so as to form long and continuous slacks in each Crenel Interval but without jeopardizing any task deadlines. Then, the slack in the Crenel Intervals can be utilized to perform not only DPM, but also DVFS. The experimental results show that our approaches can achieve considerably more energy savings than existing techniques with comparable quality.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1965834394",
    "type": "article"
  },
  {
    "title": "Extended Instruction Exploration for Multiple-Issue Architectures",
    "doi": "https://doi.org/10.1145/2560039",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "I-Wei Wu; Jean Jyh-Jiun Shann; Wei‐Chung Hsu; Chung-Ping Chung",
    "corresponding_authors": "",
    "abstract": "In order to satisfy the growing demand for high-performance computing in modern embedded devices, several architectural and microarchitectural enhancements have been implemented in processor architectures. Extended instruction (EI) is often used for architectural enhancement, while issuing multiple instructions is a common approach for microarchitectural enhancement. The impact of combining both of these approaches in the same design is not well understood. While previous studies have shown that EI can potentially improve performance in some applications on certain multiple-issue architectures, the algorithms used to identify EI for multiple-issue architectures yield only limited performance improvement. This is because not all arithmetic operations are suited for EI for multiple-issue architectures. To explore the full potential of EI for multiple-issue architectures, two important factors need to be considered: (1) the execution performance of an application is dominated by critical (located on the critical path) and highly resource-contentious (i.e., having a high probability of being delayed during execution due to hardware resource limitations) operations, and (2) an operation may become critical and/or highly resource contentious after some operations are added to the EI. This article presents an EI exploration algorithm for multiple-issue architectures that focuses on these two factors. Simulation results show that the proposed algorithm outperforms previously published algorithms.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1985873246",
    "type": "article"
  },
  {
    "title": "Heuristics on Reachability Trees for Bicriteria Scheduling of Stream Graphs on Heterogeneous Multiprocessor Architectures",
    "doi": "https://doi.org/10.1145/2638553",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Avinash Malik; David Gregg",
    "corresponding_authors": "",
    "abstract": "In this article, we partition and schedule Synchronous Dataflow (SDF) graphs onto heterogeneous execution architectures in such a way as to minimize energy consumption and maximize throughput. Partitioning and scheduling SDF graphs onto homogeneous architectures is a well-known NP-hard problem. The heterogeneity of the execution architecture makes our problem exponentially challenging to solve. We model the problem as a weighted sum and solve it using novel state space exploration inspired from the theory of parallel automata. The resultant heuristic algorithm results in good scheduling when implemented in an existing stream framework.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1987491127",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Virtual Prototyping of Parallel and Embedded Systems (ViPES)",
    "doi": "https://doi.org/10.1145/2675739",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Diana Goehringer",
    "corresponding_authors": "Diana Goehringer",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1990403420",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2698230",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1992611335",
    "type": "editorial"
  },
  {
    "title": "Placement of Linked Dynamic Data Structures over Heterogeneous Memories in Embedded Systems",
    "doi": "https://doi.org/10.1145/2656208",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Miguel Peón-Quirós; Alexandros Bartzas; Stylianos Mamagkakis; Francky Catthoor; J.M. Mendı́as; Dimitrios Soudris",
    "corresponding_authors": "",
    "abstract": "Software applications use dynamic memory (allocated and deallocated in the system's heap) to handle dynamism in their working conditions. Embedded systems tend to include complex memory organizations but most techniques for dynamic memory management do not deal with the placement of data objects in physical memory modules. Additionally, the performance of hardware-controlled cache memories may be severely hindered when used with linked data structures. We therefore present a methodology to map dynamic data on the multilevel memory subsystem of embedded systems, taking advantage of any available memories (e.g., on-chip SRAMs) and avoiding interference with the cache memories. The resulting data placement uses an exclusive memory model and is compatible with existing techniques for managing static data. Our methodology helps the designer achieve reductions in energy consumption and execution time that can be obtained by an expert in an automated way while keeping control over the process through multiple configuration knobs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1997114610",
    "type": "article"
  },
  {
    "title": "OPLE",
    "doi": "https://doi.org/10.1145/2764458",
    "publication_date": "2015-09-09",
    "publication_year": 2015,
    "authors": "Mehdi Kamal; Ali Afzali‐Kusha; Saeed Safari; Massoud Pedram",
    "corresponding_authors": "",
    "abstract": "In this article, a heuristic custom instruction (CI) selection algorithm is presented. The proposed algorithm, which is called OPLE for “Optimization based on Partitioning and Local Exploration,” uses a combination of greedy and optimal optimization methods. It searches for the near-optimal solution by reducing the search space based on partitioning the identified CI set. The partitioning of the identified set guarantees the success of the algorithm independent of the size of the identified set. First, the algorithm finds the near-optimal CIs from the candidate CIs for each part. Next, the suggested CIs from different parts are combined to determine the final selected CI set. To improve the set of the selected CIs, the solution is evolved by calling the algorithm iteratively. The efficacy of the algorithm is assessed by comparing its performance to those of optimal and nonoptimal methods. A comparative study is performed for a number of benchmarks under different area budgets and I/O constraints. The results reveal higher speedups for the OPLE algorithm, especially for larger identified candidate sets and/or small area budgets compared to those of the nonoptimal solutions. Compared to the nonoptimal techniques, the proposed algorithm provides 30% higher speedup improvement on average. The maximum improvement is 117%. The results also demonstrate that in many cases OPLE is able to find the optimal solution.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2013537186",
    "type": "article"
  },
  {
    "title": "Passive code in synchronous programs",
    "doi": "https://doi.org/10.1145/2544375.2544387",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Jens Brandt; Klaus Schneider; Yu Bai",
    "corresponding_authors": "",
    "abstract": "The synchronous model of computation requires that in every step, inputs are read and outputs are synchronously computed as the reaction of the program. In addition, all internal variables are updated in parallel even though not all of these values might be required for the current and the future reaction steps. To avoid unnecessary computations, we present a compile-time optimization procedure that computes for every variable a condition that determines whether its value is required for current or future computations. In this sense, our optimizations allow us to identify passive code that can be disabled to avoid unnecessary computations and therefore to reduce the reaction time of programs or their energy consumption.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2027283759",
    "type": "article"
  },
  {
    "title": "Yield-enhancement schemes for multicore processor and memory stacked 3D ICs",
    "doi": "https://doi.org/10.1145/2567933",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Yu-Jen Huang; Jin-Fu Li",
    "corresponding_authors": "",
    "abstract": "A three-dimensional (3D) integrated circuit (IC) with multiple dies vertically connected by through-silicon-via (TSV) offers many benefits over current 2D ICs. Multicore logic-memory die stacking has been considered as one candidate for 3D ICs by utilizing the TSV to provide high data bandwidth between logic and memory. However, 3D ICs suffer from the low-yield issue. This article proposes effective yield-enhancement techniques for multicore die-stacked 3D ICs. Two reconfiguration schemes are proposed to logically swap the positions of cores in the dies of 3D ICs such that the yield of 3D ICs is increased. Two algorithms also are proposed to determine the reconfiguration effectively. Simulation results show that the proposed reconfiguration schemes can achieve a yield gain ranging from 1% to 11%.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2060527829",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2761728",
    "publication_date": "2015-05-21",
    "publication_year": 2015,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "editorial Free AccessEditorial: Schizoid Design for Critical Embedded Systems Editor: Sandeep K. Shukla Virginia Tech Virginia TechView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 14Issue 3May 2015 Article No.: 40epp 1–3https://doi.org/10.1145/2761728Published:21 May 2015Publication History 1citation240DownloadsMetricsTotal Citations1Total Downloads240Last 12 Months28Last 6 weeks14 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2215799312",
    "type": "editorial"
  },
  {
    "title": "Data Flow Transformation for Energy-Efficient Implementation of Givens Rotation--Based QRD",
    "doi": "https://doi.org/10.1145/2837025",
    "publication_date": "2016-01-13",
    "publication_year": 2016,
    "authors": "Namita Sharma; Preeti Ranjan Panda; Francky Catthoor; Min Li; Prashant Agrawal",
    "corresponding_authors": "",
    "abstract": "QR decomposition (QRD), a matrix decomposition algorithm widely used in embedded application domain, can be realized in a large number of valid processing sequences that differ significantly in the number of memory accesses and computations, and hence the overall implementation energy. With modern low-power embedded processors evolving toward register files with wide memory interfaces and vector functional units (FUs), data flow in these algorithms needs to be carefully devised to efficiently utilize the costly wide memory accesses and the vector FUs. In this article, we present an energy-efficient data flow transformation strategy for the Givens rotation--based QRD.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2235939644",
    "type": "article"
  },
  {
    "title": "Perpetuu",
    "doi": "https://doi.org/10.1145/2767128",
    "publication_date": "2015-12-08",
    "publication_year": 2015,
    "authors": "Adam Matthews; Stanislav Bobovych; Nilanjan Banerjee; J.P. Parkerson; Ryan Robucci; Chintan Patel",
    "corresponding_authors": "",
    "abstract": "The aftermath of a natural disaster is characterized by lack of a reliable medium for dissemination of information to survivors. The state-of-the-art emergency response systems rely on satellite radio-enabled devices, but survivors, unlike first responders, do not have access to such devices. To mitigate this problem, we present perpetuu, a solar-powered portable GIS microserver. The microserver node can be deployed in a disaster scene and can serve maps to survivors viewable on browsers of off-the-shelf mobile systems. The perpetuu nodes can form a wireless mesh to cover a large geographic region. A key innovation in the design of the perpetuu node is a tiered software and hardware architecture—the system combines a low-power micro-controller with a high-power micro-processor to provide a large spectrum of power states. perpetuu stays in its lowest power state most of the time, and it can in-vitro detect survivors using Wi-Fi sensing, and consequently wake up the higher-power tier to disseminate high-resolution maps on standard web browsers that provide directions to safe locations. The tiered design leverages hardware-assisted energy measurements and a wakeup controller to balance energy harvested from solar panels with energy consumed by the system. We evaluate perpetuu using measurements from our prototype and trace-based simulations, and show that it can function near-perpetually while serving maps to a large number of survivors.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2293060220",
    "type": "article"
  },
  {
    "title": "Bandwidth Optimization and Energy Management in Real-Time Wireless Networks",
    "doi": "https://doi.org/10.1145/2851498",
    "publication_date": "2016-03-07",
    "publication_year": 2016,
    "authors": "Gianluca Franchino; Giorgio Buttazzo; Mauro Marinoni",
    "corresponding_authors": "",
    "abstract": "In embedded systems operated by battery and interacting with the environment, a fundamental issue is the enforcement of real-time and energy constraints to guarantee a desired lifetime with a given performance. A lot of research has focused on energy management at the communication level; however, not many authors considered both real-time and energy requirements in wireless communication systems. This article proposes El-SMan, a power-aware framework working in combination with MAC layer communication protocols for maximizing battery lifetime in wireless networks of embedded systems with real-time constraints. Exploiting the flexibility in bandwidth requirements, El-SMan adapts stream parameters to balance performance versus energy consumption, taking both lifetime and message deadlines into account.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2302397828",
    "type": "article"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/2886417",
    "publication_date": "2016-03-11",
    "publication_year": 2016,
    "authors": "Seungmin Rho; Wenny Rahayu; Geyong Min",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2320326698",
    "type": "editorial"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/2885503",
    "publication_date": "2016-02-26",
    "publication_year": 2016,
    "authors": "Paolo Ienne; Jean-Pierre Talpin",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2323037588",
    "type": "editorial"
  },
  {
    "title": "Live-Out Register Fencing",
    "doi": "https://doi.org/10.1145/2873058",
    "publication_date": "2016-05-11",
    "publication_year": 2016,
    "authors": "Ronaldo Rodrigues Ferreira; Gabriel L. Nazar; Jean Da Rolt; Álvaro Moreira; Luigi Carro",
    "corresponding_authors": "",
    "abstract": "This article introduces Live-Out Register Fencing (LoRF), a soft error correction mechanism that uses the novel Spill Register File as a container of checkpointing data. LoRF’s Spill Register File holds the values shared among basic blocks in the program, and, coupled with a new compilation strategy, LoRF allows for error correction in the same basic block where the error was detected. In LoRF, error correction is triggered by a hardware interrupt that restores the registers of a basic block from the Spill Register File. After these registers are restored, the basic block where the error was detected can just be re-executed, thus reducing the costs of error recovery. LoRF’s error correction policy eliminates the need for expensive architectural support for checkpointing and rollback, reducing the performance overhead of online soft error correction. LoRF relies on both a modified processor architecture and a corresponding compiler. The architecture was implemented in synthesizable VHDL, whereas the compiler was developed as an extension of the LLVM framework. Fault injection experiments support an error correction coverage of 99.35% and a mean performance overhead of 1.33 for the entire life cycle of an error from its occurrence to its elimination from the system.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2370036963",
    "type": "article"
  },
  {
    "title": "On the Improved Hard Real-Time Scheduling of Cyclo-Static Dataflow",
    "doi": "https://doi.org/10.1145/2932188",
    "publication_date": "2016-08-02",
    "publication_year": 2016,
    "authors": "Jelena Spasic; Di Liu; Emanuele Cannella; Todor Stefanov",
    "corresponding_authors": "",
    "abstract": "Recently, it has been shown that the hard real-time scheduling theory can be applied to streaming applications modeled as acyclic Cyclo-Static Dataflow (CSDF) graphs. However, this recent approach is not always efficient in terms of throughput and processor utilization. Therefore, in this article, we propose an improved hard real-time scheduling approach to schedule streaming applications modeled as acyclic CSDF graphs on a Multiprocessor System-on-Chip (MPSoC) platform. The proposed approach converts each actor in a CSDF graph to a set of real-time periodic tasks. The conversion enables application of many hard real-time scheduling algorithms that offer fast calculation of the required number of processors for scheduling the tasks. In addition, we propose a method to reduce the graph latency when the converted tasks are scheduled as real-time periodic tasks. We evaluate the performance and time complexity of our approach in comparison to several existing scheduling approaches. Experiments on a set of real-life streaming applications demonstrate that our approach (1) results in systems with higher throughput and better processor utilization in comparison to the existing hard real-time scheduling approach for CSDF graphs, while requiring comparable time for the system derivation; (2) delivers shorter application latency by applying the proposed method for graph latency reduction while providing better throughput and processor utilization when compared to the existing hard real-time scheduling approach; (3) gives the same throughput as the existing periodic scheduling approach for CSDF graphs, but requires much shorter time to derive the task schedule and tasks’ parameters (periods, start times, and so on); and (4) gives the throughput that is equal to or very close to the maximum achievable throughput of an application obtained via self-timed scheduling, but requires much shorter time to derive the schedule. The total time needed for the proposed conversion approach and the calculation of the minimum number of processors needed to schedule the tasks and the calculation of the size of communication buffers between tasks is in the range of seconds.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2483203217",
    "type": "article"
  },
  {
    "title": "MPSoC Software Debugging on Virtual Platforms via Execution Control with Event Graphs",
    "doi": "https://doi.org/10.1145/2950052",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Luis Gabriel Murillo; Róbert Lajos Bücs; Rainer Leupers; Gerd Ascheid",
    "corresponding_authors": "",
    "abstract": "Virtual Platforms (VPs) are advantageous to develop and debug complex software for multi- and many-processor systems-on-chip (MPSoCs). VPs provide unrivaled controllability and visibility of the target, which can be exploited to examine bugs that cannot be reproduced easily in real hardware (e.g., bugs originating from races or happening during a processor stand-by state). However, VPs as employed in practice for debugging are generally underutilized. The accompanying debug ecosystem is based mostly on traditional tools, such as step-based debuggers and traces, that fall short to address the enormous complexity of modern MPSoCs and their parallel software. Finding a bug is still largely left to the developer’s experience and intuition, using manual means rather than automated or systematic solutions that exploit the controllability and visibility of VPs. Profiting from VPs for MPSoC software debugging is an open question. To bridge this gap, this article presents a novel framework for debug visualization and execution control that, relying on the many benefits of VPs, helps to identify and test possible concurrency-related bug scenarios. The framework allows examining and steering the target system by manipulating an abstract graph that highlights relevant inter-component interactions and dependencies. The proposed framework reduces the effort required to understand complex concurrency patterns and helps to expose bugs. Its efficacy is demonstrated on (i) a shared memory symmetric multi-processing platform executing Linux and parallel benchmarks, and (ii) a distributed automotive system for driver assistance applications.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2531113299",
    "type": "article"
  },
  {
    "title": "F <scp>ree</scp> R <scp>ider</scp>",
    "doi": "https://doi.org/10.1145/2990194",
    "publication_date": "2016-12-12",
    "publication_year": 2016,
    "authors": "Stanislav Manilov; Björn Franke; Anthony Magrath; Cedric Andrieu",
    "corresponding_authors": "",
    "abstract": "Short-vector S imd and D sp instructions are popular extensions to common I sa s. These extensions deliver excellent performance and compact code for some compute-intensive applications, but they require specialized compiler support. To enable the programmer to explicitly request the use of such an instruction, many C compilers provide platform-specific intrinsic functions, whose implementation is handled specially by the compiler. The use of such intrinsics, however, inevitably results in nonportable code. In this article, we develop a novel methodology for retargeting such nonportable code, which maps intrinsics from one platform to another, taking advantage of similar intrinsics on the target platform. We employ a description language to specify the signature and semantics of intrinsics and perform graph-based pattern matching and high-level code transformations to derive optimized implementations exploiting the target’s intrinsics, wherever possible. We demonstrate the effectiveness of our new methodology, implemented in the F ree R ider tool, by automatically retargeting benchmarks derived from O pen CV samples and a complex embedded application optimized to run on an A rm C ortex -M4 to an I ntel E dison module with S se 4.2 instructions (and vice versa). We achieve a speedup of up to 3.73 over a plain C baseline, and on average 96.0% of the speedup of manually ported and optimized versions of the benchmarks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2564030861",
    "type": "article"
  },
  {
    "title": "Non-interference in Partial Order Models",
    "doi": "https://doi.org/10.1145/2984639",
    "publication_date": "2016-12-19",
    "publication_year": 2016,
    "authors": "Béatrice Bérard; Loı̈c Hélouët; John Mullins",
    "corresponding_authors": "",
    "abstract": "Non-interference (NI) is a property of systems stating that confidential actions should not cause effects observable by unauthorized users. Several variants of NI have been studied for many types of models but rarely for true concurrency or unbounded models. This work investigates NI for High-level Message Sequence Charts (HMSCs), a scenario language for the description of distributed systems, based on composition of partial orders. We first propose a general definition of security properties in terms of equivalence among observations of behaviors. Observations are naturally captured by partial order automata, a formalism that generalizes HMSCs and permits assembling partial orders. We show that equivalence or inclusion properties for HMSCs (and hence for partial order automata) are undecidable, which means in particular that NI is undecidable for HMSCs. We hence consider decidable subclasses of partial order automata and HMSCs. Finally, we define weaker local properties, describing situations where a system is attacked by a single agent, and show that local NI is decidable. We then refine local NI to a finer notion of causal NI that emphasizes causal dependencies between confidential actions and observations and extend it to causal NI with (selective) declassification of confidential events. Checking whether a system satisfies local and causal NI and their declassified variants are PSPACE-complete problems.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2696905313",
    "type": "article"
  },
  {
    "title": "Tailor-made Virtualization Monitor Design for CPU Virtualization on LEON Processors",
    "doi": "https://doi.org/10.1145/3584702",
    "publication_date": "2023-02-17",
    "publication_year": 2023,
    "authors": "Pablo Parra; Antônio da Silva; Borja Losa; Juan Ignacio García Tejedor; Óscar R. Polo; Agustín Martínez; Sebastián Sánchez",
    "corresponding_authors": "",
    "abstract": "In recent decades, mixed-criticality systems have been widely adopted to reduce the complexity and development times of real-time critical applications. In these systems, applications run on a separation kernel hypervisor, a software element that controls the execution of the different operating systems, providing a virtualized environment and ensuring the necessary spatial and temporal isolation. The guest code can run unmodified and unaware of the hypervisor or be explicitly modified to have a tight coupling with the hypervisor. The former is known as full virtualization, while the latter is known as para-virtualization. Full virtualization offers better compatibility and flexibility than para-virtualization at the cost of a performance penalty. LEON is a processor family that implements the SPARC V8 architecture and whose use is widespread in the field of space systems. To the best of our knowledge, all separation kernel hypervisors designed to support the development of mixed-criticality systems for LEON employ para-virtualization, which hinders the adaptation of real-time operating systems. This article presents the design of a Virtualization Monitor that allows guest real-time operating systems to run virtualized on LEON-based systems without needing to modify their source code. It is designed as a stand-alone component within a hypervisor and incorporates a set of techniques such as static binary rewriting, automatic code generation, and the use of operating system profiles. To validate the proposed solution, tests and benchmarks have been implemented for three guest systems, RTEMS, FreeRTOS, and Zephyr, analyzing the overhead introduced in certain situations characteristic of real-time applications. Finally, the same benchmarks have been run on AIR, one of the hypervisors that uses para-virtualization. The results obtained show that the use of the proposed techniques allows us to obtain similar results to those obtained using para-virtualization without the need to modify the source code of the guest real-time operating systems.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4321223866",
    "type": "article"
  },
  {
    "title": "CNN-based Robust Sound Source Localization with SRP-PHAT for the Extreme Edge",
    "doi": "https://doi.org/10.1145/3586996",
    "publication_date": "2023-03-07",
    "publication_year": 2023,
    "authors": "Jun Yin; Marian Verhelst",
    "corresponding_authors": "",
    "abstract": "Robust sound source localization for environments with noise and reverberation are increasingly exploiting deep neural networks fed with various acoustic features. Yet, state-of-the-art research mainly focuses on optimizing algorithmic accuracy, resulting in huge models preventing edge-device deployment. The edge, however, urges for real-time low-footprint acoustic reasoning for applications such as hearing aids and robot interactions. Hence, we set off from a robust CNN-based model using SRP-PHAT features, Cross3D [ 16 ], to pursue an efficient yet compact model architecture for the extreme edge. For both the SRP feature representation and neural network, we propose respectively our scalable LC-SRP-Edge and Cross3D-Edge algorithms which are optimized towards lower hardware overhead. LC-SRP-Edge halves the complexity and on-chip memory overhead for the sinc interpolation compared to the original LC-SRP [ 19 ]. Over multiple SRP resolution cases, Cross3D-Edge saves 10.32%~73.71% computational complexity and 59.77%~94.66% neural network weights against the Cross3D baseline. In terms of the accuracy-efficiency tradeoff, the most balanced version ( EM ) requires only 127.1 MFLOPS computation, 3.71 MByte/s bandwidth, and 0.821 MByte on-chip memory in total, while still retaining competitiveness in state-of-the-art accuracy comparisons. It achieves 8.59 ms/frame end-to-end latency on a Rasberry Pi 4B, which is 7.26× faster than the corresponding baseline.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4323364417",
    "type": "article"
  },
  {
    "title": "<i>XploreNAS</i> : Explore Adversarially Robust and Hardware-efficient Neural Architectures for Non-ideal Xbars",
    "doi": "https://doi.org/10.1145/3593045",
    "publication_date": "2023-04-17",
    "publication_year": 2023,
    "authors": "Abhiroop Bhattacharjee; Abhishek Moitra; Priyadarshini Panda",
    "corresponding_authors": "",
    "abstract": "Compute In-Memory platforms such as memristive crossbars are gaining focus as they facilitate acceleration of Deep Neural Networks (DNNs) with high area and compute-efficiencies. However, the intrinsic non-idealities associated with the analog nature of computing in crossbars limits the performance of the deployed DNNs. Furthermore, DNNs are shown to be vulnerable to adversarial attacks leading to severe security threats in their large-scale deployment. Thus, finding adversarially robust DNN architectures for non-ideal crossbars is critical to the safe and secure deployment of DNNs on the edge. This work proposes a two-phase algorithm-hardware co-optimization approach called XploreNAS that searches for hardware-efficient & adversarially robust neural architectures for non-ideal crossbar platforms. We use the one-shot Neural Architecture Search (NAS) approach to train a large Supernet with crossbar-awareness and sample adversarially robust Subnets therefrom, maintaining competitive hardware-efficiency. Our experiments on crossbars with benchmark datasets (SVHN, CIFAR10 & CIFAR100) show upto ~8-16% improvement in the adversarial robustness of the searched Subnets against a baseline ResNet-18 model subjected to crossbar-aware adversarial training. We benchmark our robust Subnets for Energy-Delay-Area-Products (EDAPs) using the Neurosim tool and find that with additional hardware-efficiency driven optimizations, the Subnets attain ~1.5-1.6x lower EDAPs than ResNet-18 baseline.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4366087622",
    "type": "article"
  },
  {
    "title": "Regular Composite Resource Partitioning and Reconfiguration in Open Systems",
    "doi": "https://doi.org/10.1145/3609424",
    "publication_date": "2023-07-18",
    "publication_year": 2023,
    "authors": "Wei-Ju Chen; Peng Wu; Pei-Chi Huang; Aloysius K. Mok; Song Han",
    "corresponding_authors": "",
    "abstract": "We consider the problem of resource provisioning for real-time cyber-physical applications in an open system environment where there does not exist a global resource scheduler that has complete knowledge of the real-time performance requirements of each individual application that shares the resources with the other applications. Regularity-based Resource Partition (RRP) model is an effective strategy to hierarchically partition and assign various resource slices among such applications. However, previous work on RRP model only discusses uniform resource environment, where resources are implicitly assumed to be synchronized and clocked at the same frequency. The challenge is that a task utilizing multiple resources may experience unexpected delays in non-uniform environments, where resources are clocked at different frequencies. This paper extends the RRP model to non-uniform multi-resource open system environments to tackle this problem. It first introduces a novel composite resource partition abstraction and then proposes algorithms to construct and reconfigure the composite resource partitions. Specifically, the Acyclic Regular Composite Resource Partition Scheduling (ARCRP-S) algorithm constructs regular composite resource partitions and the Acyclic Regular Composite Resource Partition Dynamic Reconfiguration (ARCRP-DR) algorithm reconfigures the composite resource partitions in the run time upon requests of partition configuration changes. Our experimental results show that compared with state-of-the-art methods, ARCRP-S can prevent unexpected resource supply shortfall and improve the schedulability up to 50%. On the other hand, ARCRP-DR can guarantee the resource supply during the reconfiguration with moderate computational overhead.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4384696790",
    "type": "article"
  },
  {
    "title": "Interruptible Remote Attestation of Low-end IoT Microcontrollers via Performance Counters",
    "doi": "https://doi.org/10.1145/3611674",
    "publication_date": "2023-07-31",
    "publication_year": 2023,
    "authors": "Davide Li Calsi; Vittorio Zaccaria",
    "corresponding_authors": "",
    "abstract": "Remote attestation is a method used in distributed systems to detect integrity violations on a target device (prover) through a challenge–response protocol initiated by a verifier device. The prover calculates a hash of its memory, which is compared to a known good state hash by the verifier. We propose a novel technique, called Counters Help Against Roving Malware (CHARM), which uses hardware performance counters on the prover’s side and machine learning on the verifier’s side to make interruptible remote attestation feasible, even for constrained microcontrollers. We will demonstrate the effectiveness of various machine learning tools and data manipulation techniques on prediction accuracy in a variety of scenarios.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4385417944",
    "type": "article"
  },
  {
    "title": "An Approach to the Systematic Characterization of Multitask Accelerated CNN Inference in Edge MPSoCs",
    "doi": "https://doi.org/10.1145/3611015",
    "publication_date": "2023-08-04",
    "publication_year": 2023,
    "authors": "Alessandro Cilardo; Vincenzo Maisto; Nicola Mazzocca; Franca Rocco di Torrepadula",
    "corresponding_authors": "",
    "abstract": "Deep Learning is ubiquitous today and is increasingly moving from the cloud down to the edge of networked infrastructures, where it enables embedded applications to perform complex inference tasks close to the data sources, reducing long-distance data movement and alleviating the need for a powerful cloud infrastructure. Edge-class multi-processor system on chip (MPSoC) devices featuring an on-chip FPGA fabric offer key advantages for Deep Learning inference tasks, especially for complex applications where multiple models may be run concurrently in the same platform. In this work, we propose an approach and a practical framework for the systematic characterization of multithreaded Deep Learning inference on edge FPGA MPSoCs. We instantiate the framework into a real-world MPSoC platform, targeting Xilinx Vitis-AI as a representative example of a commercial Deep Learning acceleration toolkit for edge environments. We design a comprehensive experimental campaign and apply it to the platform for several convolutional neural networks, each trained on three different datasets. We show that our approach can be used for both hardware- and software-level analysis of a target system. Among other findings, the analysis revealed a suboptimal behavior of the underlying toolkit runtime, involving the utilization of the accelerator cores and the uneven software latency of the support library, influenced by the shapes of the input tensors.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4385583910",
    "type": "article"
  },
  {
    "title": "ReSG: A Data Structure for Verification of Majority based In-Memory Computing on ReRAM Crossbars",
    "doi": "https://doi.org/10.1145/3615358",
    "publication_date": "2023-08-09",
    "publication_year": 2023,
    "authors": "Kousik Bhunia; Arighna Deb; Kamalika Datta; Muhammad Hassan; Saeideh Shirinzadeh; Rolf Drechsler",
    "corresponding_authors": "",
    "abstract": "Recent advancements in the fabrication of Resistive Random Access Memory (ReRAM) devices have led to the development of large-scale crossbar structures. In-memory computing architectures relying on ReRAM crossbars aim to mitigate the processor-memory bottleneck that exists with current complementary metal-oxide semiconductor technology. With this motivation, several synthesis and mapping approaches focusing on the realizations of Boolean functions in the ReRAM crossbars have been proposed earlier. Thus far, the verification of the designs realized on ReRAM crossbars is done either through manual inspection or using simulation-based approaches. Since manual inspections and simulation-based approaches are limited to smaller designs, they cannot be applied to the verification of complex designs on large-scale ReRAM crossbars. Motivated by this, we propose, for the first time, an automatic equivalence checking flow that determines the equivalence between the original function specification (e.g., Majority-inverter Graph ) and the crossbar micro-operations file formats. We consider two crossbar structures, zero-transistor, one-memristor (0T1R) and one-transistor, one-memristor (1T1R) to implement the micro-operations. While the micro-operations file format exists for 0T1R crossbar structures, no representations for micro-operations to be executed in 1T1R crossbars exist yet. In this work, we introduce the micro-operation file format for 1T1R crossbar structures to efficiently represent the micro-operations as ReRAM crossbar netlists. Afterwards, we introduce two intermediate data structures, ReRAM Sequence Graph for 0T1R crossbars (ReSG-0T1R) and for 1T1R crossbars (ReSG-1T1R) , that are derived from the 0T1R and 1T1R crossbar micro-operations file formats, respectively. These ReSGs are then translated into Boolean Satisfiability (SAT) formula, and then the verification is done by checking the generated SAT formulae against the golden functional specification (represented in Verilog) using Z3 Satisfiability solver. Experimental evaluations confirm the effectiveness of the proposed verification methodology on MCNC and ISCAS benchmarks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4385704846",
    "type": "article"
  },
  {
    "title": "An Investigation on Hardware-Aware Vision Transformer Scaling",
    "doi": "https://doi.org/10.1145/3611387",
    "publication_date": "2023-08-21",
    "publication_year": 2023,
    "authors": "Chaojian Li; Kyungmin Kim; Bichen Wu; Peizhao Zhang; Hang Zhang; Xiaoliang Dai; Péter Vajda; Yingyan Lin",
    "corresponding_authors": "",
    "abstract": "Vision Transformer (ViT) has demonstrated promising performance in various computer vision tasks, and recently attracted a lot of research attention. Many recent works have focused on proposing new architectures to improve ViT and deploying it into real-world applications. However, little effort has been made to analyze and understand ViT’s architecture design space and its implication for hardware costs on different devices. In this work, by simply scaling ViT’s depth, width, input size, and other basic configurations, we show that a scaled vanilla ViT model without bells and whistles can achieve comparable or superior accuracy-efficiency trade-off than most of the latest ViT variants. Specifically, compared with DeiT-Tiny, our scaled model achieves a ↑ 1.9% higher ImageNet top-1 accuracy under the same FLOPs and a ↑ 3.7% better ImageNet top-1 accuracy under the same latency on an NVIDIA Edge GPU TX2. Motivated by this, we further investigate the extracted scaling strategies from the following two aspects: (1) can these scaling strategies be transferred across different real hardware devices ? and (2) can these scaling strategies be transferred to different ViT variants and tasks ?. For (1), our exploration, based on various devices with different resource budgets, indicates that the transferability effectiveness depends on the underlying device together with its corresponding deployment tool. For (2), we validate the effective transferability of the aforementioned scaling strategies obtained from a vanilla ViT model on top of an image classification task to the PiT model, a strong ViT variant targeting efficiency as well as object detection and video classification tasks. In particular, when transferred to PiT, our scaling strategies lead to a boosted ImageNet top-1 accuracy of from 74.6% to 76.7% (↑ 2.1%) under the same 0.7G FLOPs. When transferred to the COCO object detection task, the average precision is boosted by ↑ 0.7% under a similar throughput on a V100 GPU.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386027557",
    "type": "article"
  },
  {
    "title": "Predictable GPU Wavefront Splitting for Safety-Critical Systems",
    "doi": "https://doi.org/10.1145/3609102",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Artem Klashtorny; Zhuanhao Wu; Anirudh Mohan Kaushik; Hiren Patel",
    "corresponding_authors": "",
    "abstract": "We present a predictable wavefront splitting (PWS) technique for graphics processing units (GPUs). PWS improves the performance of GPU applications by reducing the impact of branch divergence while ensuring that worst-case execution time (WCET) estimates can be computed. This makes PWS an appropriate technique to use in safety-critical applications, such as autonomous driving systems, avionics, and space, that require strict temporal guarantees. In developing PWS on an AMD-based GPU, we propose microarchitectural enhancements to the GPU, and a compiler pass that eliminates branch serializations to reduce the WCET of a wavefront. Our analysis of PWS exhibits a performance improvement of 11% over existing architectures with a lower WCET than prior works in wavefront splitting.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386568575",
    "type": "article"
  },
  {
    "title": "Let Coarse-Grained Resources Be Shared: Mapping Entire Neural Networks on FPGAs",
    "doi": "https://doi.org/10.1145/3609109",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Tzung-Han Juang; Christof Schlaak; Christophe Dubach",
    "corresponding_authors": "",
    "abstract": "Traditional High-Level Synthesis (HLS) provides rapid prototyping of hardware accelerators without coding with Hardware Description Languages (HDLs). However, such an approach does not well support allocating large applications like entire deep neural networks on a single Field Programmable Gate Array (FPGA) device. The approach leads to designs that are inefficient or do not fit into FPGAs due to resource constraints. This work proposes to shrink generated designs by coarse-grained resource control based on function sharing in functional Intermediate Representations (IRs). The proposed compiler passes and rewrite system aim at producing valid design points and removing redundant hardware. Such optimizations make fitting entire neural networks on FPGAs feasible and produce competitive performance compared to running specialized kernels for each layer.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386568643",
    "type": "article"
  },
  {
    "title": "IOSR: Improving I/O Efficiency for Memory Swapping on Mobile Devices Via Scheduling and Reshaping",
    "doi": "https://doi.org/10.1145/3607923",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Wentong Li; Liang Shi; Hang Li; Changlong Li; Edwin H.‐M. Sha",
    "corresponding_authors": "",
    "abstract": "Mobile systems and applications are becoming increasingly feature-rich and powerful, which constantly suffer from memory pressure, especially for devices equipped with limited DRAM. Swapping inactive DRAM pages to the storage device is a promising solution to extend the physical memory. However, existing mobile devices usually adopt flash memory as the storage device, where swapping DRAM pages to flash memory may introduce significant performance overhead. In this paper, we first conduct an in-depth analysis of the I/O characteristics of the flash-based memory swapping, including the I/O interference and swap I/O randomness in swap subsystem. Then an I/O efficiency optimization framework for memory swapping (IOSR) is proposed to enhance the performance of flash-based memory swapping for mobile devices. IOSR consists of two methods: swap I/O scheduling (SIOS) and swap I/O pattern reshaping (SIOR). SIOS is designed to schedule the swap I/O to reduce interference with other processes I/Os. SIOR is designed to reshape the swap I/O pattern with process-oriented swap slot allocation and adaptive granularity swap read-ahead. IOSR is implemented on Google Pixel 4. Experimental results show that IOSR reduces the application switching time by 31.7% and improves the swap-in bandwidth by 35.5% on average compared to the state-of-the-art.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386568715",
    "type": "article"
  },
  {
    "title": "BASS: Safe Deep Tissue Optical Sensing for Wearable Embedded Systems",
    "doi": "https://doi.org/10.1145/3607916",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Kourosh Vali; Ata Vafi; Begum Kasap; Soheil Ghiasi",
    "corresponding_authors": "",
    "abstract": "In wearable optical sensing applications whose target tissue is not superficial, such as deep tissue oximetry, the task of embedded system design has to strike a balance between two competing factors. On one hand, the sensing task is assisted by increasing the radiated energy into the body, which in turn, improves the signal-to-noise ratio (SNR) of the deep tissue at the sensor. On the other hand, patient safety consideration imposes a constraint on the amount of radiated energy into the body. In this paper, we study the trade-offs between the two factors by exploring the design space of the light source activation pulse. Furthermore, we propose BASS, an algorithm that leverages the activation pulse design space exploration, which further optimizes deep tissue SNR via spectral averaging, while ensuring the radiated energy into the body meets a safe upper bound. The effectiveness of the proposed technique is demonstrated via analytical derivations, simulations, and in vivo measurements in both pregnant sheep models and human subjects.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386568773",
    "type": "article"
  },
  {
    "title": "ZPP: A Dynamic Technique to Eliminate Cache Pollution in NoC based MPSoCs",
    "doi": "https://doi.org/10.1145/3609113",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Dipika Deb; John Jose",
    "corresponding_authors": "",
    "abstract": "Data prefetching efficiently reduces the memory access latency in NUCA architectures as the Last Level Cache (LLC) is shared and distributed across multiple cores. But cache pollution generated by prefetcher reduces its efficiency by causing contention for shared resources such as LLC and the underlying network. The paper proposes Zero Pollution Prefetcher (ZPP) that eliminates cache pollution for NUCA architecture. For this purpose, ZPP uses L1 prefetcher and places the prefetched blocks in the data locations of LLC where modified blocks are stored. Since modified blocks in LLC are stale and request for such blocks are served from the exclusively owned private cache, their space unnecessary consumes power to maintain such stale data in the cache. The benefits of ZPP are (a) Eliminates cache pollution in L1 and LLC by storing prefetched blocks in LLC locations where stale blocks are stored. (b) Insufficient cache space is solved by placing prefetched blocks in LLC as LLCs are larger in size than L1 cache. This helps in prefetching more cache blocks, thereby increasing prefetch aggressiveness. (c) Increasing prefetch aggressiveness increases its coverage. (d) It also maintains an equivalent lookup latency to L1 cache for prefetched blocks. Experimentally it has been found that ZPP increases weighted speedup by 2.19x as compared to a system with no prefetching while prefetch coverage and prefetch accuracy increases by 50%, and 12%, respectively compared to the baseline. 1",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386568807",
    "type": "article"
  },
  {
    "title": "Probabilistic Black-Box Checking via Active MDP Learning",
    "doi": "https://doi.org/10.1145/3609127",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Junya Shijubo; Masaki Waga; Kohei Suenaga",
    "corresponding_authors": "",
    "abstract": "We introduce a novel methodology for testing stochastic black-box systems, frequently encountered in embedded systems. Our approach enhances the established black-box checking (BBC) technique to address stochastic behavior. Traditional BBC primarily involves iteratively identifying an input that breaches the system’s specifications by executing the following three phases: the learning phase to construct an automaton approximating the black box’s behavior, the synthesis phase to identify a candidate counterexample from the learned automaton, and the validation phase to validate the obtained candidate counterexample and the learned automaton against the original black-box system. Our method, ProbBBC, refines the conventional BBC approach by (1) employing an active Markov Decision Process (MDP) learning method during the learning phase, (2) incorporating probabilistic model checking in the synthesis phase, and (3) applying statistical hypothesis testing in the validation phase. ProbBBC uniquely integrates these techniques rather than merely substituting each method in the traditional BBC; for instance, the statistical hypothesis testing and the MDP learning procedure exchange information regarding the black-box system’s observation with one another. The experiment results suggest that ProbBBC outperforms an existing method, especially for systems with limited observation.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386569069",
    "type": "article"
  },
  {
    "title": "<scp>CrossTalk</scp> : Making Low-Latency Fault Tolerance Cheap by Exploiting Redundant Networks",
    "doi": "https://doi.org/10.1145/3609436",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Andrew Loveless; Linh Thi Xuan Phan; Lisa Erickson; Ronald Dreslinski; Baris Kasikci",
    "corresponding_authors": "",
    "abstract": "Real-time embedded systems perform many important functions in the modern world. A standard way to tolerate faults in these systems is with Byzantine fault-tolerant (BFT) state machine replication (SMR), in which multiple replicas execute the same software and their outputs are compared by the actuators. Unfortunately, traditional BFT SMR protocols are slow , requiring replicas to exchange sensor data back and forth over multiple rounds in order to reach agreement before each execution. The state of the art in reducing the latency of BFT SMR is eager execution , in which replicas execute on data from different sensors simultaneously on different processor cores. However, this technique results in 3–5× higher computation overheads compared to traditional BFT SMR systems, significantly limiting schedulability. We present CrossTalk , a new BFT SMR protocol that leverages the prevalence of redundant switched networks in embedded systems to reduce latency without added computation. The key idea is to use specific algorithms to move messages between redundant network planes (which many systems already possess) as the messages travel from the sensors to the replicas. As a result, CrossTalk can ensure agreement automatically in the network, avoiding the need for any communication between replicas. Our evaluation shows that CrossTalk improves schedulability by 2.13–4.24× over the state of the art. Moreover, in a NASA simulation of a real spaceflight mission, CrossTalk tolerates more faults than the state of the art while using nearly 3× less processor time.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386569076",
    "type": "article"
  },
  {
    "title": "Methods to Realize Preemption in Phased Execution Models",
    "doi": "https://doi.org/10.1145/3609132",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Thilanka Thilakasiri; Matthias Becker",
    "corresponding_authors": "",
    "abstract": "Phased execution models are a good solution to tame the increased complexity and contention of commercial off-the-shelf (COTS) multi-core platforms, e.g., Acquisition-Execution-Restitution (AER) model, PRedictable Execution Model (PREM). Such models separate execution from access to shared resources on the platform to minimize contention. All data and instructions needed during an execution phase are copied into the local memory of the core before starting to execute. Phased execution models are generally used with non-preemptive scheduling to increase predictability. However, the blocking time in non-preemptive systems can reduce schedulability. Therefore, an investigation of preemption methods for phased execution models is warranted. Although, preemption for phased execution models must be carefully designed to retain its execution semantics, i.e., the handling of local memory during preemption becomes non-trivial. This paper investigates different methods to realize preemption in phased execution models while preserving their semantics. To the best of our knowledge, this is the first paper to explore different approaches to implement preemption in phased execution models from the perspective of data management. We introduce two strategies to realize preemption of execution phases based on different methods of handling local data of the preempted task. Heuristics are used to create time-triggered schedules for task sets that follow the proposed preemption methods. Additionally, a schedulability-aware preemption heuristic is proposed to reduce the number of preemptions by allowing preemption only when it is beneficial in terms of schedulability. Evaluations on a large number of synthetic task sets are performed to compare the proposed preemption models against each other and against a non-preemptive version. Furthermore, our schedulability-aware preemption heuristic has higher schedulability with a clear margin in all our experiments compared to the non-preemptive and fully-preemptive versions.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386580329",
    "type": "article"
  },
  {
    "title": "<i>AxOTreeS</i> : A <u>Tree</u> <u>S</u> earch Approach to Synthesizing FPGA-based <u>A</u> ppro <u>x</u> imate <u>O</u> perators",
    "doi": "https://doi.org/10.1145/3609096",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Siva Satyendra Sahoo; Salim Ullah; Akash Kumar",
    "corresponding_authors": "",
    "abstract": "Approximate computing (AxC) provides the scope for achieving disproportionate gains in a system’s power, performance, and area (PPA) metrics by leveraging an application’s inherent error-resilient behavior (BEHAV). Trading computational accuracy for performance gains makes AxC an attractive proposition for implementing computationally complex AI/ML-based applications on resource-constrained embedded systems. The growing diversity of application domains using AI/ML has also led to the increasing usage of FPGA-based embedded systems. However, implementing AxC for FPGAs has primarily been limited to the post-processing of ASIC-optimized approximate operators (AxOs). This approach usually involves selecting from a set of AxOs that have been optimized for a gate-based implementation in an ASIC. While such an approach does allow leveraging existing knowledge of ASIC-based AxO design, it limits the scope for considering the challenges and opportunities associated with FPGA’s LUT-based computation structures. Similarly, the few works considering the LUT-based computing for AxO design use generic optimization approaches that do not allow integrating problem-specific prior knowledge—empirical and/or statistical. To this end, we propose a novel tree search-based approach to AxO synthesis for FPGAs. Specifically, we present a design methodology using Monte Carlo Tree Search (MCTS)-based search tree traversal that allows the designer to integrate statistical data, such as correlation, into the AxOs optimization. With the proposed methods, we report improvements over standard MCTS algorithm-based results as well as improved hypervolume for both operator-level and application-specific DSE, compared to state-of-the-art design methodologies.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386580470",
    "type": "article"
  },
  {
    "title": "Optimal Synthesis of Robust IDK Classifier Cascades",
    "doi": "https://doi.org/10.1145/3609129",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Sanjoy Baruah; Alan Burns; Robert I. Davis",
    "corresponding_authors": "",
    "abstract": "An IDK classifier is a computing component that categorizes inputs into one of a number of classes, if it is able to do so with the required level of confidence, otherwise it returns “I Don’t Know” (IDK). IDK classifier cascades have been proposed as a way of balancing the needs for fast response and high accuracy in classification-based machine perception. Efficient algorithms for the synthesis of IDK classifier cascades have been derived; however, the responsiveness of these cascades is highly dependent on the accuracy of predictions regarding the run-time behavior of the classifiers from which they are built. Accurate predictions of such run-time behavior is difficult to obtain for many of the classifiers used for perception. By applying the algorithms using predictions framework, we propose efficient algorithms for the synthesis of IDK classifier cascades that are robust to inaccurate predictions in the following sense: the IDK classifier cascades synthesized by our algorithms have short expected execution durations when the predictions are accurate, and these expected durations increase only within specified bounds when the predictions are inaccurate.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386580504",
    "type": "article"
  },
  {
    "title": "Computationally Efficient DNN Mapping Search Heuristic using Deep Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3609110",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Suyash Bakshi; Lennart Johnsson",
    "corresponding_authors": "",
    "abstract": "In this work, we present a computationally efficient Reinforcement Learning mapping search heuristic for finding high quality mappings for N-dimensional convolution loops that uses a computationally inexpensive reward function based on potential data reuse of operands to guide the search process. We also present a RL state representation generalizable to N-dimensional convolution loops, and a state representation parsing strategy ensuring that only valid mappings are evaluated for quality. Our RL search heuristic is applicable to multi-core systems with a memory hierarchy. We show that our RL based search heuristic for a range of 3D convolution layers, at significantly lower computational expense than random search, generally yields mappings with lower Energy-Delay Product (EDP) for an architecture with multiple processing elements with shared memory connected to DRAM. Our evaluation results demonstrated across 19 3D convolution layers, shows that our RL method performed only an average 11.24% of the operations of that of Timeloop’s random search for assessing same number of valid mappings. The mappings found using Timeloop had an average 12.51% higher EDP compared to lowest EDP mapping found using our RL method. Further, the lowest EDP mappings found using our method had an average only 4.69× higher EDP than the theoretical lower bound EDP, with the best case being only 1.29× higher.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386580659",
    "type": "article"
  },
  {
    "title": "CRIMP: <u>C</u> ompact &amp; <u>R</u> eliable DNN Inference on <u>I</u> n- <u>M</u> emory <u>P</u> rocessing via Crossbar-Aligned Compression and Non-ideality Adaptation",
    "doi": "https://doi.org/10.1145/3609115",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Shuo Huai; Hao Kong; Xiangzhong Luo; Shiqing Li; Ravi Subramaniam; Christian Makaya; Qian Lin; Weichen Liu",
    "corresponding_authors": "",
    "abstract": "Crossbar-based In-Memory Processing (IMP) accelerators have been widely adopted to achieve high-speed and low-power computing, especially for deep neural network (DNN) models with numerous weights and high computational complexity. However, the floating-point (FP) arithmetic is not compatible with crossbar architectures. Also, redundant weights of current DNN models occupy too many crossbars, limiting the efficiency of crossbar accelerators. Meanwhile, due to the inherent non-ideal behavior of crossbar devices, like write variations, pre-trained DNN models suffer from accuracy degradation when it is deployed on a crossbar-based IMP accelerator for inference. Although some approaches are proposed to address these issues, they often fail to consider the interaction among these issues, and introduce significant hardware overhead for solving each issue. To deploy complex models on IMP accelerators, we should compact the model and mitigate the influence of device non-ideal behaviors without introducing significant overhead from each technique. In this paper, we first propose to reuse bit-shift units in crossbars for approximately multiplying scaling factors in our quantization scheme to avoid using FP processors. Second, we propose to apply kernel-group pruning and crossbar pruning to eliminate the hardware units for data aligning. We also design a zerorize-recover training process for our pruning method to achieve higher accuracy. Third, we adopt the runtime-aware non-ideality adaptation with a self-compensation scheme to relieve the impact of non-ideality by exploiting the feature of crossbars. Finally, we integrate these three optimization procedures into one training process to form a comprehensive learning framework for co-optimization, which can achieve higher accuracy. The experimental results indicate that our comprehensive learning framework can obtain significant improvements over the original model when inferring on the crossbar-based IMP accelerator, with an average reduction of computing power and computing area by 100.02× and 17.37×, respectively. Furthermore, we can obtain totally integer-only, pruned, and reliable VGG-16 and ResNet-56 models for the Cifar-10 dataset on IMP accelerators, with accuracy drops of only 2.19% and 1.26%, respectively, without any hardware overhead.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386580744",
    "type": "article"
  },
  {
    "title": "Neural Abstraction-Based Controller Synthesis and Deployment",
    "doi": "https://doi.org/10.1145/3608104",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Rupak Majumdar; Mahmoud Salamati; Sadegh Soudjani",
    "corresponding_authors": "",
    "abstract": "Abstraction-based techniques are an attractive approach for synthesizing correct-by-construction controllers to satisfy high-level temporal requirements. A main bottleneck for successful application of these techniques is the memory requirement, both during controller synthesis (to store the abstract transition relation) and in controller deployment (to store the control map). We propose memory-efficient methods for mitigating the high memory demands of the abstraction-based techniques using neural network representations . To perform synthesis for reach-avoid specifications, we propose an on-the-fly algorithm that relies on compressed neural network representations of the forward and backward dynamics of the system. In contrast to usual applications of neural representations, our technique maintains soundness of the end-to-end process. To ensure this, we correct the output of the trained neural network such that the corrected output representations are sound with respect to the finite abstraction. For deployment, we provide a novel training algorithm to find a neural network representation of the synthesized controller and experimentally show that the controller can be correctly represented as a combination of a neural network and a look-up table that requires a substantially smaller memory. We demonstrate experimentally that our approach significantly reduces the memory requirements of abstraction-based methods. We compare the performance of our approach with the standard abstraction-based synthesis on several models. For the selected benchmarks, our approach reduces the memory requirements respectively for the synthesis and deployment by a factor of 1.31× 10 5 and 7.13× 10 3 on average, and up to 7.54× 10 5 and 3.18× 10 4 . Although this reduction is at the cost of increased off-line computations to train the neural networks, all the steps of our approach are parallelizable and can be implemented on machines with higher number of processing units to reduce the required computational time.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386580800",
    "type": "article"
  },
  {
    "title": "A Robust and Energy Efficient Hyperdimensional Computing System for Voltage-scaled Circuits",
    "doi": "https://doi.org/10.1145/3620671",
    "publication_date": "2023-09-11",
    "publication_year": 2023,
    "authors": "Dehua Liang; Hiromitsu Awano; Noriyuki Miura; Jun Shiomi",
    "corresponding_authors": "",
    "abstract": "Voltage scaling is one of the most promising approaches for energy efficiency improvement but also brings challenges to fully guaranteeing stable operation in modern VLSI. To tackle such issues, we further extend the DependableHD to the second version DependableHDv2 , a HyperDimensional Computing (HDC) system that can tolerate bit-level memory failure in the low voltage region with high robustness. DependableHDv2 introduces the concept of margin enhancement for model retraining and utilizes noise injection to improve the robustness, which is capable of application in most state-of-the-art HDC algorithms. We additionally propose the dimension-swapping technique, which aims at handling the stuck-at errors induced by aggressive voltage scaling in the memory cells. Our experiment shows that under 8% memory stuck-at error, DependableHDv2 exhibits a 2.42% accuracy loss on average, which achieves a 14.1× robustness improvement compared to the baseline HDC solution. The hardware evaluation shows that DependableHDv2 supports the systems to reduce the supply voltage from 430 mV to 340 mV for both item Memory and Associative Memory, which provides a 41.8% energy consumption reduction while maintaining competitive accuracy performance.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386603070",
    "type": "article"
  },
  {
    "title": "An Analytical Model-based Capacity Planning Approach for Building CSD-based Storage Systems",
    "doi": "https://doi.org/10.1145/3623677",
    "publication_date": "2023-09-14",
    "publication_year": 2023,
    "authors": "Hongsu Byun; Safdar Jamil; Jungwook Han; Sungyong Park; Myungcheol Lee; Changsoo Kim; Beongjun Choi; Youngjae Kim",
    "corresponding_authors": "",
    "abstract": "The data movement in large-scale computing facilities (from compute nodes to data nodes) is categorized as one of the major contributors to high cost and energy utilization. To tackle it, in-storage processing (ISP) within storage devices, such as Solid-State Drives (SSDs), has been explored actively. The introduction of computational storage drives (CSDs) enabled ISP within the same form factor as regular SSDs and made it easy to replace SSDs within traditional compute nodes. With CSDs, host systems can offload various operations such as search, filter, and count. However, commercialized CSDs have different hardware resources and performance characteristics. Thus, it requires careful consideration of hardware, performance, and workload characteristics for building a CSD-based storage system within a compute node. Therefore, storage architects are hesitant to build a storage system based on CSDs as there are no tools to determine the benefits of CSD-based compute nodes to meet the performance requirements compared to traditional nodes based on SSDs. In this work, we proposed an analytical model-based storage capacity planner called CsdPlan for system architects to build performance-effective CSD-based compute nodes. Our model takes into account the performance characteristics of the host system, targeted workloads, and hardware and performance characteristics of CSDs to be deployed and provides optimal configuration based on the number of CSDs for a compute node. Furthermore, CsdPlan estimates and reduces the total cost of ownership (TCO) for building a CSD-based compute node. To evaluate the efficacy of CsdPlan , we selected two commercially available CSDs and four representative big data analysis workloads.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4386745400",
    "type": "article"
  },
  {
    "title": "Design and Analysis of High Performance Heterogeneous Block-based Approximate Adders",
    "doi": "https://doi.org/10.1145/3625686",
    "publication_date": "2023-09-28",
    "publication_year": 2023,
    "authors": "Ebrahim Farahmand; Ali Mahani; Muhammad Abdullah Hanif; Muhammad Shafique",
    "corresponding_authors": "",
    "abstract": "Approximate computing is an emerging paradigm to improve the power and performance efficiency of error-resilient applications. As adders are one of the key components in almost all processing systems, a significant amount of research has been carried out toward designing approximate adders that can offer better efficiency than conventional designs; however, at the cost of some accuracy loss. In this article, we highlight a new class of energy-efficient approximate adders, namely, Heterogeneous Block-based Approximate Adders (HBAAs), and propose a generic configurable adder model that can be configured to represent a particular HBAA configuration. An HBAA, in general, is composed of heterogeneous sub-adder blocks of equal length, where each sub-adder can be an approximate sub-adder and have a different configuration. The sub-adders are mainly approximated through inexact logic and carry truncation. Compared to the existing design space, HBAAs provide additional design points that fall on the Pareto-front and offer a better quality-efficiency tradeoff in certain scenarios. Furthermore, to enable efficient design space exploration based on user-defined constraints, we propose an analytical model to efficiently evaluate the Probability Mass Function (PMF) of approximation error and other error metrics, such as Mean Error Distance (MED), Normalized Mean Error Distance (NMED), and Error Rate (ER) of HBAAs. The results show that HBAA configurations can provide around 15% reduction in area and up to 17% reduction in energy compared to state-of-the-art approximate adders.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4387130627",
    "type": "article"
  },
  {
    "title": "Dynamic Thermal Management of 3D Memory through Rotating Low Power States and Partial Channel Closure",
    "doi": "https://doi.org/10.1145/3624581",
    "publication_date": "2023-10-05",
    "publication_year": 2023,
    "authors": "Lokesh Siddhu; Aritra Bagchi; Rajesh Kedia; Isaar Ahmad; Shailja Pandey; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "Modern high-performance and high-bandwidth three-dimensional (3D) memories are characterized by frequent heating. Prior art suggests turning off hot channels and migrating data to the background DDR memory, incurring significant performance and energy overheads. We propose three Dynamic Thermal Management (DTM) approaches for 3D memories, reducing these overheads. The first approach, Rotating-channel Low-power-state-based DTM (RL-DTM) , minimizes the energy overheads by avoiding data migration. RL-DTM places 3D memory channels into low power states instead of turning them off. Since data accesses are disallowed during low power state, RL-DTM balances each channel’s low-power-state duration. The second approach, Masked rotating-channel Low-power-state-based DTM (ML-DTM) , is a fine-grained policy that minimizes the energy-delay product (EDP) and improves the performance of RL-DTM by considering the channel access rate. The third strategy, Partial channel closure and ML-DTM , minimizes performance overheads of existing channel-level turn-off-based policies by closing a channel only partially and integrating ML-DTM, reducing the number of channels being turned off. We evaluate the proposed DTM policies using various mixes of SPEC benchmarks and multi-threaded workloads and observe them to significantly improve performance, energy, and EDP over state-of-the-art approaches for different 3D memory architectures.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4387364514",
    "type": "article"
  },
  {
    "title": "System-level memory management based on statistical variability compensation for frame-based applications",
    "doi": "https://doi.org/10.1145/2536747.2536757",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Concepción Sanz; J.I. Gomez; Christian Tenllado; Manuel Prieto; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "Process variability and dynamic domains increase the uncertainty of embedded systems and force designers to apply pessimistic designs, which become unnecessarily conservative and have a tremendous impact on both performance and energy consumption. In this context, developing uncertainty-aware design methodologies that take both variation at platform and at application level into account becomes a must. These methodologies should mitigate the effects derived from uncertainty, avoiding worst-case assumptions. In this article we propose a comprehensive methodology to tackle two forms of uncertainty: (1) process variation on the memory system, (2) application dynamism. A statistical model has been developed to deal with variability derived from fabrication process, whereas system scenarios are selected to cope with dynamic domains. Both sources of uncertainty are firstly tackled in combination at design time, to be refined later, at setup. As a result, at run time the platform can be successfully adapted to the current application behaviour as well as the current variations. Our simulations show that this methodology provides significant energy savings while still meeting strict timing constraints.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1968943278",
    "type": "article"
  },
  {
    "title": "Detection of harmful schizophrenic statements in esterel",
    "doi": "https://doi.org/10.1145/2442116.2442130",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Jeong-Han Yun; Chul-Joo Kim; Seonggun Kim; Kwang-Moo Choe; Taisook Han",
    "corresponding_authors": "",
    "abstract": "In imperative synchronous languages, a statement is called schizophrenic if it is executed more than once in a single clock. When a schizophrenic statement is translated into a circuit, the circuit can behave abnormally because of the multiple executions. To solve the problems caused by schizophrenic statements, compilers duplicate the statements to avoid multiple executions. Esterel is an imperative synchronous language. Schizophrenic statements in Esterel are considered to occur due to the instantaneous reentrance of local signal declarations or parallel statements. However, if the corresponding circuit of a schizophrenic statement behaves normally, it is harmless and thus curing is not necessary. In this paper, we identify the conditions under which a schizophrenic statement of the Esterel program must be cured during circuit translation. We also propose an algorithm to detect schizophrenic statements that have to be cured on the control flow graphs (CFGs) of source codes. Our algorithm detects all schizophrenic statements that have to be cured and results in fewer false alarms on the benchmark programs used in the previous work. It is simple and based on the CFG of a program, implying that it can be merged into existing compilers easily.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1971933195",
    "type": "article"
  },
  {
    "title": "RapidRadio",
    "doi": "https://doi.org/10.1145/2331147.2331151",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Jorge Suris; Adolfo Recio; Peter Athanas",
    "corresponding_authors": "",
    "abstract": "In this article, the RapidRadio framework for signal classification and receiver deployment is discussed. The framework is a productivity-enhancing tool that reduces the required knowledge base for implementing a receiver on an FPGA-based SDR platform. The ultimate objective of this framework is to identify unknown signals and to build FPGA-based receivers capable of receiving them. RapidRadio divides the process of radio creation into two phases; the analysis phase and radio synthesis phase. The analysis phase guides the user through the process of classifying an unknown signal and determining its modulation scheme and parameters, resulting in a radio receiver model. In the second phase, this model is transformed into a functional receiver in an FPGA-based platform.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1973254671",
    "type": "article"
  },
  {
    "title": "Data reorganization for scalable video service with embedded mobile devices",
    "doi": "https://doi.org/10.1145/2423636.2423645",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Seung‐Ho Lim; Min Choi; Young Sik Jeong",
    "corresponding_authors": "",
    "abstract": "Recent development of high-speed wireless networks and embedded systems has enabled the recording and delivery of high-performance multimedia to heterogeneous mobile users. To support heterogeneous mobile users with high-quality multimedia services, scalable video coding was introduced. In the scalable video coding (SVC), through multidimensional scalability, all types of these scalability can be exploited at the same time. However, the generated video sequences of scalable video coding are not adequate for mobile multimedia service systems since its flexibility makes non contiguous storing and retrieval of partial stream data. In this article, we propose efficient scalable video data reorganization for video servicing systems, which consist of video server and mobile clients. For video server, we reorganize scalable video streams taking into account both of decoding dependency and location in disk array storage, where disk array is widely used for storage systems of video server. In the mobile devices, we place substreams with the consideration of NAND flash memory page and block boundaries, which is storage for mobile devices. The experimental results show that the proposed reorganization of scalable video can improve the performance of mobile multimedia service systems.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1976403559",
    "type": "article"
  },
  {
    "title": "Area-efficient convolutional deinterleaver for mobile TV receiver",
    "doi": "https://doi.org/10.1145/2423636.2423646",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "Hyeong‐Ju Kang; Hee-Suk Seo; Jin Kwak",
    "corresponding_authors": "",
    "abstract": "In this article, a single-pointer structure is proposed for the convolutional deinterleavers of mobile TV receivers. To enhance the burst-error correcting capability, the convolutional interleaving and deinterleaving scheme is widely used in mobile TV receivers. However, a convolutional deinterleaver requires many pointer registers. This article introduces a single-pointer structure that reduces the number of pointer registers. Experimental results show that the single-pointer structure reduces the area of the convolutional deinterleaver by 70% in a mobile TV receiver.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1982322183",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2331147.2331162",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Georgios Fainekos; Éric Goubault; Franjo Ivančić; Sriram Sankaranarayanan",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Editorial: Special Section VCPSS’09 Guest Editors: Georgios Fainekos Arizona State University Arizona State UniversityView Profile , Eric Goubault CEA LIST CEA LISTView Profile , Franjo Ivančić Nec Laboratories America Nec Laboratories AmericaView Profile , Sriram Sankaranarayanan University of Colorado Boulder University of Colorado BoulderView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 11Issue S2Article No.: 52pp 1–3https://doi.org/10.1145/2331147.2331162Published:01 August 2012Publication History 0citation126DownloadsMetricsTotal Citations0Total Downloads126Last 12 Months6Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2022293365",
    "type": "editorial"
  },
  {
    "title": "Runtime Reconfigurations of Embedded Controllers",
    "doi": "https://doi.org/10.1145/2406336.2406350",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Mohamed Khalgui; Olfa Mosbahi; Zhiwu Li",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2032327618",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on multiprocessor system-on-chip for cyber-physical systems",
    "doi": "https://doi.org/10.1145/2435227.2435242",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Michael Hübner",
    "corresponding_authors": "Michael Hübner",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2032642169",
    "type": "article"
  },
  {
    "title": "Statistical Performance Modeling in Functional Instruction Set Simulators",
    "doi": "https://doi.org/10.1145/2180887.2180899",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Björn Franke",
    "corresponding_authors": "Björn Franke",
    "abstract": "Despite the recent progress in improving the speed of instruction-accurate simulators cycle-accurate simulation is still prohibitively slow for all but the most basic programs. In this article we present a statistical machine learning approach to performance estimation in fast, instruction accurate simulators and evaluate our methodology comprehensively against three popular embedded RISC processors and about 300 embedded applications. We show that our methodology is capable of providing accurate performance estimations with an average error of less than 3.9% while, on average, operating ≈ 14.5 times faster than cycle-accurate simulation.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2048617313",
    "type": "article"
  },
  {
    "title": "Balancing Programmability and Silicon Efficiency of Heterogeneous Multicore Architectures",
    "doi": "https://doi.org/10.1145/2180887.2180890",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Andrei Terechko; Jan Hoogerbrugge; G. Alkadi; Surendra Guntur; Anirban Lahiri; Marc Duranton; Clemens C. Wüst; P. Christie; A. Nackaerts; A. Kumar",
    "corresponding_authors": "",
    "abstract": "Multicore architectures provide scalable performance with a lower hardware design effort than single core processors. Our article presents a design methodology and an embedded multicore architecture, focusing on reducing the software design complexity and boosting the performance density. First, we analyze characteristics of the Task-Level Parallelism in modern multimedia workloads. These characteristics are used to formulate requirements for the programming model. Then we translate the programming model requirements to an architecture specification, including a novel low-complexity implementation of cache coherence and a hardware synchronization unit. Our evaluation demonstrates that the novel coherence mechanism substantially simplifies hardware design, while reducing the performance by less than 18% relative to a complex snooping technique. Compared to a single processor core, the multicores have already proven to be more area- and energy-efficient. However, the multicore architectures in embedded systems still compete with highly efficient function-specific hardware accelerators. In this article we identify five architectural methods to boost performance density of multicores; microarchitectural downscaling, asymmetric multicore architectures, multithreading, generic accelerators, and conjoining. Then, we present a novel methodology to explore multicore design spaces, including the architectural methods improving the performance density. The methodology is based on a complex formula computing performances of heterogeneous multicore systems. Using this design space exploration methodology for HD and QuadHD H.264 video decoding, we estimate that the required areas of multicores in CMOS 45 nm are 2.5 mm 2 and 8.6 mm 2 , respectively. These results suggest that heterogeneous multicores are cost-effective for embedded applications and can provide a good programmability support.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2056785995",
    "type": "article"
  },
  {
    "title": "Control-theoretic cyber-physical system modeling and synthesis",
    "doi": "https://doi.org/10.1145/2362336.2362343",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Donghwa Shin; Jaehyun Park; Younghyun Kim; Jaeam Seo; Naehyuck Chang",
    "corresponding_authors": "",
    "abstract": "A joint optimization of the physical system and the cyber world is one of the key problems in the design of a cyber-physical system (CPS). The major mechanical forces and/or chemical reactions in a plant are commonly modified by actuators in the balance-of-plant (BOP) system. More powerful actuators requires more power, but generally increase the response of the physical system powered by the electrical energy generated by the physical system. To maximize the overall output of a power generating plant therefore requires joint optimization of the physical system and the cyber world, and this is a key factor in the design of a CPS. We introduce a systematic approach to the modeling and synthesis of a CPS that emphasize joint power optimization, using an active direct methanol fuel cell (DMFC) as a case study. Active DMFC systems are superior to passive DMFCs in terms of fuel efficiency thanks to their BOP system, which includes pumps, air blowers, and fans. However, designing a small-scale active DMFC with the best overall system efficiency requires the BOP system to be jointly optimized with the DMFC stack operation, because the BOP components are powered by the stack. Our approach to this synthesis problem involves i) BOP system characterization, ii) integrated DMFC system modeling, iii) configuring a system for the maximum net power output through design space exploration, iv) synthesis of feedback control tasks, and v) implementation.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2063891454",
    "type": "article"
  },
  {
    "title": "A framework for defending embedded systems against software attacks",
    "doi": "https://doi.org/10.1145/1952522.1952526",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Najwa Aaraj; Anand Raghunathan; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "The incidence of malicious code and software vulnerability exploits on embedded platforms is constantly on the rise. Yet, little effort is being devoted to combating such threats to embedded systems. Moreover, adapting security approaches designed for general-purpose systems generally fails because of the limited processing capabilities of their embedded counterparts. In this work, we evaluate a malware and software vulnerability exploit defense framework for embedded systems. The proposed framework extends our prior work, which defines two isolated execution environments: a testing environment, wherein an untrusted application is first tested using dynamic binary instrumentation (DBI), and a real environment, wherein a program is monitored at runtime using an extracted behavioral model, along with a continuous learning process. We present a suite of software and hardware optimizations to reduce the overheads induced by the defense framework on embedded systems. Software optimizations include the usage of static analysis, complemented with DBI in the testing environment (i.e., a hybrid software analysis approach is used). Hardware optimizations exploit parallel processing capabilities of multiprocessor systems-on-chip. We have evaluated the defense framework and proposed optimizations on the ARM-Linux operating system. Experiments demonstrate that our framework achieves a high coverage of considered security threats, with acceptable performance penalties (the average execution time of applications goes up to 1.68X, considering all optimizations, which is much smaller than the 2.72X performance penalty when no optimizations are used).",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2064243367",
    "type": "article"
  },
  {
    "title": "Dependable management system for ubiquitous camera array service in an elder-care center",
    "doi": "https://doi.org/10.1145/2423636.2423647",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "K. Bharanitharan; Jiun-Ren Ding; Anand Paul; Kuen-Ming Lee; Ting‐Wei Hou",
    "corresponding_authors": "",
    "abstract": "The concept of smart homes (SH) has been extensively popularized, and there are a lot of technologies that need to be continuously utilized and integrated in such a concept. In this article, some applied problems of camera array (CA) in the SH are discussed and solved. Determining how to build an effective management method for CA in order to ensure that user privacy is not encroached upon is an important issue. In SH, the applications of CA are very diversified. We suggest that a satisfactory management method of CA should be based on the open service gateway initiative (OSGi) that includes resource management and monitoring (RMM) and UPnP security for the problems of resources and privacy, respectively. Finally, an applied example of CA is addressed in an elder-care center (EC). Simulation results show that the management strategy and application of CA based on an OSGi is satisfactory.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2066642710",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on ESTIMedia’08",
    "doi": "https://doi.org/10.1145/2180887.2180891",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Mladen Bereković; Samarjit Chakraborty; Petru Eles; Andy D. Pimentel",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2093130131",
    "type": "article"
  },
  {
    "title": "Leveraging speculative architectures for runtime program validation",
    "doi": "https://doi.org/10.1145/2512456",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Juan Carlos Martínez-Santos; Yunsi Fei",
    "corresponding_authors": "",
    "abstract": "Program execution can be tampered with by malicious attackers through exploiting software vulnerabilities. Changing the program behavior by compromising control data and decision data has become the most serious threat in computer system security. Although several hardware approaches have been presented to validate program execution, they either incur great hardware overhead or introduce false alarms. We propose a new hardware-based approach by leveraging the existing speculative architectures for runtime program validation. The on-chip branch target buffer (BTB) is utilized as a cache of the legitimate control flow transfers stored in a secure memory region. In addition, the BTB is extended to store the correct program path information. At each indirect branch site, the BTB is used to validate the decision history of previous conditional branches and monitor the following execution path at runtime. Implementation of this approach is transparent to the upper operating system and programs. Thus, it is applicable to legacy code. Because of good code locality of the executable programs and effectiveness of branch prediction, the frequency of control-flow validations against the secure off-chip memory is low. Our experimental results show a negligible performance penalty and small storage overhead.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2118046102",
    "type": "article"
  },
  {
    "title": "Modeling and Analysis of TinyOS Sensor Node Firmware",
    "doi": "https://doi.org/10.1145/2406336.2406341",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Allan McInnes",
    "corresponding_authors": "Allan McInnes",
    "abstract": "Wireless sensor networks are an increasingly popular application area for embedded systems. Individual sensor nodes within a network are typically resource-constrained, event-driven, and require a high degree of concurrency. This combination of requirements motivated the development of the widely used TinyOS sensor node operating system. The TinyOS concurrency model is a lightweight nonpreemptive system designed to suit the needs of typical sensor network applications. Although the TinyOS concurrency model is easier to reason about than preemptive threads, it can still give rise to undesirable behavior due to unexpected interleavings of related tasks, or unanticipated preemption by interrupt handlers. To aid TinyOS developers in understanding the behavior of their programs we have developed a technique for using the process algebra Communicating Sequential Processes (CSP) to model the interactions between TinyOS components, and between an application and the TinyOS scheduling and preemption mechanisms. Analysis of the resulting models can help TinyOS developers to discover and diagnose concurrency-related errors in their designs that might otherwise go undetected until after the application has been widely deployed. Such analysis is particularly valuable for the TinyOS components that are used as building blocks for a large number of other applications, since a subtle or sporadic error in a widely deployed building block component could be extremely costly to repair.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2122106516",
    "type": "article"
  },
  {
    "title": "An efficient, low-cost routing framework for convex mesh partitions to support virtualization",
    "doi": "https://doi.org/10.1145/2485984.2485995",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Frank Olaf Sem-Jacobsen; Samuel Rodrigo; Tor Skeie; Alessandro Strano; Davide Bertozzi",
    "corresponding_authors": "",
    "abstract": "At the core of an efficient chip multiprocessors (CMP) is support for unicast and multicast routing, low implementation costs, and the ability to isolate concurrent applications with maximum utilization of the CMP. We present an efficient logic-based unicast and multicast routing algorithm that guarantees isolation of local application traffic within any near-convex region on the chip, and the algorithms to recognize supported partitions and configure the cores accordingly. Evaluations show that the routing algorithm has a 57% more compact implementation than a recent multicast solution with the same coverage, and it achieves 5% higher throughput with 13% lower latency.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2123219739",
    "type": "article"
  },
  {
    "title": "INVISIOS",
    "doi": "https://doi.org/10.1145/2345770.2345772",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Divya Arora; Najwa Aaraj; Anand Raghunathan; Niraj K. Jha",
    "corresponding_authors": "",
    "abstract": "Many information security attacks exploit vulnerabilities in “trusted” and privileged software executing on the system, such as the operating system (OS). On the other hand, most security mechanisms provide no immunity to security-critical user applications if vulnerabilities are present in the underlying OS. While technologies have been proposed that facilitate isolation of security-critical software, they require either significant computational resources and are hence not applicable to many resource-constrained embedded systems, or necessitate extensive redesign of the underlying processors and hardware. In this work, we propose INVISIOS: a lightweight, minimally intrusive hardware-software architecture to make the execution of security-critical software invisible to the OS, and hence protected from its vulnerabilities. The INVISIOS software architecture encapsulates the security-critical software into a self-contained software module. While this module is part of the kernel and is run with kernel-level privileges, its code, data, and execution are transparent to and protected from the rest of the kernel. The INVISIOS hardware architecture consists of simple add-on hardware components that are responsible for bootstrapping the secure core, ensuring that it is exercised by applications in only permitted ways, and enforcing the isolation of its code and data. We implemented INVISIOS by enhancing a full-system emulator and Linux to model the proposed software and hardware enhancements, and applied it to protect a commercial cryptographic library. Our experiments demonstrate that INVISIOS is capable of facilitating secure execution at very small overheads, making it suitable for resource-constrained embedded systems and systems-on-chip.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2151368284",
    "type": "article"
  },
  {
    "title": "Custom architecture for multicore audio beamforming systems",
    "doi": "https://doi.org/10.1145/2514641.2514646",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Dimitris Theodoropoulos; Georgi Kuzmanov; Georgi Gaydadjiev",
    "corresponding_authors": "",
    "abstract": "The audio Beamforming (BF) technique utilizes microphone arrays to extract acoustic sources recorded in a noisy environment. In this article, we propose a new approach for rapid development of multicore BF systems. Research on literature reveals that the majority of such experimental and commercial audio systems are based on desktop PCs, due to their high-level programming support and potential of rapid system development. However, these approaches introduce performance bottlenecks, excessive power consumption, and increased overall cost. Systems based on DSPs require very low power, but their performance is still limited. Custom hardware solutions alleviate the aforementioned drawbacks, however, designers primarily focus on performance optimization without providing a high-level interface for system control and test. In order to address the aforementioned problems, we propose a custom platform-independent architecture for reconfigurable audio BF systems. To evaluate our proposal, we implement our architecture as a heterogeneous multicore reconfigurable processor and map it onto FPGAs. Our approach combines the software flexibility of General-Purpose Processors (GPPs) with the computational power of multicore platforms. In order to evaluate our system we compare it against a BF software application implemented to a low-power Atom 330, a middle-ranged Core2 Duo, and a high-end Core i3. Experimental results suggest that our proposed solution can extract up to 16 audio sources in real time under a 16-microphone setup. In contrast, under the same setup, the Atom 330 cannot extract any audio sources in real time, while the Core2 Duo and the Core i3 can process in real time only up to 4 and 6 sources respectively. Furthermore, a Virtex4-based BF system consumes more than an order less energy compared to the aforementioned GPP-based approaches.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2162107789",
    "type": "article"
  },
  {
    "title": "Application-specific service technologies for commodity operating systems in real-time environments",
    "doi": "https://doi.org/10.1145/1952522.1952523",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Richard West; Gabriel Parmer",
    "corresponding_authors": "",
    "abstract": "In order to eliminate the costs of proprietary systems and special purpose hardware, many real-time and embedded computing platforms are being built on commodity operating systems and generic hardware. Unfortunately, many such systems are ill-suited to the low-latency and predictable timing requirements of real-time applications. This article, therefore, focuses on application-specific service technologies for low-cost commodity operating systems and hardware, so that real-time service guarantees can be met. We describe contrasting methods to deploy first-class services on commodity systems that are dispatched with low latency and execute asynchronously according to bounds on CPU, memory, and I/O device usage. Specifically, we present a “user-level sandboxing” (ULS) mechanism that relies on hardware protection to isolate application-specific services from the core kernel. This approach is compared with a hybrid language and runtime protection scheme, called SafeX , that allows untrusted services to be dynamically linked and loaded into a base kernel. SafeX and ULS have been implemented on commodity Linux systems. Experimental results have shown—that both approaches are capable of reducing service violations (and, hence, better qualities of service) for real-time tasks, compared to traditional user-level methods of service deployment in process-private address spaces. ULS imposes minimal additional overheads on service dispatch latency compared to SafeX, with the advantage that it does not require application-specific services to execute in the trusted kernel domain. As evidence of the potential capabilities of ULS, we show how a user-level networking stack can be implemented to avoid data copying via the kernel and allow packet processing without explicit process scheduling. This improves throughput and reduces jitter.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2620924667",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2406336",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, an algorithm is proposed to design liveness-enforcing supervisors for systems of simple sequential processes with resources (S3PR) based on complementary places. Firstly, a mixed integer programming (MIP) based deadlock detection method ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4229705022",
    "type": "paratext"
  },
  {
    "title": "DLIC",
    "doi": "https://doi.org/10.1145/2501626.2512464",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Ji Gu; Hui Guo; Tohru Ishihara",
    "corresponding_authors": "",
    "abstract": "With the explosive proliferation of embedded systems, especially through countless portable devices and wireless equipment used, embedded systems have become indispensable to the modern society and people's life. Those devices are often battery driven. Therefore, low energy consumption in embedded processors is important and becomes critical in step with the system complexity. The on-chip instruction cache (I-cache) is usually the most energy-consuming component on the processor chip due to its large size and frequent access operations. To reduce such energy consumption, the existing loop cache approaches use a tiny decoded cache to filter the I-cache access and instruction decode activity for repeated loop iterations. However, such designs are effective for small and simple loops, and only suitable for DSP kernel-like applications. They are not effectual for many embedded applications where complex loops are common. In this article, we propose a decoded loop instruction cache (DLIC) that is small, hence energy efficient, yet can capture most loops, including large nested ones with branch executions, so that a significant amount of I-cache accesses and instruction decoding can be eradicated. The experiments on a set of embedded benchmarks show that our proposed DLIC scheme can reduce energy consumption by up to 87% as compared to normal cache-only design. On average, 66% energy can be saved on instruction fetching and decoding, while at a performance overhead of only 1.4%.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4237561180",
    "type": "article"
  },
  {
    "title": "L24",
    "doi": "https://doi.org/10.1145/2501626.2512465",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Phillip Stanley‐Marbell",
    "corresponding_authors": "Phillip Stanley‐Marbell",
    "abstract": "Networks of sensors must process large amounts of intermittently-available data in situ. This motivates the investigation of means for achieving high performance when required, but ultra-low-power dissipation when idle. One approach to this challenge is the use of embedded multiprocessor systems, leading to trade-offs between parallelism, performance, energy efficiency, and cost. To evaluate these trade-offs and to gain insight for future system designs, this article presents the design, implementation, and evaluation of a miniature, energy-scalable, 24-processor module, L24, for use in embedded sensor systems.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4240812555",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/993396.993397",
    "publication_date": "2004-05-01",
    "publication_year": 2004,
    "authors": "John Lach; Kia Bazargan",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Editorial: Special issue on dynamically adaptable embedded systems Editors: John Lach University of Virginia, Charlottesville, VA University of Virginia, Charlottesville, VAView Profile , Kia Bazargan University of Minnesota, Minneapolis, MN University of Minnesota, Minneapolis, MNView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 3Issue 2pp 233–236https://doi.org/10.1145/993396.993397Published:01 May 2004Publication History 1citation926DownloadsMetricsTotal Citations1Total Downloads926Last 12 Months9Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Publisher SiteeReaderPDF",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2023645171",
    "type": "editorial"
  },
  {
    "title": "Excluding Parallel Execution to Improve Global Fixed Priority Response Time Analysis",
    "doi": "https://doi.org/10.1145/3477035",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Quan Zhou; Jianjun Li; Guohui Li",
    "corresponding_authors": "",
    "abstract": "Response Time Analysis (RTA) is an effective method for testing the schedulability of real-time tasks on multiprocessor platforms. Existing RTAs for global fixed priority scheduling calculate the upper bound of the worst case response time of each task. Given a target task, existing RTAs first calculate the workload upper bound of each higher priority task (than the target task), and then calculate the interference on the target task by each higher priority task according to the obtained workload upper bounds. The workload of a task consists of three parts: carry-in, body and carry-out. The interference from all these three parts may be overestimated in existing RTAs. However, although the overestimation of the interference from body is the major factor that causes the low accuracy of existing RTAs, all existing work only focuses on how to reduce the overestimation of the interference from carry-in, and there is no method to reduce the overestimation of the interference from body or carry-out. In this work, we propose a method to calculate the lower bound of the accumulative time in which the target task and higher priority tasks are executed in parallel. By excluding the parallel execution time from the interference, we derive a new RTA test that can reduce the overestimation of the interference from all three parts of the workload. Extensive experiments are conducted to verify the superior performance of the proposed RTA test.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3200515013",
    "type": "article"
  },
  {
    "title": "MARCO: A High-performance Task <u>M</u> apping <u>a</u> nd <u>R</u> outing <u>Co</u> -optimization Framework for Point-to-Point NoC-based Heterogeneous Computing Systems",
    "doi": "https://doi.org/10.1145/3476985",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Hui Chen; Zihao Zhang; Peng Chen; Xiangzhong Luo; Shiqing Li; Weichen Liu",
    "corresponding_authors": "",
    "abstract": "Heterogeneous computing systems (HCSs), which consist of various processing elements (PEs) that vary in their processing ability, are usually facilitated by the network-on-chip (NoC) to interconnect its components. The emerging point-to-point NoCs which support single-cycle-multi-hop transmission, reduce or eliminate the latency dependence on distance, addressing the scalability concern raised by high latency for long-distance transmission and enlarging the design space of the routing algorithm to search the non-shortest paths. For such point-to-point NoC-based HCSs, resource management strategies which are managed by compilers, scheduler, or controllers, e.g., mapping and routing, are complicated for the following reasons: (i) Due to the heterogeneity, mapping and routing need to optimize computation and communication concurrently (for homogeneous computing systems, only communication). (ii) Conducting mapping and routing consecutively cannot minimize the schedule length in most cases since the PEs with high processing ability may locate in the crowded area and suffer from high resource contention overhead. (iii) Since changing the mapping selection of one task will reconstruct the whole routing design space, the exploration of mapping and routing design space is challenging. Therefore, in this work, we propose MARCO, the m apping a nd r outing co -optimization framework, to decrease the schedule length of applications on point-to-point NoC-based HCSs. Specifically, we revise the tabu search to explore the design space and evaluate the quality of mapping and routing. The advanced reinforcement learning (RL)algorithm, i.e., advantage actor-critic, is adopted to efficiently compute paths. We perform extensive experiments on various real applications, which demonstrates that the MARCO achieves a remarkable performance improvement in terms of schedule length (+44.94% ∼ +50.18%) when compared with the state-of-the-art mapping and routing co-optimization algorithm for homogeneous computing systems. We also compare MARCO with different combinations of state-of-the-art mapping and routing approaches.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3200645847",
    "type": "article"
  },
  {
    "title": "Reducing memory requirements of resource-constrained applications",
    "doi": "https://doi.org/10.1145/1509288.1509289",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "Priya Unnikrishnan; G. Chen; Mahmut Kandemir; Mustafa Karaköy; I. Kolcu",
    "corresponding_authors": "",
    "abstract": "Embedded computing platforms are often resource constrained, requiring great design and implementation attention to memory-power-, and heat-related parameters. An important task for a compiler in such platforms is to simplify the process of developing applications for limited memory devices and resource-constrained clients. Focusing on array-intensive embedded applications to be executed on single CPU-based architectures, this work explores how loop-based compiler optimizations can be used for increasing memory location reuse. Our goal is to transform a given application in such a way that the resulting code has fewer cases (as compared to the original code), where the lifetimes of array elements overlap. The reduction in lifetimes of array elements can then be exploited by reusing memory locations as much as possible. Our experimental results indicate that the proposed strategy reduces data space requirements of 15 resource constrained applications by more than 40%, on average. We also demonstrate how this strategy can be combined with data locality (cache behavior)--enhancing techniques so that a compiler can take advantage of both, that is, reduce data memory requirements and improve data locality at the same time.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2033682515",
    "type": "article"
  },
  {
    "title": "Register coalescing techniques for heterogeneous register architecture with copy sifting",
    "doi": "https://doi.org/10.1145/1457255.1457263",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Minwook Ahn; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "Optimistic coalescing has been proven as an elegant and effective technique that provides better chances of safely coloring more registers in register allocation than other coalescing techniques. Its algorithm originally assumes homogeneous registers, which are all gathered in the same register file. Although this register architecture is still common in most general-purpose processors, embedded processors often contain heterogeneous registers, which are scattered in physically different register files dedicated for each dissimilar purpose and use. In this work, we show that optimistic coalescing is also useful for an embedded processor to better handle such heterogeneity of the register architecture, and developed a modified algorithm for optimal coalescing that helps a register allocator. In the experiment, an existing register allocator was able to achieve up to 13.0% reduction in code size through our coalescing, and avoid many spills that would have been generated without our scheme.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2078229301",
    "type": "article"
  },
  {
    "title": "Securely Reinforcing Synchronization for Embedded Online Contests",
    "doi": "https://doi.org/10.1145/2899000",
    "publication_date": "2017-01-16",
    "publication_year": 2017,
    "authors": "Wei Wang; Peng Xu; Laurence T. Yang; Willy Susilo; Jinjun Chen",
    "corresponding_authors": "",
    "abstract": "When competing in eBay bidding, online games, or e-exams in embedded computing environments, people naturally face asynchronous starts from different computing devices, which is treated as a security risk of online contests. The security risks of online contests also include eavesdropping during data transmission without intended rights, and false starts by malicious competitors, which also means asynchrony in contests. Accordingly, online contests need security guarantees, especially on synchronization. In this article, for synchronic and secure starts in a contest, we update security requirements of confidentiality, anonymity, and synchrony, comparing the current work to our previous work. Based on the updated requirements, we propose a general framework for the Advanced Secure Synchronized Reading (ASSR) system, which can hold multiple contests simultaneously in the cloud. It is important to note that the system can ignore the impacts of heterogeneity among competitors. Considering the heterogeneity both on transmission and computing, we construct a novel Randomness-reused Identity Based Key Encapsulation Mechanism (RIBKEM) to support separable decapsulation, which can shorten both decryption delay and transmission delay with the best efforts. Finally, ASSR enhances synchronization achievement for contest starts with heterogeneous delays of competitors while satisfying other security requirements. As a complement, the analysis on the provable security of ASSR is given, as well as a further analysis on the achievement of synchronization.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2578217697",
    "type": "article"
  },
  {
    "title": "DMS-Based Energy Optimizations for Clustered WSNs",
    "doi": "https://doi.org/10.1145/2998179",
    "publication_date": "2017-04-11",
    "publication_year": 2017,
    "authors": "Maryam Bandari; Robert Simon; Hakan Aydın",
    "corresponding_authors": "",
    "abstract": "In this article, we consider clustered wireless sensor networks where the nodes harvest energy from the environment. We target performance-sensitive applications that have to collectively send their information to a cluster head by a predefined deadline. The nodes are equipped with Dynamic Modulation Scaling (DMS)-capable wireless radios. DMS provides a tuning knob, allowing us to trade off communication latency with energy consumption. We consider two optimization objectives, maximizing total energy reserves and maximizing the minimum energy level across all nodes. For both objectives, we show that optimal solutions can be obtained by solving Mixed Integer Linear Programming problems. We also develop several fast heuristics that are shown to provide approximate solutions experimentally.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2606910881",
    "type": "article"
  },
  {
    "title": "Area, Throughput, and Power Trade-Offs for FPGA- and ASIC-Based Execution Stream Compression",
    "doi": "https://doi.org/10.1145/3063312",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Maria Isabel Mera; Jonah Caplan; Seyyed Hasan Mozafari; Brett H. Meyer; Peter Milder",
    "corresponding_authors": "",
    "abstract": "An emerging trend in safety-critical computer system design is the use of compression—for example, using cyclic redundancy check (CRC) or Fletcher checksum (FC)—to reduce the state that must be compared to verify correct redundant execution. We examine the costs and performance of CRC and FC as compression algorithms when implemented in hardware for embedded safety-critical systems. To do so, we have developed parameterizable hardware-generation tools targeting CRC and two novel FC implementations. We evaluate the resulting designs implemented for FPGA and ASIC and analyze their efficiency. While CRC is often best, FC dominates when high throughput is needed.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2612560320",
    "type": "article"
  },
  {
    "title": "Task Transition Scheduling for Data-Adaptable Systems",
    "doi": "https://doi.org/10.1145/3047498",
    "publication_date": "2017-05-11",
    "publication_year": 2017,
    "authors": "Nathan Sandoval; Casey Mackin; Sean Whitsitt; Vijay Shankar Gopinath; Sachidanand Mahadevan; Andrew Milakovich; Kyle Merry; Jonathan Sprinkle; Roman Lysecky",
    "corresponding_authors": "",
    "abstract": "Data-adaptable embedded systems operate on a variety of data streams, which requires a large degree of configurability and adaptability to support runtime changes in data stream inputs. Data-adaptable reconfigurable embedded systems, when decomposed into a series of tasks, enable a flexible runtime implementation in which a system can transition the execution of certain tasks between hardware and software while simultaneously continuing to process data during the transition. Efficient runtime scheduling of task transitions is needed to optimize system throughput and latency of the reconfiguration and transition periods. In this article, we provide an overview of a runtime framework enabling the efficient transition of tasks between software and hardware in response to changes in system inputs. We further present and analyze several runtime transition scheduling algorithms and highlight the latency and throughput tradeoffs for two data-adaptable systems. To evaluate the task transition selection algorithms, a case study was performed on an adaptable JPEG2000 implementation as well as three other synchronous dataflow systems characterized by transition latency and communication load.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2613393035",
    "type": "article"
  },
  {
    "title": "An efficient placement and routing technique for fault-tolerant distributed embedded computing",
    "doi": "https://doi.org/10.1145/1550987.1550991",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Roozbeh Jafari; Hassan Ghasemzadeh; Foad Dabiri; Ani Nahapetian; Majid Sarrafzadeh",
    "corresponding_authors": "",
    "abstract": "This article presents an efficient technique for placement and routing of sensors/actuators and processing units in a grid network. The driver application that we present is a medical jacket, which requires an extremely high level of robustness and fault tolerance. The power consumption of such jacket is another key technological constraint. Our proposed interconnection network is a mesh of wires. A jacket made of fabric and wires would be susceptible to accidental damage via tears. By modeling the tears, we evaluate the probability of having failures on every segment of wires in our mesh interconnection network. Then, we study two problems of placement and routing in the sensor networks such that the fault tolerance is maximized while the power consumption is minimized. We develop efficient integer linear programming (ILP) formulations to address these problems and perform both placement and routing, simultaneously. This ensures that the solution is a lower bound for both problems. We evaluate the effectiveness of our proposed techniques on a variety of benchmarks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2617729566",
    "type": "article"
  },
  {
    "title": "Incremental Inductive Verification of Parameterized Timed Systems",
    "doi": "https://doi.org/10.1145/2984640",
    "publication_date": "2017-01-16",
    "publication_year": 2017,
    "authors": "Tobias Isenberg",
    "corresponding_authors": "Tobias Isenberg",
    "abstract": "We propose and extend an approach for the verification of safety properties for parameterized timed systems modeled as networks of timed automata. For this task, we introduce an incremental workflow that is based on our algorithm IC3 with Zones . It proceeds in a cycle in which single models of the system are verified, and the verification results are employed for the reasoning about the entire system. Starting with the smallest instances, the verification of the safety property is carried out fast and efficient. On successful verification, the algorithm produces an inductive strengthening of the safety property. We reuse this result and try to reason about the entire parameterized timed system. To this end, we extrapolate the inductive strengthening into a candidate for the next-larger model. In case this candidate is a valid inductive strengthening for the next larger model, our main theorem reasons about all models of the parameterized timed system, stating that the safety property holds true for all models. Otherwise, the main cycle starts over with the verification of the next larger model. This workflow is iterated indefinitely, until able to reason about the entire parameterized timed system, until a counterexample trace is found, or until the single models become too large to be handled in the verification. We reuse the intermediate results in a Feedback -loop in order to accelerate the verification runs for the single models. Furthermore, we consider an extended formalism in comparison to our previous publications.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2671454091",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3129534",
    "publication_date": "2017-09-15",
    "publication_year": 2017,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2755866833",
    "type": "editorial"
  },
  {
    "title": "A Novel Emulation Model of the Cardiac Conduction System",
    "doi": "https://doi.org/10.1145/3126542",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Sidharta Andalam; Nathan Allen; Avinash Malik; Partha S. Roop; Mark L. Trew",
    "corresponding_authors": "",
    "abstract": "Models of the cardiac conduction system are usually at two extremes: (1) high fidelity models with excellent precision but lacking a real-time response for emulation (hardware in the loop simulation); or (2) models amenable for emulation, but that do not exhibit appropriate dynamic response, which is necessary for arrhythmia susceptibility. We introduce two abstractions to remedy the situation. The first abstraction is a new cell model, which is a semi-linear hybrid automata. The proposed model is as computationally efficient as current state-of-the-art cell models amenable for emulation. Yet, unlike these models, it is also able to capture the dynamic response of the cardiac cell like the higher-fidelity models. The second abstraction is the use of smooth-tokens to develop a new path model, connecting cells, which is efficient in terms of memory consumption. Moreover, the memory requirements of the path model can be statically bounded and are invariant to the emulation step size. Results show that the proposed semi-linear abstraction for the cell reduces the execution time by up to 44%. Furthermore, the smooth-tokens based path model reduces the memory consumption by 40 times when compared to existing path models. This paves the way for the emulation of complex cardiac conduction systems, using hardware code-generators.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2756562933",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1814539",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In real-time systems, the execution-time overrun of a thread may lead to a deadline being missed by the thread or even others threads in the system. From a fault tolerance perspective, both execution time overruns and deadline misses can be considered ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4255355929",
    "type": "paratext"
  },
  {
    "title": "ForSyDe-Atom",
    "doi": "https://doi.org/10.1145/3424667",
    "publication_date": "2021-01-04",
    "publication_year": 2021,
    "authors": "George Ungureanu; José Edil Guimarães de Medeiros; Timmy Sundström; Ingemar Söderquist; Anders Åhlander; Ingo Sander",
    "corresponding_authors": "",
    "abstract": "We present ForSyDe-Atom, a formal framework intended as an entry point for disciplined design of complex cyber-physical systems. This framework provides a set of rules for combining several domain-specific languages as structured, enclosing layers to orthogonalize the many aspects of system behavior, yet study their interaction in tandem . We define four layers: one for capturing timed interactions in heterogeneous systems, one for structured parallelism, one for modeling uncertainty, and one for describing component properties. This framework enables a systematic exploitation of design properties in a design flow by facilitating the stepwise projection of certain layers of interest, the isolated analysis and refinement on projections, and the seamless reconstruction of a system model by virtue of orthogonalization. We demonstrate the capabilities of this approach by providing a compact yet expressive model of an active electronically scanned array antenna and signal processing chain, simulate it, validate its conformity with the design specifications, refine it, synthesize a sub-system to VHDL and sequential code, and co-simulate the generated artifacts.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3121018858",
    "type": "article"
  },
  {
    "title": "Real-time, High-resolution Depth Upsampling on Embedded Accelerators",
    "doi": "https://doi.org/10.1145/3436878",
    "publication_date": "2021-03-27",
    "publication_year": 2021,
    "authors": "David Langerman; Alan D. George",
    "corresponding_authors": "",
    "abstract": "High-resolution, low-latency apps in computer vision are ubiquitous in today’s world of mixed-reality devices. These innovations provide a platform that can leverage the improving technology of depth sensors and embedded accelerators to enable higher-resolution, lower-latency processing for 3D scenes using depth-upsampling algorithms. This research demonstrates that filter-based upsampling algorithms are feasible for mixed-reality apps using low-power hardware accelerators. The authors parallelized and evaluated a depth-upsampling algorithm on two different devices: a reconfigurable-logic FPGA embedded within a low-power SoC; and a fixed-logic embedded graphics processing unit. We demonstrate that both accelerators can meet the real-time requirements of 11 ms latency for mixed-reality apps. 1",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3149383472",
    "type": "article"
  },
  {
    "title": "Toward Object-oriented Modeling in SCCharts",
    "doi": "https://doi.org/10.1145/3453482",
    "publication_date": "2021-05-29",
    "publication_year": 2021,
    "authors": "Alexander Schulz-Rosengarten; Steven Smyth; Michael Mendler",
    "corresponding_authors": "",
    "abstract": "Object orientation is a powerful and widely used paradigm for abstraction and structuring in programming. Many languages are designed with this principle or support different degrees of object orientation. In synchronous languages, originally developed to design embedded reactive systems, there are only few object-oriented influences. However, especially in combination with a statechart notation, the modeling process can be improved by facilitating object orientation as we argue here. At the same time the graphical representation can be used to illustrate the object-oriented design of a system. Synchronous statechart dialects, such as the SCCharts language, provide deterministic concurrency for specifying safety-critical systems. Using SCCharts as an example, we illustrate how an object-oriented modeling approach that supports inheritance can be introduced. We further present how external, i.e., host language, objects can be included in the SCCharts language. Specifically, we discuss how the recently developed concepts of scheduling directives and scheduling policies can be used to ensure the determinism of objects while retaining encapsulation.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3169720173",
    "type": "article"
  },
  {
    "title": "Guaranteeing Timely Response to Changes of Monitored Objects by Assigning Deadlines and Periods to Tasks",
    "doi": "https://doi.org/10.1145/3477027",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Quan Zhou; Guohui Li; Qi Chen; Jianjun Li",
    "corresponding_authors": "",
    "abstract": "Timely response to changes of monitored objects is the key to ensuring the safety and reliability of cyber-physical systems (CPSs). There are two kinds of tasks in CPSs: update tasks and control tasks. Update tasks are responsible for updating the data in the system based on the state of the objects they monitor. Control tasks are responsible for making decisions based on the data in the system. The response time of the system to the change of a monitored object consists of two parts: the time taken by update tasks to reflect the change to the system, and the time taken by control tasks to make decisions according to the data in the system. Deadlines and periods of update tasks and control tasks directly affect the response time. Reasonable deadline and period assignment is the key to ensuring timely response to the changes of monitored objects. In this paper, we study the deadline and period assignment in CPSs. To the best of our knowledge, all existing work only focuses on the deadline and period assignment for update tasks with the goal of ensuring the freshness of the data in CPSs, and this is the first study focusing on the deadline and period assignment for both update tasks and control tasks with the goal of ensuring timely response to the changes of monitored objects. A new problem about response time control and system workload control is defined in this paper. Two deadline and period assignment methods are proposed to solve the defined problem. All the proposed methods can be used in the CPSs adopting the earliest deadline first (EDF) scheduling method. Experiments with randomly generated tasks are conducted to evaluate the performance of the proposed methods in terms of acceptance ratio and execution efficiency.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3199007811",
    "type": "article"
  },
  {
    "title": "Data Pattern Aware Reliability Enhancement Scheme for 3D Solid-State Drives",
    "doi": "https://doi.org/10.1145/3477000",
    "publication_date": "2021-09-17",
    "publication_year": 2021,
    "authors": "Shiqiang Nie; Weiguo Wu; Chi Zhang",
    "corresponding_authors": "",
    "abstract": "3D charge-trap (CT) NAND flash-based SSD has been used widely for its large capacity, low cost per bit, and high endurance. One-shot program (OSP) scheme, as a variation of incremental step pulse programming (ISPP) scheme, has been employed to program data for CT flash, whose program unit is the Word-Line (WL) instead of the page. The existing program optimization schemes either make trade-offs among program latency and reliability by adjusting the program step voltage on demand; or remap the most error-prone cell states to others by re-encoding programmed data. However, the data pattern, which represents the ratio of 1s in data values, has not been thoroughly studied. In this paper, we observe that most small files do not contain uniform 1s and 0s among these common file types (i.e., image, audio, text, executable file), leading to programming WL cells in different states unevenly. Some cell states dominate over the WL, while others are not. Based on this observation, we propose a flexible reliability enhancement scheme based on the OSP scheme. This scheme programs the cells into different states with varied , i.e., these cells in one state, whose number is the largest in one WL, are programmed with a fine-grained (namely slow write). In contrast, the minority are programmed with a coarse-grained (namely fast write). So the reliability is improved due to averaging the major enhanced cells with the minor degraded cells without program latency overhead. A series of experiments have been conducted, and the results indicate that the proposed scheme achieves 34% read performance improvement and 16% lifetime elongation on average.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3199451795",
    "type": "article"
  },
  {
    "title": "Schedulability Analysis for Timed Automata With Tasks",
    "doi": "https://doi.org/10.1145/3477020",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Jinghao Sun; Nan Guan; Rongxiao Shi; Guozhen Tan; Wang Yi",
    "corresponding_authors": "",
    "abstract": "Research on modeling and analysis of real-time computing systems has been done in two areas, model checking and real-time scheduling theory. In model checking, an expressive modeling formalism such as timed automata (TA) is used to model complex systems, but the analysis is typically very expensive due to state-space explosion. In real-time scheduling theory, the analysis techniques are highly efficient, but the models are often restrictive. In this paper, we aim to exploit the possibility of applying efficient analysis techniques rooted in real-time scheduling theory to analysis of real-time task systems modeled by timed automata with tasks (TAT). More specifically, we develop efficient techniques to analyze the feasibility of TAT-based task models (i.e., whether all tasks can meet their deadlines on single-processor) using demand bound functions (DBF), a widely used workload abstraction in real-time scheduling theory. Our proposed analysis method has a pseudo-polynomial time complexity if the number of clocks used to model each task is bounded by a constant, which is much lower than the exponential complexity of the traditional model-checking based analysis approach (also assuming the number of clocks is bounded by a constant). We apply dynamic programming techniques to implement the DBF-based analysis framework, and propose state space pruning techniques to accelerate the analysis process. Experimental results show that our DBF-based method can analyze a TAT system with 50 tasks within a few minutes, which significantly outperforms the state-of-the-art TAT-based schedulability analysis tool TIMES.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3201631855",
    "type": "article"
  },
  {
    "title": "Mapping Computations in Heterogeneous Multicore Systems with Statistical Regression on Program Inputs",
    "doi": "https://doi.org/10.1145/3478288",
    "publication_date": "2021-10-18",
    "publication_year": 2021,
    "authors": "Junio Cezar Ribeiro da Silva; Lorena Leão; Vinícius Petrucci; Abdoulaye Gamatié; Fernando Magno Quintão Pereira",
    "corresponding_authors": "",
    "abstract": "A hardware configuration is a set of processors and their frequency levels in a multicore heterogeneous system. This article presents a compiler-based technique to match functions with hardware configurations. Such a technique consists of using multivariate linear regression to associate function arguments with particular hardware configurations. By showing that this classification space tends to be convex in practice, this article demonstrates that linear regression is not only an efficient tool to map computations to heterogeneous hardware, but also an effective one. To demonstrate the viability of multivariate linear regression as a way to perform adaptive compilation for heterogeneous architectures, we have implemented our ideas onto the Soot Java bytecode analyzer. Code that we produce can predict the best configuration for a large class of Java and Scala benchmarks running on an Odroid XU4 big.LITTLE board; hence, outperforming prior techniques such as ARM’s GTS and CHOAMP, a recently released static program scheduler.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3207235688",
    "type": "article"
  },
  {
    "title": "The security of the Fiat--Shamir scheme in the presence of transient hardware faults",
    "doi": "https://doi.org/10.1145/1347375.1347384",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "Artemios G. Voyiatzis; Dimitrios Serpanos",
    "corresponding_authors": "",
    "abstract": "Implementation cryptanalysis has emerged as a realistic threat for cryptographic systems. It consists of two classes of attacks: fault-injection and side-channel attacks. In this work, we examine the resistance of the Fiat--Shamir scheme to fault-injection attacks, since Fiat--Shamir is a popular scheme for “light” consumer devices, such as smartcards, in a wide range of consumer services. We prove that an existing attack, known as the Bellcore attack, is incomplete. We propose an extension to the protocol that proactively secures Fiat--Shamir systems from the Bellcore attack and we prove its strength. Finally, we introduce a new attack model, which, under stronger assumptions, can derive the secret keys from both the original Fiat--Shamir scheme as well as its proposed extension. Our approach demonstrates that countermeasures for implementation cryptanalysis must be carefully designed and that deployed systems must include appropriate protection mechanisms for all known attacks and be flexible enough to incorporate countermeasures for new ones.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1987942835",
    "type": "article"
  },
  {
    "title": "Direct address translation for virtual memory in energy-efficient embedded systems",
    "doi": "https://doi.org/10.1145/1457246.1457251",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Xiangrong Zhou; П. П. Петров",
    "corresponding_authors": "",
    "abstract": "This article presents a methodology for virtual memory support in energy-efficient embedded systems. A holistic approach is proposed, where the combined efforts of compiler, operating system, and hardware architecture achieve a significant system power reductions. The application information extracted and analyzed by the compiler is utilized dynamically by the microarchitecture and the operating system to perform energy-efficient and, for many memory references, time-deterministic address translations. We demonstrate that by using application information regarding virtual memory layout, an efficient and conflict-free translation process can be implemented through the utilization of a small hardware direct translation table (DTT) accessed in an application-specific manner. The set of virtual pages is partitioned into groups, such that for each group only a few of the least significant bits are used as an index to obtain the physical page number. We outline an efficient compile-time algorithm for identifying these groups and allocate their translation entries optimally into the DTT. The introduced hardware is minimal in terms of area, performance, and power overhead, while offering the flexibility of software programmability. This is achieved through a small set of registers and tables, which are made software accessible. We have quantitatively evaluated the proposed methodology on a number of embedded applications, including voice, image, and video processing.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2038045290",
    "type": "article"
  },
  {
    "title": "Efficient software implementation of embedded communication protocol controllers using asynchronous software thread integration with time- and space-efficient procedure calls",
    "doi": "https://doi.org/10.1145/1210268.1210270",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Nagendra J. Kumar; Vasanth Asokan; Siddhartha Shivshankar; Alexander G. Dean",
    "corresponding_authors": "",
    "abstract": "The overhead of context switching limits efficient scheduling of multiple concurrent threads on a uniprocessor when real-time requirements exist. A software-implemented protocol controller may be crippled by this problem. The available idle time may be too short to recover through context switching, so only the primary thread can execute during message activity, slowing the secondary threads and potentially missing deadlines. Asynchronous software thread integration (ASTI) uses coroutine calls and integration, letting threads make independent progress efficiently, and reducing the needed context switches. We demonstrate the methods with a software implementation of an automotive communication protocol (J1850) and several secondary threads.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2061909578",
    "type": "article"
  },
  {
    "title": "Quasistatic shared libraries and XIP for memory footprint reduction in MMU-less embedded systems",
    "doi": "https://doi.org/10.1145/1457246.1457252",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Jiyong Park; Jaesoo Lee; Saehwa Kim; Seongsoo Hong",
    "corresponding_authors": "",
    "abstract": "Despite a rapid decrease in the price of solid state memory devices, system memory is still a very precious resource in embedded systems. The use of shared libraries and execution-in-place (XIP) is known to be effective in significantly reducing memory usage. Unfortunately, many resource-constrained embedded systems lack an MMU, making it extremely difficult to support these techniques. To address this problem, we propose a novel shared library technique called a quasi-static shared library and an XIP, both based on our enhanced position independent code technique. In our quasistatic shared libraries, global symbols are bound to pseudoaddresses at linking time and actual physical addresses are bound at loading time. Unlike conventional shared libraries, they do not require symbol tables that take up valuable memory space and, therefore, allow for expedited address translation at runtime. Our XIP technique is facilitated by our enhanced position independent code where a data section can be arbitrarily located. Both the shared library and XIP techniques are made possible by emulating an MMU's memory mapping feature with a data section base register (DSBR) and a data section base table (DSBT). We have implemented these proposed techniques in a commercial ADSL (Asymmetric Digital Subscriber Line) home network gateway equipped with an MMU-less ARM7TDMI processor core, 2MB flash memory, and 16MB RAM. We measured its memory usage and evaluated its performance overhead by conducting a series of experiments. These experiments clearly demonstrate the effectiveness of our techniques in reducing memory usage. The results are impressive: 35% reduction in flash memory usage when using only the shared library and 30% reduction in RAM usage when using the shared library and XIP together. These results were achieved with only a negligible performance penalty of less than 4%. Even though these techniques were applied to uClinux-based embedded systems, they can be used for any MMU-less real-time operating system.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2072240274",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1275986",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this paper, we propose the novel concept of probabilistic design for multimedia embedded systems, which is motivated by the challenge of how to design, but not overdesign, such systems while systematically incorporating performance requirements of ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4237139345",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1274858",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4242663740",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1324969",
    "publication_date": "2007-12-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Space-based radar is a suite of applications that presents many unique system design challenges. In this paper, we investigate use of RapidIO, a new high-performance embedded systems interconnect, in addressing issues associated with the high network ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4251860942",
    "type": "paratext"
  },
  {
    "title": "OnNetwork+",
    "doi": "https://doi.org/10.1145/3182171",
    "publication_date": "2018-05-01",
    "publication_year": 2018,
    "authors": "Hyeonggyu Kim; Minho Ju; Soontae Kim",
    "corresponding_authors": "",
    "abstract": "Network errors such as packet losses consume large amounts of energy. We analyzed the reason for this through measurements using the latest smartphones and full-system simulation. We found that on packet losses the smartphones maintain high frequencies for CPU without doing useful work. To address this problem, we propose a method for reducing the energy consumption by lowering the performance level by exploiting a dynamic voltage and frequency scaling mechanism when long network delays are expected. According to our experiments, our method reduces the total energy consumption of web browsing on two different smartphones by up to 10.0% and 11.5%, respectively.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2800674402",
    "type": "article"
  },
  {
    "title": "Extended Redundant-Digit Instruction Set for Energy-Efficient Processors",
    "doi": "https://doi.org/10.1145/3202664",
    "publication_date": "2018-05-22",
    "publication_year": 2018,
    "authors": "Saba Amanollahi; Ghassem Jaberipur",
    "corresponding_authors": "",
    "abstract": "The impact of extending the instruction set architecture (ISA) of a conventional binary processor by a set of redundant-digit arithmetic instructions is studied. Selected binary arithmetic instructions within a given code sequence are replaced with appropriate redundant-digit ones. The selection criteria is so enforced to lead to overall reduction of execution energy and energy-delay product (EDP). A special branch and bound algorithm is devised to modify the dataflow graph (DFG) to a new one that takes advantage of the extended redundant-digit instruction set. The DFG is obtained, via an in-house tool, from the intermediate code representation that is normally produced by the utilized compiler. The required redundant-digit arithmetic operations (including a multiplier, a multiply accumulator, and three- to four-operand redundant-digit adders specially designed for this work) have been synthesized on 45nm NanGate technology by a Synopsys Design Compiler. To evaluate the impact of the proposed ISA augmentation on actual code execution, the simulation and evaluation platform of our choice is an MIPS processor whose ISA is extended by the proposed redundant-digit instructions. Several digital signal processing benchmarks are utilized as the source of the baseline MIPS codes, which are converted (via the aforementioned algorithm) to the equivalent mixed binary/redundant-digit codes. Our experiments, as such, show up to 26% energy and 44% EDP savings.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2803332154",
    "type": "article"
  },
  {
    "title": "Algorithm/Architecture Co-optimisation Technique for Automatic Data Reduction of Wireless Read-Out in High-Density Electrode Arrays",
    "doi": "https://doi.org/10.1145/3190854",
    "publication_date": "2018-05-22",
    "publication_year": 2018,
    "authors": "Yahya H. Yassin; Francky Catthoor; Fabian Kloosterman; Jyh‐Jang Sun; João Couto; Per Gunnar Kjeldsberg; Nick Van Helleputte",
    "corresponding_authors": "",
    "abstract": "High-density electrode arrays used to read out neural activity will soon surpass the limits of the amount of data that can be transferred within reasonable energy budgets. This is true for wired brain implants when the required bandwidth becomes very high, and even more so for untethered brain implants that require wireless transmission of data. We propose an energy-efficient spike data extraction solution for high-density electrode arrays, capable of reducing the data to be transferred by over 85%. We combine temporal and spatial spike data analysis with low implementation complexity, where amplitude thresholds are used to detect spikes and the spatial location of the electrodes is used to extract potentially useful sub-threshold data on neighboring electrodes. We tested our method against a state-of-the-art spike detection algorithm, with prohibitively high implementation complexity, and found that the majority of spikes are extracted reliably. We obtain further improved quality results when ignoring very small spikes below 30% of the voltage thresholds, resulting in 91% accuracy. Our approach uses digital logic and is therefore scalable with an increasing number of electrodes.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2803405539",
    "type": "article"
  },
  {
    "title": "Runtime Precomputation of Data-Dependent Parameters in Embedded Systems",
    "doi": "https://doi.org/10.1145/3191311",
    "publication_date": "2018-05-22",
    "publication_year": 2018,
    "authors": "Elena Hammari; Per Gunnar Kjeldsberg; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "In many modern embedded systems, the available resources (e.g., CPU clock cycles, memory, and energy) are consumed nonuniformly while the system is under exploitation. Typically, the resource requirements in the system change with different input data that the system process. These data trigger different parts of the embedded software, resulting in different operations executed that require different hardware platform resources to be used. A significant research effort has been dedicated to develop mechanisms for runtime resource management (e.g., branch prediction for pipelined processors, prefetching of data from main memory to cache, and scenario-based design methodologies). All these techniques rely on the availability of information at runtime about upcoming changes in resource requirements. In this article, we propose a method for detecting upcoming resource changes based on preliminary calculation of software variables that have the most dynamic impact on resource requirements in the system. We apply the method on a modified real-life biomedical algorithm with real input data and estimate a 40% energy reduction as compared to static DVFS scheduling. Comparing to dynamic DVFS scheduling, an 18% energy reduction is demonstrated.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2803416720",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3206342",
    "publication_date": "2018-05-22",
    "publication_year": 2018,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2811498926",
    "type": "editorial"
  },
  {
    "title": "Enabling On-the-Fly Hardware Tracing of Data Reads in Multicores",
    "doi": "https://doi.org/10.1145/3322642",
    "publication_date": "2019-06-10",
    "publication_year": 2019,
    "authors": "Mounika Ponugoti; Aleksandar Milenković",
    "corresponding_authors": "",
    "abstract": "Software debugging is one of the most challenging aspects of embedded system development due to growing hardware and software complexity, limited visibility of system components, and tightening time-to-market. To find software bugs faster, developers often rely on on-chip trace modules with large buffers to capture program execution traces with minimum interference with program execution. However, the high volumes of trace data and the high cost of trace modules limit the visibility into the system operation to short program segments. This article introduces a new hardware/software technique for capturing and filtering read data value traces in multicores that enables a complete reconstruction of parallel program execution. The proposed technique exploits tracking of data reads in data caches and cache coherence protocol states to minimize the number of trace messages streamed out of the target platform to the software debugger. The effectiveness of the proposed technique is determined by analyzing the required trace port bandwidth and trace buffer sizes as a function of the data cache size and the number of processor cores. The results show that the proposed technique significantly reduces the required trace port bandwidth, from 12.2 to 73.9 times, when compared to the Nexus-like read data value tracing, thus enabling continuous on-the-fly data tracing at modest hardware cost.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2951385121",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Cryptographic Engineering for Internet of Things: Security Foundations, Lightweight Solutions, and Attacks",
    "doi": "https://doi.org/10.1145/3322641",
    "publication_date": "2019-05-31",
    "publication_year": 2019,
    "authors": "Lejla Batina; Sherman S. M. Chow; Gerhard P. Hancke; Zhe Liu",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Introduction to the Special Issue on Cryptographic Engineering for Internet of Things: Security Foundations, Lightweight Solutions, and Attacks Editors: Lejla Batina Radboud University Radboud UniversityView Profile , Sherman S. M. Chow Chinese University of Hong Kong Chinese University of Hong KongView Profile , Gerhard Hancke City University of Hong Kong City University of Hong KongView Profile , Zhe Liu University of Luxembourg 8 Nanjing University of Aeronautics and Astronautics University of Luxembourg 8 Nanjing University of Aeronautics and AstronauticsView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 18Issue 3May 2019 Article No.: 22pp 1–3https://doi.org/10.1145/3322641Published:05 June 2019Publication History 0citation315DownloadsMetricsTotal Citations0Total Downloads315Last 12 Months68Last 6 weeks7 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2956195710",
    "type": "article"
  },
  {
    "title": "Power-mode-aware Memory Subsystem Optimization for Low-power System-on-Chip Design",
    "doi": "https://doi.org/10.1145/3356583",
    "publication_date": "2019-09-30",
    "publication_year": 2019,
    "authors": "Manuel Strobel; Martin Radetzki",
    "corresponding_authors": "",
    "abstract": "The memory subsystem is increasingly subject to an intensive energy minimization effort in embedded and System-on-Chip development. While the main focus is typically put on energy consumption reduction, there are other optimization aspects that become more and more relevant as well, e.g., peak power constraints or time budgets. In this regard, the present article makes the following contributions. Taking industrial-grade information into account, different Static Random-Access Memory (SRAM) power modes and their characteristics are presented at first. Using this information, a comprehensive optimization model with the main intention of energy minimization is defined. It is based on memory access statistics that represent the embedded software of interest, which allows for application-tailored improvements. Further, it considers different power states of the memory subsystem and enables the definition of peak power and time corridor constraints. The presented two-stage implementation of this optimization model allows the handling of large design spaces. Clearly defined interfaces facilitate the exchange of individual workflow parts in a plug-and-play fashion and further enable a neat integration of our optimization method with existing hardware/software (HW/SW) codesign synthesis flows. A general evaluation for different technology nodes yields that the optimization potential of memory low-power modes increases with advancing miniaturization but also depends on the data footprint of the embedded software. Experimental results for a set of benchmark applications confirm these findings and provide energy savings of up to 90% and over 60% on average compared to a monolithic memory layout without low-power modes.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2979363755",
    "type": "article"
  },
  {
    "title": "Synterface",
    "doi": "https://doi.org/10.1145/3358188",
    "publication_date": "2019-10-07",
    "publication_year": 2019,
    "authors": "Aditya Sridhar; Mohamed Ibrahim; Krishnendu Chakrabarty",
    "corresponding_authors": "",
    "abstract": "Flow-based microfluidic biochips can be used to perform bioassays by manipulating a large number of on-chip valves. These biochips are increasingly used today for biomolecular recognition, single-cell screening, and point-of-care disease diagnostics, and design-automation solutions for flow-based microfluidics enable the mapping and optimization of bimolecular protocols and software-based valve control. However, a key problem that has not received adequate attention is chip-to-world interfacing, which requires the use of off-chip control equipment to provide control signals for the on-chip valves. This problem is exacerbated by the increase in the number of valves as chips get more complex. To address the interfacing problem, we present an efficient pin-count minimization (synthesis) problem, referred to as Synterface, which uses on-chip microfluidic logic gates and optimization based on concepts from linear algebra. We present results to show that Synterface significantly reduces pin-count and simplifies the external interface for flow-based microfluidics.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2979365743",
    "type": "article"
  },
  {
    "title": "Techniques and Analysis for Mixed-criticality Scheduling with Mode-dependent Server Execution Budgets",
    "doi": "https://doi.org/10.1145/3358234",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Muhammad Ali Awan; Konstantinos Bletsas; Pedro F. Souto; Benny Åkesson; Eduardo Tovar",
    "corresponding_authors": "",
    "abstract": "In mixed-criticality systems, tasks of different criticality share system resources, mainly to reduce cost. Cost is further reduced by using adaptive mode-based scheduling arrangements, such as Vestal’s model, to improve resource efficiency, while guaranteeing schedulability of critical functionality. To simplify safety certification, servers are often used to provide temporal isolation between tasks. In its simplest form, a server is a periodically recurring time window, in which some tasks are scheduled. A server’s computational requirements may greatly vary in different modes, although state-of-the-art techniques and schedulability tests do not allow different budgets to be used by a server in different modes. This results in a single conservative execution budget for all modes, increasing system cost. The goal of this paper is to reduce the cost of mixed-criticality systems through three main contributions: (i) a scheduling arrangement for uniprocessor systems employing fixed-priority scheduling within periodic servers, whose budgets are dynamically adjusted at run-time in the event of a mode change, (ii) a new schedulability analysis for such systems, and (iii) heuristic algorithms for assigning budgets to servers in different modes and ordering the execution of the servers. Experiments with synthetic task sets demonstrate considerable improvements (up to 52.8%) in scheduling success ratio when using dynamic server budgets vs. static “one-size-fits-all-modes” budgets.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2979433922",
    "type": "article"
  },
  {
    "title": "GRec",
    "doi": "https://doi.org/10.1145/3350533",
    "publication_date": "2019-09-30",
    "publication_year": 2019,
    "authors": "Guy Durrieu; Claire Pagetti",
    "corresponding_authors": "",
    "abstract": "research-article Share on GRec: Automatic Computation of Reconfiguration Graphs for Multi-core Platforms Authors: Guy Durrieu ONERA ONERAView Profile , Claire Pagetti ONERA ONERA 0000-0001-7265-1839View Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 18Issue 5September 2019 Article No.: 41pp 1–24https://doi.org/10.1145/3350533Published:09 October 2019Publication History 1citation110DownloadsMetricsTotal Citations1Total Downloads110Last 12 Months5Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2979772093",
    "type": "article"
  },
  {
    "title": "Alleria",
    "doi": "https://doi.org/10.1145/3358193",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Hadi Brais; Preeti Ranjan Panda",
    "corresponding_authors": "",
    "abstract": "Application analysis and simulation tools are used extensively by embedded system designers to improve existing optimization techniques or develop new ones. We propose the Alleria framework to make it easier for designers to comprehensively collect critical information such as virtual and physical memory addresses, accessed values, and thread schedules about one or more target applications. Such profilers often incur substantial performance overheads that are orders of magnitude larger than native execution time. We discuss how that overhead can be significantly reduced using a novel profiling mechanism called adaptive profiling. We develop a heuristic-based adaptive profiling mechanism and evaluate its performance using single-threaded and multi-threaded applications. The proposed technique can improve profiling throughput by up to 145% and by 37% on an average, enabling Alleria to be used to comprehensively profile applications with a throughput of over 3 million instructions per second.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2979859319",
    "type": "article"
  },
  {
    "title": "エネルギー効率の良いプロセッサのための拡張冗長ディジット命令セット【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Amanollahi Saba; Ghassem Jaberipur",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3188181658",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3160927",
    "publication_date": "2018-04-26",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Today’s MPSoCs (multiprocessor systems-on-chip) have brought up massively parallel processor array accelerators that may achieve a high computational efficiency by exploiting multiple levels of parallelism and different memory hierarchies. Such parallel ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4245787918",
    "type": "paratext"
  },
  {
    "title": "Introduction to the Special Issue on Real-Time Computing in the IoT-to-Edge-to-Cloud Continuum",
    "doi": "https://doi.org/10.1145/3605180",
    "publication_date": "2024-01-10",
    "publication_year": 2024,
    "authors": "Daniel Casini; Dakshina Dasari; Matthias Becker; Giorgio Buttazzo",
    "corresponding_authors": "",
    "abstract": "Special Issue Part 1 (Issue 3) and Part 2 (Issue 4) of AIEDAM are based on a workshop on Learning and Creativity held at the 2002 conference on Artificial Intelligence in Design, AID '02 (www.cad.strath.ac.uk/AID02_workshop/Workshop_webpage.html; Gero, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4390696061",
    "type": "article"
  },
  {
    "title": "Elements of Timed Pattern Matching",
    "doi": "https://doi.org/10.1145/3645114",
    "publication_date": "2024-02-10",
    "publication_year": 2024,
    "authors": "Dogan Ulus; Thomas Ferrère; Eugène Asarin; Dejan Ničković; Oded Maler",
    "corresponding_authors": "",
    "abstract": "The rise of machine learning and cloud technologies has led to a remarkable influx of data within modern cyber-physical systems. However, extracting meaningful information from this data has become a significant challenge due to its volume and complexity. Timed pattern matching has emerged as a powerful specification-based runtime verification and temporal data analysis technique to address this challenge. In this paper, we provide a comprehensive tutorial on timed pattern matching that ranges from the underlying algebra and pattern specification languages to performance analyses and practical case studies. Analogous to textual pattern matching, timed pattern matching is the task of finding all time periods within temporal behaviors of cyber-physical systems that match a predefined pattern. Originally we introduced and solved several variants of the problem using the name of match sets, which has evolved into the concept of timed relations over the past decade. Here we first formalize and present the algebra of timed relations as a standalone mathematical tool to solve the pattern matching problem of timed pattern specifications. In particular, we show how to use the algebra of timed relations to solve the pattern matching problem for timed regular expressions and metric compass logic in a unified manner. We experimentally demonstrate that our timed pattern matching approach performs and scales well in practice. We further provide in-depth insights into the similarities and fundamental differences between monitoring and matching problems as well as regular expressions and temporal logic formulas. Finally, we illustrate the practical application of timed pattern matching through two case studies, which show how to extract structured information from temporal datasets obtained via simulations or real-world observations. These results and examples show that timed pattern matching is a rigorous and efficient technique in developing and analyzing cyber-physical systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4391723340",
    "type": "article"
  },
  {
    "title": "Energy Management for Fault-tolerant (m,k)-constrained Real-time Systems That Use Standby-Sparing",
    "doi": "https://doi.org/10.1145/3648365",
    "publication_date": "2024-02-21",
    "publication_year": 2024,
    "authors": "Linwei Niu; Danda B. Rawat; Dakai Zhu; Jonathan Musselwhite; Zonghua Gu; Qingxu Deng",
    "corresponding_authors": "",
    "abstract": "Fault tolerance, energy management, and quality of service (QoS) are essential aspects for the design of real-time embedded systems. In this work, we focus on exploring methods that can simultaneously address the above three critical issues under standby-sparing. The standby-sparing mechanism adopts a dual-processor architecture in which each processor plays the role of the backup for the other one dynamically. In this way, it can provide fault tolerance subject to both permanent and transient faults. Due to its duplicate executions of the real-time jobs/tasks, the energy consumption of a standby-sparing system could be quite high. With the purpose of reducing energy under standby-sparing, we proposed three novel scheduling schemes: The first one is for (1, 1)-constrained tasks, and the second one and the third one (which can be combined into an integrated approach to maximize the overall energy reduction) are for general ( m,k )-constrained tasks that require that among any k consecutive jobs of a task no more than ( k - m ) out of them could miss their deadlines. Through extensive evaluations and performance analysis, our results demonstrate that compared with the existing research, the proposed techniques can reduce energy by up to 11% for (1, 1)-constrained tasks and 25% for general ( m,k )-constrained tasks while assuring ( m,k )-constraints and fault tolerance as well as providing better user perceived QoS levels under standby-sparing.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4392015006",
    "type": "article"
  },
  {
    "title": "NAVIDRO, a CARES architectural style for configuring drone co-simulation",
    "doi": "https://doi.org/10.1145/3651889",
    "publication_date": "2024-03-17",
    "publication_year": 2024,
    "authors": "Loïc Salmon; Pierre-Yves Pillain; Goulven Guillou; Jean‐Philippe Babau",
    "corresponding_authors": "",
    "abstract": "One primary objective of drone simulation is to evaluate diverse drone configurations and contexts aligned with specific user objectives. The initial challenge for simulator designers involves managing the heterogeneity of drone components, encompassing both software and hardware systems, as well as the drone’s behavior. To facilitate the integration of these diverse models, the Functional Mock-Up Interface (FMI) for co-simulation proposes a generic data-oriented interface. However, an additional challenge lies in simplifying the configuration of co-simulation, necessitating an approach to guide the modeling of parametric features and operational conditions such as failures or environment changes. The article addresses this challenge by introducing CARES, a model-driven engineering and component-based approach for designing drone simulators, integrating the FMI for co-simulation. The proposed models incorporate concepts from component-based software engineering and FMI. The NAVIDRO architectural style is presented for designing and configuring drone co-simulation. CARES utilizes a code generator to produce structural glue code (Java or C++), facilitating the integration of FMI-based domain-specific code. The approach is evaluated through the development of a simulator for navigation functions in an autonomous underwater vehicle, demonstrating its effectiveness in assessing various autonomous underwater vehicle configurations and contexts.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4392895240",
    "type": "article"
  },
  {
    "title": "Special Issue on Post-Quantum Cryptography for Embedded Systems",
    "doi": "https://doi.org/10.1145/3641852",
    "publication_date": "2024-03-29",
    "publication_year": 2024,
    "authors": "Shivam Bhasin; Fabrizio De Santis; Francesco Regazzoni",
    "corresponding_authors": "",
    "abstract": "This survey provides a comparative overview of code-based signature schemes with respect to security and performance. Furthermore, we explicitly describe serveral code-based signature schemes with additional properties such as identity-based, threshold ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4393318093",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on tinyML",
    "doi": "https://doi.org/10.1145/3658375",
    "publication_date": "2024-05-11",
    "publication_year": 2024,
    "authors": "Theocharis Theocharides; Charlotte Frenkel; Lukas Cavigelli",
    "corresponding_authors": "",
    "abstract": "Special Issue Part 1 (Issue 3) and Part 2 (Issue 4) of AIEDAM are based on a workshop on Learning and Creativity held at the 2002 conference on Artificial Intelligence in Design, AID '02 (www.cad.strath.ac.uk/AID02_workshop/Workshop_webpage.html; Gero, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4396834200",
    "type": "article"
  },
  {
    "title": "CARIn: Constraint-Aware and Responsive Inference on Heterogeneous Devices for Single- and Multi-DNN Workloads",
    "doi": "https://doi.org/10.1145/3665868",
    "publication_date": "2024-05-23",
    "publication_year": 2024,
    "authors": "Ioannis Panopoulos; Stylianos I. Venieris; Iakovos S. Venieris",
    "corresponding_authors": "",
    "abstract": "The relentless expansion of deep learning applications in recent years has prompted a pivotal shift toward on-device execution, driven by the urgent need for real-time processing, heightened privacy concerns, and reduced latency across diverse domains. This article addresses the challenges inherent in optimising the execution of deep neural networks (DNNs) on mobile devices, with a focus on device heterogeneity, multi-DNN execution, and dynamic runtime adaptation. We introduce CARIn, a novel framework designed for the optimised deployment of both single- and multi-DNN applications under user-defined service-level objectives. Leveraging an expressive multi-objective optimisation framework and a runtime-aware sorting and search algorithm (RASS) as the MOO solver, CARIn facilitates efficient adaptation to dynamic conditions while addressing resource contention issues associated with multi-DNN execution. Notably, RASS generates a set of configurations, anticipating subsequent runtime adaptation, ensuring rapid, low-overhead adjustments in response to environmental fluctuations. Extensive evaluation across diverse tasks, including text classification, scene recognition, and face analysis, showcases the versatility of CARIn across various model architectures, such as Convolutional Neural Networks and Transformers, and realistic use cases. We observe a substantial enhancement in the fair treatment of the problem's objectives, reaching 1.92x when compared to single-model designs and up to 10.69x in contrast to the state-of-the-art OODIn framework. Additionally, we achieve a significant gain of up to 4.06x over hardware-unaware designs in multi-DNN applications. Finally, our framework sustains its performance while effectively eliminating the time overhead associated with identifying the optimal design in response to environmental challenges.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4398238712",
    "type": "article"
  },
  {
    "title": "A Hybrid Sparse-dense Defensive DNN Accelerator Architecture against Adversarial Example Attacks",
    "doi": "https://doi.org/10.1145/3677318",
    "publication_date": "2024-07-09",
    "publication_year": 2024,
    "authors": "Xingbin Wang; Boyan Zhao; Yulan Su; Sisi Zhang; Fengkai Yuan; Jun Zhang; Dan Meng; Rui Hou",
    "corresponding_authors": "",
    "abstract": "Understanding how to defend against adversarial attacks is crucial for ensuring the safety and reliability of these systems in real-world applications. Various adversarial defense methods are proposed, which aim at improving the robustness of neural networks against adversarial attacks by changing the model structure, adding detection networks, and adversarial purification network. However, deploying adversarial defense methods in existing DNN accelerators or defensive accelerators leads to many key issues. To address these challenges, this article proposes sDNNGuard , an elastic heterogeneous DNN accelerator architecture that can efficiently orchestrate the simultaneous execution of original ( target ) DNN networks and the detect algorithm or network. It not only supports for dense DNN detect algorithms, but also allows for sparse DNN defense methods and other mixed dense-sparse (e.g., dense-dense and sparse-dense) workloads to fully exploit the benefits of sparsity. sDNNGuard with a CPU core also supports the non-DNN computing and allows the special layer of the neural network, and used for the conversion for sparse storage format for weights and activation values. To reduce off-chip traffic and improve resources utilization, a new hardware abstraction with elastic on-chip buffer/computing resource management is proposed to achieve dynamical resource scheduling mechanism. We propose an extended AI instruction set for neural networks synchronization, task scheduling and efficient data interaction. Experiment results show that sDNNGuard can effectively validate the legitimacy of the input samples in parallel with the target DNN model, achieving an average 1.42× speedup compared with the state-of-the-art accelerators.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400460173",
    "type": "article"
  },
  {
    "title": "Trust Based Active Game Data Collection Scheme in Smart Cities",
    "doi": "https://doi.org/10.1145/3677319",
    "publication_date": "2024-07-22",
    "publication_year": 2024,
    "authors": "Zhuoqun Xia; Z.Q. Wang; Xiao Liu",
    "corresponding_authors": "",
    "abstract": "The concept of a smart city is to equip sensors to various objects in urban life to monitor areas and collect sensing data, and make wise decisions based on the collected data. However, some malicious sensor devices may interrupt and interfere with data collection, leading to a reduction in the integrity and availability of information, thereby causing harm to Internet of Things (IoT) applications. Therefore, identifying the credibility of sensor nodes to ensure the credibility of data collection is a challenge. This article proposes a trust-based active game data collection (TAGDC) scheme to collect trust data in the IoT. This TAGDC scheme mainly includes the following parts: (1) An active trust framework plus evolutionary game theory is proposed to encourage high-energy sensors to send detection routes and quickly obtain sensor trust. (2) In order to balance the data security requirements of subnetworks, the number and frequency of detection routes required by subnetworks are estimated through mechanism modeling and fuzzy analytic hierarchy process. (3) The design focuses on the internal trust computing model in the region to evaluate the trust of nodes. The findings of the experiment demonstrate that the TAGDC scheme, as described in this research study, enhances the accuracy of identifying malicious nodes by 20%, reduces the required identification time by 40%, and improves the data collection success rate by 5%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400887705",
    "type": "article"
  },
  {
    "title": "Co-Approximator: Enabling Performance Prediction in Colocated Applications.",
    "doi": "https://doi.org/10.1145/3677180",
    "publication_date": "2024-07-25",
    "publication_year": 2024,
    "authors": "Rafiuzzaman Mohammad; Sathish Gopalakrishnan; Karthik Pattabiraman",
    "corresponding_authors": "",
    "abstract": "Today’s Internet of Things (IoT) devices can colocate multiple applications on a platform with hardware resource sharing. Such colocations allow for increasing the throughput of contemporary IoT applications, similar to the use of multi-tenancy in clouds. However, avoiding performance interference among colocated applications through virtualized performance isolation is expensive in IoT platforms due to resource limitations. Hence, on the one hand, colocated IoT applications without performance isolation contend for shared limited resources, which makes their performance variance discontinuous and a priori unknown. On the other hand, different combinations of colocated applications make the overall state space exceedingly large. All of these make such colocated routines challenging to predict, making it difficult to plan which applications to colocate on which platform. We propose Co - Approximator , a technique for systematically sampling an exponentially large colocated application state space and efficiently approximating it from only four available complete colocation samples. We demonstrate the performance of Co - Approximator with 17 standard benchmarks and three pipelined data processing applications on different IoT platforms, where on average, Co - Approximator reduces existing techniques’ approximation error from 61% to just 7%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400983910",
    "type": "article"
  },
  {
    "title": "APB-tree: An Adaptive Pre-built Tree Indexing Scheme for NVM-based IoT Systems",
    "doi": "https://doi.org/10.1145/3677179",
    "publication_date": "2024-07-26",
    "publication_year": 2024,
    "authors": "Shih-Wen Hsu; Yen-Ting Chen; Kam-Yiu Lam; Yuan-Hao Chang; Wei‐Kuan Shih; Han‐Chieh Chao",
    "corresponding_authors": "",
    "abstract": "With the proliferation of sensors and the emergence of novel applications, IoT data has grown exponentially in recent years. Given this trend, efficient data management is crucial for a system to easily access vast amounts of information. For decades, B + -tree-based indexing schemes have been widely adopted for providing effective search in IoT systems. However, in systems with pre-distributed sensors, B + -tree-based indexes fail to optimally utilize the known IoT data distribution, leading to significant write overhead and energy consumption. Furthermore, as non-volatile memory (NVM) technology emerges as the alternative storage medium, the inherent write asymmetry of NVM leads to instability issues in IoT systems, especially for write-intensive applications. In this research, by considering the write overheads of tree-based indexing schemes and key-range distribution assumption, we rethink the design of the tree-based indexing schemes and propose an adaptive pre-built tree (APB-tree) indexing scheme to reduce the write overhead in serving insertion and deletion of keys in the NVM-Based IoT system. The APB-tree profiles the hot region of the key distribution from the known key range to pre-allocate the index structure that alleviates online index management costs and run-time index overhead. Meanwhile, the APB-tree maintains the scalability of a tree-based index structure to accommodate the large amount of new data brought by the additional nodes to the IoT system. Extensive experiments demonstrate that our solution achieves significant performance improvements in write operations while maintaining effective energy consumption in the NVM-based IoT system. We compare the energy and time required for basic key operations like Put(), Get(), and Delete() in APB-trees and B + -tree-based indexing schemes. Under workloads with varying ratios of these operations, the proposed design effectively reduces execution time by 47% to 72% and energy consumption by 11% to 72% compared to B + -tree-based indexing schemes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401029860",
    "type": "article"
  },
  {
    "title": "Software Optimization and Design Methodology for Low Power Computer Vision Systems",
    "doi": "https://doi.org/10.1145/3687310",
    "publication_date": "2024-08-07",
    "publication_year": 2024,
    "authors": "Soonhoi Ha; Eunjin Jeong",
    "corresponding_authors": "",
    "abstract": "This tutorial article addresses a low power computer vision system as an example of a growing application domain of neural networks, exploring various technologies developed to enhance accuracy within the resource and performance constraints imposed by the hardware platform. Focused on a given hardware platform and network model, software optimization techniques, including pruning, quantization, low-rank approximation, and parallelization, aim to satisfy resource and performance constraints while minimizing accuracy loss. Due to the interdependence of model compression approaches, their systematic application is crucial, as evidenced by winning solutions in the Lower Power Image Recognition Challenge (LPIRC) of 2017 and 2018. Recognizing the typical heterogeneity of processing elements in contemporary hardware platforms, the effective utilization through parallelizing neural networks emerges as increasingly vital for performance enhancement. The article advocates for a more impactful strategy—designing a network architecture tailored to a specific hardware platform. For detailed information on each technique, the article provides corresponding references.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401395552",
    "type": "article"
  },
  {
    "title": "Load-balanced Routing Heuristics for Bandwidth Allocation of AVB Flow in TSN",
    "doi": "https://doi.org/10.1145/3687307",
    "publication_date": "2024-08-28",
    "publication_year": 2024,
    "authors": "Meng Wang; Yiqin Lu; Haihan Wang; Zhuoxing Chen; Jiancheng Qin",
    "corresponding_authors": "",
    "abstract": "Time-Sensitive Networking (TSN) is a new technology developed from Ethernet that guarantees deterministic transmission of various types of flows, such as Time-triggered (TT) flows and Audio-video-bridging (AVB) flows, in the same network. Currently, Time-aware Shaping (TAS) and Credit-based Shaping (CBS) are widely used for scheduling hybrid flows, where the credit value in CBS is directly linked to the logical bandwidth value idleSlope , which affects the real-time performance of AVB flows. However, as the network scale increases, existing bandwidth allocation methods result in higher computation times and lower allocation success rates. In this article, the aforementioned problem is addressed by two-step: first, we design a load-balanced routing heuristic (LBRH) to improve the allocation success rate; second, we accelerate the CBS bandwidth allocation by using unified bandwidth allocation scheme, which integrates LBRH and further improves the allocation success rate. Performance evaluation in multiple test cases shows that LBRH can improve the success rate of bandwidth allocation, and the unified bandwidth allocation scheme integrating LBRH significantly reduces the overall execution time while improving the success rate of bandwidth allocation, which is more suitable for large-scale TSN networks with complex routing.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401395623",
    "type": "article"
  },
  {
    "title": "Tutorial: A Novel Runtime Environment for Accelerator-Rich Heterogeneous Architectures",
    "doi": "https://doi.org/10.1145/3687463",
    "publication_date": "2024-08-08",
    "publication_year": 2024,
    "authors": "Joshua Mack; Anish Krishnakumar; Ümit Y. Ogras; Ali Akoglu",
    "corresponding_authors": "",
    "abstract": "As the landscape of computing advances, system designers are increasingly exploring methodologies that leverage higher levels of heterogeneity to enhance performance within constrained size, weight, power, and cost parameters. CEDR (Compiler-integrated Extensible DSSoC Runtime) stands as an ecosystem facilitating productive and efficient application development and deployment across heterogeneous computing systems. It fosters the co-design of applications, scheduling heuristics, and accelerators within a unified framework. Our goal is to present CEDR as a promising environment for lifting the barriers to research on heterogeneous systems and addressing the broader challenges within domain-specific architectures. We introduce CEDR and discuss the evolutionary design decisions underlying its programming model. Subsequently, we explore its utility for a broad range of users through design sweeps on off-the-shelf heterogeneous platforms across scheduling heuristics, hardware compositions, and workload scenarios.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401427289",
    "type": "article"
  },
  {
    "title": "High Performance and Predictable Shared Last-level Cache for Safety-Critical Systems",
    "doi": "https://doi.org/10.1145/3687308",
    "publication_date": "2024-08-08",
    "publication_year": 2024,
    "authors": "Zhuanhao Wu; Anirudh Mohan Kaushik; Hiren Patel",
    "corresponding_authors": "",
    "abstract": "We propose ZeroCost-LLC (ZCLLC), a novel shared inclusive last-level cache (LLC) design for timing predictable multi-core platforms that offers lower worst-case latency (WCL) when compared with a traditional shared inclusive LLC design. ZCLLC achieves low WCL by eliminating certain memory operations in the form of cache line invalidations across the cache hierarchy that are a consequence of a core’s memory request that misses in the cache hierarchy and when there is no vacant entry in the LLC to accommodate the fetched data for this request. In addition to low WCL, ZCLLC offers performance benefits in the form of additional caching capacity and unlike state-of-the-art approaches, ZCLLC does not impose any constraints on its usage across multiple cores. In this work, we describe the impact of LLC cache line invalidations on the WCL and systematically build solutions to eliminate these invalidations resulting in ZCLLC. We also present ZCLLC-OPT, an optimized variant of ZCLLC that offers lower WCL and improved average-case performance over ZCLLC. We apply optimizations to the shared bus arbitration mechanism and extend the micro-architecture of ZCLLC to allow for overlapping memory requests to the main memory. Our analysis reveals that the analytical WCL of a memory request under ZCLLC-OPT is 87.0%, 93.8%, and 97.1% lower than that under state-of-the-art LLC partition sharing techniques for 2, 4, and 8 cores, respectively. ZCLLC-OPT shows average-case performance speedups of 1.89×, 3.36×, and 6.24× compared with the state-of-the-art LLC partition sharing techniques for 2, 4, and 8 cores, respectively. When compared with the original ZCLLC that does not have any optimizations, ZCLLC-OPT shows lower analytical WCLs that are 76.5%, 82.6%, and 86.2% lower compared with ZCLLC-NORMAL for 2, 4, and 8 cores, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401428548",
    "type": "article"
  },
  {
    "title": "Transient Fault Detection in Tensor Cores for Modern GPUs",
    "doi": "https://doi.org/10.1145/3687483",
    "publication_date": "2024-08-28",
    "publication_year": 2024,
    "authors": "Mohammad Hafezan; Ehsan Atoofian",
    "corresponding_authors": "",
    "abstract": "Deep neural networks (DNNs) have emerged as an effective solution for many machine learning applications. However, the great success comes with the cost of excessive computation. The Volta graphics processing unit (GPU) from NVIDIA introduced a specialized hardware unit called tensor core (TC) aiming at meeting the growing computation demand needed by DNNs. Most previous studies on TCs have focused on performance improvement through the utilization of the TC's high degree of parallelism. However, as DNNs are deployed into security-sensitive applications such as autonomous driving, the reliability of TCs is as important as performance. In this work, we exploit the unique architectural characteristics of TCs and propose a simple and implementation-efficient hardware technique called fault detection in tensor core (FDTC) to detect transient faults in TCs. In particular, FDTC exploits the zero-valued weights that stem from network pruning as well as sparse activations arising from the common ReLU operator to verify tensor operations. The high level of sparsity in tensors allows FDTC to run original and verifying products simultaneously, leading to zero performance penalty. For applications with a low sparsity rate, FDTC relies on temporal redundancy to re-execute effectual products. FDTC schedules the execution of verifying products only when multipliers are idle. Our experimental results reveal that FDTC offers 100% fault coverage with no performance penalty and small energy overhead in TCs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401482586",
    "type": "article"
  },
  {
    "title": "Combining Weight Approximation, Sharing and Retraining for Neural Network Model Compression",
    "doi": "https://doi.org/10.1145/3687466",
    "publication_date": "2024-08-10",
    "publication_year": 2024,
    "authors": "Prachi Kashikar; Olivier Sentieys; Sharad Sinha",
    "corresponding_authors": "",
    "abstract": "Neural network model compression is very important to achieve model deployment based on the memory and storage available in different computing systems. Generally, the continuous drive for higher accuracy in these models increases their size and complexity, making it challenging to deploy them on resource-constrained computing environments. This article proposes various algorithms for model compression by exploiting weight characteristics and conducts an in-depth study of their performance. The algorithms involve manipulating exponents and mantissa in the floating-point representations of weights. In addition, we also present a retraining method that uses the proposed algorithms to further reduce the size of pre-trained models. The results presented in this article are mainly on BFloat16 floating-point format. The proposed weight manipulation algorithms save at least 20% of memory on state-of-the-art image classification models with very minor accuracy loss. This loss is bridged using the retraining method that saves at least 30% of memory, with potential memory savings of up to 43%. We compare the performance of the proposed methods against the state-of-the-art model compression techniques in terms of accuracy, memory savings, inference time, and energy.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401482614",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Specification and Design Languages (FDL 2021)",
    "doi": "https://doi.org/10.1145/3677316",
    "publication_date": "2024-08-14",
    "publication_year": 2024,
    "authors": "Julien Deantoni; Alain Girault; Daniel Große",
    "corresponding_authors": "",
    "abstract": "The \"operational approach\" to software development is based on separation of problem-oriented and implementation-oriented concerns, and features executable specifications and transformational implementation. \"Operational specification languages\" are ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401572498",
    "type": "article"
  },
  {
    "title": "Efficient Low-Memory Implementation of Sparse CNNs Using Encoded Partitioned Hybrid Sparse Format",
    "doi": "https://doi.org/10.1145/3687239",
    "publication_date": "2024-08-22",
    "publication_year": 2024,
    "authors": "Barnali Basak; Pallab Dasgupta; Arpan Pal",
    "corresponding_authors": "",
    "abstract": "Certain data compression techniques like pruning leads to unstructured sparse Convolution Neural Network (CNN) models without directly leveraging sparsity in optimizing both memory consumption and inference latency of a model having low to medium sparsity. State-of-the-art storage techniques either optimize model size at the cost of execution latency or optimize inference latency at the overhead of the memory consumption of the model. This tradeoff is largely due to the absence of storage selection methodology addressing sparsity sensitivity , arising from varied sparsity and positions of nonzero values called sparsity structure across different sparse layers of a model. However, this issue remains unexplored due to the lack of support to handle sparse data in the current deployment standards for edge devices. This article introduces a data compaction strategy for unstructured sparse data that not only compresses nonzero data but also encodes it, leveraging the memory consumption and latency reduction benefits of both data compression and data encoding techniques . We propose a novel storage representation, named Encoded Partitioned Hybrid Sparse (EPaHS) format, which addresses sparsity sensitivity by customizing data storage based on the sparsity structure of the data. Our data compaction technique and storage solution optimizes the tradeoff between the memory consumption and inference latency of a sparse model without altering the network architecture and affecting its accuracy. Our solution easily extends to higher-dimensional data and outperforms standard storage solutions. It proves to be beneficial to all the valid mode orientations of multi-dimensional data. For an important health and wellness application, a single-lead short-time ECG classification model, EPaHS achieves up to \\({\\tt 16.18\\%}\\) reduction in size and \\({\\tt 15.16\\%}\\) reduction in latency when compared to its original model of \\({\\tt 42}\\) MB size and \\({\\tt 26.35}\\) sec latency, having \\({\\tt \\approx 59\\%}\\) sparsity. For a ResNet50 model handling higher-dimensional data, it achieves \\({\\tt 21.33\\%}\\) size reduction and \\({\\tt 53.9\\%}\\) latency gain against the original model of \\({\\tt 3265}\\) KB size and \\({\\tt 1.7}\\) sec latency, having \\({\\tt \\approx 67\\%}\\) sparsity.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401767502",
    "type": "article"
  },
  {
    "title": "SLEXNet: Adaptive Inference Using Slimmable Early Exit Neural Networks",
    "doi": "https://doi.org/10.1145/3689632",
    "publication_date": "2024-08-24",
    "publication_year": 2024,
    "authors": "Başar Kütükçü; Sabur Baidya; Sujit Dey",
    "corresponding_authors": "",
    "abstract": "Deep learning is a proven method in many applications. However, it requires high computation resources and usually has a constant architecture. Mobile systems are good candidates to benefit from deep learning applications since they are closely integrated in people’s life. However, mobile systems experience varying conditions for the same reason. Constant deep learning architectures against varying resources cannot satisfy the requirements of the applications, so dynamic deep learning architectures are needed. In this work, we propose SLEXNet, a slimmable early exit neural network architecture. SLEXNet combines dynamic depth and width architectures to adapt to varying time and power conditions. Moreover, we propose a runtime scheduling algorithm that can estimate inference time and power consumption of SLEXNet variations on runtime. We train SLEXNet on real aerial drone images and implement the runtime on NVIDIA Jetson Orin. We show that our approach achieves significantly better responses to time and power requirements in varying conditions than baseline dynamic depth and width techniques in a wide range of experiments.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401846882",
    "type": "article"
  },
  {
    "title": "Improving Robustness in IoT Malware Detection through Execution Order Analysis",
    "doi": "https://doi.org/10.1145/3689427",
    "publication_date": "2024-08-26",
    "publication_year": 2024,
    "authors": "Gao-Yu Lin; Po-Yuan Wang; Shin‐Ming Cheng; Hahn-Ming Lee",
    "corresponding_authors": "",
    "abstract": "The rapid expansion of the Internet of Things (IoT) has significantly increased the prevalence of malware targeting IoT devices. Although machine learning models offer promising solutions for automatic malware detection, they are increasingly vulnerable to adversarial attacks. These attacks exploit the model’s feedback loop to iteratively refine malware, producing adversarial samples that evade detection. As such, enhancing the robustness of these models is of paramount importance. Our research introduces a novel approach to bolster malware detection by retaining additional semantic information within the execution order analysis of malware programs. The method significantly improves the resilience of detection models against adversarial samples and implements two adversarial attack methods to rigorously test our model’s robustness by generating authentic adversarial examples for validation. We highlight the critical impact of preserving semantic integrity in malware detection and present a solution to counteract the growing threat of adversarial attacks in IoT environments.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401895019",
    "type": "article"
  },
  {
    "title": "An Efficient Approach for Improving Message Acceptance Rate and Link Utilization in Time-Sensitive Networking",
    "doi": "https://doi.org/10.1145/3690638",
    "publication_date": "2024-08-29",
    "publication_year": 2024,
    "authors": "Junqiang Jiang; Shengjie Jin; Zhifang Sun; Jinxue Duan; Lizhi Liu; Li Pan; Zebo Peng",
    "corresponding_authors": "",
    "abstract": "Time-sensitive networking (TSN) is an emerging technology widely used in real-time systems for its high bandwidth and deterministic timing properties. To ensure the deterministic transmission of Time-triggered (TT) messages, a guard band mechanism is employed to prevent interference from other messages, such as Audio-Video Bridging (AVB) and Best-effort (BE) messages, before transmitting the TT messages in TSN. However, this mechanism introduces transmission delays for non-TT messages and bandwidth wastes for the physical links. Another challenge arises from the default First-in-first-out (FIFO) order of incoming messages, resulting in a relatively low acceptance rate for non-TT messages. To address these issues, a hybrid scheduling algorithm based on the min-heap structure (HSMH) is proposed. For AVB messages, HSMH sorts them in ascending style on the basis of deadlines, guaranteeing the earliest deadline message to be sent first. For BE messages, a threshold is designed to diverge them into two queues: a FIFO queue and a STF (shortest-time-first) queue. The former outputs the messages in a FIFO style, while the latter outputs messages in a STF style. All the output order of AVB messages and STF-queue messages are arranged in a min-heap structure. The algorithm can efficiently improve the transmission rate of AVB messages, the sending rate of BE messages, and the overall link utilization. Experimental results demonstrate that the proposed algorithm outperforms existing approaches in all these three aspects.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402006107",
    "type": "article"
  },
  {
    "title": "MVLevelDB <sup>+</sup> : Meeting Relative Consistency Requirements of Temporal Queries in Sensor Streams Databases",
    "doi": "https://doi.org/10.1145/3694787",
    "publication_date": "2024-09-04",
    "publication_year": 2024,
    "authors": "Kam-Yiu Lam; Xiaofei Zhao; Chunjiang Zhu; Tei‐Wei Kuo",
    "corresponding_authors": "",
    "abstract": "Ensuring relative consistency in executing temporal queries to access real-time sensor data streams maintained in a database is a challenging problem, particularly when data transmission delays are lengthy and highly variable. Due to the unordered arrivals of sensor data, the databases may contain numerous open data versions (ODVs) with undefined validity intervals. Accessing ODVs may violate the relative consistency requirements of temporal queries, resulting in incorrect results. Although the Re-execution with Every Update (REU) method can resolve this issue, it may introduce heavy re-execution costs and significant delays in query completion. In this article, we study the problem of retrieving data items with temporal consistency requirements in a multi-data-stream database. To balance response time and meet the relative consistency requirements of queries, we introduce an enhanced REU mechanism called Re-Execution with Deadline (RED). Moreover, we propose a novel optional mechanism called Backward Execution Option (BEO) for temporal queries to achieve relative consistency in their execution with quick results by relaxing the data freshness constraints. By combining RED with BEO, we formulate the Repeated BEO (RBEO) to further reduce the query response time. We extend the timestamped key-value store MVLevelDB into MVLevelDB + to implement the proposed mechanisms. To reduce the query re-execution cost as required in RED and REU, we designed the Query Pool with Execution State (QpES) mechanism to achieve relative consistency in query execution with lower checking overhead and only one re-execution. We conducted extensive evaluation experiments on MVLevelDB + using benchmark programs to illustrate their performance characteristics on handling temporal queries in the modeled IoT system.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402226878",
    "type": "article"
  },
  {
    "title": "ZIP-CNN: Design Space Exploration for CNN Implementation within a MCU",
    "doi": "https://doi.org/10.1145/3691343",
    "publication_date": "2024-09-04",
    "publication_year": 2024,
    "authors": "Thomas Garbay; Khalil Hachicha; Petr Dobiáš; Andrea Pinna; Karim Hocine; Wilfried Dron; Pedro Lusich; Imane Khalis; Bertrand Granado",
    "corresponding_authors": "",
    "abstract": "Embedded systems based on Microcontroller Units (MCUs) often gather significant quantities of data and solve various issues. Convolutional Neural Networks (CNNs) have proven their effectiveness in solving computer vision and natural language processing tasks. However, implementing CNNs within MCUs is challenging due to their high inference costs, which varies widely depending on hardware targets and CNN topologies. Despite state-of-the-art advancements, no efficient design space exploration solutions handle the wide variety of implementation solutions. In this article, we introduce the ZIP-CNN design space exploration methodology, which facilitates CNN implementation within MCUs. We developed a model that quantitatively estimates the latency, energy consumption, and memory space required to run a CNN within an MCU. This model accounts for algorithmic reductions such as knowledge distillation, pruning, or quantization and applies to any CNN topology. To demonstrate the efficiency of our methodology, we investigated LeNet5, ResNet8, and ResNet26 within three different MCUs. We made materials and supplementary results available in a GitHub repository: https://github.com/ThGbay/ZIP-CNN . The proposed method was empirically verified on three hardware targets running at 14 different operating frequencies. The three CNN topologies investigated were implemented in their default configuration in FP32, and also reduced with INT8 quantization, pruning at five different rates and with knowledge distillation. The estimates of our model are very reliable with an error of 3.29% to 15.23% for latency, 3.12% to 10.34% for energy consumption, and 1.95% to 6.31% for memory space. These results are based on on-device measurements.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402227187",
    "type": "article"
  },
  {
    "title": "Towards Analysing Cache-Related Preemption Delay in Non-Inclusive Cache Hierarchies",
    "doi": "https://doi.org/10.1145/3695768",
    "publication_date": "2024-09-10",
    "publication_year": 2024,
    "authors": "Thilo L. Fischer; Heiko Falk",
    "corresponding_authors": "",
    "abstract": "The impact of preemptions has to be considered when determining the schedulability of a task set in a preemptively scheduled system. In particular, the contents of caches can be disturbed by a preemption, thus creating context-switching costs. These context-switching costs occur when a preempted task needs to reload data from memory after a preemption. The additional delay created by this effect is termed cache-related preemption delay (CRPD). The analysis of CRPD has been extensively studied for single-level caches in the past. However, for two-level caches, the analysis of CRPD is still an emerging area of research. In contrast to a single-level cache, which is only affected by direct preemption effects, the second-level cache in a two-level hierarchy can be subject to indirect interference after a preemption. Accesses that could be served from the L1 cache in the absence of preemptions, may be forwarded to the L2 cache, as the relevant data was evicted by a preemption. These accesses create the indirect interference in the L2 cache and can cause further evictions. Recently, a CRPD analysis for two-level non-inclusive cache hierarchies was proposed. In this article, we show that this state-of-the-art analysis is unsafe as it potentially underestimates the CRPD. Furthermore, we show that the analysis is pessimistic and can overestimate the indirect preemption effects. To address these issues, we propose a novel analysis approach for the CRPD in a two-level non-inclusive cache hierarchy. We prove the correctness of the presented approach based on the set of feasible program execution traces. We implemented the presented approach in a worst-case execution time (WCET) analysis tool and compared the performance to existing analysis methods. Our evaluation shows that the presented analysis increases task set schedulability by up to 14 percentage points compared with the state-of-the-art analysis.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402391993",
    "type": "article"
  },
  {
    "title": "Introduction to Special Issue on In/Near Memory and Storage Computing for Embedded Systems",
    "doi": "https://doi.org/10.1145/3677018",
    "publication_date": "2024-09-11",
    "publication_year": 2024,
    "authors": "Liang Shi; Jingtong Shi; Xiaobo Sharon Hu; Kuan-Hsun Chen; Mengying Zhao; Weichen Liu",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402439186",
    "type": "article"
  },
  {
    "title": "Leveraging HLS to Design a Versatile &amp; High-Performance Classic McEliece Accelerator",
    "doi": "https://doi.org/10.1145/3698395",
    "publication_date": "2024-10-02",
    "publication_year": 2024,
    "authors": "Vatistas Kostalabros; Jordi Ribes; Xavier Carril; Oriol Farràs; Carles Hernàndez; Miquel Moretó",
    "corresponding_authors": "",
    "abstract": "By harnessing fundamental quantum properties, a large-scale quantum computer could undermine currently deployed public-key algorithms. The post-quantum, code-based cryptosystem Classic McEliece (CM) addresses this security concern. However, its large public key size (up to 1.3MB) poses various hardware implementation challenges. In this paper, we focus on the high memory bandwidth requirements of the CM encoding function, in the context of heterogeneous CPU-FPGA devices. More concretely, we target the acceleration of public-key loading and processing from any globally-shared or accelerator-private memory system. We present a novel and constant-time accelerator eEnc that exploits the elevated parallelization potential of FPGA devices to yield high-performance results. Our accelerator implements the encoding and the random error vector generation functions, which comprise the main computational load of Encapsulation. Two accelerator design variants are introduced, providing different hardware tradeoffs. Regarding intra-accelerator data communication, and unlike other state-of-the-art (SOTA) works, we combine a streaming protocol with task-level parallelization to remove the need to store the public key in accelerator-private memories. Our proposed design shows new record execution times over its SOTA counterparts, ranging on average from 3.5 × up to 7.7 × across the five security level parameter sets. Our end-to-end implementation in a Zynq SoC shows an average speedup of 2.2 × compared to a 64-bit vectorized CM software-baseline. The elevated logic resource consumption, characteristic of HLS designs, can be readily adjusted with a performance tradeoff.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403077726",
    "type": "article"
  },
  {
    "title": "ALOHA-FP2I: Efficient Algorithms and Hardware for Multi-Mode Rounding of Floating Point to Integer",
    "doi": "https://doi.org/10.1145/3701560",
    "publication_date": "2024-10-24",
    "publication_year": 2024,
    "authors": "Mahendra Rathor",
    "corresponding_authors": "Mahendra Rathor",
    "abstract": "Modern technology is relying on hardware accelerators to achieve enhanced performance of computing systems. In the modern computing paradigm, floating point representation of numbers has gained popularity owing to its wide dynamic range. Rounding of floating point numbers to integer is used in modern processor architectures e.g., ARM and Intel's architecture (IA) as well as in specific applications such as multimedia. However, the academic literature lacks discussion on hardware designs for rounding binary floating point numbers to integer in different rounding modes. This article presents novel efficient algorithms and hardware architecture designs for rounding binary floating point numbers to the integer for the following rounding modes: round towards zero, round up (towards positive infinity), round down (towards negative infinity), round to the nearest integer, and round to nearest even. The article also proposes an integrated multi-mode rounding (IMR) algorithm and hardware design which can be configured to a specific rounding mode among the above-mentioned five modes. This article proposes a mantissa bit of rounding (MBR) to determine the condition of rounding for the various modes. The MBR is identified on the basis of the dynamic range and precision features of floating point representation. To the best of our knowledge, we present the individual as well as an integrated hardware design for the various rounding modes for the first time in the literature. The proposed designs have been implemented on an FPGA platform to analyze the design metrics such as area, delay, and power. The results imply that the proposed designs are suitable to aid the intended hardware accelerators as they are efficient in terms of the design parameters. Moreover, this article presents the integration of the proposed rounding hardware design with the compression processor and evaluates the integration overhead which is found to be nominal (&lt;1%).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403734732",
    "type": "article"
  },
  {
    "title": "A Proof System for the SMrCaIT Calculus",
    "doi": "https://doi.org/10.1145/3701729",
    "publication_date": "2024-10-24",
    "publication_year": 2024,
    "authors": "Ningning Chen; Huibiao Zhu",
    "corresponding_authors": "",
    "abstract": "The rapid development of the Internet of Things (IoT) spurs strong global demand for related applications and technologies, especially in enhancing system reliability and security. Communication security, mobility, and real-time are the three vital features for constructing secure and reliable IoT systems. Formal methods, based on rigorous mathematical theory, are widely used to describe, analyze, model, and verify software and hardware systems, significantly improving their security and reliability. However, the current research mainly focuses on the practical applications of IoT, and there are still few studies on applying formal methods to IoT systems. As a response, our recent work has proposed the SMrCaIT calculus, which is the only process calculus currently designed for IoT that can comprehensively describe the security, real-time, and mobile features of IoT. Applying the SMrCaIT calculus enables us to model and verify IoT systems before their actual implementation, thereby providing a solid theoretical foundation for building secure and reliable IoT systems. To verify the correctness of the SMrCaIT programs, this paper presents a proof system for SMrCaIT calculus, based on the extended Hoare Logic considering time. Additionally, we explore the cooperation test between isolated proofs to further ensure messages are delivered correctly between IoT entities. The soundness of the proof system is also confirmed. A Vehicle Ad Hoc Network (VANET) case and a Multi-UAV (Unmanned Aerial Vehicle) case demonstrate the usability of our proof system in analyzing IoT scenarios.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403735102",
    "type": "article"
  },
  {
    "title": "MemScape: Sculpting Tiered Memory Management for Autonomous Vehicles",
    "doi": "https://doi.org/10.1145/3701621",
    "publication_date": "2024-10-26",
    "publication_year": 2024,
    "authors": "Dongjoo Seo; Ping-Xiang Chen; Changhoon Sung; Quang Anh Hoang; Adam Manzanares; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "The increasing complexity of autonomous vehicle (AV) systems underscores a critical challenge in efficient management of tiered memory architectures, which requires advances beyond conventional memory management strategies to achieve desired performance. This paper introduces MemScape, a novel policy designed to dynamically sculpt the memory landscape of AV systems, facilitating the optimal utilization of tiered memory configurations to minimize unexpected performance drop for AV operation. In contrast to conventional tiered memory management approaches, MemScape utilizes a user- and kernel- level memory allocation flow to migrate memory, which greatly improves system performance, while simultaneously reducing system memory cost. MemScape employs both reactive and proactive reinforcement learning agents for memory management. The reactive agent responds to current performance metrics, while the proactive agent anticipates future memory needs, ensuring optimal performance stability and efficiency. Through comprehensive emulation of an exemplar AV application pipeline utilizing tiered memory, MemScape demonstrates the potential to increase application performance by up to 3.8 × compared to vanilla Linux while saving \\(20\\% \\) system memory cost. Central to MemScape’s efficacy is its novel reactive-and-proactive reinforcement learning approach to memory promotion and demotion that ensures targeting user-level goals. Our findings showcase MemScape’s promise to revolutionize memory management practices in AV systems, presenting a performance-optimized solution adept at meeting the varying demands of emerging autonomous technologies via a combination of reactive and proactive learning strategies.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403790109",
    "type": "article"
  },
  {
    "title": "Application-Level Evaluation of IEEE 802.1AS Synchronized Time and Linux for Distributed Real-Time Systems",
    "doi": "https://doi.org/10.1145/3701300",
    "publication_date": "2024-10-26",
    "publication_year": 2024,
    "authors": "Héctor Pérez; J. Javier Gutiérrez; Diego García Prieto",
    "corresponding_authors": "",
    "abstract": "The use of Ethernet and Linux is becoming common in industrial applications, even for those with real-time requirements, although neither of them were originally designed for this purpose. The emergence of Industry 4.0 (also known as Industrial Internet of Things, IIoT) has encouraged the evolution of these technologies to better handle real-time issues. On the one hand, Linux now supports mechanisms to configure certain real-time parameters, as well as core isolation and interrupt allocation facilities in multicore processors. On the other hand, the set of Ethernet standards IEEE 802.1 Time-Sensitive Networking (TSN) includes a high precision clock synchronization protocol (IEEE 802.1AS). The purpose of this work is to outline an execution framework for distributed systems based on TSN and Linux, which allows the execution of time-aware applications. We have studied and evaluated different configurations available for the proposed execution framework. In particular, a detailed characterization of the clock synchronization mechanism, from the application point of view, has been performed. Some conclusions about the current real-time capabilities of these technologies are also presented.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403790137",
    "type": "article"
  },
  {
    "title": "Hardware Area Efficiently and Real-Time FPGA Implementation of PHMMRGB",
    "doi": "https://doi.org/10.1145/3701727",
    "publication_date": "2024-10-28",
    "publication_year": 2024,
    "authors": "Suhap Şahın; Oğuz Narlı; Muhammet Bahadır Türkoğlu; Hikmetcan Özcan",
    "corresponding_authors": "",
    "abstract": "For encryption applications on embedded systems, operating in real-time while using minimal system resources is essential. It is expected that efficient and rapid encryption of high-resolution images is to be accomplished with limited hardware resources. Therefore, to ensure the desired efficiency of encryption of high-resolution images, the system must possess a digital architecture capable of achieving high speeds with minimal hardware resources. This study considered the limitations of a hardware architecture for an image encryption algorithm based on the Profile Hidden Markov Model called PHMMRGB. The proposed architecture is relatively simple in comparison to its alternatives. The hardware architecture, designed with the objective of using minimal resources, has been implemented on an FPGA. Based on the results of the proposed architecture, it is believed that the implementation of the specified method on an FPGA would yield high efficiency. Experiments conducted using large-sized satellite images confirmed this expectation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403842252",
    "type": "article"
  },
  {
    "title": "Towards a Rust-Like Borrow Checker for C",
    "doi": "https://doi.org/10.1145/3702229",
    "publication_date": "2024-10-29",
    "publication_year": 2024,
    "authors": "Tiago Silva; Pedro Gonçalo Correia; Luís Miguel Sousa; João Bispo; Tiago Carvalho",
    "corresponding_authors": "",
    "abstract": "Memory safety issues in C are the origin of various vulnerabilities that can compromise a program’s correctness or safety from attacks. We propose an approach to tackle memory safety by replicating Rust’s Mid-level Intermediate Representation (MIR) Borrow Checker. Our solution uses static analysis and successive source-to-source code transformations to be composed upstream of the compiler, ensuring maximal compatibility with existing build systems. This allows us to apply the memory safety guarantees of the rustc compiler to C code with fewer changes than a rewrite in Rust. In this work, we present a comprehensive study of Rust’s efforts towards ensuring memory safety, and describe the theoretical basis for a C borrow checker, alongside a proof-of-concept that was developed to demonstrate its potential. We have evaluated the prototype on the CHStone and bzip2 benchmarks. This prototype correctly identified violations of the ownership and aliasing rules, and exposed incompatibilities between such rules and common C patterns, which can be addressed in future work.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403875723",
    "type": "article"
  },
  {
    "title": "RTPL: A Real-Time Communication Protocol for LoRa Network",
    "doi": "https://doi.org/10.1145/3702209",
    "publication_date": "2024-11-04",
    "publication_year": 2024,
    "authors": "Sezana Fahmida; Aarti Jain; Venkata P. Modekurthy; Dali Ismail; Abusayeed Saifullah",
    "corresponding_authors": "",
    "abstract": "The industrial Internet of Things (IIoT) is prominently emerging in applications of large-scale and wide-area applications, such as oilfield management, smart grid management, real-time equipment monitoring, and integration of traffic management systems for smart cities. Relying on short-range wireless technologies (e.g., WirelessHART and ISA100.11a), traditional wireless solutions for industrial automation find it challenging to support the expansive scale of today’s IIoT. To address this limitation, we propose to adopt LoRaWAN, a prominent low-power wide-area network technology, for industrial automation. LoRaWAN for industrial automation poses some unique challenges. The fundamental building blocks of any industrial automation system are feedback control loops that largely rely on real-time communication. LoRaWAN traditionally adopts a simple protocol based on ALOHA with no collision avoidance or Listen Before Talk with Clear Channel Assessment and Random Backoff mechanisms to minimize energy consumption, which are less suitable for real-time communication. Existing real-time protocols for short-range technologies cannot be applied to a LoRaWAN network due to its unique characteristics such as asymmetry between downlink and the uplink spectrum, predefined modes (or classes) of operation, and concurrent reception through orthogonal spreading factors. In this paper, we address these challenges and propose RTPL- a Real-Time communication Protocol for LoRaWAN networks. RTPL is a low-overhead and conflict-free communication protocol allowing autonomous real-time communication of low-energy devices and exploits LoRa’s capability of parallel communication. We implement our approach on LoRa devices and evaluate through both physical experiments and extensive simulations. All results show that RTPL achieves on average 75% improvement in real-time performance without sacrificing throughput or energy compared to traditional LoRaWAN.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404047388",
    "type": "article"
  },
  {
    "title": "Time-Series Forecasting and Sequence Learning Using Memristor-based Reservoir System",
    "doi": "https://doi.org/10.1145/3703446",
    "publication_date": "2024-11-05",
    "publication_year": 2024,
    "authors": "Abdullah M. Zyarah; Dhireesha Kudithipudi",
    "corresponding_authors": "",
    "abstract": "Pushing the frontiers of time-series information processing in the ever-growing domain of edge devices with stringent resources has been impeded by the systems’ ability to process information and learn locally on the device. Local processing and learning of time-series information typically demand intensive computations and massive storage as the process involves retrieving information and tuning hundreds of parameters back in time. In this work, we developed a memristor-based echo state network accelerator that features efficient temporal data processing and in situ online learning. The proposed design is benchmarked using various datasets involving real-world tasks, such as forecasting the load energy consumption and weather conditions. The experimental results illustrate that the hardware model experiences a marginal degradation in performance as compared to the software counterpart. This is mainly attributed to the limited precision and dynamic range of network parameters when emulated using memristor devices. The proposed system is evaluated for lifespan, robustness, and energy-delay product. It is observed that the system demonstrates reasonable robustness for device failure below 10%, which may occur due to stuck-at faults. Furthermore, 247× reduction in energy consumption is achieved when compared to a custom CMOS digital design implemented at the same technology node.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404077861",
    "type": "article"
  },
  {
    "title": "PEak: A Single Source of Truth for Hardware Design and Verification",
    "doi": "https://doi.org/10.1145/3703456",
    "publication_date": "2024-11-12",
    "publication_year": 2024,
    "authors": "Caleb Donovick; Jackson Melchert; Ross Daly; Leonard Truong; Priyanka Raina; Pat Hanrahan; Clark Barrett",
    "corresponding_authors": "",
    "abstract": "Domain-specific languages for hardware can significantly enhance designer productivity, but sometimes at the cost of ease of verification. On the other hand, ISA specification languages are too static to be used during early stage design space exploration. We present PEak, an open-source hardware design and specification language, which aims to improve both design productivity and verification capability. PEak does this by providing a single source of truth for functional models, formal specifications, and RTL. PEak has been used in several academic projects, and PEak-generated RTL has been included in three fabricated hardware accelerators. In these projects, the formal capabilities of PEak were crucial for enabling both novel design space exploration techniques and automated compiler synthesis.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404252710",
    "type": "article"
  },
  {
    "title": "TreeHouse: An MLIR-based Compilation Flow for Real-Time Tree-based Inference",
    "doi": "https://doi.org/10.1145/3704727",
    "publication_date": "2024-11-15",
    "publication_year": 2024,
    "authors": "Chiahui Su; Chien-Chun Ku; Jenq‐Kuen Lee; Kuan-Hsun Chen",
    "corresponding_authors": "",
    "abstract": "Tree-based ensembles stand as the prominent resource-efficient approaches for real-time inference. To optimize their performance, researchers have developed several solutions to accommodate their unique program structure, i.e., consecutive branches and eliminate the floating-point arithmetic operations, which are usually costly at the embedded computing systems. Most of them are realized at the level of source code and a standard compilation is applied subsequently. Therefore, an end-to-end compilation flow may consolidate these methods and provide a holistic optimization. In this work, we introduce TreeHouse, a compilation flow based on MLIR designed for real-time inference of tree ensembles. First, we optimize the layout of basic blocks to reduce the expected branches during inference. Moreover, we provide a solution to facilitate LLVM register allocation for further efficiency. In addressing the suboptimal performance of floating-point operations in edge systems, we incorporate methods to convert data into integer format. We implemented and evaluated TreeHouse using two tree-based ensembles: boosting trees and random forests. Overall, boosting trees exhibited performance gains ranging from 1.38 × to 8.24 × on x86, 1.70 × to 6.61 × on ARMv8, and 1.75 × to 4.52 × on RISC-V compared to state-of-the-art decision tree research. Random forests achieved performance gains of up to 1.6 × on x86, 2.03 × on ARMv8, and 2.9 × on RISC-V.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404418000",
    "type": "article"
  },
  {
    "title": "Coarse Grained Task Parallelization by Dynamic Profiling for Heterogeneous SoC Based Embedded System",
    "doi": "https://doi.org/10.1145/3704635",
    "publication_date": "2024-11-15",
    "publication_year": 2024,
    "authors": "Liangliang Chang; Serhan Gener; Joshua Mack; H. Umut Suluhan; Ali Akoglu; Chaitali Chakrabarti",
    "corresponding_authors": "",
    "abstract": "In this study, we introduce a methodology for automatically transforming user applications written in C/C++ to a parallel representation consisting of coarse-grained tasks based on dynamic profiling. Such a parallel representation is suitable for mapping applications onto heterogeneous SoCs. We present our approach for instrumenting the user application binary during the compilation process with parallel primitives that enable the runtime system to schedule and execute independent computation-intensive coarse-grained tasks concurrently. We use the proposed compilation and code transformation methodology to retarget each application for execution on a heterogeneous SoC composed of processor cores and accelerators. We demonstrate the capabilities of our integrated compile time and runtime flow through task-level parallelization and functionally correct execution of real-world applications in the communication systems and radar processing domains. We demonstrate the functionality of our integrated system by executing six distinct applications with different degrees of parallelism on four different platforms: an eight-core general-purpose processor, a heterogeneous SoC simulator, and two heterogeneous SoCs utilizing the Xilinx Zynq UltraScale+ FPGA and the Nvidia Jetson AGX board. Our integrated approach offers a path forward for application developers to take full advantage of the target SoC without requiring users to become hardware or parallel programming experts.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404418062",
    "type": "article"
  },
  {
    "title": "SENNA: Unified Hardware/Software Space Exploration for Parametrizable Neural Network Accelerators",
    "doi": "https://doi.org/10.1145/3705731",
    "publication_date": "2024-11-26",
    "publication_year": 2024,
    "authors": "Jungyoon ­Kwon; Hyemi Min; Bernhard Egger",
    "corresponding_authors": "",
    "abstract": "Parametrizable neural network accelerators enable the deployment of targeted hardware for specialized environments. Finding the best architecture configuration for a given specification, however, is challenging. A large number of hardware configurations have to be considered, and for each hardware instance, an efficient software execution plan needs to be found, leading to a vast search space. Prior work has tackled this problem by dividing the search into subproblems for individual layers of a network. There is no guarantee, however, that the overall best hardware configuration that delivers the desired end-to-end performance across the entire network is among the best individual layer configurations. This work presents SENNA, a unified hardware/software space exploration framework for parametrizable neural network accelerators. To guide the exploration towards the overall best configuration, SENNA employs a multi-objective genetic algorithm with a novel design space representation that encodes the configuration of hardware and software parameters in a single chromosome. Using the Parallel Island Model (PIM), each layer is represented by one or more individual islands each containing a separate population to simultaneously search for the best configuration across the entire network. A tailored gene migration technique enables the exchange of genes between the populations of different islands. SENNA is evaluated with three parametrizable architectures and four neural networks. The evaluation result demonstrates that SENNA achieves upto 1.92x EDP improvement compared to the State-of-the-Art. With equivalent evaluation budgets, SENNA shows 2.5x-9.3x speedup compared to an Oracle scheme and the State-of-the-Art.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404721951",
    "type": "article"
  },
  {
    "title": "StreamNet++: Memory-Efficient Streaming TinyML Model Compilation on Microcontrollers",
    "doi": "https://doi.org/10.1145/3706107",
    "publication_date": "2024-11-29",
    "publication_year": 2024,
    "authors": "Hsu Cynthia; Hong-Sheng Zheng; Yu-Yuan Liu; Tsung Tai Yeh",
    "corresponding_authors": "",
    "abstract": "The rapid growth of on-device artificial intelligence increases the importance of TinyML inference applications. However, the stringent tiny memory space on the microcontroller unit (MCU) raises the grand challenge when deploying deep neural network (DNN) models on such a resource-constrained embedded system device. Traditionally, the machine learning system platform executes operators in a layer-wise manner. The layer-wise inference continues to the next operator before completing an operator. Thus, the DNN model compiler needs to allocate the SRAM memory space to store an operator’s entire input and output tensor when using the layer-wise inference on an MCU. However, the layer-wise inference will run out of memory quickly when an operator’s input and output tensor size in a DNN model is large. Consequently, the patch-based inference work divides a tensor into multiple small patches and only stores a small one to reduce the peak SRAM memory usage on an MCU. However, the computation of the overlapping patches tremendously increases the computational overhead of the patch-based inference and makes the patch-based inference undesirable on an MCU. Thus, this work presents StreamNet, a TinyML model compilation framework. StreamNet employs the stream buffer to eliminate redundant computation of patch-based inference while using small SRAM memory space on an MCU. StreamNet typically uses one type of patch configuration in a DNN model and does not completely eliminate the memory bottleneck of TinyML models. Unlike StreamNet, this article designs StreamNet++ patch-based variant inference that uses several types of patch configurations to completely remove the additional memory bottleneck even using StreamNet. Furthermore, StreamNet++ designs a parameter selection algorithm that quickly yields the best patch parameter candidates to meet the memory constraint of different MCUs. As a result, in 10 TinyML models, StreamNet++2D stream processing achieves a geometric mean of 5.7X speedup and removes 78% of redundant MACs over the latest patch-based inference.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404862392",
    "type": "article"
  },
  {
    "title": "HSPA: High-Throughput Sparse Polynomial Multiplication for Code-based Post-Quantum Cryptography",
    "doi": "https://doi.org/10.1145/3703837",
    "publication_date": "2024-12-10",
    "publication_year": 2024,
    "authors": "Pengzhou He; Yazheng Tu; Tianyou Bao; Çetin Kaya Koç; Jiafeng Xie",
    "corresponding_authors": "",
    "abstract": "Increasing attention has been paid to code-based post-quantum cryptography (PQC) schemes, e.g., HQC (Hamming Quasi-Cyclic) and BIKE (Bit Flipping Key Encapsulation), since they’ve been selected as the fourth-round National Institute of Standards and Technology (NIST) PQC standardization candidates. Though sparse polynomial multiplication is one of the critical components for HQC and BIKE, hardware-implemented high-performance sparse polynomial multiplier is rarely reported in the literature (due to its high-dimension and sparsity of polynomials involved in the computation). Based on this consideration, in this article, we propose two novel H igh-throughput S parse P olynomial multiplication A ccelerators (HSPA) for the mentioned two code-based PQC schemes. Specifically, we have designed the two accelerators based on two different implementation strategies targeting potential applications with different resource availability, i.e., one accelerator deploys a memory-based structure for computation while the other does not need memory usage. We have proposed three layers of coherent interdependent efforts to obtain the proposed accelerators. First, we have proposed two implementation strategies to execute the targeted sparse polynomial multiplication, i.e., a new parallel segment based accumulation (PSA) approach and a novel permutating-with-power (PWP)-based method. Then, the proposed two hardware accelerators are presented with detailed structural descriptions. Finally, field-programmable gate array (FPGA)-based implementation is presented to showcase the superior performance of the proposed accelerators. A proper comparison is also carried out to confirm the efficiency of the proposed designs. For instance, the proposed accelerator (using memory-based structure) has 56.84% and 80.25% less area-delay product (ADP) than the existing memory-based design (an extended high-speed version) on the UltraScale+ device, respectively, for n =17,669 and ω =75 (HQC) and n = 12,323 and ω =142 (BIKE). The proposed design strategy fits well with the two targeted code-based PQC schemes, which can be extended further to construct high-performance hardware cryptoprocessors. We hope the results of this work will be useful for the ongoing NIST PQC standardization process.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405245144",
    "type": "article"
  },
  {
    "title": "A Highly Hardware Efficient ML-KEM Accelerator with Optimised Architectural Layers",
    "doi": "https://doi.org/10.1145/3708469",
    "publication_date": "2024-12-18",
    "publication_year": 2024,
    "authors": "Ziying Ni; Ayesha Khalid; Weiqiang Liu; Máire O’Neill",
    "corresponding_authors": "",
    "abstract": "The Module-Lattice-Based Key encapsulation Mechanism (ML-KEM) scheme, which is currently being standardised, is a quantum attack resistant KEM that is based on CRYSTALS-Kyber. CRYSTALS-Kyber is the only Public-key Encryption (PKE)/ KEM scheme selected in the first set of successful candidates as part of the NIST initiated Post-Quantum Cryptography (PQC) process. ML-KEM scheme includes three different security levels, namely security level 1, 3, and 5. In this research, we propose a highly area-time efficient hardware ML-KEM architecture. The architecture comprises three computational layers. The first layer comprises a hash and sampling module; the second layer includes a number theoretic transform (NTT), its inverse (INTT) and a point-wise multiplication (PWM) module; and the third layer comprises addition, compressing and encoding. Intra-layer pipelining and out-of-layer scheduling ensures that either layer 1 or layer 2 operate in the shortest time. In the reduction module, we propose a novel hybrid architecture to obtain the final result within 2 cycles with low area consumption. In the NTT module, the PWM pipelining method is modified and an optimised iterative FIFO access method is adopted to reduce the size of FIFO units by 55% over previous research. Look-up tables are also used to replace the first-stage of the NTT to reduce 8 cycles. Furthermore, the memory unit uses only FIFOs, the size are optimised based on the requirements of the most resource-intensive function in ML-KEM (ML-KEM.CPA.Dec). The results show that the proposed architecture has a 48.2%, 41.2%, and 78.1% reduction in computational time in comparison to previous work for security levels 1, 3, and 5, respectively. In addition, the area of proposed optimised ML-KEM designs is reduced by 73%, 70%, 76% and resulting in an improved area-time (AT) product of 15.8%, 10.7%, and 11.3%, for the Level 1, 3, and 5 security levels respectively, compared with state-of-the-art designs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405547338",
    "type": "article"
  },
  {
    "title": "Model-based Toolchain for Core Flight System (cFS) Embedded Systems",
    "doi": "https://doi.org/10.1145/3706587",
    "publication_date": "2024-12-19",
    "publication_year": 2024,
    "authors": "Hugo Valente; Miguel de Miguel; Ángel-Grover Pérez-Muñoz; Alejandro Alonso; Juan Zamorano; Juan A. de la Puente",
    "corresponding_authors": "",
    "abstract": "The space domain is experiencing a paradigm shift with the rise of micro and nanosatellites. Historically, launching a satellite required a big financial risk only sustained by governments or big companies. Nowadays, with the miniaturization of satellites, there has been a significant reduction in costs and, as a consequence, a greater opportunity for universities and smaller businesses to launch satellites into space. Companies are taking advantage of this reduction in launch and manufacturing costs to gain a competitive edge by adopting what is known as “Agile Space”, which emphasizes rapid iterations. To facilitate this high development pace, specialized toolchains and frameworks are designed for satellite software development. In this article, we provide a solution to reduce the development time of embedded software systems by ensuring consistency between the design and the implementation. We have integrated the core Flight System (cFS), a message-oriented framework developed by NASA based on a publish-subscribe architecture, with TASTE, a toolset from the European Space Agency. This integration combines modeling capabilities and automatic code generation, reducing error-prone repetitive tasks. It ensures consistency across different development stages allowing the end-user to focus on the implementation-specific details. To demonstrate the feasibility and advantages of this model-based toolchain, we present a case study of the UPMSat-2 microsatellite. This study demonstrates how this approach can be used to successfully support the development of embedded software systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405578635",
    "type": "article"
  },
  {
    "title": "Mixed-Level Modeling and Evaluation of a Cache-less Grid of Processing Cells",
    "doi": "https://doi.org/10.1145/3708988",
    "publication_date": "2024-12-19",
    "publication_year": 2024,
    "authors": "Vivek Govindasamy; Rainer Doemer",
    "corresponding_authors": "",
    "abstract": "Modern processors experience memory contention when the speed of their computational units exceeds the rate at which new data is available to be processed. This phenomenon is well known as the memory wall and is a great challenge in computer engineering. The reason for this phenomenon is the unequal growth rate in memory access speeds compared to processor clock rates. In order to mitigate the memory bottleneck in classic computer architectures, a scalable parallel computing platform called the Grid of Processing Cells (GPC) has been proposed. To evaluate its effectiveness, the GPC is modeled at the instruction-level and functional-level using SystemC TLM-2.0, with a focus on memory contention. Individual GPC cells can be switched between the two abstraction levels. Our mixed-level system model enables fast and accurate simulations. We test multiple streaming applications on the GPC, analyze software-based optimization methods and their effects on the GPC, at both abstraction levels. The performance is then compared against the traditional shared memory processor (SMP) architecture. Experimental results show improved execution times on the GPC primarily due to a large decrease in main memory contention.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405578731",
    "type": "article"
  },
  {
    "title": "System-level exploration of association table implementations in telecom network applications",
    "doi": "https://doi.org/10.1145/581888.581895",
    "publication_date": "2002-11-01",
    "publication_year": 2002,
    "authors": "C. Ykman-Couvreur; Joris Lambrecht; A. van der Togt; Francky Catthoor; H. De Man",
    "corresponding_authors": "",
    "abstract": "We present a new exploration and optimization method at the system level to select customized implementations for dynamic data sets, as encountered in telecom network, database, and multimedia applications. Our method fits in the context of embedded system synthesis for such applications, and enables to further raise the abstraction level of the initial specification, where dynamic data sets can be specified without low-level details. Our method is suited for hardware and software implementations. In this paper, it mainly aims at minimizing the average memory power, although it can also be driven by other cost functions such as memory size and performance. Compared with existing methods, for large dynamic data sets, it can save up to 90% of the average memory power, while still saving up to 80% of the average memory size.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2080561064",
    "type": "article"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/1151074.1151075",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "Ahmed Jerraya; Trevor Mudge",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest editorial: Concurrent hardware and software design for multiprocessor SoC Guest Editors: Ahmed Jerraya View Profile , Trevor Mudge View Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 5Issue 2May 2006 pp 259–262https://doi.org/10.1145/1151074.1151075Published:01 May 2006Publication History 1citation685DownloadsMetricsTotal Citations1Total Downloads685Last 12 Months21Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1994124401",
    "type": "editorial"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/1067915.1067916",
    "publication_date": "2005-05-01",
    "publication_year": 2005,
    "authors": "Sandeep K. Shukla; Jean-Pierre Talpin",
    "corresponding_authors": "",
    "abstract": "This special issue is based on innovative ideas presented and discussed during the first ACM/IEEE Conference on Formal Methods and Models for Co-Design (MEMOCODE) held at Mont Saint Michel in France during the summer of 2003. Selected papers from the conference were invited for this special issue together with an open call for papers soliciting novel contributions on the topics of this conference. Rigorous reviews of 12 submissions led to the selection of four papers for this special issue. In this editorial statement, we outline the premise and the context of this special issue, and give a short introduction to the theme under consideration and briefly introduce the papers selected. We also thank the authors who submitted their contributions to this special issue, and all the reviewers without whose dedication and hard work toward ensuring the quality of the selections, editing this special issue would have been impossible.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2010760101",
    "type": "editorial"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/1015047.1015048",
    "publication_date": "2004-08-01",
    "publication_year": 2004,
    "authors": "Dimitrios Serpanos; Haris Lekatsas",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2094804848",
    "type": "editorial"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/972627.972628",
    "publication_date": "2004-02-01",
    "publication_year": 2004,
    "authors": "Rajesh Gupta",
    "corresponding_authors": "Rajesh Gupta",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2129816332",
    "type": "editorial"
  },
  {
    "title": "Design and Implementation of an Escape Analysis in the Context of Safety-Critical Embedded Systems",
    "doi": "https://doi.org/10.1145/3372133",
    "publication_date": "2020-01-31",
    "publication_year": 2020,
    "authors": "Clemens Lang; Isabella Stilkerich",
    "corresponding_authors": "",
    "abstract": "The use of a managed, type-safe language such as Standard ML, Ada Ravenscar, or Java in hard real-time and embedded systems offers productivity, safety, and dependability benefits at a reasonable cost. Static software systems, that is systems in which all relevant resource entities such as threads and their priorities, for instance, and the entire source code are known ahead of time, are particularly interesting for the deployment in safety-critical embedded systems: Code verification is rather maintainable in contrast to dynamic systems. Additionally, static analyses can incorporate information from all software and system layers to assist compilers in emitting code that is well suited to an application on a particular hardware device. It was shown in the past that a program composed in type-safe Java in combination with a static system setup can be as efficient as one that is written in C [30], which is still the most widely used language in the embedded domain. Escape analysis (EA) is one of several static-analysis techniques. It supports, for instance, runtime efficiency by enabling automated stack allocation of objects. In addition, Stilkerich et al. [27, 28] have argued that EA enables further applications in safety-critical embedded systems such as the computation of memory classes stated in the Real-Time Specification for Java (RTSJ) [6]. EA can be applied to any programming language but the quality of its results greatly benefits from the properties of a type-safe language. Notably, embedded multicore devices can positively be affected by the use of EA. Thus, we explore an ahead-of-time (AOT) escape analysis in the context of the KESO JVM featuring a Java AOT compiler targeting (deeply) embedded (hard) real-time systems.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3004893380",
    "type": "article"
  },
  {
    "title": "CORIDOR: Using <u>CO</u> herence and Tempo <u>R</u> al Local <u>I</u> ty to Mitigate Read <u>D</u> isurbance Err <u>OR</u> in STT-RAM Caches",
    "doi": "https://doi.org/10.1145/3484493",
    "publication_date": "2022-01-14",
    "publication_year": 2022,
    "authors": "Sheel Sindhu Manohar; Sparsh Mittal; Hemangee K. Kapoor",
    "corresponding_authors": "",
    "abstract": "In the deep sub-micron region, “spin-transfer torque RAM” (STT-RAM ) suffers from “read-disturbance error” (RDE) , whereby a read operation disturbs the stored data. Mitigation of RDE requires restore operations, which imposes latency and energy penalties. Hence, RDE presents a crucial threat to the scaling of STT-RAM. In this paper, we offer three techniques to reduce the restore overhead. First, we avoid the restore operations for those reads, where the block will get updated at a higher level cache in the near future. Second, we identify read-intensive blocks using a lightweight mechanism and then migrate these blocks to a small SRAM buffer. On a future read to these blocks, the restore operation is avoided. Third, for data blocks having zero value, a write operation is avoided, and only a flag is set. Based on this flag, both read and restore operations to this block are avoided. We combine these three techniques to design our final policy, named CORIDOR. Compared to a baseline policy, which performs restore operation after each read, CORIDOR achieves a 31.6% reduction in total energy and brings the relative CPI (cycle-per-instruction) to 0.64×. By contrast, an ideal RDE-free STT-RAM saves 42.7% energy and brings the relative CPI to 0.62×. Thus, our CORIDOR policy achieves nearly the same performance as an ideal RDE-free STT-RAM cache. Also, it reaches three-fourths of the energy-saving achieved by the ideal RDE-free cache. We also compare CORIDOR with four previous techniques and show that CORIDOR provides higher restore energy savings than these techniques.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4206457987",
    "type": "article"
  },
  {
    "title": "Telomere: Real-Time NAND Flash Storage",
    "doi": "https://doi.org/10.1145/3479157",
    "publication_date": "2022-01-14",
    "publication_year": 2022,
    "authors": "Katherine Missimer; Manos Athanassoulis; Richard West",
    "corresponding_authors": "",
    "abstract": "Modern solid-state disks achieve high data transfer rates due to their massive internal parallelism. However, out-of-place updates for flash memory incur garbage collection costs when valid data needs to be copied during space reclamation. The root cause of this extra cost is that solid-state disks are not always able to accurately determine data lifetime and group together data that expires before the space needs to be reclaimed. Real-time systems found in autonomous vehicles, industrial control systems, and assembly-line robots store data from hundreds of sensors and often have predictable data lifetimes. These systems require guaranteed high storage bandwidth for read and write operations by mission-critical real-time tasks. In this article, we depart from the traditional block device interface to guarantee the high throughput needed to process large volumes of data. Using data lifetime information from the application layer, our proposed real-time design, called Telomere , is able to intelligently lay out data in NAND flash memory and eliminate valid page copies during garbage collection. Telomere’s real-time admission control is able to guarantee tasks their required read and write operations within their periods. Under randomly generated tasksets containing 500 tasks, Telomere achieves 30% higher throughput with a 5% storage cost compared to pre-existing techniques.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4206789823",
    "type": "article"
  },
  {
    "title": "Physics-Driven Page Fault Handling for Customized Deception against CPS Malware",
    "doi": "https://doi.org/10.1145/3502742",
    "publication_date": "2022-01-26",
    "publication_year": 2022,
    "authors": "Julian Rrushi",
    "corresponding_authors": "Julian Rrushi",
    "abstract": "Malware crafted to attack cyber-physical systems such as the electrical power grid have a physics-centric nucleus. Cyber-physical systems malware understand physics and hence use their knowledge to guide how they initiate physical damage on a compromised industrial computer. We develop a physics-driven page fault handler in the seL4 microkernel, which, in addition to reducing the page fault rate, differentiates active physics in main memory from passive physics in the backing store. We aid the identification of active physics via a CPU scheduler that tracks the evolution of active physics over time. We exploit the concept of active physics to develop deception that is customized to attack the physics-centric nucleus of malware. We evaluated this research against a variety of malware samples and techniques, including both numerous samples from publicly available repositories and custom-made academic code, and present our findings in the article. The physics data of reference pertain to an electrical substation, with a higher focus on a power transformer and related industrial computer algorithms.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4210658600",
    "type": "article"
  },
  {
    "title": "Mobile or FPGA? A Comprehensive Evaluation on Energy Efficiency and a Unified Optimization Framework",
    "doi": "https://doi.org/10.1145/3528578",
    "publication_date": "2022-04-20",
    "publication_year": 2022,
    "authors": "Geng Yuan; Peiyan Dong; Mengshu Sun; Wei Niu; Zhengang Li; Yuxuan Cai; Yanyu Li; Jun Liu; Weiwen Jiang; Xue Lin; Bin Ren; Xulong Tang; Yanzhi Wang",
    "corresponding_authors": "",
    "abstract": "Efficient deployment of Deep Neural Networks (DNNs) on edge devices (i.e., FPGAs and mobile platforms) is very challenging, especially under a recent witness of the increasing DNN model size and complexity. Model compression strategies, including weight quantization and pruning, are widely recognized as effective approaches to significantly reduce computation and memory intensities, and have been implemented in many DNNs on edge devices. However, most state-of-the-art works focus on ad hoc optimizations, and there lacks a thorough study to comprehensively reveal the potentials and constraints of different edge devices when considering different compression strategies. In this article, we qualitatively and quantitatively compare the energy efficiency of FPGA-based and mobile-based DNN executions using mobile GPU and provide a detailed analysis. Based on the observations obtained from the analysis, we propose a unified optimization framework using block-based pruning to reduce the weight storage and accelerate the inference speed on mobile devices and FPGAs, achieving high hardware performance and energy-efficiency gain while maintaining accuracy.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4224228726",
    "type": "article"
  },
  {
    "title": "Brain-inspired Cognition in Next-generation Racetrack Memories",
    "doi": "https://doi.org/10.1145/3524071",
    "publication_date": "2022-03-21",
    "publication_year": 2022,
    "authors": "Asif Ali Khan; Sébastien Ollivier; Stephen Longofono; Gerald Hempel; Jeronimo Castrillon; Alex K. Jones",
    "corresponding_authors": "",
    "abstract": "Hyperdimensional computing (HDC) is an emerging computational framework inspired by the brain that operates on vectors with thousands of dimensions to emulate cognition. Unlike conventional computational frameworks that operate on numbers, HDC, like the brain, uses high dimensional random vectors and is capable of one-shot learning. HDC is based on a well-defined set of arithmetic operations and is highly error-resilient. The core operations of HDC manipulate HD vectors in bulk bit-wise fashion, offering many opportunities to leverage parallelism. Unfortunately, on conventional Von-Neuman architectures, the continuous movement of HD vectors among the processor and the memory can make the cognition task prohibitively slow and energy-intensive. Hardware accelerators only marginally improve related metrics. On the contrary, only partial implementation of an HDC framework inside memory, using emerging memristive devices, has reported considerable performance/energy gains. This paper presents an architecture based on racetrack memory (RTM) to conduct and accelerate the entire HDC framework within the memory. The proposed solution requires minimal additional CMOS circuitry and uses a read operation across multiple domains in RTMs called transverse read (TR) to realize exclusive-or (XOR) and addition operations. To minimize the overhead the CMOS circuitry, we propose an RTM nanowires-based counting mechanism that leverages the TR operation and the standard RTM operations. Using language recognition as the use case demonstrates 7.8x and 5.3x reduction in the overall runtime and energy consumption compared to the FPGA design, respectively. Compared to the state-of-the-art in-memory implementation, the proposed HDC system reduces the energy consumption by 8.6x.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4226507562",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1113830",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4249185148",
    "type": "paratext"
  },
  {
    "title": "Toward Efficient and Adaptive Design of Video Detection System with Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3484946",
    "publication_date": "2022-05-31",
    "publication_year": 2022,
    "authors": "Jiachen Mao; Qing Yang; Ang Li; Kent W. Nixon; Hai Li; Yiran Chen",
    "corresponding_authors": "",
    "abstract": "In the past decade, Deep Neural Networks (DNNs), e.g., Convolutional Neural Networks, achieved human-level performance in vision tasks such as object classification and detection. However, DNNs are known to be computationally expensive and thus hard to be deployed in real-time and edge applications. Many previous works have focused on DNN model compression to obtain smaller parameter sizes and consequently, less computational cost. Such methods, however, often introduce noticeable accuracy degradation. In this work, we optimize a state-of-the-art DNN-based video detection framework—Deep Feature Flow (DFF) from the cloud end using three proposed ideas. First, we propose Asynchronous DFF (ADFF) to asynchronously execute the neural networks. Second, we propose a Video-based Dynamic Scheduling (VDS) method that decides the detection frequency based on the magnitude of movement between video frames. Last, we propose Spatial Sparsity Inference, which only performs the inference on part of the video frame and thus reduces the computation cost. According to our experimental results, ADFF can reduce the bottleneck latency from 89 to 19 ms. VDS increases the detection accuracy by 0.6% mAP without increasing computation cost. And SSI further saves 0.2 ms with a 0.6% mAP degradation of detection accuracy.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4285813722",
    "type": "article"
  },
  {
    "title": "Rethinking the Interactivity of OS and Device Layers in Memory Management",
    "doi": "https://doi.org/10.1145/3530876",
    "publication_date": "2022-07-31",
    "publication_year": 2022,
    "authors": "Tse-Yuan Wang; Chun-Feng Wu; Che-Wei Tsao; Yuan-Hao Chang; Tei‐Wei Kuo; Xue Liu",
    "corresponding_authors": "",
    "abstract": "In the big data era, a huge number of services has placed a fast-growing demand on the capacity of DRAM-based main memory. However, due to the high hardware cost and serious leakage power/energy consumption, the growth rate of DRAM capacity cannot meet the increased rate of the required main memory space when the energy or hardware cost is a critical concern. To tackle this issue, hybrid main-memory devices/modules have been proposed to replace the pure DRAM main memory with a hybrid main memory module that provides a large main memory space by integrating a small-sized DRAM and a large-sized non-volatile memory (NVM) into the same memory module. Although NVMs have high-density and low-cost features, they suffer from the low read/write performance and low endurance issue, compared to DRAM. Thus, inside the hybrid main-memory module, it also includes a memory management design to use DRAM as the cache of NVMs to enhance its performance and lifetime. However, it also introduces new design challenges in both the OS and the memory module. In this work, we rethink the interactivity of OS and hybrid main-memory module, and propose a cross-layer cache design that (1) utilizes the information from the operating system to optimize the hit ratio of the DRAM cache inside the memory module, and (2) takes advantage of the bulk-size (or block-based) read/write feature of NVM to minimize the time overhead on the data movement between DRAM and NVM. At the same time, this cross-layer cache design is very lightweight and only introduces limited runtime management overheads. A series of experiments was conducted to evaluate the effectiveness of the proposed cross-layer cache design. The results show that the proposed design could improve access performance for up to 88%, compared to the investigated well-known page replacement algorithms.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4292722031",
    "type": "article"
  },
  {
    "title": "CAP’NN: A Class-aware Framework for Personalized Neural Network Inference",
    "doi": "https://doi.org/10.1145/3520126",
    "publication_date": "2022-03-21",
    "publication_year": 2022,
    "authors": "Maedeh Hemmat; Joshua San Miguel; Azadeh Davoodi",
    "corresponding_authors": "",
    "abstract": "We propose a framework for Class-aware Personalized Neural Network Inference (CAP’NN), which prunes an already-trained neural network model based on the preferences of individual users. Specifically, by adapting to the subset of output classes that each user is expected to encounter, CAP’NN is able to prune not only ineffectual neurons but also miseffectual neurons that confuse classification, without the need to retrain the network. CAP’NN also exploits the similarities among pruning requests from different users to minimize the timing overheads of pruning the network. To achieve this, we propose a clustering algorithm that groups similar classes in the network based on the firing rates of neurons for each class and then implement a lightweight cache architecture to store and reuse information from previously pruned networks. In our experiments with VGG-16, AlexNet, and ResNet-152 networks, CAP’NN achieves, on average, up to 47% model size reduction while actually improving the top-1(5) classification accuracy by up to 3.9%(3.4%) when the user only encounters a subset of the trained classes in these networks.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4293102051",
    "type": "article"
  },
  {
    "title": "QUIDAM: A Framework for <u>Qu</u> ant <u>i</u> zation-aware <u>D</u> NN <u>A</u> ccelerator and <u>M</u> odel Co-Exploration",
    "doi": "https://doi.org/10.1145/3555807",
    "publication_date": "2022-09-01",
    "publication_year": 2022,
    "authors": "Ahmet Inci; Siri Garudanagiri Virupaksha; Aman Jain; Ting-Wu Chin; Venkata Vivek Thallam; Ruizhou Ding; Diana Marculescu",
    "corresponding_authors": "",
    "abstract": "As the machine learning and systems communities strive to achieve higher energy efficiency through custom deep neural network (DNN) accelerators, varied precision or quantization levels, and model compression techniques, there is a need for design space exploration frameworks that incorporate quantization-aware processing elements into the accelerator design space while having accurate and fast power, performance, and area models. In this work, we present QUIDAM , a highly parameterized quantization-aware DNN accelerator and model co-exploration framework. Our framework can facilitate future research on design space exploration of DNN accelerators for various design choices such as bit precision, processing element type, scratchpad sizes of processing elements, global buffer size, number of total processing elements, and DNN configurations. Our results show that different bit precisions and processing element types lead to significant differences in terms of performance per area and energy. Specifically, our framework identifies a wide range of design points where performance per area and energy varies more than 5× and 35×, respectively. With the proposed framework, we show that lightweight processing elements achieve on par accuracy results and up to 5.7× more performance per area and energy improvement when compared to the best 16-bit integer quantization–based implementation. Finally, due to the efficiency of the pre-characterized power, performance, and area models, QUIDAM can speed up the design exploration process by three to four orders of magnitude as it removes the need for expensive synthesis and characterization of each design.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4294031337",
    "type": "article"
  },
  {
    "title": "An <i>Intermediate-Centric</i> Dataflow for Transposed Convolution Acceleration on FPGA",
    "doi": "https://doi.org/10.1145/3561053",
    "publication_date": "2022-09-01",
    "publication_year": 2022,
    "authors": "Zhengzheng Ma; Tuo Dai; Xuechao Wei; Guojie Luo",
    "corresponding_authors": "",
    "abstract": "Transposed convolution has been prevailing in convolutional neural networks (CNNs), playing an important role in multiple scenarios such as image segmentation and back-propagation process of training CNNs. This mainly benefits from the ability to up-sample the input feature maps by interpolating new information from the input feature pixels. However, the backward-stencil computation constrains its performance and hindered its wide application in diverse platforms. Moreover, in contrast to the efforts on accelerating the convolution, there is a rare investigation on the acceleration of transposed convolution that is identically compute-intensive as the former. For acceleration of transposed convolution, we propose an intermediate-centric dataflow scheme, in which we decouple the generation of the intermediate patch from its further process, aim at efficiently performing the backward-stencil computation . The intermediate-centric dataflow breaks the transposed convolution into several phases/stages, achieving feeding the input feature maps and performing the backward-stencil computation in a pipelining manner. It also provides four-degree computation parallelism and efficient data reuse of input feature maps/weights. Furthermore, we also theoretically analyze the irregular data dependence leveraging the polyhedral model, which constrains the parallel computing of transposed convolution. Additionally, we devise an optimization problem to explore the design space and automatically generate the optimal design configurations for different transposed convolutional layers and hardware platforms. By selecting the representative transposed convolutional layers from DCGAN, FSRCNN, and FCN, we generate the corresponding accelerator arrays of intermediate-centric dataflow on the Xilinx Alveo U200 platform and reach the performance of 3.92 TOPS, 2.72 TOPS, and 4.76 TOPS, respectively.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4294032011",
    "type": "article"
  },
  {
    "title": "LanCeX: A Versatile and Lightweight Defense Method against Condensed Adversarial Attacks in Image and Audio Recognition",
    "doi": "https://doi.org/10.1145/3555375",
    "publication_date": "2022-08-09",
    "publication_year": 2022,
    "authors": "Zirui Xu; Fuxun Yu; Chenchen Liu; Xiang Chen",
    "corresponding_authors": "",
    "abstract": "Convolutional Neural Networks (CNNs) are widely deployed in various embedded recognition applications. However, they demonstrate a considerable vulnerability to adversarial attacks, which leverage the well-designed perturbations to mislead the recognition results. Recently, for easier perturbation injection and higher attack effectiveness, the adversarial perturbations have been concentrated into a small area with various types and different data modalities. When defending such condensed adversarial attacks on the embedded recognition scenarios, most of the existing defense works highlight two critical issues. First, they are particularly designed for each individual condensed attack scenario, lacking enough versatility to accommodate attacks with different data modalities. Second, they rely on computation-intensive preprocessing techniques, which is impractical for time-sensitive embedded recognition scenarios. In this article, we propose LanCeX –a versatile and lightweight CNN defense solution against condensed adversarial attacks. By examining the CNN’s intrinsic vulnerability, we first identify the common attacking mechanism behind condensed adversarial attacks across different data modalities. Based on this mechanism, LanCeX can defend against various condensed attacks with the optimal computation workload in different recognition scenarios. Experiments show that LanCeX can achieve an average 91%, 85%, and 90% detection success rate and optimal adversarial mitigation performance in three recognition scenarios, respectively: image classification, object detection, and audio recognition. Moreover, LanCeX is at most 3× faster compared with the state-of-the-art defense methods, making it feasible to use with resource-constrained embedded systems.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4297816476",
    "type": "article"
  },
  {
    "title": "TCX: A RISC Style Tensor Computing Extension and a Programmable Tensor Processor",
    "doi": "https://doi.org/10.1145/3568310",
    "publication_date": "2022-10-19",
    "publication_year": 2022,
    "authors": "Tailin Liang; Lei Wang; Shi Shao-bo; John Glossner; Xiaotong Zhang",
    "corresponding_authors": "",
    "abstract": "Neural network processors and accelerators are domain-specific architectures deployed to solve the high computational requirements of deep learning algorithms. This article proposes a new instruction set extension for tensor computing, TCX, using Reduced Instruction Set Computer (RISC) instructions enhanced with variable length tensor extensions. It features a multi-dimensional register file, dimension registers, and fully generic tensor instructions. It can be seamlessly integrated into existing RISC Instruction Set Architectures and provides software compatibility for scalable hardware implementations. We present a tensor accelerator implementation of the tensor extensions using an out-of-order RISC microarchitecture. The tensor accelerator is scalable in computation units from several hundred to tens of thousands. An optimized register renaming mechanism is described that allows for many physical tensor registers without requiring architectural support for large tensor register names. We describe new tensor load and store instructions that reduce bandwidth requirements using tensor dimension registers. Implementations may balance data bandwidth and computation utilization for different types of tensor computations such as element-wise, depthwise, and matrix-multiplication. We characterize the computation precision of tensor operations to balance area, generality, and accuracy loss for several well-known neural networks. The TCX processor runs at 1 GHz and sustains 8.2 Tera operations per second using a 4,096 multiply-accumulate compute unit. It consumes 12.8 mm 2 while dissipating 0.46W/TOPs in TSMC 28-nm technology.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4306755820",
    "type": "article"
  },
  {
    "title": "HDLRuby: A Ruby Extension for Hardware Description and its Translation to Synthesizable Verilog HDL",
    "doi": "https://doi.org/10.1145/3581757",
    "publication_date": "2024-08-14",
    "publication_year": 2024,
    "authors": "Lovic Gauthier; Yohei Ishikawa",
    "corresponding_authors": "",
    "abstract": "HDLRuby is a new hardware description language defined as an extension of the Ruby programming language aiming to improve circuit design productivity. HDLRuby allows to model digital circuits at the register transfer level while supporting high-level paradigms comprising object-oriented programming, genericity, metaprogramming, and reflection. By construction, HDLRuby can also execute any code in Ruby and supports all of its libraries. Yet, even if high-level features are beneficial for design productivity, such advantages can be negated if the design tools are not efficient enough for producing in reasonable time quality hardware. This article investigates this issue by presenting the techniques used for compiling HDLRuby descriptions and by evaluating their performance. In detail, it explains how the language has been implemented and how it is translated to synthesizable Verilog HDL. Experiments are then presented for confirming the productivity gain of using HDLRuby and for evaluating the performance of the translation, the size of the resulting code, and the time required by a commercially available synthesis tool to produce an FPGA configuration from it. The HDLRuby descriptions used for the experiments include a set of repetitive designs for single construct evaluations and the implementation of generic convolution neural networks for real-life applications. For these evaluations, the translation time proves to be more than 10 times shorter than the synthesis time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4318826892",
    "type": "article"
  },
  {
    "title": "PolyARBerNN: A Neural Network Guided Solver and Optimizer for Bounded Polynomial Inequalities",
    "doi": "https://doi.org/10.1145/3632970",
    "publication_date": "2024-01-24",
    "publication_year": 2024,
    "authors": "Wael Fatnassi; Yasser Shoukry",
    "corresponding_authors": "",
    "abstract": "Constraints solvers play a significant role in the analysis, synthesis, and formal verification of complex cyber-physical systems. In this article, we study the problem of designing a scalable constraints solver for an important class of constraints named polynomial constraint inequalities (also known as nonlinear real arithmetic theory). In this article, we introduce a solver named PolyARBerNN that uses convex polynomials as abstractions for highly nonlinears polynomials. Such abstractions were previously shown to be powerful to prune the search space and restrict the usage of sound and complete solvers to small search spaces. Compared with the previous efforts on using convex abstractions, PolyARBerNN provides three main contributions namely (i) a neural network guided abstraction refinement procedure that helps selecting the right abstraction out of a set of pre-defined abstractions, (ii) a Bernstein polynomial-based search space pruning mechanism that can be used to compute tight estimates of the polynomial maximum and minimum values which can be used as an additional abstraction of the polynomials, and (iii) an optimizer that transforms polynomial objective functions into polynomial constraints (on the gradient of the objective function) whose solutions are guaranteed to be close to the global optima. These enhancements together allowed the PolyARBerNN solver to solve complex instances and scales more favorably compared to the state-of-the-art nonlinear real arithmetic solvers while maintaining the soundness and completeness of the resulting solver. In particular, our test benches show that PolyARBerNN achieved 100X speedup compared with Z3 8.9, Yices 2.6, and PVS (a solver that uses Bernstein expansion to solve multivariate polynomial constraints) on a variety of standard test benches. Finally, we implemented an optimizer called PolyAROpt that uses PolyARBerNN to solve constrained polynomial optimization problems. Numerical results show that PolyAROpt is able to solve high-dimensional and high order polynomial optimization problems with higher speed compared to the built-in optimizer in the Z3 8.9 solver.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4391169514",
    "type": "article"
  },
  {
    "title": "Coupling bit and modular arithmetic for efficient general-purpose fully homomorphic encryption",
    "doi": "https://doi.org/10.1145/3665280",
    "publication_date": "2024-05-16",
    "publication_year": 2024,
    "authors": "Eduardo Chielle; Oleg Mazonka; Homer Gamil; Michail Maniatakos",
    "corresponding_authors": "",
    "abstract": "Fully Homomorphic Encryption (FHE) enables computation directly on encrypted data. This property is desirable for outsourced computation of sensitive data as it relies solely on the underlying security of the cryptosystem and not in access control policies. Even though FHE is still significantly slower than unencrypted computation, practical times are possible for applications easily representable as low-order polynomials, since most FHE schemes support modular addition and multiplication over ciphertexts. If, however, an application cannot be expressed with low-order polynomials, then Boolean logic must be emulated. This bit-level arithmetic enables any computation to be performed homomorphically. Nevertheless, as it runs on top of the natively supported modular arithmetic, it has poor performance, which hinders its use in the majority of scenarios. In this work, we propose Bridging, a technique that allows conversion from bit-level to modular arithmetic and vice-versa. This enables the use of the comprehensive computation provided by bit-level arithmetic and the performance of modular arithmetic within the same application. Experimental results show that Bridging can lead to 1-2 orders of magnitude performance improvement for tested benchmarks and two real-world applications: URL denylisting and genotype imputation. Bridging performance comes from two factors: reduced number of operations and smaller multiplicative depth.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4396956522",
    "type": "article"
  },
  {
    "title": "A Comprehensive Study of Systems Challenges in Visual Simultaneous Localization and Mapping Systems",
    "doi": "https://doi.org/10.1145/3677317",
    "publication_date": "2024-08-03",
    "publication_year": 2024,
    "authors": "Sofiya Semenova; Steven Y. Ko; Yu David Liu; Lukasz Ziarek; Karthik Dantu",
    "corresponding_authors": "",
    "abstract": "Visual SLAM systems are concurrent, performance-critical systems that respond to real-time environmental conditions and are frequently deployed on resource-constrained hardware. Previous work has identified three interconnected systems challenges to building consistent, accurate, and robust SLAM systems— timeliness , concurrency , and context awareness . In this article, we analyze three popular, state-of-the-art frameworks with varying system designs and optimization techniques, and we quantify the extent to which they are affected by the aforementioned system challenges. We find that all SLAM systems must balance the interconnected nature of timeliness and accuracy, and different system designs and optimization techniques uniquely address this tension. Global-map-based SLAM systems typically achieve the best performance but suffer in resource-constrained scenarios with increased concurrency . Across all SLAM systems, incorporating context awareness into decision-making would mitigate the impact of timeliness and concurrency on accuracy in resource-constrained scenarios.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401288389",
    "type": "article"
  },
  {
    "title": "Efficient Multi-Byte Power Analysis Architecture Focusing on Bitwise Linear Leakage",
    "doi": "https://doi.org/10.1145/3687484",
    "publication_date": "2024-08-22",
    "publication_year": 2024,
    "authors": "Zhuoyang Jiang; Qun Ding; An Wang",
    "corresponding_authors": "",
    "abstract": "As the most commonly used side-channel analysis method, Correlation Power Analysis (CPA) usually uses the divide-and-conquer strategy to guess the single-byte key in the scenario of block cipher parallel implementation. However, this method cannot effectively use the power consumption information, resulting in a large number of power consumption traces. Therefore, genetic algorithm-based CPA is proposed, which can efficiently extract keys by multi-byte power analysis. However, genetic algorithm-based CPA tends to sacrifice computational cost to achieve a high key guessing success rate. To solve the above problems, this article focuses on bitwise linear leakage and proposes a multi-byte power analysis architecture based on the raindrop ripple algorithm. First, we propose to complete the key initialization by multiple linear regression. Second, we propose a novel swarm intelligence algorithm, the raindrop ripple algorithm, tailored for multi-byte power analysis based on the principles of “family planning” and “eugenics,” which greatly improves the probability of producing individuals with high fitness values. Third, we further enhance the possibility of the correct key being recovered by traversing the candidate key space in specific conditions. To verify the key guessing efficiency of the multi-byte power analysis architecture based on the raindrop ripple algorithm, comparative experiments are conducted on SAKURA-G with three power analysis methods based on genetic algorithms. Experimental results show that our proposal not only has the efficient power information utilization of multi-byte power analysis but also has a convergence speed comparable to or even faster than that of single-byte CPA. Its efficiency of key guessing is improved by 85.64% compared to EfficiencyGa-CPA, and its convergence speed is even faster than that of single-byte CPA at 725 power traces, and 83.87% faster than single-byte CPA at 1000 power traces, which is astonishing as a multi-byte power analysis.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401768517",
    "type": "article"
  },
  {
    "title": "EXPRESS: A Framework for Execution Time Prediction of Concurrent CNNs on Xilinx DPU Accelerator",
    "doi": "https://doi.org/10.1145/3697835",
    "publication_date": "2024-10-03",
    "publication_year": 2024,
    "authors": "Shikha Goel; Rajesh Kedia; Rijurekha Sen; M. Balakrishnan",
    "corresponding_authors": "",
    "abstract": "Deep learning Processor Unit (DPU) is a highly configurable CNN accelerator that supports a variety of CNNs and can be implemented with multiple instances on the same FPGA. Many applications deploy concurrent execution of different CNNs and in such a setting, an execution time predictor can help “optimize” the DPU configurations to meet the performance requirements of different tasks. We characterize CNN execution on DPUs and reduce the variability in execution time due to interference from the operating system. Subsequently, we propose a machine learning-based framework (EXPRESS) to predict the execution time of any given CNN on a DPU configuration, considering CNN, DPU, and bus characteristics. We improvise EXPRESS to support heterogeneous CNNs in EXPRESS-2.0 by making features independent of the number of CNNs. Our entire experimentation is based on data from a real FPGA board for 16 standard CNNs. Our frameworks, EXPRESS and EXPRESS-2.0, significantly outperform state-of-the-art by achieving an average execution time prediction error of 2.2% and 0.7%, respectively. We illustrate the effectiveness of this low prediction error for design space exploration, which is very useful for embedded system application developers.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403103392",
    "type": "article"
  },
  {
    "title": "MLTL Multi-type: A Typed Logic for Cyber-Physical Systems",
    "doi": "https://doi.org/10.1145/3704809",
    "publication_date": "2024-11-25",
    "publication_year": 2024,
    "authors": "Gokul Hariharan; Brian Kempa; Tichakorn Wongpiromsarn; Phillip H. Jones; Kristin Yvonne Rozier",
    "corresponding_authors": "",
    "abstract": "Modern cyber-physical systems-of-systems (CPSoS) operate in complex systems-of-systems that must seamlessly work together to control safety- or mission-critical functions. Linear Temporal Logic (LTL) and Mission-time Linear Temporal logic (MLTL) intuitively express CPSoS requirements for automated system verification and validation. However, both LTL and MLTL presume that all signals populating the variables in a formula are sampled over the same rate and type (e.g., time or distance), and agree on a standard “time” step. Formal verification of cyber-physical systems-of-systems needs validate-able requirements expressed over (sub-)system signals of different types, such as signals sampled at different timescales, distances, or levels of abstraction, expressed in the same formula. Previous works developed more expressive logics to account for types (e.g., timescales) by sacrificing the intuitive simplicity of LTL. However, a legible direct one-to-one correspondence between a verbal and formal specification will ease validation, reduce bugs, increase productivity, and linearize the workflow from a project’s conception to actualization. Validation includes both transparency for human interpretation, and tractability for automated reasoning, as CPSoS often run on resource-limited embedded systems. To address these challenges, we introduced Mission-time Linear Temporal Logic Multi-type (Hariharan et al., Numerical Software Verification Workshop, 2022), a logic building on MLTL. MLTLM enables writing formal requirements over finite input signals (e.g., sensor signals and local computations) of different types, while maintaining the same simplicity as LTL and MLTL. Furthermore, MLTLM maintains a direct correspondence between a verbal requirement and its corresponding formal specification. Additionally, reasoning a formal specification in the intended type (e.g., hourly for an hourly rate, and per second for a seconds rate) will use significantly less memory in resource-constrained hardware. This article extends the previous work with (1) many illustrated examples on types (e.g., time and space) expressed in the same specification, (2) proofs omitted for space in the workshop version, (3) proofs of succinctness of MLTLM compared to MLTL, and (4) a minimal translation to MLTL of optimal length.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404700209",
    "type": "article"
  },
  {
    "title": "Speculating to reduce unnecessary power consumption",
    "doi": "https://doi.org/10.1145/950162.950165",
    "publication_date": "2003-11-01",
    "publication_year": 2003,
    "authors": "Enric Musoll",
    "corresponding_authors": "Enric Musoll",
    "abstract": "The power consumption of current processors keeps increasing in spite of aggressive circuit design techniques and process shrinks. One of the reasons for this increase is the complexity of the microarchitecture required to achieve the performance that each processor generation demands. These techniques, such as branch prediction and on-chip level two caches, increase not only the power consumption of the committed instructions, but also the useless power associated with those block accesses that generate results that are not needed for the correct execution and commit of the instructions.In this work, the different accesses that a particular block receives are classified into four different components, based on whether the accesses are performed by instructions of the correct path or the wrong (mispredicted) path, and also based on whether the results of the accesses are needed or not for the correct execution of the instructions. Out of the four components, only one accounts for the useful accesses to the block, that is, accesses performed to correctly execute instructions that will be committed. The other three components account for the useless activity on the block. The simulations performed indicate that, if the useless power dissipation of a high-performance processor could be totally removed with no performance degradation, the overall processor power consumption would be reduced by as much as 65% compared to the same processor in which all the blocks are accessed every cycle.This work then proposes a microarchitectural technique that targets the reduction of the useless power dissipation. The technique consists of predicting whether the result of a particular block of logic will be useful in order to execute the instructions (no matter whether the instructions will be eventually committed or not). If it is predicted useless, then the block is disabled.A case example is presented where two blocks are predicted for low power: the on-chip L2 cache for instruction fetches and the branch target buffer (BTB). The IPC versus power-consumption design space is explored for a particular microprocessor architecture. Both the average and the peak power consumption are targeted. High-level estimations are done to show that it is plausible that the ideas described might produce a significant reduction in useless block accesses. As an example, 65% accesses to the L2 cache can be eliminated at a 0.2% IPC degradation, and about 5% accesses to the BTB can be saved at the penalty of 0.7% IPC reduction.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1993798484",
    "type": "article"
  },
  {
    "title": "Static resource models for code-size efficient embedded processors",
    "doi": "https://doi.org/10.1145/643470.643475",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Qin Zhao; Bart Mesman; Twan Basten",
    "corresponding_authors": "",
    "abstract": "Due to an increasing need for flexibility, embedded systems embody more and more programmable processors as their core components. Due to silicon area and power considerations, the corresponding instruction sets are often highly encoded to minimize code size for given performance requirements. This has hampered the development of robust optimizing compilers because the resulting irregular instruction set architectures are far from convenient compiler targets. Among other considerations, they introduce an interdependence between the tasks of instruction selection and scheduling. This so-called phase coupling is so strong that, in practice, instruction selection rather than scheduling is responsible for the quality of the schedule, which tends to disappoint. The lack of efficient compilation tools has also severely hampered the design space exploration of code-size efficient instruction sets, and correspondingly, their tuning to the application domain. In this article, we present an approach that reduces the need for explicit instruction selection by transferring constraints implied by the instruction set to static resource constraints. All resulting schedules are then guaranteed to correspond to a valid implementation with given instructions. We also demonstrate the suitability of this model to enable instruction set design (-space exploration) with a simple, well-understood and proven method long used in high-level synthesis (HLS) of ASICs. Experimental results show the efficacy of our approach.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2127938953",
    "type": "article"
  },
  {
    "title": "Introduction to the two special issues on memory",
    "doi": "https://doi.org/10.1145/605459.605460",
    "publication_date": "2003-02-01",
    "publication_year": 2003,
    "authors": "Bruce Jacob; Shuvra S. Bhattacharyya",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to the two special issues on memory Share on Authors: Bruce Jacob View Profile , Shuvra Bhattacharyya View Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 2Issue 1February 2003 pp 1–4https://doi.org/10.1145/605459.605460Online:01 February 2003Publication History 1citation2,104DownloadsMetricsTotal Citations1Total Downloads2,104Last 12 Months4Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4214718549",
    "type": "article"
  },
  {
    "title": "A Storage Device Emulator for System Performance Evaluation",
    "doi": "https://doi.org/10.1145/2785969",
    "publication_date": "2015-10-20",
    "publication_year": 2015,
    "authors": "Ming‐Ju Wu; Chun-Jen Tsai",
    "corresponding_authors": "",
    "abstract": "The performance and characteristics of the storage devices used in embedded systems can have a great influence on the overall end user experience. When building embedded systems or designing new storage device components, it is important for the designers to be able to evaluate how storage devices of different characteristics will affect the overall system performance. Storage device emulation enables a system's performance to be evaluated with simulated storage devices that are not yet available. In storage device emulation, the emulated storage device appears to the operating system (OS) as a real storage device and its service timings are determined by a disk model, which simulates the behavior of the target storage device. In the conventional storage device emulators, because the OS is running continuously in the real-time domain, the amount of time that the emulators can spend on processing each I/O request is limited by the service time of each corresponding I/O request. This timing constraint can make emulating high-speed storage devices a challenge for the conventional storage device emulators. In this article, we propose an OS state pausing approach to storage device emulation that can overcome the timing constraints faced by the conventional storage device emulators. By pausing the state of the OS while the storage device emulator is busy, the proposed emulator can spend as much time as it needs for processing each I/O request without affecting the performance of the emulated storage device as perceived by the OS. This allows the proposed storage device emulator to emulate storage devices that would otherwise be challenging or even impossible for the conventional storage device emulators. In addition, the main task of storage device emulation is offloaded to an external computer to minimize the impact of the emulation workload on the target machine. The proposed storage device emulator is implemented with the Linux OS 1 on an embedded system development board. Experimental results show that the full-system performance benchmarks measured with the proposed storage device emulator are within 2% differences compared to the results of the reference system.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1970587542",
    "type": "article"
  },
  {
    "title": "Guest Editorial for Special Issue Application of Concurrency to System Design",
    "doi": "https://doi.org/10.1145/2809925",
    "publication_date": "2015-10-20",
    "publication_year": 2015,
    "authors": "Kamel Barkaoui; Luca Bernardinello; Andrey Mokhov",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1972112016",
    "type": "editorial"
  },
  {
    "title": "Maximizing the Number of Good Dies for Streaming Applications in NoC-Based MPSoCs Under Process Variation",
    "doi": "https://doi.org/10.1145/2785968",
    "publication_date": "2015-09-24",
    "publication_year": 2015,
    "authors": "Davit Mirzoyan; Benny Åkesson; Sander Stuijk; Kees Goossens",
    "corresponding_authors": "",
    "abstract": "Scaling CMOS technology into nanometer feature-size nodes has made it practically impossible to precisely control the manufacturing process. This results in variation in the speed and power consumption of a circuit. As a solution to process-induced variations, circuits are conventionally implemented with conservative design margins to guarantee the target frequency of each hardware component in manufactured multiprocessor chips. This approach, referred to as worst-case design, results in a considerable circuit upsizing, in turn reducing the number of dies on a wafer. This work deals with the design of real-time systems for streaming applications (e.g., video decoders) constrained by a throughput requirement (e.g., frames per second) with reduced design margins, referred to as better-than-worst-case design . To this end, the first contribution of this work is a complete modeling framework that captures a streaming application mapped to an NoC-based multiprocessor system with voltage-frequency islands under process-induced die-to-die and within-die frequency variations . The framework is used to analyze the impact of variations in the frequency of hardware components on application throughput at the system level . The second contribution of this work is a methodology to use the proposed framework and estimate the impact of reducing circuit design margins on the number of good dies that satisfy the throughput requirement of a real-time streaming application . We show on both synthetic and real applications that the proposed better-than-worst-case design approach can increase the number of good dies by up to 9.6% and 18.8% for designs with and without fixed SRAM and IO blocks, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1978131249",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2588608",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Marco Di Natale; Rich West; Jian-Jia Chen; Rahul Mangharam",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1987364993",
    "type": "editorial"
  },
  {
    "title": "Introduction to Special Issue on Cross-layer Dependable Embedded Systems",
    "doi": "https://doi.org/10.1145/2588610",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Nikil Dutt; Mehdi B. Tahoori",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1990120234",
    "type": "article"
  },
  {
    "title": "Towards scalable arithmetic units with graceful degradation",
    "doi": "https://doi.org/10.1145/2499367",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Danny P. Riemens; Georgi Gaydadjiev; Chris I. De Zeeuw; Christos Strydis",
    "corresponding_authors": "",
    "abstract": "This article presents a new family of scalable arithmetic units (ScAUs) targeting resource-constrained, embedded devices. We, first, study the performance, power, area and scalability properties of general adders. Next, suitable error-detection schemes for low-power embedded systems are discussed. As a result, our ScAUs are enhanced with a suitable error-detection scheme, resulting in a Parity-Checked ScAU (PCScAU) design. The PCScAU strikes a flexible trade-off between space and time redundancy, offering dependability similar to high-end techniques for the area and power cost of low-end approaches. An alternative design, the Precision-Scalable Arithmetic Unit (PScAU) maintains throughput with degraded precision in case of hardware failures. The PScAU is targeting dependable applications where latency rather than numerical accuracy is more important. The PScAU's downscaled mode is also interesting for runtime thermal management due to its advantageous power consumption. We implemented and synthesized the PCScAU, PScAU and a few important reference designs (double-, triple- and quadruple-modular-redundancy adders with/without input gating) in 90- nm UMC technology. Overall, the PC-ScAU ranks first in 9 out of 10 power-delay-area (PDA)-product variants. It exhibits 16% area savings and 12% performance speedup for 7% increase in total power consumption, compared to the cheapest form of conventional hardware replication with the same fault coverage. The PDA product of the PCScAU is, thus, reduced by 21%. It is interesting that, while total power slightly increases, the PCScAU static power in fact decreases by 14%. Therefore, for newer technology nodes where the static power component is significant, the PCScAU can also achieve—next to performance and area -- significant power improvements.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1999916686",
    "type": "article"
  },
  {
    "title": "Introduction to Special Issue on Application of Concurrency to System Design (ACSD'13)",
    "doi": "https://doi.org/10.1145/2627347",
    "publication_date": "2014-07-01",
    "publication_year": 2014,
    "authors": "Josep Carmona; Mihai T. Lazarescu; Marta Pietkiewicz-Koutny",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2009797164",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2567941",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Masoud Daneshtalab; Maurizio Palesi; Juha Plosila",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2018605241",
    "type": "editorial"
  },
  {
    "title": "3D CV Descriptor on Parallel Heterogeneous Platforms",
    "doi": "https://doi.org/10.1145/2733377",
    "publication_date": "2015-09-24",
    "publication_year": 2015,
    "authors": "Daniele Palossi; Martino Ruggiero; Luca Benini",
    "corresponding_authors": "",
    "abstract": "Embedded three-dimensional (3D) Computer Vision (CV) is considered a technology enabler for future consumer applications, attracting a wide interest in academia and industry. However, 3D CV processing is a computation-intensive task. Its high computational cost is directly related to the processing of 3D point clouds, with the 3D descriptor computation representing one of the main bottlenecks. Understanding the main computational challenges of 3D CV applications, as well as the key characteristics, enabling features, and limitations of current computing platforms, is clearly strategic to identify the directions of evolution for future embedded processing systems targeting 3D CV. In this work, an innovative and complex 3D descriptor (called SHOT) has been ported on a high-end and an embedded computing platform. The high-end system is composed by a high-performance Intel CPU coupled with a Nvidia GPU. The embedded platform is, instead, composed by an ARM-based processor, coupled with the STHORM accelerator. STHORM is a many-core low-power accelerator developed by ST Microelectronics, featuring up to 64 computational units. The SHOT descriptor has been parallelized using the OpenCL programming model for both platforms. Finally, we have performed an in-depth performance comparison and analysis between general-purpose processors and accelerators in both high-end and embedded domains, discussing and highlighting the main differences in the Hardware/Software (HW/SW) design methodologies and approaches between high-end and embedded systems targeting 3D CV applications.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2019576895",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2678027",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2025875996",
    "type": "editorial"
  },
  {
    "title": "Stability of Online Resource Managers for Distributed Systems under Execution Time Variations",
    "doi": "https://doi.org/10.1145/2629495",
    "publication_date": "2015-03-09",
    "publication_year": 2015,
    "authors": "Sergiu Rafiliu; Petru Eles; Zebo Peng; Michael Lemmon",
    "corresponding_authors": "",
    "abstract": "Today's embedded systems are exposed to variations in resource usage due to complex software applications, hardware platforms, and impact of the runtime environments. When these variations are large and efficiency is required, on-line resource managers may be deployed on the system to help it control its resource usage. An often neglected problem is whether these resource managers are stable, meaning that the resource usage is controlled under all possible scenarios. In distributed systems, this problem is particularly hard because applications distributed over many resources generate complex dependencies between their resources. In this article, we develop a mathematical model of the system, and derive conditions that, if satisfied, guarantee stability.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2027625734",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2587894",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2040247852",
    "type": "editorial"
  },
  {
    "title": "Parameter Space Representation of Pareto Front to Explore Hardware-Software Dependencies",
    "doi": "https://doi.org/10.1145/2764457",
    "publication_date": "2015-09-09",
    "publication_year": 2015,
    "authors": "Vincenzo Catania; Andrea Araldo; Davide Patti",
    "corresponding_authors": "",
    "abstract": "Embedded systems design requires conflicting objectives to be optimized with an appropriate choice of hardware-software parameters. A simulation campaign can guide the design in finding the best trade-offs, but due to the big number of possible configurations, it is often unfeasible to simulate them all. For these reasons, design space exploration algorithms aim at finding near-optimal system configurations by simulating only a subset of them. In this work, we present PS, a new multiobjective optimization algorithm, and evaluate it in the context of the embedded system design. The basic idea is to recognize interesting regions—that is, regions of the configuration space that provide better configurations with respect to other ones. PS evaluates more configurations in the interesting regions while less thoroughly exploring the rest of the configuration space. After a detailed formal description of the algorithm and the underlying concepts, we show a case study involving the hardware/software exploration of a VLIW architecture. Qualitative and quantitative comparisons of PS against a well-known multiobjective genetic approach demonstrate that while not outperforming it in terms of Pareto dominance, the proposed approach can balance the uniformity and granularity qualities of the solutions found, obtaining more extended Pareto fronts that provide a wider view of the potentiality of the designed device. Therefore, PS represents a further valid choice for the designer when objective constrains allow it.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2040456947",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Domain-Specific Multicore Computing",
    "doi": "https://doi.org/10.1145/2588609",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Vijaykrishnan Narayanan; Jürgen Teich",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2040993729",
    "type": "article"
  },
  {
    "title": "Introduction to Special Issue on Risk and Trust in Embedded Critical Systems",
    "doi": "https://doi.org/10.1145/2659008",
    "publication_date": "2014-10-06",
    "publication_year": 2014,
    "authors": "Judith E. Y. Rossebø; Siv Hilde Houmb; Geri Georg; Virginia N. L. Franqueira; Dimitrios Serpanos",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2049726449",
    "type": "article"
  },
  {
    "title": "Transport triggered architecture to perform carrier synchronization for LTE",
    "doi": "https://doi.org/10.1145/2560036",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Omer Anjum; Mubashir Ali; Teemu Pitkänen; Jari Nurmi",
    "corresponding_authors": "",
    "abstract": "In this article implementation of carrier frequency offset estimate for 20MHz LTE baseband processing is discussed. LTE (Long Term Evolution) is a wireless communication standard that makes use of some innovative techniques to gain very high data rates (&gt;100Mbps). This goal for such a high throughput also imposes design challenges for the industry and academia such as in the case of handheld mobile devices where the power budget is very limited. Implicitly high throughput means we need more computation power and more energy. On the other hand industry is also struggling for a flexible hardware solution, or software defined a radio (SDR), to amortize the huge cost of required hardware changes as the wireless standards have kept evolving. Design innovations are now needed to confront those challenges of low power and flexible design without changing the hardware. The implementation is made on Transport Triggered Architecture (TTA), which is a unique concept in computer architecture design, based on the single instruction, “MOVE”. The power consumption of the architecture when synthesized on 180nm technology at 180MHz and 1.8V is 18.39mW. The total area occupied excluding memory is 0.6mm 2 . The proposed TTA solution has been compared with, a more ASIC (application specific integrated circuits), like ASIP (application specific instruction processor) solution and a coprocessor accelerator-based solution. The proposed solution is more flexible: easily programmable due to high level language support, easily scalable, and still efficient in energy consumption needed to complete the CFO (carrier frequency offset) estimation task. Because of these attractive characteristics, TTA is also a potential candidate for SDR platforms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2051044822",
    "type": "article"
  },
  {
    "title": "GENESIS",
    "doi": "https://doi.org/10.1145/2629651",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "Dionysios Diamantopoulos; Kostas Siozios; Sotirios Xydis; Dimitrios Soudris",
    "corresponding_authors": "",
    "abstract": "Placement is though as the most time-consuming processes in physical implementation flows for reconfigurable architectures, while it highly affects the quality of derived application implementation, as it has impact on the maximum operating frequency. Throughout this article, we propose a novel placer, based on genetic algorithm, targeting to FPGAs. Rather than relevant approaches, which are executed sequentially, the new placer exhibits inherent parallelism, which can benefit from multicore processors. Experimental results prove the effectiveness of this solution, as it achieves average reduction of execution runtime and application’s delay by 67× and 16%, respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2056350318",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2567942",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "Maurizio Palesi; Todor Stefanov",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2062670023",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2559122",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2067776971",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2632152",
    "publication_date": "2014-07-01",
    "publication_year": 2014,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2082691975",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2742044",
    "publication_date": "2015-03-25",
    "publication_year": 2015,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2087334779",
    "type": "editorial"
  },
  {
    "title": "Simulation-based functional verification of dynamically reconfigurable systems",
    "doi": "https://doi.org/10.1145/2560042",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Lingkan Gong; Oliver Diessel",
    "corresponding_authors": "",
    "abstract": "Dynamically reconfigurable systems (DRS) implemented using field-programmable gate arrays (FPGAs) allow hardware logic to be partially reconfigured while the rest of the design continues to operate. By mapping multiple reconfigurable hardware modules to the same physical region of an FPGA, such systems are able to time-multiplex their modules at runtime and adapt themselves to changing execution requirements. This architectural flexibility introduces challenges for verifying system functionality. New simulation approaches are required to extend traditional simulation techniques to assist designers in testing and debugging the time-varying behavior of DRS. This article summarizes our previous work on ReSim, the first tool to allow cycle-accurate yet physically independent simulation of a DRS reconfiguring both its logic and state. Furthermore, ReSim-based simulation does not require changing the design for simulation purposes and thereby verifies the implementation-ready design instead of a variation of the design. We discuss the conflicting requirements of simulation accuracy and verification productivity in verifying DRS designs and describe our approach to resolve this challenge. Through a range of case studies, we demonstrate that ReSim assists designers in detecting fabric-independent bugs of DRS designs and helps to achieve verification closure of DRS design projects.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2092796988",
    "type": "article"
  },
  {
    "title": "Rapid evaluation of custom instruction selection approaches with FPGA estimation",
    "doi": "https://doi.org/10.1145/2560014",
    "publication_date": "2014-03-10",
    "publication_year": 2014,
    "authors": "Siew-Kei Lam; Thambipillai Srikanthan; Christopher T. Clarke",
    "corresponding_authors": "",
    "abstract": "The main aim of this article is to demonstrate that a fast and accurate FPGA estimation engine is indispensable in design flows for custom instruction (template) selection. The need for a FPGA estimation engine stems from the difficulty in predicting the FPGA performance measures of selected custom instructions. We will present a FPGA estimation technique that partitions the high-level representation of custom instructions into clusters based on the structural organization of the target FPGA, while taking into account general logic synthesis principles adopted by FPGA tools. In this work, we have evaluated a widely used graph covering algorithm with various heuristics for custom instruction selection. In addition, we present an algorithm called Refined Largest Fit First (RLFF) that relies on a graph covering heuristic to select non-overlapping superset templates, which typically incorporate frequently used basic templates. The initial solution is further refined by considering overlapping templates that were ignored previously to see if their introduction could lead to higher performance. While RLFF provides the most efficient cover compared to the ILP method and other graph covering heuristics, FPGA estimation results reveals that RLFF leads to the worst performance in certain applications. It is therefore a worthy proposition to equip design flows with accurate FPGA estimation in order to rapidly determine the most profitable custom instruction approach for a given application.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2125398922",
    "type": "article"
  },
  {
    "title": "TBES",
    "doi": "https://doi.org/10.1145/2816817",
    "publication_date": "2016-01-13",
    "publication_year": 2016,
    "authors": "Youenn Corre; Jean-Philippe Diguet; Dominique Heller; Dominique Blouin; Loïc Lagadec",
    "corresponding_authors": "",
    "abstract": "This article describes TBES, a software end-to-end environment for synthesizing multitask applications on FPGAs. The implementation follows a template-based approach for creating heterogeneous multiprocessor architectures. Heterogeneity stems from the use of general-purpose processors along with custom accelerators. Experimental results demonstrate substantial speedup for several classes of applications. Furthermore, this work allows for reducing development costs and saving development time for the software architect, the domain expert, and the optimization expert. This work provides a framework to bring together various existing tools and optimisation algorithms. The advantages are manifold: modularity and flexibility, easy customization for best-fit algorithm selection, durability and evolution over time, and legacy preservation including domain experts' know-how. In addition to the use of architecture templates for the overall system, a second contribution lies in using high-level synthesis for promoting exploration of hardware IPs. The domain expert, who best knows which tasks are good candidates for hardware implementation, selects parts of the initial application to be potentially synthesized as dedicated accelerators. As a consequence, the HLS general problem turns into a constrained and more tractable issue, and automation capabilities eliminate the need for tedious and error-prone manual processes during domain space exploration. The automation only takes place once the application has been broken down into concurrent tasks by the designer, who can then drive the synthesis process with a set of parameters provided by TBES to balance tradeoffs between optimization efforts and quality of results. The approach is demonstrated step by step up to FPGA implementations and executions with an MJPEG benchmark and a complex Viola-Jones face detection application. We show that TBES allows one to achieve results with up to 10 times speedup to reduce development times and to widen design space exploration.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2233740382",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2953045",
    "publication_date": "2016-07-21",
    "publication_year": 2016,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2498938599",
    "type": "editorial"
  },
  {
    "title": "Guest Editorial for Special Issue of ESWEEK 2015",
    "doi": "https://doi.org/10.1145/2968218",
    "publication_date": "2016-09-01",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2509536124",
    "type": "editorial"
  },
  {
    "title": "A Universal Application Storage System Based on Smart Card",
    "doi": "https://doi.org/10.1145/2886116",
    "publication_date": "2016-09-01",
    "publication_year": 2016,
    "authors": "Jie Shen; Yingjue Cai; Ren Yang; Xiao Yang",
    "corresponding_authors": "",
    "abstract": "Nowadays, electronic commerce (e-commerce) has brought facilitation to people’s daily lives. Smart-card-based systems are widely used as an implementation, where smart cards act as a secure carrier for small-sized data. However, most of these systems are developed and managed by each service provider individually and repeatedly, which causes both unnecessary work and difficulties in future maintenance. Besides, advantages of smart card technology are not full-fledged for the lack of enough consideration in flexibility and security. To propose a solution, this article presents a Universal Application Storage System, including card side, terminal side, and back-end system. The card side provides a universal and secured infrastructure for data storage, where data are organized and stored in a card file system with several security mechanisms. In the terminal side, a framework for accessing various forms of secure element is presented to simplify the procedures involved in manipulating smart cards. Through this framework, the back-end system is able to establish a direct connection to the card, and performs authorized operations by exchanging commands in a secure channel. The validity of the proposed system is verified at the end of this article, illustrated by an e-coupon system.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2510136822",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2976731",
    "publication_date": "2016-09-01",
    "publication_year": 2016,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2511225454",
    "type": "editorial"
  },
  {
    "title": "VecRA",
    "doi": "https://doi.org/10.1145/2961026",
    "publication_date": "2016-09-01",
    "publication_year": 2016,
    "authors": "Yi‐Ping You; Szu‐Chien Chen",
    "corresponding_authors": "",
    "abstract": "Graphics processing units (GPUs) are now widely used in embedded systems for manipulating computer graphics and even for general-purpose computation. However, many embedded systems have to manage highly restricted hardware resources in order to achieve high performance or energy efficiency. The number of registers is one of the common limiting factors in an embedded GPU design. Programs that run with a low number of registers may suffer from high register pressure if register allocation is not properly designed, especially on a GPU in which a register is divided into four elements and each element can be accessed separately, because allocating a register for a vector-type variable that does not contain values in all elements wastes register spaces. In this article, we present a vector-aware register allocation framework to improve register utilization on shader architectures. The framework involves two major components: (1) element-based register allocation that allocates registers based on the element requirement of variables and (2) register packing that rearranges elements of registers in order to increase the number of contiguous free elements, thereby keeping more live variables in registers. Experimental results on a cycle-approximate simulator showed that the proposed framework decreased 92% of register spills in total and made 91.7% of 14 common shader programs spill free. These results indicate an opportunity for energy management of the space that is used for storing spilled variables, with the framework improving the performance by a geometric mean of 8.3%, 16.3%, and 29.2% for general shader processors in which variables are spilled to memory with 5-, 10-, and 20-cycle access latencies, respectively. Furthermore, the reduction in the register requirement of programs enabled another 11 programs with high register pressure to be runnable on a lightweight GPU.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2512495129",
    "type": "article"
  },
  {
    "title": "A Lightweight Framework for the Dynamic Creation and Configuration of Virtual Platforms in SystemC",
    "doi": "https://doi.org/10.1145/2983626",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Christian Sauer; Hans-Peter Loeb",
    "corresponding_authors": "",
    "abstract": "Virtual prototypes leverage SystemC/TLM for simulating programmable platforms comprising hundreds of modules. Their efficient creation and configuration is vital for acceptable turnaround times, for example, during performance exploration or software development. Therefore, our lightweight framework provides a factory that creates designs from abstract descriptions of module instances, properties, and connections. Modules mark properties as creation or runtime parameters. The resulting generic design descriptions are usable by non-experts and enable front-ends. The infrastructure is a small C++ library with only 1,350 lines of code that can be combined with existing SystemC/TLM models and simulation kernels. An industrial case study of a complex multiprocessor SoC shows a distinct productivity gain.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2530037301",
    "type": "article"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/2991466",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Jerónimo Castrillón; Cristina Silvano",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2530282724",
    "type": "editorial"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/2991464",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Dakai Zhu; Meikang Qiu; Samarjit Chakraborty",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2530329654",
    "type": "editorial"
  },
  {
    "title": "A Framework for Interconnection-Aware Domain-Specific Many-Accelerator Synthesis",
    "doi": "https://doi.org/10.1145/2983624",
    "publication_date": "2016-10-13",
    "publication_year": 2016,
    "authors": "Efstathios Sotiriou-Xanthopoulos; Sotirios Xydis; Kostas Siozios; George Economakos; Dimitrios Soudris",
    "corresponding_authors": "",
    "abstract": "Many-accelerator Systems-on-Chip (SoC) have recently emerged as a promising platform paradigm that combines parallelization with heterogeneity, in order to cover the increasing demands for high performance and energy efficiency. To exploit the full potential of many-accelerator systems, automated design verification and analysis frameworks are required, targeted to both computational and interconnection optimization. Accurate simulation of interconnection schemes should use real stimuli, which are produced from fully functional nodes, requiring the prototyping of the processing elements and memories of the many-accelerator system. In this article, we argue that the Hierarchical Network-on-Chip (HNoC) scheme forms a very promising solution for many-accelerator systems in terms of scalability and data-congestion minimization. We present a parameterizable SystemC prototyping framework for HNoCs, targeted to domain-specific many-accelerator systems. The framework supports the prototyping of processing elements, memory modules, and underlying interconnection infrastructure, while it provides an API for their easy integration to the HNoC. Finally, it enables holistic system simulation using real node data. Using as a case study a many-accelerator system of an MRI pipeline, an analysis on the proposed framework is presented to demonstrate the impact of the system parameters on the system. Through extensive experimental analysis, we show the superiority of HNoC schemes in comparison to typical interconnection architectures. Finally, we show that, adopting the proposed many-accelerator design flow, significant performance improvements are achieved, from 1.2 × up to 26 × , as compared to a x86 software implementation of the MRI pipeline.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2531531599",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on ESTIMedia'11",
    "doi": "https://doi.org/10.1145/2544375.2544378",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Naehyuck Chang; Jian-Jia Chen",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2915341808",
    "type": "article"
  },
  {
    "title": "On the infeasibility of analysing worst-case dynamic energy",
    "doi": null,
    "publication_date": "2016-03-07",
    "publication_year": 2016,
    "authors": "Jeremy Morse; Steve Kerrison; Kerstin Eder",
    "corresponding_authors": "",
    "abstract": "In this paper we study the sources of dynamic energy during the execution of software on microprocessors suited for the Internet of Things (IoT) domain. Estimating the energy consumed by executing software is typically achieved by determining the most costly path through the program according to some energy model of the processor. Few models, however, adequately tackle the matter of dynamic energy caused by operand data. We find that the contribution of operand data to overall energy can be significant, prove that finding the worst-case input data is NP-hard, and further, that it cannot be estimated to any useful factor. Our work shows that accurate worst-case analysis of data dependent energy is infeasible, and that other techniques for energy estimation should be considered.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2963805742",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2821757",
    "publication_date": "2015-12-08",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "To improve the performance of the memory system, multiprocessors implement weak memory consistency models. Weak memory models admit different views of the processes on their load and store instructions, thus allowing for computations that are not ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230893114",
    "type": "paratext"
  },
  {
    "title": "Abstracts",
    "doi": "https://doi.org/10.1145/2688494.2688495",
    "publication_date": "2014-12-05",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "research-article Share on Abstracts: Online Supplements Volume 13, Number 1s Volume 13, Number 2s Volume 13, Number 3s Volume 13, Number 4s Volume 13, Number 5sACM Transactions on Embedded Computing SystemsVolume 13Issue 4November 2014 Article No.: 99pp 1–57https://doi.org/10.1145/2688494.2688495Online:05 December 2014Publication History 0citation92DownloadsMetricsTotal Citations0Total Downloads92Last 12 Months6Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230966371",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3008024",
    "publication_date": "2016-11-03",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Architectural heterogeneity has proven to be an effective design paradigm to cope with an ever-increasing demand for computational power within tight energy budgets, in virtually every computing domain. Programmable manycore accelerators are currently ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231724262",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2592905",
    "publication_date": "2014-12-05",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The main aim of this article is to demonstrate that a fast and accurate FPGA estimation engine is indispensable in design flows for custom instruction (template) selection. The need for a FPGA estimation engine stems from the difficulty in predicting ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232356756",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2724585",
    "publication_date": "2015-01-21",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In the Ghiribaldi et al. [2013] paper, a complete self-testing and self configuring NoC infrastructure for cost-effective MPSoCs was presented in order to make NoC architecture tolerant to faults. To overcome the complexity involved during the complete ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234167335",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2597868",
    "publication_date": "2014-03-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article proposes a scalable wavelength-routed optical Network on Chip (NoC) based on the Spidergon topology, named Power-efficient Scalable Wavelength-routed Network-on-chip (PeSWaN). The key idea of the proposed all-optical architecture is the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235421711",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2982215",
    "publication_date": "2016-09-01",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Graphics processing units (GPUs) are now widely used in embedded systems for manipulating computer graphics and even for general-purpose computation. However, many embedded systems have to manage highly restricted hardware resources in order to achieve ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235753548",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2888407",
    "publication_date": "2016-06-07",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Embedded systems must address a multitude of potentially conflicting design constraints such as resiliency, energy, heat, cost, performance, security, etc., all in the face of highly dynamic operational behaviors and environmental conditions. By ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239136624",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2660459",
    "publication_date": "2014-12-15",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We address the challenge of designing predictable real-time systems in an unpredictable thermal environment where environmental temperature may dynamically change (e.g., implantable medical devices). Towards this challenge, we propose a control-...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243123705",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2872313",
    "publication_date": "2016-02-20",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "With the advent of ubiquitous computing and the Internet of Things (IoT), the security and privacy issues for various smart devices such as radio-frequency identification (RFID) tags and wireless sensor nodes are receiving increased attention from ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244093646",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2737797",
    "publication_date": "2015-03-25",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Today's embedded systems are exposed to variations in resource usage due to complex software applications, hardware platforms, and impact of the runtime environments. When these variations are large and efficiency is required, on-line resource managers ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4249839153",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2764962",
    "publication_date": "2015-05-21",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Digital signatures are an important primitive for building secure systems and are used in most real-world security protocols. However, almost all popular signature schemes are either based on the factoring assumption (RSA) or the hardness of the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251021535",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2601432",
    "publication_date": "2014-07-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We describe and evaluate explicit reservation of cache memory to reduce the cache-related preemption delay (CRPD) observed when tasks share a cache in a preemptive multitasking hard real-time system. We demonstrate the approach using measurements ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251581374",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2899033",
    "publication_date": "2016-07-21",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In embedded systems operated by battery and interacting with the environment, a fundamental issue is the enforcement of real-time and energy constraints to guarantee a desired lifetime with a given performance. A lot of research has focused on energy ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254705180",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2544375",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article presents a framework for deploying a minimal number of smart meters to accurately track the ON/OFF states of a massive number of electrical appliances which exploits the sparseness feature of simultaneous ON/OFF switching events of the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256490091",
    "type": "paratext"
  },
  {
    "title": "Analytical Program Power Characterization for Battery Depletion-time Estimation",
    "doi": "https://doi.org/10.1145/3421511",
    "publication_date": "2021-01-04",
    "publication_year": 2021,
    "authors": "Mahdi Mohammadpour Fard; Mahmood Hasanloo; Mehdi Kargahi",
    "corresponding_authors": "",
    "abstract": "Appropriate battery selection is a major design decision regarding the fast growth of battery-operated devices like space rovers, wireless sensor network nodes, rescue robots, and so on. Many such systems are mission critical, where estimation of the battery depletion time has an important role in the design efficiency with regard to the mission time. Accurate characterization of the system power usage pattern is essential for such an estimation. The following complexities exist: (1) The system behavior changes during interaction with the physical world, (2) the power consumption varies as the runtime progresses, (3) the total delivered battery charge has non-linear dependency on the power variability, and (4) design-time exhaustive study about runtime execution paths is almost impossible. This article presents an analytical method to first characterize the power variability of a given embedded program modeled by a directed acyclic graph, concerning the first and the second complexities. To include the third complexity, however, the concept of Worst-case Power Consumption Trace (WPCT) is proposed toward the worst-case scenario in terms of charge depletion for a given battery. A polynomial algorithm is also presented to construct WPCT and use it to estimate a tight lower bound for the system energy depletion time, i.e., its failure time, avoiding an exhaustive study. Comparisons between the analytical and simulation results reveal less than 3.4% of error in the bound estimations for the considered setups.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3120019096",
    "type": "article"
  },
  {
    "title": "Precise Cache Profiling for Studying Radiation Effects",
    "doi": "https://doi.org/10.1145/3442339",
    "publication_date": "2021-03-27",
    "publication_year": 2021,
    "authors": "James B. Marshall; Robert Gifford; Gedare Bloom; Gabriel Parmer; Rahul Simha",
    "corresponding_authors": "",
    "abstract": "Increased access to space has led to an increase in the usage of commodity processors in radiation environments. These processors are vulnerable to transient faults such as single event upsets that may cause bit-flips in processor components. Caches in particular are vulnerable due to their relatively large area, yet are often omitted from fault injection testing because many processors do not provide direct access to cache contents and they are often not fully modeled by simulators. The performance benefits of caches make disabling them undesirable, and the presence of error correcting codes is insufficient to correct for increasingly common multiple bit upsets. This work explores building a program’s cache profile by collecting cache usage information at an instruction granularity via commonly available on-chip debugging interfaces. The profile provides a tighter bound than cache utilization for cache vulnerability estimates (50% for several benchmarks). This can be applied to reduce the number of fault injections required to characterize behavior by at least two-thirds for the benchmarks we examine. The profile enables future work in hardware fault injection for caches that avoids the biases of existing techniques.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3145692879",
    "type": "article"
  },
  {
    "title": "Microcontroller Fingerprinting Using Partially Erased NOR Flash Memory Cells",
    "doi": "https://doi.org/10.1145/3448271",
    "publication_date": "2021-03-27",
    "publication_year": 2021,
    "authors": "Prawar Poudel; Biswajit Ray; Aleksandar Milenković",
    "corresponding_authors": "",
    "abstract": "Electronic device fingerprints, unique bit vectors extracted from device's physical properties, are used to differentiate between instances of functionally identical devices. This article introduces a new technique that extracts fingerprints from unique properties of partially erased NOR flash memory cells in modern microcontrollers. NOR flash memories integrated in modern systems-on-a-chip typically hold firmware and read-only data, but they are increasingly in-system-programmable, allowing designers to erase and program them during normal operation. The proposed technique leverages partial erase operations of flash memory segments that bring them into the state that exposes physical properties of the flash memory cells through a digital interface. These properties reflect semiconductor process variations and defects that are unique to each microcontroller or a flash memory segment within a microcontroller. The article explores threshold voltage variation in NOR flash memory cells for generating fingerprints and describes an algorithm for extracting fingerprints. The experimental evaluation utilizing a family of commercial microcontrollers demonstrates that the proposed technique is cost-effective, robust, and resilient to changes in voltage and temperature as well as to aging effects.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3151687928",
    "type": "article"
  },
  {
    "title": "Time Measurement and Control Blocks for Bare-Metal C++ Applications",
    "doi": "https://doi.org/10.1145/3434401",
    "publication_date": "2021-05-13",
    "publication_year": 2021,
    "authors": "Friederike Bruns; Irune Yarza; Philipp Ittershagen; Kim Grüttner",
    "corresponding_authors": "",
    "abstract": "Precisely timed execution of resource constrained bare-metal applications is difficult, because the embedded software developer usually has to implement and check the timeliness of the executed application through manual interaction with timers or counters. In the scope of this work, we propose a combined timing specification and concept for time annotation and control blocks in C++. Our proposed blocks can be used to measure and profile software block execution time. Furthermore, it can be used to control and enforce the software time behavior at runtime. After the application of these time blocks, a trace-based verification against the block-based timing specification can be performed to obtain evidence on the correct implementation and usage of the time blocks on the target platform. We have implemented our time block concept in a C++ library and tested it on an ARM Cortex A9 bare-metal platform. The combined usage of timing specification and our time block library has been successfully evaluated on a critical flight-control software for a multi-rotor system.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3160657308",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3450438",
    "publication_date": "2021-04-23",
    "publication_year": 2021,
    "authors": "Tulika Mitra",
    "corresponding_authors": "Tulika Mitra",
    "abstract": "editorial Free Access Share on Editorial: Reimagining ACM Transactions on Embedded Computing Systems (TECS) Editor: Tulika Mitra National University of Singapore National University of SingaporeView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 20Issue 3May 2021 Article No.: 18epp 1–3https://doi.org/10.1145/3450438Published:23 April 2021Publication History 0citation268DownloadsMetricsTotal Citations0Total Downloads268Last 12 Months106Last 6 weeks7 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3162455083",
    "type": "editorial"
  },
  {
    "title": "Precise Correlation Extraction for IoT Fault Detection With Concurrent Activities",
    "doi": "https://doi.org/10.1145/3477025",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Gyeongmin Lee; Bongjun Kim; Seungbin Song; Changsu Kim; Jong Kim; Hanjun Kim",
    "corresponding_authors": "",
    "abstract": "In the Internet of Things (IoT) environment, detecting a faulty device is crucial to guarantee the reliable execution of IoT services. To detect a faulty device, existing schemes trace a series of events among IoT devices within a certain time window, extract correlations among them, and find a faulty device that violates the correlations. However, if a few users share the same IoT environment, since their concurrent activities make non-correlated devices react together in the same time window, the existing schemes fail to detect a faulty device without differentiating the concurrent activities. To correctly detect a faulty device in the multiple concurrent activities, this work proposes a new precise correlation extraction scheme, called PCoExtractor. Instead of using a time window, PCoExtractor continuously traces the events, removes unrelated device statuses that inconsistently react for the same activity, and constructs fine-grained correlations. Moreover, to increase the detection precision, this work newly defines a fine-grained correlation representation that reflects not only sensor values and functionalities of actuators but also their transitions and program states such as contexts. Compared to existing schemes, PCoExtractor detects and identifies 40.06% more faults for 4 IoT services with concurrent activities of 12 users while reducing 80.3% of detection and identification times.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3199389319",
    "type": "article"
  },
  {
    "title": "Declarative Power Sequencing",
    "doi": "https://doi.org/10.1145/3477039",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Jasmin Schult; Daniel Schwyn; Michael Giardino; David Cock; Reto Achermann; Timothy Roscoe",
    "corresponding_authors": "",
    "abstract": "Modern computer server systems are increasingly managed at a low level by baseboard management controllers (BMCs). BMCs are processors with access to the most critical parts of the platform, below the level of OS or hypervisor, including control over power delivery to every system component. Buggy or poorly designed BMC software not only poses a security threat to a machine, it can permanently render the hardware inoperative. Despite this, there is little published work on how to rigorously engineer the power management functionality of BMCs so as to prevent this happening. This article takes a first step toward putting BMC software on a sound footing by specifying the hardware environment and the constraints necessary for safe and correct operation. This is best accomplished through automation: correct-by-construction power control sequences can be efficiently generated from a simple, trustworthy model of the platform’s power tree that incorporates the sequencing requirements and safe voltage ranges of all components. We present both a modeling language for complex power-delivery networks and a tool to automatically generate safe, efficient power sequences for complex modern platforms. This not only increases the trustworthiness of a hitherto opaque yet critical element of platform firmware: regulator and chip power models are significantly simpler to produce than hand-written power sequences. This, combined with model reuse for common components, reduces both time and cost associated with platform bring-up for new hardware. We evaluate our tool using a new high-performance 2-socket server platform with &gt;100W per socket TDP, tight voltage limits and 25 distinct power regulators needing configuration, showing both fast (&lt;10s) tool runtime, and correct power sequencing of a live system.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3199460485",
    "type": "article"
  },
  {
    "title": "Federated Scheduling of Sporadic DAGs on Unrelated Multiprocessors",
    "doi": "https://doi.org/10.1145/3477018",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Petros Voudouris; Per Stenström; Risat Mahmud Pathan",
    "corresponding_authors": "",
    "abstract": "This paper presents a federated scheduling algorithm for implicit-deadline sporadic DAGs that execute on an unrelated heterogeneous multiprocessor platform. We consider a global work-conserving scheduler to execute a single DAG exclusively on a subset of the unrelated processors. Formal schedulability analysis to find the makespan of a DAG on its dedicated subset of the processors is proposed. The problem of determining each subset of dedicated unrelated processors for each DAG such that the DAG meets its deadline (i.e., designing the federated scheduling algorithm) is tackled by proposing a novel processors-to-task assignment heuristic using a new concept called processor value . Empirical evaluation is presented to show the effectiveness of our approach.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3199518438",
    "type": "article"
  },
  {
    "title": "Specification Guided Automated Synthesis of Feedback Controllers",
    "doi": "https://doi.org/10.1145/3477011",
    "publication_date": "2021-09-22",
    "publication_year": 2021,
    "authors": "Nikhil Kumar Singh; Indranil Saha",
    "corresponding_authors": "",
    "abstract": "The growing use of complex Cyber-Physical Systems (CPSs) in safety-critical applications has led to the demand for the automatic synthesis of robust feedback controllers that satisfy a given set of formal specifications. Controller synthesis from the high-level specification is an NP-Hard problem. We propose a heuristic-based automated technique that synthesizes feedback controllers guided by Signal Temporal Logic (STL) specifications. Our technique involves rigorous analysis of the traces generated by the closed-loop system, matrix decomposition, and an incremental multi-parameter tuning procedure. In case a controller cannot be found to satisfy all the specifications, we propose a technique for modifying the unsatisfiable specifications so that the controller synthesized for the satisfiable subset of specifications now also satisfies the modified specifications. We demonstrate our technique on eleven controllers used as standard closed-loop control system benchmarks, including complex controllers having multiple independent or nested control loops. Our experimental results establish that the proposed algorithm can automatically solve complex feedback controller synthesis problems within a few minutes.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3200972884",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on wireless health systems",
    "doi": "https://doi.org/10.1145/2485984.2485986",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Roozbeh Jafari; John Lach; Majid Sarrafzadeh; William Kaiser",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1970060472",
    "type": "article"
  },
  {
    "title": "Configuration and operation of networked control systems over heterogeneous WSANs",
    "doi": "https://doi.org/10.1145/2536747.2536756",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Pedro Furtado; José Cecílio",
    "corresponding_authors": "",
    "abstract": "There have been both research and commercial advances on applying Wireless Sensor and Actuator Networks (WSN) in industrial premises. These have cost advantages related to avoiding some cabled deployments. A possible architecture involves a Networked Control System (NCS) with many small WSN subnetworks, cabled nodes and computer servers (e.g., servers, control stations). In those systems individual sensor nodes can be programmed, as opposed to cabled analog systems. We investigate approaches for networked-wide configuration, where all nodes—cabled or WSN sensors—can be configured with simplicity from a single interface, instead of hand-coding or complex configurations of individual nodes. We propose an architecture and approach for configuration and operation. Previous related proposals on middleware involving WSNs suffer from two major limitations: they either program within an individual WSN or configure operation outside WSNs, wrapping data coming from WSN. They do not allow configuring WSN and non-WSN nodes for operation from a single interface. We discuss the architecture and propose the NCSWSN configuration and operation approach. We are applying this system in an industrial testbed, therefore we test the approach and also show user interfaces and results from the deployment.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1994224723",
    "type": "article"
  },
  {
    "title": "Joint variable partitioning and bank selection instruction optimization for partitioned memory architectures",
    "doi": "https://doi.org/10.1145/2442116.2442126",
    "publication_date": "2013-03-10",
    "publication_year": 2013,
    "authors": "Tiantian Liu; Chun Jason Xue; Minming Li",
    "corresponding_authors": "",
    "abstract": "About 55% of all CPUs sold in the world are 8-bit microcontrollers or microprocessors which can only access limited memory space without extending address buses. Partitioned memory with bank switching is a technique to increase memory size without extending address buses. Bank Selection Instructions (BSLs) need to be inserted into the original programs to modify the bank register to point to the desired banks. These BSLs introduce both code size and execution time overheads. In this paper, we partition variables into different banks and insert BSLs at different positions of programs so that the overheads can be minimized. Minimizing speed (execution time) overhead and minimizing space (code size) overhead are two objectives investigated in this paper. A multi-copy approach is also proposed to store multiple copies of several variables on different banks when the memory space allows. It takes the read/write properties of variables into consideration and achieves more BSL overhead reduction. Experiments show that the proposed algorithms can reduce BSL overheads effectively compared to state-of-the-art techniques.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1996727634",
    "type": "article"
  },
  {
    "title": "Models for characterizing noise based PCMOS circuits",
    "doi": "https://doi.org/10.1145/2536747.2536761",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Anshul Singh; Arindam Basu; Keck Voon Ling; Vincent J. Mooney",
    "corresponding_authors": "",
    "abstract": "Quick and accurate error-rate prediction of Probabilistic CMOS (PCMOS) circuits is crucial for their systematic design and performance evaluation. While still in the early stage of research, PCMOS has shown potential to drastically reduce energy consumption at a cost of increased errors. Recently, a methodology has been proposed which could predict the error rates of cascade structures of blocks in PCMOS. This methodology requires error rates of unique blocks to predict the error rates of multiblock cascade structures composed of these unique blocks. In this article we present a new model for characterization of probabilistic circuits/blocks and present a procedure to find and characterize unique circuits/blocks. Unlike prior approaches, our new model distinguishes distinct filtering effects per output, thereby improving prediction accuracy by an average of 95% over the prior art by Palem and coauthors. Furthermore, we show two models where our new model with three stages is 18% more accurate, on average, than our simpler two-stage model. We apply our proposed models to Ripple Carry Adders and Wallace Tree Multipliers and show that using our models, the methodology of cascade structures can predict error rates of PCMOS circuits with reasonable accuracy (within 9%) in PCMOS for uniform voltages as well as multiple voltages. Finally, our approach takes seconds of simulation time whereas using HSPICE would take days of simulation time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1997390755",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on on-chip and off-chip network architectures",
    "doi": "https://doi.org/10.1145/2485984.2485992",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "José Flich; Maurizio Palesi",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2014432156",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on rigorous embedded systems design",
    "doi": "https://doi.org/10.1145/2435227.2435237",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Joseph Sifakis; Lothar Thiele; Reinhard Wilhelm",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2016301102",
    "type": "article"
  },
  {
    "title": "Parallel programming patterns for multi-processor SoC",
    "doi": "https://doi.org/10.1145/2435227.2435243",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Pierre Paulin; Ali Özcan; Vincent Gagné; Bruno Lavigueur; Olivier Benny",
    "corresponding_authors": "",
    "abstract": "Efficient, scalable and productive parallel programming is a major challenge for exploiting the future multi-processor SoC platforms. This article presents the MultiFlex programming environment which has been developed to address this challenge. It is targeted for use on Platform 2012 , a scalable multi-processor fabric. The MultiFlex environment supports high-level simulation, iterative platform mapping, and includes tools for programming model aware debug, trace, visualization and analysis. This article focuses on the two classes of programming abstractions supported in MultiFlex. The first is a set of Parallel Programming Patterns (PPP) which offer a rich set of programming abstractions for implementing efficient data- and task-level parallel applications. The second is a Reactive Task Management (RTM) abstraction, which offers a lightweight C-based API to support dynamic dispatching of small grain tasks on tightly coupled parallel processing resources. The use of the MultiFlex native programming model is illustrated through the capture and mapping of two representative video applications. The first is a high-quality rescaling (HQR) application on a multi-processor platform. We present the details of the optimization process which was required for mapping the HQR application, for which the reference code requires 350 GIPS (giga instructions per second), onto a 16 processor cluster. Our results show that the parallel implementation using the PPP model offers almost linear acceleration with respect to the number of processing elements. The second application is a high-definition VC-1 decoder. For this application, we illustrate two different parallel programming model variants, one using PPPs, the other based on RTM. These two versions are mapped onto two variants of a homogeneous version of the Platform 2012 multi-core fabric.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2019507425",
    "type": "article"
  },
  {
    "title": "Fusing statecharts and java",
    "doi": "https://doi.org/10.1145/2435227.2435241",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Maria-Cristina Marinescu; César Sánchez",
    "corresponding_authors": "",
    "abstract": "This article presents FUSE, an approach for modeling and implementing embedded software components which starts from a main-stream programming language and brings some of the key concepts of Statecharts as first-class elements within this language. Our approach provides a unified programming environment which not only preserves some of the advantages of Statecharts' formal foundation but also directly supports features of object-orientation and strong typing. By specifying Statecharts directly in FUSE we eliminate the out-of-synch between the model and the generated code and we allow the tuning and debugging to be done within the same programming model. This article describes the main language constructs of FUSE and presents its semantics by translation into the Java programming language. We conclude by discussing extensions to the base language which enable the efficient static checking of program properties.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2034184652",
    "type": "article"
  },
  {
    "title": "Introduction to the special issue on application-specific processors",
    "doi": "https://doi.org/10.1145/2514641.2514642",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Philip Brisk; Tulika Mitra",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the special issue on application-specific processors Authors: Philip Brisk University of California, Riverside University of California, RiversideView Profile , Tulika Mitra National University of Singapore National University of SingaporeView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 13Issue 2Article No.: 15pp 1–3https://doi.org/10.1145/2514641.2514642Published:30 September 2013Publication History 0citation325DownloadsMetricsTotal Citations0Total Downloads325Last 12 Months2Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2054961477",
    "type": "article"
  },
  {
    "title": "Compiler-Supported Thread Management for Multithreaded Network Processors",
    "doi": "https://doi.org/10.1145/2043662.2043668",
    "publication_date": "2011-11-01",
    "publication_year": 2011,
    "authors": "Xiaotong Zhuang; Santosh Pande",
    "corresponding_authors": "",
    "abstract": "Traditionally, runtime management involving CPU sharing, real-time scheduling, etc., is provided by the runtime environment (typically an operating system) using hardware support such as timers and interrupts. However, due to stringent performance requirements on network processors, neither OS nor hardware mechanisms are typically feasible/available. Mapping packet processing tasks on network processors involves complex trade-offs to maximize parallelism and pipelining. Due to an increase in the size of the code store and complexity of application requirements, network processors are being programmed with heterogeneous threads that may execute code belonging to different tasks on a given micro-engine. Also, most network applications are streaming applications that are typically processed in a pipelined fashion. Thus, the tasks on different micro-engines are pipelined in such a way as to maximize the throughput. Tasks themselves could have different runtime performance demands. In this article, we focus on network processors on which hardware can only schedule threads in a round-robin fashion and no OS assistance is provided. We show that it is very difficult and inefficient for the programmer to meet the constraints of runtime management by coding them statically. Due to the infeasibility of hardware or OS solution (even in the near future), we undertake a compiler approach. We propose a complete compiler solution to automatically insert explicit context switch (ctx) instructions provided on the network processor such that the execution of threads is better manipulated at runtime to meet their constraints. Two approaches are presented that can control programs’ runtime behavior with different applicability and overheads. We show that it is feasible and also opens new application domains that would need heterogeneous thread programming. Such approaches would in general become important for multicore processors. Finally, our experiments show that the runtime constraints are enforced nearly ideally with minimal runtime degradation and small code growth.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2075746113",
    "type": "article"
  },
  {
    "title": "Introduction to Special Section on Probabilistic Embedded Computing",
    "doi": "https://doi.org/10.1145/2465787.2465788",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Christoph Kirsch; Vincent J. Mooney",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2133647401",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on LCTES'11",
    "doi": "https://doi.org/10.1145/2435227.2435234",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Bjorn De Sutter; Jan Vítek",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2134581128",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on ESTIMedia'12",
    "doi": "https://doi.org/10.1145/2435227.2435228",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Jian-Jia Chen; Maurizio Palesi",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2139087523",
    "type": "article"
  },
  {
    "title": "Flexible filters in stream programs",
    "doi": "https://doi.org/10.1145/2539036.2539041",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "Rebecca L. Collins; Luca P. Carloni",
    "corresponding_authors": "",
    "abstract": "The stream-processing model is a natural fit for multicore systems because it exposes the inherent locality and concurrency of a program and highlights its separable tasks for efficient parallel implementations. We present flexible filters , a load-balancing optimization technique for stream programs. Flexible filters utilize the programmability of the cores in order to improve the data-processing throughput of individual bottleneck tasks by “borrowing” resources from neighbors in the stream. Our technique is distributed and scalable because all runtime load-balancing decisions are based on point-to-point handshake signals exchanged between neighboring cores. Load balancing with flexible filters increases the system-level processing throughput of stream applications, particularly those with large dynamic variations in the computational load of their tasks. We empirically evaluate flexible filters in a homogeneous multicore environment over a suite of five real-word stream programs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2156036004",
    "type": "article"
  },
  {
    "title": "Latent space segmentation for mobile gait analysis",
    "doi": "https://doi.org/10.1145/2485984.2485989",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Aris Valtazanos; D. K. Arvind; Subramanian Ramamoorthy",
    "corresponding_authors": "",
    "abstract": "An unsupervised learning algorithm is presented for segmentation and evaluation of motion data from the on-body Orient wireless motion capture system for mobile gait analysis. The algorithm is model-free and operates on the latent space of the motion, by first aggregating all the sensor data into a single vector, and then modeling them on a low-dimensional manifold to perform segmentation. The proposed approach is contrasted to a basic, model-based algorithm, which operates directly on the joint angles computed by the Orient sensor devices. The latent space algorithm is shown to be capable of retrieving qualitative features of the motion even in the face of noisy or incomplete sensor readings.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2158508574",
    "type": "article"
  },
  {
    "title": "System-level memory management based on statistical variability compensation",
    "doi": null,
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Concepción Sanz Pineda; Ignácio Aguaded; Christian Tenllado; Manuel Prieto; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2527267458",
    "type": "article"
  },
  {
    "title": "Introduction to the special section on ESTIMedia'10",
    "doi": "https://doi.org/10.1145/2536747.2536748",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Naehyuck Chang; Jian-Jia Chen",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2917799960",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2501626",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Sea depth monitoring is a critical task for ensuring safe operation of harbors. Traditional schemes largely rely on labor-intensive work and expensive hardware. This study explores the possibility of deploying networked sensors on the surface of the sea,...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236303799",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2485984",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Stress is a growing problem in society and can cause musculoskeletal complaints. It would be useful to measure stress for prevention of stress-related health problems. An experiment is described in which EMG signals of the upper trapezius muscle were ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236842134",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2442116",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Earliest Deadline First (EDF) is the most widely studied optimal dynamic scheduling algorithm for uniprocessor real-time systems. In the existing literature, however, there is no complete exact analysis for EDF scheduling when both resource sharing and ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241128702",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2435227",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242857147",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2514641",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The field of modern control theory and the systems used to implement these controls have shown rapid development over the last 50 years. It was often the case that those developing control algorithms could assume the computing medium was solely ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244258944",
    "type": "paratext"
  },
  {
    "title": "Abstracts",
    "doi": "https://doi.org/10.1145/2485984.2499550",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Share on Abstracts: Online Supplements Volume 12, Number 1s Volume 12, Number 2sACM Transactions on Embedded Computing SystemsVolume 12Issue 4June 2013 Article No.: 112pp 1–22https://doi.org/10.1145/2485984.2499550Online:03 July 2013Publication History 0citation105DownloadsMetricsTotal Citations0Total Downloads105Last 12 Months1Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244972064",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2423636",
    "publication_date": "2013-02-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This study proposes an efficient localization scheme in wireless sensor networks. The proposed scheme utilizes mobile anchors and is based on ring overlapping. In a wireless sensor network, the nodes that know their locations are called reference nodes, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246610896",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2465787",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Well over a decade ago, many believed that an engine of growth driving the semiconductor and computing industries---captured nicely by Gordon Moore’s remarkable prophecy (Moore’s law)---was speeding towards a dangerous cliff-edge. Ranging from ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250436553",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1952522",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In order to eliminate the costs of proprietary systems and special purpose hardware, many real-time and embedded computing platforms are being built on commodity operating systems and generic hardware. Unfortunately, many such systems are ill-suited to ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251080463",
    "type": "paratext"
  },
  {
    "title": "A constraint programming approach for integrated spatial and temporal scheduling for clustered architectures",
    "doi": "https://doi.org/10.1145/2501626.2512470",
    "publication_date": "2013-08-01",
    "publication_year": 2013,
    "authors": "Mirza Omer Beg; Peter van Beek",
    "corresponding_authors": "",
    "abstract": "Many embedded processors use clustering to scale up instruction-level parallelism in a cost-effective manner. In a clustered architecture, the registers and functional units are partitioned into smaller units and clusters communicate through register-to-register copy operations. Texas Instruments, for example, has a series of architectures for embedded processors which are clustered. Such an architecture places a heavier burden on the compiler, which must now assign instructions to clusters (spatial scheduling), assign instructions to cycles (temporal scheduling), and schedule copy operations to move data between clusters. We consider instruction scheduling of local blocks of code on clustered architectures to improve performance. Scheduling for space and time is known to be a hard problem. Previous work has proposed greedy approaches based on list scheduling to simultaneously perform spatial and temporal scheduling and phased approaches based on first partitioning a block of code to do spatial assignment and then performing temporal scheduling. Greedy approaches risk making mistakes that are then costly to recover from, and partitioning approaches suffer from the well-known phase ordering problem. In this article, we present a constraint programming approach for scheduling instructions on clustered architectures. We employ a problem decomposition technique that solves spatial and temporal scheduling in an integrated manner. We analyze the effect of different hardware parameters—such as the number of clusters, issue-width, and intercluster communication cost—on application performance. We found that our approach was able to achieve an improvement of up to 26%, on average, over a state-of-the-art technique on superblocks from SPEC 2000 benchmarks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251606168",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2043662",
    "publication_date": "2011-11-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Modern embedded systems integrate more and more complex functionalities. At the same time, the semiconductor technology advances enable to increase the amount of hardware resources on a chip for the execution. Massively parallel embedded systems ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252354562",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2536747",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we present a flexible and extensible system-level MP-SoC design space exploration (DSE) infrastructure, called NASA. This highly modular framework uses well-defined interfaces to easily integrate different system-level simulation tools ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252423349",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2539036",
    "publication_date": "2013-12-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Today, mobile smartphones are expected to be able to run the same complex, algorithm-heavy, memory-intensive applications that were originally designed and coded for general-purpose processors. All the while, it is also expected that these mobile ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253782181",
    "type": "paratext"
  },
  {
    "title": "Introduction to the two special issues on memory",
    "doi": "https://doi.org/10.1145/581888.581890",
    "publication_date": "2002-11-01",
    "publication_year": 2002,
    "authors": "Bruce Jacob; Shuvra S. Bhattacharyya",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to the two special issues on memory Share on Authors: Bruce Jacob View Profile , Shuvra Bhattacharyya View Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 1Issue 1November 2002 pp 2–5https://doi.org/10.1145/581888.581890Online:01 November 2002Publication History 0citation861DownloadsMetricsTotal Citations0Total Downloads861Last 12 Months7Last 6 weeks3 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1995029114",
    "type": "article"
  },
  {
    "title": "Introduction to the inaugural issue",
    "doi": "https://doi.org/10.1145/581888.581889",
    "publication_date": "2002-11-01",
    "publication_year": 2002,
    "authors": "Wayne Wolf",
    "corresponding_authors": "Wayne Wolf",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2124681421",
    "type": "article"
  },
  {
    "title": "Pre- and postfabrication architecture exploration for partially reconfigurable VLIW processors",
    "doi": "https://doi.org/10.1145/1457255.1457259",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Anupam Chattopadhyay; Harold Ishebabi; X. Chen; Z. Rakosi; Kingshuk Karuri; David W. Kammler; Rainer Leupers; Gerd Ascheid; H. Meyr",
    "corresponding_authors": "",
    "abstract": "Modern application-specific instruction-set processors (ASIPs) face the daunting task of delivering high performance for a wide range of applications. For enhancing the performance, architectural features, for example, pipelining, VLIW, are often employed in ASIPs, leading to high design complexity. Integrated ASIP design environments, like template-based approaches and language-driven approaches, provide an answer to this growing design complexity. At the same time, increasing hardware design costs have motivated the processor designers to introduce high flexibility in the processor. Flexibility, in its most effective form, can be introduced to the ASIP by coupling a reconfigurable unit to the base processor. Because of its obvious benefits, several reconfigurable ASIPs (rASIPs) have been designed for years. This design paradigm gained momentum with the advent of coarse-grained FPGAs, where the lack of domain-specific performance common in general-purpose FPGAs are largely overcome by choosing application-dependent basic functional units. These rASIP designs lack a generic flow from high-level specification, resulting in intuitive design decisions and hard-to-retarget processor design tools. Although partial, template-based approaches for rASIP design is existent, a clear design methodology especially for the prefabrication architecture exploration is not present. In order to address this issue, a high-level specification and design methodology for partially reconfigurable VLIW processors is proposed in this article. To show the benefit of this approach, a commercial VLIW processor is used as the base architecture and two domains of applications are studied for potential performance gain.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W183562185",
    "type": "article"
  },
  {
    "title": "On Heuristic Solutions to the Simple Offset Assignment Problem in Address-Code Optimization",
    "doi": "https://doi.org/10.1145/2345770.2345775",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Hesham Shokry; Hatem M. El-Boghdadi",
    "corresponding_authors": "",
    "abstract": "The increasing demand for more functionality in embedded systems applications nowadays requires efficient generation of compact code for embedded DSP processors. Because such processors have highly irregular data-paths, compilers targeting those processors are challenged with the automatic generation of optimized code with competent quality comparable to hand-crafted code. A major issue in code-generation is to optimize the placement of program variables in ROM relative to each other so as to reduce the overhead instructions dedicated for address computations. Modern DSP processors are typically shipped with a feature called Address Generation Unit (AGU) that provides efficient address-generation instructions for accessing program variables. Compilers targeting those processors are expected to exploit the AGU to optimize variables assignment. This article focuses on one of the basic offset-assignment problems; the Simple Offset Assignment (SOA) problem, where the AGU has only one Address Register and no Modify Registers. The notion of Tie-Break Function, TBF, introduced by Leupers and Marwedel [1996], has been used to guide the placement of variables in memory. In this article, we introduce a more effective form of the TBF; the Effective Tie-Breaking Function, ETBF, and show that the ETBF is better at guiding the variables placement process. Underpinning ETBF is the fact that program variables are placed in memory in sequence, with each variable having only two neighbors. We applied our technique to randomly generated graphs as well as to real-world code from the OffsetStone testbench [2010]). In previous work [Ali et al. 2008], our technique showed up to 7% reduction in overhead when applied to randomly-generated problem instances. We report in this article on a further experiment of our technique on real-code from the Offsetstone testbench. Despite the substantial improvement our technique has achieved when applied to random problem instances, we found that it shows slight overhead reduction when applied to real-world instances in OffsetStone, which agrees with similar existing experiments. We analyze these results and show that the ETBF defaults to TBF.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1973368005",
    "type": "article"
  },
  {
    "title": "Instant Multiunit Resource Hardware Deadlock Detection Scheme for System-on-Chips",
    "doi": "https://doi.org/10.1145/2345770.2345780",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "John J. Lee; Xiang Xiao",
    "corresponding_authors": "",
    "abstract": "In this article, a brand new method of determining deadlock is presented. Most previous deadlock detection methods are algorithmic in the sense that they usually leverage some forms of Resource Allocation Graph (RAG) representations and then algorithms are devised to manipulate such representations in order to detect deadlock using information contained in the graph. Different from all previous methods, the proposed method actualizes the RAG with a digital circuit and uses it as a token-transmitting network. By supplying special input signals (tokens) to the network and observing the output tokens from the network, it is easier to identify which process nodes are reachable from each resource node in the graph. Using the reachability information, deadlock can be detected immediately. The time required to obtain the reachability information is determined by how fast the combinational circuit operates. Compared with previous algorithmic methods, the proposed deadlock detection can be deemed instant. We show that the proposed method is an order of magnitude faster than the previous fastest hardware mechanism and several orders of magnitude faster than traditional software-based algorithms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1982755028",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2331147.2331155",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Ani Napapetian; William Kaiser; Majid Sarrafzadeh",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1995620906",
    "type": "editorial"
  },
  {
    "title": "Power scalability in a mesh-connected reconfigurable architecture",
    "doi": "https://doi.org/10.1145/1596543.1596547",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Paul Beckett",
    "corresponding_authors": "Paul Beckett",
    "abstract": "We analyze power--area--performance trade-offs within a hypothetical mesh-connected reconfigurable architecture. A new analytic model relating area, power, and performance based on a simple VLSI complexity metric, is used to determine the behavior of some computing functions mapped to the platform. Although it might reasonably be expected that entirely local connectivity in the array would impose severe delay overheads, thus making performance--power trade-offs more difficult, it was found that the flexibility of the reconfigurable platform, in which logic and interconnect are (mostly) interchangeable, can result in compact layouts, which tends to offset the impact of the interconnect delay.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2000095533",
    "type": "article"
  },
  {
    "title": "Abstracts of Papers to appear in Special Supplemental Issue of TECS (v11, iSupplemental1)",
    "doi": "https://doi.org/10.1145/2220336.2220337",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "TECS Staff",
    "corresponding_authors": "TECS Staff",
    "abstract": "In order to speed up the publication process, we have begun to publish supplemental online-only issues. The following abstracts describe the articles in the first such issue, Vol. 11S(1). These articles are available in the Digital Library.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2011016235",
    "type": "article"
  },
  {
    "title": "Introduction to special section SCPS'09",
    "doi": "https://doi.org/10.1145/2362336.2362341",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Robert Dick; Shang Li; Nikil Dutt",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2011355054",
    "type": "article"
  },
  {
    "title": "Cross-layer customization for rapid and low-cost task preemption in multitasked embedded systems",
    "doi": "https://doi.org/10.1145/1457255.1457261",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "Xiangrong Zhou; П. П. Петров",
    "corresponding_authors": "",
    "abstract": "Preemptive multitasking is widely used in many low-cost and real-time embedded applications for its superior hardware utilization. The frequent and asynchronous context switches, however, require the preservation and restoration of the task state, thus resulting in a large number of memory transfer instructions. As a consequence, task responsiveness and application throughput can be significantly deteriorated. To address this problem we propose a cross-layer customization framework which through the close cooperation of compiler, OS, and hardware architecture achieves rapid and low-cost task switch. Application information extracted during compile-time regarding state liveness is exploited in order to preserve a minimal amount of task state on task preemption. We introduce two complementary techniques to implement the application-aware state preservation. The first technique utilizes compiler-generated custom routines which preserve/restore an extremely small live context at judiciously selected points in the application code. The second technique requires more sophisticated hardware support. It employs an OS-controlled register file mapping to achieve a rapid context switch. By mapping a small fraction of the register file in a single clock cycle, a context switch is achieved requiring no memory transfers for the majority of cases to preserve/restore the live state. The effect of aggressively replicated register files, where each task is given its own replica, is achieved with the hardware cost of only adding from 25% to 50% extra physical registers. Through the utilization of these novel mechanisms, a significant improvement on task response time is achieved as the context-switch cost is minimized.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2012430669",
    "type": "article"
  },
  {
    "title": "Adaptive Source-Level Data Assignment to Dual Memory Banks",
    "doi": "https://doi.org/10.1145/2180887.2180897",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Alastair Murray; Björn Franke",
    "corresponding_authors": "",
    "abstract": "Dual memory banks provide extra memory bandwidth to DSP applications and enable simultaneous access to two operands if the data is partitioned appropriately. Fully automated and compiler integrated approaches to data partitioning and memory bank assignment have, however, found little acceptance by DSP software developers. In this article we present a novel source-level approach that is more programmer friendly. Our scheme is based on soft graph coloring and highly adaptive heuristics generated by genetic programming. We have evaluated our scheme on an Analog Devices TigerSHARC TS-101 DSP and achieved speedups of up to 57% on 13 UTDSP benchmarks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2030317514",
    "type": "article"
  },
  {
    "title": "Call for papers",
    "doi": "https://doi.org/10.1145/1880050.1880065",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Montek Singh; Steven M. Nowick",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2035245217",
    "type": "paratext"
  },
  {
    "title": "On the Impact of Manufacturing Process Variations on the Lifetime of Sensor Networks",
    "doi": "https://doi.org/10.1145/2220336.2220345",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Siddharth Garg; Diana Marculescu",
    "corresponding_authors": "",
    "abstract": "The lifetime of individual nodes in a sensor network depends strongly on the leakage power of the nodes in idle state. With technology scaling, variability in leakage power dissipation of sensor nodes will cause increased variability in their lifetimes. In this article, we analyze how the lifetime variations of sensor nodes affect the performance of the sensor network as a whole. We demonstrate the use of the proposed framework to explore deployment cost versus performance trade-offs for sensor networks. Results indicate that up to 37% improvement in the critical lifetime of a sensor network can be obtained with a 20% increase in deployment cost.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2042901045",
    "type": "article"
  },
  {
    "title": "A packet-switched network architecture for reconfigurable computing",
    "doi": "https://doi.org/10.1145/1596532.1596539",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Scott Lloyd; Quinn Snell",
    "corresponding_authors": "",
    "abstract": "A packet-switched network architecture named Qnet and programming interface is presented that simplifies the integration of reconfigurable computing modules within a Field-Programmable Gate Array (FPGA). Qnet provides an abstraction layer to the designer of FPGA accelerator modules that hides the complexities of the system, while supporting a high degree of parallelism and performance. The architecture facilitates system design with pluggable, reusable modules. A network protocol is described that supports a three-party communication scheme between an initiator, a sender and a receiver. This protocol allows a master device to manage the state of other devices and the data flow within the system. An example using a high-level language is given. The Qnet architecture opens the computational power of FPGAs to computer scientists and software developers.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2062438251",
    "type": "article"
  },
  {
    "title": "Architecture Optimization of Application-Specific Implicit Instructions",
    "doi": "https://doi.org/10.1145/2331147.2331154",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Andrea Di Biagio; Giovanni Agosta; Martino Sykora; Cristina Silvano",
    "corresponding_authors": "",
    "abstract": "Dynamic configuration of application-specific implicit instructions has been proposed to better exploit the available parallelism at the instruction level in pipelined processors. The support of such implicit instruction issue-requires the pipeline to be extended with a trigger table that describes the instruction implicitly issued as a response to a value written into a triggering register by a triggering instruction (which may be an add or sub instruction). In this article, we explore the design optimization of the trigger table to maximize the number of instructions that can be implicitly issued while keeping the limited size of the trigger table. The concept of implicitly issued instruction has been formally defined by considering the inter-basic block analysis of control and data dependencies. A compilation tool chain has been developed to automatically identify the optimization opportunities, taking into account the constraints imposed by control and data dependencies as well as by architectural limitations. The proposed solutions have been applied to the case of a baseline scalar MIPS processor where, for the selected set of benchmarks (DSPStone and Mibench/automotive), we obtained an average speedup of 17%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2064781582",
    "type": "article"
  },
  {
    "title": "PICA",
    "doi": "https://doi.org/10.1145/2220336.2220338",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Jongeun Lee; Aviral Shrivastava",
    "corresponding_authors": "",
    "abstract": "Processor Idle Cycle Aggregation (PICA) is a promising approach for low-power execution of processors, in which small memory stalls are aggregated to create large ones, enabling profitable switch of the processor into low-power mode. We extend the previous approach in three dimensions. First we develop static analysis for the PICA technique and present optimal parameters for five common types of loops based on steady-state analysis. Second, to remedy the weakness of software-only control in varying environment, we enhance PICA with minimal hardware extension that ensures correct execution for any loops and parameters, thus greatly facilitating exploration-based parameter tuning. Third, we demonstrate that our PICA technique can be applied to certain types of nested loops with variable bounds, thus enhancing the applicability of PICA. We validate our analytical model against simulation-based optimization and also show, through our experiments on embedded application benchmarks, that our technique can be applied to a wide range of loops with average 20% energy reductions, compared to executions without PICA.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2066337812",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on SCOPES’09",
    "doi": "https://doi.org/10.1145/2180887.2180894",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Heiko Falk; Peter Marwedel",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to the Special Section on SCOPES’09 Guest Editors: Heiko Falk Ulm University, Germany Ulm University, GermanyView Profile , Peter Marwedel TU Dortmund, Germany TU Dortmund, GermanyView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 11SIssue 1Article No.: 17pp 1–3https://doi.org/10.1145/2180887.2180894Published:01 June 2012Publication History 0citation126DownloadsMetricsTotal Citations0Total Downloads126Last 12 Months1Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2069425035",
    "type": "article"
  },
  {
    "title": "Guest editorial CAPA'08 Configurable computing",
    "doi": "https://doi.org/10.1145/1596543.1596544",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Toomas P. Plaks; Neil Bergmann; Bernard Pottier",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest editorial CAPA'08 Configurable computing: Configuring algorithms, processes, and architecture Issue II: Configuring hardware architecture Editors: Dr. Toomas P. Plaks Reading University, UK Reading University, UKView Profile , Neil Bergmann Queensland University, Australia Queensland University, AustraliaView Profile , Bernard Pottier University of Bretagne, France University of Bretagne, FranceView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 9Issue 2Article No.: 10pp 1–3https://doi.org/10.1145/1596543.1596544Published:29 October 2009Publication History 0citation248DownloadsMetricsTotal Citations0Total Downloads248Last 12 Months3Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2079754322",
    "type": "editorial"
  },
  {
    "title": "Introduction to special section ESTIMedia'09",
    "doi": "https://doi.org/10.1145/2362336.2362337",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Andy D. Pimentel; Naehyuck Chang; Mladen Bereković",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2092789062",
    "type": "article"
  },
  {
    "title": "A robust seamless communication architecture for next-generation mobile terminals on multi-CPU SoCs",
    "doi": "https://doi.org/10.1145/1698772.1698777",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "Hiroaki Inoue; Junji Sakai; Masato Edahiro",
    "corresponding_authors": "",
    "abstract": "We propose a robust seamless communication architecture that enables legacy mobile terminal software designed for single-CPU processors to be run on multi-CPU processors without any software modifications. This architecture features two new technologies: proxy processes, which help achieve the design of its user-level system-call hooking and a robust design method, which reduces bandwidth variation by systematic parameter optimization. Our evaluations confirmed that this architecture achieves fundamental features with satisfactory performance, that we have succeeded in getting actual mobile terminal software to run on three CPUs without modifying the software, and that the robust design method reduces bandwidth variation by 21%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2095511455",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2331147.2331148",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Toomas P. Plaks",
    "corresponding_authors": "Toomas P. Plaks",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2126094169",
    "type": "editorial"
  },
  {
    "title": "Integrating Memory Optimization with Mapping Algorithms for Multi-Processors System-on-Chip",
    "doi": "https://doi.org/10.1145/2345770.2345776",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "B. Girodias; Luiza Gheorghe Iugan; Youcef Bouchebaba; Gabriela Nicolescu; El Mostapha Abouhamid; M. Langevin; Pierre Paulin",
    "corresponding_authors": "",
    "abstract": "Due to their great ability to parallelize at a very high integration level, Multi-Processors Systems-on-Chip (MPSoCs) are good candidates for systems and applications such as multimedia. Memory is becoming a key player for significant improvements in these applications (power, performance and area). The large amount of data manipulated by these applications requires high-capacity computing and memory. Lately, new programming models have been introduced. This leads to the need of new optimization and mapping techniques suitable for embedded systems and their programming models. This article presents novel approaches for combining memory optimization with mapping of data-driven applications while considering anti-dependence conflicts. Two different approaches are studied and integrated with existing mapping algorithms. The first approach (based on heuristic algorithms) keeps the graph transformation for memory optimization stage from the mapping stage and enables their combination in a design flow. The second approach (based on evolutionary algorithms) combines these two stages and integrates them in a unique stage. Some significant improvements are obtained for memory gain, communication load and physical links.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2131138471",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1880050.1880051",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Twan Basten; Rolf Ernst",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Editorial: Model-driven embedded-system design Editors: Twan Basten Embedded Systems Institute, Netherlands, Eindhoven University of Technology, Netherlands Embedded Systems Institute, Netherlands, Eindhoven University of Technology, NetherlandsView Profile , Rolf Ernst Technische Universität Braunschweig, Germany Technische Universität Braunschweig, GermanyView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 10Issue 2Article No.: 15pp 1–4https://doi.org/10.1145/1880050.1880051Published:07 January 2011Publication History 0citation572DownloadsMetricsTotal Citations0Total Downloads572Last 12 Months10Last 6 weeks4 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2154714499",
    "type": "editorial"
  },
  {
    "title": "Storage Optimization through Offset Assignment with Variable Coalescing",
    "doi": "https://doi.org/10.1145/2180887.2180893",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "Hassan Salamy; J. Ramanujam",
    "corresponding_authors": "",
    "abstract": "Most modern digital signal processors (DSPs) provide multiple address registers and a dedicated address generation unit (AGU) which performs address generation in parallel to instruction execution. There is no address computation overhead if the next address is within the auto-modify range. A careful placement of variables in memory is utilized to decrease the number of address arithmetic instructions and thus to generate compact and efficient code. The simple offset assignment (SOA) problem concerns the layout of variables for machines with one address register and the general offset assignment (GOA) deals with multiple address registers. Both these problems assume that each variable needs to be allocated for the entire duration of a program. Both SOA and GOA are NP-complete. In this article, we present effective heuristics for the simple and the general offset assignment problems with variable coalescing where two or more non-interfering variables can be mapped into the same memory location. Results on several benchmarks show the significant improvement of our proposed heuristics compared to other heuristics in the literature.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2162740404",
    "type": "article"
  },
  {
    "title": "Multi-Core Reconfigurable Computing for Advanced Video Coding",
    "doi": null,
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "Anand Paul; Jhing-Fa Wang; Jar‐Ferr Yang",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2241439628",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2146417",
    "publication_date": "2012-03-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Traffic shaping is a well-known technique in the area of networking and is proven to reduce global buffer requirements and end-to-end delays in networked systems. Due to these properties, shapers also play an increasingly important role in the design of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230517666",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1596532",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article explores methods to reconfigure infinite impulse response (IIR) filters in processes that utilize computer resource management. A high-performance mode uses a full-length IIR filter, while low resources or a desire to conserve power ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236027568",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1509288",
    "publication_date": "2009-04-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236134226",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1721695",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Online memory compression is a technology that increases the amount of memory available to applications by dynamically compressing and decompressing their working datasets on demand. It has proven extremely useful in embedded systems with tight physical ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237118936",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1457255",
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Reducing the power consumption of computing devices has gained a lot of attention recently. Many research works have focused on reducing power consumption in the off-chip buses as they consume a significant amount of total power. Since the bus power ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237705923",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2362336",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Sub-50nm CMOS technologies are affected by significant variability, which causes power and performance variations among nominally similar cores in MPSoC platforms. This undesired heterogeneity threatens execution predictability and energy efficiency. We ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243011843",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1596543",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Emerging embedded applications are based on evolving standards (e.g., MPEG2/4, H.264/265, IEEE802.11a/b/g/n). Since most of these applications run on handheld devices, there is an increasing need for a single chip solution that can dynamically ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243565281",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2331147",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Computational load of motion estimation in advanced video coding (AVC) standard is significantly high and even worse for HDTV and super-resolution sequences. In this article, a video processing algorithm is dynamically mapped onto a new parallel ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245638423",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1880050",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246014880",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1550987",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Publisher Note: This Guest Editorial by Li and Pande describes a number of related articles originally intended as a special issue but which were published in earlier issues as follows:",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247695211",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2220336",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In order to speed up the publication process, we have begun to publish supplemental online-only issues. The following abstracts describe the articles in the first such issue, Vol. 11S(1). These articles are available in the Digital Library.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250811451",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1698772",
    "publication_date": "2010-02-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The Dynamic Voltage Scaling (DVS) technique has been widely studied for energy-constrained real-time systems; however, its application to control systems has not been studied in a variety of aspects. This article presents a novel method to ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251709760",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2180887",
    "publication_date": "2012-06-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We propose a performance analysis framework for adaptive real-time synchronous data flow streaming applications on runtime reconfigurable FPGAs. As the main contribution, we present a constraint based approach to capture both streaming application ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254580707",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2345770",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Many techniques have been developed recently for establishing pairwise keys in sensor networks. However, some of them are vulnerable to a few compromised sensor nodes, while others could involve expensive protocols for establishing keys. This article ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254990835",
    "type": "paratext"
  },
  {
    "title": "Introduction to embedded systems week 2006 special issue",
    "doi": "https://doi.org/10.1145/1331331.1331332",
    "publication_date": "2008-01-29",
    "publication_year": 2008,
    "authors": "Soonhoi Ha; Ki‐Young Choi; Taewhan Kim; Krisztián Flautner; Sang-Lyul Min; Wang Yi",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to embedded systems week 2006 special issue Editors: Soonhoi Ha Seoul National University Seoul National UniversityView Profile , Kiyoung Choi Seoul National University Seoul National UniversityView Profile , Taewhan Kim Seoul National University Seoul National UniversityView Profile , Krisztian Flautner ARM Ltd. U.K. ARM Ltd. U.K.View Profile , Sanglyul Min Seoul National University Seoul National UniversityView Profile , Wang Yi Uppsala University Uppsala UniversityView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 7Issue 2Article No.: 8pp 1–3https://doi.org/10.1145/1331331.1331332Published:29 January 2008Publication History 0citation445DownloadsMetricsTotal Citations0Total Downloads445Last 12 Months3Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2002013468",
    "type": "article"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/1234675.1234676",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Henk Schepers",
    "corresponding_authors": "Henk Schepers",
    "abstract": "editorial Free Access Share on Guest editorial: Introduction to the special issue on software and compilers for embedded systems Author: Henk Schepers Royal Philips Electronics Royal Philips ElectronicsView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 6Issue 2May 2007 pp 9–eshttps://doi.org/10.1145/1234675.1234676Published:01 May 2007Publication History 0citation409DownloadsMetricsTotal Citations0Total Downloads409Last 12 Months6Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2051349029",
    "type": "editorial"
  },
  {
    "title": "Introduction to the special LCTES'05 issue",
    "doi": "https://doi.org/10.1145/1274858.1274859",
    "publication_date": "2007-09-01",
    "publication_year": 2007,
    "authors": "Rajiv Gupta; Yunheung Paek",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2076117836",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1376804.1376805",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "Fabiano Hessel; Kenneth B. Kent; Dionisios Pnevmatikatos",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Editorial: Embedded systems—new challenges and future directions Editors: Fabiano Hessell PUCRS, Brazil PUCRS, BrazilView Profile , Kenneth Kent University New Brunswick, Canada University New Brunswick, CanadaView Profile , Dionisios Pnevmatikatos Tech. University of Crete, Greece Tech. University of Crete, GreeceView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 7Issue 4July 2008 Article No.: 37pp 1–3https://doi.org/10.1145/1376804.1376805Published:01 August 2008Publication History 0citation802DownloadsMetricsTotal Citations0Total Downloads802Last 12 Months24Last 6 weeks4 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2114774139",
    "type": "editorial"
  },
  {
    "title": "Message from the Guest Editors",
    "doi": "https://doi.org/10.1145/3037413",
    "publication_date": "2017-02-03",
    "publication_year": 2017,
    "authors": "S. Haar; Roland Meyer",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2586120200",
    "type": "article"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/3041038",
    "publication_date": "2017-03-06",
    "publication_year": 2017,
    "authors": "Sebastian Fischmeister; Jason Xue",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2591955391",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3043965",
    "publication_date": "2017-03-06",
    "publication_year": 2017,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2594493947",
    "type": "editorial"
  },
  {
    "title": "Guest Editorial for ACM TECS Special Issue on Effective Divide-and-Conquer, Incremental, or Distributed Mechanisms of Embedded Designs for Extremely Big Data in Large-Scale Devices",
    "doi": "https://doi.org/10.1145/3068457",
    "publication_date": "2017-04-28",
    "publication_year": 2017,
    "authors": "Bo‐Wei Chen; Wen Ji; Li Zhu",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2607737973",
    "type": "editorial"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/3075563",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Jimson Mathew; Rajat Subhra Chakraborty; Prof. Dhiraj K. Pradhan",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2619870069",
    "type": "editorial"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/3065713",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Marilyn Wolf; Jason Xue",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2619888371",
    "type": "editorial"
  },
  {
    "title": "Exploiting Stable Data Dependency in Stream Processing Acceleration on FPGAs",
    "doi": "https://doi.org/10.1145/3092950",
    "publication_date": "2017-07-13",
    "publication_year": 2017,
    "authors": "Yuliang Sun; Lanjun Wang; Chen Wang; Yu Wang",
    "corresponding_authors": "",
    "abstract": "With the unique feature of fine-grained parallelism, field-programmable gate arrays (FPGAs) show great potential for streaming algorithm acceleration. However, the lack of a design framework, restrictions on FPGAs, and ineffective tools impede the utilization of FPGAs in practice. In this study, we provide a design paradigm to support streaming algorithm acceleration on FPGAs. We first propose an abstract model to describe streaming algorithms with homogeneous sub-functions (HSF) and stable data dependency (SDD), which we call the HSF-SDD model. Using this model, we then develop an FPGA framework, PE-Ring, that has the advantages of (1) fully exploiting algorithm parallelism to achieve high performance, (2) leveraging block RAM to serve large scale parameters, and (3) enabling flexible parameter adjustments. Based on the proposed model and framework, we finally implement a specific converter to generate the register-transfer level representation of the PE-Ring. Experimental results show that our method outperforms ordinary FPGA design tools by one to two orders of magnitude. Experiments also demonstrate the scalability of the PE-Ring.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2735827543",
    "type": "article"
  },
  {
    "title": "A DFA-Resistant and Masked PRESENT with Area Optimization for RFID Applications",
    "doi": "https://doi.org/10.1145/3035543",
    "publication_date": "2017-07-28",
    "publication_year": 2017,
    "authors": "Yi Wang; Yajun Ha",
    "corresponding_authors": "",
    "abstract": "Radio-Frequency Identification (RFID) tag-based applications are usually resource constrained and security sensitive. However, only about 2,000 gate equivalents in a tag can be budgeted for implementing security components [27]. This requires not only lightweight cryptographic algorithms such as PRESENT (around 1,000 gate equivalents) but also lightweight protections against modern Side Channel Attacks (SCAs). With this budget, the first-order masking and fault detection are two suitable countermeasures to be developed for PRESENT. However, if both countermeasures are applied without any optimization, it will significantly exceed the given area budget. In this work, we optimize area to include both countermeasures to maximize the security for PRESENT within this RFID area budget. The most area-consuming parts of the proposed design are the masked S-boxes and the inverse masked S-boxes. To optimize the area, we have deduced a computational relationship between these two parts, which enables us to reuse the hardware resource of the masked S-boxes to implement the inverse masked S-boxes. The proposed design takes up only 2,376 gates with UMC 65nm CMOS technology. Compared with the unoptimized design, our implementation reduces the overall area by 28.45%. We have tested the effectiveness of the first-order Differential Power Analysis (DPA) and Differential Fault Analysis (DFA) -resistant countermeasures. Experimental results show that we have enhanced the SCA resistance of our PRESENT implementation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2740228706",
    "type": "article"
  },
  {
    "title": "Guest Editorial for ACM TECS",
    "doi": "https://doi.org/10.1145/3127494",
    "publication_date": "2017-08-29",
    "publication_year": 2017,
    "authors": "Jiming Chen; Yu Gu; Gil Zussman",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2753045697",
    "type": "editorial"
  },
  {
    "title": "Transmission Adaptation for Battery-Free Relaying",
    "doi": "https://doi.org/10.1145/3055513",
    "publication_date": "2017-10-24",
    "publication_year": 2017,
    "authors": "Zejue Wang; Hongjia Li; Dan Hu; Song Ci",
    "corresponding_authors": "",
    "abstract": "Energy harvesting (EH)–enabled relaying has attracted considerable attention as an effective way to prolong the operation time of energy-constrained networks and extend coverage beside desired survivability and rate of transmission. In related literature, the Harvest-Store-Use (HSU) model is usually utilized to describe the energy flow behavior of the EH system. However, the half-duplex (HD) constraint of HSU that harvested energy can only be used after being temporally stored in energy buffer may reduce effective transmission time. Thus, we first construct the full-duplex (FD) energy flow behavior model of the EH system where the harvested energy can be tuned to power load and being stored simultaneously. The FD model is then proved to be equivalent with the HSU model when time interval is small enough. Considering some key physical variabilities, for example, the wireless channel and the amount of harvested energy, the transmission adaptation problem for multiple relays embedded with FD EH systems is formulated with the objective to improve the utilization of the harvested energy. We tackle the problem by using a centralized optimization algorithm by jointly tuning the factors, including power control for source and relay nodes, relay selection and dynamic switching among four relay transmission mode, namely HD amplify-and-forward (AF), HD decode-and-forward (DF), FD AF, and FD DF. The centralized optimization algorithm is proposed on the basis of dual decomposition and serves as a benchmark. To enable relays to individually make their own decisions, a distributed algorithm with relatively higher complexity is given by using consensus optimization in conjunction with the alternating direction method of multipliers, and a sub-optimal algorithm with low complexity is provided. The proposed algorithms are shown to have good performance via simulations for a range of different EH rates and prediction errors.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2765183545",
    "type": "article"
  },
  {
    "title": "Improving Write Performance and Extending Endurance of Object-Based NAND Flash Devices",
    "doi": "https://doi.org/10.1145/3105924",
    "publication_date": "2017-11-14",
    "publication_year": 2017,
    "authors": "Jie Guo; Chuhan Min; Tao Cai; Yiran Chen",
    "corresponding_authors": "",
    "abstract": "Write amplification is a major cause of performance and endurance degradations in NAND flash-based storage systems. In an object-based NAND flash device (ONFD), two causes of write amplification are onode partial update and cascading update. Here, onode is a type of small-sized object metadata, and multiple onodes are stored in one NAND flash page. Updating one onode invokes partial page update (i.e., onode partial update), incurring unnecessary migration of the un-updated data. Cascading update denotes updating object metadata in a cascading manner due to object data update or migration. Although there are only several bytes that need to be updated in the object metadata, one or more pages have to be re-written accordingly. In this work, we propose a system design to alleviate the write amplification issue in the object-based NAND flash device. The proposed design includes (1) a multi-level garbage collection technique to minimize unnecessary data migration incurred by onode partial update and (2) a B+ table tree, Semantics-Aware Flexible (SAF) data layout, and selective cache design to reduce the write operations associated with cascading update. To guarantee system consistency, we also propose a power failure handling technique. Experiment results show that our proposed design can achieve up to 20% write reduction compared to the best states of the art.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2770411362",
    "type": "article"
  },
  {
    "title": "Guest Editorial for the Special Issue of ESWEEK 2016",
    "doi": "https://doi.org/10.1145/3152097",
    "publication_date": "2017-12-08",
    "publication_year": 2017,
    "authors": "Petru Eles; Jörg Henkel",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Guest Editorial for the Special Issue of ESWEEK 2016 Editors: Petru Eles View Profile , Jörg Henkel View Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 17Issue 1January 2018 Article No.: 14pp 1–3https://doi.org/10.1145/3152097Published:08 December 2017Publication History 0citation174DownloadsMetricsTotal Citations0Total Downloads174Last 12 Months14Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2771062671",
    "type": "editorial"
  },
  {
    "title": "Timestamp Temporal Logic (TTL) for Time Testing of Cyber-Physical Systems",
    "doi": "https://doi.org/10.1002/https://dx.doi.org/10.1145/3126510",
    "publication_date": "2017-09-27",
    "publication_year": 2017,
    "authors": "Mohammadreza Mehrabian; Mohammad Khayatian; Aviral Shrivastava; John C. Eidson; Patricia Derler; Hugo A. Andrade; Ya-Shian Li-Baboud; Edward Griffor; Marc A. Weiss; Kevin Stanton",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2796638921",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1331331",
    "publication_date": "2008-02-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Real-time multimedia applications are increasingly being mapped onto MPSoC (multiprocessor system-on-chip) platforms containing hardware--software IPs (intellectual property), along with a library of common scheduling policies such as EDF, RM. The ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230194714",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1376804",
    "publication_date": "2008-07-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, a novel FTL (flash translation layer) architecture is proposed for NAND flash-based applications such as MP3 players, DSCs (digital still cameras) and SSDs (solid-state drives). Although the basic function of an FTL is to translate a ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234563408",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3092956",
    "publication_date": "2017-09-15",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Soft error is one of the most important design concerns in modern embedded systems with aggressive technology scaling. Among various microarchitectural components in a processor, cache is the most susceptible component to soft errors. Error detection ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235842424",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3072970",
    "publication_date": "2017-07-07",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This work is motivated by a general question: can micro-scale energy-harvesting techniques be exploited to support low-cost standard security solutions on resource-constrained devices? We focus on guaranteeing integrity and authentication in Internet of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237073921",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1210268",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240351389",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1234675",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Embedded systems are often constrained in terms of both code size and execution time, because of a limited amount of available memory and real-time nature of applications. A dual instruction set processor, which supports a reduced instruction set (16 ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240535130",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1457246",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242267565",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3025020",
    "publication_date": "2017-04-14",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244487516",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1347375",
    "publication_date": "2008-04-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Automatic generation of a controller implementation from a synchronous reactive model is among the best practices for software development in the automotive and aeronautics industry, because of the possibility of simulation, model checking, and error-...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254444482",
    "type": "paratext"
  },
  {
    "title": "Introduction to the Special Issue on Domain-Specific System-on-Chip Architectures and Run-Time Management Techniques",
    "doi": "https://doi.org/10.1145/3567834",
    "publication_date": "2023-01-24",
    "publication_year": 2023,
    "authors": "Ümit Y. Ogras; Radu Mărculescu; Trevor Mudge; Michael Kishinevsky",
    "corresponding_authors": "",
    "abstract": "introduction Introduction to the Special Issue on Domain-Specific System-on-Chip Architectures and Run-Time Management Techniques Authors: Umit Y. Ogras University of Wisconsin University of WisconsinView Profile , Radu Marculescu University of Texas University of TexasView Profile , Trevor N. Mudge University of Michigan University of MichiganView Profile , Michael Kishinevsky Intel Corporation Intel CorporationView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 22Issue 2Article No.: 27pp 1–3https://doi.org/10.1145/3567834Published:24 January 2023Publication History 0citation78DownloadsMetricsTotal Citations0Total Downloads78Last 12 Months78Last 6 weeks20 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4317881072",
    "type": "article"
  },
  {
    "title": "A Multi-tenant Key-value SSD with Secondary Index for Search Query Processing and Analysis",
    "doi": "https://doi.org/10.1145/3590153",
    "publication_date": "2023-04-11",
    "publication_year": 2023,
    "authors": "Donghyun Min; Kihyun Kim; Chaewon Moon; Awais Khan; Seungjin Lee; Changhwan Yun; Woosuk Chung; Youngjae Kim",
    "corresponding_authors": "",
    "abstract": "Key-value SSDs (KVSSDs) introduced so far are limited in their use as an alternative to the key-value store running on the host due to the following technical limitations. First, they were designed only for a single tenant, limiting the use of multiple tenants. Second, they mainly focused on designing indexes for primary key-based searches, without supporting various queries using a combination of primary key and non-primary attribute-based searches. This article proposes Cerberus , a Log Structured Merged (LSM) tree-based KVSSD armed with (1) namespace and performance isolation for multiple tenants in a multi-tenant environment and (2) capability for processing non-primary attribute-based search queries. Specifically, Cerberus identifies the tenant’s namespace and splits a single large LSM-tree into namespace-specific LSM-tree indexes for tenants. Cerberus also manages secondary LSM-tree indexes to enable non-primary attribute-based data access and fast search query processing. With the SSD-internal CPU/DRAM resources, Cerberus supports non-primary attribute-based search queries and handles complex queries that are combined with search and computing operations. We prototyped Cerberus on the Cosmos+ OpenSSD platform. When there are multiple tenants, Cerberus exhibits up to 2.9× higher read throughput and negligible write overhead compared to existing KVSSD. Cerberus also shows lower latency by up to 9.31× for non-primary attribute-based queries.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4364361809",
    "type": "article"
  },
  {
    "title": "ACM TECS Special Issue on Embedded System Security Tutorials",
    "doi": "https://doi.org/10.1145/3594872",
    "publication_date": "2023-05-31",
    "publication_year": 2023,
    "authors": "Aviral Shrivastava; Jian-Jia Chen; Akash Kumar; Anup Das",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4378981678",
    "type": "article"
  },
  {
    "title": "AMP: Total Variation Reduction for Lossless Compression via Approximate Median-based Preconditioning",
    "doi": "https://doi.org/10.1145/3605359",
    "publication_date": "2023-06-19",
    "publication_year": 2023,
    "authors": "Fenfang Li; Huizhang Luo; Junqi Wang; Yida Li; Zhuo Tang; Kenli Li",
    "corresponding_authors": "",
    "abstract": "With the increasing scale of cloud computing applications of next-generation embedded systems, a major challenge that domain scientists are facing is how to efficiently store and analyze the vast volume of output data. Compression can reduce the amount of data that needs to be transferred and stored. However, most of the large datasets are in floating-point format, which exhibits high entropy. As a result, existing lossless compressors cannot provide enough performance for such applications. To address this problem, we propose a total variation reduction method for improving the compression ratio of lossless compressors (namely, FPC + and FPZIP + ), which employs a median-based hyperplane to precondition the data. In particular, we first try to exploit the space-filling curve (SFC), a well-known technique to preserve data locality for a multi-dimensional dataset. We show and explain why a raw SFC, such as Hilbert and Z-order curves, cannot improve the compression ratio. Then, we explore the opportunity and theoretical feasibility of the proposed total variation reduction-based algorithm. The experiment results show the effectiveness of the proposed method. The compression ratios are improved up to 48.2% (20.6% on average) for FPZIP and 42.4% (18.4% on average) for FPC. Moreover, through observing the time composition of the proposed method, it is found that the median finding holds a high percentage of the execution time. Hence, we further introduce an approximate median finding algorithm, providing a linear-time overhead reduction scheme. The experiment results clearly demonstrate that this algorithm reduces execution time by an average of 56.7% and 40.7% compared to FPC + and FPZIP + , respectively.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4381163907",
    "type": "article"
  },
  {
    "title": "Special Issue: “Approximation at the Edge”",
    "doi": "https://doi.org/10.1145/3605757",
    "publication_date": "2023-06-22",
    "publication_year": 2023,
    "authors": "Alberto Bosio; Lara Dolecek; Alexandra Kourfali; Sri Parameswaran; Alessandro Savino",
    "corresponding_authors": "",
    "abstract": "introduction Share on Special Issue: “Approximation at the Edge” Authors: Alberto Bosio University of Lyon, ECL, INSA Lyon, CNRS, UCBL, CPE Lyon, INL, UMR5270, France University of Lyon, ECL, INSA Lyon, CNRS, UCBL, CPE Lyon, INL, UMR5270, France 0000-0001-6116-7339View Profile , Lara Dolecek Department of Electrical and Computer Engineering, University of California at Los Angeles, Los Angeles, CA, USA Department of Electrical and Computer Engineering, University of California at Los Angeles, Los Angeles, CA, USA 0000-0003-3736-4345View Profile , Alexandra Kourfali University of Stuttgart, ITI, D-70569 Stuttgart, Germany University of Stuttgart, ITI, D-70569 Stuttgart, Germany 0000-0003-3430-1007View Profile , Sri Parameswaran School of Electrical and Information Engineering, University of Sydney, NSW, Australia School of Electrical and Information Engineering, University of Sydney, NSW, Australia 0000-0003-0435-9080View Profile , Alessandro Savino Politecnico di Torino, Dept. of Control and Computer Engineering, Italy Politecnico di Torino, Dept. of Control and Computer Engineering, Italy 0000-0002-1445-4877View Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 22Issue 4Article No.: 72pp 1–4https://doi.org/10.1145/3605757Published:24 July 2023Publication History 0citation76DownloadsMetricsTotal Citations0Total Downloads76Last 12 Months76Last 6 weeks13 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4381485956",
    "type": "article"
  },
  {
    "title": "Analog In-memory Circuit Design of Polynomial Multiplication for Lattice Cipher Acceleration Application",
    "doi": "https://doi.org/10.1145/3605891",
    "publication_date": "2023-06-26",
    "publication_year": 2023,
    "authors": "Sichun Du; Jun Li; Chen Sun; Pingdan Xiao; Qinghui Hong; Jiliang Zhang",
    "corresponding_authors": "",
    "abstract": "As the core operation of lattice cipher, large-scale polynomial multiplication is the biggest computational bottleneck in its realization process. How to quickly calculate polynomial multiplication under resource constraints has become an urgent problem to be solved in the hardware implementation of lattice ciphers. Therefore, an analog in-memory circuit for fast polynomial multiplication calculation is proposed. First, an in-memory computing circuit for Discrete Fourier Transform and Inverse Discrete Fourier Transform based on memristor array is designed. On this basis, a fully analog circuit that can realize polynomial multiplication in one step is designed. Compared with traditional hardware implementation, the in-memory calculation method used in this article decreases the calculation time of polynomial multiplication to the microsecond level, which greatly improves the speed of lattice cipher encryption and decryption. For the specific examples in this article, PSPICE simulation shows that the average accuracy of the calculation result is above 99.90%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4382024040",
    "type": "article"
  },
  {
    "title": "Hercules: Enabling Atomic Durability for Persistent Memory with Transient Persistence Domain",
    "doi": "https://doi.org/10.1145/3607473",
    "publication_date": "2023-07-06",
    "publication_year": 2023,
    "authors": "Chongnan Ye; Meng Chen; Qisheng Jiang; Chundong Wang",
    "corresponding_authors": "",
    "abstract": "Persistent memory (pmem) products bring the persistence domain up to the memory level. Intel recently introduced the eADR feature that guarantees to flush data buffered in CPU cache to pmem on a power outage, thereby making the CPU cache a transient persistence domain . Researchers have explored how to enable the atomic durability for applications’ in-pmem data. In this paper, we exploit the eADR-supported CPU cache to do so. A modified cache line, until written back to pmem, is a natural redo log copy of the in-pmem data. However, a write-back due to cache replacement or eADR on a crash overwrites the original copy. We accordingly develop Hercules, a hardware logging design for the transaction-level atomic durability, with supportive components installed in CPU cache, memory controller (MC), and pmem. When a transaction commits, Hercules commits on-chip its data staying in cache lines. For cache lines evicted before the commit, Hercules asks the MC to redirect and persist them into in-pmem log entries and commits them off-chip upon committing the transaction. Hercules lazily conducts pmem writes only for cache replacements at runtime. On a crash, Hercules saves metadata and data for active transactions into pmem for recovery. Experiments show that, by using CPU cache for both buffering and logging, Hercules yields much higher throughput and incurs significantly fewer pmem writes than state-of-the-art designs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4383342512",
    "type": "article"
  },
  {
    "title": "SMaLL: Software for rapidly instantiating Machine Learning Libraries",
    "doi": "https://doi.org/10.1145/3607870",
    "publication_date": "2023-07-12",
    "publication_year": 2023,
    "authors": "Upasana Sridhar; Nicholai Tukanov; Elliott Binder; Tze Meng Low; Scott McMillan; Martin Schatz",
    "corresponding_authors": "",
    "abstract": "Interest in deploying deep neural network (DNN) inference on edge devices has resulted in an explosion of the number and types of hardware platforms that machine learning (ML) libraries must support. High-level programming interfaces, such as TensorFlow, can be readily ported across different devices; however, maintaining performance when porting the low-level implementation is more nuanced. High-performance inference implementations require an effective mapping of the high-level interface to the target hardware platform. Commonly, this mapping may use optimizing compilers to generate code at compile time or high-performance vendor libraries that have been specialized to the target platform. Both approaches rely on expert knowledge across levels to produce an efficient mapping. This makes supporting new architectures difficult and time-consuming. In this work, we present a DNN library framework, SMaLL, that is easily extensible to new architectures. The framework uses a unified loop structure and shared, cache-friendly data format across all intermediate layers, eliminating the time and memory overheads incurred by data transformation between layers. Each layer is implemented by specifying its dimensions and a kernel , the key computing operation of that layer. The unified loop structure and kernel abstraction allows the reuse of code across layers and computing platforms. New architectures only require a few hundred lines in the kernel to be redesigned. To show the benefits of our approach, we have developed software that supports a range of layer types and computing platforms; this software is easily extensible for rapidly instantiating high-performance DNN libraries. An evaluation of the portability of our framework is shown by instantiating end-to-end networks from the MLPerf:tiny benchmark suite on five ARM platforms and one x86 platform (an AMD Zen 2). We also show that the end-to-end performance is comparable to or better than ML frameworks such as TensorFlow, TVM, and LibTorch.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4384030041",
    "type": "article"
  },
  {
    "title": "Minimal-Overlap Centrality for Multi-Gateway Designation in Real-Time TSCH Networks",
    "doi": "https://doi.org/10.1145/3610583",
    "publication_date": "2023-07-25",
    "publication_year": 2023,
    "authors": "Miguel Gutiérrez Gaitán; Lúıs Almeida; Pedro M. d’Orey; Pedro M. Santos; Thomas Watteyne",
    "corresponding_authors": "",
    "abstract": "This article presents a novel centrality-driven gateway designation framework for the improved real-time performance of low-power wireless sensor networks (WSNs) at system design time. We target time-synchronized channel hopping (TSCH) WSNs with centralized network management and multiple gateways with the objective of enhancing traffic schedulability by design . To this aim, we propose a novel network centrality metric termed minimal-overlap centrality that characterizes the overall number of path overlaps between all the active flows in the network when a given node is selected as gateway. The metric is used as a gateway designation criterion to elect as a gateway the node leading to the minimal number of overlaps. The method is then extended to multiple gateways with the aid of the unsupervised learning method of spectral clustering . Concretely, after a given number of clusters are identified, we use the new metric at each cluster to designate as cluster gateway the node with the least overall number of overlaps. Extensive simulations with random topologies under centralized earliest-deadline-first (EDF) scheduling and shortest-path routing suggest our approach is dominant over traditional centrality metrics from social network analysis, namely, eigenvector , closeness , betweenness , and degree . Notably, our approach reduces by up to \\(40\\% \\) the worst-case end-to-end deadline misses achieved by classical centrality-driven gateway designation methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385239593",
    "type": "article"
  },
  {
    "title": "A Secure and Efficient Framework for Outsourcing Large-scale Matrix Determinant and Linear Equations",
    "doi": "https://doi.org/10.1145/3611014",
    "publication_date": "2023-07-26",
    "publication_year": 2023,
    "authors": "Yuling Luo; Shiqi Zhang; Shunsheng Zhang; Junxiu Liu; Yanhu Wang; Su Yang",
    "corresponding_authors": "",
    "abstract": "Large-scale matrix determinants and linear equations are two basic computational tools in science and engineering fields. However, it is difficult for a resource-constrained client to solve large-scale computational tasks. Cloud computing service provides additional computing resources for resource-constrained clients. To solve the problem of large-scale computation, in this article, a secure and efficient framework is proposed to outsource large-scale matrix determinants and linear equations to a cloud. Specifically, the proposed framework contains two protocols, which solve large-scale matrix determinant and linear equations, respectively. In the outsourcing protocols of large-scale matrix determinants and linear equations, the task matrix is encrypted and sent to the cloud by the client. The encrypted task matrix is directly computed by using LU factorization in the cloud. The computed result is returned and verified by the cloud and the client, respectively. The computed result is decrypted if it passes the verification. Otherwise, it is returned to the cloud for recalculation. The framework can protect the input privacy and output privacy of the client. The framework also can guarantee the correctness of the result and reduce the local computational complexity. Furthermore, the experimental results show that the framework can save more than 70% of computing resources after outsourcing computing. Thus, this article provides a secure and efficient alternative for solving large-scale computational tasks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385283904",
    "type": "article"
  },
  {
    "title": "Static Scheduling of Weight Programming for DNN Acceleration with Resource Constrained PIM",
    "doi": "https://doi.org/10.1145/3615657",
    "publication_date": "2023-08-11",
    "publication_year": 2023,
    "authors": "Xin Gao; Hongyue Wang; Yiyan Chen; Yuhao Zhang; Zhaoyan Shen; Lei Ju",
    "corresponding_authors": "",
    "abstract": "Most existing architectural studies on ReRAM-based processing-in-memory (PIM) DNN accelerators assume that all weights of the DNN can be mapped to the crossbar at once. However, these studies are over-idealized. ReRAM crossbar resources for calculation are limited because of technological limitations, so multiple weight mapping procedures are required during the inference process. In this article, we propose a static scheduling framework which generates the mapping between DNN weights and ReRAM cells with minimum runtime weight programming cost. We first build a ReRAM crossbar programming latency model by simultaneously considering the DNN weight patterns, ReRAM programming operations, and PIM architecture characteristics. Then, the model is used in the searching process to obtain an optimized weight-to-OU mapping table with minimum online programming latency. Finally, an OU scheduler is used to coordinate the activation sequences of OUs in the crossbars to perform the inference computation correctly. Evaluation results show the proposed framework significantly reduces the weight programming overhead and the overall inference latency for various DNN models with different input datasets.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385768723",
    "type": "article"
  },
  {
    "title": "Real-Time Fixed Priority Scheduling Synthesis using Affine DataFlow Graphs: from Theory to Practice",
    "doi": "https://doi.org/10.1145/3615586",
    "publication_date": "2023-08-18",
    "publication_year": 2023,
    "authors": "Alexandre Honorat; Hai Nam Tran; Thierry Gautier; Loïc Besnard; Shuvra S. Bhattacharyya; Jean-Pierre Talpin",
    "corresponding_authors": "",
    "abstract": "The major drawback of using static schedules to execute dataflow applications is their high inflexibility. In real-time systems, periodic schedules make it easier to assert safety guarantees and to decrease the schedule size, but their characteristics remain hard to compute. This article presents an approach to automatically generate fixed priority schedules from a dataflow specification. To do so, precedence dependencies between actors in the dataflow graphs are abstracted, as well as the task periods, by using affine relations . This abstraction allows us to synthesize schedules efficiently considering two main objectives: the maximization of throughput and the minimization of buffer sizes. Given a dataflow graph to execute in a real-time environment, we transform it into an Affine DataFlow Graph (ADFG) and compute the task priorities, their mapping, the number of delays in the buffers, and the buffer sizes. This article is the first to present an overview of both theoretical and practical aspects of ADFG. On the theoretical side, it presents corrections and improvements on the fixed priority case. On the practical side, benchmark evaluations demonstrate the robustness and maturity of the approach that our scheduling synthesizer implements. Synthesized schedules are evaluated by using scheduling simulation and real-time implementation. Last but not least, the synthesized periods reach the optimal throughput if enough processors are available, and most of the time the periods reach the maximal processor utilization factor in the uni-processor case. Moreover, execution time of the synthesis is about only one second for the main proposed algorithms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385980106",
    "type": "article"
  },
  {
    "title": "Real-Time Guarantees in Routerless Networks-on-Chip",
    "doi": "https://doi.org/10.1145/3616539",
    "publication_date": "2023-08-23",
    "publication_year": 2023,
    "authors": "Leandro Soares Indrusiak; Alan Burns",
    "corresponding_authors": "",
    "abstract": "This article considers the use of routerless networks-on-chip as an alternative on-chip interconnect for multi-processor systems requiring hard real-time guarantees for inter-processor communication. It presents a novel analytical framework that can provide latency upper bounds to real-time packet flows sent over routerless networks-on-chip, and it uses that framework to evaluate the ability of such networks to provide real-time guarantees. Extensive comparative analysis is provided, considering different architectures for routerless networks and a state-of-the-art wormhole network based on priority-preemptive routers as a baseline.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386099434",
    "type": "article"
  },
  {
    "title": "Rectifying Skewed Kernel Page Reclamation in Mobile Devices for Improving User-Perceivable Latency",
    "doi": "https://doi.org/10.1145/3607937",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Yi-Quan Chou; Lin-Wei Shen; Li-Pin Chang",
    "corresponding_authors": "",
    "abstract": "A crucial design factor for users of smart mobile devices is the latency of graphical interface interaction. Switching a background app to foreground is a frequent operation on mobile devices and the latency of this process is highly perceivable to users. Based on an Android smartphone, through analysis of memory reference generated during the app-switching process, we observe that file (virtual) pages and anonymous pages are both heavily involved. However, to our surprise, the amounts of the two types of pages in the main memory are highly imbalanced, and frequent I/O operations on file pages noticeably slows down the app-switching process. In this study, we advocate to improve the app-switching latency by rectifying the skewed kernel page reclaiming. Our approach involves two parts: proactive identification of unused anonymous pages and adaptive balance between file pages and anonymous pages. As mobile apps are found inflating their anonymous pages, we propose identifying unused anonymous pages in sync with the app-switching events. In addition, Android devices replaces the swap device with RAM-based zram, and swapping on zram is much faster than file accessing on flash storage. Without causing thrashing, we propose swapping out as many anonymous pages to zram as possible for caching more file pages. We conduct experiments on a Google Pixel phone with realistic user workloads, and results confirm that our method is adaptive to different memory requirements and greatly improves the app-switching latency by up to 43% compared with the original kernel.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386568681",
    "type": "article"
  },
  {
    "title": "B-AWARE: Blockage Aware RSU Scheduling for 5G Enabled Autonomous Vehicles",
    "doi": "https://doi.org/10.1145/3609133",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Matthew Szeto; Edward Andert; Aviral Shrivastava; Martin Reisslein; Chung‐Wei Lin; Christ D. Richmond",
    "corresponding_authors": "",
    "abstract": "5G Millimeter Wave (mmWave) technology holds great promise for Connected Autonomous Vehicles (CAVs) due to its ability to achieve data rates in the Gbps range. However, mmWave suffers from a high beamforming overhead and requirement of line of sight (LOS) to maintain a strong connection. For Vehicle-to-Infrastructure (V2I) scenarios, where CAVs connect to roadside units (RSUs), these drawbacks become apparent. Because vehicles are dynamic, there is a large potential for link blockages. These blockages are detrimental to the connected applications running on the vehicle, such as cooperative perception and remote driver takeover. Existing RSU selection schemes base their decisions on signal strength and vehicle trajectory alone, which is not enough to prevent the blockage of links. Many modern CAVs motion planning algorithms routinely use other vehicle’s near-future path plans, either by explicit communication among vehicles, or by prediction. In this paper, we make use of the knowledge of other vehicle’s near future path plans to further improve the RSU association mechanism for CAVs. We solve the RSU association algorithm by converting it to a shortest path problem with the objective to maximize the total communication bandwidth. We evaluate our approach, titled B-AWARE, in simulation using Simulation of Urban Mobility (SUMO) and Digital twin for self-dRiving Intelligent VEhicles (DRIVE) on 12 highway and city street scenarios with varying traffic density and RSU placements. Simulations show B-AWARE results in a 1.05× improvement of the potential datarate in the average case and 1.28× in the best case vs. the state-of-the-art. But more impressively, B-AWARE reduces the time spent with no connection by 42% in the average case and 60% in the best case as compared to the state-of-the-art methods. This is a result of B-AWARE reducing nearly 100% of blockage occurrences.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386568717",
    "type": "article"
  },
  {
    "title": "WARM-tree: Making Quadtrees Write-efficient and Space-economic on Persistent Memories",
    "doi": "https://doi.org/10.1145/3608033",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Shin-Ting Wu; Liang-Chi Chen; Po‐Chun Huang; Yuan-Hao Chang; Chien-Chung Ho; Wei‐Kuan Shih",
    "corresponding_authors": "",
    "abstract": "Recently, the value of data has been widely recognized, which highlights the significance of data-centric computing in diversified application scenarios. In many cases, the data are multidimensional, and the management of multidimensional data often confronts greater challenges in supporting efficient data access operations and guaranteeing the space utilization. On the other hand, while many existing index data structures have been proposed for multidimensional data management, however, their designs are not fully optimized for modern nonvolatile memories, in particular the byte-addressable persistent memories. As a result, they might undergo serious access performance degradation or fail to guarantee space utilization. This observation motivates the redesigning of index data structures for multidimensional point data on modern persistent memories, such as the phase-change memory. In this work, we present the WARM-tree , a m ultidimensional t ree for r educing the w rite a mplification effect, for multidimensional point data. In our evaluation studies, as compared to the bucket PR quadtree and R*-tree, the WARM-tree can provide any worst-case space utilization guarantees in the form of \\(\\frac{m-1}{m}\\) ( m ∈ ℤ^+) and effectively reduces the write traffic of key insertions by up to 48.10% and 85.86%, respectively, at the price of degraded average space utilization and prolonged latency of query operations. This suggests that the WARM-tree is a potential multidimensional index structure for insert-intensive workloads.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386568804",
    "type": "article"
  },
  {
    "title": "STADIA: Photonic Stochastic Gradient Descent for Neural Network Accelerators",
    "doi": "https://doi.org/10.1145/3607920",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Chengpeng Xia; Yawen Chen; Haibo Zhang; Jigang Wu",
    "corresponding_authors": "",
    "abstract": "Deep Neural Networks (DNNs) have demonstrated great success in many fields such as image recognition and text analysis. However, the ever-increasing sizes of both DNN models and training datasets make deep leaning extremely computation- and memory-intensive. Recently, photonic computing has emerged as a promising technology for accelerating DNNs. While the design of photonic accelerators for DNN inference and forward propagation of DNN training has been widely investigated, the architectural acceleration for equally important backpropagation of DNN training has not been well studied. In this paper, we propose a novel silicon photonic-based backpropagation accelerator for high performance DNN training. Specifically, a general-purpose photonic gradient descent unit named STADIA is designed to implement the multiplication, accumulation, and subtraction operations required for computing gradients using mature optical devices including Mach-Zehnder Interferometer (MZI) and Mircoring Resonator (MRR), which can significantly reduce the training latency and improve the energy efficiency of backpropagation. To demonstrate efficient parallel computing, we propose a STADIA-based backpropagation acceleration architecture and design a dataflow by using wavelength-division multiplexing (WDM). We analyze the precision of STADIA by quantifying the precision limitations imposed by losses and noises. Furthermore, we evaluate STADIA with different element sizes by analyzing the power, area and time delay for photonic accelerators based on DNN models such as AlexNet, VGG19 and ResNet. Simulation results show that the proposed architecture STADIA can achieve significant improvement by 9.7× in time efficiency and 147.2× in energy efficiency, compared with the most advanced optical-memristor based backpropagation accelerator.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386568805",
    "type": "article"
  },
  {
    "title": "Energy-efficient Personalized Federated Search with Graph for Edge Computing",
    "doi": "https://doi.org/10.1145/3609435",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Yang Zhao; Qingshuang Sun",
    "corresponding_authors": "",
    "abstract": "Federated Learning (FL) is a popular method for privacy-preserving machine learning on edge devices. However, the heterogeneity of edge devices, including differences in system architecture, data, and co-running applications, can significantly impact the energy efficiency of FL. To address these issues, we propose an energy-efficient personalized federated search framework. This framework has three key components. Firstly, we search for partial models with high inference efficiency to reduce training energy consumption and the occurrence of stragglers in each round. Secondly, we build lightweight search controllers that control the model sampling and respond to runtime variances, mitigating new straggler issues caused by co-running applications. Finally, we design an adaptive search update strategy based on graph aggregation to improve personalized training convergence. Our framework reduces the energy consumption of the training process by lowering the training overhead of each round and speeding up the training convergence rate. Experimental results show that our approach achieves up to 5.02% accuracy and 3.45× energy efficiency improvements.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386568850",
    "type": "article"
  },
  {
    "title": "Equation-Directed Axiomatization of Lustre Semantics to Enable Optimized Code Validation",
    "doi": "https://doi.org/10.1145/3609393",
    "publication_date": "2023-09-09",
    "publication_year": 2023,
    "authors": "Lélio Brun; Christophe Garion; Pierre-Loïc Garoche; Xavier Thirioux",
    "corresponding_authors": "",
    "abstract": "Model-based design tools like SCADE Suite and Simulink are often used to design safety-critical embedded software. Consequently, generating correct code from such models is crucial. We tackle this challenge on Lustre, a dataflow synchronous language that embodies the concepts that base such tools. Instead of proving correct a whole code generator, we turn an existing compiler into a certifying compiler from Lustre to C, following a translation validation approach. We propose a solution that generates both C code and an attached specification expressing a correctness result for the generated and optionally optimized code. The specification yields proof obligations that are discharged by external solvers through the Frama-C platform.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386580300",
    "type": "article"
  },
  {
    "title": "Scheduling Dynamic Software Updates in Mobile Robots",
    "doi": "https://doi.org/10.1145/3623676",
    "publication_date": "2023-09-13",
    "publication_year": 2023,
    "authors": "Ahmed El Yaacoub; Luca Mottola; Thiemo Voigt; Philipp Rümmer",
    "corresponding_authors": "",
    "abstract": "We present NeRTA ( Ne xt R elease T ime A nalysis), a technique to enable dynamic software updates for low-level control software of mobile robots. Dynamic software updates enable software correction and evolution during system operation. In mobile robotics, they are crucial to resolve software defects without interrupting system operation or to enable on-the-fly extensions. Low-level control software for mobile robots, however, is time sensitive and runs on resource-constrained hardware with no operating system support. To minimize the impact of the update process, NeRTA safely schedules updates during times when the computing unit would otherwise be idle. It does so by utilizing information from the existing scheduling algorithm without impacting its operation. As such, NeRTA works orthogonal to the existing scheduler, retaining the existing platform-specific optimizations and fine-tuning, and may simply operate as a plug-in component. To enable larger dynamic updates, we further conceive an additional mechanism called bounded reactive control and apply mixed-criticality concepts. The former cautiously reduces the overall control frequency, whereas the latter excludes less critical tasks from NeRTA processing. Their use increases the available idle times. We combine real-world experiments on embedded hardware with simulations to evaluate NeRTA. Our experimental evaluation shows that the difference between NeRTA’s estimated idle times and the measured idle times is less than 15% in more than three-quarters of the samples. The combined effect of bounded reactive control and mixed-criticality concepts results in a 150+% increase in available idle times. We also show that the processing overhead of NeRTA and of the additional mechanisms is essentially negligible.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386711741",
    "type": "article"
  },
  {
    "title": "Energy-Efficient Communications for Improving Timely Progress of Intermittent-Powered BLE Devices",
    "doi": "https://doi.org/10.1145/3626197",
    "publication_date": "2023-09-29",
    "publication_year": 2023,
    "authors": "Chen-Tui Hung; Kai Xuan Lee; Yi-Zheng Liu; Ya-Shu Chen; Zhong-Han Chan",
    "corresponding_authors": "",
    "abstract": "Battery-less devices offer potential solutions for maintaining sustainable Internet of Things (IoT) networks. However, limited energy harvesting capacity can lead to power failures, limiting the system’s quality of service (QoS) . To improve timely task progress, we present ETIME, a scheduling framework that enables energy-efficient communication for intermittent-powered IoT devices. To maximize energy efficiency while meeting the timely requirements of intermittent systems, we first model the relationship between insufficient harvesting energy and task behavior time. We then propose a method for predicting response times for battery-less devices. Considering both delays from multiple task interference and insufficient system energy, we introduce a dynamic wake-up strategy to improve timely task progress. Additionally, to minimize power consumption from connection components, we propose a dynamic connection interval adjustment to provide energy-efficient communication. The proposed algorithms are implemented in a lightweight operating system on real devices. Experimental results show that our approach can significantly improve progress for timely applications while maintaining task progress.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4387168569",
    "type": "article"
  },
  {
    "title": "A Comprehensive Model for Efficient Design Space Exploration of Imprecise Computational Blocks",
    "doi": "https://doi.org/10.1145/3625555",
    "publication_date": "2023-09-29",
    "publication_year": 2023,
    "authors": "Mohammad Haji Seyed Javadi; Mohsen Faryabi; Hamid Reza Mahdiani",
    "corresponding_authors": "",
    "abstract": "After almost a decade of research, development of more efficient imprecise computational blocks is still a major concern in imprecise computing domain. There are many instances of the introduced imprecise components of different types, while their main difference is that they propose different precision-cost-performance trade-offs. In this paper, a novel comprehensive model for the imprecise components is introduced, which can be exploited to cover a wide range of precision-cost-performance trade-offs, for different types of imprecise components. The model helps to find the suitable imprecise component based on any desired error criterion. Therefore, the most significant advantage of the proposed model is that it can be simply exploited for design space exploration of different imprecise components to extract the suitable components, with the desired precision-cost-performance trade-off for any specific application. To demonstrate the efficiency of the proposed model, two novel families of Lowest-cost Imprecise Adders (LIAs) and Lowest-cost Imprecise Multipliers (LIMs) are introduced in the paper, which are systematically extracted based on exploration of the design space provided by the proposed model. A wide range of simulation and synthesis results are also presented in the paper to prove the comparable efficiency of the systematically extracted LIA/LIM structures with respect to the most efficient existing human-made imprecise components both individually and in a Multiply-Accumulate application.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4387168707",
    "type": "article"
  },
  {
    "title": "Synchronised Shared Memory and Model Checking",
    "doi": "https://doi.org/10.1145/3626188",
    "publication_date": "2023-10-02",
    "publication_year": 2023,
    "authors": "Joaquín Aguado; Alejandra Duenas",
    "corresponding_authors": "",
    "abstract": "In this article, a formal generic framework for defining and reasoning about deterministic concurrency in synchronous systems is implemented in the Spin model checker. Concretely, the work implements the clock-synchronised shared memory ( csm ) theory, which extends synchronous programming with more and higher-level csm data types. These csm data types are equipped with a synchronisation policy prescribing how concurrent calls to objects methods must be organised. In a policy constructive system, all methods of every object can be scheduled in a policy-conformant manner without deadlocking. In our framework, synchronous policies get codified as Promela never-claims. In this form, the model checker can search for executions (interleavings) that satisfy the synchronous product of all the never-claims, namely policy-conformant schedules for all the csm objects. The existence of such policy-conformant schedules verifies that the concurrent synchronous system is deterministic. The approach of this article extends beyond a single semantics since it can handle the synchronous programming model as well as the various forms of the sequentially constructive model found in the literature.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4387263274",
    "type": "article"
  },
  {
    "title": "Special Issue: “AI Acceleration on FPGAs”",
    "doi": "https://doi.org/10.1145/3626323",
    "publication_date": "2023-11-09",
    "publication_year": 2023,
    "authors": "Yun Liang; Wei Zhang; Stephen Neuendorffer; Wayne Luk",
    "corresponding_authors": "",
    "abstract": "introduction Share on Special Issue: “AI Acceleration on FPGAs” Authors: Yun (Eric) Liang Peking University, Peking, People's Republic of China Peking University, Peking, People's Republic of China 0000-0002-9076-7998View Profile , Wei Zhang The Hong Kong University of Science and Technology, Hong Kong, People's Republic of China The Hong Kong University of Science and Technology, Hong Kong, People's Republic of China 0000-0002-7622-6714View Profile , Stephen Neuendorffer Xilinx, San Jose, CA Xilinx, San Jose, CA 0000-0003-2956-8428View Profile , Wayne Luk Imperial College London, London, UK Imperial College London, London, UK 0000-0002-6750-927XView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 22Issue 6Article No.: 89pp 1–3https://doi.org/10.1145/3626323Published:09 November 2023Publication History 0citation52DownloadsMetricsTotal Citations0Total Downloads52Last 12 Months52Last 6 weeks42 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4388527108",
    "type": "article"
  },
  {
    "title": "Virtual Environment Model Generation for CPS Goal Verification using Imitation Learning",
    "doi": "https://doi.org/10.1145/3633804",
    "publication_date": "2023-11-27",
    "publication_year": 2023,
    "authors": "Yong-Jun Shin; Donghwan Shin; Doo‐Hwan Bae",
    "corresponding_authors": "",
    "abstract": "Cyber-Physical Systems (CPS) continuously interact with their physical environments through embedded software controllers that observe the environments and determine actions. Field Operational Tests (FOT) are essential to verify to what extent the CPS under analysis can achieve certain CPS goals, such as satisfying the safety and performance requirements, while interacting with the real operational environment. However, performing many FOTs to obtain statistically significant verification results is challenging due to its high cost and risk in practice. Simulation-based verification can be an alternative to address the challenge, but it still requires an accurate virtual environment model that can replace the real environment interacting with the CPS in a closed loop. In this paper, we propose ENVI (ENVironment Imitation), a novel approach to automatically generate an accurate virtual environment model, enabling efficient and accurate simulation-based CPS goal verification in practice.To do this, we first formally define the problem of the virtual environment model generation and solve it by leveraging Imitation Learning (IL), which has been actively studied in machine learning to learn complex behaviors from expert demonstrations. The key idea behind the model generation is to leverage IL for training a model that imitates the interactions between the CPS controller and its real environment as recorded in (possibly very small) FOT logs. We then statistically verify the goal achievement of the CPS by simulating it with the generated model. We empirically evaluate ENVI by applying it to the verification of two popular autonomous driving assistant systems. The results show that ENVI can reduce the cost of CPS goal verification while maintaining its accuracy by generating accurate environment models from only a few FOT logs. The use of IL in virtual environment model generation opens new research directions, further discussed at the end of the paper.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4389057876",
    "type": "article"
  },
  {
    "title": "Parallelizing load/stores on dual-bank memory embedded processors",
    "doi": "https://doi.org/10.1145/1165780.1165784",
    "publication_date": "2006-08-01",
    "publication_year": 2006,
    "authors": "Xiaotong Zhuang; Santosh Pande",
    "corresponding_authors": "",
    "abstract": "Many modern embedded processors such as DSPs support partitioned memory banks (also called X--Y memory or dual-bank memory) along with parallel load/store instructions to achieve higher code density and performance. In order to effectively utilize the parallel load/store instructions, the compiler must partition the memory-resident values and assign them to X or Y bank. This paper gives a postregister allocation solution to merge the generated load/store instructions into their parallel counterparts. Simultaneously, our framework performs allocation of values to X or Y memory banks. We first remove as many load/stores and register--register moves as possible through an excellent iterated coalescing based register allocator by Appel and George [1996]. We then attempt to parallelize the generated load/stores using a multipass approach. The basic phase of our approach attempts the merger of load/stores without duplication and web splitting. We model this problem as a graph-coloring problem in which each value is colored as either X or Y. We then construct a motion scheduling graph (MSG), based on the range of motion for each load/store instruction. MSG reflects potential instructions that could be merged. We propose a notion of pseudofixed boundaries so that the load/store movement is less affected by register dependencies. We prove that the coloring problem for MSG is NP-complete and solve it with two different heuristic algorithms with different complexity. We then propose a two-level iterative process to attempt instruction duplication, variable duplication, web splitting, and local conflict elimination to effectively merge the remaining load/stores. Finally, we clean up some multiple-aliased load/stores. To improve the performance, we combine profiling information with each stage coupled with some modifications to the algorithm. We show that our framework results in parallelization of a large number of load/stores without much growth in data and code segments. The average speedup for our optimization pass reaches roughly 13% if no profile information is available and 17% with profile information. The average code and data segment growth is controlled within 13%.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2030440900",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3173385",
    "publication_date": "2018-01-12",
    "publication_year": 2018,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "editorial Free Access Share on Editorial: Trust and Security Must Become a Primary Design Concern in Embedded Computing Editor: Sandeep K. Shukla Indian Institute of Technology Kanpur Indian Institute of Technology KanpurView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 17Issue 1January 2018 Article No.: 1pp 1–3https://doi.org/10.1145/3173385Published:12 January 2018Publication History 0citation400DownloadsMetricsTotal Citations0Total Downloads400Last 12 Months51Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2784323745",
    "type": "editorial"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/3162079",
    "publication_date": "2018-01-23",
    "publication_year": 2018,
    "authors": "Elizabeth Leonard",
    "corresponding_authors": "Elizabeth Leonard",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2787692754",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3241724",
    "publication_date": "2018-07-31",
    "publication_year": 2018,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2892798121",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3282437",
    "publication_date": "2018-09-30",
    "publication_year": 2018,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2900958844",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3293502",
    "publication_date": "2018-11-30",
    "publication_year": 2018,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2911589008",
    "type": "editorial"
  },
  {
    "title": "Mining Missing Assumptions from Counter-Examples",
    "doi": "https://doi.org/10.1145/3288759",
    "publication_date": "2019-01-25",
    "publication_year": 2019,
    "authors": "Guillaume Plassan; Katell Morin-Allory; D. Borrione",
    "corresponding_authors": "",
    "abstract": "During the formal functional verification of Register-Transfer Level designs, a false failure is often observed. Most of the time, this failure is caused by an underconstrained model. The analysis of the root cause for the verification error and the creation of missing assumptions are a significant time burden. In this article, we present a methodology to automatically mine these missing assumptions from counter-examples. First, multiple counter-examples are generated for the same property. Then, relevant behaviors are mined from the counter-examples. Finally, corresponding assumptions are filtered and a small amount is returned to the user for review.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2913442164",
    "type": "article"
  },
  {
    "title": "Guest Editorial",
    "doi": "https://doi.org/10.1145/3292422",
    "publication_date": "2019-01-08",
    "publication_year": 2019,
    "authors": "Patricia Derler; Klaus Schneider; Jean-Pierre Talpin",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2926937651",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3302888",
    "publication_date": "2019-01-31",
    "publication_year": 2019,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2931905897",
    "type": "editorial"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3345556",
    "publication_date": "2019-07-31",
    "publication_year": 2019,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2978844055",
    "type": "editorial"
  },
  {
    "title": "Parametric Scheduler Characterization",
    "doi": "https://doi.org/10.1145/3358226",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Joost van Pinxten; Marc Geilen; Twan Basten",
    "corresponding_authors": "",
    "abstract": "Schedulers assign starting times to events in a system such that a set of constraints is met and system productivity is maximized. We characterize the scheduler behaviour for the case where decisions are made by comparing affine expressions of design parameters such as task workload, processing speed, robot travelling speed, or a controller’s rise and settling time. Deterministic schedulers can be extended with symbolic execution, to keep track of the affine conditions on the parameters for which the scheduling decisions are made. We introduce a divide-and-conquer algorithm that uses this information to determine parameter regions for which the same sequence of decisions is taken given a particular scenario. The results provide designers insight in the impact of parameter changes on the performance of their system. The exploration can also be executed with the KLEE symbolic execution engine of the LLVM tool chain to extract the same results. We show that the divide-and-conquer approach provides the results much faster than the generic symbolic execution engine of KLEE. The results allow visualization of the sensitivity to all parameter combinations. The results of our approach therefore provide more insight in the sensitivity to parameters.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2979544468",
    "type": "article"
  },
  {
    "title": "Will My Program Break on This Faulty Processor?",
    "doi": "https://doi.org/10.1145/3358238",
    "publication_date": "2019-10-08",
    "publication_year": 2019,
    "authors": "Levente Bajczi; András Vörös; Vince Molnár",
    "corresponding_authors": "",
    "abstract": "Formal verification is approaching a point where it will be reliably applicable to embedded software. Even though formal verification can efficiently analyze multi-threaded applications, multi-core processors are often considered too dangerous to use in critical systems, despite the many benefits they can offer. One reason is the advanced memory consistency model of such CPUs. Nowadays, most software verifiers assume strict sequential consistency, which is also the naïve view of programmers. Modern multi-core processors, however, rarely guarantee this assumption by default. In addition, complex processor architectures may easily contain design faults. Thanks to the recent advances in hardware verification, these faults are increasingly visible and can be detected even in existing processors, giving an opportunity to compensate for the problem in software. In this paper, we propose a generic approach to consider inconsistent behavior of the hardware in the analysis of software. Our approach is based on formal methods and can be used to detect the activation of existing hardware faults on the application level and facilitate their mitigation in software. The approach relies heavily on recent results of model checking and hardware verification and offers new, integrative research directions. We propose a partial solution based on existing model checking tools to demonstrate feasibility and evaluate their performance in this context.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2980051369",
    "type": "article"
  },
  {
    "title": "Toward Customized Hybrid Fuel-Cell and Battery-powered Mobile Device for Individual Users",
    "doi": "https://doi.org/10.1145/3362033",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Kaige Yan; Jingweijia Tan; Longjun Liu; Xingyao Zhang; Stanko R. Brankovic; Jinghong Chen; Xin Fu",
    "corresponding_authors": "",
    "abstract": "Rapidly evolving technologies and applications of mobile devices inevitably increase the power demands on the battery. However, the development of batteries can hardly keep pace with the fast-growing demands, leading to short battery life, which becomes the top complaints from customers. In this article, we investigate a novel energy supply technology, fuel cell (FC), and leverage its advantages of providing long-term energy storage to build a hybrid FC-battery power system. Therefore, mobile device operation time is dramatically extended, and users are no longer bothered by battery recharging. We examine real-world smartphone usage data and find that a naive hybrid power system cannot meet many users’ highly diversified power demands. We thus propose an OS-level power management policy that reduces the device power consumption for each power peak to solve this mismatch. This technique trades the quality-of-service (QoS) for a larger FC ratio in the system and thus much longer device operation time. We further observe that the user’s personality largely determines his/her satisfaction with the QoS degradation and the operation time extension. Thus, applying a hybrid system with fixed configuration (i.e., peak throttling level coupled with corresponding FC/battery ratio) fails to satisfy every user. We then explore customized hybrid system configuration based on each individual user’s personality to deliver the optimal satisfaction for him/her. The experimental results show that our personality-aware hybrid FC-battery solution can achieve 4× longer operation time and 25% higher satisfaction score compared to the common setting for state-of-the-art mobile devices.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2984558029",
    "type": "article"
  },
  {
    "title": "Introduction to the special issue",
    "doi": "https://doi.org/10.1145/1053271.1053272",
    "publication_date": "2005-02-01",
    "publication_year": 2005,
    "authors": "Frank Mueller; Per Stenström",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2994496172",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3368250",
    "publication_date": "2019-11-30",
    "publication_year": 2019,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "editorial Free Access Share on Editorial: Embedded Computing and Society Author: Sandeep K. Shukla Indian Institute of Technology Kanpur, Kanpur, UP, India Indian Institute of Technology Kanpur, Kanpur, UP, IndiaView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 18Issue 6November 2019 Article No.: 112pp 1–3https://doi.org/10.1145/3368250Published:21 January 2020Publication History 0citation261DownloadsMetricsTotal Citations0Total Downloads261Last 12 Months32Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3001367426",
    "type": "editorial"
  },
  {
    "title": "次元関数合成を用いたセンサデータからの方程式導出【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2019-01-01",
    "publication_year": 2019,
    "authors": "Wang Youchao; Willis Sam; Tsoutsouras Vasileios; Stanley-Marbell Phillip",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3174027859",
    "type": "article"
  },
  {
    "title": "プライバシー保持監視システムのための著者認証画像クロッパー【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2019-01-01",
    "publication_year": 2019,
    "authors": "Jihye Kim; Lee Jiwon; Ko Hankyung; Oh Donghwan; Han Semin; Jeong Gwonho; Oh Hyunok",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3177154430",
    "type": "article"
  },
  {
    "title": "NoCに基づく多コアのための階層的分散型実行リソース管理方式【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Tsoutsouras Vasileios; Anagnostopoulos Iraklis; Masouros Dimosthenis; Soudris Dimitrios",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3179231477",
    "type": "article"
  },
  {
    "title": "サイバー物理システムのロバスト設計と検証【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2019-01-01",
    "publication_year": 2019,
    "authors": "Sood Surinder; Malik Avinash; Roop Partha",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3179676172",
    "type": "article"
  },
  {
    "title": "多くのコア加速器に関する空間分離のための応用展開戦略【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Real Maria Mendez; Philipp Wehner; Vianney Lapôtre; Diana Göhringer; Guy Gogniat",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3180512883",
    "type": "article"
  },
  {
    "title": "モバイルデバイスにおける深い学習に基づく屋内位置決めフレームワークにおけるセキュリティ脆弱性の克服【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2019-01-01",
    "publication_year": 2019,
    "authors": "Tiku Saideep; Pasricha Sudeep",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3190413558",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3365919",
    "publication_date": "2019-10-19",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230507849",
    "type": "paratext"
  },
  {
    "title": "Preface",
    "doi": "https://doi.org/10.1145/1113830.1113831",
    "publication_date": "2005-11-01",
    "publication_year": 2005,
    "authors": "Rajeev Alur; Insup Lee",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231781837",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3236463",
    "publication_date": "2018-08-29",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Electric Vehicles (EV) as a zero-emission means of transportation encounter challenges in battery design that cause a range anxieties for the drivers. Besides the electric motor, the Heating, Ventilation, and Air Conditioning (HVAC) system is another ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232521716",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3320151",
    "publication_date": "2019-04-03",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "With the popularity of modern FPGAs, the business of FPGA specific intellectual properties (IP) is expanding rapidly. This also brings in the concern of IP protection. FPGA vendors are making serious efforts toward IP protection, leading to ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233455885",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1196636",
    "publication_date": "2006-11-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Embedded systems usually lack virtual memory and are vulnerable to memory overflow since they lack a mechanism to detect overflow or use swap space thereafter. We present a method to detect memory overflows using compiler-inserted software run-time ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233660185",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3372377",
    "publication_date": "2019-12-14",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Resistive crossbars have shown strong potential as the building blocks of future neural fabrics, due to their ability to natively execute vector-matrix multiplication (the dominant computational kernel in DNNs). However, a key challenge that arises in ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235900615",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3305158",
    "publication_date": "2019-02-28",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present an assume-guarantee contract framework for cyber-physical system design under probabilistic requirements. Given a stochastic linear system and a set of requirements captured by bounded Stochastic Signal Temporal Logic (StSTL) contracts, we ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237562365",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3278719",
    "publication_date": "2018-11-22",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237742529",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1132357",
    "publication_date": "2006-02-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The mobile computing device market has been growing rapidly. This brings the technologies that optimize system energy to the forefront. As circuits continue to scale in the future, it would be important to optimize both leakage and dynamic energy. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4238014314",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3349526",
    "publication_date": "2019-10-12",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article presents a microcontroller unit (MCU) based simplified discrete wavelet transform (Sim-DWT) algorithm that can detect high-voltage spindles (HVSs) in local field potential (LFP) signals. The Sim-DWT algorithm operates in an 8-bit MCU, 8MHz ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239083901",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1151074",
    "publication_date": "2006-05-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "With the help of HW/SW codesign, system-on-chip (SoC) can effectively reduce cost, improve reliability, and produce versatile products. The growing complexity of SoC designs makes on-chip communication subsystem design as important as computation ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240675080",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3323876",
    "publication_date": "2019-06-13",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In safety-critical systems, time predictability is vital. This extends to I/O operations that require predictability, timing-accuracy, parallel access, scalability, and isolation. Currently, existing approaches cannot achieve all these requirements at ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244180445",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3136518",
    "publication_date": "2018-01-12",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Water quality data is incredibly important and valuable, but its acquisition is not always trivial. A promising solution is to distribute a wireless sensor network in water to measure and collect the data; however, a drawback exists in that the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244791605",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3185335",
    "publication_date": "2018-06-02",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article examines dynamic energy consumption caused by data during software execution on deeply embedded microprocessors, which can be significant on some devices. In worst-case energy consumption analysis, energy models are used to find the most ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245130140",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1165780",
    "publication_date": "2006-08-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present an energy-efficient, utility accrual, real-time scheduling algorithm called ReUA. ReUA considers an application model where activities are subject to time/utility function time constraints, mutual exclusion constraints on shared non-CPU ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247310896",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3299750",
    "publication_date": "2019-01-09",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Due to limited numbers of program/erase cycles (i.e., P/Es) of NAND Flash, excessive out-of-place update and erase-before-write operations wear out these P/Es during garbage collections, which adversely shorten solid state disk (i.e., SSD) lifetime. The ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4249564966",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3340300",
    "publication_date": "2019-08-12",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253691818",
    "type": "paratext"
  },
  {
    "title": "Montgomery Multiplication for Public Key Cryptography on MSP430X",
    "doi": "https://doi.org/10.1145/3387919",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Hwajeong Seo; Kyuhwang An; Hyeokdong Kwon; Zhi Hu",
    "corresponding_authors": "",
    "abstract": "For traditional public key cryptography and post-quantum cryptography, such as elliptic curve cryptography and supersingular isogeny key encapsulation, modular multiplication is the most performance-critical operation among basic arithmetic of these cryptographic schemes. For this reason, the execution timing of such cryptographic schemes, which may highly determine that the service availability for low-end microprocessors (e.g., 8-bit AVR, 16-bit MSP430X, and 32-bit ARM Cortex-M), mainly relies on the efficiency of modular multiplication on target embedded processors. In this article, we present new optimal modular multiplication techniques based on the interleaved Montgomery multiplication on 16-bit MSP430X microprocessors, where the multiplication part is performed in a hardware multiplier and the reduction part is performed in a basic arithmetic logic unit (ALU) with the optimal modular multiplication routine, respectively. This two-step approach is effective for the special modulus of NIST curves, SM2 curves, and supersingular isogeny key encapsulation. We further optimized the Montgomery reduction by using techniques for “Montgomery-friendly” prime. This technique significantly reduces the number of partial products. To demonstrate the superiority of the proposed implementation of Montgomery multiplication, we applied the proposed method to the NIST P-256 curve, of which the implementation improves the previous modular multiplication operation by 23.6% on 16-bit MSP430X microprocessors and to the SM2 curve as well (first implementation on 16-bit MSP430X microcontrollers). Moreover, secure countermeasures against timing attack and simple power analysis are also applied to the scalar multiplication of NIST P-256 and SM2 curves, which achieve the 8,582,338 clock cycles (0.53 seconds@16 MHz) and 10,027,086 clock cycles (0.62 seconds@16 MHz), respectively. The proposed Montgomery multiplication is a generic method that can be applied to other cryptographic schemes and microprocessors with minor modifications.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3035440391",
    "type": "article"
  },
  {
    "title": "A Retargetable MATLAB-to-C Compiler Exploiting Custom Instructions and Data Parallelism",
    "doi": "https://doi.org/10.1145/3391898",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Ioannis Latifis; Karthick Parashar; Grigoris Dimitroulakos; Hans Cappelle; Christakis Lezos; Κωνσταντίνος Μασσέλος; Francky Catthoor",
    "corresponding_authors": "",
    "abstract": "This article presents a MATLAB-to-C compiler that exploits custom instructions present in state-of-the-art processor architectures and supports semi-automatic vectorization. A parameterized processor model is used to describe the target instruction set architecture to achieve user-friendly retargetability. Custom instructions are represented via specialized intrinsic functions in the generated code, which can then be used as input to any C/C++ compiler supporting the target processor. In addition, the compiler supports the generation of data parallel/vectorized code through the introduction of data packing/unpacking statements. The compiler has been used for code generation targeting ARM and x86 architectures for several benchmarks. The vectorized code generated by the compiler achieves an average speedup of 4.1× and 2.7× for packed fixed and floating point data, respectively, compared to scalarized code for ARM architecture and an average speedup of 3.1× and 1.5× for packed fixed and floating point data, respectively, for x86 architecture. Implementing data parallel instructions directly in the assembly code would have required a lot of design effort, and it would not been sustainable across evolving platform variants. Thus, the compiler can be employed to efficiently speed up critical sections of the target application. The compiler is therefore potentially employable to raise the design abstraction and reduce development time for both embedded and general-purpose applications.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3041027772",
    "type": "article"
  },
  {
    "title": "TECS Editorial",
    "doi": "https://doi.org/10.1145/3395923",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Sandeep K. Shukla",
    "corresponding_authors": "Sandeep K. Shukla",
    "abstract": "editorial Free AccessTECS Editorial: Rethinking and Re-evaluating in the Time of Crisis Share on Editor: Sandeep K. Shukla Indian Institute of Technology, Kanpur Indian Institute of Technology, KanpurView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 19Issue 3June 2020 Article No.: 16epp 1–3https://doi.org/10.1145/3395923Published:16 May 2020 0citation127DownloadsMetricsTotal Citations0Total Downloads127Last 12 Months59Last 6 weeks8 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3046302399",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Languages, Compilers, Tools, and Theory of Embedded Systems",
    "doi": "https://doi.org/10.1145/3417732",
    "publication_date": "2020-09-26",
    "publication_year": 2020,
    "authors": "Aviral Shrivastava; Jian-Jia Chen; Youtao Zhang",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Issue on Languages, Compilers, Tools, and Theory of Embedded Systems: Part 1 Authors: Aviral Shrivastava View Profile , Jian-Jia Chen View Profile , Youtao Zhang View Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 19Issue 5September 2020 Article No.: 30pp 1–3https://doi.org/10.1145/3417732Online:26 September 2020Publication History 0citation62DownloadsMetricsTotal Citations0Total Downloads62Last 12 Months22Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3089312090",
    "type": "article"
  },
  {
    "title": "リングLWEポスト量子暗号の早期採用のための柔軟な加速器の合成【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2020-01-01",
    "publication_year": 2020,
    "authors": "Nejatollahi Hamid; Valencia Felipe; Banik Subhadeep; Regazzoni Francesco; Cammarota Rosario; Dutt Nikil",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3208496876",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Languages, Compilers, Tools, and Theory of Embedded Systems",
    "doi": "https://doi.org/10.1145/3417734",
    "publication_date": "2020-09-29",
    "publication_year": 2020,
    "authors": "Aviral Shrivastava; Jian-Jia Chen; Youtao Zhang",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254629802",
    "type": "article"
  },
  {
    "title": "Special issue on compilers, architecture, and synthesis for embedded systems",
    "doi": "https://doi.org/10.1145/643470.643471",
    "publication_date": "2003-05-01",
    "publication_year": 2003,
    "authors": "Guang Gao; Trevor Mudge",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2033207018",
    "type": "article"
  },
  {
    "title": "Compressing MIPS code by multiple operand dependencies",
    "doi": "https://doi.org/10.1145/950162.950164",
    "publication_date": "2003-11-01",
    "publication_year": 2003,
    "authors": "Kelvin Lin; Chung-Ping Chung; Jean Jyh-Jiun Shann",
    "corresponding_authors": "",
    "abstract": "Intuitively, destination registers of some instructions have great possibilities to be used as the source registers of the immediately subsequent instructions. Such destination register/source register pairs have been exploited previously to improve code compression ratio [ compression ratio = ( Dictionary Size + Encoded Program Size )/ Original Program Size ]. This paper further examines the exploitation of both register and immediate operand dependencies to improve the compression ratio. A mapping tag is used to flag dependency relationships so that dependent operands can be omitted during compression. The compression ratio is enhanced by both the removal of dependent operands and the sharing of mapping tags between different types of dependencies and between different instructions. Simulation results show that the proposed method results in the best compression ratio achieved so far, giving average compression ratios of 33.8% for MediaBench benchmarks and 33.6% for SPEC95 benchmarks, both compiled for a MIPS R2000 processor.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2059403060",
    "type": "article"
  },
  {
    "title": "Accurate Estimation of Service Rates in Interleaved Scratchpad Memory Systems",
    "doi": "https://doi.org/10.1145/3457171",
    "publication_date": "2022-01-31",
    "publication_year": 2022,
    "authors": "Robert Wittig; Philipp Schulz; Emil Matúš; Gerhard Fettweis",
    "corresponding_authors": "",
    "abstract": "The prototyping of embedded platforms demands rapid exploration of multi-dimensional parameter sets. Especially the design of the memory system is essential to guarantee high utilization while reducing conflicts at the same time. To aid the design process, several probabilistic models to estimate the throughput of interleaved memory systems have been proposed. While accurately estimating the average throughput of the system, these models fail to determine the impact on individual processing elements. To mitigate this divergence, we extend three known models to include non-uniform access probabilities and priorities.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4211236231",
    "type": "article"
  },
  {
    "title": "Cache Abstraction for Data Race Detection in Heterogeneous Systems with Non-coherent Accelerators",
    "doi": "https://doi.org/10.1145/3535457",
    "publication_date": "2022-05-10",
    "publication_year": 2022,
    "authors": "May Young; Alan J. Hu; Guy Lemieux",
    "corresponding_authors": "",
    "abstract": "Embedded systems are becoming increasingly complex and heterogeneous, featuring multiple processor cores (which might themselves be heterogeneous) as well as specialized hardware accelerators, all accessing shared memory. Many accelerators are non-coherent (i.e., do not support hardware cache coherence) because it reduces hardware complexity, cost, and power consumption, while potentially offering superior performance. However, the disadvantage of non-coherence is that the software must explicitly synchronize between accelerators and processors, and this synchronization is notoriously error-prone. We propose an analysis technique to find data races in software for heterogeneous systems that include non-coherent accelerators. Our approach builds on classical results for data race detection, but the challenge turns out to be analyzing cache behavior rather than the behavior of the non-coherent accelerators. Accordingly, our central contribution is a novel, sound (data-race-preserving) abstraction of cache behavior. We prove our abstraction sound, and then to demonstrate the precision of our abstraction, we implement it in a simple dynamic race detector for a system with a processor and a massively parallel accelerator provided by a commercial FPGA-based accelerator vendor. On eleven software examples provided by the vendor, the tool had zero false positives and was able to detect previously unknown data races in two of the 11 examples.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4280578181",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Memory and Storage Systems for Embedded and IoT Applications: Part 2",
    "doi": "https://doi.org/10.1145/3531707",
    "publication_date": "2022-05-28",
    "publication_year": 2022,
    "authors": "Yuan-Hao Chang; Jalil Boukhobza; Song Han",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4281703581",
    "type": "article"
  },
  {
    "title": "A Predictable QoS-aware Memory Request Scheduler for Soft Real-time Systems",
    "doi": "https://doi.org/10.1145/3561052",
    "publication_date": "2022-09-07",
    "publication_year": 2022,
    "authors": "Аладышев О.С.; Arnab Sarkar; Hemangee K. Kapoor",
    "corresponding_authors": "",
    "abstract": "A memory controller manages the flow of data to and from attached memory devices. The order in which a set of contending memory requests from different tasks are serviced significantly influences the rate of progress and completion times of these tasks. This in turn may affect the Quality-of-Service (QoS) delivered by these tasks. In this article, we focus towards the design of a QoS-aware memory controller targeted towards soft real-time systems. The proposed memory controller tries to generate an urgency-based schedule for the contending memory requests based on the allowable response time latencies associated with each request. The objective is to improve task-level response time predictability while maximizing acquired QoS. Exhaustive experiments carried out using real memory traces and standard simulation tools exhibit the practical efficacy of the proposed memory controller design.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4294877633",
    "type": "article"
  },
  {
    "title": "<scp>SAT-Reach</scp> : A Bounded Model Checker for Affine Hybrid Systems",
    "doi": "https://doi.org/10.1145/3567425",
    "publication_date": "2022-10-08",
    "publication_year": 2022,
    "authors": "A. Kundu; Sarthak Das; R. L. Ray",
    "corresponding_authors": "",
    "abstract": "Bounded model checking (BMC) is well-known to be undecidable even for simple hybrid systems. Existing work targeted for a wide class of non-linear hybrid systems reduces the BMC problem to the satisfiability problem of an satisfiability modulo theory formula encoding the hybrid system dynamics. Consequently, the satisfiability of the formula is deduced with a δ-decision procedure. However, the encoded formula can be complex for large automaton and for deep exploration causing the decision procedure to be inefficient. Additionally, a generalized decision procedure can be inefficient for hybrid systems with simple dynamics. In this article, we propose a BMC algorithm built upon the foundation of the counter example guided abstraction refinement (CEGAR) technique and targeted for hybrid systems with piecewise affine dynamics, modeled as a hybrid automaton. In particular, our algorithm begins by searching an abstract counterexample in the discrete state-space of the automaton. We check whether a discovered abstract counterexample is spurious or real by a two-tier refinement of the state-space guided by the abstract counterexample. The primary refinement is through symbolic reachability analysis and the following refinement is via a search of a real counterexample by the trajectory splicing method, guided in turn by the outcome of reachability analysis. We show that our algorithm reaps the benefits of the CEGAR technique by directing the exploration in the regions of interest and pruning search space that is irrelevant to the property under consideration. In addition, an optimization by memoizing the computed symbolic states during reachability analysis has been proposed for efficiency. The proposed algorithm is implemented in the tool SAT-Reach, and we compare its performance with dReach , XSpeed , Flow* , SpaceEx, and a pattern database heuristic-guided search algorithm. Experiments demonstrate the efficacy of our algorithm.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4303647457",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Accelerating AI on the Edge – Part 2",
    "doi": "https://doi.org/10.1145/3563127",
    "publication_date": "2022-11-30",
    "publication_year": 2022,
    "authors": "Muhammad Shafique; Theocharis Theocharides; Hai Li; Chun Jason Xue",
    "corresponding_authors": "",
    "abstract": "Introduction to the Special Issue on Accelerating AI on the Edge -Part 2Machine Learning (ML) is nowadays embedded in several computing devices, consumer electronics, and cyber-physical systems.Smart sensors are deployed everywhere, in applications such as autonomous vehicles, robotics, wearables, and perceptual computing devices, and intelligent algorithms power our connected world.These devices collect and aggregate volumes of data, and in doing so, they augment our society in multiple ways; from healthcare, to social networks, to consumer electronics and many more.To process these immense volumes of data, machine learning is emerging as the de facto analysis tool, that powers several aspects of our Big Data society.Applications spanning from infrastructure (smart agriculture, smart cities, intelligent transportation systems, smart grids, to name a few), to social networks and content delivery, to ecommerce and smart factories, and emerging concepts such as self-driving cars and autonomous/ assistive robots, are powered by advanced machine learning technologies.These emerging systems require real-time inference and decision support; such scenarios therefore may use customized hardware accelerators, are typically bound by limited compute, memory and energy resources, and are restricted to limited connectivity and bandwidth.Thus, near-sensor computation and near-sensor intelligence are starting to emerge as necessities, in order to continue supporting the paradigm shift of our connected world.The need for real-time intelligent data analytics (especially in the era of Big Data) for decision support near the data acquisition points, emphasizes the need of revolutionizing the way we design, build, test and verify processors, accelerators, and systems that facilitate machine learning (and deep learning in particular) implemented in resource-constrained environments for use at the edge and the fog.As such, traditional Von Neumann architectures may no longer be sufficient and suitable, primarily because of limitations in both performance and energy efficiency caused especially by large amounts of data movement.Furthermore, due to the connected and critical nature of such systems, security and reliability are also critically important.To facilitate AI at the edge, we need to re-focus on problems such as design, verification, architecture, scheduling and allocation policies, optimization, and many more, for determining the most efficient way to implement these novel applications within a resource-constrained system, which may or may not be connected.Acceleration of AI at the edge therefore, is a fast-growing field of machine learning technologies and applications including algorithms, hardware, and software capable of performing on-device sensor (vision, audio, IMU, biomedical, etc.) data analytics at extremely low power, typically in the mW range and below, and hence enabling a variety of always-on use-cases and targeting batteryoperated devices.This special issue therefore targets research at the intersection of AI/machine",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4311254205",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Accelerating AI on the Edge – Part 1",
    "doi": "https://doi.org/10.1145/3558078",
    "publication_date": "2022-09-30",
    "publication_year": 2022,
    "authors": "Muhammad Shafique; Theocharis Theocharides; Hai Li; Chun Jason Xue",
    "corresponding_authors": "",
    "abstract": "Special Issue Part 1 (Issue 3) and Part 2 (Issue 4) of AIEDAM are based on a workshop on Learning and Creativity held at the 2002 conference on Artificial Intelligence in Design, AID '02 (www.cad.strath.ac.uk/AID02_workshop/Workshop_webpage.html; Gero, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4312592987",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Specification and Design Languages (FDL 2019)",
    "doi": "https://doi.org/10.1145/3458748",
    "publication_date": "2021-05-29",
    "publication_year": 2021,
    "authors": "Alain Girault; Reinhard von Hanxleden",
    "corresponding_authors": "",
    "abstract": "editorial Free Access Share on Introduction to the Special Issue on Specification and Design Languages (FDL 2019) Authors: Alain Girault Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIGView Profile , Reinhard Von Hanxleden Dept. of Computer Science, Kiel University Dept. of Computer Science, Kiel UniversityView Profile Authors Info & Claims ACM Transactions on Embedded Computing SystemsVolume 20Issue 4July 2021 Article No.: 27pp 1–3https://doi.org/10.1145/3458748Online:29 May 2021Publication History 0citation112DownloadsMetricsTotal Citations0Total Downloads112Last 12 Months112Last 6 weeks9 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3166229024",
    "type": "article"
  },
  {
    "title": "SystemC Implementation of Stochastic Petri Nets for Simulation and Parameterization of Biological Networks",
    "doi": "https://doi.org/10.1145/3427091",
    "publication_date": "2021-05-29",
    "publication_year": 2021,
    "authors": "Nicola Bombieri; Silvia Scaffeo; Antonio Mastrandrea; Simone Caligola; Tommaso Carlucci; Franco Fummi; Carlo Laudanna; Gabriela Constantin; Rosalba Giugno",
    "corresponding_authors": "",
    "abstract": "Model development and simulation of biological networks is recognized as a key task in Systems Biology. Integrated with in vitro and in vivo experimental data, network simulation allows for the discovery of the dynamics that regulate biological systems. Stochastic Petri Nets (SPNs) have become a widespread and reference formalism to model metabolic networks thanks to their natural expressiveness to represent metabolites, reactions, molecule interactions, and simulation randomness due to system fluctuations and environmental noise. In the literature, starting from the network model and the complete set of system parameters, there exist frameworks that allow for dynamic system simulation. Nevertheless, they do not allow for automatic model parameterization, which is a crucial task to identify, in silico, the network configurations that lead the model to satisfy specific temporal properties. To cover such a gap, this work first presents a framework to implement SPN models into SystemC code. Then, it shows how the framework allows for automatic parameterization of the networks. The user formally defines the network properties to be observed and the framework automatically extrapolates, through Assertion-based Verification (ABV), the parameter configurations that satisfy such properties. We present the results obtained by applying the proposed framework to model the complex metabolic network of the purine metabolism. We show how the automatic extrapolation of the system parameters allowed us to simulate the model under different conditions, which led to the understanding of behavioral differences in the regulation of the entire purine network. We also show the scalability of the approach through the modeling and simulation of four biological networks, each one with different structural characteristics.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3166453917",
    "type": "article"
  },
  {
    "title": "エッジデバイスによる宇宙航空電子機器における性能-電力-プログラム可能性の改善:Myriad2 SoC上のVBN【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2021-01-01",
    "publication_year": 2021,
    "authors": "Leon Vasileios; Lentaris George; Petrongonas Evangelos; Soudris Dimitrios; Furano Gianluca; Antonis Tavoularis; Moloney David",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3208317416",
    "type": "article"
  }
]
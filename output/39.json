[
  {
    "title": "Evaluating collaborative filtering recommender systems",
    "doi": "https://doi.org/10.1145/963770.963772",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Jonathan L. Herlocker; Joseph A. Konstan; Loren Terveen; John Riedl",
    "corresponding_authors": "",
    "abstract": "Recommender systems have been evaluated in many, often incomparable, ways. In this article, we review the key decisions in evaluating collaborative filtering recommender systems: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole. In addition to reviewing the evaluation strategies used by prior researchers, we present empirical results from the analysis of various accuracy metrics on one content domain where all the tested metrics collapsed roughly into three equivalence classes. Metrics within each equivalency class were strongly correlated, while metrics from different equivalency classes were uncorrelated.",
    "cited_by_count": 5700,
    "openalex_id": "https://openalex.org/W1971040550",
    "type": "article"
  },
  {
    "title": "Cumulated gain-based evaluation of IR techniques",
    "doi": "https://doi.org/10.1145/582415.582418",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Kalervo Järvelin; Jaana Kekäläinen",
    "corresponding_authors": "",
    "abstract": "Modern large retrieval environments tend to overwhelm their users by their large output. Since all documents are not of equal relevance to their users, highly relevant documents should be identified and ranked first for presentation. In order to develop IR techniques in this direction, it is necessary to develop evaluation approaches and methods that credit IR methods for their ability to retrieve highly relevant documents. This can be done by extending traditional evaluation methods, that is, recall and precision based on binary relevance judgments, to graded relevance judgments. Alternatively, novel measures based on graded relevance judgments may be developed. This article proposes several novel measures that compute the cumulative gain the user obtains by examining the retrieval result up to a given ranked position. The first one accumulates the relevance scores of retrieved documents along the ranked result list. The second one is similar but applies a discount factor to the relevance scores in order to devaluate late-retrieved documents. The third one computes the relative-to-the-ideal performance of IR techniques, based on the cumulative gain they are able to yield. These novel measures are defined and discussed and their use is demonstrated in a case study using TREC data: sample system run results for 20 queries in TREC-7. As a relevance base we used novel graded relevance judgments on a four-point scale. The test results indicate that the proposed measures credit IR methods for their ability to retrieve highly relevant documents and allow testing of statistical significance of effectiveness differences. The graphs based on the measures also provide insight into the performance IR techniques and allow interpretation, for example, from the user point of view.",
    "cited_by_count": 4456,
    "openalex_id": "https://openalex.org/W2069870183",
    "type": "article"
  },
  {
    "title": "The active badge location system",
    "doi": "https://doi.org/10.1145/128756.128759",
    "publication_date": "1992-01-02",
    "publication_year": 1992,
    "authors": "Roy Want; Andy Hopper; Veronica Falcão; Jonathan Gibbons",
    "corresponding_authors": "",
    "abstract": "A novel system for the location of people in an office environment is described. Members of staff wear badges that transmit signals providing information about their location to a centralized location service, through a network of sensors. The paper also examines alternative location techniques, system design issues and applications, particularly relating to telephone call routing. Location systems raise concerns about the privacy of an individual and these issues are also addressed.",
    "cited_by_count": 3851,
    "openalex_id": "https://openalex.org/W2094204865",
    "type": "article"
  },
  {
    "title": "Item-based top-<i>N</i>recommendation algorithms",
    "doi": "https://doi.org/10.1145/963770.963776",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Mukund Deshpande; George Karypis",
    "corresponding_authors": "",
    "abstract": "The explosive growth of the world-wide-web and the emergence of e-commerce has led to the development of recommender systems ---a personalized information filtering technology used to identify a set of items that will be of interest to a certain user. User-based collaborative filtering is the most successful technology for building recommender systems to date and is extensively used in many commercial recommender systems. Unfortunately, the computational complexity of these methods grows linearly with the number of customers, which in typical commercial applications can be several millions. To address these scalability concerns model-based recommendation techniques have been developed. These techniques analyze the user--item matrix to discover relations between the different items and use these relations to compute the list of recommendations.In this article, we present one such class of model-based recommendation algorithms that first determines the similarities between the various items and then uses them to identify the set of items to be recommended. The key steps in this class of algorithms are (i) the method used to compute the similarity between the items, and (ii) the method used to combine these similarities in order to compute the similarity between a basket of items and a candidate recommender item. Our experimental evaluation on eight real datasets shows that these item-based algorithms are up to two orders of magnitude faster than the traditional user-neighborhood based recommender systems and provide recommendations with comparable or better quality.",
    "cited_by_count": 2168,
    "openalex_id": "https://openalex.org/W2142144955",
    "type": "article"
  },
  {
    "title": "Technological frames",
    "doi": "https://doi.org/10.1145/196734.196745",
    "publication_date": "1994-04-01",
    "publication_year": 1994,
    "authors": "Wanda J. Orlikowski; Debra C. Gash",
    "corresponding_authors": "",
    "abstract": "In this article, we build on and extend research into the cognitions and values of users and designers by proposing a systematic approach for examining the underlying assumptions, expectations, and knowledge that people have about technology. Such interpretations of technology (which we call technological frames) are central to understanding technological development, use, and change in organizations. We suggest that where the technological frames of key groups in organizations—such as managers, technologists, and users— are significantly different, difficulties and conflict around the development, use, and change of technology may result. We use the findings of an empirical study to illustrate how the nature, value, and use of a groupware technology were interpreted by various organizational stakeholders, resulting in outcomes that deviated from those expected. We argue that technological frames offer an interesting and useful analytic perspective for explaining an anticipating actions and meanings that are not easily obtained with other theoretical lenses.",
    "cited_by_count": 1716,
    "openalex_id": "https://openalex.org/W2127089424",
    "type": "article"
  },
  {
    "title": "Measuring praise and criticism",
    "doi": "https://doi.org/10.1145/944012.944013",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Peter D. Turney; Michael L. Littman",
    "corresponding_authors": "",
    "abstract": "The evaluative character of a word is called its semantic orientation . Positive semantic orientation indicates praise (e.g., \"honest\", \"intrepid\") and negative semantic orientation indicates criticism (e.g., \"disturbing\", \"superfluous\"). Semantic orientation varies in both direction (positive or negative) and degree (mild to strong). An automated system for measuring semantic orientation would have application in text classification, text filtering, tracking opinions in online discussions, analysis of survey responses, and automated chat systems ( chatbots ). This article introduces a method for inferring the semantic orientation of a word from its statistical association with a set of positive and negative paradigm words. Two instances of this approach are evaluated, based on two different statistical measures of word association: pointwise mutual information (PMI) and latent semantic analysis (LSA). The method is experimentally tested with 3,596 words (including adjectives, adverbs, nouns, and verbs) that have been manually labeled positive (1,614 words) and negative (1,982 words). The method attains an accuracy of 82.8% on the full test set, but the accuracy rises above 95% when the algorithm is allowed to abstain from classifying mild words.",
    "cited_by_count": 1536,
    "openalex_id": "https://openalex.org/W2168625136",
    "type": "article"
  },
  {
    "title": "Latent semantic models for collaborative filtering",
    "doi": "https://doi.org/10.1145/963770.963774",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Thomas Hofmann",
    "corresponding_authors": "Thomas Hofmann",
    "abstract": "Collaborative filtering aims at learning predictive models of user preferences, interests or behavior from community data, that is, a database of available user preferences. In this article, we describe a new family of model-based algorithms designed for this task. These algorithms rely on a statistical modelling technique that introduces latent class variables in a mixture model setting to discover user communities and prototypical interest profiles. We investigate several variations to deal with discrete and continuous response variables as well as with different objective functions. The main advantages of this technique over standard memory-based methods are higher accuracy, constant time prediction, and an explicit and compact model representation. The latter can also be used to mine for user communitites. The experimental evaluation shows that substantial improvements in accucracy over existing methods and published results can be obtained.",
    "cited_by_count": 1389,
    "openalex_id": "https://openalex.org/W2049455633",
    "type": "article"
  },
  {
    "title": "A study of smoothing methods for language models applied to information retrieval",
    "doi": "https://doi.org/10.1145/984321.984322",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "ChengXiang Zhai; John Lafferty",
    "corresponding_authors": "",
    "abstract": "Language modeling approaches to information retrieval are attractive and promising because they connect the problem of retrieval with that of language model estimation, which has been studied extensively in other application areas such as speech recognition. The basic idea of these approaches is to estimate a language model for each document, and to then rank documents by the likelihood of the query according to the estimated language model. A central issue in language model estimation is smoothing , the problem of adjusting the maximum likelihood estimator to compensate for data sparseness. In this article, we study the problem of language model smoothing and its influence on retrieval performance. We examine the sensitivity of retrieval performance to the smoothing parameters and compare several popular smoothing methods on different test collections. Experimental results show that not only is the retrieval performance generally sensitive to the smoothing parameters, but also the sensitivity pattern is affected by the query type, with performance being more sensitive to smoothing for verbose queries than for keyword queries. Verbose queries also generally require more aggressive smoothing to achieve optimal performance. This suggests that smoothing plays two different role---to make the estimated document language model more accurate and to \"explain\" the noninformative words in the query. In order to decouple these two distinct roles of smoothing, we propose a two-stage smoothing strategy, which yields better sensitivity patterns and facilitates the setting of smoothing parameters automatically. We further propose methods for estimating the smoothing parameters automatically. Evaluation on five different databases and four types of queries indicates that the two-stage smoothing method with the proposed parameter estimation methods consistently gives retrieval performance that is close to---or better than---the best results achieved using a single smoothing method and exhaustive parameter search on the test data.",
    "cited_by_count": 1235,
    "openalex_id": "https://openalex.org/W1972594981",
    "type": "article"
  },
  {
    "title": "Incorporating contextual information in recommender systems using a multidimensional approach",
    "doi": "https://doi.org/10.1145/1055709.1055714",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Gediminas Adomavičius; Ramesh Sankaranarayanan; Shahana Sen; Alexander Tuzhilin",
    "corresponding_authors": "",
    "abstract": "The article presents a multidimensional (MD) approach to recommender systems that can provide recommendations based on additional contextual information besides the typical information on users and items used in most of the current recommender systems. This approach supports multiple dimensions, profiling information, and hierarchical aggregation of recommendations. The article also presents a multidimensional rating estimation method capable of selecting two-dimensional segments of ratings pertinent to the recommendation context and applying standard collaborative filtering or other traditional two-dimensional rating estimation techniques to these segments. A comparison of the multidimensional and two-dimensional rating estimation approaches is made, and the tradeoffs between the two are studied. Moreover, the article introduces a combined rating estimation method, which identifies the situations where the MD approach outperforms the standard two-dimensional approach and uses the MD approach in those situations and the standard two-dimensional approach elsewhere. Finally, the article presents a pilot empirical study of the combined approach, using a multidimensional movie recommender system that was developed for implementing this approach and testing its performance.",
    "cited_by_count": 1192,
    "openalex_id": "https://openalex.org/W2112430581",
    "type": "article"
  },
  {
    "title": "gIBIS: a hypertext tool for exploratory policy discussion",
    "doi": "https://doi.org/10.1145/58566.59297",
    "publication_date": "1988-10-01",
    "publication_year": 1988,
    "authors": "Jeff Conklin; Michael L. Begeman",
    "corresponding_authors": "",
    "abstract": "This paper describes an application-specific hypertext system designed to facilitate the capture of early design deliberations. It implements a specific method, called Issue Based Information Systems (IBIS), which has been developed for use on large, complex design problems. The hypertext system described here, gIBIS (for graphical IBIS), makes use of color and a high-speed relational database server to facilitate building and browsing typed IBIS networks. Further, gIBIS is designed to support the collaborative construction of these networks by any number of cooperating team members spread across a local area network. Early experiments suggest that the IBIS method is still incomplete, but there is a good match between the tool and method even in this experimental version.",
    "cited_by_count": 1109,
    "openalex_id": "https://openalex.org/W2150531367",
    "type": "article"
  },
  {
    "title": "Placing search in context: the concept revisited.",
    "doi": null,
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Lev Finkelstein; Evgeniy Gabrilovich; Yossi Matias; Ehud Rivlin; Zach Solan; Gadi Wolfman; Eytan Ruppin",
    "corresponding_authors": "",
    "abstract": "Keyword-based search engines are in widespread use today as a popular means for Web-based information retrieval. Although such systems seem deceptively simple, a considerable amount of skill is required in order to satisfy non-trivial information needs. This paper presents a new conceptual paradigm for performing search in context, that largely automates the search process, providing even non-professional users with highly relevant results. This paradigm is implemented in practice in the IntelliZap system, where search is initiated from a text query marked by the user in a document she views, and is guided by the text surrounding the marked query in that document (“the context”). The context-driven information retrieval process involves semantic keyword extraction and clustering to automatically generate new, augmented queries. The latter are submitted to a host of general and domain-specific search engines. Search results are then semantically reranked, using context. Experimental results testify that using context to guide search, effectively offers even inexperienced users an advanced search tool on the Web.",
    "cited_by_count": 1015,
    "openalex_id": "https://openalex.org/W2053921957",
    "type": "article"
  },
  {
    "title": "Bias in computer systems",
    "doi": "https://doi.org/10.1145/230538.230561",
    "publication_date": "1996-07-01",
    "publication_year": 1996,
    "authors": "Batya Friedman; Helen Nissenbaum",
    "corresponding_authors": "",
    "abstract": "From an analysis of actual cases, three categories of bias in computer systems have been developed: preexisting, technical, and emergent. Preexisting bias has its roots in social institutions, practices, and attitudes. Technical bias arises from technical constraints of considerations. Emergent bias arises in a context of use. Although others have pointed to bias inparticular computer systems and have noted the general problem, we know of no comparable work that examines this phenomenon comprehensively and which offers a framework for understanding and remedying it. We conclude by suggesting that freedom from bias should by counted amoung the select set of criteria—including reliability, accuracy, and efficiency—according to which the quality of systems in use in society should be judged.",
    "cited_by_count": 1012,
    "openalex_id": "https://openalex.org/W2006447892",
    "type": "article"
  },
  {
    "title": "Sentiment analysis in multiple languages",
    "doi": "https://doi.org/10.1145/1361684.1361685",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Ahmed Abbasi; Hsinchun Chen; Arab Salem",
    "corresponding_authors": "",
    "abstract": "The Internet is frequently used as a medium for exchange of information and opinions, as well as propaganda dissemination. In this study the use of sentiment analysis methodologies is proposed for classification of Web forum opinions in multiple languages. The utility of stylistic and syntactic features is evaluated for sentiment classification of English and Arabic content. Specific feature extraction components are integrated to account for the linguistic characteristics of Arabic. The entropy weighted genetic algorithm (EWGA) is also developed, which is a hybridized genetic algorithm that incorporates the information-gain heuristic for feature selection. EWGA is designed to improve performance and get a better assessment of key features. The proposed features and techniques are evaluated on a benchmark movie review dataset and U.S. and Middle Eastern Web forum postings. The experimental results using EWGA with SVM indicate high performance levels, with accuracies of over 91% on the benchmark dataset as well as the U.S. and Middle Eastern forums. Stylistic features significantly enhanced performance across all testbeds while EWGA also outperformed other feature selection methods, indicating the utility of these features and techniques for document-level classification of sentiments.",
    "cited_by_count": 905,
    "openalex_id": "https://openalex.org/W2005624335",
    "type": "article"
  },
  {
    "title": "Probabilistic models of information retrieval based on measuring the divergence from randomness",
    "doi": "https://doi.org/10.1145/582415.582416",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Giambattista Amati; Cornelis J. van Rijsbergen",
    "corresponding_authors": "",
    "abstract": "We introduce and create a framework for deriving probabilistic models of Information Retrieval. The models are nonparametric models of IR obtained in the language model approach. We derive term-weighting models by measuring the divergence of the actual term distribution from that obtained under a random process. Among the random processes we study the binomial distribution and Bose--Einstein statistics. We define two types of term frequency normalization for tuning term weights in the document--query matching process. The first normalization assumes that documents have the same length and measures the information gain with the observed term once it has been accepted as a good descriptor of the observed document. The second normalization is related to the document length and to other statistics. These two normalization methods are applied to the basic models in succession to obtain weighting formulae. Results show that our framework produces different nonparametric models forming baseline alternatives to the standard tf-idf model.",
    "cited_by_count": 895,
    "openalex_id": "https://openalex.org/W2105157020",
    "type": "article"
  },
  {
    "title": "Automated learning of decision rules for text categorization",
    "doi": "https://doi.org/10.1145/183422.183423",
    "publication_date": "1994-07-01",
    "publication_year": 1994,
    "authors": "Chidanand Apté; Fred J. Damerau; Sholom M. Weiss",
    "corresponding_authors": "",
    "abstract": "We describe the results of extensive experiments using optimized rule-based induction methods on large document collections. The goal of these methods is to discover automatically classification patterns that can be used for general document categorization or personalized filtering of free text. Previous reports indicate that human-engineered rule-based systems, requiring many man-years of developmental efforts, have been successfully built to “read” documents and assign topics to them. We show that machine-generated decision rules appear comparable to human performance, while using the identical rule-based representation. In comparison with other machine-learning techniques, results on a key benchmark from the Reuters collection show a large gain in performance, from a previously reported 67% recall/precision breakeven point to 80.5%. In the context of a very high-dimensional feature space, several methodological alternatives are examined, including universal versus local dictionaries, and binary versus frequency-related features.",
    "cited_by_count": 879,
    "openalex_id": "https://openalex.org/W2094934653",
    "type": "article"
  },
  {
    "title": "The use of eye movements in human-computer interaction techniques",
    "doi": "https://doi.org/10.1145/123078.128728",
    "publication_date": "1991-04-01",
    "publication_year": 1991,
    "authors": "Robert J. K. Jacob",
    "corresponding_authors": "Robert J. K. Jacob",
    "abstract": "article Free Access Share on The use of eye movements in human-computer interaction techniques: what you look at is what you get Author: Robert J. K. Jacob Naval Research Loboratory Naval Research LoboratoryView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 9Issue 2pp 152–169https://doi.org/10.1145/123078.128728Published:01 April 1991Publication History 673citation7,124DownloadsMetricsTotal Citations673Total Downloads7,124Last 12 Months686Last 6 weeks102 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 832,
    "openalex_id": "https://openalex.org/W2110228188",
    "type": "article"
  },
  {
    "title": "How do people organize their desks?",
    "doi": "https://doi.org/10.1145/357423.357430",
    "publication_date": "1983-01-01",
    "publication_year": 1983,
    "authors": "Thomas W. Malone",
    "corresponding_authors": "Thomas W. Malone",
    "abstract": "article Free AccessHow do people organize their desks?: Implications for the design of office information systems Author: Thomas W. Malone Xerox PARC, 3333 Coyote Hill Road, Palo Alto, CA Xerox PARC, 3333 Coyote Hill Road, Palo Alto, CAView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 1Jan. 1983 pp 99–112https://doi.org/10.1145/357423.357430Published:01 January 1983Publication History 537citation7,332DownloadsMetricsTotal Citations537Total Downloads7,332Last 12 Months828Last 6 weeks384 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 815,
    "openalex_id": "https://openalex.org/W2156492599",
    "type": "article"
  },
  {
    "title": "Telos: representing knowledge about information systems",
    "doi": "https://doi.org/10.1145/102675.102676",
    "publication_date": "1990-10-01",
    "publication_year": 1990,
    "authors": "John Mylopoulos; Alex Borgida; Matthias Jarke; Manolis Koubarakis",
    "corresponding_authors": "",
    "abstract": "We describe Telos, a language intended to support the development of information systems. The design principles for the language are based on the premise that information system development is knowledge intensive and that the primary responsibility of any language intended for the task is to be able to formally represent the relevent knowledge. Accordingly, the proposed language is founded on concepts from knowledge representations. Indeed, the language is appropriate for representing knowledge about a variety of worlds related to a particular information system, such as the subject world (application domain), the usage world (user models, environments), the system world (software requirements, design), and the development world (teams, metodologies). We introduce the features of the language through examples, focusing on those provided for desribing metaconcepts that can then be used to describe knowledge relevant to a particular information system. Telos' fetures include an object-centered framework which supports aggregation, generalization, and classification; a novel treatment of attributes; an explicit representation of time; and facilities for specifying integrity constraints and deductive rules. We review actual applications of the language through further examples, and we sketch a formalization of the language.",
    "cited_by_count": 798,
    "openalex_id": "https://openalex.org/W2079814255",
    "type": "article"
  },
  {
    "title": "Interpreting TF-IDF term weights as making relevance decisions",
    "doi": "https://doi.org/10.1145/1361684.1361686",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Jack Wu; Robert W. P. Luk; Kam‐Fai Wong; K. L. Kwok",
    "corresponding_authors": "",
    "abstract": "A novel probabilistic retrieval model is presented. It forms a basis to interpret the TF-IDF term weights as making relevance decisions. It simulates the local relevance decision-making for every location of a document, and combines all of these “local” relevance decisions as the “document-wide” relevance decision for the document. The significance of interpreting TF-IDF in this way is the potential to: (1) establish a unifying perspective about information retrieval as relevance decision-making; and (2) develop advanced TF-IDF-related term weights for future elaborate retrieval models. Our novel retrieval model is simplified to a basic ranking formula that directly corresponds to the TF-IDF term weights. In general, we show that the term-frequency factor of the ranking formula can be rendered into different term-frequency factors of existing retrieval systems. In the basic ranking formula, the remaining quantity - log p (r¯| t ∈ d ) is interpreted as the probability of randomly picking a nonrelevant usage (denoted by r¯) of term t . Mathematically, we show that this quantity can be approximated by the inverse document-frequency (IDF). Empirically, we show that this quantity is related to IDF, using four reference TREC ad hoc retrieval data collections.",
    "cited_by_count": 793,
    "openalex_id": "https://openalex.org/W1965667542",
    "type": "article"
  },
  {
    "title": "Textual analysis of stock market prediction using breaking financial news",
    "doi": "https://doi.org/10.1145/1462198.1462204",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Robert P. Schumaker; Hsinchun Chen",
    "corresponding_authors": "",
    "abstract": "Our research examines a predictive machine learning approach for financial news articles analysis using several different textual representations: bag of words, noun phrases, and named entities. Through this approach, we investigated 9,211 financial news articles and 10,259,042 stock quotes covering the S&amp;P 500 stocks during a five week period. We applied our analysis to estimate a discrete stock price twenty minutes after a news article was released. Using a support vector machine (SVM) derivative specially tailored for discrete numeric prediction and models containing different stock-specific variables, we show that the model containing both article terms and stock price at the time of article release had the best performance in closeness to the actual future stock price (MSE 0.04261), the same direction of price movement as the future price (57.1% directional accuracy) and the highest return using a simulated trading engine (2.06% return). We further investigated the different textual representations and found that a Proper Noun scheme performs better than the de facto standard of Bag of Words in all three metrics.",
    "cited_by_count": 743,
    "openalex_id": "https://openalex.org/W2015174807",
    "type": "article"
  },
  {
    "title": "Ontological user profiling in recommender systems",
    "doi": "https://doi.org/10.1145/963770.963773",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Stuart E. Middleton; N. R. Shadbolt; David De Roure",
    "corresponding_authors": "",
    "abstract": "We explore a novel ontological approach to user profiling within recommender systems, working on the problem of recommending on-line academic research papers. Our two experimental systems, Quickstep and Foxtrot, create user profiles from unobtrusively monitored behaviour and relevance feedback, representing the profiles in terms of a research paper topic ontology. A novel profile visualization approach is taken to acquire profile feedback. Research papers are classified using ontological classes and collaborative recommendation algorithms used to recommend papers seen by similar people on their current topics of interest. Two small-scale experiments, with 24 subjects over 3 months, and a large-scale experiment, with 260 subjects over an academic year, are conducted to evaluate different aspects of our approach. Ontological inference is shown to improve user profiling, external ontological knowledge used to successfully bootstrap a recommender system and profile visualization employed to improve profiling accuracy. The overall performance of our ontological recommender systems are also presented and favourably compared to other systems in the literature.",
    "cited_by_count": 718,
    "openalex_id": "https://openalex.org/W2040974535",
    "type": "article"
  },
  {
    "title": "A similarity measure for indefinite rankings",
    "doi": "https://doi.org/10.1145/1852102.1852106",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "William Webber; Alistair Moffat; Justin Zobel",
    "corresponding_authors": "",
    "abstract": "Ranked lists are encountered in research and daily life and it is often of interest to compare these lists even when they are incomplete or have only some members in common. An example is document rankings returned for the same query by different search engines. A measure of the similarity between incomplete rankings should handle nonconjointness, weight high ranks more heavily than low, and be monotonic with increasing depth of evaluation; but no measure satisfying all these criteria currently exists. In this article, we propose a new measure having these qualities, namely rank-biased overlap (RBO). The RBO measure is based on a simple probabilistic user model. It provides monotonicity by calculating, at a given depth of evaluation, a base score that is non-decreasing with additional evaluation, and a maximum score that is nonincreasing. An extrapolated score can be calculated between these bounds if a point estimate is required. RBO has a parameter which determines the strength of the weighting to top ranks. We extend RBO to handle tied ranks and rankings of different lengths. Finally, we give examples of the use of the measure in comparing the results produced by public search engines and in assessing retrieval systems in the laboratory.",
    "cited_by_count": 705,
    "openalex_id": "https://openalex.org/W2021581601",
    "type": "article"
  },
  {
    "title": "An iterative design methodology for user-friendly natural language office information applications",
    "doi": "https://doi.org/10.1145/357417.357420",
    "publication_date": "1984-01-01",
    "publication_year": 1984,
    "authors": "John F. Kelley",
    "corresponding_authors": "John F. Kelley",
    "abstract": "article Free Access Share on An iterative design methodology for user-friendly natural language office information applications Author: J. F. Kelley IBM, Thomas J. Watson Research Center, Room ST-K40, P.O. Box 218, Yorktown Heights, NY IBM, Thomas J. Watson Research Center, Room ST-K40, P.O. Box 218, Yorktown Heights, NYView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 1Jan. 1984 pp 26–41https://doi.org/10.1145/357417.357420Published:01 January 1984Publication History 391citation3,831DownloadsMetricsTotal Citations391Total Downloads3,831Last 12 Months506Last 6 weeks54 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 691,
    "openalex_id": "https://openalex.org/W1969152782",
    "type": "article"
  },
  {
    "title": "HDM—a model-based approach to hypertext application design",
    "doi": "https://doi.org/10.1145/151480.151483",
    "publication_date": "1993-01-02",
    "publication_year": 1993,
    "authors": "Franca Garzotto; Paolo Paolini; Daniel Schwabe",
    "corresponding_authors": "",
    "abstract": "Hypertext development should benefit from a systematic, structured development, especially in the case of large and complex applications. A structured approach to hypertext development suggests the notion of authoring-in-the-large . Authoring-in-the-large allows the description of overall classes of information elements and navigational structures of complex applications without much concern with implementation details, and in a system-independent manner. The paper presents HDM (Hypertext Design Model), a first step towards defining a general purpose model for authoring-in-the-large. Some of the most innovative features of HDM are: the notion of perspective ; the identification of different categories of links (structural links, application links, and perspective links) with different representational roles; the distinction between hyperbase and access structures ; and the possibility of easily integrating the structure of a hypertext application with its browsing semantics. HDM can be used in different manners: as a modeling device or as an implementation device. As a modeling device, it supports producing high level specifications of existing or to-be-developed applications. As an implementation device, it is the basis for designing tools that directly support application development. One of the central advantages of HDM in the design and practical construction of hypertext applications is that the definition of a significant number of links can be derived automatically from a conceptual-design level description. Examples of usage of HDM are also included.",
    "cited_by_count": 688,
    "openalex_id": "https://openalex.org/W2083583325",
    "type": "article"
  },
  {
    "title": "Evaluating the accuracy of implicit feedback from clicks and query reformulations in Web search",
    "doi": "https://doi.org/10.1145/1229179.1229181",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Thorsten Joachims; Laura Granka; Bing Pan; Helene Hembrooke; Filip Radlinski; Geri Gay",
    "corresponding_authors": "",
    "abstract": "This article examines the reliability of implicit feedback generated from clickthrough data and query reformulations in World Wide Web (WWW) search. Analyzing the users' decision process using eyetracking and comparing implicit feedback against manual relevance judgments, we conclude that clicks are informative but biased. While this makes the interpretation of clicks as absolute relevance judgments difficult, we show that relative preferences derived from clicks are reasonably accurate on average. We find that such relative preferences are accurate not only between results from an individual query, but across multiple sets of results within chains of query reformulations.",
    "cited_by_count": 672,
    "openalex_id": "https://openalex.org/W1974360117",
    "type": "article"
  },
  {
    "title": "Applying associative retrieval techniques to alleviate the sparsity problem in collaborative filtering",
    "doi": "https://doi.org/10.1145/963770.963775",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Zan Huang; Hsinchun Chen; Daniel Zeng",
    "corresponding_authors": "",
    "abstract": "Recommender systems are being widely applied in many application settings to suggest products, services, and information items to potential consumers. Collaborative filtering, the most successful recommendation approach, makes recommendations based on past transactions and feedback from consumers sharing similar interests. A major problem limiting the usefulness of collaborative filtering is the sparsity problem, which refers to a situation in which transactional or feedback data is sparse and insufficient to identify similarities in consumer interests. In this article, we propose to deal with this sparsity problem by applying an associative retrieval framework and related spreading activation algorithms to explore transitive associations among consumers through their past transactions and feedback. Such transitive associations are a valuable source of information to help infer consumer interests and can be explored to deal with the sparsity problem. To evaluate the effectiveness of our approach, we have conducted an experimental study using a data set from an online bookstore. We experimented with three spreading activation algorithms including a constrained Leaky Capacitor algorithm, a branch-and-bound serial symbolic search algorithm, and a Hopfield net parallel relaxation search algorithm. These algorithms were compared with several collaborative filtering approaches that do not consider the transitive associations: a simple graph search approach, two variations of the user-based approach, and an item-based approach. Our experimental results indicate that spreading activation-based approaches significantly outperformed the other collaborative filtering methods as measured by recommendation precision, recall, the F-measure, and the rank score. We also observed the over-activation effect of the spreading activation approach, that is, incorporating transitive associations with past transactional data that is not sparse may \"dilute\" the data used to infer user preferences and lead to degradation in recommendation performance.",
    "cited_by_count": 655,
    "openalex_id": "https://openalex.org/W2169757306",
    "type": "article"
  },
  {
    "title": "Rank-biased precision for measurement of retrieval effectiveness",
    "doi": "https://doi.org/10.1145/1416950.1416952",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Alistair Moffat; Justin Zobel",
    "corresponding_authors": "",
    "abstract": "A range of methods for measuring the effectiveness of information retrieval systems has been proposed. These are typically intended to provide a quantitative single-value summary of a document ranking relative to a query. However, many of these measures have failings. For example, recall is not well founded as a measure of satisfaction, since the user of an actual system cannot judge recall. Average precision is derived from recall, and suffers from the same problem. In addition, average precision lacks key stability properties that are needed for robust experiments. In this article, we introduce a new effectiveness metric, rank-biased precision , that avoids these problems. Rank-biased pre-cision is derived from a simple model of user behavior, is robust if answer rankings are extended to greater depths, and allows accurate quantification of experimental uncertainty, even when only partial relevance judgments are available.",
    "cited_by_count": 605,
    "openalex_id": "https://openalex.org/W1968927634",
    "type": "article"
  },
  {
    "title": "Evaluation of an inference network-based retrieval model",
    "doi": "https://doi.org/10.1145/125187.125188",
    "publication_date": "1991-07-01",
    "publication_year": 1991,
    "authors": "Howard R. Turtle; W. Bruce Croft",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Evaluation of an inference network-based retrieval model Authors: Howard Turtle Univ. of Massachusetts, Amherst Univ. of Massachusetts, AmherstView Profile , W. Bruce Croft Univ. of Massachusetts, Amherst Univ. of Massachusetts, AmherstView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 9Issue 3pp 187–222https://doi.org/10.1145/125187.125188Published:01 July 1991Publication History 386citation2,513DownloadsMetricsTotal Citations386Total Downloads2,513Last 12 Months73Last 6 weeks17 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 592,
    "openalex_id": "https://openalex.org/W2078875869",
    "type": "article"
  },
  {
    "title": "Data model issues for object-oriented applications",
    "doi": "https://doi.org/10.1145/22890.22945",
    "publication_date": "1987-01-01",
    "publication_year": 1987,
    "authors": "Jay Banerjee; Hong‐Tai Chou; Jorge F. Garza; Won Bae Kim; Darrell Woelk; Nat Ballou; Hyoung-Joo Kim",
    "corresponding_authors": "",
    "abstract": "Presented in this paper is the data model for ORION, a prototype database system that adds persistence and sharability to objects created and manipulated in object-oriented applications. The ORION data model consolidates and modifies a number of major concepts found in many object-oriented systems, such as objects, classes, class lattice, methods, and inheritance. These concepts are reviewed and three major enhancements to the conventional object-oriented data model, namely, schema evolution, composite objects, and versions, are elaborated upon. Schema evolution is the ability to dynamically make changes to the class definitions and the structure of the class lattice. Composite objects are recursive collections of exclusive components that are treated as units of storage, retrieval, and integrity enforcement. Versions are variations of the same object that are related by the history of their derivation. These enhancements are strongly motivated by the data management requirements of the ORION applications from the domains of artificial intelligence, computer-aided design and manufacturing, and office information systems with multimedia documents.",
    "cited_by_count": 585,
    "openalex_id": "https://openalex.org/W2026735162",
    "type": "article"
  },
  {
    "title": "Evaluating implicit measures to improve web search",
    "doi": "https://doi.org/10.1145/1059981.1059982",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Steve Fox; Kuldeep Karnawat; Mark Mydland; Susan Dumais; Thomas White",
    "corresponding_authors": "",
    "abstract": "Of growing interest in the area of improving the search experience is the collection of implicit user behavior measures (implicit measures) as indications of user interest and user satisfaction. Rather than having to submit explicit user feedback, which can be costly in time and resources and alter the pattern of use within the search experience, some research has explored the collection of implicit measures as an efficient and useful alternative to collecting explicit measure of interest from users.This research article describes a recent study with two main objectives. The first was to test whether there is an association between explicit ratings of user satisfaction and implicit measures of user interest. The second was to understand what implicit measures were most strongly associated with user satisfaction. The domain of interest was Web search. We developed an instrumented browser to collect a variety of measures of user activity and also to ask for explicit judgments of the relevance of individual pages visited and entire search sessions. The data was collected in a workplace setting to improve the generalizability of the results.Results were analyzed using traditional methods (e.g., Bayesian modeling and decision trees) as well as a new usage behavior pattern analysis (“gene analysis”). We found that there was an association between implicit measures of user activity and the user's explicit satisfaction ratings. The best models for individual pages combined clickthrough, time spent on the search result page, and how a user exited a result or ended a search session (exit type/end action). Behavioral patterns (through the gene analysis) can also be used to predict user satisfaction for search sessions.",
    "cited_by_count": 578,
    "openalex_id": "https://openalex.org/W2123937625",
    "type": "article"
  },
  {
    "title": "A federated architecture for information management",
    "doi": "https://doi.org/10.1145/4229.4233",
    "publication_date": "1985-07-01",
    "publication_year": 1985,
    "authors": "Dennis Heimbigner; Dennis McLeod",
    "corresponding_authors": "",
    "abstract": "An approach to the coordinated sharing and interchange of computerized information is described emphasizing partial, controlled sharing among autonomous databases. Office information systems provide a particularly appropriate context for this type of information sharing and exchange. A federated database architecture is described in which a collection of independent database systems are united into a loosely coupled federation in order to share and exchange information. A federation consists of components (of which there may be any number) and a single federal dictionary. The components represent individual users, applications, workstations, or other components in an office information system. The federal dictionary is a specialized component that maintains the topology of the federation and oversees the entry of new components. Each component in the federation controls its interactions with other components by means of an export schema and an import schema. The export schema specifies the information that a component will share with other components, while the import schema specifies the nonlocal information that a component wishes to manipulate. The federated architecture provides mechanisms for sharing data, for sharing transactions (via message types) for combining information from several components, and for coordinating activities among autonomous components (via negotiation). A prototype implementation of the federated database mechanism is currently operational on an experimental basis.",
    "cited_by_count": 560,
    "openalex_id": "https://openalex.org/W2162520370",
    "type": "article"
  },
  {
    "title": "Improving the effectiveness of information retrieval with local context analysis",
    "doi": "https://doi.org/10.1145/333135.333138",
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "Jinxi Xu; W. Bruce Croft",
    "corresponding_authors": "",
    "abstract": "Techniques for automatic query expansion have been extensively studied in information research as a means of addressing the word mismatch between queries and documents. These techniques can be categorized as either global or local. While global techniques rely on analysis of a whole collection to discover word relationships, local techniques emphasize analysis of the top-ranked documents retrieved for a query. While local techniques have shown to be more effective that global techniques in general, existing local techniques are not robust and can seriously hurt retrieved when few of the retrieval documents are relevant. We propose a new technique, called local context analysis, which selects expansion terms based on cooccurrence with the query terms within the top-ranked documents. Experiments on a number of collections, both English and non-English, show that local context analysis offers more effective and consistent retrieval results.",
    "cited_by_count": 553,
    "openalex_id": "https://openalex.org/W2002306339",
    "type": "article"
  },
  {
    "title": "WYSIWIS revised: early experiences with multiuser interfaces",
    "doi": "https://doi.org/10.1145/27636.28056",
    "publication_date": "1987-04-01",
    "publication_year": 1987,
    "authors": "Mark Stefik; Daniel G. Bobrow; Gregg Foster; Stan Lanning; Deborah Tatar",
    "corresponding_authors": "",
    "abstract": "WYSIWIS (What You See Is What I See) is a foundational abstraction for multiuser interfaces that expresses many of the characteristics of a chalkboard in face-to-face meetings. In its strictest interpretation, it means that everyone can also see the same written information and also see where anyone else is pointing. In our attempts to build software support for collaboration in meetings, we have discovered that WYSIWIS is crucial, yet too inflexible when strictly enforced. This paper is about the design issues and choices that arose in our first generation of meeting tools based on WYSIWIS. Several examples of multiuser interfaces that start from this abstraction are presented. These tools illustrate that there are inherent conflicts between the needs of a group and the needs of individuals, since user interfaces compete for the same display space and meeting time. To help minimize the effect of these conflicts, constraints were relaxed along four key dimensions of WYSIWIS: display space, time of display, subgroup population, and congruence of view. Meeting tools must be designed to support the changing needs of information sharing during process transitions, as subgroups are formed and dissolved, as individuals shift their focus of activity, and as the group shifts from multiple parallel activities to a single focused activity and back again.",
    "cited_by_count": 552,
    "openalex_id": "https://openalex.org/W2153163326",
    "type": "article"
  },
  {
    "title": "The integration of computing and routine work",
    "doi": "https://doi.org/10.1145/214427.214429",
    "publication_date": "1986-07-01",
    "publication_year": 1986,
    "authors": "Les Gasser",
    "corresponding_authors": "Les Gasser",
    "abstract": "Most computing serves as a resource or tool to support other work: performing complex analyses for engineering projects, preparing documents, or sending electronic mail using office automation equipment, etc. To improve the character, quality, and ease of computing work, we must understand how automated systems actually are integrated into the work they support. How do people actually adapt to computing as a resource? How do they deal with the unreliability in hardware, software, or operations; data inaccuracy; system changes; poor documentation; inappropriate designs; etc.; which are present in almost every computing milieu, even where computing is widely used and considered highly successful? This paper presents some results of a detailed empirical study of routine computer use in several organizations. We present a theoretical account of computing work and use it to explain a number of observed phenomena, such as: How people knowingly use “false” data to obtain desired analytical results by tricking their systems. How organizations come to rely upon complex, critical computer systems despite significant, recurrent, known errors and inaccurate data. How people work around inadequate computing systems by using manual or duplicate systems, rather than changing their systems via maintenance or enhancement. In addition, the framework for analyzing computing and routine work presented here proves useful for representing and reasoning about activity in multiactor systems in general, and in understanding how better to integrate organizations of people and computers in which work is coordinated.",
    "cited_by_count": 533,
    "openalex_id": "https://openalex.org/W1978581435",
    "type": "article"
  },
  {
    "title": "Computer systems and the design of organizational interaction",
    "doi": "https://doi.org/10.1145/45941.45943",
    "publication_date": "1988-04-01",
    "publication_year": 1988,
    "authors": "Fernando Flores; Michael Graves; Brad Hartfield; Terry Winograd",
    "corresponding_authors": "",
    "abstract": "The goal of this paper is to relate theory to invention and application in the design of systems for organizational communication and management. We propose and illustrate a theory of design, technology, and action that we believe has been missing in the mainstream of work on office systems. At the center of our thinking is a theory of language as social action, which differs from the generally taken-for-granted understandings of what goes on in an organization. This approach has been presented elsewhere, and our aim here is to examine its practical implications and assess its effectiveness in the design of The Coordinator, a workgroup productivity system that is in widespread commercial use on personal computers.",
    "cited_by_count": 501,
    "openalex_id": "https://openalex.org/W2111243467",
    "type": "article"
  },
  {
    "title": "Arithmetic coding revisited",
    "doi": "https://doi.org/10.1145/290159.290162",
    "publication_date": "1998-07-01",
    "publication_year": 1998,
    "authors": "Alistair Moffat; Radford M. Neal; Ian H. Witten",
    "corresponding_authors": "",
    "abstract": "Over the last decade, arithmetic coding has emerged as an important compression tool. It is now the method of choice for adaptive coding on myltisymbol alphabets because of its speed, low storage requirements, and effectiveness of compression. This article describes a new implementation of arithmetic coding that incorporates several improvements over a widely used earlier version by Witten, Neal, and Cleary, which has become a de facto standard. These improvements include fewer multiplicative operations, greatly extended range of alphabet sizes and symbol probabilities, and the use of low-precision arithmetic, permitting implementation by fast shift/add operations. We also describe a modular structure that separates the coding, modeling, and probability estimation components of a compression system. To motivate the improved coder, we consider the needs of a word-based text compression program. We report a range of experimental results using this and other models. Complete source code is available.",
    "cited_by_count": 490,
    "openalex_id": "https://openalex.org/W2072210981",
    "type": "article"
  },
  {
    "title": "Cyberchondria",
    "doi": "https://doi.org/10.1145/1629096.1629101",
    "publication_date": "2009-11-01",
    "publication_year": 2009,
    "authors": "Ryen W. White; Eric Horvitz",
    "corresponding_authors": "",
    "abstract": "The World Wide Web provides an abundant source of medical information. This information can assist people who are not healthcare professionals to better understand health and illness, and to provide them with feasible explanations for symptoms. However, the Web has the potential to increase the anxieties of people who have little or no medical training, especially when Web search is employed as a diagnostic procedure. We use the term cyberchondria to refer to the unfounded escalation of concerns about common symptomatology, based on the review of search results and literature on the Web. We performed a large-scale, longitudinal, log-based study of how people search for medical information online, supported by a survey of 515 individuals' health-related search experiences. We focused on the extent to which common, likely innocuous symptoms can escalate into the review of content on serious, rare conditions that are linked to the common symptoms. Our results show that Web search engines have the potential to escalate medical concerns. We show that escalation is associated with the amount and distribution of medical content viewed by users, the presence of escalatory terminology in pages visited, and a user's predisposition to escalate versus to seek more reasonable explanations for ailments. We also demonstrate the persistence of postsession anxiety following escalations and the effect that such anxieties can have on interrupting user's activities across multiple sessions. Our findings underscore the potential costs and challenges of cyberchondria and suggest actionable design implications that hold opportunity for improving the search and navigation experience for people turning to the Web to interpret common symptoms.",
    "cited_by_count": 487,
    "openalex_id": "https://openalex.org/W2119265954",
    "type": "article"
  },
  {
    "title": "Efficient mining of both positive and negative association rules",
    "doi": "https://doi.org/10.1145/1010614.1010616",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "Xindong Wu; Chengqi Zhang; Shichao Zhang",
    "corresponding_authors": "",
    "abstract": "This paper presents an efficient method for mining both positive and negative association rules in databases. The method extends traditional associations to include association rules of forms A ⇒ ¬ B , ¬ A ⇒ B , and ¬ A ⇒ ¬ B , which indicate negative associations between itemsets. With a pruning strategy and an interestingness measure, our method scales to large databases. The method has been evaluated using both synthetic and real-world databases, and our experimental results demonstrate its effectiveness and efficiency.",
    "cited_by_count": 474,
    "openalex_id": "https://openalex.org/W2026562765",
    "type": "article"
  },
  {
    "title": "Office procedure as practical action",
    "doi": "https://doi.org/10.1145/357442.357445",
    "publication_date": "1983-10-01",
    "publication_year": 1983,
    "authors": "Lucy Suchman",
    "corresponding_authors": "Lucy Suchman",
    "abstract": "article Free Access Share on Office procedure as practical action: models of work and system design Author: Lucy A. Suchman XEROX Palto Alto Research Center, 3333 Coyote Hill Road, Palo Alto, CA XEROX Palto Alto Research Center, 3333 Coyote Hill Road, Palo Alto, CAView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 401 October 1983pp 320–328https://doi.org/10.1145/357442.357445Published:01 October 1983Publication History 324citation3,649DownloadsMetricsTotal Citations324Total Downloads3,649Last 12 Months368Last 6 weeks36 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 466,
    "openalex_id": "https://openalex.org/W2083799270",
    "type": "article"
  },
  {
    "title": "A critical investigation of recall and precision as measures of retrieval system performance",
    "doi": "https://doi.org/10.1145/65943.65945",
    "publication_date": "1989-07-01",
    "publication_year": 1989,
    "authors": "Vijay V. Raghavan; P. Bollmann; Gwang S. Jung",
    "corresponding_authors": "",
    "abstract": "Recall and precision are often used to evaluate the effectiveness of information retrieval systems. They are easy to define if there is a single query and if the retrieval result generated for the query is a linear ordering. However, when the retrieval results are weakly ordered, in the sense that several documents have an identical retrieval status value with respect to a query, some probabilistic notion of precision has to be introduced. Relevance probability, expected precision, and so forth, are some alternatives mentioned in the literature for this purpose. Furthermore, when many queries are to be evaluated and the retrieval results averaged over these queries, some method of interpolation of precision values at certain preselected recall levels is needed. The currently popular approaches for handling both a weak ordering and interpolation are found to be inconsistent, and the results obtained are not easy to interpret. Moreover, in cases where some alternatives are available, no comparative analysis that would facilitate the selection of a particular strategy has been provided. In this paper, we systematically investigate the various problems and issues associated with the use of recall and precision as measures of retrieval system performance. Our motivation is to provide a comparative analysis of methods available for defining precision in a probabilistic sense and to promote a better understanding of the various issues involved in retrieval performance evaluation.",
    "cited_by_count": 459,
    "openalex_id": "https://openalex.org/W2117030594",
    "type": "article"
  },
  {
    "title": "Bias and Debias in Recommender System: A Survey and Future Directions",
    "doi": "https://doi.org/10.1145/3564284",
    "publication_date": "2022-10-19",
    "publication_year": 2022,
    "authors": "Jiawei Chen; Hande Dong; Xiang Wang; Fuli Feng; Meng Wang; Xiangnan He",
    "corresponding_authors": "",
    "abstract": "While recent years have witnessed a rapid growth of research papers on recommender system (RS) , most of the papers focus on inventing machine learning models to better fit user behavior data. However, user behavior data is observational rather than experimental. This makes various biases widely exist in the data, including but not limited to selection bias, position bias, exposure bias, and popularity bias. Blindly fitting the data without considering the inherent biases will result in many serious issues, e.g., the discrepancy between offline evaluation and online metrics, hurting user satisfaction and trust on the recommendation service, and so on. To transform the large volume of research models into practical improvements, it is highly urgent to explore the impacts of the biases and perform debiasing when necessary. When reviewing the papers that consider biases in RS, we find that, to our surprise, the studies are rather fragmented and lack a systematic organization. The terminology “bias” is widely used in the literature, but its definition is usually vague and even inconsistent across papers. This motivates us to provide a systematic survey of existing work on RS biases. In this paper, we first summarize seven types of biases in recommendation, along with their definitions and characteristics. We then provide a taxonomy to position and organize the existing work on recommendation debiasing. Finally, we identify some open challenges and envision some future directions, with the hope of inspiring more research work on this important yet less investigated topic. The summary of debiasing methods reviewed in this survey can be found at https://github.com/jiawei-chen/RecDebiasing .",
    "cited_by_count": 451,
    "openalex_id": "https://openalex.org/W3092103025",
    "type": "article"
  },
  {
    "title": "A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions",
    "doi": "https://doi.org/10.1145/3703155",
    "publication_date": "2024-11-20",
    "publication_year": 2024,
    "authors": "Lei Huang; Weijiang Yu; Weitao Ma; Weihong Zhong; Zhangyin Feng; Haotian Wang; Qianglong Chen; Weihua Peng; Xiaocheng Feng; Bing Qin; Ting Liu",
    "corresponding_authors": "",
    "abstract": "The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), fueling a paradigm shift in information acquisition. Nevertheless, LLMs are prone to hallucination, generating plausible yet nonfactual content. This phenomenon raises significant concerns over the reliability of LLMs in real-world information retrieval (IR) systems and has attracted intensive research to detect and mitigate such hallucinations. Given the open-ended general-purpose attributes inherent to LLMs, LLM hallucinations present distinct challenges that diverge from prior task-specific models. This divergence highlights the urgency for a nuanced understanding and comprehensive overview of recent advances in LLM hallucinations. In this survey, we begin with an innovative taxonomy of hallucination in the era of LLM and then delve into the factors contributing to hallucinations. Subsequently, we present a thorough overview of hallucination detection methods and benchmarks. Our discussion then transfers to representative methodologies for mitigating LLM hallucinations. Additionally, we delve into the current limitations faced by retrieval-augmented LLMs in combating hallucinations, offering insights for developing more robust IR systems. Finally, we highlight the promising research directions on LLM hallucinations, including hallucination in large vision-language models and understanding of knowledge boundaries in LLM hallucinations.",
    "cited_by_count": 433,
    "openalex_id": "https://openalex.org/W4404534210",
    "type": "article"
  },
  {
    "title": "Structural analysis of hypertexts",
    "doi": "https://doi.org/10.1145/146802.146826",
    "publication_date": "1992-04-01",
    "publication_year": 1992,
    "authors": "Rodrigo A. Botafogo; Ehud Rivlin; Ben Shneiderman",
    "corresponding_authors": "",
    "abstract": "Hypertext users often suffer from the “lost in hyperspace” problem: disorientation from too many jumps while traversing a complex network. One solution to this problem is improved authoring to create more comprehensible structures. This paper proposes several authoring tools, based on hypertext structure analysis. In many hypertext systems authors are encouraged to create hierarchical structures, but when writing, the hierarchy is lost because of the inclusion of cross-reference links. The first part of this paper looks at ways of recovering lost hierarchies and finding new ones, offering authors different views of the same hypertext. The second part helps authors by identifying properties of the hypertext document. Multiple metrics are developed including compactness and stratum . Compactness indicates the intrinsic connectedness of the hypertext, and stratum reveals to what degree the hypertext is organized so that some nodes must be read before others. Several existing hypertexts are used to illustrate the benefits of each technique. The collection of techniques provides a multifaceted view of the hypertext, which should allow authors to reduce undesired structural complexity and create documents that readers can traverse more easily.",
    "cited_by_count": 431,
    "openalex_id": "https://openalex.org/W2112140746",
    "type": "article"
  },
  {
    "title": "Placing search in context",
    "doi": "https://doi.org/10.1145/503104.503110",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Keyword-based search engines are in widespread use today as a popular means for Web-based information retrieval. Although such systems seem deceptively simple, a considerable amount of skill is required in order to satisfy non-trivial information needs. This paper presents a new conceptual paradigm for performing search in context, that largely automates the search process, providing even non-professional users with highly relevant results. This paradigm is implemented in practice in the IntelliZap system, where search is initiated from a text query marked by the user in a document she views, and is guided by the text surrounding the marked query in that document (\"the context\"). The context-driven information retrieval process involves semantic keyword extraction and clustering to automatically generate new, augmented queries. The latter are submitted to a host of general and domain-specific search engines. Search results are then semantically reranked, using context. Experimental results testify that using context to guide search, effectively offers even inexperienced users an advanced search tool on the Web.",
    "cited_by_count": 416,
    "openalex_id": "https://openalex.org/W3216404684",
    "type": "article"
  },
  {
    "title": "Lexical ambiguity and information retrieval",
    "doi": "https://doi.org/10.1145/146802.146810",
    "publication_date": "1992-04-01",
    "publication_year": 1992,
    "authors": "Robert Krovetz; W. Bruce Croft",
    "corresponding_authors": "",
    "abstract": "Lexical ambiguity is a pervasive problem in natural language processing. However, little quantitative information is available about the extent of the problem or about the impact that it has on information retrieval systems. We report on an analysis of lexical ambiguity in information retrieval test collections and on experiments to determine the utility of word meanings for separating relevant from nonrelevant documents. The experiments show that there is considerable ambiguity even in a specialized database. Word senses provide a significant separation between relevant and nonrelevant documents, but several factors contribute to determining whether disambiguation will make an improvement in performance. For example, resolving lexical ambiguity was found to have little impact on retrieval effectiveness for documents that have many words in common with the query. Other uses of word sense disambiguation in an information retrieval context are discussed.",
    "cited_by_count": 414,
    "openalex_id": "https://openalex.org/W2097802284",
    "type": "article"
  },
  {
    "title": "IRIS: an object-oriented database management system",
    "doi": null,
    "publication_date": "1989-12-01",
    "publication_year": 1989,
    "authors": "Daniel Fishman; David Beech; H. P. Cate; Ey-Chih Chow; Terrance E. Conners; James W. Davis; Nigel Derrett; Charles G. Hoch; William Kent; Peter Lyngbæk; B. Mahbod; M.-A. Neimat; T. A. Ryan; M.-C. Shan",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 412,
    "openalex_id": "https://openalex.org/W1590607611",
    "type": "article"
  },
  {
    "title": "A probabilistic relational algebra for the integration of information retrieval and database systems",
    "doi": "https://doi.org/10.1145/239041.239045",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Norbert Fuhr; Thomas Rölleke",
    "corresponding_authors": "",
    "abstract": "We present a probabilistic relational algebra (PRA) which is a generalization of standard relational algebra. In PRA, tuples are assigned probabilistic weights giving the probability that a tuple belongs to a relation. Based on intensional semantics, the tuple weights of the result of a PRA expression always conform to the underlying probabilistic model. We also show for which expressions extensional semantics yields the same results. Furthermore, we discuss complexity issues and indicate possibilities for optimization. With regard to databases, the approach allows for representing imprecise attribute values, whereas for information retrieval, probabilistic document indexing and probabilistic search term weighting can be modeled. We introduce the concept of vague predicates which yield probabilistic weights instead of Boolean values, thus allowing for queries with vague selection conditions. With these features, PRA implements uncertainty and vagueness in combination with the relational model.",
    "cited_by_count": 412,
    "openalex_id": "https://openalex.org/W1992609556",
    "type": "article"
  },
  {
    "title": "An example-based mapping method for text categorization and retrieval",
    "doi": "https://doi.org/10.1145/183422.183424",
    "publication_date": "1994-07-01",
    "publication_year": 1994,
    "authors": "Yiming Yang; Christopher G. Chute",
    "corresponding_authors": "",
    "abstract": "A unified model for text categorization and text retrieval is introduced. We use a training set of manually categorized documents to learn word-category associations, and use these associations to predict the categories of arbitrary documents. Similarly, we use a training set of queries and their related documents to obtain empirical associations between query words and indexing terms of documents, and use these associations to predict the related documents of arbitrary queries. A Linear Least Squares Fit (LLSF) technique is employed to estimate the likelihood of these associations. Document collections from the MEDLINE database and Mayo patient records are used for studies on the effectiveness of our approach, and on how much the effectiveness depends on the choices of training data, indexing language, word-weighting scheme, and morphological canonicalization. Alternative methods are also tested on these data collections for comparison. It is evident that the LLSF approach uses the relevance information effectively within human decisions of categorization and retrieval, and achieves a semantic mapping of free texts to their representations in an indexing language. Such a semantic mapping lead to a significant improvement in categorization and retrieval, compared to alternative approaches.",
    "cited_by_count": 410,
    "openalex_id": "https://openalex.org/W1986913017",
    "type": "article"
  },
  {
    "title": "Writeprints",
    "doi": "https://doi.org/10.1145/1344411.1344413",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Ahmed Abbasi; Hsinchun Chen",
    "corresponding_authors": "",
    "abstract": "One of the problems often associated with online anonymity is that it hinders social accountability, as substantiated by the high levels of cybercrime. Although identity cues are scarce in cyberspace, individuals often leave behind textual identity traces. In this study we proposed the use of stylometric analysis techniques to help identify individuals based on writing style. We incorporated a rich set of stylistic features, including lexical, syntactic, structural, content-specific, and idiosyncratic attributes. We also developed the Writeprints technique for identification and similarity detection of anonymous identities. Writeprints is a Karhunen-Loeve transforms-based technique that uses a sliding window and pattern disruption algorithm with individual author-level feature sets. The Writeprints technique and extended feature set were evaluated on a testbed encompassing four online datasets spanning different domains: email, instant messaging, feedback comments, and program code. Writeprints outperformed benchmark techniques, including SVM, Ensemble SVM, PCA, and standard Karhunen-Loeve transforms, on the identification and similarity detection tasks with accuracy as high as 94% when differentiating between 100 authors. The extended feature set also significantly outperformed a baseline set of features commonly used in previous research. Furthermore, individual-author-level feature sets generally outperformed use of a single group of attributes.",
    "cited_by_count": 400,
    "openalex_id": "https://openalex.org/W2092475127",
    "type": "article"
  },
  {
    "title": "Temporal Relational Ranking for Stock Prediction",
    "doi": "https://doi.org/10.1145/3309547",
    "publication_date": "2019-03-05",
    "publication_year": 2019,
    "authors": "Fuli Feng; Xiangnan He; Xiang Wang; Cheng Luo; Yiqun Liu; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Stock prediction aims to predict the future trends of a stock in order to help investors make good investment decisions. Traditional solutions for stock prediction are based on time-series models. With the recent success of deep neural networks in modeling sequential data, deep learning has become a promising choice for stock prediction. However, most existing deep learning solutions are not optimized toward the target of investment, i.e., selecting the best stock with the highest expected revenue. Specifically, they typically formulate stock prediction as a classification (to predict stock trends) or a regression problem (to predict stock prices). More importantly, they largely treat the stocks as independent of each other. The valuable signal in the rich relations between stocks (or companies), such as two stocks are in the same sector and two companies have a supplier-customer relation, is not considered. In this work, we contribute a new deep learning solution, named Relational Stock Ranking (RSR), for stock prediction. Our RSR method advances existing solutions in two major aspects: (1) tailoring the deep learning models for stock ranking, and (2) capturing the stock relations in a time-sensitive manner. The key novelty of our work is the proposal of a new component in neural network modeling, named Temporal Graph Convolution , which jointly models the temporal evolution and relation network of stocks. To validate our method, we perform back-testing on the historical data of two stock markets, NYSE and NASDAQ. Extensive experiments demonstrate the superiority of our RSR method. It outperforms state-of-the-art stock prediction solutions achieving an average return ratio of 98% and 71% on NYSE and NASDAQ, respectively.",
    "cited_by_count": 399,
    "openalex_id": "https://openalex.org/W3123329971",
    "type": "article"
  },
  {
    "title": "Getting around the task-artifact cycle",
    "doi": "https://doi.org/10.1145/146802.146834",
    "publication_date": "1992-04-01",
    "publication_year": 1992,
    "authors": "John M. Carroll; Mary Beth Rosson",
    "corresponding_authors": "",
    "abstract": "We are developing an “action science” approach to human-computer interaction (HCI), seeking to better integrate activities directed at understanding with those directed at design. The approach leverages development practices of current HCI with methods and concepts to support a shift toward using broad and explicit design rationale to reify where we are in a design process, why we are there, and to guide reasoning about where we might go from there. We represent a designed artifact as the set of user scenarios supported by that artifact and more finely by causal schemas detailing the underlying psychological rationale. These schemas, called claims , unpack wherefores and whys of the scenarios. In this paper, we stand back from several empirical projects to clarify our commitments and practices.",
    "cited_by_count": 388,
    "openalex_id": "https://openalex.org/W1995620802",
    "type": "article"
  },
  {
    "title": "Query clustering using user logs",
    "doi": "https://doi.org/10.1145/503104.503108",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Ji-Rong Wen; Jian‐Yun Nie; Hao Zhang",
    "corresponding_authors": "",
    "abstract": "Query clustering is a process used to discover frequently asked questions or most popular topics on a search engine. This process is crucial for search engines based on question-answering. Because of the short lengths of queries, approaches based on keywords are not suitable for query clustering. This paper describes a new query clustering method that makes use of user logs which allow us to identify the documents the users have selected for a query. The similarity between two queries may be deduced from the common documents the users selected for them. Our experiments show that a combination of both keywords and user logs is better than using either method alone.",
    "cited_by_count": 384,
    "openalex_id": "https://openalex.org/W2041179002",
    "type": "article"
  },
  {
    "title": "Formative design evaluation of superbook",
    "doi": "https://doi.org/10.1145/64789.64790",
    "publication_date": "1989-01-03",
    "publication_year": 1989,
    "authors": "Dennis E. Egan; Joel R. Remde; Louis M. Gomez; Thomas K. Landauer; Jennifer L. Eberhardt; Carol C. Lochbaum",
    "corresponding_authors": "",
    "abstract": "SuperBook is a hypertext browsing system designed to improve the usability of conventional documents. Successive versions of SuperBook were evaluated in a series of behavioral studies. Students searched for information in a statistics text. presented either in conventional printed form or in SuperBook form. The best version of SuperBook enabled students to answer search questions more quickly and accurately than they could with the conventional text. Students wrote higher quality “open-book” essays using SuperBook than they did with the conventional text, and their subjective ratings of the documentation strongly favored SuperBook. This work is a case study of formative design-evaluation. Behavioral evaluation of the first version of SuperBook showed how design factors and user strategies affected search and established baseline performance measures with printed text. The second version of SuperBook was implemented with the goal of improving search accuracy and speed. User strategies that had proved effective in the first study were made very easy and attractive to use. System response time for common operations was greatly improved. Behavioral evaluation of the new SuperBook demonstrated its superiority to printed text and suggested additional improvements that were incorporated into “MiteyBook,” a SuperBook implementation for PC-size screens. Search with MiteyBook proved to be approximately 25 percent faster and 25 percent more accurate than that obtained with a conventional printed book.",
    "cited_by_count": 353,
    "openalex_id": "https://openalex.org/W2022335546",
    "type": "article"
  },
  {
    "title": "Offices are open systems",
    "doi": "https://doi.org/10.1145/214427.214432",
    "publication_date": "1986-07-01",
    "publication_year": 1986,
    "authors": "Carl Hewitt",
    "corresponding_authors": "Carl Hewitt",
    "abstract": "This paper is intended as a contribution to analysis of the implications of viewing offices as open systems. It takes a prescriptive stance on how to establish the information-processing foundations for taking action and making decisions in office work from an open systems perspective. We propose due process as a central activity in organizational information processing. Computer systems are beginning to play important roles in mediating the ongoing activities of organizations. We expect that these roles will gradually increase in importance as computer systems take on more of the authority and responsibility for ongoing activities. At the same time we expect computer systems to acquire more of the characteristics and structure of human organizations.",
    "cited_by_count": 348,
    "openalex_id": "https://openalex.org/W2057496341",
    "type": "article"
  },
  {
    "title": "Signature files",
    "doi": "https://doi.org/10.1145/2275.357411",
    "publication_date": "1984-10-01",
    "publication_year": 1984,
    "authors": "Christos Faloutsos; Stavros Christodoulakis",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Signature files: an access method for documents and its analytical performance evaluation Authors: Chris Faloutsos Computer Systems Research Institute, Department of Computer Science, University of Toronto, Toronto, Ontario M5S 1A4, Canada Computer Systems Research Institute, Department of Computer Science, University of Toronto, Toronto, Ontario M5S 1A4, CanadaView Profile , Stavros Christodoulakis Computer Systems Research Institute, Department of Computer Science, University of Toronto, Toronto, Ontario M5S 1A4, Canada Computer Systems Research Institute, Department of Computer Science, University of Toronto, Toronto, Ontario M5S 1A4, CanadaView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 4pp 267–288https://doi.org/10.1145/2275.357411Published:01 October 1984Publication History 243citation1,664DownloadsMetricsTotal Citations243Total Downloads1,664Last 12 Months187Last 6 weeks19 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 331,
    "openalex_id": "https://openalex.org/W1981663733",
    "type": "article"
  },
  {
    "title": "Semistructured messages are surprisingly useful for computer-supported coordination",
    "doi": "https://doi.org/10.1145/27636.27637",
    "publication_date": "1987-04-01",
    "publication_year": 1987,
    "authors": "Thomas W. Malone; Kenneth R. Grant; Kum‐Yew Lai; Ramana Rao; David Rosenblitt",
    "corresponding_authors": "",
    "abstract": "This paper argues that using a set of semistructured message templates is surprisingly helpful in designing a variety of computer-based communication and coordination systems. Semistructured messages can help provide automatic aids for (1) composing messages to be sent, (2) selecting, sorting, and prioritizing messages that are received, (3) responding automatically to some messages, and (4) suggesting likely responses to other messages. The use of these capabilities is illustrated in a range of applications including electronic mail, computer conferencing, calendar management, and task tracking. The applications show how ideas from artificial intelligence (such as inheritance and production rules) and ideas from user interface design (such as interactive graphical editors) can be combined in novel ways for dealing with semistructured messages. The final part of the paper discusses how communities can evolve a useful set of message type definitions.",
    "cited_by_count": 330,
    "openalex_id": "https://openalex.org/W2025172185",
    "type": "article"
  },
  {
    "title": "Deep Item-based Collaborative Filtering for Top-N Recommendation",
    "doi": "https://doi.org/10.1145/3314578",
    "publication_date": "2019-04-12",
    "publication_year": 2019,
    "authors": "Feng Xue; Xiangnan He; Xiang Wang; Jiandong Xu; Kai Liu; Richang Hong",
    "corresponding_authors": "",
    "abstract": "Item-based Collaborative Filtering (ICF) has been widely adopted in recommender systems in industry, owing to its strength in user interest modeling and ease in online personalization. By constructing a user’s profile with the items that the user has consumed, ICF recommends items that are similar to the user’s profile. With the prevalence of machine learning in recent years, significant processes have been made for ICF by learning item similarity (or representation) from data. Nevertheless, we argue that most existing works have only considered linear and shallow relationships between items, which are insufficient to capture the complicated decision-making process of users. In this article, we propose a more expressive ICF solution by accounting for the nonlinear and higher-order relationships among items. Going beyond modeling only the second-order interaction (e.g., similarity) between two items, we additionally consider the interaction among all interacted item pairs by using nonlinear neural networks. By doing this, we can effectively model the higher-order relationship among items, capturing more complicated effects in user decision-making. For example, it can differentiate which historical itemsets in a user’s profile are more important in affecting the user to make a purchase decision on an item. We treat this solution as a deep variant of ICF, thus term it as DeepICF. To justify our proposal, we perform empirical studies on two public datasets from MovieLens and Pinterest. Extensive experiments verify the highly positive effect of higher-order item interaction modeling with nonlinear neural networks. Moreover, we demonstrate that by more fine-grained second-order interaction modeling with attention network, the performance of our DeepICF method can be further improved.",
    "cited_by_count": 315,
    "openalex_id": "https://openalex.org/W2900229157",
    "type": "article"
  },
  {
    "title": "Learning author-topic models from text corpora",
    "doi": "https://doi.org/10.1145/1658377.1658381",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "Michal Rosen‐Zvi; Chaitanya Chemudugunta; Thomas Griffiths; Padhraic Smyth; Mark Steyvers",
    "corresponding_authors": "",
    "abstract": "We propose an unsupervised learning technique for extracting information about authors and topics from large text collections. We model documents as if they were generated by a two-stage stochastic process. An author is represented by a probability distribution over topics, and each topic is represented as a probability distribution over words. The probability distribution over topics in a multi-author paper is a mixture of the distributions associated with the authors. The topic-word and author-topic distributions are learned from data in an unsupervised manner using a Markov chain Monte Carlo algorithm. We apply the methodology to three large text corpora: 150,000 abstracts from the CiteSeer digital library, 1740 papers from the Neural Information Processing Systems (NIPS) Conferences, and 121,000 emails from the Enron corporation. We discuss in detail the interpretation of the results discovered by the system including specific topic and author models, ranking of authors by topic and topics by author, parsing of abstracts by topics and authors, and detection of unusual papers by specific authors. Experiments based on perplexity scores for test documents and precision-recall for document retrieval are used to illustrate systematic differences between the proposed author-topic model and a number of alternatives. Extensions to the model, allowing for example, generalizations of the notion of an author, are also briefly discussed.",
    "cited_by_count": 304,
    "openalex_id": "https://openalex.org/W2069078812",
    "type": "article"
  },
  {
    "title": "Concept-Based Information Retrieval Using Explicit Semantic Analysis",
    "doi": "https://doi.org/10.1145/1961209.1961211",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Ofer Egozi; Shaul Markovitch; Evgeniy Gabrilovich",
    "corresponding_authors": "",
    "abstract": "Information retrieval systems traditionally rely on textual keywords to index and retrieve documents. Keyword-based retrieval may return inaccurate and incomplete results when different keywords are used to describe the same concept in the documents and in the queries. Furthermore, the relationship between these related keywords may be semantic rather than syntactic, and capturing it thus requires access to comprehensive human world knowledge. Concept-based retrieval methods have attempted to tackle these difficulties by using manually built thesauri, by relying on term cooccurrence data, or by extracting latent word relationships and concepts from a corpus. In this article we introduce a new concept-based retrieval approach based on Explicit Semantic Analysis (ESA), a recently proposed method that augments keyword-based text representation with concept-based features, automatically extracted from massive human knowledge repositories such as Wikipedia. Our approach generates new text features automatically, and we have found that high-quality feature selection becomes crucial in this setting to make the retrieval more focused. However, due to the lack of labeled data, traditional feature selection methods cannot be used, hence we propose new methods that use self-generated labeled training data. The resulting system is evaluated on several TREC datasets, showing superior performance over previous state-of-the-art results.",
    "cited_by_count": 283,
    "openalex_id": "https://openalex.org/W2099868020",
    "type": "article"
  },
  {
    "title": "Challenges in Building Intelligent Open-domain Dialog Systems",
    "doi": "https://doi.org/10.1145/3383123",
    "publication_date": "2020-04-09",
    "publication_year": 2020,
    "authors": "Minlie Huang; Xiaoyan Zhu; Jianfeng Gao",
    "corresponding_authors": "",
    "abstract": "There is a resurgent interest in developing intelligent open-domain dialog systems due to the availability of large amounts of conversational data and the recent progress on neural approaches to conversational AI [33]. Unlike traditional task-oriented bots, an open-domain dialog system aims to establish long-term connections with users by satisfying the human need for communication, affection, and social belonging. This article reviews the recent work on neural approaches that are devoted to addressing three challenges in developing such systems: semantics , consistency , and interactiveness . Semantics requires a dialog system to not only understand the content of the dialog but also identify users’ emotional and social needs during the conversation. Consistency requires the system to demonstrate a consistent personality to win users’ trust and gain their long-term confidence. Interactiveness refers to the system’s ability to generate interpersonal responses to achieve particular social goals such as entertainment and conforming. The studies we select to present in this survey are based on our unique views and are by no means complete. Nevertheless, we hope that the discussion will inspire new research in developing more intelligent open-domain dialog systems.",
    "cited_by_count": 277,
    "openalex_id": "https://openalex.org/W3015322406",
    "type": "article"
  },
  {
    "title": "Large-scale validation and analysis of interleaved search evaluation",
    "doi": "https://doi.org/10.1145/2094072.2094078",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Olivier Chapelle; Thorsten Joachims; Filip Radlinski; Yisong Yue",
    "corresponding_authors": "",
    "abstract": "Interleaving is an increasingly popular technique for evaluating information retrieval systems based on implicit user feedback. While a number of isolated studies have analyzed how this technique agrees with conventional offline evaluation approaches and other online techniques, a complete picture of its efficiency and effectiveness is still lacking. In this paper we extend and combine the body of empirical evidence regarding interleaving, and provide a comprehensive analysis of interleaving using data from two major commercial search engines and a retrieval system for scientific literature. In particular, we analyze the agreement of interleaving with manual relevance judgments and observational implicit feedback measures, estimate the statistical efficiency of interleaving, and explore the relative performance of different interleaving variants. We also show how to learn improved credit-assignment functions for clicks that further increase the sensitivity of interleaving.",
    "cited_by_count": 229,
    "openalex_id": "https://openalex.org/W1982530130",
    "type": "article"
  },
  {
    "title": "A Survey on the Fairness of Recommender Systems",
    "doi": "https://doi.org/10.1145/3547333",
    "publication_date": "2022-07-09",
    "publication_year": 2022,
    "authors": "Yifan Wang; Weizhi Ma; Min Zhang; Yiqun Liu; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Recommender systems are an essential tool to relieve the information overload challenge and play an important role in people's daily lives. Since recommendations involve allocations of social resources (e.g., job recommendation), an important issue is whether recommendations are fair. Unfair recommendations are not only unethical but also harm the long-term interests of the recommender system itself. As a result, fairness issues in recommender systems have recently attracted increasing attention. However, due to multiple complex resource allocation processes and various fairness definitions, the research on fairness in recommendation is scattered. To fill this gap, we review over 60 papers published in top conferences/journals, including TOIS, SIGIR, and WWW. First, we summarize fairness definitions in the recommendation and provide several views to classify fairness issues. Then, we review recommendation datasets and measurements in fairness studies and provide an elaborate taxonomy of fairness methods in the recommendation. Finally, we conclude this survey by outlining some promising future directions.",
    "cited_by_count": 215,
    "openalex_id": "https://openalex.org/W4282027681",
    "type": "article"
  },
  {
    "title": "A Troubling Analysis of Reproducibility and Progress in Recommender Systems Research",
    "doi": "https://doi.org/10.1145/3434185",
    "publication_date": "2021-01-06",
    "publication_year": 2021,
    "authors": "Maurizio Ferrari Dacrema; Simone Boglio; Paolo Cremonesi; Dietmar Jannach",
    "corresponding_authors": "",
    "abstract": "The design of algorithms that generate personalized ranked item lists is a central topic of research in the field of recommender systems. In the past few years, in particular, approaches based on deep learning (neural) techniques have become dominant in the literature. For all of them, substantial progress over the state-of-the-art is claimed. However, indications exist of certain problems in today's research practice, e.g., with respect to the choice and optimization of the baselines used for comparison, raising questions about the published claims. In order to obtain a better understanding of the actual progress, we have tried to reproduce recent results in the area of neural recommendation approaches based on collaborative filtering. The worrying outcome of the analysis of these recent works-all were published at prestigious scientific conferences between 2015 and 2018-is that 11 out of the 12 reproducible neural approaches can be outperformed by conceptually simple methods, e.g., based on the nearest-neighbor heuristics. None of the computationally complex neural methods was actually consistently better than already existing learning-based techniques, e.g., using matrix factorization or linear models. In our analysis, we discuss common issues in today's research practice, which, despite the many papers that are published on the topic, have apparently led the field to a certain level of stagnation.",
    "cited_by_count": 211,
    "openalex_id": "https://openalex.org/W3125645198",
    "type": "article"
  },
  {
    "title": "Product-Based Neural Networks for User Response Prediction over Multi-Field Categorical Data",
    "doi": "https://doi.org/10.1145/3233770",
    "publication_date": "2018-10-30",
    "publication_year": 2018,
    "authors": "Yanru Qu; Bohui Fang; Weinan Zhang; Ruiming Tang; Minzhe Niu; Huifeng Guo; Yong Yu; Xiuqiang He",
    "corresponding_authors": "",
    "abstract": "User response prediction is a crucial component for personalized information retrieval and filtering scenarios, such as recommender system and web search. The data in user response prediction is mostly in a multi-field categorical format and transformed into sparse representations via one-hot encoding. Due to the sparsity problems in representation and optimization, most research focuses on feature engineering and shallow modeling. Recently, deep neural networks have attracted research attention on such a problem for their high capacity and end-to-end training scheme. In this article, we study user response prediction in the scenario of click prediction. We first analyze a coupled gradient issue in latent vector-based models and propose kernel product to learn field-aware feature interactions. Then, we discuss an insensitive gradient issue in DNN-based models and propose Product-based Neural Network, which adopts a feature extractor to explore feature interactions. Generalizing the kernel product to a net-in-net architecture, we further propose Product-network in Network (PIN), which can generalize previous models. Extensive experiments on four industrial datasets and one contest dataset demonstrate that our models consistently outperform eight baselines on both area under curve and log loss. Besides, PIN makes great click-through rate improvement (relatively 34.67%) in online A/B test.",
    "cited_by_count": 209,
    "openalex_id": "https://openalex.org/W2963924287",
    "type": "article"
  },
  {
    "title": "A Context-Aware User-Item Representation Learning for Item Recommendation",
    "doi": "https://doi.org/10.1145/3298988",
    "publication_date": "2019-01-31",
    "publication_year": 2019,
    "authors": "Libing Wu; Cong Quan; Chenliang Li; Qian Wang; Bolong Zheng; Xiangyang Luo",
    "corresponding_authors": "",
    "abstract": "Both reviews and user-item interactions (i.e., rating scores) have been widely adopted for user rating prediction. However, these existing techniques mainly extract the latent representations for users and items in an independent and static manner. That is, a single static feature vector is derived to encode user preference without considering the particular characteristics of each candidate item. We argue that this static encoding scheme is incapable of fully capturing users’ preferences, because users usually exhibit different preferences when interacting with different items. In this article, we propose a novel c ontext- a ware user-item r epresentation l earning model for rating prediction, named CARL. CARL derives a joint representation for a given user-item pair based on their individual latent features and latent feature interactions. Then, CARL adopts Factorization Machines to further model higher order feature interactions on the basis of the user-item pair for rating prediction. Specifically, two separate learning components are devised in CARL to exploit review data and interaction data, respectively: review-based feature learning and interaction-based feature learning . In the review-based learning component, with convolution operations and attention mechanism, the pair-based relevant features for the given user-item pair are extracted by jointly considering their corresponding reviews. However, these features are only reivew-driven and may not be comprehensive. Hence, an interaction-based learning component further extracts complementary features from interaction data alone, also on the basis of user-item pairs. The final rating score is then derived with a dynamic linear fusion mechanism. Experiments on seven real-world datasets show that CARL achieves significantly better rating prediction accuracy than existing state-of-the-art alternatives. Also, with the attention mechanism, we show that the pair-based relevant information (i.e., context-aware information) in reviews can be highlighted to interpret the rating prediction for different user-item pairs.",
    "cited_by_count": 202,
    "openalex_id": "https://openalex.org/W2782111139",
    "type": "article"
  },
  {
    "title": "Deep Learning for Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3426723",
    "publication_date": "2020-11-13",
    "publication_year": 2020,
    "authors": "Hui Fang; Danning Zhang; Yiheng Shu; Guibing Guo",
    "corresponding_authors": "",
    "abstract": "In the field of sequential recommendation, deep learning--(DL) based methods have received a lot of attention in the past few years and surpassed traditional models such as Markov chain-based and factorization-based ones. However, there is little systematic study on DL-based methods, especially regarding how to design an effective DL model for sequential recommendation. In this view, this survey focuses on DL-based sequential recommender systems by taking the aforementioned issues into consideration. Specifically, we illustrate the concept of sequential recommendation, propose a categorization of existing algorithms in terms of three types of behavioral sequences, summarize the key factors affecting the performance of DL-based models, and conduct corresponding evaluations to showcase and demonstrate the effects of these factors. We conclude this survey by systematically outlining future directions and challenges in this field.",
    "cited_by_count": 196,
    "openalex_id": "https://openalex.org/W3105472188",
    "type": "article"
  },
  {
    "title": "Efficient Neural Matrix Factorization without Sampling for Recommendation",
    "doi": "https://doi.org/10.1145/3373807",
    "publication_date": "2020-01-14",
    "publication_year": 2020,
    "authors": "Chong Chen; Min Zhang; Yongfeng Zhang; Yiqun Liu; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Recommendation systems play a vital role to keep users engaged with personalized contents in modern online platforms. Recently, deep learning has revolutionized many research fields and there is a surge of interest in applying it for recommendation. However, existing studies have largely focused on exploring complex deep-learning architectures for recommendation task, while typically applying the negative sampling strategy for model learning. Despite effectiveness, we argue that these methods suffer from two important limitations: (1) the methods with complex network structures have a substantial number of parameters, and require expensive computations even with a sampling-based learning strategy; (2) the negative sampling strategy is not robust, making sampling-based methods difficult to achieve the optimal performance in practical applications. In this work, we propose to learn neural recommendation models from the whole training data without sampling. However, such a non-sampling strategy poses strong challenges to learning efficiency. To address this, we derive three new optimization methods through rigorous mathematical reasoning, which can efficiently learn model parameters from the whole data (including all missing data) with a rather low time complexity. Moreover, based on a simple Neural Matrix Factorization architecture, we present a general framework named ENMF, short for Efficient Neural Matrix Factorization . Extensive experiments on three real-world public datasets indicate that the proposed ENMF framework consistently and significantly outperforms the state-of-the-art methods on the Top-K recommendation task. Remarkably, ENMF also shows significant advantages in training efficiency, which makes it more applicable to real-world large-scale systems.",
    "cited_by_count": 177,
    "openalex_id": "https://openalex.org/W2999649805",
    "type": "article"
  },
  {
    "title": "HGAT: Heterogeneous Graph Attention Networks for Semi-supervised Short Text Classification",
    "doi": "https://doi.org/10.1145/3450352",
    "publication_date": "2021-05-05",
    "publication_year": 2021,
    "authors": "Tianchi Yang; Linmei Hu; Chuan Shi; Houye Ji; Xiaoli Li; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "Short text classification has been widely explored in news tagging to provide more efficient search strategies and more effective search results for information retrieval. However, most existing studies, concentrating on long text classification, deliver unsatisfactory performance on short texts due to the sparsity issue and the insufficiency of labeled data. In this article, we propose a novel heterogeneous graph neural network-based method for semi-supervised short text classification, leveraging full advantage of limited labeled data and large unlabeled data through information propagation along the graph. Specifically, we first present a flexible heterogeneous information network (HIN) framework for modeling short texts, which can integrate any type of additional information and meanwhile capture their relations to address the semantic sparsity. Then, we propose Heterogeneous Graph Attention networks (HGAT) to embed the HIN for short text classification based on a dual-level attention mechanism, including node-level and type-level attentions. To efficiently classify new coming texts that do not previously exist in the HIN, we extend our model HGAT for inductive learning, avoiding re-training the model on the evolving HIN. Extensive experiments on single-/multi-label classification demonstrates that our proposed model HGAT significantly outperforms state-of-the-art methods across the benchmark datasets under both transductive and inductive learning.",
    "cited_by_count": 148,
    "openalex_id": "https://openalex.org/W3159075545",
    "type": "article"
  },
  {
    "title": "Personalized News Recommendation: Methods and Challenges",
    "doi": "https://doi.org/10.1145/3530257",
    "publication_date": "2022-04-14",
    "publication_year": 2022,
    "authors": "Chuhan Wu; Fangzhao Wu; Yongfeng Huang; Xing Xie",
    "corresponding_authors": "",
    "abstract": "Personalized news recommendation is important for users to find interesting news information and alleviate information overload. Although it has been extensively studied over decades and has achieved notable success in improving user experience, there are still many problems and challenges that need to be further studied. To help researchers master the advances in personalized news recommendation, in this article, we present a comprehensive overview of personalized news recommendation. Instead of following the conventional taxonomy of news recommendation methods, in this article, we propose a novel perspective to understand personalized news recommendation based on its core problems and the associated techniques and challenges. We first review the techniques for tackling each core problem in a personalized news recommender system and the challenges they face. Next, we introduce the public datasets and evaluation methods for personalized news recommendation. We then discuss the key points on improving the responsibility of personalized news recommender systems. Finally, we raise several research directions that are worth investigating in the future. This article can provide up-to-date and comprehensive views on personalized news recommendation. We hope this article can facilitate research on personalized news recommendation as well as related fields in natural language processing and data mining.",
    "cited_by_count": 147,
    "openalex_id": "https://openalex.org/W4223982309",
    "type": "article"
  },
  {
    "title": "A Survey on Cross-domain Recommendation: Taxonomies, Methods, and Future Directions",
    "doi": "https://doi.org/10.1145/3548455",
    "publication_date": "2022-07-11",
    "publication_year": 2022,
    "authors": "Tianzi Zang; Yanmin Zhu; Haobing Liu; Ruohan Zhang; Jiadi Yu",
    "corresponding_authors": "",
    "abstract": "Traditional recommendation systems are faced with two long-standing obstacles, namely data sparsity and cold-start problems, which promote the emergence and development of Cross-Domain Recommendation (CDR). The core idea of CDR is to leverage information collected from other domains to alleviate the two problems in one domain. Since the early 2010s, many efforts have been engaged for cross-domain recommendation. Recently, with the development of deep learning and neural networks, a large number of methods have emerged. However, there is a limited number of systematic surveys on CDR, especially regarding the latest proposed methods as well as the recommendation scenarios and recommendation tasks they address. In this survey article, we first proposed a two-level taxonomy of cross-domain recommendation that classifies different recommendation scenarios and recommendation tasks. We then introduce and summarize existing cross-domain recommendation approaches under different recommendation scenarios in a structured manner. We also organize datasets commonly used. We conclude this survey by providing several potential research directions about this field.",
    "cited_by_count": 120,
    "openalex_id": "https://openalex.org/W3190386329",
    "type": "article"
  },
  {
    "title": "Reinforced Neighborhood Selection Guided Multi-Relational Graph Neural Networks",
    "doi": "https://doi.org/10.1145/3490181",
    "publication_date": "2021-12-01",
    "publication_year": 2021,
    "authors": "Hao Peng; Ruitong Zhang; Yingtong Dou; Renyu Yang; Jingyi Zhang; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "Graph Neural Networks (GNNs) have been widely used for the representation learning of various structured graph data, typically through message passing among nodes by aggregating their neighborhood information via different operations. While promising, most existing GNNs oversimplify the complexity and diversity of the edges in the graph and thus are inefficient to cope with ubiquitous heterogeneous graphs, which are typically in the form of multi-relational graph representations. In this article, we propose RioGNN , a novel Reinforced, recursive, and flexible neighborhood selection guided multi-relational Graph Neural Network architecture, to navigate complexity of neural network structures whilst maintaining relation-dependent representations. We first construct a multi-relational graph, according to the practical task, to reflect the heterogeneity of nodes, edges, attributes, and labels. To avoid the embedding over-assimilation among different types of nodes, we employ a label-aware neural similarity measure to ascertain the most similar neighbors based on node attributes. A reinforced relation-aware neighbor selection mechanism is developed to choose the most similar neighbors of a targeting node within a relation before aggregating all neighborhood information from different relations to obtain the eventual node embedding. Particularly, to improve the efficiency of neighbor selecting, we propose a new recursive and scalable reinforcement learning framework with estimable depth and width for different scales of multi-relational graphs. RioGNN can learn more discriminative node embedding with enhanced explainability due to the recognition of individual importance of each relation via the filtering threshold mechanism. Comprehensive experiments on real-world graph data and practical tasks demonstrate the advancements of effectiveness, efficiency, and the model explainability, as opposed to other comparative GNN models.",
    "cited_by_count": 118,
    "openalex_id": "https://openalex.org/W3217103056",
    "type": "article"
  },
  {
    "title": "eFraudCom: An E-commerce Fraud Detection System via Competitive Graph Neural Networks",
    "doi": "https://doi.org/10.1145/3474379",
    "publication_date": "2022-03-07",
    "publication_year": 2022,
    "authors": "Ge Zhang; Zhao Li; Jiaming Huang; Jia Wu; Chuan Zhou; Jian Yang; Jianliang Gao",
    "corresponding_authors": "",
    "abstract": "With the development of e-commerce, fraud behaviors have been becoming one of the biggest threats to the e-commerce business. Fraud behaviors seriously damage the ranking system of e-commerce platforms and adversely influence the shopping experience of users. It is of great practical value to detect fraud behaviors on e-commerce platforms. However, the task is non-trivial, since the adversarial action taken by fraudsters. Existing fraud detection systems used in the e-commerce industry easily suffer from performance decay and can not adapt to the upgrade of fraud patterns, as they take already known fraud behaviors as supervision information to detect other suspicious behaviors. In this article, we propose a competitive graph neural networks (CGNN)-based fraud detection system (eFraudCom) to detect fraud behaviors at one of the largest e-commerce platforms, “Taobao” 1 . In the eFraudCom system, (1) the competitive graph neural networks (CGNN) as the core part of eFraudCom can classify behaviors of users directly by modeling the distributions of normal and fraud behaviors separately; (2) some normal behaviors will be utilized as weak supervision information to guide the CGNN to build the profile for normal behaviors that are more stable than fraud behaviors. The algorithm dependency on fraud behaviors will be eliminated, which enables eFraudCom to detect fraud behaviors in presence of the new fraud patterns; (3) the mutual information regularization term can maximize the separability between normal and fraud behaviors to further improve CGNN. eFraudCom is implemented into a prototype system and the performance of the system is evaluated by extensive experiments. The experiments on two Taobao and two public datasets demonstrate that the proposed deep framework CGNN is superior to other baselines in detecting fraud behaviors. A case study on Taobao datasets verifies that CGNN is still robust when the fraud patterns have been upgraded.",
    "cited_by_count": 115,
    "openalex_id": "https://openalex.org/W4220721362",
    "type": "article"
  },
  {
    "title": "Personalized Prompt Learning for Explainable Recommendation",
    "doi": "https://doi.org/10.1145/3580488",
    "publication_date": "2023-03-23",
    "publication_year": 2023,
    "authors": "Lei Li; Yongfeng Zhang; Li Chen",
    "corresponding_authors": "",
    "abstract": "Providing user-understandable explanations to justify recommendations could help users better understand the recommended items, increase the system’s ease of use, and gain users’ trust. A typical approach to realize it is natural language generation. However, previous works mostly adopt recurrent neural networks to meet the ends, leaving the potentially more effective pre-trained Transformer models under-explored. In fact, user and item IDs, as important identifiers in recommender systems, are inherently in different semantic space as words that pre-trained models were already trained on. Thus, how to effectively fuse IDs into such models becomes a critical issue. Inspired by recent advancement in prompt learning, we come up with two solutions: find alternative words to represent IDs (called discrete prompt learning) and directly input ID vectors to a pre-trained model (termed continuous prompt learning). In the latter case, ID vectors are randomly initialized but the model is trained in advance on large corpora, so they are actually in different learning stages. To bridge the gap, we further propose two training strategies: sequential tuning and recommendation as regularization. Extensive experiments show that our continuous prompt learning approach equipped with the training strategies consistently outperforms strong baselines on three datasets of explainable recommendation.",
    "cited_by_count": 113,
    "openalex_id": "https://openalex.org/W4360612299",
    "type": "article"
  },
  {
    "title": "Semantic Models for the First-Stage Retrieval: A Comprehensive Review",
    "doi": "https://doi.org/10.1145/3486250",
    "publication_date": "2022-03-24",
    "publication_year": 2022,
    "authors": "Jiafeng Guo; Yinqiong Cai; Yixing Fan; Fei Sun; Ruqing Zhang; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "Multi-stage ranking pipelines have been a practical solution in modern search systems, where the first-stage retrieval is to return a subset of candidate documents, and latter stages attempt to re-rank those candidates. Unlike re-ranking stages going through quick technique shifts during past decades, the first-stage retrieval has long been dominated by classical term-based models. Unfortunately, these models suffer from the vocabulary mismatch problem, which may block re-ranking stages from relevant documents at the very beginning. Therefore, it has been a long-term desire to build semantic models for the first-stage retrieval that can achieve high recall efficiently. Recently, we have witnessed an explosive growth of research interests on the first-stage semantic retrieval models. We believe it is the right time to survey current status, learn from existing methods, and gain some insights for future development. In this paper, we describe the current landscape of the first-stage retrieval models under a unified framework to clarify the connection between classical term-based retrieval methods, early semantic retrieval methods and neural semantic retrieval methods. Moreover, we identify some open challenges and envision some future directions, with the hope of inspiring more researches on these important yet less investigated topics.",
    "cited_by_count": 86,
    "openalex_id": "https://openalex.org/W3137305332",
    "type": "review"
  },
  {
    "title": "Dense Text Retrieval Based on Pretrained Language Models: A Survey",
    "doi": "https://doi.org/10.1145/3637870",
    "publication_date": "2023-12-18",
    "publication_year": 2023,
    "authors": "Wayne Xin Zhao; Jing Liu; Ruiyang Ren; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Text retrieval is a long-standing research topic on information seeking, where a system is required to return relevant information resources to user’s queries in natural language. From heuristic-based retrieval methods to learning-based ranking functions, the underlying retrieval models have been continually evolved with the ever-lasting technical innovation. To design effective retrieval models, a key point lies in how to learn text representations and model the relevance matching. The recent success of pretrained language models (PLM) sheds light on developing more capable text-retrieval approaches by leveraging the excellent modeling capacity of PLMs. With powerful PLMs, we can effectively learn the semantic representations of queries and texts in the latent representation space, and further construct the semantic matching function between the dense vectors for relevance modeling. Such a retrieval approach is called dense retrieval , since it employs dense vectors to represent the texts. Considering the rapid progress on dense retrieval, this survey systematically reviews the recent progress on PLM-based dense retrieval. Different from previous surveys on dense retrieval, we take a new perspective to organize the related studies by four major aspects, including architecture, training, indexing and integration, and thoroughly summarize the mainstream techniques for each aspect. We extensively collect the recent advances on this topic, and include 300+ reference papers. To support our survey, we create a website for providing useful resources, and release a code repository for dense retrieval. This survey aims to provide a comprehensive, practical reference focused on the major progress for dense text retrieval.",
    "cited_by_count": 81,
    "openalex_id": "https://openalex.org/W4389921502",
    "type": "article"
  },
  {
    "title": "PARADE: Passage Representation Aggregation forDocument Reranking",
    "doi": "https://doi.org/10.1145/3600088",
    "publication_date": "2023-05-26",
    "publication_year": 2023,
    "authors": "Canjia Li; Andrew Yates; Sean MacAvaney; Ben He; Yingfei Sun",
    "corresponding_authors": "",
    "abstract": "Pre-trained transformer models, such as BERT and T5, have shown to be highly effective at ad hoc passage and document ranking. Due to the inherent sequence length limits of these models, they need to process document passages one at a time rather than processing the entire document sequence at once. Although several approaches for aggregating passage-level signals into a document-level relevance score have been proposed, there has yet to be an extensive comparison of these techniques. In this work, we explore strategies for aggregating relevance signals from a document’s passages into a final ranking score. We find that passage representation aggregation techniques can significantly improve over score aggregation techniques proposed in prior work, such as taking the maximum passage score. We call this new approach PARADE. In particular, PARADE can significantly improve results on collections with broad information needs where relevance signals can be spread throughout the document (such as TREC Robust04 and GOV2). Meanwhile, less complex aggregation techniques may work better on collections with an information need that can often be pinpointed to a single passage (such as TREC DL and TREC Genomics). We also conduct efficiency analyses and highlight several strategies for improving transformer-based aggregation.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W3064953855",
    "type": "article"
  },
  {
    "title": "How Can Recommender Systems Benefit from Large Language Models: A Survey",
    "doi": "https://doi.org/10.1145/3678004",
    "publication_date": "2024-07-13",
    "publication_year": 2024,
    "authors": "Jianghao Lin; Xinyi Dai; Yunjia Xi; Weiwen Liu; Bo Chen; Hao Zhang; Yong Liu; Chuhan Wu; Xiangyang Li; Chenxu Zhu; Huifeng Guo; Yong Yu; Ruiming Tang; Weinan Zhang",
    "corresponding_authors": "",
    "abstract": "With the rapid development of online services and web applications, recommender systems (RS) have become increasingly indispensable for mitigating information overload and matching users’ information needs by providing personalized suggestions over items. Although the RS research community has made remarkable progress over the past decades, conventional recommendation models (CRM) still have some limitations, e.g. , lacking open-domain world knowledge, and difficulties in comprehending users’ underlying preferences and motivations. Meanwhile, large language models (LLM) have shown impressive general intelligence and human-like capabilities for various natural language processing (NLP) tasks, which mainly stem from their extensive open-world knowledge, logical and commonsense reasoning abilities, as well as their comprehension of human culture and society. Consequently, the emergence of LLM is inspiring the design of recommender systems and pointing out a promising research direction, i.e. , whether we can incorporate LLM and benefit from their common knowledge and capabilities to compensate for the limitations of CRM. In this paper, we conduct a comprehensive survey on this research direction, and draw a bird’s-eye view from the perspective of the whole pipeline in real-world recommender systems. Specifically, we summarize existing research works from two orthogonal aspects: where and how to adapt LLM to RS. For the “ WHERE ” question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e. , feature engineering, feature encoder, scoring/ranking function, user interaction, and pipeline controller. For the “ HOW ” question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e. , whether to tune LLM or not during training, and whether to involve conventional recommendation models for inference. Detailed analysis and general development paths are provided for both “WHERE” and “HOW” questions, respectively. Then, we highlight the key challenges in adapting LLM to RS from three aspects, i.e. , efficiency, effectiveness, and ethics. Finally, we summarize the survey and discuss the future prospects. To further facilitate the research community of LLM-enhanced recommender systems, we actively maintain a GitHub repository for papers and other related resources in this rising direction 1 .",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W4400606525",
    "type": "article"
  },
  {
    "title": "Quotation Recommendation for Multi-party Online Conversations Based on Semantic and Topic Fusion",
    "doi": "https://doi.org/10.1145/3594633",
    "publication_date": "2023-05-05",
    "publication_year": 2023,
    "authors": "Lingzhi Wang; Xingshan Zeng; Kam‐Fai Wong",
    "corresponding_authors": "",
    "abstract": "Quotations are crucial for successful explanations and persuasions in interpersonal communications. However, finding what to quote in a conversation is challenging for humans. This work studies automatic quotation recommendation for online conversations. Unlike the previous works that only consider semantic-level modeling, we adopt topic-level representation to facilitate the recommendation. A hierarchical architecture that is based on a pretrained language model is adopted to model the semantic-level conversation representation, and a neural topic model is employed to learn the topic-level representation. Moreover, the semantic-level conversation modeling is enhanced by a topic-aware attention mechanism, which is adopted to capture the interactive conversation structure from the perspective of word co-occurrence. The joint training of semantic- and topic-based recommendation leads to significantly better performance than the state-of-the-art models on two large-scale datasets. Apart from the novel and advanced recommendation framework, we conduct extensive quantitative experiments to investigate the difficulty of the quotation recommendation task, validate the topic-based recommendation assumption, and explore the stability of the recommendation. Some qualitative experiments and analyses are also included to interpret the quotation and topic distribution for some instances. All the extensive experiments and analyses provide persuasive explanations and interpretations of the module design and the recommendation results.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W4372347502",
    "type": "article"
  },
  {
    "title": "CIRS: Bursting Filter Bubbles by Counterfactual Interactive Recommender System",
    "doi": "https://doi.org/10.1145/3594871",
    "publication_date": "2023-04-28",
    "publication_year": 2023,
    "authors": "Chongming Gao; Shiqi Wang; Shijun Li; Jiawei Chen; Xiangnan He; Wenqiang Lei; Biao Li; Yuan Zhang; Peng Jiang",
    "corresponding_authors": "",
    "abstract": "While personalization increases the utility of recommender systems, it also brings the issue of filter bubbles . e.g., if the system keeps exposing and recommending the items that the user is interested in, it may also make the user feel bored and less satisfied. Existing work studies filter bubbles in static recommendation, where the effect of overexposure is hard to capture. In contrast, we believe it is more meaningful to study the issue in interactive recommendation and optimize long-term user satisfaction. Nevertheless, it is unrealistic to train the model online due to the high cost. As such, we have to leverage offline training data and disentangle the causal effect on user satisfaction. To achieve this goal, we propose a counterfactual interactive recommender system (CIRS) that augments offline reinforcement learning (offline RL) with causal inference. The basic idea is to first learn a causal user model on historical data to capture the overexposure effect of items on user satisfaction. It then uses the learned causal user model to help the planning of the RL policy. To conduct evaluation offline, we innovatively create an authentic RL environment (KuaiEnv) based on a real-world fully observed user rating dataset. The experiments show the effectiveness of CIRS in bursting filter bubbles and achieving long-term success in interactive recommendation. The implementation of CIRS is available via https://github.com/chongminggao/ CIRS-codes.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W4367319708",
    "type": "article"
  },
  {
    "title": "DiffuRec: A Diffusion Model for Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3631116",
    "publication_date": "2023-12-29",
    "publication_year": 2023,
    "authors": "Zihao Li; Aixin Sun; Chenliang Li",
    "corresponding_authors": "",
    "abstract": "Mainstream solutions to sequential recommendation represent items with fixed vectors. These vectors have limited capability in capturing items’ latent aspects and users’ diverse preferences. As a new generative paradigm, diffusion models have achieved excellent performance in areas like computer vision and natural language processing. To our understanding, its unique merit in representation generation well fits the problem setting of sequential recommendation. In this article, we make the very first attempt to adapt the diffusion model to sequential recommendation and propose DiffuRec for item representation construction and uncertainty injection. Rather than modeling item representations as fixed vectors, we represent them as distributions in DiffuRec , which reflect a user’s multiple interests and an item’s various aspects adaptively. In the diffusion phase, DiffuRec corrupts the target item embedding into a Gaussian distribution via noise adding, which is further applied for sequential item distribution representation generation and uncertainty injection. Afterward, the item representation is fed into an approximator for target item representation reconstruction. In the reverse phase, based on a user’s historical interaction behaviors, we reverse a Gaussian noise into the target item representation, then apply a rounding operation for target item prediction. Experiments over four datasets show that DiffuRec outperforms strong baselines by a large margin. 1",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W4390412407",
    "type": "article"
  },
  {
    "title": "Contrastive Self-supervised Learning in Recommender Systems: A Survey",
    "doi": "https://doi.org/10.1145/3627158",
    "publication_date": "2023-10-09",
    "publication_year": 2023,
    "authors": "Mengyuan Jing; Yanmin Zhu; Tianzi Zang; Ke Wang",
    "corresponding_authors": "",
    "abstract": "Deep learning-based recommender systems have achieved remarkable success in recent years. However, these methods usually heavily rely on labeled data (i.e., user-item interactions), suffering from problems such as data sparsity and cold-start. Self-supervised learning, an emerging paradigm that extracts information from unlabeled data, provides insights into addressing these problems. Specifically, contrastive self-supervised learning, due to its flexibility and promising performance, has attracted considerable interest and recently become a dominant branch in self-supervised learning-based recommendation methods. In this survey, we provide an up-to-date and comprehensive review of current contrastive self-supervised learning-based recommendation methods. Firstly, we propose a unified framework for these methods. We then introduce a taxonomy based on the key components of the framework, including view generation strategy, contrastive task, and contrastive objective. For each component, we provide detailed descriptions and discussions to guide the choice of the appropriate method. Finally, we outline open issues and promising directions for future research.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W4387461044",
    "type": "article"
  },
  {
    "title": "Causal Inference in Recommender Systems: A Survey and Future Directions",
    "doi": "https://doi.org/10.1145/3639048",
    "publication_date": "2024-01-02",
    "publication_year": 2024,
    "authors": "Chen Gao; Yu Zheng; Wenjie Wang; Fuli Feng; Xiangnan He; Yong Li",
    "corresponding_authors": "",
    "abstract": "Recommender systems have become crucial in information filtering nowadays. Existing recommender systems extract user preferences based on the correlation in data, such as behavioral correlation in collaborative filtering, feature-feature, or feature-behavior correlation in click-through rate prediction. However, unfortunately, the real world is driven by causality , not just correlation, and correlation does not imply causation. For instance, recommender systems might recommend a battery charger to a user after buying a phone, where the latter can serve as the cause of the former; such a causal relation cannot be reversed. Recently, to address this, researchers in recommender systems have begun utilizing causal inference to extract causality, thereby enhancing the recommender system. In this survey, we offer a comprehensive review of the literature on causal inference-based recommendation. Initially, we introduce the fundamental concepts of both recommender system and causal inference as the foundation for subsequent content. We then highlight the typical issues faced by non-causality recommender system. Following that, we thoroughly review the existing work on causal inference-based recommender systems, based on a taxonomy of three-aspect challenges that causal inference can address. Finally, we discuss the open problems in this critical research area and suggest important potential future works.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W4390490824",
    "type": "article"
  },
  {
    "title": "Federated Recommender System Based on Diffusion Augmentation and Guided Denoising",
    "doi": "https://doi.org/10.1145/3688570",
    "publication_date": "2024-08-13",
    "publication_year": 2024,
    "authors": "Yicheng Di; Hongjian Shi; Xiaoming Wang; Ruhui Ma; Yuan Liu",
    "corresponding_authors": "",
    "abstract": "Sequential recommender systems often struggle with accurate personalized recommendations due to data sparsity issues. Existing works use variational autoencoders and generative adversarial network methods to enrich sparse data. However, they often overlook diversity in the latent data distribution, hindering the model’s generative capacity. This characteristic of generative methods can introduce additional noise in many cases. Moreover, retaining personalized user preferences through the generation process remains a challenge. This work introduces DGFedRS, a Federated Recommender System Based on Diffusion Augmentation and Guided Denoising, designed to capture the diversity in the latent data distribution while preserving user-specific information and suppressing noise. In particular, we pre-train the diffusion model using the recommender dataset and use a diffusion augmentation strategy to generate interaction sequences, expanding the sparse user-item interactions in the discrete space. To preserve user-specific preferences in the generated interactions, we employ a guided denoising strategy to guide the generation process during reverse diffusion. Subsequently, we design a noise control strategy to reduce the damage to personalized information during the diffusion process. Additionally, a stepwise scheduling strategy is devised to input generated data into the sequential recommender model based on their challenge levels. The success of the DGFedRS approach is demonstrated by thorough experiments conduct on three real-world datasets.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W4401544324",
    "type": "article"
  },
  {
    "title": "Contrastive Modality-Disentangled Learning for Multimodal Recommendation",
    "doi": "https://doi.org/10.1145/3715876",
    "publication_date": "2025-01-28",
    "publication_year": 2025,
    "authors": "Xixun Lin; Rui Liu; Yanan Cao; Lixin Zou; Qian Li; Yongxuan Wu; Yang Liu; Dawei Yin; Guandong Xu",
    "corresponding_authors": "",
    "abstract": "Multimodal recommendation, which utilizes rich multimodal information to learn user preferences, has attracted significant attention. Most works focus on designing powerful encoders for extracting multimodal features, and simply aggregate the learned features together to make prediction. Consequently, they have a limited capacity to learn the inter-modality knowledge including the modality-shared and modality-unique knowledge. In fact, learning the modality-shared knowledge enables us to align cross-modality data for fusing heterogeneous modality features. Learning the modality-unique knowledge is equally important when recommendation tasks only involve a small amount of shared features and the necessary information is contained within specific modality. In this paper, we propose Contrastive Modality-Disentangled Learning (CMDL) to overcome this critical limitation. CMDL exactly captures the inter-modality knowledge by achieving modality disentanglement. Specifically, CMDL first disentangles the initial representation into the modality-invariant and modality-specific representations. Afterwards, CMDL introduces a novel manner of contrastive learning to approximate the MI upper bounds for achieving disentanglement regularization. Building upon the proposed regularization, CMDL encourages the modality-invariant and modality-specific representations to capture the modality-shared and modality-unique knowledge respectively and to be statistically independent to each other. Empirically, extensive experiments are conducted on benchmark datasets, demonstrating the superior performance of CMDL compared with strong multimodal recommenders.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4406903235",
    "type": "article"
  },
  {
    "title": "Mitigating Propensity Bias of Large Language Models for Recommender Systems",
    "doi": "https://doi.org/10.1145/3736404",
    "publication_date": "2025-05-19",
    "publication_year": 2025,
    "authors": "Guixian Zhang; Guan Yuan; Debo Cheng; Lin Liu; Jiuyong Li; Shichao Zhang",
    "corresponding_authors": "",
    "abstract": "The rapid development of Large Language Models (LLMs) creates new opportunities for recommender systems, especially by exploiting the side information (e.g., descriptions and analyses of items) generated by these models. However, aligning this side information with collaborative information from historical interactions poses significant challenges. The inherent biases within LLMs can skew recommendations, resulting in distorted and potentially unfair user experiences. On the other hand, propensity bias causes side information to be aligned in such a way that it often tends to represent all inputs in a low-dimensional subspace, leading to a phenomenon known as dimensional collapse, which severely restricts the recommender system’s ability to capture user preferences and behaviours. To address these issues, we introduce a novel framework named C ounterfactual LLM R ecommendation (CLLMR). Specifically, we propose a spectrum-based side information encoder that implicitly embeds structural information from historical interactions into the side information representation, thereby circumventing the risk of dimension collapse. Furthermore, our CLLMR approach explores the causal relationships inherent in LLM-based recommender systems. By leveraging counterfactual inference, we counteract the biases introduced by LLMs. Extensive experiments demonstrate that our CLLMR approach consistently enhances the performance of various recommender models.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4410502616",
    "type": "article"
  },
  {
    "title": "From Matching to Generation: A Survey on Generative Information Retrieval",
    "doi": "https://doi.org/10.1145/3722552",
    "publication_date": "2025-03-11",
    "publication_year": 2025,
    "authors": "Xiaoxi Li; Jiajie Jin; Yujia Zhou; Yuyao Zhang; Peitian Zhang; Yutao Zhu; Zhicheng Dou",
    "corresponding_authors": "",
    "abstract": "Information Retrieval (IR) systems are crucial tools for users to access information, which have long been dominated by traditional methods relying on similarity matching. With the advancement of pre-trained language models, generative information retrieval (GenIR) emerges as a novel paradigm, attracting increasing attention. Based on the form of information provided to users, current research in GenIR can be categorized into two aspects: (1) Generative Document Retrieval (GR) leverages the generative model’s parameters for memorizing documents, enabling retrieval by directly generating relevant document identifiers without explicit indexing. (2) Reliable Response Generation employs language models to directly generate information users seek, breaking the limitations of traditional IR in terms of document granularity and relevance matching while offering flexibility, efficiency, and creativity to meet practical needs. This paper aims to systematically review the latest research progress in GenIR. We will summarize the advancements in GR regarding model training and structure, document identifier, incremental learning, etc., as well as progress in reliable response generation in aspects of internal knowledge memorization, external knowledge augmentation, etc. We also review the evaluation, challenges and future developments in GenIR systems. This review aims to offer a comprehensive reference for researchers, encouraging further development in the GenIR field. 1",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4408326921",
    "type": "article"
  },
  {
    "title": "A Survey on the Memory Mechanism of Large Language Model based Agents",
    "doi": "https://doi.org/10.1145/3748302",
    "publication_date": "2025-07-11",
    "publication_year": 2025,
    "authors": "Zeyu Zhang; Quanyu Dai; Xiaohe Bo; Chen Ma; Rui Li; Xu Chen; Jieming Zhu; Zhenhua Dong; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Large language model (LLM) based agents have recently attracted much attention from the research and industry communities. Compared with original LLMs, LLM-based agents are featured in their self-evolving capability, which is the basis for solving real-world problems that need long-term and complex agent-environment interactions. The key component to support agent-environment interactions is the memory of the agents. While previous studies have proposed many promising memory mechanisms, they are scattered in different papers, and there lacks a systematical review to summarize and compare these works from a holistic perspective, failing to abstract common and effective designing patterns for inspiring future studies. To bridge this gap, in this paper, we propose a comprehensive survey on the memory mechanism of LLM-based agents. In specific, we first discuss “what is” and “why do we need” the memory in LLM-based agents. Then, we systematically review previous studies on how to design and evaluate the memory module. In addition, we also present many agent applications, where the memory module plays an important role. At last, we analyze the limitations of existing work and show important future directions. To keep up with the latest advances in this field, we create a repository at https://github.com/nuster1128/LLM_Agent_Memory_Survey .",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4412203333",
    "type": "article"
  },
  {
    "title": "Query-based sampling of text databases",
    "doi": "https://doi.org/10.1145/382979.383040",
    "publication_date": "2001-04-01",
    "publication_year": 2001,
    "authors": "Jamie Callan; Margaret E. Connell",
    "corresponding_authors": "",
    "abstract": "The proliferation of searchable text databases on corporate networks and the Internet causes a database selection problem for many people. Algorithms such as gGLOSS and CORI can automatically select which text databases to search for a given information need, but only if given a set of resource descriptions that accurately represent the contents of each database. The existing techniques for a acquiring resource descriptions have significant limitations when used in wide-area networks controlled by many parties. This paper presents query-based sampling , a new technicque for acquiring accurate resource descriptions. Query-based sampling does not require the cooperation of resource providers, nor does it require that resource providers use a particular search engine or representation technique. An extensive set of experimental results demonstrates that accurate resource descriptions are crated, that computation and communication costs are reasonable, and that the resource descriptions do in fact enable accurate automatic dtabase selection.",
    "cited_by_count": 381,
    "openalex_id": "https://openalex.org/W1986828474",
    "type": "article"
  },
  {
    "title": "An information-theoretic approach to automatic query expansion",
    "doi": "https://doi.org/10.1145/366836.366860",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Claudio Carpineto; Renato De Mori; Giovanni Romano; Brigitte Bigi",
    "corresponding_authors": "",
    "abstract": "Techniques for automatic query expansion from top retrieved documents have shown promise for improving retrieval effectiveness on large collections; however, they often rely on an empirical ground, and there is a shortage of cross-system comparisons. Using ideas from Information Theory, we present a computationally simple and theoretically justified method for assigning scores to candidate expansion terms. Such scores are used to select and weight expansion terms within Rocchio's framework for query reweigthing. We compare ranking with information-theoretic query expansion versus ranking with other query expansion techniques, showing that the former achieves better retrieval effectiveness on several performance measures. We also discuss the effect on retrieval effectiveness of the main parameters involved in automatic query expansion, such as data sparseness, query difficulty, number of selected documents, and number of selected terms, pointing out interesting relationships.",
    "cited_by_count": 379,
    "openalex_id": "https://openalex.org/W2034117506",
    "type": "article"
  },
  {
    "title": "Exploiting hierarchical domain structure to compute similarity",
    "doi": "https://doi.org/10.1145/635484.635487",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Prasanna Ganesan; Héctor García-Molina; Jennifer Widom",
    "corresponding_authors": "",
    "abstract": "The notion of similarity between objects finds use in many contexts, for example, in search engines, collaborative filtering, and clustering. Objects being compared often are modeled as sets, with their similarity traditionally determined based on set intersection. Intersection-based measures do not accurately capture similarity in certain domains, such as when the data is sparse or when there are known relationships between items within sets. We propose new measures that exploit a hierarchical domain structure in order to produce more intuitive similarity scores. We extend our similarity measures to provide appropriate results in the presence of multisets (also handled unsatisfactorily by traditional measures), for example, to correctly compute the similarity between customers who buy several instances of the same product (say milk), or who buy several products in the same category (say dairy products). We also provide an experimental comparison of our measures against traditional similarity measures, and report on a user study that evaluated how well our measures match human intuition.",
    "cited_by_count": 367,
    "openalex_id": "https://openalex.org/W1973754941",
    "type": "article"
  },
  {
    "title": "Self-indexing inverted files for fast text retrieval",
    "doi": "https://doi.org/10.1145/237496.237497",
    "publication_date": "1996-10-01",
    "publication_year": 1996,
    "authors": "Alistair Moffat; Justin Zobel",
    "corresponding_authors": "",
    "abstract": "Query-processing costs on large text databases are dominated by the need to retrieve and scan the inverted list of each query term. Retrieval time for inverted lists can be greatly reduced by the use of compression, but this adds to the CPU time required. Here we show that the CPU component of query response time for conjunctive Boolean queries and for informal ranked queries can be similarly reduced, at little cost in terms of storage, by the inclusion of an internal index in each compressed inverted list. This method has been applied in a retrieval system for a collection of nearly two million short documents. Our experimental results show that the self-indexing strategy adds less than 20% to the size of the compressed inverted file, which itself occupies less than 10% of the indexed text, yet can reduce processing time for Boolean queries of 5-10 terms to under one fifth of the previous cost. Similarly, ranked queries of 40-50 terms can be evaluated in as little as 25% of the previous time, with little or no loss of retrieval effectiveness.",
    "cited_by_count": 366,
    "openalex_id": "https://openalex.org/W2125203709",
    "type": "article"
  },
  {
    "title": "SALSA",
    "doi": "https://doi.org/10.1145/382979.383041",
    "publication_date": "2001-04-01",
    "publication_year": 2001,
    "authors": "Ronny Lempel; Shlomo Moran",
    "corresponding_authors": "",
    "abstract": "Today, when searching for information on the WWW, one usually performs a query through a term-based search engine. These engines return, as the query's result, a list of Web pages whose contents matches the query. For broad-topic queries, such searches often result in a huge set of retrieved documents, many of which are irrelevant to the user. However, much information is contained in the link-structure of the WWW. Information such as which pages are linked to others can be used to augment search algorithms. In this context, Jon Kleinberg introduced the notion of two distinct types of Web pages: hubs and authorities . Kleinberg argued that hubs and authorities exhibit a mutually reinforcing relationship : a good hub will point to many authorities, and a good authority will be pointed at by many hubs. In light of this, he dervised an algoirthm aimed at finding authoritative pages. We present SALSA, a new stochastic approach for link-structure analysis, which examines random walks on graphs derived from the link-structure. We show that both SALSA and Kleinberg's Mutual Reinforcement approach employ the same metaalgorithm. We then prove that SALSA is quivalent to a weighted in degree analysis of the link-sturcutre of WWW subgraphs, making it computationally more efficient than the Mutual reinforcement approach. We compare that results of applying SALSA to the results derived through Kleinberg's approach. These comparisions reveal a topological Phenomenon called the TKC effect which, in certain cases, prevents the Mutual reinforcement approach from identifying meaningful authorities.",
    "cited_by_count": 364,
    "openalex_id": "https://openalex.org/W2039976898",
    "type": "article"
  },
  {
    "title": "Context-sensitive learning methods for text categorization",
    "doi": "https://doi.org/10.1145/306686.306688",
    "publication_date": "1999-04-01",
    "publication_year": 1999,
    "authors": "William W. Cohen; Yoram Singer",
    "corresponding_authors": "",
    "abstract": "Two recently implemented machine-learning algorithms, RIPPER and sleeping-experts for phrases , are evaluated on a number of large text categorization problems. These algorithms both construct classifiers that allow the “context” of a word w to affect how (or even whether) the presence or absence of w will contribute to a classification. However, RIPPER and sleeping-experts differ radically in many other respects: differences include different notions as to what constitutes a context, different ways of combining contexts to construct a classifier, different methods to search for a combination of contexts, and different criteria as to what contexts should be included in such a combination. In spite of these differences, both RIPPER and sleeping-experts perform extremely well across a wide variety of categorization problems, generally outperforming previously applied learning methods. We view this result as a confirmation of the usefulness of classifiers that represent contextual information.",
    "cited_by_count": 354,
    "openalex_id": "https://openalex.org/W1969572066",
    "type": "article"
  },
  {
    "title": "Context interchange",
    "doi": "https://doi.org/10.1145/314516.314520",
    "publication_date": "1999-07-01",
    "publication_year": 1999,
    "authors": "Cheng Hian Goh; Stéphane Bressan; Stuart Madnick; Michael Siegel",
    "corresponding_authors": "",
    "abstract": "The Context Interchange strategy presents a novel perspective for mediated data access in which semantic conflicts among heterogeneous systems are not identified a priori, but are detected and reconciled by a context mediator through comparison of contexts axioms corresponding to the systems engaged in data exchange. In this article, we show that queries formulated on shared views, export schema, and shared “ontologies” can be mediated in the same way using the Context Interchange framework . The proposed framework provides a logic-based object-oriented formalsim for representing and reasoning about data semantics in disparate systems, and has been validated in a prototype implementation providing mediated data access to both traditional and web-based information sources.",
    "cited_by_count": 348,
    "openalex_id": "https://openalex.org/W2083915057",
    "type": "article"
  },
  {
    "title": "Streams, structures, spaces, scenarios, societies (5s)",
    "doi": "https://doi.org/10.1145/984321.984325",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Marcos André Gonçalves; Edward A. Fox; Layne T. Watson; Neill A. Kipp",
    "corresponding_authors": "",
    "abstract": "Digital libraries (DLs) are complex information systems and therefore demand formal foundations lest development efforts diverge and interoperability suffers. In this article, we propose the fundamental abstractions of Streams, Structures, Spaces, Scenarios, and Societies (5S), which allow us to define digital libraries rigorously and usefully. Streams are sequences of arbitrary items used to describe both static and dynamic (e.g., video) content. Structures can be viewed as labeled directed graphs, which impose organization. Spaces are sets with operations on those sets that obey certain constraints. Scenarios consist of sequences of events or actions that modify states of a computation in order to accomplish a functional requirement. Societies are sets of entities and activities and the relationships among them. Together these abstractions provide a formal foundation to define, relate, and unify concepts---among others, of digital objects, metadata, collections, and services---required to formalize and elucidate \"digital libraries\". The applicability, versatility, and unifying power of the 5S model are demonstrated through its use in three distinct applications: building and interpretation of a DL taxonomy, informal and formal analysis of case studies of digital libraries (NDLTD and OAI), and utilization as a formal basis for a DL description language.",
    "cited_by_count": 330,
    "openalex_id": "https://openalex.org/W2004276548",
    "type": "article"
  },
  {
    "title": "PocketLens",
    "doi": "https://doi.org/10.1145/1010614.1010618",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "Brad Miller; Joseph A. Konstan; John Riedl",
    "corresponding_authors": "",
    "abstract": "Recommender systems using collaborative filtering are a popular technique for reducing information overload and finding products to purchase. One limitation of current recommenders is that they are not portable. They can only run on large computers connected to the Internet. A second limitation is that they require the user to trust the owner of the recommender with personal preference data. Personal recommenders hold the promise of delivering high quality recommendations on palmtop computers, even when disconnected from the Internet. Further, they can protect the user's privacy by storing personal information locally, or by sharing it in encrypted form. In this article we present the new PocketLens collaborative filtering algorithm along with five peer-to-peer architectures for finding neighbors. We evaluate the architectures and algorithms in a series of offline experiments. These experiments show that Pocketlens can run on connected servers, on usually connected workstations, or on occasionally connected portable devices, and produce recommendations that are as good as the best published algorithms to date.",
    "cited_by_count": 328,
    "openalex_id": "https://openalex.org/W2020480318",
    "type": "article"
  },
  {
    "title": "A morphological analysis of the design space of input devices",
    "doi": "https://doi.org/10.1145/123078.128726",
    "publication_date": "1991-04-01",
    "publication_year": 1991,
    "authors": "Stuart K. Card; Jock D. Mackinlay; George G. Robertson",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on A morphological analysis of the design space of input devices Authors: Stuart K. Card Xerox Palo Alto Research Center Xerox Palo Alto Research CenterView Profile , Jock D. Mackinlay Xerox Palo Alto Research Center Xerox Palo Alto Research CenterView Profile , George G. Robertson Xerox Palo Alto Research Center Xerox Palo Alto Research CenterView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 9Issue 2April 1991 pp 99–122https://doi.org/10.1145/123078.128726Online:01 April 1991Publication History 157citation3,980DownloadsMetricsTotal Citations157Total Downloads3,980Last 12 Months253Last 6 weeks29 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 324,
    "openalex_id": "https://openalex.org/W2036024905",
    "type": "article"
  },
  {
    "title": "Analyzing due process in the workplace",
    "doi": "https://doi.org/10.1145/214427.214431",
    "publication_date": "1986-07-01",
    "publication_year": 1986,
    "authors": "Elihu M. Gerson; Susan Leigh Star",
    "corresponding_authors": "",
    "abstract": "Every office is an open system, and the products of office work are the result of decentralized negotiations. Changing patterns of task organization and alliance inevitably give rise to inconsistent knowledge bases and procedures. This implies that there are no globally correct answers to problems addressed by OISs. Rather, systems must deal with multiple competing, possibly irreconcilable, solutions. Articulating alternative solutions is the problem of due process . This problem and its consequences are illustrated by a case study of a rate-setting group in a large health insurance firm. There is no formal solution to the problem of due process. But it must be solved in practice if distributed intelligent OISs are to be developed. We propose an alternative approach based on the work of social scientists concerned with analyzing analogous problems in human organization. Solution of the due process problem hinges on developing local closures to the problem faced by an organization. This means analyzing (a) local, tacit knowledge and its transfer ability; (b) articulation work, that is, reconciling incommensurate assumptions and procedures.",
    "cited_by_count": 320,
    "openalex_id": "https://openalex.org/W2974702374",
    "type": "article"
  },
  {
    "title": "Petri-net-based hypertext: document structure with browsing semantics",
    "doi": "https://doi.org/10.1145/64789.64791",
    "publication_date": "1989-01-03",
    "publication_year": 1989,
    "authors": "P. David Stotts; Richard Furuta",
    "corresponding_authors": "",
    "abstract": "We present a formal definition of the Trellis model of hypertext and describe an authoring and browsing prototype called αTrellis that is based on the model. The Trellis model not only represents the relationships that tie individual pieces of information together into a document (i.e., the adjacencies), but specifies the browsing semantics to be associated with the hypertext as well (i.e., the manner in which the information is to be visited and presented). The model is based on Petri nets, and is a generalization of existing directed graph-based forms of hypertext. The Petri net basis permits more powerful specification of what is to be displayed when a hypertext is browsed and permits application of previously developed Petri net analysis techniques to verify properties of the hypertext. A number of useful hypertext constructs, easily described in the Trellis model, are presented. These include the synchronization of simultaneous traversals of separate paths through a hypertext, the incorporation of access controls into a hypertext (i.e., specifying nodes that can be proven to be accessible only to certain classes of browsers), and construction of multiple specialized (tailored) versions from a single hypertext.",
    "cited_by_count": 318,
    "openalex_id": "https://openalex.org/W1998215802",
    "type": "article"
  },
  {
    "title": "Finding a happy medium",
    "doi": "https://doi.org/10.1145/196734.196738",
    "publication_date": "1994-04-01",
    "publication_year": 1994,
    "authors": "M. Lynne Markus",
    "corresponding_authors": "M. Lynne Markus",
    "abstract": "The sometimes observed negative social effects of electronic communication technology are often attributed to the characteristics of the technology itself. Electronic mail, for instance, filters out personal and social cues and provides new capabilities not found in traditional media, and it has been argued that these factors have consequences such as “flaming” and depersonalization. Alternative theoretical perspectives on the impacts of information technology suggest that our ability to explain these outcomes might be enhanced by attending to users' intentional choices about how to use technology and to unpredictable technology usage patterns that emerge when users interact with the technology and each other. These alternative perspectives are examined in the context of an exploratory case study of a complex organization in which electronic mail was heavily used. Users were found to select email deliberately when they wished to avoid unwanted social interactions. At the same time, they actively took steps to avoid negative outcomes, such as depersonalization of their relationships with subordinates. However, despite their well-intentioned efforts, some negative social effects did occur that cannot entirely be attributed to the technological characteristics of electronic communication. Instead, they appear to be ironic side effects of users' thoughtful efforts to use email effectively. These results suggest the value of according a prominent role in explanations of technology impacts to users' intended and unintended technology uses. The results also imply that negative social effects from using electronic communication technology may not prove easy to eradicate, despite technological developments such as multimedia integration, and despite efforts to train users in the best email “etiquette.”",
    "cited_by_count": 317,
    "openalex_id": "https://openalex.org/W2162228590",
    "type": "article"
  },
  {
    "title": "Corpus-based stemming using cooccurrence of word variants",
    "doi": "https://doi.org/10.1145/267954.267957",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "Jinxi Xu; W. Bruce Croft",
    "corresponding_authors": "",
    "abstract": "Stemming is used in many information retrieval (IR) systems to reduce variant word forms to common roots. It is one of the simplest applications of natural-language processing to IR and is one of the most effective in terms of user acceptance and consistency, though small retrieval improvements. Current stemming techniques do not, however, reflect the language use in specific corpora, and this can lead to occasional serious retrieval failures. We propose a technique for using corpus-based word variant cooccurrence statistics to modify or create a stemmer. The experimental results generated using English newspaper and legal text and Spanish text demonstrate the viability of this technique and its advantages relative to conventional approaches that only employ morphological rules.",
    "cited_by_count": 316,
    "openalex_id": "https://openalex.org/W2008495066",
    "type": "article"
  },
  {
    "title": "Design and evaluation of algorithms for image retrieval by spatial similarity",
    "doi": "https://doi.org/10.1145/201040.201041",
    "publication_date": "1995-04-01",
    "publication_year": 1995,
    "authors": "Venkat N. Gudivada; Vijay V. Raghavan",
    "corresponding_authors": "",
    "abstract": "Similarity-based retrieval of images is an important task in many image database applications. A major class of users' requests requires retrieving those images in the database that are spatially similar to the query image. We propose an algorithm for computing the spatial similarity between two symbolic images. A symbolic image is a logical representation of the original image where the image objects are uniquely labeled with symbolic names. Spatial relationships in a symbolic image are represented as edges in a weighted graph referred to as spatial-orientation graph. Spatial similarity is then quantified in terms of the number of, as well as the extent to which, the edges of the spatial-orientation graph of the database image conform to the corresponding edges of the spatial-orientation graph of the query image. The proposed algorithm is robust in the sense that it can deal with translation, scale, and rotational variances in images. The algorithm has quadratic time complexity in terms of the total number of objects in both the database and query images. We also introduce the idea of quantifying a system's retrieval quality by having an expert specify the expected rank ordering with respect to each query for a set of test queries. This enables us to assess the quality of algorithms comprehensively for retrieval in image databases. The characteristics of the proposed algorithm are compared with those of the previously available algorithms using a testbed of images. The comparison demonstrated that our algorithm is not only more efficient but also provides a rank ordering of images that consistently matches with the expert's expected rank ordering.",
    "cited_by_count": 303,
    "openalex_id": "https://openalex.org/W2061993166",
    "type": "article"
  },
  {
    "title": "VAGUE: a user interface to relational databases that permits vague queries",
    "doi": "https://doi.org/10.1145/45945.48027",
    "publication_date": "1988-07-01",
    "publication_year": 1988,
    "authors": "Amihai Motro",
    "corresponding_authors": "Amihai Motro",
    "abstract": "A specific query establishes a rigid qualification and is concerned only with data that match it precisely. A vague query establishes a target qualification and is concerned also with data that are close to this target. Most conventional database systems cannot handle vague queries directly, forcing their users to retry specific queries repeatedly with minor modifications until they match data that are satisfactory. This article describes a system called VAGUE that can handle vague queries directly. The principal concept behind VAGUE is its extension to the relational data model with data metrics, which are definitions of distances between values of the same domain. A problem with implementing data distances is that different users may have different interpretations for the notion of distance. VAGUE incorporates several features that enable it to adapt itself to the individual views and priorities of its users.",
    "cited_by_count": 299,
    "openalex_id": "https://openalex.org/W2108699731",
    "type": "article"
  },
  {
    "title": "Repeatable evaluation of search services in dynamic environments",
    "doi": "https://doi.org/10.1145/1292591.1292592",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Eric C. Jensen; Steven M. Beitzel; Abdur Chowdhury; Ophir Frieder",
    "corresponding_authors": "",
    "abstract": "In dynamic environments, such as the World Wide Web, a changing document collection, query population, and set of search services demands frequent repetition of search effectiveness (relevance) evaluations. Reconstructing static test collections, such as in TREC, requires considerable human effort, as large collection sizes demand judgments deep into retrieved pools. In practice it is common to perform shallow evaluations over small numbers of live engines (often pairwise, engine A vs. engine B) without system pooling. Although these evaluations are not intended to construct reusable test collections, their utility depends on conclusions generalizing to the query population as a whole. We leverage the bootstrap estimate of the reproducibility probability of hypothesis tests in determining the query sample sizes required to ensure this, finding they are much larger than those required for static collections. We propose a semiautomatic evaluation framework to reduce this effort. We validate this framework against a manual evaluation of the top ten results of ten Web search engines across 896 queries in navigational and informational tasks. Augmenting manual judgments with pseudo-relevance judgments mined from Web taxonomies reduces both the chances of missing a correct pairwise conclusion, and those of finding an errant conclusion, by approximately 50%.",
    "cited_by_count": 278,
    "openalex_id": "https://openalex.org/W2077620588",
    "type": "article"
  },
  {
    "title": "Extending object-oriented systems with roles",
    "doi": "https://doi.org/10.1145/230538.230540",
    "publication_date": "1996-07-01",
    "publication_year": 1996,
    "authors": "Georg Gottlob; Michael Schrefl; Brigitte Röck",
    "corresponding_authors": "",
    "abstract": "In many class-based object-oriented systems the association between as instance and a class is exclusive and permanent. Therefore these systems have serious difficulties in representing objects taking on different roles over time. Such objects must be reclassified any time they evolve (e.g., if a person becomes a student and later an employee). Class hierarchies must be planned carefully and may grow exponentially if entities may take on serveral independent roles. The problem is even more servere for object-oriented databases than for common object-oriented programming. Databases store objects over longer periods, during which the represented entities evolve. This article shows how class-based object-oriented systems can be extended to handle evolving objects well. Class hierarchies are complemented by role hierarchies, whose nodes represent role types an object classified in the root may take on. At any point in time, an entity is represented by an instance of the root and an instance of every role type whose role it currently plays. In a natural way, the approach extends traditional object-oriented concepts, such as classification, object identity, specialization, inheritance, and polymorphism in a natural way. The practicability of the approach is demonstrated by an implementation in Smalltalk. Smalltalk was chosen because it is widely known, which is not true for any particular class-based object-oriented database programming language. Roles can be provided in Smalltalk by adding a few classes. There is no need to modify the semantics of Smalltalk itself. Role hierarchies are mapped transparently onto ordinary classes. The presented implementation can easily be ported to object-oriented database programming languages based on Smalltalk, such as Gemstone's OPAL hierarchies are complemented by role hierarchies, whose nodes represent role types an object classified in the root may take on. At any point in time, an entity is represented by an instance of the root and an instance of every role type whose role in currently plays.",
    "cited_by_count": 273,
    "openalex_id": "https://openalex.org/W1965695377",
    "type": "article"
  },
  {
    "title": "Collection statistics for fast duplicate document detection",
    "doi": "https://doi.org/10.1145/506309.506311",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "Abdur Chowdhury; Ophir Frieder; David A. Grossman; M. Catherine McCabe",
    "corresponding_authors": "",
    "abstract": "We present a new algorithm for duplicate document detection that uses collection statistics. We compare our approach with the state-of-the-art approach using multiple collections. These collections include a 30 MB 18,577 web document collection developed by Excite@Home and three NIST collections. The first NIST collection consists of 100 MB 18,232 LA-Times documents, which is roughly similar in the number of documents to the Excite&amp;at;Home collection. The other two collections are both 2 GB and are the 247,491-web document collection and the TREC disks 4 and 5---528,023 document collection. We show that our approach called I-Match, scales in terms of the number of documents and works well for documents of all sizes. We compared our solution to the state of the art and found that in addition to improved accuracy of detection, our approach executed in roughly one-fifth the time.",
    "cited_by_count": 257,
    "openalex_id": "https://openalex.org/W2067432306",
    "type": "article"
  },
  {
    "title": "Information systems interoperability",
    "doi": "https://doi.org/10.1145/1028099.1028103",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "Jinsoo Park; Sudha Ram",
    "corresponding_authors": "",
    "abstract": "Interoperability is the most critical issue facing businesses that need to access information from multiple information systems. Our objective in this research is to develop a comprehensive framework and methodology to facilitate semantic interoperability among distributed and heterogeneous information systems. A comprehensive framework for managing various semantic conflicts is proposed. Our proposed framework provides a unified view of the underlying representational and reasoning formalism for the semantic mediation process. This framework is then used as a basis for automating the detection and resolution of semantic conflicts among heterogeneous information sources. We define several types of semantic mediators to achieve semantic interoperability. A domain-independent ontology is used to capture various semantic conflicts. A mediation-based query processing technique is developed to provide uniform and integrated access to the multiple heterogeneous databases. A usable prototype is implemented as a proof-of-concept for this work. Finally, the usefulness of our approach is evaluated using three cases in different application domains. Various heterogeneous datasets are used during the evaluation phase. The results of the evaluation suggest that correct identification and construction of both schema and ontology-schema mapping knowledge play very important roles in achieving interoperability at both the data and schema levels.",
    "cited_by_count": 256,
    "openalex_id": "https://openalex.org/W2093993994",
    "type": "article"
  },
  {
    "title": "Fast and flexible word searching on compressed text",
    "doi": "https://doi.org/10.1145/348751.348754",
    "publication_date": "2000-04-01",
    "publication_year": 2000,
    "authors": "Edleno Silva de Moura; Gonzalo Navarro; Nívio Ziviani; Ricardo Baeza‐Yates",
    "corresponding_authors": "",
    "abstract": "We present a fast compression technique for natural language texts. The novelties are that (1) decompression of arbitrary portions of the text can be done very efficiently, (2) exact search for words and phrases can be done on the compressed text directly, using any known sequential pattern-matching algorithm, and (3) word-based approximate and extended search can also be done efficiently without any decoding. The compression scheme uses a semistatic word-based model and a Huffman code where the coding alphabet is byte-oriented rather than bit-oriented. We compress typical English texts to about 30% of their original size, against 40% and 35% for Compress and Gzip , respectively. Compression time is close to that of Compress and approximately half of the time of Gzip , and decompression time is lower than that of Gzip and one third of that of Compress . We present three algorithms to search the compressed text. They allow a large number of variations over the basic word and phrase search capability, such as sets of characters, arbitrary regular expressions, and approximate matching. Separators and stopwords can be discarded at search time without significantly increasing the cost. When searching for simple words, the experiments show that running our algorithms on a compressed text is twice as fast as running the best existing software on the uncompressed version of the same text. When searching complex or approximate patterns, our algorithms are up to 8 times faster than the search on uncompressed text. We also discuss the impact of our technique in inverted files pointing to logical blocks and argue for the possibility of keeping the text compressed all the time, decompressing only for displaying purposes.",
    "cited_by_count": 250,
    "openalex_id": "https://openalex.org/W2013849299",
    "type": "article"
  },
  {
    "title": "CrimeNet explorer: a framework for criminal network knowledge discovery",
    "doi": "https://doi.org/10.1145/1059981.1059984",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Jennifer Xu; Hsinchun Chen",
    "corresponding_authors": "",
    "abstract": "Knowledge about the structure and organization of criminal networks is important for both crime investigation and the development of effective strategies to prevent crimes. However, except for network visualization, criminal network analysis remains primarily a manual process. Existing tools do not provide advanced structural analysis techniques that allow extraction of network knowledge from large volumes of criminal-justice data. To help law enforcement and intelligence agencies discover criminal network knowledge efficiently and effectively, in this research we proposed a framework for automated network analysis and visualization. The framework included four stages: network creation, network partition, structural analysis, and network visualization. Based upon it, we have developed a system called CrimeNet Explorer that incorporates several advanced techniques: a concept space approach, hierarchical clustering, social network analysis methods, and multidimensional scaling. Results from controlled experiments involving student subjects demonstrated that our system could achieve higher clustering recall and precision than did untrained subjects when detecting subgroups from criminal networks. Moreover, subjects identified central members and interaction patterns between groups significantly faster with the help of structural analysis functionality than with only visualization functionality. No significant gain in effectiveness was present, however. Our domain experts also reported that they believed CrimeNet Explorer could be very useful in crime investigation.",
    "cited_by_count": 247,
    "openalex_id": "https://openalex.org/W2077573113",
    "type": "article"
  },
  {
    "title": "Sound and complete relevance assessment for XML retrieval",
    "doi": "https://doi.org/10.1145/1416950.1416951",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Benjamin Piwowarski; Andrew Trotman; Mounia Lalmas",
    "corresponding_authors": "",
    "abstract": "In information retrieval research, comparing retrieval approaches requires test collections consisting of documents, user requests and relevance assessments. Obtaining relevance assessments that are as sound and complete as possible is crucial for the comparison of retrieval approaches. In XML retrieval, the problem of obtaining sound and complete relevance assessments is further complicated by the structural relationships between retrieval results. A major difference between XML retrieval and flat document retrieval is that the relevance of elements (the retrievable units) is not independent of that of related elements. This has major consequences for the gathering of relevance assessments. This article describes investigations into the creation of sound and complete relevance assessments for the evaluation of content-oriented XML retrieval as carried out at INEX, the evaluation campaign for XML retrieval. The campaign, now in its seventh year, has had three substantially different approaches to gather assessments and has finally settled on a highlighting method for marking relevant passages within documents—even though the objective is to collect assessments at element level. The different methods of gathering assessments at INEX are discussed and contrasted. The highlighting method is shown to be the most reliable of the methods.",
    "cited_by_count": 244,
    "openalex_id": "https://openalex.org/W1967370444",
    "type": "article"
  },
  {
    "title": "Scaling question answering to the web",
    "doi": "https://doi.org/10.1145/502115.502117",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Cody Kwok; Oren Etzioni; Daniel S. Weld",
    "corresponding_authors": "",
    "abstract": "The wealth of information on the web makes it an attractive resource for seeking quick answers to simple, factual questions such as “who was the first American in space?” or “what is the second tallest mountain in the world?” Yet today's most advanced web search services (e.g., Google and AskJeeves) make it surprisingly tedious to locate answers to such questions. In this paper, we extend question-answering techniques, first studied in the information retrieval literature, to the web and experimentally evaluate their performance.First we introduce Mulder, which we believe to be the first general-purpose, fully-automated question-answering system available on the web. Second, we describe Mulder's architecture, which relies on multiple search-engine queries, natural-language parsing, and a novel voting procedure to yield reliable answers coupled with high recall. Finally, we compare Mulder's performance to that of Google and AskJeeves on questions drawn from the TREC-8 question answering track. We find that Mulder's recall is more than a factor of three higher than that of AskJeeves. In addition, we find that Google requires 6.6 times as much user effort to achieve the same level of recall as Mulder.",
    "cited_by_count": 243,
    "openalex_id": "https://openalex.org/W2104009457",
    "type": "article"
  },
  {
    "title": "Performance issues and error analysis in an open-domain question answering system",
    "doi": "https://doi.org/10.1145/763693.763694",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "Dan Moldovan; Marius Paşca; Sanda M. Harabagiu; Mihai Surdeanu",
    "corresponding_authors": "",
    "abstract": "This paper presents an in-depth analysis of a state-of-the-art Question Answering system. Several scenarios are examined: (1) the performance of each module in a serial baseline system, (2) the impact of feedbacks and the insertion of a logic prover, and (3) the impact of various retrieval strategies and lexical resources. The main conclusion is that the overall performance depends on the depth of natural language processing resources and the tools used for answer finding.",
    "cited_by_count": 241,
    "openalex_id": "https://openalex.org/W2029118765",
    "type": "article"
  },
  {
    "title": "Data integration using similarity joins and a word-based information representation language",
    "doi": "https://doi.org/10.1145/352595.352598",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "William W. Cohen",
    "corresponding_authors": "William W. Cohen",
    "abstract": "The integration of distributed, heterogeneous databases, such as those available on the World Wide Web, poses many problems. Herer we consider the problem of integrating data from sources that lack common object identifiers. A solution to this problem is proposed for databases that contain informal, natural-language “names” for objects; most Web-based databases satisfy this requirement, since they usually present their information to the end-user through a veneer of text. We describe WHIRL, a “soft” database management system which supports “similarity joins,” based on certain robust, general-purpose similarity metrics for text. This enables fragments of text (e.g., informal names of objects) to be used as keys. WHIRL includes textual objects as a built-in type, similarity reasoning as a built-in predicate, and answers every query with a list of answer substitutions that are ranked according to an overall score. Experiments show that WHIRL is much faster than naive inference methods, even for short queries, and efficient on typical queries to real-world databases with tens of thousands of tuples. Inferences made by WHIRL are also surprisingly accurate, equaling the accuracy of hand-coded normalization routines on one benchmark problem, and outerperforming exact matching with a plausible global domain on a second.",
    "cited_by_count": 234,
    "openalex_id": "https://openalex.org/W2052581258",
    "type": "article"
  },
  {
    "title": "Guided tours and tabletops: tools for communicating in a hypertext environment",
    "doi": "https://doi.org/10.1145/58566.59299",
    "publication_date": "1988-10-01",
    "publication_year": 1988,
    "authors": "Randall H. Trigg",
    "corresponding_authors": "Randall H. Trigg",
    "abstract": "The author of a complex hypertext document is often faced with the problem of conveying the document's meaning to future readers through a shared computer environment. Two tools implemented in the NoteCards hypertext environment, guided tours and tabletops, allow authors to employ annotation, graphic layout, and ordered presentation when communicating to readers. This paper describes these tools and gives examples of their use. Issues of remote pointing arising from an application in legal argumentation are discussed as well as early work on the use of these tools to support sharing of hypertext strategies among NoteCards users.",
    "cited_by_count": 234,
    "openalex_id": "https://openalex.org/W2054149722",
    "type": "article"
  },
  {
    "title": "A semidiscrete matrix decomposition for latent semantic indexing information retrieval",
    "doi": "https://doi.org/10.1145/291128.291131",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "Tamara G. Kolda; Dianne P. O’Leary",
    "corresponding_authors": "",
    "abstract": "The vast amount of textual information available today is useless unless it can be effectively and efficiently searched. The goal in information retrieval is to find documents that are relevant to a given user query. We can represent and document collection by a matrix whose ( i, j) entry is nonzero only if the i th term appears in the j th document; thus each document corresponds to a columm vector. The query is also represented as a column vector whose i th term is nonzero only if the i th term appears in the query. We score each document for relevancy by taking its inner product with the query. The highest-scoring documents are considered the most relevant. Unfortunately, this method does not necessarily retrieve all relevant documents because it is based on literal term matching. Latent semantic indexing (LSI) replaces the document matrix with an approximation generated by the truncated singular-value decomposition (SVD). This method has been shown to overcome many difficulties associated with literal term matching. In this article we propose replacing the SVD with the semidiscrete decomposition (SDD). We will describe the SDD approximation, show how to compute it, and compare the SDD-based LSI method to the SVD-based LSI methods. We will show that SDD-based LSI does as well as SVD-based LSI in terms of document retrieval while requiring only one-twentieth the storage and one-half the time to compute each query. We will also show how to update the SDD approximation when documents are added or deleted from the document collection.",
    "cited_by_count": 234,
    "openalex_id": "https://openalex.org/W2080051508",
    "type": "article"
  },
  {
    "title": "Extending document management systems with user-specific active properties",
    "doi": "https://doi.org/10.1145/348751.348758",
    "publication_date": "2000-04-01",
    "publication_year": 2000,
    "authors": "Paul Dourish; W. Keith Edwards; Anthony LaMarca; John Lamping; Karin Anna Petersen; Michael Salisbury; Douglas B. Terry; James D. Thornton",
    "corresponding_authors": "",
    "abstract": "Document properties are a compelling infrastructure on which to develop document management applications. A property-based approach avoids many of the problems of traditional heierarchical storage mechanisms, reflects document organizations meaningful to user tasks, provides a means to integrate the perspectives of multiple individuals and groups, and does this all within a uniform interaction framework. Document properties can reflect not only categorizations of documents and document use, but also expressions of desired system activity, such as sharing criteria, replication management, and versioning. Augmenting property-based document management systems with active properties that carry executable code enables the provision of document-based services on a property infrastructure. The combination of document properties as a uniform mechanism for document management, and active properties as a way of delivering document services, represents a new paradigm for document management infrastructures. The Placeless Documents system is an experimental prototype developed to explore this new paradigm. It is based on the seamless integration of user-specific, active properties. We present the fundamental design approach, explore the challenges and opportunities it presents, and show our architectures deals with them.",
    "cited_by_count": 233,
    "openalex_id": "https://openalex.org/W2082001372",
    "type": "article"
  },
  {
    "title": "Augmenting organizational memory",
    "doi": "https://doi.org/10.1145/290159.290160",
    "publication_date": "1998-07-01",
    "publication_year": 1998,
    "authors": "Mark S. Ackerman",
    "corresponding_authors": "Mark S. Ackerman",
    "abstract": "A growing concern for organizations and groups has been to augment their knowledge and expertise. One such augmentation is to provide an organizational memory, some record of the organization's knowledge. However, relatively little is known about how computer systems might enhance organizational, group, or community memory. This article presents Answer Garden, a system for growing organizational memory. The article describes the system and its underlying implementation. It then presents findings from a field study of Answer Garden. The article discusses the usage data and qualitative evaluations from the field study, and then draws a set of lessons for next-generation organizational memory systems.",
    "cited_by_count": 232,
    "openalex_id": "https://openalex.org/W1983708541",
    "type": "article"
  },
  {
    "title": "Data sharing in group work",
    "doi": "https://doi.org/10.1145/27636.27640",
    "publication_date": "1987-04-01",
    "publication_year": 1987,
    "authors": "Irene Greif; Sunil K. Sarin",
    "corresponding_authors": "",
    "abstract": "Data sharing is fundamental to computer-supported cooperative work: People share information through explicit communication channels and through their coordinated use of shared databases. This paper examines the data management requirements of group work applications on the basis of experience with three prototype systems and on observations from the literature. Database and object management technologies that support these requirements are briefly surveyed, and unresolved issues in the particular areas of access control and concurrency control are identified for future research.",
    "cited_by_count": 229,
    "openalex_id": "https://openalex.org/W2067025103",
    "type": "article"
  },
  {
    "title": "Context and orientation in hypermedia networks",
    "doi": "https://doi.org/10.1145/64789.64992",
    "publication_date": "1989-01-03",
    "publication_year": 1989,
    "authors": "Kenneth Utting; Nicole Yankelovich",
    "corresponding_authors": "",
    "abstract": "The core of hypermedia's power lies in the complex networks of links that can be created within and between documents. However, these networks frequently overwhelm the user and become a source of confusion. Within Intermedia, we have developed the Web View-a tool for viewing and navigating such networks with a minimum of user confusion and disorientation. The key factors in the Web View's success are a display that combines a record of the user's path through the network with a map of the currently available links; a scope line that summarizes the number of documents and links in the network; and a set of commands that permit the user to open documents directly from the Web View.",
    "cited_by_count": 225,
    "openalex_id": "https://openalex.org/W2030775668",
    "type": "article"
  },
  {
    "title": "Evaluating 3D task performance for fish tank virtual worlds",
    "doi": "https://doi.org/10.1145/159161.155359",
    "publication_date": "1993-07-01",
    "publication_year": 1993,
    "authors": "Kevin Arthur; Kellogg S. Booth; Colin Ware",
    "corresponding_authors": "",
    "abstract": "article Free AccessEvaluating 3D task performance for fish tank virtual worlds Authors: Kevin W. Arthur View Profile , Kellogg S. Booth View Profile , Colin Ware View Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 11Issue 3July 1993 pp 239–265https://doi.org/10.1145/159161.155359Published:01 July 1993Publication History 166citation2,094DownloadsMetricsTotal Citations166Total Downloads2,094Last 12 Months110Last 6 weeks33 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 220,
    "openalex_id": "https://openalex.org/W2036520185",
    "type": "article"
  },
  {
    "title": "A new model for handling input",
    "doi": "https://doi.org/10.1145/98188.98204",
    "publication_date": "1990-07-01",
    "publication_year": 1990,
    "authors": "Brad A. Myers",
    "corresponding_authors": "Brad A. Myers",
    "abstract": "Although there has been important progress in models and packages for the output of graphics to computer screens, there has been little change in the way that input from the mouse, keyboard, and other input devices is handled. New graphics standards are still using a fifteen-year-old model even though it is widely accepted as inadequate, and most modern window managers simply return a stream of low-level, device-dependent input events. This paper presents a new model that handles input devices for highly interactive, direct manipulation, graphical user interfaces, which could be used in future toolkits, window managers, and graphics standards. This model encapsulates interactive behaviors into a few “Interactor” object types. Application programs can then create instances of these Interactor objects which hide the details of the underlying window manager events. In addition, Interactors allow a clean separation between the input handling, the graphics, and the application programs. This model has been extensively used as part of the Garnet system and has proven to be convenient, efficient, and easy to learn.",
    "cited_by_count": 217,
    "openalex_id": "https://openalex.org/W2063048463",
    "type": "article"
  },
  {
    "title": "Principles of delay-sensitive multimedia data storage retrieval",
    "doi": "https://doi.org/10.1145/128756.128758",
    "publication_date": "1992-01-02",
    "publication_year": 1992,
    "authors": "Jim Gemmell; Stavros Christodoulakis",
    "corresponding_authors": "",
    "abstract": "This paper establishes some fundamental principles for the retrieval and storage of delay-sensitive multimedia data. Delay-sensitive data include digital audio, animations, and video. Retrieval of these data types from secondary storage has to satisfy certain time constraints in order to be acceptable to the user. The presentation is based on digital audio in order to provide intuition to the reader, although the results are applicable to all delay-sensitive data. A theoretical framework is developed for the real-time requirements of digital audio playback. We show how to describe these requirements in terms of the consumption rate of the audio data and the nature of the data-retrieval rate from secondary storage. Making use of this framework, bounds are derived for buffer space requirements for certain common retrieval scenarios. Storage placement strategies for multichannel synchronized data are then categorized and examined. The results presented in this paper are basic to any playback of delay-sensitive data and should assist the multimedia system designer in estimating hardware requirements and in evaluating possible design choices.",
    "cited_by_count": 216,
    "openalex_id": "https://openalex.org/W1979052508",
    "type": "article"
  },
  {
    "title": "Improving Recommender Systems by Incorporating Social Contextual Information",
    "doi": "https://doi.org/10.1145/1961209.1961212",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Hao Ma; Tom Chao Zhou; Michael R. Lyu; Irwin King",
    "corresponding_authors": "",
    "abstract": "Due to their potential commercial value and the associated great research challenges, recommender systems have been extensively studied by both academia and industry recently. However, the data sparsity problem of the involved user-item matrix seriously affects the recommendation quality. Many existing approaches to recommender systems cannot easily deal with users who have made very few ratings. In view of the exponential growth of information generated by online users, social contextual information analysis is becoming important for many Web applications. In this article, we propose a factor analysis approach based on probabilistic matrix factorization to alleviate the data sparsity and poor prediction accuracy problems by incorporating social contextual information, such as social networks and social tags. The complexity analysis indicates that our approach can be applied to very large datasets since it scales linearly with the number of observations. Moreover, the experimental results show that our method performs much better than the state-of-the-art approaches, especially in the circumstance that users have made few ratings.",
    "cited_by_count": 216,
    "openalex_id": "https://openalex.org/W2098655743",
    "type": "article"
  },
  {
    "title": "A probabilistic learning approach for document indexing",
    "doi": "https://doi.org/10.1145/125187.125189",
    "publication_date": "1991-07-01",
    "publication_year": 1991,
    "authors": "Norbert Fuhr; Chris Buckley",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on A probabilistic learning approach for document indexing Authors: Norbert Fuhr Univ. Dortmund, Dortmund, Germany Univ. Dortmund, Dortmund, GermanyView Profile , Chris Buckley Cornell Univ., Ithaca, NY Cornell Univ., Ithaca, NYView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 9Issue 3pp 223–248https://doi.org/10.1145/125187.125189Published:01 July 1991Publication History 116citation1,091DownloadsMetricsTotal Citations116Total Downloads1,091Last 12 Months61Last 6 weeks10 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 215,
    "openalex_id": "https://openalex.org/W2010652031",
    "type": "article"
  },
  {
    "title": "Object lens: a “spreadsheet” for cooperative work",
    "doi": "https://doi.org/10.1145/58566.59298",
    "publication_date": "1988-10-01",
    "publication_year": 1988,
    "authors": "Kum‐Yew Lai; Thomas W. Malone; Keh-Chiang Yu",
    "corresponding_authors": "",
    "abstract": "Object Lens allows unsophisticated computer users to create their own cooperative work applications using a set of simple, but powerful, building blocks. By defining and modifying templates for various semistructured objects, users can represent information about people, tasks, products, messages, and many other kinds of information in a form that can be processed intelligently by both people and their computers. By collecting these objects in customizable folders, users can create their own displays which summarize selected information from the objects in table or tree formats. Finally, by creating semiautonomous agents, users can specify rules for automatically processing this information in different ways at different times. The combination of these primitives provides a single consistent interface that integrates facilities for object-oriented databases, hypertext, electronic messaging, and rule-based intelligent agents. To illustrate the power of this combined approach, we describe several simple examples of applications (such as task tracking, intelligent message routing, and database retrieval) that we have developed in this framework.",
    "cited_by_count": 214,
    "openalex_id": "https://openalex.org/W2092849686",
    "type": "article"
  },
  {
    "title": "Integration of interpersonal space and shared workspace",
    "doi": "https://doi.org/10.1145/159764.159762",
    "publication_date": "1993-10-01",
    "publication_year": 1993,
    "authors": "Hiroshi Ishii; Minoru Kobayashi; Jonathan Grudin",
    "corresponding_authors": "",
    "abstract": "We describe the evolution of the novel shared drawing medium ClearBoard which was designed to seamlessly integrate an interpersonal space and a shared workspace. ClearBoard permits coworkers in two locations to draw with color markers or with electronic pens and software tools while maintaining direct eye contact and the ability to employ natural gestures. The ClearBoard design is based on the key metaphor of “talking through and drawing on a transparent glass window.” We describe the evolution from ClearBoard-1 (which enables shared video drawing) to ClearBoard-2 (which incorporates TeamPaint, a multiuser paint editor). Initial observations and findings gained through the experimental use of the prototype, including the feature of “gaze awareness,” are discussed. Further experiments are conducted with ClearBoard-0 (a simple mockup), ClearBoard-1, and an actual desktop as a control. In the settings we examined, the ClearBoard environment led to more eye contact and potential awareness of collaborator's gaze direction over the traditional desktop environment.",
    "cited_by_count": 210,
    "openalex_id": "https://openalex.org/W2007992204",
    "type": "article"
  },
  {
    "title": "Information extraction as a basis for high-precision text classification",
    "doi": "https://doi.org/10.1145/183422.183428",
    "publication_date": "1994-07-01",
    "publication_year": 1994,
    "authors": "Ellen Riloff; Wendy G. Lehnert",
    "corresponding_authors": "",
    "abstract": "We describe an approach to text classification that represents a compromise between traditional word-based techniques and in-depth natural language processing. Our approach uses a natural language processing task called “information extraction” as a basis for high-precision text classification. We present three algorithms that use varying amounts of extracted information to classify texts. The relevancy signatures algorithm uses linguistic phrases; the augmented relevancy signatures algorithm uses phrases and local context; and the case-based text classification algorithm uses larger pieces of context. Relevant phrases and contexts are acquired automatically using a training corpus. We evaluate the algorithms on the basis of two test sets from the MUC-4 corpus. All three algorithms achieved high precision on both test sets, with the augmented relevancy signatures algorithm and the case-based algorithm reaching 100% precision with over 60% recall on one set. Additionally, we compare the algorithms on a larger collection of 1700 texts and describe an automated method for empirically deriving appropriate threshold values. The results suggest that information extraction techniques can support high-precision text classification and, in general, that using more extracted information improves performance. As a practical matter, we also explain how the text classification system can be easily ported across domains.",
    "cited_by_count": 210,
    "openalex_id": "https://openalex.org/W2097847889",
    "type": "article"
  },
  {
    "title": "Temporal profiles of queries",
    "doi": "https://doi.org/10.1145/1247715.1247720",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Rosie Jones; Fernando Díaz",
    "corresponding_authors": "",
    "abstract": "Documents with timestamps, such as email and news, can be placed along a timeline. The timeline for a set of documents returned in response to a query gives an indication of how documents relevant to that query are distributed in time. Examining the timeline of a query result set allows us to characterize both how temporally dependent the topic is, as well as how relevant the results are likely to be. We outline characteristic patterns in query result set timelines, and show experimentally that we can automatically classify documents into these classes. We also show that properties of the query result set timeline can help predict the mean average precision of a query. These results show that meta-features associated with a query can be combined with text retrieval techniques to improve our understanding and treatment of text search on documents with timestamps.",
    "cited_by_count": 209,
    "openalex_id": "https://openalex.org/W2044002869",
    "type": "article"
  },
  {
    "title": "Learning to use word processors",
    "doi": "https://doi.org/10.1145/357436.357440",
    "publication_date": "1983-07-01",
    "publication_year": 1983,
    "authors": "Robert L. Mack; Clayton Lewis; John M. Carroll",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Learning to use word processors: problems and prospects Authors: Robert L. Mack IBM Thomas J. Watson Research Center, Computer Science Department, P.O. Box 218, Yorktown Heights, NY IBM Thomas J. Watson Research Center, Computer Science Department, P.O. Box 218, Yorktown Heights, NYView Profile , Clayton H. Lewis IBM Thomas J. Watson Research Center, Computer Science Department, P.O. Box 218, Yorktown Heights, NY IBM Thomas J. Watson Research Center, Computer Science Department, P.O. Box 218, Yorktown Heights, NYView Profile , John M. Carroll IBM Thomas J. Watson Research Center, Computer Science Department, P.O. Box 218, Yorktown Heights, NY IBM Thomas J. Watson Research Center, Computer Science Department, P.O. Box 218, Yorktown Heights, NYView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 3July 1983 pp 254–271https://doi.org/10.1145/357436.357440Published:01 July 1983Publication History 164citation1,140DownloadsMetricsTotal Citations164Total Downloads1,140Last 12 Months92Last 6 weeks17 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 208,
    "openalex_id": "https://openalex.org/W2070458494",
    "type": "article"
  },
  {
    "title": "Experiences with selecting search engines using metasearch",
    "doi": "https://doi.org/10.1145/256163.256164",
    "publication_date": "1997-07-01",
    "publication_year": 1997,
    "authors": "Daniel Dreilinger; Adele E. Howe",
    "corresponding_authors": "",
    "abstract": "Search engines are among the most useful and high-profile resources on the Internet. The problem of finding information on the Internet has been replaced with the problem of knowing where search engines are, what they are designed to retrieve, and how to use them. This article describes and evaluates SavvySearch, a metasearch engine designed to intelligently select and interface with multiple remote search engines. The primary metasearch issue examined is the importance of carefully selecting and ranking remote search engines for user queries. We studied the efficacy of SavvySearch's incrementally acquired metaindex approach to selecting search engines by analyzing the effect of time and experience on performance. We also compared the metaindex approach to the simpler categorical approach and showed how much experience is required to surpass the simple scheme.",
    "cited_by_count": 207,
    "openalex_id": "https://openalex.org/W1980094776",
    "type": "article"
  },
  {
    "title": "Discovering personally meaningful places",
    "doi": "https://doi.org/10.1145/1247715.1247718",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Changqing Zhou; Dan Frankowski; Pamela Ludford; Shashi Shekhar; Loren Terveen",
    "corresponding_authors": "",
    "abstract": "The discovery of a person's meaningful places involves obtaining the physical locations and their labels for a person's places that matter to his daily life and routines. This problem is driven by the requirements from emerging location-aware applications, which allow a user to pose queries and obtain information in reference to places, for example, “home”, “work” or “Northwest Health Club”. It is a challenge to map from physical locations to personally meaningful places due to a lack of understanding of what constitutes the real users' personally meaningful places. Previous work has explored algorithms to discover personal places from location data. However, we know of no systematic empirical evaluations of these algorithms, leaving designers of location-aware applications in the dark about their choices. Our work remedies this situation. We extended a clustering algorithm to discover places. We also defined a set of essential evaluation metrics and an interactive evaluation framework. We then conducted a large-scale experiment that collected real users' location data and personally meaningful places, and illustrated the utility of our evaluation framework. Our results establish a baseline that future work can measure itself against. They also demonstrate that that our algorithm discovers places with reasonable accuracy and outperforms the well-known K-Means clustering algorithm for place discovery. Finally, we provide evidence that shapes more complex than “points” are required to represent the full range of people's everyday places.",
    "cited_by_count": 203,
    "openalex_id": "https://openalex.org/W2108335620",
    "type": "article"
  },
  {
    "title": "ITS: a tool for rapidly developing interactive applications",
    "doi": "https://doi.org/10.1145/98188.98194",
    "publication_date": "1990-07-01",
    "publication_year": 1990,
    "authors": "Charles Wiecha; William E. Bennett; Stephen J. Boies; John Gould; Sharon L. Greene",
    "corresponding_authors": "",
    "abstract": "The ITS architecture separates applications into four layers. The action layer implements back-end application functions. The dialog layer defines the content of the user interface, independent of its style. Content specifies the objects included in each frame of the interface, the flow of control among frames, and what actions are associated with each object. The style rule layer defines the presentation and behavior of a family of interaction techniques. Finally, the style program layer implements primitive toolkit objects that are composed by the rule layer into complete interaction techniques. This paper describes the architecture in detail, compares it with previous User Interface Management systems and toolkits, and describes how ITS is being used to implement the visitor information system for EXPO '92.",
    "cited_by_count": 199,
    "openalex_id": "https://openalex.org/W2118826983",
    "type": "article"
  },
  {
    "title": "A decision-theoretic approach to database selection in networked IR",
    "doi": "https://doi.org/10.1145/314516.314517",
    "publication_date": "1999-07-01",
    "publication_year": 1999,
    "authors": "Norbert Fuhr",
    "corresponding_authors": "Norbert Fuhr",
    "abstract": "In networked IR, a client submits a query to a broker, which is in contact with a large number of databases. In order to yield a maximum number of documents at minimum cost, the broker has to make estimates about the retrieval cost of each database, and then decide for each database whether or not to use it for the current query, and if, how many documents to retrieve from it. For this purpose, we develop a general decision-theoretic model and discuss different cost structures. Besides cost for retrieving relevant versus nonrelevant documents, we consider the following parameters for each database: expected retrieval quality, expected number of relevant documents in the database and cost factors for query processing and document delivery. For computing the overall optimum, a divide-and-conquer algorithm is given. If there are several brokers knowing different databases, a preselection of brokers can only be performed heuristically, but the computation of the optimum can be done similarily to the single-broker case. In addition, we derive a formula which estimates the number of relevant documents in a database based on dictionary information.",
    "cited_by_count": 197,
    "openalex_id": "https://openalex.org/W2059344928",
    "type": "article"
  },
  {
    "title": "Boosting the performance of Web search engines",
    "doi": "https://doi.org/10.1145/1125857.1125859",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Tiziano Fagni; Raffaele Perego; Fabrizio Silvestri; Salvatore Orlando",
    "corresponding_authors": "",
    "abstract": "This article discusses efficiency and effectiveness issues in caching the results of queries submitted to a Web search engine (WSE). We propose SDC (Static Dynamic Cache), a new caching strategy aimed to efficiently exploit the temporal and spatial locality present in the stream of processed queries. SDC extracts from historical usage data the results of the most frequently submitted queries and stores them in a static , read-only portion of the cache. The remaining entries of the cache are dynamically managed according to a given replacement policy and are used for those queries that cannot be satisfied by the static portion. Moreover, we improve the hit ratio of SDC by using an adaptive prefetching strategy, which anticipates future requests by introducing a limited overhead over the back-end WSE. We experimentally demonstrate the superiority of SDC over purely static and dynamic policies by measuring the hit ratio achieved on three large query logs by varying the cache parameters and the replacement policy used for managing the dynamic part of the cache. Finally, we deploy and measure the throughput achieved by a concurrent version of our caching system. Our tests show how the SDC cache can be efficiently exploited by many threads that concurrently serve the queries of different users.",
    "cited_by_count": 197,
    "openalex_id": "https://openalex.org/W2110679325",
    "type": "article"
  },
  {
    "title": "TEXTNET: a network-based approach to text handling",
    "doi": "https://doi.org/10.1145/5401.5402",
    "publication_date": "1986-01-01",
    "publication_year": 1986,
    "authors": "Randall H. Trigg; Mark Weiser",
    "corresponding_authors": "",
    "abstract": "Textnet is a new system for structuring text. The Textnet approach uses one uniform data structure to capture graphlike pools of text, as well as embedded hierarchical structures. By using a semantic network formalism of nodes connected by typed links, the relationships between neighboring pieces of text are made explicit. Also described is our partial implementation of the Textnet approach, which makes use of an object-oriented window/menu-driven user interface. Users peruse the network by moving among object menus or by reading text along a path through the network. In addition, critiquing, reader linking, searching, and jumping are easily accessible operations. Finally, the results of a short trial with users are presented.",
    "cited_by_count": 192,
    "openalex_id": "https://openalex.org/W2083872548",
    "type": "article"
  },
  {
    "title": "On modeling information retrieval with probabilistic inference",
    "doi": "https://doi.org/10.1145/195705.195713",
    "publication_date": "1995-01-02",
    "publication_year": 1995,
    "authors": "S. K. M. Wong; Yiyu Yao",
    "corresponding_authors": "",
    "abstract": "This article examines and extends the logical models of information retrieval in the context of probability theory. The fundamental notions of term weights and relevance are given probabilistic interpretations. A unified framework is developed for modeling the retrieval process with probabilistic inference. This new approach provides a common conceptual and mathematical basis for many retrieval models, such as the Boolean, fuzzy set, vector space, and conventional probabilistic models. Within this framework, the underlying assumptions employed by each model are identified, and the inherent relationships between these models are analyzed. Although this article is mainly a theoretical analysis of probabilistic inference for information retrieval, practical methods for estimating the required probabilities are provided by simple examples.",
    "cited_by_count": 191,
    "openalex_id": "https://openalex.org/W2047031127",
    "type": "article"
  },
  {
    "title": "A speech-act-based office modeling approach",
    "doi": "https://doi.org/10.1145/45941.214328",
    "publication_date": "1988-04-01",
    "publication_year": 1988,
    "authors": "Esa Auramäki; Erkki Lehtinen; Kalle Lyytinen",
    "corresponding_authors": "",
    "abstract": "In this paper methods and principles that help to analyze offices as systems of communicative action are explored. In communicative action, office agents create commitments through symbolic means. A SAMPO (Speech-Act-based office Modeling aPprOach), which studies office activities as a series of speech acts creating, maintaining, modifying, reporting, and terminating commitments, is presented. The main steps and methods in the office system specification are outlined and their application illustrated through a simple example. In the final section advantages and disadvantages in the SAMPO are noted and some research directions for the future are suggested.",
    "cited_by_count": 189,
    "openalex_id": "https://openalex.org/W2031096619",
    "type": "article"
  },
  {
    "title": "Diversity in the use of electronic mail: a preliminary inquiry",
    "doi": "https://doi.org/10.1145/58566.58567",
    "publication_date": "1988-10-01",
    "publication_year": 1988,
    "authors": "Wendy E. Mackay",
    "corresponding_authors": "Wendy E. Mackay",
    "abstract": "This paper describes a series of interviews that examine the ways that professional office workers use electronic mail to manage their daily work. The purpose is to generate hypotheses for future research. A number of implications for the design of flexible mail systems are discussed. Two principal claims are made. First, the use of electronic mail is strikingly diverse, although not infinitely so. Individuals vary both in objective measures of mail use and in preferred strategies for managing work electronically. Feelings of control are similarly diverse and are related to the size of the user's inbox, numbers of folders, and subscriptions to distribution lists. This diversity implies that one's own experiences with electronic mail are unlikely to provide sufficient understanding of other's uses of mail. Mail designers should thus seek flexible primitives that capture the important dimensions of use and provide flexibility for a wide range of users. The second claim is that electronic mail is more than just a communication system. Users archive messages for subject retrieval, prioritize messages to sequence work activities, and delegate tasks via mail. A taxonomy of work management is proposed in which mail is used for information management, time management, and task management activities. Directions for future research are suggested.",
    "cited_by_count": 189,
    "openalex_id": "https://openalex.org/W2089417143",
    "type": "article"
  },
  {
    "title": "Information systems strategy and implementation",
    "doi": "https://doi.org/10.1145/196734.196744",
    "publication_date": "1994-04-01",
    "publication_year": 1994,
    "authors": "Geoff Walsham; Timothy Mwololo Waema",
    "corresponding_authors": "",
    "abstract": "The formation and implementation of strategy with respect to computer-based information systems (IS) are important issues in many contemporary organizations, including those in the financial services sector. This paper describes and analyzes an in-depth case study of the strategy formation and implementation process in one such organization, a medium-sized UK building society, and relates the process to its organizational and broader contexts; the organization is examined over a period of several years and under the contrasting leadership of two different chief executives. The case study is used to develop some general implications on IS strategy and implementation, which can be taken as themes for debate in any new situation. The paper provides an example of a more detailed perspective on processes in IS strategy and implementation than typically available in the literature. In addition, a new framework for further research in this area is developed, which directs the researcher toward exploring the dynamic interplay of strategic content, multilevel contexts, and cultural and political perspectives on the process of change.",
    "cited_by_count": 184,
    "openalex_id": "https://openalex.org/W1972094782",
    "type": "article"
  },
  {
    "title": "The clearinghouse",
    "doi": "https://doi.org/10.1145/357436.357439",
    "publication_date": "1983-07-01",
    "publication_year": 1983,
    "authors": "Derek C. Oppen; Yogen K. Dalal",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on The clearinghouse: a decentralized agent for locating named objects in a distributed environment Authors: Derek C. Oppen 495 Arbor Road, Menlo Park, CA 495 Arbor Road, Menlo Park, CAView Profile , Yogen K. Dalal Metaphor Computer Systems, 2500 Garcia Avenue, Mountain View, CA Metaphor Computer Systems, 2500 Garcia Avenue, Mountain View, CAView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 3July 1983 pp 230–253https://doi.org/10.1145/357436.357439Online:01 July 1983Publication History 100citation877DownloadsMetricsTotal Citations100Total Downloads877Last 12 Months41Last 6 weeks9 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 184,
    "openalex_id": "https://openalex.org/W2009312542",
    "type": "article"
  },
  {
    "title": "An experimental study of people creating spreadsheets",
    "doi": "https://doi.org/10.1145/27641.28058",
    "publication_date": "1987-07-01",
    "publication_year": 1987,
    "authors": "P. S. Brown; John D. Gould",
    "corresponding_authors": "",
    "abstract": "Nine experienced users of electronic spreadsheets each created three spreadsheets. Although participants were quite confident that their spreadsheets were accurate, 44 percent of the spreadsheets contained user-generated programming errors. With regard to the spreadsheet creation process, we found that experienced spreadsheet users spend a large percentage of their time using the cursor keys, primarily for the purpose of moving the cursor around the spreadsheet. Users did not spend a lot of time planning before launching into spreadsheet creation, nor did they spend much time in a separate, systematic debugging stage. Participants spent 21 percent of their time pausing, presumably reading and/or thinking, prior to the initial keystrokes of spreadsheet creation episodes.",
    "cited_by_count": 183,
    "openalex_id": "https://openalex.org/W2042031818",
    "type": "article"
  },
  {
    "title": "Work group structures and computer support: a field experiment",
    "doi": "https://doi.org/10.1145/58566.58568",
    "publication_date": "1988-10-01",
    "publication_year": 1988,
    "authors": "J. D. Eveland; Tora K. Bikson",
    "corresponding_authors": "",
    "abstract": "It is frequently suggested that work groups that have computer technology to support activities such as text editing, data manipulation, and communication develop systematically different structures and working processes from groups that rely on more conventional technologies such as memos, phone calls, and meetings. However, cross-sectional or retrospective research designs do not allow this hypothesis to be tested with much power. This field experiment created two task forces, each composed equally of recently retired employees and employees still at work but eligible to retire. They were given the identical tasks of preparing reports for their company on retirement planning issues, but they were randomly assigned to different technology conditions. One group had full conventional office support; the other had, in addition, networked microcomputers with electronic mail and routine office software. Structured interviews were conducted four times during the year-long project; in addition, electronic mail activity was logged in the on-line group. Although both groups produced effective reports, the two differed significantly in the kind of work they produced, the group structures that emerged, and evaluations of their own performance. Although the standard group was largely dominated by the employees through the extensive reliance on informal meetings, the electronic technology used by the other task force allowed the retirees to exercise primary leverage. We conclude that use of computer support for cooperative work results in both quantitative and qualitative changes but that effective participation in such electronically supported groups requires significant investments of time and energy on the part of its members to master the technology and a relatively high level of assistance during the learning process.",
    "cited_by_count": 179,
    "openalex_id": "https://openalex.org/W1966755847",
    "type": "article"
  },
  {
    "title": "A reappraisal of structured analysis",
    "doi": "https://doi.org/10.1145/130226.148055",
    "publication_date": "1993-04-01",
    "publication_year": 1993,
    "authors": "Jørgen P. Bansler; Keld Bødker",
    "corresponding_authors": "",
    "abstract": "We review Structured Analysis as presented by Yourdon and DeMarco. First, we examine the implicit assumptions embodied in the method about the nature of organizations, work processes, and design. Following this we present the results of an exploratory study, conducted to find out how the method is applied in practice. This study reveals that while some of the tools of Structured Analysis—notably the data flow diagrams—are used and combined with other tools, the designers do not follow the analysis and design procedures prescribed by the method. Our findings suggest that there is a gap between the way systems development is portrayed in the normative technical literature and the way in which it is carried out.",
    "cited_by_count": 177,
    "openalex_id": "https://openalex.org/W1999926902",
    "type": "article"
  },
  {
    "title": "Introduction to recommender systems",
    "doi": "https://doi.org/10.1145/963770.963771",
    "publication_date": "2004-01-01",
    "publication_year": 2004,
    "authors": "Joseph A. Konstan",
    "corresponding_authors": "Joseph A. Konstan",
    "abstract": "introduction Share on Introduction to recommender systems: Algorithms and Evaluation Editor: Joseph A. Konstan University of Minnesota, Minneapolis, MN University of Minnesota, Minneapolis, MNView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 22Issue 1January 2004 pp 1–4https://doi.org/10.1145/963770.963771Published:01 January 2004Publication History 84citation4,830DownloadsMetricsTotal Citations84Total Downloads4,830Last 12 Months241Last 6 weeks16 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 177,
    "openalex_id": "https://openalex.org/W2027564548",
    "type": "article"
  },
  {
    "title": "The UAN: a user-oriented representation for direct manipulation interface designs",
    "doi": "https://doi.org/10.1145/98188.98191",
    "publication_date": "1990-07-01",
    "publication_year": 1990,
    "authors": "H. Rex Hartson; Antonio C. Siochi; Deborah Hix",
    "corresponding_authors": "",
    "abstract": "Many existing interface representation techniques, especially those associated with UIMS, are constructional and focused on interface implementation, and therefore do not adequately support a user-centered focus. But it is in the behavioral domain of the user that interface designers and evaluators do their work . We are seeking to complement constructional methods by providing a tool-supported technique capable of specifying the behavioral aspects of an interactive system–the tasks and the actions a user performs to accomplish those tasks. In particular, this paper is a practical introduction to use of the User Action Notation (UAN), a task- and user-oriented notation for behavioral representation of asynchronous, direct manipulation interface designs. Interfaces are specified in UAN as a quasihierarchy of asynchronous tasks. At the lower levels, user actions are associated with feedback and system state changes. The notation makes use of visually onomatopoeic symbols and is simple enough to read with little instruction. UAN is being used by growing numbers of interface developers and researchers. In addition to its design role, current research is investigating how UAN can support production and maintenance of code and documentation.",
    "cited_by_count": 167,
    "openalex_id": "https://openalex.org/W1975517312",
    "type": "article"
  },
  {
    "title": "Efficient set intersection for inverted indexing",
    "doi": "https://doi.org/10.1145/1877766.1877767",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "J. Shane Culpepper; Alistair Moffat",
    "corresponding_authors": "",
    "abstract": "Conjunctive Boolean queries are a key component of modern information retrieval systems, especially when Web-scale repositories are being searched. A conjunctive query q is equivalent to a | q |-way intersection over ordered sets of integers, where each set represents the documents containing one of the terms, and each integer in each set is an ordinal document identifier. As is the case with many computing applications, there is tension between the way in which the data is represented, and the ways in which it is to be manipulated. In particular, the sets representing index data for typical document collections are highly compressible, but are processed using random access techniques, meaning that methods for carrying out set intersections must be alert to issues to do with access patterns and data representation. Our purpose in this article is to explore these trade-offs, by investigating intersection techniques that make use of both uncompressed “integer” representations, as well as compressed arrangements. We also propose a simple hybrid method that provides both compact storage, and also faster intersection computations for conjunctive querying than is possible even with uncompressed representations.",
    "cited_by_count": 166,
    "openalex_id": "https://openalex.org/W1984614894",
    "type": "article"
  },
  {
    "title": "The dimensions of accessibility to online information: implications for implementing office information systems",
    "doi": "https://doi.org/10.1145/521.523",
    "publication_date": "1984-05-24",
    "publication_year": 1984,
    "authors": "Mary J. Culnan",
    "corresponding_authors": "Mary J. Culnan",
    "abstract": "article Free Access Share on The dimensions of accessibility to online information: implications for implementing office information systems Author: Mary J. Culnan University of California University of CaliforniaView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 2April 1984 pp 141–150https://doi.org/10.1145/521.523Published:24 May 1984Publication History 98citation1,680DownloadsMetricsTotal Citations98Total Downloads1,680Last 12 Months164Last 6 weeks31 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 165,
    "openalex_id": "https://openalex.org/W2047805418",
    "type": "article"
  },
  {
    "title": "Interest-based personalized search",
    "doi": "https://doi.org/10.1145/1198296.1198301",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Zhongming Ma; Gautam Pant; Olivia R. Liu Sheng",
    "corresponding_authors": "",
    "abstract": "Web search engines typically provide search results without considering user interests or context. We propose a personalized search approach that can easily extend a conventional search engine on the client side. Our mapping framework automatically maps a set of known user interests onto a group of categories in the Open Directory Project (ODP) and takes advantage of manually edited data available in ODP for training text classifiers that correspond to, and therefore categorize and personalize search results according to user interests. In two sets of controlled experiments, we compare our personalized categorization system (PCAT) with a list interface system (LIST) that mimics a typical search engine and with a nonpersonalized categorization system (CAT). In both experiments, we analyze system performances on the basis of the type of task and query length. We find that PCAT is preferable to LIST for information gathering types of tasks and for searches with short queries, and PCAT outperforms CAT in both information gathering and finding types of tasks, and for searches associated with free-form queries. From the subjects' answers to a questionnaire, we find that PCAT is perceived as a system that can find relevant Web pages quicker and easier than LIST and CAT.",
    "cited_by_count": 164,
    "openalex_id": "https://openalex.org/W1987233790",
    "type": "article"
  },
  {
    "title": "Joint Modeling of User Check-in Behaviors for Real-time Point-of-Interest Recommendation",
    "doi": "https://doi.org/10.1145/2873055",
    "publication_date": "2016-10-10",
    "publication_year": 2016,
    "authors": "Hongzhi Yin; Bin Cui; Xiaofang Zhou; Weiqing Wang; Zi Huang; Shazia Sadiq",
    "corresponding_authors": "",
    "abstract": "Point-of-Interest (POI) recommendation has become an important means to help people discover attractive and interesting places, especially when users travel out of town. However, the extreme sparsity of a user-POI matrix creates a severe challenge. To cope with this challenge, we propose a unified probabilistic generative model, the Topic-Region Model (TRM) , to simultaneously discover the semantic, temporal, and spatial patterns of users’ check-in activities, and to model their joint effect on users’ decision making for selection of POIs to visit. To demonstrate the applicability and flexibility of TRM, we investigate how it supports two recommendation scenarios in a unified way, that is, hometown recommendation and out-of-town recommendation. TRM effectively overcomes data sparsity by the complementarity and mutual enhancement of the diverse information associated with users’ check-in activities (e.g., check-in content, time, and location) in the processes of discovering heterogeneous patterns and producing recommendations. To support real-time POI recommendations, we further extend the TRM model to an online learning model, TRM-Online, to track changing user interests and speed up the model training. In addition, based on the learned model, we propose a clustering-based branch and bound algorithm (CBB) to prune the POI search space and facilitate fast retrieval of the top- k recommendations. We conduct extensive experiments to evaluate the performance of our proposals on two real-world datasets, including recommendation effectiveness, overcoming the cold-start problem, recommendation efficiency, and model-training efficiency. The experimental results demonstrate the superiority of our TRM models, especially TRM-Online, compared with state-of-the-art competitive methods, by making more effective and efficient mobile recommendations. In addition, we study the importance of each type of pattern in the two recommendation scenarios, respectively, and find that exploiting temporal patterns is most important for the hometown recommendation scenario, while the semantic patterns play a dominant role in improving the recommendation effectiveness for out-of-town users.",
    "cited_by_count": 164,
    "openalex_id": "https://openalex.org/W2531384334",
    "type": "article"
  },
  {
    "title": "A shared, segmented memory system for an object-oriented database",
    "doi": "https://doi.org/10.1145/22890.22891",
    "publication_date": "1987-01-01",
    "publication_year": 1987,
    "authors": "Mark F. Hornick; Stanley B. Zdonik",
    "corresponding_authors": "",
    "abstract": "This paper describes the basic data model of an object-oriented database and the basic architecture of the system implementing it. In particular, a secondary storage segmentation scheme and a transaction-processing scheme are discussed. The segmentation scheme allows for arbitrary clustering of objects, including duplicates. The transaction scheme allows for many different sharing protocols ranging from those that enforce serializability to those that are nonserializable and require communication with the server only on demand. The interaction of these two features is described such that segment-level transfer and object-level locking is achieved.",
    "cited_by_count": 163,
    "openalex_id": "https://openalex.org/W1967133810",
    "type": "article"
  },
  {
    "title": "Semisupervised SVM batch mode active learning with applications to image retrieval",
    "doi": "https://doi.org/10.1145/1508850.1508854",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Steven C. H. Hoi; Rong Jin; Jianke Zhu; Michael R. Lyu",
    "corresponding_authors": "",
    "abstract": "Support vector machine (SVM) active learning is one popular and successful technique for relevance feedback in content-based image retrieval (CBIR). Despite the success, conventional SVM active learning has two main drawbacks. First, the performance of SVM is usually limited by the number of labeled examples. It often suffers a poor performance for the small-sized labeled examples, which is the case in relevance feedback. Second, conventional approaches do not take into account the redundancy among examples, and could select multiple examples that are similar (or even identical). In this work, we propose a novel scheme for explicitly addressing the drawbacks. It first learns a kernel function from a mixture of labeled and unlabeled data, and therefore alleviates the problem of small-sized training data. The kernel will then be used for a batch mode active learning method to identify the most informative and diverse examples via a min-max framework. Two novel algorithms are proposed to solve the related combinatorial optimization: the first approach approximates the problem into a quadratic program, and the second solves the combinatorial optimization approximately by a greedy algorithm that exploits the merits of submodular functions. Extensive experiments with image retrieval using both natural photo images and medical images show that the proposed algorithms are significantly more effective than the state-of-the-art approaches. A demo is available at http://msm.cais.ntu.edu.sg/LSCBIR/.",
    "cited_by_count": 161,
    "openalex_id": "https://openalex.org/W2016405781",
    "type": "article"
  },
  {
    "title": "YASS",
    "doi": "https://doi.org/10.1145/1281485.1281489",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "Prasenjit Majumder; Mandar Mitra; Swapan K. Parui; Gobinda Kole; Pabitra Mitra; Kalyankumar Datta",
    "corresponding_authors": "",
    "abstract": "Stemmers attempt to reduce a word to its stem or root form and are used widely in information retrieval tasks to increase the recall rate. Most popular stemmers encode a large number of language-specific rules built over a length of time. Such stemmers with comprehensive rules are available only for a few languages. In the absence of extensive linguistic resources for certain languages, statistical language processing tools have been successfully used to improve the performance of IR systems. In this article, we describe a clustering-based approach to discover equivalence classes of root words and their morphological variants. A set of string distance measures are defined, and the lexicon for a given text collection is clustered using the distance measures to identify these equivalence classes. The proposed approach is compared with Porter's and Lovin's stemmers on the AP and WSJ subcollections of the Tipster dataset using 200 queries. Its performance is comparable to that of Porter's and Lovin's stemmers, both in terms of average precision and the total number of relevant documents retrieved. The proposed stemming algorithm also provides consistent improvements in retrieval performance for French and Bengali, which are currently resource-poor.",
    "cited_by_count": 160,
    "openalex_id": "https://openalex.org/W2138958299",
    "type": "article"
  },
  {
    "title": "Dynamic User Modeling in Social Media Systems",
    "doi": "https://doi.org/10.1145/2699670",
    "publication_date": "2015-03-09",
    "publication_year": 2015,
    "authors": "Hongzhi Yin; Bin Cui; Ling Chen; Zhiting Hu; Xiaofang Zhou",
    "corresponding_authors": "",
    "abstract": "Social media provides valuable resources to analyze user behaviors and capture user preferences. This article focuses on analyzing user behaviors in social media systems and designing a latent class statistical mixture model, named temporal context-aware mixture model (TCAM), to account for the intentions and preferences behind user behaviors. Based on the observation that the behaviors of a user in social media systems are generally influenced by intrinsic interest as well as the temporal context (e.g., the public's attention at that time), TCAM simultaneously models the topics related to users' intrinsic interests and the topics related to temporal context and then combines the influences from the two factors to model user behaviors in a unified way. Considering that users' interests are not always stable and may change over time, we extend TCAM to a dynamic temporal context-aware mixture model (DTCAM) to capture users' changing interests. To alleviate the problem of data sparsity, we exploit the social and temporal correlation information by integrating a social-temporal regularization framework into the DTCAM model. To further improve the performance of our proposed models (TCAM and DTCAM), an item-weighting scheme is proposed to enable them to favor items that better represent topics related to user interests and topics related to temporal context, respectively. Based on our proposed models, we design a temporal context-aware recommender system (TCARS). To speed up the process of producing the top- k recommendations from large-scale social media data, we develop an efficient query-processing technique to support TCARS. Extensive experiments have been conducted to evaluate the performance of our models on four real-world datasets crawled from different social media sites. The experimental results demonstrate the superiority of our models, compared with the state-of-the-art competitor methods, by modeling user behaviors more precisely and making more effective and efficient recommendations.",
    "cited_by_count": 158,
    "openalex_id": "https://openalex.org/W2066365352",
    "type": "article"
  },
  {
    "title": "Recommendation systems with complex constraints",
    "doi": "https://doi.org/10.1145/2037661.2037665",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Aditya Parameswaran; Petros Venetis; Héctor García-Molina",
    "corresponding_authors": "",
    "abstract": "We study the problem of making recommendations when the objects to be recommended must also satisfy constraints or requirements. In particular, we focus on course recommendations: the courses taken by a student must satisfy requirements (e.g., take two out of a set of five math courses) in order for the student to graduate. Our work is done in the context of the CourseRank system, used by students to plan their academic program at Stanford University. Our goal is to recommend to these students courses that not only help satisfy constraints, but that are also desirable (e.g., popular or taken by similar students). We develop increasingly expressive models for course requirements, and present a variety of schemes for both checking if the requirements are satisfied, and for making recommendations that take into account the requirements. We show that some types of requirements are inherently expensive to check, and we present exact, as well as heuristic techniques, for those cases. Although our work is specific to course requirements, it provides insights into the design of recommendation systems in the presence of complex constraints found in other applications.",
    "cited_by_count": 152,
    "openalex_id": "https://openalex.org/W2005653178",
    "type": "article"
  },
  {
    "title": "Predicting Query Performance by Query-Drift Estimation",
    "doi": "https://doi.org/10.1145/2180868.2180873",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Anna Shtok; Oren Kurland; David Carmel; Fiana Raiber; Gad Markovits",
    "corresponding_authors": "",
    "abstract": "Predicting query performance , that is, the effectiveness of a search performed in response to a query, is a highly important and challenging problem. We present a novel approach to this task that is based on measuring the standard deviation of retrieval scores in the result list of the documents most highly ranked. We argue that for retrieval methods that are based on document-query surface-level similarities, the standard deviation can serve as a surrogate for estimating the presumed amount of query drift in the result list, that is, the presence (and dominance) of aspects or topics not related to the query in documents in the list. Empirical evaluation demonstrates the prediction effectiveness of our approach for several retrieval models. Specifically, the prediction quality often transcends that of current state-of-the-art prediction methods.",
    "cited_by_count": 152,
    "openalex_id": "https://openalex.org/W2087131461",
    "type": "article"
  },
  {
    "title": "A Neural Network Approach to Jointly Modeling Social Networks and Mobile Trajectories",
    "doi": "https://doi.org/10.1145/3041658",
    "publication_date": "2017-08-16",
    "publication_year": 2017,
    "authors": "Cheng Yang; Maosong Sun; Wayne Xin Zhao; Zhiyuan Liu; Edward Yi Chang",
    "corresponding_authors": "",
    "abstract": "Two characteristics of location-based services are mobile trajectories and the ability to facilitate social networking. The recording of trajectory data contributes valuable resources towards understanding users’ geographical movement behaviors. Social networking is possible when users are able to quickly connect to anyone nearby. A social network with location based services is known as location-based social network (LBSN). As shown in Cho et al. [2013], locations that are frequently visited by socially related persons tend to be correlated, which indicates the close association between social connections and trajectory behaviors of users in LBSNs. To better analyze and mine LBSN data, we need to have a comprehensive view of each of these two aspects, i.e., the mobile trajectory data and the social network. Specifically, we present a novel neural network model that can jointly model both social networks and mobile trajectories. Our model consists of two components: the construction of social networks and the generation of mobile trajectories. First we adopt a network embedding method for the construction of social networks: a networking representation can be derived for a user. The key to our model lies in generating mobile trajectories. Second, we consider four factors that influence the generation process of mobile trajectories: user visit preference, influence of friends, short-term sequential contexts, and long-term sequential contexts. To characterize the last two contexts, we employ the RNN and GRU models to capture the sequential relatedness in mobile trajectories at the short or long term levels. Finally, the two components are tied by sharing the user network representations. Experimental results on two important applications demonstrate the effectiveness of our model. In particular, the improvement over baselines is more significant when either network structure or trajectory data is sparse.",
    "cited_by_count": 152,
    "openalex_id": "https://openalex.org/W2472954632",
    "type": "article"
  },
  {
    "title": "Yum-Me",
    "doi": "https://doi.org/10.1145/3072614",
    "publication_date": "2017-07-17",
    "publication_year": 2017,
    "authors": "Longqi Yang; Cheng-Kang Hsieh; Hongjian Yang; John P. Pollak; Nicola Dell; Serge Belongie; Curtis L Cole; Deborah Estrin",
    "corresponding_authors": "",
    "abstract": "Nutrient-based meal recommendations have the potential to help individuals prevent or manage conditions such as diabetes and obesity. However, learning people's food preferences and making recommendations that simultaneously appeal to their palate and satisfy nutritional expectations are challenging. Existing approaches either only learn high-level preferences or require a prolonged learning period. We propose Yum-me, a personalized nutrient-based meal recommender system designed to meet individuals' nutritional expectations, dietary restrictions, and fine-grained food preferences. Yum-me enables a simple and accurate food preference profiling procedure via a visual quiz-based user interface and projects the learned profile into the domain of nutritionally appropriate food options to find ones that will appeal to the user. We present the design and implementation of Yum-me and further describe and evaluate two innovative contributions. The first contriution is an open source state-of-the-art food image analysis model, named FoodDist. We demonstrate FoodDist's superior performance through careful benchmarking and discuss its applicability across a wide array of dietary applications. The second contribution is a novel online learning framework that learns food preference from itemwise and pairwise image comparisons. We evaluate the framework in a field study of 227 anonymous users and demonstrate that it outperforms other baselines by a significant margin. We further conducted an end-to-end validation of the feasibility and effectiveness of Yum-me through a 60-person user study, in which Yum-me improves the recommendation acceptance rate by 42.63%.",
    "cited_by_count": 149,
    "openalex_id": "https://openalex.org/W2963918631",
    "type": "article"
  },
  {
    "title": "On Effective Location-Aware Music Recommendation",
    "doi": "https://doi.org/10.1145/2846092",
    "publication_date": "2016-04-07",
    "publication_year": 2016,
    "authors": "Zhiyong Cheng; Jialie Shen",
    "corresponding_authors": "",
    "abstract": "Rapid advances in mobile devices and cloud-based music service now allow consumers to enjoy music anytime and anywhere. Consequently, there has been an increasing demand in studying intelligent techniques to facilitate context-aware music recommendation. However, one important context that is generally overlooked is user’s venue, which often includes surrounding atmosphere, correlates with activities, and greatly influences the user’s music preferences. In this article, we present a novel venue-aware music recommender system called VenueMusic to effectively identify suitable songs for various types of popular venues in our daily lives. Toward this goal, a Location-aware Topic Model (LTM) is proposed to (i) mine the common features of songs that are suitable for a venue type in a latent semantic space and (ii) represent songs and venue types in the shared latent space, in which songs and venue types can be directly matched. It is worth mentioning that to discover meaningful latent topics with the LTM, a Music Concept Sequence Generation (MCSG) scheme is designed to extract effective semantic representations for songs. An extensive experimental study based on two large music test collections demonstrates the effectiveness of the proposed topic model and MCSG scheme. The comparisons with state-of-the-art music recommender systems demonstrate the superior performance of VenueMusic system on recommendation accuracy by associating venue and music contents using a latent semantic space. This work is a pioneering study on the development of a venue-aware music recommender system. The results show the importance of considering the influence of venue types in the development of context-aware music recommender systems.",
    "cited_by_count": 148,
    "openalex_id": "https://openalex.org/W2334831412",
    "type": "article"
  },
  {
    "title": "Enhancing Topic Modeling for Short Texts with Auxiliary Word Embeddings",
    "doi": "https://doi.org/10.1145/3091108",
    "publication_date": "2017-08-21",
    "publication_year": 2017,
    "authors": "Chenliang Li; Yu Duan; Haoran Wang; Zhiqian Zhang; Aixin Sun; Zongyang Ma",
    "corresponding_authors": "",
    "abstract": "Many applications require semantic understanding of short texts, and inferring discriminative and coherent latent topics is a critical and fundamental task in these applications. Conventional topic models largely rely on word co-occurrences to derive topics from a collection of documents. However, due to the length of each document, short texts are much more sparse in terms of word co-occurrences. Recent studies show that the Dirichlet Multinomial Mixture (DMM) model is effective for topic inference over short texts by assuming that each piece of short text is generated by a single topic. However, DMM has two main limitations. First, even though it seems reasonable to assume that each short text has only one topic because of its shortness, the definition of “shortness” is subjective and the length of the short texts is dataset dependent. That is, the single-topic assumption may be too strong for some datasets. To address this limitation, we propose to model the topic number as a Poisson distribution, allowing each short text to be associated with a small number of topics (e.g., one to three topics). This model is named PDMM. Second, DMM (and also PDMM) does not have access to background knowledge (e.g., semantic relations between words) when modeling short texts. When a human being interprets a piece of short text, the understanding is not solely based on its content words, but also their semantic relations. Recent advances in word embeddings offer effective learning of word semantic relations from a large corpus. Such auxiliary word embeddings enable us to address the second limitation. To this end, we propose to promote the semantically related words under the same topic during the sampling process, by using the generalized Pólya urn (GPU) model. Through the GPU model, background knowledge about word semantic relations learned from millions of external documents can be easily exploited to improve topic modeling for short texts. By directly extending the PDMM model with the GPU model, we propose two more effective topic models for short texts, named GPU-DMM and GPU-PDMM. Through extensive experiments on two real-world short text collections in two languages, we demonstrate that PDMM achieves better topic representations than state-of-the-art models, measured by topic coherence. The learned topic representation leads to better accuracy in a text classification task, as an indirect evaluation. Both GPU-DMM and GPU-PDMM further improve topic coherence and text classification accuracy. GPU-PDMM outperforms GPU-DMM at the price of higher computational costs.",
    "cited_by_count": 145,
    "openalex_id": "https://openalex.org/W2745475103",
    "type": "article"
  },
  {
    "title": "Improved search engines and navigation preference in personal information management",
    "doi": "https://doi.org/10.1145/1402256.1402259",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Ofer Bergman; Tal Marom; Rafi Nachmias; Noa Gradovitch; Steve Whittaker",
    "corresponding_authors": "",
    "abstract": "Traditionally users access their personal files mainly by using folder navigation. We evaluate whether recent improvements in desktop search have changed this fundamental aspect of Personal Information Management (PIM). We tested this in two studies using the same questionnaire: (a) The Windows Studya longitudinal comparison of Google Desktop and Windows XP Search Companion , and (b) The Mac Studya large scale comparison of Mac Spotlight and Sherlock . There were few effects for improved search. First, regardless of search engine, there was a strong navigation preference: on average, users estimated that they used navigation for 56-68% of file retrieval events but searched for only 4-15% of events. Second, the effect of improving the quality of the search engine on search usage was limited and inconsistent. Third, search was used mainly as a last resort when users could not remember file location. Finally, there was no evidence that using improved desktop search engines leads people to change their filing habits to become less reliant on hierarchical file organization. We conclude by offering theoretical explanations for navigation preference, relating to differences between PIM and Internet retrieval, and suggest alternative design directions for PIM systems.",
    "cited_by_count": 141,
    "openalex_id": "https://openalex.org/W2003482363",
    "type": "article"
  },
  {
    "title": "Spatiotemporal Representation Learning for Translation-Based POI Recommendation",
    "doi": "https://doi.org/10.1145/3295499",
    "publication_date": "2019-01-27",
    "publication_year": 2019,
    "authors": "Tieyun Qian; Bei Liu; Quoc Viet Hung Nguyen; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "The increasing proliferation of location-based social networks brings about a huge volume of user check-in data, which facilitates the recommendation of points of interest (POIs). Time and location are the two most important contextual factors in the user’s decision-making for choosing a POI to visit. In this article, we focus on the spatiotemporal context-aware POI recommendation, which considers the joint effect of time and location for POI recommendation. Inspired by the recent advances in knowledge graph embedding, we propose a spatiotemporal context-aware and translation-based recommender framework (STA) to model the third-order relationship among users, POIs, and spatiotemporal contexts for large-scale POI recommendation. Specifically, we embed both users and POIs into a “transition space” where spatiotemporal contexts (i.e., a &lt; time, location &gt; pair) are modeled as translation vectors operating on users and POIs. We further develop a series of strategies to exploit various correlation information to address the data sparsity and cold-start issues for new spatiotemporal contexts, new users, and new POIs. We conduct extensive experiments on two real-world datasets. The experimental results demonstrate that our STA framework achieves the superior performance in terms of high recommendation accuracy, robustness to data sparsity, and effectiveness in handling the cold-start problem.",
    "cited_by_count": 141,
    "openalex_id": "https://openalex.org/W2914041468",
    "type": "article"
  },
  {
    "title": "Multiple testing in statistical analysis of systems-based information retrieval experiments",
    "doi": "https://doi.org/10.1145/2094072.2094076",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Benjamin Carterette",
    "corresponding_authors": "Benjamin Carterette",
    "abstract": "High-quality reusable test collections and formal statistical hypothesis testing together support a rigorous experimental environment for information retrieval research. But as Armstrong et al. [2009b] recently argued, global analysis of experiments suggests that there has actually been little real improvement in ad hoc retrieval effectiveness over time. We investigate this phenomenon in the context of simultaneous testing of many hypotheses using a fixed set of data. We argue that the most common approaches to significance testing ignore a great deal of information about the world. Taking into account even a fairly small amount of this information can lead to very different conclusions about systems than those that have appeared in published literature. We demonstrate how to model a set of IR experiments for analysis both mathematically and practically, and show that doing so can cause p -values from statistical hypothesis tests to increase by orders of magnitude. This has major consequences on the interpretation of experimental results using reusable test collections: it is very difficult to conclude that anything is significant once we have modeled many of the sources of randomness in experimental design and analysis.",
    "cited_by_count": 140,
    "openalex_id": "https://openalex.org/W2017292914",
    "type": "article"
  },
  {
    "title": "Oracle in Image Search",
    "doi": "https://doi.org/10.1145/2180868.2180875",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Liqiang Nie; Meng Wang; Zheng-Jun Zha; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "This article studies a novel problem in image search. Given a text query and the image ranking list returned by an image search system, we propose an approach to automatically predict the search performance. We demonstrate that, in order to estimate the mathematical expectations of Average Precision (AP) and Normalized Discounted Cumulative Gain (NDCG), we only need to predict the relevance probability of each image. We accomplish the task with a query-adaptive graph-based learning based on the images’ ranking order and visual content. We validate our approach with a large-scale dataset that contains the image search results of 1,165 queries from 4 popular image search engines. Empirical studies demonstrate that our approach is able to generate predictions that are highly correlated with the real search performance. Based on the proposed image search performance prediction scheme, we introduce three applications: image metasearch, multilingual image search, and Boolean image search. Comprehensive experiments are conducted to validate our approach.",
    "cited_by_count": 138,
    "openalex_id": "https://openalex.org/W2105124491",
    "type": "article"
  },
  {
    "title": "LCARS",
    "doi": "https://doi.org/10.1145/2629461",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Hongzhi Yin; Bin Cui; Yizhou Sun; Zhiting Hu; Ling Chen",
    "corresponding_authors": "",
    "abstract": "Newly emerging location-based and event-based social network services provide us with a new platform to understand users' preferences based on their activity history. A user can only visit a limited number of venues/events and most of them are within a limited distance range, so the user-item matrix is very sparse, which creates a big challenge to the traditional collaborative filtering-based recommender systems. The problem becomes even more challenging when people travel to a new city where they have no activity information. In this article, we propose LCARS, a location-content-aware recommender system that offers a particular user a set of venues (e.g., restaurants and shopping malls) or events (e.g., concerts and exhibitions) by giving consideration to both personal interest and local preference. This recommender system can facilitate people's travel not only near the area in which they live, but also in a city that is new to them. Specifically, LCARS consists of two components: offline modeling and online recommendation. The offline modeling part, called LCA-LDA, is designed to learn the interest of each individual user and the local preference of each individual city by capturing item cooccurrence patterns and exploiting item contents. The online recommendation part takes a querying user along with a querying city as input, and automatically combines the learned interest of the querying user and the local preference of the querying city to produce the top- k recommendations. To speed up the online process, a scalable query processing technique is developed by extending both the Threshold Algorithm (TA) and TA-approximation algorithm. We evaluate the performance of our recommender system on two real datasets, that is, DoubanEvent and Foursquare, and one large-scale synthetic dataset. The results show the superiority of LCARS in recommending spatial items for users, especially when traveling to new cities, in terms of both effectiveness and efficiency. Besides, the experimental analysis results also demonstrate the excellent interpretability of LCARS.",
    "cited_by_count": 136,
    "openalex_id": "https://openalex.org/W2034688657",
    "type": "article"
  },
  {
    "title": "FNED",
    "doi": "https://doi.org/10.1145/3386253",
    "publication_date": "2020-05-05",
    "publication_year": 2020,
    "authors": "Yang Liu; Yi-Fang Wu",
    "corresponding_authors": "",
    "abstract": "The fast spreading of fake news stories on social media can cause inestimable social harm. Developing effective methods to detect them early is of paramount importance. A major challenge of fake news early detection is fully utilizing the limited data observed at the early stage of news propagation and then learning useful patterns from it for identifying fake news. In this article, we propose a novel deep neural network to detect fake news early. It has three novel components: (1) a status-sensitive crowd response feature extractor that extracts both text features and user features from combinations of users’ text response and their corresponding user profiles, (2) a position-aware attention mechanism that highlights important user responses at specific ranking positions, and (3) a multi-region mean-pooling mechanism to perform feature aggregation based on multiple window sizes. Experimental results on two real-world datasets demonstrate that our proposed model can detect fake news with greater than 90% accuracy within 5 minutes after it starts to spread and before it is retweeted 50 times, which is significantly faster than state-of-the-art baselines. Most importantly, our approach requires only 10% labeled fake news samples to achieve this effectiveness under PU-Learning settings.",
    "cited_by_count": 134,
    "openalex_id": "https://openalex.org/W3022435406",
    "type": "article"
  },
  {
    "title": "Joint Neural Collaborative Filtering for Recommender Systems",
    "doi": "https://doi.org/10.1145/3343117",
    "publication_date": "2019-08-14",
    "publication_year": 2019,
    "authors": "Wanyu Chen; Fei Cai; Honghui Chen; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "We propose a Joint Neural Collaborative Filtering (J-NCF) method for recommender systems. The J-NCF model applies a joint neural network that couples deep feature learning and deep interaction modeling with a rating matrix. Deep feature learning extracts feature representations of users and items with a deep learning architecture based on a user-item rating matrix. Deep interaction modeling captures non-linear user-item interactions with a deep neural network using the feature representations generated by the deep feature learning process as input. J-NCF enables the deep feature learning and deep interaction modeling processes to optimize each other through joint training, which leads to improved recommendation performance. In addition, we design a new loss function for optimization that takes both implicit and explicit feedback, point-wise and pair-wise loss into account. Experiments on several real-world datasets show significant improvements of J-NCF over state-of-the-art methods, with improvements of up to 8.24% on the MovieLens 100K dataset, 10.81% on the MovieLens 1M dataset, and 10.21% on the Amazon Movies dataset in terms of HR@10. NDCG@10 improvements are 12.42%, 14.24%, and 15.06%, respectively. We also conduct experiments to evaluate the scalability and sensitivity of J-NCF. Our experiments show that the J-NCF model has a competitive recommendation performance with inactive users and different degrees of data sparsity when compared to state-of-the-art baselines.",
    "cited_by_count": 133,
    "openalex_id": "https://openalex.org/W2967481075",
    "type": "article"
  },
  {
    "title": "On Crowdsourcing Relevance Magnitudes for Information Retrieval Evaluation",
    "doi": "https://doi.org/10.1145/3002172",
    "publication_date": "2017-01-04",
    "publication_year": 2017,
    "authors": "Eddy Maddalena; Stefano Mizzaro; Falk Scholer; Andrew Turpin",
    "corresponding_authors": "",
    "abstract": "Magnitude estimation is a psychophysical scaling technique for the measurement of sensation, where observers assign numbers to stimuli in response to their perceived intensity. We investigate the use of magnitude estimation for judging the relevance of documents for information retrieval evaluation, carrying out a large-scale user study across 18 TREC topics and collecting over 50,000 magnitude estimation judgments using crowdsourcing. Our analysis shows that magnitude estimation judgments can be reliably collected using crowdsourcing, are competitive in terms of assessor cost, and are, on average, rank-aligned with ordinal judgments made by expert relevance assessors. We explore the application of magnitude estimation for IR evaluation, calibrating two gain-based effectiveness metrics, nDCG and ERR, directly from user-reported perceptions of relevance. A comparison of TREC system effectiveness rankings based on binary, ordinal, and magnitude estimation relevance shows substantial variation; in particular, the top systems ranked using magnitude estimation and ordinal judgments differ substantially. Analysis of the magnitude estimation scores shows that this effect is due in part to varying perceptions of relevance: different users have different perceptions of the impact of relative differences in document relevance. These results have direct implications for IR evaluation, suggesting that current assumptions about a single view of relevance being sufficient to represent a population of users are unlikely to hold.",
    "cited_by_count": 129,
    "openalex_id": "https://openalex.org/W2569307494",
    "type": "article"
  },
  {
    "title": "Matrix Factorization with Explicit Trust and Distrust Side Information for Improved Social Recommendation",
    "doi": "https://doi.org/10.1145/2641564",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Rana Forsati; Mehrdad Mahdavi; Mehrnoush Shamsfard; Mohamed Sarwat",
    "corresponding_authors": "",
    "abstract": "With the advent of online social networks, recommender systems have became crucial for the success of many online applications/services due to their significance role in tailoring these applications to user-specific needs or preferences. Despite their increasing popularity, in general, recommender systems suffer from data sparsity and cold-start problems. To alleviate these issues, in recent years, there has been an upsurge of interest in exploiting social information such as trust relations among users along with the rating data to improve the performance of recommender systems. The main motivation for exploiting trust information in the recommendation process stems from the observation that the ideas we are exposed to and the choices we make are significantly influenced by our social context. However, in large user communities, in addition to trust relations, distrust relations also exist between users. For instance, in Epinions, the concepts of personal “web of trust” and personal “block list” allow users to categorize their friends based on the quality of reviews into trusted and distrusted friends, respectively. Hence, it will be interesting to incorporate this new source of information in recommendation as well. In contrast to the incorporation of trust information in recommendation which is thriving, the potential of explicitly incorporating distrust relations is almost unexplored. In this article, we propose a matrix factorization-based model for recommendation in social rating networks that properly incorporates both trust and distrust relationships aiming to improve the quality of recommendations and mitigate the data sparsity and cold-start users issues. Through experiments on the Epinions dataset, we show that our new algorithm outperforms its standard trust-enhanced or distrust-enhanced counterparts with respect to accuracy, thereby demonstrating the positive effect that incorporation of explicit distrust information can have on recommender systems.",
    "cited_by_count": 122,
    "openalex_id": "https://openalex.org/W2035463970",
    "type": "article"
  },
  {
    "title": "Encoding Syntactic Knowledge in Neural Networks for Sentiment Classification",
    "doi": "https://doi.org/10.1145/3052770",
    "publication_date": "2017-06-05",
    "publication_year": 2017,
    "authors": "Minlie Huang; Qian Qiao; Xiaoyan Zhu",
    "corresponding_authors": "",
    "abstract": "Phrase/Sentence representation is one of the most important problems in natural language processing. Many neural network models such as Convolutional Neural Network (CNN), Recursive Neural Network (RNN), and Long Short-Term Memory (LSTM) have been proposed to learn representations of phrase/sentence, however, rich syntactic knowledge has not been fully explored when composing a longer text from its shorter constituent words. In most traditional models, only word embeddings are utilized to compose phrase/sentence representations, while the syntactic information of words is yet to be explored. In this article, we discover that encoding syntactic knowledge (part-of-speech tag) in neural networks can enhance sentence/phrase representation. Specifically, we propose to learn tag-specific composition functions and tag embeddings in recursive neural networks, and propose to utilize POS tags to control the gates of tree-structured LSTM networks. We evaluate these models on two benchmark datasets for sentiment classification, and demonstrate that improvements can be obtained with such syntactic knowledge encoded.",
    "cited_by_count": 122,
    "openalex_id": "https://openalex.org/W2622365670",
    "type": "article"
  },
  {
    "title": "MMALFM",
    "doi": "https://doi.org/10.1145/3291060",
    "publication_date": "2019-01-11",
    "publication_year": 2019,
    "authors": "Zhiyong Cheng; Xiaojun Chang; Lei Zhu; Rose Kanjirathinkal; Mohan Kankanhalli",
    "corresponding_authors": "",
    "abstract": "Personalized rating prediction is an important research problem in recommender systems. Although the latent factor model (e.g., matrix factorization) achieves good accuracy in rating prediction, it suffers from many problems including cold-start, non-transparency, and suboptimal results for individual user-item pairs. In this article, we exploit textual reviews and item images together with ratings to tackle these limitations. Specifically, we first apply a proposed multi-modal aspect-aware topic model (MATM) on text reviews and item images to model users’ preferences and items’ features from different aspects , and also estimate the aspect importance of a user toward an item. Then, the aspect importance is integrated into a novel aspect-aware latent factor model (ALFM), which learns user’s and item’s latent factors based on ratings. In particular, ALFM introduces a weight matrix to associate those latent factors with the same set of aspects in MATM, such that the latent factors could be used to estimate aspect ratings. Finally, the overall rating is computed via a linear combination of the aspect ratings, which are weighted by the corresponding aspect importance. To this end, our model could alleviate the data sparsity problem and gain good interpretability for recommendation. Besides, every aspect rating is weighted by its aspect importance, which is dependent on the targeted user’s preferences and the targeted item’s features. Therefore, it is expected that the proposed method can model a user’s preferences on an item more accurately for each user-item pair. Comprehensive experimental studies have been conducted on the Yelp 2017 Challenge dataset and Amazon product datasets. Results show that (1) our method achieves significant improvement compared to strong baseline methods, especially for users with only few ratings; (2) item visual features can improve the prediction performance—the effects of item image features on improving the prediction results depend on the importance of the visual features for the items; and (3) our model can explicitly interpret the predicted results in great detail.",
    "cited_by_count": 122,
    "openalex_id": "https://openalex.org/W2900806287",
    "type": "article"
  },
  {
    "title": "Location Extraction from Social Media",
    "doi": "https://doi.org/10.1145/3202662",
    "publication_date": "2018-06-13",
    "publication_year": 2018,
    "authors": "Stuart E. Middleton; Giorgos Kordopatis-Zilos; Symeon Papadopoulos; Ioannis Kompatsiaris",
    "corresponding_authors": "",
    "abstract": "Location extraction, also called “toponym extraction,” is a field covering geoparsing, extracting spatial representations from location mentions in text, and geotagging, assigning spatial coordinates to content items. This article evaluates five “best-of-class” location extraction algorithms. We develop a geoparsing algorithm using an OpenStreetMap database, and a geotagging algorithm using a language model constructed from social media tags and multiple gazetteers. Third-party work evaluated includes a DBpedia-based entity recognition and disambiguation approach, a named entity recognition and Geonames gazetteer approach, and a Google Geocoder API approach. We perform two quantitative benchmark evaluations, one geoparsing tweets and one geotagging Flickr posts, to compare all approaches. We also perform a qualitative evaluation recalling top N location mentions from tweets during major news events. The OpenStreetMap approach was best (F1 0.90+) for geoparsing English, and the language model approach was best (F1 0.66) for Turkish. The language model was best (F1@1km 0.49) for the geotagging evaluation. The map database was best (R@20 0.60+) in the qualitative evaluation. We report on strengths, weaknesses, and a detailed failure analysis for the approaches and suggest concrete areas for further research.",
    "cited_by_count": 121,
    "openalex_id": "https://openalex.org/W2796495817",
    "type": "article"
  },
  {
    "title": "Exploring High-Order User Preference on the Knowledge Graph for Recommender Systems",
    "doi": "https://doi.org/10.1145/3312738",
    "publication_date": "2019-03-16",
    "publication_year": 2019,
    "authors": "Hongwei Wang; Fuzheng Zhang; Jialin Wang; Miao Zhao; Wenjie Li; Xing Xie; Minyi Guo",
    "corresponding_authors": "",
    "abstract": "To address the sparsity and cold-start problem of collaborative filtering, researchers usually make use of side information, such as social networks or item attributes, to improve the performance of recommendation. In this article, we consider the knowledge graph (KG) as the source of side information. To address the limitations of existing embedding-based and path-based methods for KG-aware recommendation, we propose RippleNet , an end-to-end framework that naturally incorporates the KG into recommender systems. RippleNet has two versions: (1) The outward propagation version, which is analogous to the actual ripples on water, stimulates the propagation of user preferences over the set of knowledge entities by automatically and iteratively extending a user’s potential interests along links in the KG. The multiple “ripples” activated by a user’s historically clicked items are thus superposed to form the preference distribution of the user with respect to a candidate item. (2) The inward aggregation version aggregates and incorporates the neighborhood information biasedly when computing the representation of a given entity. The neighborhood can be extended to multiple hops away to model high-order proximity and capture users’ long-distance interests. In addition, we intuitively demonstrate how a KG assists with recommender systems in RippleNet, and we also find that RippleNet provides a new perspective of explainability for the recommended results in terms of the KG. Through extensive experiments on real-world datasets, we demonstrate that both versions of RippleNet achieve substantial gains in a variety of scenarios, including movie, book, and news recommendations, over several state-of-the-art baselines.",
    "cited_by_count": 121,
    "openalex_id": "https://openalex.org/W2923964967",
    "type": "article"
  },
  {
    "title": "Sparse hashing for fast multimedia search",
    "doi": "https://doi.org/10.1145/2457465.2457469",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Xiaofeng Zhu; Zi Huang; Hong Cheng; Jiangtao Cui; Heng Tao Shen",
    "corresponding_authors": "",
    "abstract": "Hash-based methods achieve fast similarity search by representing high-dimensional data with compact binary codes. However, both generating binary codes and encoding unseen data effectively and efficiently remain very challenging tasks. In this article, we focus on these tasks to implement approximate similarity search by proposing a novel hash based method named sparse hashing (SH for short). To generate interpretable (or semantically meaningful) binary codes, the proposed SH first converts original data into low-dimensional data through a novel nonnegative sparse coding method. SH then converts the low-dimensional data into Hamming space (i.e., binary encoding low-dimensional data) by a new binarization rule. After this, training data are represented by generated binary codes. To efficiently and effectively encode unseen data, SH learns hash functions by taking a-priori knowledge into account, such as implicit group effect of the features in training data, and the correlations between original space and the learned Hamming space. SH is able to perform fast approximate similarity search by efficient bit XOR operations in the memory of a modern PC with short binary code representations. Experimental results show that the proposed SH significantly outperforms state-of-the-art techniques.",
    "cited_by_count": 119,
    "openalex_id": "https://openalex.org/W2164585733",
    "type": "article"
  },
  {
    "title": "Diagnostic Evaluation of Information Retrieval Models",
    "doi": "https://doi.org/10.1145/1961209.1961210",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Hui Fang; Tao Tao; ChengXiang Zhai",
    "corresponding_authors": "",
    "abstract": "Developing effective retrieval models is a long-standing central challenge in information retrieval research. In order to develop more effective models, it is necessary to understand the deficiencies of the current retrieval models and the relative strengths of each of them. In this article, we propose a general methodology to analytically and experimentally diagnose the weaknesses of a retrieval function, which provides guidance on how to further improve its performance. Our methodology is motivated by the empirical observation that good retrieval performance is closely related to the use of various retrieval heuristics. We connect the weaknesses and strengths of a retrieval function with its implementations of these retrieval heuristics, and propose two strategies to check how well a retrieval function implements the desired retrieval heuristics. The first strategy is to formalize heuristics as constraints, and use constraint analysis to analytically check the implementation of retrieval heuristics. The second strategy is to define a set of relevance-preserving perturbations and perform diagnostic tests to empirically evaluate how well a retrieval function implements retrieval heuristics. Experiments show that both strategies are effective to identify the potential problems in implementations of the retrieval heuristics. The performance of retrieval functions can be improved after we fix these problems.",
    "cited_by_count": 117,
    "openalex_id": "https://openalex.org/W2082359527",
    "type": "article"
  },
  {
    "title": "Exploring Question Selection Bias to Identify Experts and Potential Experts in Community Question Answering",
    "doi": "https://doi.org/10.1145/2180868.2180872",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Aditya Pal; F. Maxwell Harper; Joseph A. Konstan",
    "corresponding_authors": "",
    "abstract": "Community Question Answering (CQA) services enable their users to exchange knowledge in the form of questions and answers. These communities thrive as a result of a small number of highly active users, typically called experts , who provide a large number of high-quality useful answers. Expert identification techniques enable community managers to take measures to retain the experts in the community. There is further value in identifying the experts during the first few weeks of their participation as it would allow measures to nurture and retain them. In this article we address two problems: (a) How to identify current experts in CQA? and (b) How to identify users who have potential of becoming experts in future (potential experts)? In particular, we propose a probabilistic model that captures the selection preferences of users based on the questions they choose for answering. The probabilistic model allows us to run machine learning methods for identifying experts and potential experts. Our results over several popular CQA datasets indicate that experts differ considerably from ordinary users in their selection preferences; enabling us to predict experts with higher accuracy over several baseline models. We show that selection preferences can be combined with baseline measures to improve the predictive performance even further.",
    "cited_by_count": 111,
    "openalex_id": "https://openalex.org/W2002258741",
    "type": "article"
  },
  {
    "title": "Attentive Long Short-Term Preference Modeling for Personalized Product Search",
    "doi": "https://doi.org/10.1145/3295822",
    "publication_date": "2019-01-11",
    "publication_year": 2019,
    "authors": "Yangyang Guo; Zhiyong Cheng; Liqiang Nie; Yinglong Wang; Jun Ma; Mohan Kankanhalli",
    "corresponding_authors": "",
    "abstract": "E-commerce users may expect different products even for the same query, due to their diverse personal preferences. It is well known that there are two types of preferences: long-term ones and short-term ones. The former refers to users’ inherent purchasing bias and evolves slowly. By contrast, the latter reflects users’ purchasing inclination in a relatively short period. They both affect users’ current purchasing intentions. However, few research efforts have been dedicated to jointly model them for the personalized product search. To this end, we propose a novel Attentive Long Short-Term Preference model, dubbed as ALSTP, for personalized product search. Our model adopts the neural networks approach to learn and integrate the long- and short-term user preferences with the current query for the personalized product search. In particular, two attention networks are designed to distinguish which factors in the short-term as well as long-term user preferences are more relevant to the current query. This unique design enables our model to capture users’ current search intentions more accurately. Our work is the first to apply attention mechanisms to integrate both long- and short-term user preferences with the given query for the personalized search. Extensive experiments over four Amazon product datasets show that our model significantly outperforms several state-of-the-art product search methods in terms of different evaluation metrics.",
    "cited_by_count": 109,
    "openalex_id": "https://openalex.org/W2900464008",
    "type": "article"
  },
  {
    "title": "GeoMF++",
    "doi": "https://doi.org/10.1145/3182166",
    "publication_date": "2018-03-23",
    "publication_year": 2018,
    "authors": "Defu Lian; Kai Zheng; Yong Ge; Longbing Cao; Enhong Chen; Xing Xie",
    "corresponding_authors": "",
    "abstract": "Location recommendation is an important means to help people discover attractive locations. However, extreme sparsity of user-location matrices leads to a severe challenge, so it is necessary to take implicit feedback characteristics of user mobility data into account and leverage the location’s spatial information. To this end, based on previously developed GeoMF, we propose a scalable and flexible framework, dubbed GeoMF++, for joint geographical modeling and implicit feedback-based matrix factorization. We then develop an efficient optimization algorithm for parameter learning, which scales linearly with data size and the total number of neighbor grids of all locations. GeoMF++ can be well explained from two perspectives. First, it subsumes two-dimensional kernel density estimation so that it captures spatial clustering phenomenon in user mobility data; Second, it is strongly connected with widely used neighbor additive models, graph Laplacian regularized models, and collective matrix factorization. Finally, we extensively evaluate GeoMF++ on two large-scale LBSN datasets. The experimental results show that GeoMF++ consistently outperforms the state-of-the-art and other competing baselines on both datasets in terms of NDCG and Recall. Besides, the efficiency studies show that GeoMF++ is much more scalable with the increase of data size and the dimension of latent space.",
    "cited_by_count": 108,
    "openalex_id": "https://openalex.org/W2791723757",
    "type": "article"
  },
  {
    "title": "Attentive Aspect Modeling for Review-Aware Recommendation",
    "doi": "https://doi.org/10.1145/3309546",
    "publication_date": "2019-03-27",
    "publication_year": 2019,
    "authors": "Xinyu Guan; Zhiyong Cheng; Xiangnan He; Yongfeng Zhang; Zhibo Zhu; Qinke Peng; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "In recent years, many studies extract aspects from user reviews and integrate them with ratings for improving the recommendation performance. The common aspects mentioned in a user’s reviews and a product’s reviews indicate indirect connections between the user and product. However, these aspect-based methods suffer from two problems. First, the common aspects are usually very sparse, which is caused by the sparsity of user-product interactions and the diversity of individual users’ vocabularies. Second, a user’s interests on aspects could be different with respect to different products, which are usually assumed to be static in existing methods. In this article, we propose an Attentive Aspect-based Recommendation Model (AARM) to tackle these challenges. For the first problem, to enrich the aspect connections between user and product, besides common aspects, AARM also models the interactions between synonymous and similar aspects. For the second problem, a neural attention network which simultaneously considers user, product, and aspect information is constructed to capture a user’s attention toward aspects when examining different products. Extensive quantitative and qualitative experiments show that AARM can effectively alleviate the two aforementioned problems and significantly outperforms several state-of-the-art recommendation methods on the top-N recommendation task.",
    "cited_by_count": 108,
    "openalex_id": "https://openalex.org/W2899626049",
    "type": "article"
  },
  {
    "title": "Incorporating User Expectations and Behavior into the Measurement of Search Effectiveness",
    "doi": "https://doi.org/10.1145/3052768",
    "publication_date": "2017-06-05",
    "publication_year": 2017,
    "authors": "Alistair Moffat; Peter Bailey; Falk Scholer; Paul Thomas",
    "corresponding_authors": "",
    "abstract": "Information retrieval systems aim to help users satisfy information needs. We argue that the goal of the person using the system, and the pattern of behavior that they exhibit as they proceed to attain that goal, should be incorporated into the methods and techniques used to evaluate the effectiveness of IR systems, so that the resulting effectiveness scores have a useful interpretation that corresponds to the users’ search experience. In particular, we investigate the role of search task complexity, and show that it has a direct bearing on the number of relevant answer documents sought by users in response to an information need, suggesting that useful effectiveness metrics must be goal sensitive . We further suggest that user behavior while scanning results listings is affected by the rate at which their goal is being realized, and hence that appropriate effectiveness metrics must be adaptive to the presence (or not) of relevant documents in the ranking. In response to these two observations, we present a new effectiveness metric, INST, that has both of the desired properties: INST employs a parameter T , a direct measure of the user’s search goal that adjusts the top-weightedness of the evaluation score; moreover, as progress towards the target T is made, the modeled user behavior is adapted, to reflect the remaining expectations. INST is experimentally compared to previous effectiveness metrics, including Average Precision (AP), Normalized Discounted Cumulative Gain (NDCG), and Rank-Biased Precision (RBP), demonstrating our claims as to INST’s usefulness. Like RBP, INST is a weighted-precision metric, meaning that each score can be accompanied by a residual that quantifies the extent of the score uncertainty caused by unjudged documents. As part of our experimentation, we use crowd-sourced data and score residuals to demonstrate that a wide range of queries arise for even quite specific information needs, and that these variant queries introduce significant levels of residual uncertainty into typical experimental evaluations. These causes of variability have wide-reaching implications for experiment design, and for the construction of test collections.",
    "cited_by_count": 105,
    "openalex_id": "https://openalex.org/W2624553223",
    "type": "article"
  },
  {
    "title": "Cross-Platform App Recommendation by Jointly Modeling Ratings and Texts",
    "doi": "https://doi.org/10.1145/3017429",
    "publication_date": "2017-07-11",
    "publication_year": 2017,
    "authors": "Da Cao; Xiangnan He; Liqiang Nie; Xiaochi Wei; Xia Hu; Shunxiang Wu; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Over the last decade, the renaissance of Web technologies has transformed the online world into an application (App) driven society. While the abundant Apps have provided great convenience, their sheer number also leads to severe information overload, making it difficult for users to identify desired Apps. To alleviate the information overloading issue, recommender systems have been proposed and deployed for the App domain. However, existing work on App recommendation has largely focused on one single platform (e.g., smartphones), while it ignores the rich data of other relevant platforms (e.g., tablets and computers). In this article, we tackle the problem of cross-platform App recommendation, aiming at leveraging users’ and Apps’ data on multiple platforms to enhance the recommendation accuracy. The key advantage of our proposal is that by leveraging multiplatform data, the perpetual issues in personalized recommender systems—data sparsity and cold-start—can be largely alleviated. To this end, we propose a hybrid solution, STAR (short for “croSs-plaTform App Recommendation”) that integrates both numerical ratings and textual content from multiple platforms. In STAR, we innovatively represent an App as an aggregation of common features across platforms (e.g., App’s functionalities) and specific features that are dependent on the resided platform. In light of this, STAR can discriminate a user’s preference on an App by separating the user’s interest into two parts (either in the App’s inherent factors or platform-aware features). To evaluate our proposal, we construct two real-world datasets that are crawled from the App stores of iPhone, iPad, and iMac. Through extensive experiments, we show that our STAR method consistently outperforms highly competitive recommendation methods, justifying the rationality of our cross-platform App recommendation proposal and the effectiveness of our solution.",
    "cited_by_count": 102,
    "openalex_id": "https://openalex.org/W2736230012",
    "type": "article"
  },
  {
    "title": "User Activity Patterns During Information Search",
    "doi": "https://doi.org/10.1145/2699656",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Michael Cole; Chathra Hendahewa; Nicholas J. Belkin; Chirag Shah",
    "corresponding_authors": "",
    "abstract": "Personalization of support for information seeking depends crucially on the information retrieval system's knowledge of the task that led the person to engage in information seeking. Users work during information search sessions to satisfy their task goals, and their activity is not random. To what degree are there patterns in the user activity during information search sessions? Do activity patterns reflect the user's situation as the user moves through the search task under the influence of his or her task goal? Do these patterns reflect aspects of different types of information-seeking tasks? Could such activity patterns identify contexts within which information seeking takes place? To investigate these questions, we model sequences of user behaviors in two independent user studies of information search sessions (N = 32 users, 128 sessions, and N = 40 users, 160 sessions). Two representations of user activity patterns are used. One is based on the sequences of page use; the other is based on a cognitive representation of information acquisition derived from eye movement patterns in service of the reading process. One of the user studies considered journalism work tasks; the other concerned background research in genomics using search tasks taken from the TREC Genomics Track. The search tasks differed in basic dimensions of complexity, specificity, and the type of information product (intellectual or factual) needed to achieve the overall task goal. The results show that similar patterns of user activity are observed at both the cognitive and page use levels. The activity patterns at both representation layers are able to distinguish between task types in similar ways and, to some degree, between tasks of different levels of difficulty. We explore relationships between the results and task difficulty and discuss the use of activity patterns to explore events within a search session. User activity patterns can be at least partially observed in server-side search logs. A focus on patterns of user activity sequences may contribute to the development of information systems that better personalize the user's search experience.",
    "cited_by_count": 101,
    "openalex_id": "https://openalex.org/W1995311669",
    "type": "article"
  },
  {
    "title": "Learning or Forgetting? A Dynamic Approach for Tracking the Knowledge Proficiency of Students",
    "doi": "https://doi.org/10.1145/3379507",
    "publication_date": "2020-02-20",
    "publication_year": 2020,
    "authors": "Zhenya Huang; Qi Liu; Yuying Chen; Le Wu; Keli Xiao; Enhong Chen; Haiping Ma; Guoping Hu",
    "corresponding_authors": "",
    "abstract": "The rapid development of the technologies for online learning provides students with extensive resources for self-learning and brings new opportunities for data-driven research on educational management. An important issue of online learning is to diagnose the knowledge proficiency (i.e., the mastery level of a certain knowledge concept) of each student. Considering that it is a common case that students inevitably learn and forget knowledge from time to time, it is necessary to track the change of their knowledge proficiency during the learning process. Existing approaches either relied on static scenarios or ignored the interpretability of diagnosis results. To address these problems, in this article, we present a focused study on diagnosing the knowledge proficiency of students, where the goal is to track and explain their evolutions simultaneously. Specifically, we first devise an explanatory probabilistic matrix factorization model, Knowledge Proficiency Tracing (KPT), by leveraging educational priors. KPT model first associates each exercise with a knowledge vector in which each element represents a specific knowledge concept with the help of Q -matrix. Correspondingly, at each time, each student can be represented as a proficiency vector in the same knowledge space. Then, our KPT model jointly applies two classical educational theories (i.e., learning curve and forgetting curve ) to capture the change of students’ proficiency level on concepts over time. Furthermore, for improving the predictive performance, we develop an improved version of KPT, named Exercise-correlated Knowledge Proficiency Tracing (EKPT), by considering the connectivity among exercises with the same knowledge concepts. Finally, we apply our KPT and EKPT models to three important diagnostic tasks, including knowledge estimation, score prediction, and diagnosis result visualization. Extensive experiments on four real-world datasets demonstrate that both of our models could track the knowledge proficiency of students effectively and interpretatively.",
    "cited_by_count": 99,
    "openalex_id": "https://openalex.org/W3021176691",
    "type": "article"
  },
  {
    "title": "A Tensor-Based Information Framework for Predicting the Stock Market",
    "doi": "https://doi.org/10.1145/2838731",
    "publication_date": "2016-02-08",
    "publication_year": 2016,
    "authors": "Qing Li; Yuanzhu Chen; Li Jiang; Ping Li; Hsinchun Chen",
    "corresponding_authors": "",
    "abstract": "To study the influence of information on the behavior of stock markets, a common strategy in previous studies has been to concatenate the features of various information sources into one compound feature vector, a procedure that makes it more difficult to distinguish the effects of different information sources. We maintain that capturing the intrinsic relations among multiple information sources is important for predicting stock trends. The challenge lies in modeling the complex space of various sources and types of information and studying the effects of this information on stock market behavior. For this purpose, we introduce a tensor-based information framework to predict stock movements. Specifically, our framework models the complex investor information environment with tensors. A global dimensionality-reduction algorithm is used to capture the links among various information sources in a tensor, and a sequence of tensors is used to represent information gathered over time. Finally, a tensor-based predictive model to forecast stock movements, which is in essence a high-order tensor regression learning problem, is presented. Experiments performed on an entire year of data for China Securities Index stocks demonstrate that a trading system based on our framework outperforms the classic Top- N trading strategy and two state-of-the-art media-aware trading algorithms.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W2271008577",
    "type": "article"
  },
  {
    "title": "An Enhanced Neural Network Approach to Person-Job Fit in Talent Recruitment",
    "doi": "https://doi.org/10.1145/3376927",
    "publication_date": "2020-02-11",
    "publication_year": 2020,
    "authors": "Chuan Qin; Hengshu Zhu; Tong Xu; Chen Zhu; Chao Ma; Enhong Chen; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "The widespread use of online recruitment services has led to an information explosion in the job market. As a result, recruiters have to seek intelligent ways for Person-Job Fit, which is the bridge for adapting the right candidates to the right positions. Existing studies on Person-Job Fit usually focus on measuring the matching degree between talent qualification and job requirements mainly based on the manual inspection of human resource experts, which could be easily misguided by the subjective, incomplete, and inefficient nature of human judgment. To that end, in this article, we propose a novel end-to-end T opic-based A bility-aware P erson- J ob F it N eural N etwork (TAPJFNN) framework, which has a goal of reducing the dependence on manual labor and can provide better interpretability about the fitting results. The key idea is to exploit the rich information available in abundant historical job application data. Specifically, we propose a word-level semantic representation for both job requirements and job seekers’ experiences based on Recurrent Neural Network (RNN). Along this line, two hierarchical topic-based ability-aware attention strategies are designed to measure the different importance of job requirements for semantic representation, as well as measure the different contribution of each job experience to a specific ability requirement. In addition, we design a refinement strategy for Person-Job Fit prediction based on historical recruitment records. Furthermore, we introduce how to exploit our TAPJFNN framework for enabling two specific applications in talent recruitment: talent sourcing and job recommendation. Particularly, in the application of job recommendation, a novel training mechanism is designed for addressing the challenge of biased negative labels. Finally, extensive experiments on a large-scale real-world dataset clearly validate the effectiveness and interpretability of the TAPJFNN and its variants compared with several baselines.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W3011595896",
    "type": "article"
  },
  {
    "title": "Influence Estimation and Maximization in Continuous-Time Diffusion Networks",
    "doi": "https://doi.org/10.1145/2824253",
    "publication_date": "2016-02-08",
    "publication_year": 2016,
    "authors": "Manuel Gomez-Rodriguez; Le Song; Nan Du; Hongyuan Zha; Bernhard Schölkopf",
    "corresponding_authors": "",
    "abstract": "If a piece of information is released from a set of media sites, can it spread, in 1 month, to a million web pages? Can we efficiently find a small set of media sites among millions that can maximize the spread of the information, in 1 month? The two problems are called influence estimation and maximization problems respectively, which are very challenging since both the time-sensitive nature of the problems and the issue of scalability need to be addressed simultaneously. In this article, we propose two algorithms for influence estimation in continuous-time diffusion networks. The first one uses continuous-time Markov chains to estimate influence exactly on networks with exponential, or, more generally, phase-type transmission functions, but does not scale to large-scale networks, and the second one is a highly efficient randomized algorithm, which estimates the influence of every node in a network with general transmission functions, |ν| nodes and |ε| edges to an accuracy of ϵ using n = O (1/ϵ 2 ) randomizations and up to logarithmic factors O ( n |ε|+ n |ν| computations. We then show that finding the set of most influential source nodes in a continuous time diffusion network is an NP-hard problem and develop an efficient greedy algorithm with provable near-optimal performance. When used as subroutines in the influence maximization algorithm, the exact influence estimation algorithm is guaranteed to find a set of C nodes with an influence of at least (1 − 1/ e )OPT and the randomized algorithm is guaranteed to find a set with an influence of at least 1 − 1/ e )OPT − 2 C ε, where OPT is the optimal value. Experiments on both synthetic and real-world data show that the proposed algorithms significantly improve over previous state-of-the-art methods in terms of the accuracy of the estimated influence and the quality of the selected nodes to maximize the influence, and the randomized algorithm can easily scale up to networks of millions of nodes.",
    "cited_by_count": 89,
    "openalex_id": "https://openalex.org/W2254070738",
    "type": "article"
  },
  {
    "title": "Seamlessly Unifying Attributes and Items: Conversational Recommendation for Cold-start Users",
    "doi": "https://doi.org/10.1145/3446427",
    "publication_date": "2021-08-17",
    "publication_year": 2021,
    "authors": "Shijun Li; Wenqiang Lei; Qingyun Wu; Xiangnan He; Peng Jiang; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Static recommendation methods like collaborative filtering suffer from the inherent limitation of performing real-time personalization for cold-start users. Online recommendation, e.g., multi-armed bandit approach, addresses this limitation by interactively exploring user preference online and pursuing the exploration-exploitation (EE) trade-off. However, existing bandit-based methods model recommendation actions homogeneously. Specifically, they only consider the items as the arms, being incapable of handling the item attributes, which naturally provide interpretable information of user's current demands and can effectively filter out undesired items. In this work, we consider the conversational recommendation for cold-start users, where a system can both ask the attributes from and recommend items to a user interactively. This important scenario was studied in a recent work. However, it employs a hand-crafted function to decide when to ask attributes or make recommendations. Such separate modeling of attributes and items makes the effectiveness of the system highly rely on the choice of the hand-crafted function, thus introducing fragility to the system. To address this limitation, we seamlessly unify attributes and items in the same arm space and achieve their EE trade-offs automatically using the framework of Thompson Sampling. Our Conversational Thompson Sampling (ConTS) model holistically solves all questions in conversational recommendation by choosing the arm with the maximal reward to play. Extensive experiments on three benchmark datasets show that ConTS outperforms the state-of-the-art methods Conversational UCB (ConUCB) and Estimation-Action-Reflection model in both metrics of success rate and average number of conversation turns.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W3195061894",
    "type": "article"
  },
  {
    "title": "Hierarchical Hyperedge Embedding-Based Representation Learning for Group Recommendation",
    "doi": "https://doi.org/10.1145/3457949",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Lei Guo; Hongzhi Yin; Tong Chen; Xiangliang Zhang; Kai Zheng",
    "corresponding_authors": "",
    "abstract": "Group recommendation aims to recommend items to a group of users. In this work, we study group recommendation in a particular scenario, namely occasional group recommendation, where groups are formed ad hoc and users may just constitute a group for the first time—that is, the historical group-item interaction records are highly limited. Most state-of-the-art works have addressed the challenge by aggregating group members’ personal preferences to learn the group representation. However, the representation learning for a group is most complex beyond the aggregation or fusion of group member representation, as the personal preferences and group preferences may be in different spaces and even orthogonal. In addition, the learned user representation is not accurate due to the sparsity of users’ interaction data. Moreover, the group similarity in terms of common group members has been overlooked, which, however, has the great potential to improve the group representation learning. In this work, we focus on addressing the aforementioned challenges in the group representation learning task, and devise a hierarchical hyperedge embedding-based group recommender, namely HyperGroup. Specifically, we propose to leverage the user-user interactions to alleviate the sparsity issue of user-item interactions, and design a graph neural network-based representation learning network to enhance the learning of individuals’ preferences from their friends’ preferences, which provides a solid foundation for learning groups’ preferences. To exploit the group similarity (i.e., overlapping relationships among groups) to learn a more accurate group representation from highly limited group-item interactions, we connect all groups as a network of overlapping sets (a.k.a. hypergraph), and treat the task of group preference learning as embedding hyperedges (i.e., user sets/groups) in a hypergraph, where an inductive hyperedge embedding method is proposed. To further enhance the group-level preference modeling, we develop a joint training strategy to learn both user-item and group-item interactions in the same process. We conduct extensive experiments on two real-world datasets, and the experimental results demonstrate the superiority of our proposed HyperGroup in comparison to the state-of-the-art baselines.",
    "cited_by_count": 81,
    "openalex_id": "https://openalex.org/W3198098536",
    "type": "article"
  },
  {
    "title": "KR-GCN: Knowledge-Aware Reasoning with Graph Convolution Network for Explainable Recommendation",
    "doi": "https://doi.org/10.1145/3511019",
    "publication_date": "2022-03-15",
    "publication_year": 2022,
    "authors": "Ting Ma; Longtao Huang; Qianqian Lu; Songlin Hu",
    "corresponding_authors": "",
    "abstract": "Incorporating knowledge graphs (KGs) into recommender systems to provide explainable recommendation has attracted much attention recently. The multi-hop paths in KGs can provide auxiliary facts for improving recommendation performance as well as explainability. However, existing studies may suffer from two major challenges: error propagation and weak explainability. Considering all paths between every user-item pair might involve irrelevant ones, which leads to error propagation of user preferences. Defining meta-paths might alleviate the error propagation, but the recommendation performance would heavily depend on the pre-defined meta-paths. Some recent methods based on graph convolution network (GCN) achieve better recommendation performance, but fail to provide explainability. To tackle the above problems, we propose a novel method named K nowledge-aware R easoning with G raph C onvolution N etwork (KR-GCN). Specifically, to alleviate the effect of error propagation, we design a transition-based method to determine the triple-level scores and utilize nucleus sampling to select triples within the paths between every user-item pair adaptively. To improve the recommendation performance and guarantee the diversity of explanations, user-item interactions and knowledge graphs are integrated into a heterogeneous graph, which is performed with the graph convolution network. A path-level self-attention mechanism is adopted to discriminate the contributions of different selected paths and predict the interaction probability, which improves the relevance of the final explanation. Extensive experiments conducted on three real-world datasets show that KR-GCN consistently outperforms several state-of-the-art baselines. And human evaluation proves the superiority of KR-GCN on explainability.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W4220770035",
    "type": "article"
  },
  {
    "title": "User Cold-Start Recommendation via Inductive Heterogeneous Graph Neural Network",
    "doi": "https://doi.org/10.1145/3560487",
    "publication_date": "2022-09-01",
    "publication_year": 2022,
    "authors": "Desheng Cai; Shengsheng Qian; Quan Fang; Jun Hu; Changsheng Xu",
    "corresponding_authors": "",
    "abstract": "Recently, user cold-start recommendations have attracted a lot of attention from industry and academia. In user cold-start recommendation systems, the user attribute information is often used by existing approaches to learn user preferences due to the unavailability of user action data. However, most existing recommendation methods often ignore the sparsity of user attributes in cold-start recommendation systems. To tackle this limitation, this article proposes a novel Inductive Heterogeneous Graph Neural Network (IHGNN) model, which utilizes the relational information in user cold-start recommendation systems to alleviate the sparsity of user attributes. Our model converts new users, items, and associated multimodal information into a Modality-aware Heterogeneous Graph (M-HG) that preserves the rich and heterogeneous relationship information among them. Specifically, to utilize rich and heterogeneous relational information in an M-HG for enriching the sparse attribute information of new users, we design a strategy based on random walk operations to collect associated neighbors of new users by multiple times sampling operation. Then, a well-designed multiple hierarchical attention aggregation model consisting of the intra- and inter-type attention aggregating module is proposed, focusing on useful connected neighbors and neglecting meaningless and noisy connected neighbors to generate high-quality representations for user cold-start recommendations. Experimental results on three real datasets demonstrate that the IHGNN outperforms the state-of-the-art baselines.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W4294031701",
    "type": "article"
  },
  {
    "title": "ReFRS: Resource-efficient Federated Recommender System for Dynamic and Diversified User Preferences",
    "doi": "https://doi.org/10.1145/3560486",
    "publication_date": "2022-08-29",
    "publication_year": 2022,
    "authors": "Mubashir Imran; Hongzhi Yin; Tong Chen; Quoc Viet Hung Nguyen; Alexander Zhou; Kai Zheng",
    "corresponding_authors": "",
    "abstract": "Owing to its nature of scalability and privacy by design, federated learning (FL) has received increasing interest in decentralized deep learning. FL has also facilitated recent research on upscaling and privatizing personalized recommendation services, using on-device data to learn recommender models locally. These models are then aggregated globally to obtain a more performant model while maintaining data privacy. Typically, federated recommender systems (FRSs) do not take into account the lack of resources and data availability at the end-devices. In addition, they assume that the interaction data between users and items is i.i.d. and stationary across end-devices (i.e., users), and that all local recommender models can be directly averaged without considering the user’s behavioral diversity. However, in real scenarios, recommendations have to be made on end-devices with sparse interaction data and limited resources. Furthermore, users’ preferences are heterogeneous and they frequently visit new items. This makes their personal preferences highly skewed, and the straightforwardly aggregated model is thus ill-posed for such non-i.i.d. data. In this article, we propose Resource Efficient Federated Recommender System (ReFRS) to enable decentralized recommendation with dynamic and diversified user preferences. On the device side, ReFRS consists of a lightweight self-supervised local model built upon the variational autoencoder for learning a user’s temporal preference from a sequence of interacted items. On the server side, ReFRS utilizes a scalable semantic sampler to adaptively perform model aggregation within each identified cluster of similar users. The clustering module operates in an asynchronous and dynamic manner to support efficient global model update and cope with shifting user interests. As a result, ReFRS achieves superior performance in terms of both accuracy and scalability, as demonstrated by comparative experiments on real datasets.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W4293452925",
    "type": "article"
  },
  {
    "title": "Decentralized Collaborative Learning Framework for Next POI Recommendation",
    "doi": "https://doi.org/10.1145/3555374",
    "publication_date": "2022-08-08",
    "publication_year": 2022,
    "authors": "Jing Long; Tong Chen; Quoc Viet Hung Nguyen; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "Next Point-of-Interest (POI) recommendation has become an indispensable functionality in Location-based Social Networks (LBSNs) due to its effectiveness in helping people decide the next POI to visit. However, accurate recommendation requires a vast amount of historical check-in data, thus threatening user privacy as the location-sensitive data needs to be handled by cloud servers. Although there have been several on-device frameworks for privacy-preserving POI recommendations, they are still resource intensive when it comes to storage and computation, and show limited robustness to the high sparsity of user-POI interactions. On this basis, we propose a novel d ecentralized c ollaborative l earning framework for POI r ecommendation (DCLR), which allows users to train their personalized models locally in a collaborative manner. DCLR significantly reduces the local models’ dependence on the cloud for training, and can be used to expand arbitrary centralized recommendation models. To counteract the sparsity of on-device user data when learning each local model, we design two self-supervision signals to pretrain the POI representations on the server with geographical and categorical correlations of POIs. To facilitate collaborative learning, we innovatively propose to incorporate knowledge from either geographically or semantically similar users into each local model with attentive aggregation and mutual information maximization. The collaborative learning process makes use of communications between devices while requiring only minor engagement from the central server for identifying user groups, and is compatible with common privacy preservation mechanisms like differential privacy. We evaluate DCLR with two real-world datasets, where the results show that DCLR outperforms state-of-the-art on-device frameworks and yields competitive results compared with centralized counterparts.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W4290648792",
    "type": "article"
  },
  {
    "title": "On the Robustness of Aspect-based Sentiment Analysis: Rethinking Model, Data, and Training",
    "doi": "https://doi.org/10.1145/3564281",
    "publication_date": "2022-09-19",
    "publication_year": 2022,
    "authors": "Hao Fei; Tat‐Seng Chua; Chenliang Li; Donghong Ji; Meishan Zhang; Yafeng Ren",
    "corresponding_authors": "",
    "abstract": "Aspect-based sentiment analysis (ABSA) aims at automatically inferring the specific sentiment polarities toward certain aspects of products or services behind the social media texts or reviews, which has been a fundamental application to the real-world society. Since the early 2010s, ABSA has achieved extraordinarily high accuracy with various deep neural models. However, existing ABSA models with strong in-house performances may fail to generalize to some challenging cases where the contexts are variable, i.e., low robustness to real-world environments. In this study, we propose to enhance the ABSA robustness by systematically rethinking the bottlenecks from all possible angles, including model, data, and training. First, we strengthen the current best-robust syntax-aware models by further incorporating the rich external syntactic dependencies and the labels with aspect simultaneously with a universal-syntax graph convolutional network. In the corpus perspective, we propose to automatically induce high-quality synthetic training data with various types, allowing models to learn sufficient inductive bias for better robustness. Last, we based on the rich pseudo data perform adversarial training to enhance the resistance to the context perturbation and meanwhile employ contrastive learning to reinforce the representations of instances with contrastive sentiments. Extensive robustness evaluations are conducted. The results demonstrate that our enhanced syntax-aware model achieves better robustness performances than all the state-of-the-art baselines. By additionally incorporating our synthetic corpus, the robust testing results are pushed with around 10% accuracy, which are then further improved by installing the advanced training strategies. In-depth analyses are presented for revealing the factors influencing the ABSA robustness.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W4296366985",
    "type": "article"
  },
  {
    "title": "A Multi-Objective Optimization Framework for Multi-Stakeholder Fairness-Aware Recommendation",
    "doi": "https://doi.org/10.1145/3564285",
    "publication_date": "2022-09-19",
    "publication_year": 2022,
    "authors": "Haolun Wu; Chen Ma; Bhaskar Mitra; Fernando Díaz; Xue Liu",
    "corresponding_authors": "",
    "abstract": "Nowadays, most online services are hosted on multi-stakeholder marketplaces, where consumers and producers may have different objectives. Conventional recommendation systems, however, mainly focus on maximizing consumers’ satisfaction by recommending the most relevant items to each individual. This may result in unfair exposure of items, thus jeopardizing producer benefits. Additionally, they do not care whether consumers from diverse demographic groups are equally satisfied. To address these limitations, we propose a multi-objective optimization framework for fairness-aware recommendation, Multi-FR , that adaptively balances accuracy and fairness for various stakeholders with Pareto optimality guarantee. We first propose four fairness constraints on consumers and producers. In order to train the whole framework in an end-to-end way, we utilize the smooth rank and stochastic ranking policy to make these fairness criteria differentiable and friendly to back-propagation. Then, we adopt the multiple gradient descent algorithm to generate a Pareto set of solutions, from which the most appropriate one is selected by the Least Misery Strategy. The experimental results demonstrate that Multi-FR largely improves recommendation fairness on multiple stakeholders over the state-of-the-art approaches while maintaining almost the same recommendation accuracy. The training efficiency study confirms our model’s ability to simultaneously optimize different fairness constraints for many stakeholders efficiently.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W4296448351",
    "type": "article"
  },
  {
    "title": "AutoML for Deep Recommender Systems: A Survey",
    "doi": "https://doi.org/10.1145/3579355",
    "publication_date": "2023-01-05",
    "publication_year": 2023,
    "authors": "Ruiqi Zheng; Liang Qu; Bin Cui; Yuhui Shi; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "Recommender systems play a significant role in information filtering and have been utilized in different scenarios, such as e-commerce and social media. With the prosperity of deep learning, deep recommender systems show superior performance by capturing non-linear information and item-user relationships. However, the design of deep recommender systems heavily relies on human experiences and expert knowledge. To tackle this problem, Automated Machine Learning (AutoML) is introduced to automatically search for the proper candidates for different parts of deep recommender systems. This survey performs a comprehensive review of the literature in this field. Firstly, we propose an abstract concept for AutoML for deep recommender systems (AutoRecSys) that describes its building blocks and distinguishes it from conventional AutoML techniques and recommender systems. Secondly, we present a taxonomy as a classification framework containing feature selection search, embedding dimension search, feature interaction search, model architecture search, and other components search. Furthermore, we put a particular emphasis on the search space and search strategy, as they are the common thread to connect all methods within each category and enable practitioners to analyze and compare various approaches. Finally, we propose four future promising research directions that will lead this line of research.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W4313558118",
    "type": "article"
  },
  {
    "title": "A Critical Study on Data Leakage in Recommender System Offline Evaluation",
    "doi": "https://doi.org/10.1145/3569930",
    "publication_date": "2022-10-28",
    "publication_year": 2022,
    "authors": "Yitong Ji; Aixin Sun; Jie Zhang; Chenliang Li",
    "corresponding_authors": "",
    "abstract": "Recommender models are hard to evaluate, particularly under offline setting. In this article, we provide a comprehensive and critical analysis of the data leakage issue in recommender system offline evaluation. Data leakage is caused by not observing global timeline in evaluating recommenders e.g., train/test data split does not follow global timeline. As a result, a model learns from the user-item interactions that are not expected to be available at the prediction time. We first show the temporal dynamics of user-item interactions along global timeline, then explain why data leakage exists for collaborative filtering models. Through carefully designed experiments, we show that all models indeed recommend future items that are not available at the time point of a test instance, as the result of data leakage. The experiments are conducted with four widely used baseline models—BPR, NeuMF, SASRec, and LightGCN, on four popular offline datasets—MovieLens-25M, Yelp, Amazon-music, and Amazon-electronic, adopting leave-last-one-out data split. 1 We further show that data leakage does impact models’ recommendation accuracy. Their relative performance orders thus become unpredictable with different amount of leaked future data in training. To evaluate recommendation systems in a realistic manner in offline setting, we propose a timeline scheme, which calls for a revisit of the recommendation model design.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W3154199194",
    "type": "article"
  },
  {
    "title": "LightFR: Lightweight Federated Recommendation with Privacy-preserving Matrix Factorization",
    "doi": "https://doi.org/10.1145/3578361",
    "publication_date": "2022-12-22",
    "publication_year": 2022,
    "authors": "Honglei Zhang; Fangyuan Luo; Jun Wu; Xiangnan He; Yidong Li",
    "corresponding_authors": "",
    "abstract": "Federated recommender system (FRS), which enables many local devices to train a shared model jointly without transmitting local raw data, has become a prevalent recommendation paradigm with privacy-preserving advantages. However, previous work on FRS performs similarity search via inner product in continuous embedding space, which causes an efficiency bottleneck when the scale of items is extremely large. We argue that such a scheme in federated settings ignores the limited capacities in resource-constrained user devices (i.e., storage space, computational overhead, and communication bandwidth), and makes it harder to be deployed in large-scale recommender systems. Besides, it has been shown that transmitting local gradients in real-valued form between server and clients may leak users' private information. To this end, we propose a lightweight federated recommendation framework with privacy-preserving matrix factorization, LightFR, that is able to generate high-quality binary codes by exploiting learning to hash technique under federated settings, and thus enjoys both fast online inference and economic memory consumption. Moreover, we devise an efficient federated discrete optimization algorithm to collaboratively train model parameters between the server and clients, which can effectively prevent real-valued gradient attacks from malicious parties. Through extensive experiments on four real-world datasets, we show that our LightFR model outperforms several state-of-the-art FRS methods in terms of recommendation accuracy, inference efficiency and data privacy.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W4312191182",
    "type": "article"
  },
  {
    "title": "A Unified Multi-task Learning Framework for Multi-goal Conversational Recommender Systems",
    "doi": "https://doi.org/10.1145/3570640",
    "publication_date": "2022-11-04",
    "publication_year": 2022,
    "authors": "Yang Deng; Wenxuan Zhang; Weiwen Xu; Wenqiang Lei; Tat‐Seng Chua; Wai Lam",
    "corresponding_authors": "",
    "abstract": "Recent years witnessed several advances in developing multi-goal conversational recommender systems (MG-CRS) that can proactively attract users’ interests and naturally lead user-engaged dialogues with multiple conversational goals and diverse topics. Four tasks are often involved in MG-CRS, including Goal Planning, Topic Prediction, Item Recommendation, and Response Generation. Most existing studies address only some of these tasks. To handle the whole problem of MG-CRS, modularized frameworks are adopted where each task is tackled independently without considering their interdependencies. In this work, we propose a novel Unified MultI-goal conversational recommeNDer system (UniMIND). Specifically, we unify these four tasks with different formulations into the same sequence-to-sequence paradigm. Prompt-based learning strategies are investigated to endow the unified model with the capability of multi-task learning. Finally, the overall learning and inference procedure consists of three stages, including multi-task learning, prompt-based tuning, and inference. Experimental results on two MG-CRS benchmarks (DuRecDial and TG-ReDial) show that UniMIND achieves state-of-the-art performance on all tasks with a unified model. Extensive analyses and discussions are provided for shedding some new perspectives for MG-CRS.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W4308198680",
    "type": "article"
  },
  {
    "title": "Interaction-aware Drug Package Recommendation via Policy Gradient",
    "doi": "https://doi.org/10.1145/3511020",
    "publication_date": "2022-02-14",
    "publication_year": 2022,
    "authors": "Zhi Zheng; Chao Wang; Tong Xu; D. Z. Shen; Penggang Qin; Xiangyu Zhao; Baoxing Huai; Xian Wu; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "Recent years have witnessed the rapid accumulation of massive electronic medical records, which highly support intelligent medical services such as drug recommendation. However, although there are multiple interaction types between drugs, e.g., synergism and antagonism, which can influence the effect of a drug package significantly, prior arts generally neglect the interaction between drugs or consider only a single type of interaction. Moreover, most existing studies generally formulate the problem of package recommendation as getting a personalized scoring function for users, despite the limits of discriminative models to achieve satisfactory performance in practical applications. To this end, in this article, we propose a novel end-to-end Drug Package Generation (DPG) framework, which develops a new generative model for drug package recommendation that considers the interaction effects between drugs that are affected by patient conditions. Specifically, we propose to formulate the drug package generation as a sequence generation process. Along this line, we first initialize the drug interaction graph based on medical records and domain knowledge. Then, we design a novel message-passing neural network to capture the drug interaction, as well as a drug package generator based on a recurrent neural network. In detail, a mask layer is utilized to capture the impact of patient condition, and the deep reinforcement learning technique is leveraged to reduce the dependence on the drug order. Finally, extensive experiments on a real-world dataset from a first-rate hospital demonstrate the effectiveness of our DPG framework compared with several competitive baseline methods.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W4212804458",
    "type": "article"
  },
  {
    "title": "Addressing Confounding Feature Issue for Causal Recommendation",
    "doi": "https://doi.org/10.1145/3559757",
    "publication_date": "2022-08-30",
    "publication_year": 2022,
    "authors": "Xiangnan He; Yang Zhang; Fuli Feng; Chonggang Song; Lingling Yi; Guohui Ling; Yongdong Zhang",
    "corresponding_authors": "",
    "abstract": "In recommender systems, some features directly affect whether an interaction would happen, making the happened interactions not necessarily indicate user preference. For instance, short videos are objectively easier to finish even though the user may not like the video. We term such feature as confounding feature , and video length is a confounding feature in video recommendation. If we fit a model on such interaction data, just as done by most data-driven recommender systems, the model will be biased to recommend short videos more, and deviate from user actual requirement. This work formulates and addresses the problem from the causal perspective. Assuming there are some factors affecting both the confounding feature and other item features, e.g., the video creator, we find the confounding feature opens a backdoor path behind user-item matching and introduces spurious correlation. To remove the effect of backdoor path, we propose a framework named Deconfounding Causal Recommendation (DCR) , which performs intervened inference with do-calculus . Nevertheless, evaluating do-calculus requires to sum over the prediction on all possible values of confounding feature, significantly increasing the time cost. To address the efficiency challenge, we further propose a mixture-of-experts (MoE) model architecture, modeling each value of confounding feature with a separate expert module. Through this way, we retain the model expressiveness with few additional costs. We demonstrate DCR on the backbone model of neural factorization machine (NFM) , showing that DCR leads to more accurate prediction of user preference with small inference time cost. We release our code at: https://github.com/zyang1580/DCR .",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W4293569092",
    "type": "article"
  },
  {
    "title": "Towards Robust Neural Graph Collaborative Filtering via Structure Denoising and Embedding Perturbation",
    "doi": "https://doi.org/10.1145/3568396",
    "publication_date": "2022-10-17",
    "publication_year": 2022,
    "authors": "Haibo Ye; Xinjie Li; Yuan Yao; Hanghang Tong",
    "corresponding_authors": "",
    "abstract": "Neural graph collaborative filtering has received great recent attention due to its power of encoding the high-order neighborhood via the backbone graph neural networks. However, their robustness against noisy user-item interactions remains largely unexplored. Existing work on robust collaborative filtering mainly improves the robustness by denoising the graph structure, while recent progress in other fields has shown that directly adding adversarial perturbations in the embedding space can significantly improve the model robustness. In this work, we propose to improve the robustness of neural graph collaborative filtering via both denoising in the structure space and perturbing in the embedding space. Specifically, in the structure space, we measure the reliability of interactions and further use it to affect the message propagation process of the backbone graph neural networks; in the embedding space, we add in-distribution perturbations by mimicking the behavior of adversarial attacks and further combine it with contrastive learning to improve the performance. Extensive experiments have been conducted on four benchmark datasets to evaluate the effectiveness and efficiency of the proposed approach. The results demonstrate that the proposed approach outperforms the recent neural graph collaborative filtering methods especially when there are injected noisy interactions in the training data.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W4306407769",
    "type": "article"
  },
  {
    "title": "Position-Enhanced and Time-aware Graph Convolutional Network for Sequential Recommendations",
    "doi": "https://doi.org/10.1145/3511700",
    "publication_date": "2022-04-04",
    "publication_year": 2022,
    "authors": "Liwei Huang; Yutao Ma; Yanbo Liu; Bohong Danny Du; Shuliang Wang; Deyi Li",
    "corresponding_authors": "",
    "abstract": "The sequential recommendation (also known as the next-item recommendation), which aims to predict the following item to recommend in a session according to users’ historical behavior, plays a critical role in improving session-based recommender systems. Most of the existing deep learning-based approaches utilize the recurrent neural network architecture or self-attention to model the sequential patterns and temporal influence among a user's historical behavior and learn the user's preference at a specific time. However, these methods have two main drawbacks. First, they focus on modeling users’ dynamic states from a user-centric perspective and always neglect the dynamics of items over time. Second, most of them deal with only the first-order user-item interactions and do not consider the high-order connectivity between users and items, which has recently been proved helpful for the sequential recommendation. To address the above problems, in this article, we attempt to model user-item interactions by a bipartite graph structure and propose a new recommendation approach based on a Position-enhanced and Time-aware Graph Convolutional Network (PTGCN) for the sequential recommendation. PTGCN models the sequential patterns and temporal dynamics between user-item interactions by defining a position-enhanced and time-aware graph convolution operation and learning the dynamic representations of users and items simultaneously on the bipartite graph with a self-attention aggregator. Also, it realizes the high-order connectivity between users and items by stacking multi-layer graph convolutions. To demonstrate the effectiveness of PTGCN, we carried out a comprehensive evaluation of PTGCN on three real-world datasets of different sizes compared with a few competitive baselines. Experimental results indicate that PTGCN outperforms several state-of-the-art sequential recommendation models in terms of two commonly-used evaluation metrics for ranking. In particular, it can make a better trade-off between recommendation performance and model training efficiency, which holds great potential for online session-based recommendation scenarios in the future.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W3178564468",
    "type": "article"
  },
  {
    "title": "Time-aware Path Reasoning on Knowledge Graph for Recommendation",
    "doi": "https://doi.org/10.1145/3531267",
    "publication_date": "2022-05-06",
    "publication_year": 2022,
    "authors": "Yuyue Zhao; Xiang Wang; Jiawei Chen; Yashen Wang; Wei Tang; Xiangnan He; Haiyong Xie",
    "corresponding_authors": "",
    "abstract": "Reasoning on knowledge graph (KG) has been studied for explainable recommendation due to it's ability of providing explicit explanations. However, current KG-based explainable recommendation methods unfortunately ignore the temporal information (such as purchase time, recommend time, etc.), which may result in unsuitable explanations. In this work, we propose a novel Time-aware Path reasoning for Recommendation (TPRec for short) method, which leverages the potential of temporal information to offer better recommendation with plausible explanations. First, we present an efficient time-aware interaction relation extraction component to construct collaborative knowledge graph with time-aware interactions (TCKG for short), and then introduce a novel time-aware path reasoning method for recommendation. We conduct extensive experiments on three real-world datasets. The results demonstrate that the proposed TPRec could successfully employ TCKG to achieve substantial gains and improve the quality of explainable recommendation.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W3190867660",
    "type": "article"
  },
  {
    "title": "Collaborative Graph Learning for Session-based Recommendation",
    "doi": "https://doi.org/10.1145/3490479",
    "publication_date": "2022-04-12",
    "publication_year": 2022,
    "authors": "Zhiqiang Pan; Fei Cai; Wanyu Chen; Chonghao Chen; Honghui Chen",
    "corresponding_authors": "",
    "abstract": "Session-based recommendation (SBR) , which mainly relies on a user’s limited interactions with items to generate recommendations, is a widely investigated task. Existing methods often apply RNNs or GNNs to model user’s sequential behavior or transition relationship between items to capture her current preference. For training such models, the supervision signals are merely generated from the sequential interactions inside a session, neglecting the correlations of different sessions, which we argue can provide additional supervisions for learning the item representations. Moreover, previous methods mainly adopt the cross-entropy loss for training, where the user’s ground truth preference distribution towards items is regarded as a one-hot vector of the target item, easily making the network over-confident and leading to a serious overfitting problem. Thus, in this article, we propose a Collaborative Graph Learning (CGL) approach for session-based recommendation. CGL first applies the Gated Graph Neural Networks (GGNNs) to learn item embeddings and then is trained by considering both the main supervision as well as the self-supervision signals simultaneously. The main supervisions are produced by the sequential order while the self-supervisions are derived from the global graph constructed by all sessions. In addition, to prevent overfitting, we propose a Target-aware Label Confusion (TLC) learning method in the main supervised component. Extensive experiments are conducted on three publicly available datasets, i.e., Retailrocket, Diginetica, and Gowalla. The experimental results show that CGL can outperform the state-of-the-art baselines in terms of Recall and MRR.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W4223449011",
    "type": "article"
  },
  {
    "title": "Cascading Residual Graph Convolutional Network for Multi-Behavior Recommendation",
    "doi": "https://doi.org/10.1145/3587693",
    "publication_date": "2023-03-15",
    "publication_year": 2023,
    "authors": "Mingshi Yan; Zhiyong Cheng; Chen Gao; Jing Sun; Fan Liu; Fuming Sun; Haojie Li",
    "corresponding_authors": "",
    "abstract": "Multi-behavior recommendation exploits multiple types of user-item interactions, such as view and cart , to learn user preferences and has demonstrated to be an effective solution to alleviate the data sparsity problem faced by the traditional models that often utilize only one type of interaction for recommendation. In real scenarios, users often take a sequence of actions to interact with an item, in order to get more information about the item and thus accurately evaluate whether an item fits their personal preferences. Those interaction behaviors often obey a certain order, and more importantly, different behaviors reveal different information or aspects of user preferences towards the target item. Most existing multi-behavior recommendation methods take the strategy to first extract information from different behaviors separately and then fuse them for final prediction. However, they have not exploited the connections between different behaviors to learn user preferences. Besides, they often introduce complex model structures and more parameters to model multiple behaviors, largely increasing the space and time complexity. In this work, we propose a lightweight multi-behavior recommendation model named Cascading Residual Graph Convolutional Network ( CRGCN for short) for multi-behavior recommendation, which can explicitly exploit the connections between different behaviors into the embedding learning process without introducing any additional parameters (with comparison to the single-behavior based recommendation model). In particular, we design a cascading residual graph convolutional network (GCN) structure, which enables our model to learn user preferences by continuously refining the embeddings across different types of behaviors. The multi-task learning method is adopted to jointly optimize our model based on different behaviors. Extensive experimental results on three real-world benchmark datasets show that CRGCN can substantially outperform the state-of-the-art methods, achieving 24.76%, 27.28%, and 25.10% relative gains on average in terms of HR@K (K = {10,20,50,80}) over the best baseline across the three datasets. Further studies also analyze the effects of leveraging multi-behaviors in different numbers and orders on the final performance.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W4324359913",
    "type": "article"
  },
  {
    "title": "Federated User Modeling from Hierarchical Information",
    "doi": "https://doi.org/10.1145/3560485",
    "publication_date": "2023-02-09",
    "publication_year": 2023,
    "authors": "Qi Liu; Jinze Wu; Zhenya Huang; Hao Wang; Yuting Ning; Ming Chen; Enhong Chen; Jinfeng Yi; Bowen Zhou",
    "corresponding_authors": "",
    "abstract": "The generation of large amounts of personal data provides data centers with sufficient resources to mine idiosyncrasy from private records. User modeling has long been a fundamental task with the goal of capturing the latent characteristics of users from their behaviors. However, centralized user modeling on collected data has raised concerns about the risk of data misuse and privacy leakage. As a result, federated user modeling has come into favor, since it expects to provide secure multi-client collaboration for user modeling through federated learning. Unfortunately, to the best of our knowledge, existing federated learning methods that ignore the inconsistency among clients cannot be applied directly to practical user modeling scenarios, and moreover, they meet the following critical challenges: 1) Statistical heterogeneity . The distributions of user data in different clients are not always independently identically distributed (IID), which leads to unique clients with needful personalized information; 2) Privacy heterogeneity . User data contains both public and private information, which have different levels of privacy, indicating that we should balance different information shared and protected; 3) Model heterogeneity . The local user models trained with client records are heterogeneous, and thus require a flexible aggregation in the server; 4) Quality heterogeneity . Low-quality information from inconsistent clients poisons the reliability of user models and offsets the benefit from high-quality ones, meaning that we should augment the high-quality information during the process. To address the challenges, in this paper, we first propose a novel client-server architecture framework, namely Hierarchical Personalized Federated Learning (HPFL), with a primary goal of serving federated learning for user modeling in inconsistent clients. More specifically, the client train and deliver the local user model via the hierarchical components containing hierarchical information from privacy heterogeneity to join collaboration in federated learning. Moreover, the client updates the personalized user model with a fine-grained personalized update strategy for statistical heterogeneity. Correspondingly, the server flexibly aggregates hierarchical components from heterogeneous user models in the case of privacy and model heterogeneity with a differentiated component aggregation strategy. In order to augment high-quality information and generate high-quality user models, we expand HPFL to the Augmented-HPFL (AHPFL) framework by incorporating the augmented mechanisms, which filters out low-quality information such as noise, sparse information and redundant information. Specially, we construct two implementations of AHPFL, i.e., AHPFL-SVD and AHPFL-AE, where the augmented mechanisms follow SVD (singular value decomposition) and AE (autoencoder), respectively. Finally, we conduct extensive experiments on real-world datasets, which demonstrate the effectiveness of both HPFL and AHPFL frameworks.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W4319734845",
    "type": "article"
  },
  {
    "title": "DGEKT: A Dual Graph Ensemble Learning Method for Knowledge Tracing",
    "doi": "https://doi.org/10.1145/3638350",
    "publication_date": "2023-12-22",
    "publication_year": 2023,
    "authors": "Chaoran Cui; Yumo Yao; Chunyun Zhang; Hebo Ma; Yuling Ma; Zhaochun Ren; Chen Zhang; James Ko",
    "corresponding_authors": "",
    "abstract": "Knowledge tracing aims to trace students’ evolving knowledge states by predicting their future performance on concept-related exercises. Recently, some graph-based models have been developed to incorporate the relationships between exercises to improve knowledge tracing, but only a single type of relationship information is generally explored. In this article, we present a novel Dual Graph Ensemble learning method for Knowledge Tracing (DGEKT), which establishes a dual graph structure of students’ learning interactions to capture the heterogeneous exercise–concept associations and interaction transitions by hypergraph modeling and directed graph modeling, respectively. To combine the dual graph models, we introduce the technique of online knowledge distillation. This choice arises from the observation that, while the knowledge tracing model is designed to predict students’ responses to the exercises related to different concepts, it is optimized merely with respect to the prediction accuracy on a single exercise at each step. With online knowledge distillation, the dual graph models are adaptively combined to form a stronger ensemble teacher model, which provides its predictions on all exercises as extra supervision for better modeling ability. In the experiments, we compare DGEKT against eight knowledge tracing baselines on three benchmark datasets, and the results demonstrate that DGEKT achieves state-of-the-art performance.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W4390105690",
    "type": "article"
  },
  {
    "title": "On the Effectiveness of Sampled Softmax Loss for Item Recommendation",
    "doi": "https://doi.org/10.1145/3637061",
    "publication_date": "2023-12-13",
    "publication_year": 2023,
    "authors": "Jiancan Wu; Xiang Wang; Xingyu Gao; Jiawei Chen; Hongcheng Fu; Tianyu Qiu",
    "corresponding_authors": "",
    "abstract": "The learning objective plays a fundamental role to build a recommender system. Most methods routinely adopt either pointwise (e.g., binary cross-entropy) or pairwise (e.g., BPR) loss to train the model parameters, while rarely pay attention to softmax loss, which assumes the probabilities of all classes sum up to 1, due to its computational complexity when scaling up to large datasets or intractability for streaming data where the complete item space is not always available. The sampled softmax (SSM) loss emerges as an efficient substitute for softmax loss. Its special case, InfoNCE loss, has been widely used in self-supervised learning and exhibited remarkable performance for contrastive learning. Nonetheless, limited recommendation work uses the SSM loss as the learning objective. Worse still, none of them explores its properties thoroughly and answers “Does SSM loss suit for item recommendation?” and “What are the conceptual advantages of SSM loss, as compared with the prevalent losses?”, to the best of our knowledge. In this work, we aim at offering a better understanding of SSM for item recommendation. Specifically, we first theoretically reveal three model-agnostic advantages: (1) mitigating popularity bias, which is beneficial to long-tail recommendation; (2) mining hard negative samples, which offers informative gradients to optimize model parameters; and (3) maximizing the ranking metric, which facilitates top- K performance. However, based on our empirical studies, we recognize that the default choice of cosine similarity function in SSM limits its ability in learning the magnitudes of representation vectors. As such, the combinations of SSM with the models that also fall short in adjusting magnitudes (e.g., matrix factorization) may result in poor representations. One step further, we provide mathematical proof that message passing schemes in graph convolution networks can adjust representation magnitude according to node degree, which naturally compensates for the shortcoming of SSM. Extensive experiments on four benchmark datasets justify our analyses, demonstrating the superiority of SSM for item recommendation. Our implementations are available in both TensorFlow 1 and PyTorch. 2",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W4389675217",
    "type": "article"
  },
  {
    "title": "M3GAT: A Multi-modal, Multi-task Interactive Graph Attention Network for Conversational Sentiment Analysis and Emotion Recognition",
    "doi": "https://doi.org/10.1145/3593583",
    "publication_date": "2023-05-20",
    "publication_year": 2023,
    "authors": "Yazhou Zhang; Ao Jia; Bo Wang; Peng Zhang; Dongming Zhao; Pu Li; Yuexian Hou; Xiaojia Jin; Dawei Song; Jing Qin",
    "corresponding_authors": "",
    "abstract": "Sentiment and emotion, which correspond to long-term and short-lived human feelings, are closely linked to each other, leading to the fact that sentiment analysis and emotion recognition are also two interdependent tasks in natural language processing (NLP). One task often leverages the shared knowledge from another task and performs better when solved in a joint learning paradigm. Conversational context dependency, multi-modal interaction, and multi-task correlation are three key factors that contribute to this joint paradigm. However, none of the recent approaches have considered them in a unified framework. To fill this gap, we propose a multi-modal, multi-task interactive graph attention network, termed M3GAT, to simultaneously solve the three problems. At the heart of the model is a proposed interactive conversation graph layer containing three core sub-modules, which are: (1) local-global context connection for modeling both local and global conversational context, (2) cross-modal connection for learning multi-modal complementary and (3) cross-task connection for capturing the correlation across two tasks. Comprehensive experiments on three benchmarking datasets, MELD, MEISD, and MSED, show the effectiveness of M3GAT over state-of-the-art baselines with the margin of 1.88%, 5.37%, and 0.19% for sentiment analysis, and 1.99%, 3.65%, and 0.13% for emotion recognition, respectively. In addition, we also show the superiority of multi-task learning over the single-task framework.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W4377140104",
    "type": "article"
  },
  {
    "title": "Contrastive Learning for Legal Judgment Prediction",
    "doi": "https://doi.org/10.1145/3580489",
    "publication_date": "2023-01-18",
    "publication_year": 2023,
    "authors": "Han Zhang; Zhicheng Dou; Yutao Zhu; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Legal judgment prediction (LJP) is a fundamental task of legal artificial intelligence. It aims to automatically predict the judgment results of legal cases. Three typical subtasks are relevant law article prediction, charge prediction, and term-of-penalty prediction. Due to the wide range of potential applications, LJP has attracted a great deal of interest, prompting the development of numerous approaches. These methods mainly focus on building a more accurate representation of a case’s fact description in order to improve the performance of judgment prediction. They overlook, however, the practical judicial scenario in which human judges often compare similar law articles or possible charges before making a final decision. To this end, we propose a supervised contrastive learning framework for the LJP task. Specifically, we train the model to distinguish (1) various law articles within the same chapter of a Law and (2) similar charges of the same law article or related law articles. By this means, the fine-grained differences between similar articles/charges can be captured, which are important for making a judgment. Besides, we optimize our model by identifying cases with the same article/charge labels, allowing it to more effectively model the relationship between the case’s fact description and its associated labels. By jointly learning the LJP task with the aforementioned contrastive learning tasks, our model achieves better performance than the state-of-the-art models on two real-world datasets.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W4317209756",
    "type": "article"
  },
  {
    "title": "A Diffusion Model for POI Recommendation",
    "doi": "https://doi.org/10.1145/3624475",
    "publication_date": "2023-09-14",
    "publication_year": 2023,
    "authors": "Yifang Qin; Hongjun Wu; Wei Ju; Xiao Luo; Ming Zhang",
    "corresponding_authors": "",
    "abstract": "Next Point-of-Interest (POI) recommendation is a critical task in location-based services that aim to provide personalized suggestions for the user’s next destination. Previous works on POI recommendation have laid focus on modeling the user’s spatial preference. However, existing works that leverage spatial information are only based on the aggregation of users’ previous visited positions, which discourages the model from recommending POIs in novel areas. This trait of position-based methods will harm the model’s performance in many situations. Additionally, incorporating sequential information into the user’s spatial preference remains a challenge. In this article, we propose Diff-POI : a Diffu sion-based model that samples the user’s spatial preference for the next POI recommendation. Inspired by the wide application of diffusion algorithm in sampling from distributions, Diff-POI encodes the user’s visiting sequence and spatial character with two tailor-designed graph encoding modules, followed by a diffusion-based sampling strategy to explore the user’s spatial visiting trends. We leverage the diffusion process and its reverse form to sample from the posterior distribution and optimized the corresponding score function. We design a joint training and inference framework to optimize and evaluate the proposed Diff-POI. Extensive experiments on four real-world POI recommendation datasets demonstrate the superiority of our Diff-POI over state-of-the-art baseline methods. Further ablation and parameter studies on Diff-POI reveal the functionality and effectiveness of the proposed diffusion-based sampling strategy for addressing the limitations of existing methods.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W4386746103",
    "type": "article"
  },
  {
    "title": "Multi-View Enhanced Graph Attention Network for Session-Based Music Recommendation",
    "doi": "https://doi.org/10.1145/3592853",
    "publication_date": "2023-05-20",
    "publication_year": 2023,
    "authors": "Dongjing Wang; Xin Zhang; Yuyu Yin; Dongjin Yu; Guandong Xu; Shuiguang Deng",
    "corresponding_authors": "",
    "abstract": "Traditional music recommender systems are mainly based on users’ interactions, which limit their performance. Particularly, various kinds of content information, such as metadata and description can be used to improve music recommendation. However, it remains to be addressed how to fully incorporate the rich auxiliary/side information and effectively deal with heterogeneity in it. In this paper, we propose a M ulti-view E nhanced G raph A ttention N etwork (named MEGAN ) for session-based music recommendation. MEGAN can learn informative representations (embeddings) of music pieces and users from heterogeneous information based on graph neural network and attention mechanism. Specifically, the proposed approach MEGAN firstly models users’ listening behaviors and the textual content of music pieces with a Heterogeneous Music Graph (HMG). Then, a devised Graph Attention Network is used to learn the low-dimensional embedding of music pieces and users and by integrating various kinds of information, which is enhanced by multi-view from HMG in an adaptive and unified way. Finally, users’ hybrid preferences are learned from users’ listening behaviors and music pieces that satisfy users real-time requirements are recommended. Comprehensive experiments are conducted on two real-world datasets, and the results show that MEGAN achieves better performance than baselines, including several state-of-the-art recommendation methods.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W4377138220",
    "type": "article"
  },
  {
    "title": "A Next Basket Recommendation Reality Check",
    "doi": "https://doi.org/10.1145/3587153",
    "publication_date": "2023-03-09",
    "publication_year": 2023,
    "authors": "Ming Li; Sami Jullien; Mozhdeh Ariannezhad; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "The goal of a next basket recommendation (NBR) system is to recommend items for the next basket for a user, based on the sequence of their prior baskets. We examine whether the performance gains of the NBR methods reported in the literature hold up under a fair and comprehensive comparison. To clarify the mixed picture that emerges from our comparison, we provide a novel angle on the evaluation of next basket recommendation (NBR) methods, centered on the distinction between repetition and exploration: the next basket is typically composed of previously consumed items (i.e., repeat items) and new items (i.e., explore items). We propose a set of metrics that measure the repetition/exploration ratio and performance of NBR models. Using these new metrics, we provide a second analysis of state-of-the-art NBR models. The results help to clarify the extent of the actual progress achieved by existing NBR methods as well as the underlying reasons for any improvements that we observe. Overall, our work sheds light on the evaluation problem of NBR, provides a new evaluation protocol, and yields useful insights for the design of models for this task.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W3204257979",
    "type": "article"
  },
  {
    "title": "Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach",
    "doi": "https://doi.org/10.1145/3708882",
    "publication_date": "2024-12-20",
    "publication_year": 2024,
    "authors": "Junjie Zhang; Ruobing Xie; Yupeng Hou; Wayne Xin Zhao; Leyu Lin; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "In the past decades, recommender systems have attracted much attention in both research and industry communities. Existing recommendation models mainly learn the underlying user preference from historical behavior data (typically in the forms of item IDs), and then estimate the user-item matching relationships for recommendations. Inspired by the recent progress on large language models (LLMs), we develop a different recommendation paradigm, considering recommendation as instruction following by LLMs. The key idea is that the needs of a user can be expressed in natural language descriptions (called instructions ), so that LLMs can understand and further execute the instruction for fulfilling the recommendation. For this purpose, we instruction tune the 3B Flan-T5-XL, to better adapt LLMs to recommender systems. We first design a general instruction format for describing the preference, intention, and task form of a user in natural language. Then we manually design 39 instruction templates and automatically generate large amounts of user-personalized instruction data with varying types of preferences and intentions. To demonstrate the effectiveness of our approach, we instantiate the instructions into several widely studied recommendation (or search) tasks, and conduct extensive experiments with real-world datasets. Experiment results show that our approach can outperform several competitive baselines, including the powerful GPT-3.5, on these evaluation tasks. Our approach sheds light on developing user-friendly recommender systems, in which users can freely communicate with the system and obtain accurate recommendations via natural language instructions.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W4405643374",
    "type": "article"
  },
  {
    "title": "CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented Generation of Large Language Models",
    "doi": "https://doi.org/10.1145/3701228",
    "publication_date": "2024-10-19",
    "publication_year": 2024,
    "authors": "Yuanjie Lyu; Zhiyu Li; Simin Niu; Feiyu Xiong; Bo Tang; Wenjin Wang; Hao Wu; Huanyong Liu; Tong Xu; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "Retrieval-Augmented Generation (RAG) is a technique that enhances the capabilities of large language models (LLMs) by incorporating external knowledge sources. This method addresses common LLM limitations, including outdated information and the tendency to produce inaccurate “hallucinated” content. However, evaluating RAG systems is a challenge. Most benchmarks focus primarily on question answering applications, neglecting other potential scenarios where RAG could be beneficial. Accordingly, in the experiments, these benchmarks often assess only the LLM components of the RAG pipeline or the retriever in knowledge-intensive scenarios, overlooking the impact of external knowledge base construction and the retrieval component on the entire RAG pipeline in non-knowledge-intensive scenarios. To address these issues, this paper constructs a large-scale and more comprehensive benchmark, and evaluates all the components of RAG systems in various RAG application scenarios. Specifically, we refer to the CRUD actions that describe interactions between users and knowledge bases, and also categorize the range of RAG applications into four distinct types–Create, Read, Update, and Delete (CRUD). “Create” refers to scenarios requiring the generation of original, varied content. “Read” involves responding to intricate questions in knowledge-intensive situations. “Update” focuses on revising and rectifying inaccuracies or inconsistencies in pre-existing texts. “Delete” pertains to the task of summarizing extensive texts into more concise forms. For each of these CRUD categories, we have developed different datasets to evaluate the performance of RAG systems. We also analyze the effects of various components of the RAG system, such as the retriever, context length, knowledge base construction, and LLM. Finally, we provide useful insights for optimizing the RAG technology for different scenarios 1 .",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4403560390",
    "type": "article"
  },
  {
    "title": "Should Fairness be a Metric or a Model? A Model-based Framework for Assessing Bias in Machine Learning Pipelines",
    "doi": "https://doi.org/10.1145/3641276",
    "publication_date": "2024-01-23",
    "publication_year": 2024,
    "authors": "John P. Lalor; Ahmed Abbasi; Kezia Oketch; Yi Yang; Nicole Forsgren",
    "corresponding_authors": "",
    "abstract": "Fairness measurement is crucial for assessing algorithmic bias in various types of machine learning (ML) models, including ones used for search relevance, recommendation, personalization, talent analytics, and natural language processing. However, the fairness measurement paradigm is currently dominated by fairness metrics that examine disparities in allocation and/or prediction error as univariate key performance indicators (KPIs) for a protected attribute or group. Although important and effective in assessing ML bias in certain contexts such as recidivism, existing metrics don’t work well in many real-world applications of ML characterized by imperfect models applied to an array of instances encompassing a multivariate mixture of protected attributes, that are part of a broader process pipeline. Consequently, the upstream representational harm quantified by existing metrics based on how the model represents protected groups doesn’t necessarily relate to allocational harm in the application of such models in downstream policy/decision contexts. We propose FAIR-Frame, a model-based framework for parsimoniously modeling fairness across multiple protected attributes in regard to the representational and allocational harm associated with the upstream design/development and downstream usage of ML models. We evaluate the efficacy of our proposed framework on two testbeds pertaining to text classification using pretrained language models. The upstream testbeds encompass over fifty thousand documents associated with twenty-eight thousand users, seven protected attributes and five different classification tasks. The downstream testbeds span three policy outcomes and over 5.41 million total observations. Results in comparison with several existing metrics show that the upstream representational harm measures produced by FAIR-Frame and other metrics are significantly different from one another, and that FAIR-Frame’s representational fairness measures have the highest percentage alignment and lowest error with allocational harm observed in downstream applications. Our findings have important implications for various ML contexts, including information retrieval, user modeling, digital platforms, and text classification, where responsible and trustworthy AI is becoming an imperative.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4391136348",
    "type": "article"
  },
  {
    "title": "MultiCBR: Multi-view Contrastive Learning for Bundle Recommendation",
    "doi": "https://doi.org/10.1145/3640810",
    "publication_date": "2024-01-23",
    "publication_year": 2024,
    "authors": "Yunshan Ma; Yingzhi He; Xiang Wang; Yinwei Wei; Xiaoyu Du; Yuyangzi Fu; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Bundle recommendation seeks to recommend a bundle of related items to users to improve both user experience and the profits of platform. Existing bundle recommendation models have progressed from capturing only user-bundle interactions to the modeling of multiple relations among users, bundles, and items. CrossCBR, in particular, incorporates cross-view contrastive learning into a two-view preference learning framework, significantly improving SOTA performance. It does, however, have two limitations: (1) the two-view formulation does not fully exploit all the heterogeneous relations among users, bundles, and items; and (2) the “early contrast and late fusion” framework is less effective in capturing user preference and difficult to generalize to multiple views. In this article, we present MultiCBR, a novel Multi -view C ontrastive learning framework for B undle R ecommendation. First, we devise a multi-view representation learning framework capable of capturing all the user-bundle, user-item, and bundle-item relations, especially better utilizing the bundle-item affiliations to enhance sparse bundles’ representations. Second, we innovatively adopt an “early fusion and late contrast” design that first fuses the multi-view representations before performing self-supervised contrastive learning. In comparison to existing approaches, our framework reverses the order of fusion and contrast, introducing the following advantages: (1) Our framework is capable of modeling both cross-view and ego-view preferences, allowing us to achieve enhanced user preference modeling; and (2) instead of requiring quadratic number of cross-view contrastive losses, we only require two self-supervised contrastive losses, resulting in minimal extra costs. Experimental results on three public datasets indicate that our method outperforms SOTA methods. The code and dataset can be found in the github repo https://github.com/HappyPointer/MultiCBR .",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4391145699",
    "type": "article"
  },
  {
    "title": "Contrastive Clustering Learning for Multi-Behavior Recommendation",
    "doi": "https://doi.org/10.1145/3698192",
    "publication_date": "2024-10-01",
    "publication_year": 2024,
    "authors": "Wei Lan; Guoxian Zhou; Qingfeng Chen; Wenguang Wang; Shirui Pan; Yi Pan; Shichao Zhang",
    "corresponding_authors": "",
    "abstract": "Increasing multiple behavior recommendation models have achieved great successes. However, many models do not consider commonalities and differences between behaviors and data sparsity of the target behavior. This paper proposes a novel Multi-behavior Recommendation Model (MBRCC) based on Contrastive Clustering Learning. Specifically, the graph convolutional network (GCN) is employed to obtain the embeddings of users and items, respectively. Then, three kinds of tasks (including behavior-level embedding, instance-level embedding and cluster-level embedding) are designed to optimize the embeddings of users and items. In behavior-level embedding, we design an adaptive parameter learning strategy to analyze the impact of auxiliary behaviors on the target behavior. Then, the embeddings of users for each behavior are weighted to obtain the final embeddings of users. In instance-level embedding, we employ contrastive learning to analyze the instances of user and item for mitigating the issue of data sparsity. In cluster-level embedding, we design a new cluster contrastive learning method to capture the similarity between groups of user and item. Finally, we combine these three tasks to improve the quality of the embeddings of users and items. We conduct extensive experiments on three real-world datasets and experimental results indicate that the MBRCC remarkably outperforms numerous existing recommendation models.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4403028081",
    "type": "article"
  },
  {
    "title": "Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations",
    "doi": "https://doi.org/10.1145/3731446",
    "publication_date": "2025-04-21",
    "publication_year": 2025,
    "authors": "Xu Huang; Jianxun Lian; Yuxuan Lei; Jing Yao; Defu Lian; Xing Xie",
    "corresponding_authors": "",
    "abstract": "Recommender models capture ever-changing user preferences by training with in-domain user behavior data. These models are typically lightweight, facilitating real-time and large-scale online services. However, these models often falter when tasked with providing more sophisticated functionalities, such as offering explanations or engaging in conversations. Recently, large language models (LLMs) have emerged as a significant advancement towards artificial general intelligence, demonstrating impressive capabilities in instruction comprehension, reasoning, and human interaction. Unfortunately, LLMs lack the understanding of domain-specific item catalogs and behavioral patterns, especially in areas that deviate from general world knowledge, such as online e-commerce. This limitation makes them unsuitable to function as recommender models directly. In this paper, we bridge the gap between recommender models and LLMs, combining their respective strengths to create an interactive recommender system. We present an efficient framework, termed as InteRecAgent , which utilizes LLMs as the brain and recommender models as instrumental tools. We first outline a minimal set of essential tools required to transform LLMs into InteRecAgent. To overcome specific challenges associated with LLM-based agents for recommender systems, we enhance three core components, covering memory mechanism, task planning, and tool learning abilities. The InteRecAgent empowers traditional recommender systems, like ID-based matrix factorization models, to evolve into versatile and interactive systems with a natural language interface through the integration of LLMs. Experimental results derived from three public datasets demonstrate that the InteRecAgent delivers strong performance as a conversational recommender system, surpassing general LLMs such as GPT-4.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4409643680",
    "type": "article"
  },
  {
    "title": "C2lRec: Causal Contrastive Learning for User Cold-start Recommendation with Social Variable",
    "doi": "https://doi.org/10.1145/3711858",
    "publication_date": "2025-01-09",
    "publication_year": 2025,
    "authors": "Xiaolong Xu; Hongsheng Dong; Haolong Xiang; Xiyuan Hu; Xiaoyong Li; Xiaoyu Xia; Xuyun Zhang; Lianyong Qi; Wanchun Dou",
    "corresponding_authors": "",
    "abstract": "Embedding-based recommender systems rely on historical interactions to model users, which poses challenges for recommending to new users, known as the user cold-start problem. Some approaches incorporate social networks to deduce preferences based on the social circles of cold-start users to solve the problem of sparse features. However, such methods have difficulty distinguishing between superficial correlations and causal relationships in social behaviors, leading to inaccuracies in predicting user preferences. To address the aforementioned issues, we propose the Causal Contrastive Learning Recommendation (C2lRec) framework. Specifically, we causally model the inference of hidden preferences from the feature and historical behavior of warm users and predict user interactions based on such preferences. The counterfactual inference is subsequently performed to intervene and extract interactions from historical behaviors of warm users that influence their preferences, designating as primary causal variables. Additionally, we utilize the primary causal variables from users within the social circle of cold-start users to substitute the missing historical interactions of cold-start users and employ a similar causal modeling approach to uncover hidden preferences as we do with warm users. Finally, we realize causal contrastive learning to enhance the distribution of cold-start users. Extensive experiments conducted on three public datasets demonstrate that the recommendation performance of C2lRec exceeds that of state-of-the-art methods.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4406213719",
    "type": "article"
  },
  {
    "title": "Proactive Conversational AI: A Comprehensive Survey of Advancements and Opportunities",
    "doi": "https://doi.org/10.1145/3715097",
    "publication_date": "2025-01-24",
    "publication_year": 2025,
    "authors": "Yang Deng; Lizi Liao; Wenqiang Lei; Grace Hui Yang; Wai Lam; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Dialogue systems are designed to offer human users social support or functional services through natural language interactions. Traditional conversation research has put significant emphasis on a system’s response-ability, including its capacity to understand dialogue context and generate appropriate responses. However, the key element of proactive behavior – a crucial aspect of intelligent conversations – is often overlooked in these studies. Proactivity empowers conversational agents to lead conversations towards achieving pre-defined targets or fulfilling specific goals on the system side. Proactive dialogue systems are equipped with advanced techniques to handle complex tasks, requiring strategic and motivational interactions, thus representing a significant step towards artificial general intelligence. Motivated by the necessity and challenges of building proactive dialogue systems, we provide a comprehensive review of various prominent problems and advanced designs for implementing proactivity into different types of dialogue systems, including open-domain dialogues, task-oriented dialogues, and information-seeking dialogues. We also discuss real-world challenges that require further research attention to meet application needs in the future, such as proactivity in dialogue systems that are based on large language models, proactivity in hybrid dialogues, evaluation protocols and ethical considerations for proactive dialogue systems. By providing a quick access and overall picture of the proactive dialogue systems domain, we aim to inspire new research directions and stimulate further advancements towards achieving the next level of conversational AI capabilities, paving the way for more dynamic and intelligent interactions within various application domains.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4406800170",
    "type": "article"
  },
  {
    "title": "Efficient and Effective Role Player: A Compact Knowledge-grounded Persona-based Dialogue Model Enhanced by LLM Distillation",
    "doi": "https://doi.org/10.1145/3711857",
    "publication_date": "2025-01-10",
    "publication_year": 2025,
    "authors": "Linmei Hu; Xinyu Zhang; Dandan Song; Changzhi Zhou; Hongyu He; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "Incorporating explicit personas into dialogue models is critical for generating responses that fulfill specific user needs and preferences, creating a more personalized and engaging interaction. Early works on persona-based dialogue generation directly concatenate the persona descriptions and dialogue history into relatively small pre-trained language models (PLMs) for response generation, which leads to uninformative and inferior results due to the sparse persona information and the limited model generation capabilities. Recently, large language models (LLMs) have shown their surprising capabilities in language generation. Prompting the LLMs with the persona descriptions for role-playing dialogue generation has also achieved promising results. However, deploying LLMs is challenging for practical applications due to their large scale, spurring efforts to distill the generation capabilities into more concise and compact models through teacher-student learning. In this paper, we propose an efficient compact K nowledge-grounded P ersona-based D ialogue model enhanced by LLM D istillation (KPDD). Specifically, first, we propose to enrich the annotated persona descriptions by integrating external knowledge graphs (KGs) with a mixed encoding network, coupled with a mixture of experts (MoE) module for both informative and diverse response generation. The mixed encoding network contains multiple layers of modality interaction operations, enabling information from both modalities propagates to the other. Second, to fully exploit the generation capabilities of LLMs, we turn to the distillation technique to improve the generation capabilities of our model, facilitated by a natural language inference (NLI) based filtering mechanism to extract high-quality information from LLMs. In addition, we employ a curriculum learning strategy to train our model on the high-quality filtered distilled data and progressively on the relatively noisy original data, enhancing its adaptability and performance. Extensive experiments show that KPDD outperforms state-of-the-art baselines in terms of both automatic and human evaluation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4406243029",
    "type": "article"
  },
  {
    "title": "LLMCDSR: Enhancing Cross-Domain Sequential Recommendation with Large Language Models",
    "doi": "https://doi.org/10.1145/3715099",
    "publication_date": "2025-01-28",
    "publication_year": 2025,
    "authors": "Haoran Xin; Ying Sun; Chao Wang; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "Cross-Domain Sequential Recommendation (CDSR) aims to predict users’ preferences based on historical sequential interactions across multiple domains. Existing works focus on the overlapped users who interact in multiple domains to capture the cross-domain correlations. These methods often underperform in practical scenarios featuring both overlapped and non-overlapped users due to the limited cross-domain interactions and knowledge transfer misalignment for non-overlapped users. To address this, we leverage Large Language Models (LLMs) to facilitate CDSR by fully exploiting single-domain interactions. However, LLMs exhibit inherent limitations in handling extensive item repositories and sequential collaborative signals. Moreover, the generation reliability is compromised by the hallucination problem, potentially causing noisy and unstable outputs. To this end, we propose a novel LLMCDSR framework, which employs LLMs to predict unobserved cross-domain interactions, termed pseudo items, within single-domain interactions. Specifically, we first prompt LLMs to execute the Candidate-Free Cross-Domain Interaction Generation task. Then, we devise a Collaborative-Textual Contrastive Pre-Training strategy, learning to infuse collaborative information into textual features. Afterwards, we present a novel Relevance-Aware Meta Recall Network (RMRN) to selectively identify and retrieve high-quality pseudo items from the dataset, where the parameters are optimized in a meta-learning manner. Finally, extensive experiments on two public datasets validate the effectiveness of LLMCDSR in enhancing CDSR.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4406903437",
    "type": "article"
  },
  {
    "title": "A multilevel approach to intelligent information filtering",
    "doi": "https://doi.org/10.1145/263479.263481",
    "publication_date": "1997-10-01",
    "publication_year": 1997,
    "authors": "Javed Mostafa; Saurabh Mukhopadhyay; Mathew Palakal; Wai Lam",
    "corresponding_authors": "",
    "abstract": "In information-filtering environments, uncertainties associated with changing interests of the user and the dynamic document stream must be handled efficiently. In this article, a filtering model is proposed that decomposes the overall task into subsystem functionalities and highlights the need for multiple adaptation techniques to cope with uncertainties. A filtering system, SIFTER, has been implemented based on the model, using established techniques in information retrieval and artificial intelligence. These techniques include document representation by a vector-space model, document classification by unsupervised learning, and user modeling by reinforcement learning. The system can filter information based on content and a user's specific interests. The user's interests are automatically learned with only limited user intervention in the form of optional relevance feedback for documents. We also describe experimental studies conducted with SIFTER to filter computer and information science documents collected from the Internet and commercial database services. The experimental results demonstrate that the system performs very well in filtering documents in a realistic problem setting.",
    "cited_by_count": 177,
    "openalex_id": "https://openalex.org/W1985048767",
    "type": "article"
  },
  {
    "title": "Groupwork close up",
    "doi": "https://doi.org/10.1145/159764.159763",
    "publication_date": "1993-10-01",
    "publication_year": 1993,
    "authors": "Judith S. Olson; Gary M. Olson; Marianne Storrøsten; Mark Carter",
    "corresponding_authors": "",
    "abstract": "A simple collaborative tool, a shared text editor called ShrEdit, changed the way groups of designers performed their work, and changed it for the better. First, the designs produced by the 19 groups of three designers were of higher quality than those of the 19 groups who worked with conventional whiteboard, paper and pencil. The groups with the new tool reported liking their work process a little less, probably because they had to adapt their work style to a new tool. We expected, from the brainstorming literature and recent work on Group Support Systems, that the reason the designs were of better quality was that the supported groups generated more ideas . To our surprise, the groups working with ShrEdit generated fewer design ideas , but apparently better ones. It appears that the tool helped the supported groups keep more focused on the core issued in the emerging design, to waste less time on less important topics, and to capture what was said as they went. This suggests that small workgroups can capitalize on the free access they have to a shared workspace, without requiring a facilitator or a work process embedded in the software.",
    "cited_by_count": 171,
    "openalex_id": "https://openalex.org/W2162623029",
    "type": "article"
  },
  {
    "title": "Videodraw: a video interface for collaborative drawing",
    "doi": "https://doi.org/10.1145/123078.128729",
    "publication_date": "1991-04-01",
    "publication_year": 1991,
    "authors": "John Tang; Scott Minneman",
    "corresponding_authors": "",
    "abstract": "article Free AccessVideodraw: a video interface for collaborative drawing Authors: John C. Tang Xerox Palo Alto Research Center Xerox Palo Alto Research CenterView Profile , Scott L. Minneman Xerox Palo Alto Research Center Xerox Palo Alto Research CenterView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 9Issue 2pp 170–184https://doi.org/10.1145/123078.128729Published:01 April 1991Publication History 112citation1,413DownloadsMetricsTotal Citations112Total Downloads1,413Last 12 Months115Last 6 weeks17 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 168,
    "openalex_id": "https://openalex.org/W1975153339",
    "type": "article"
  },
  {
    "title": "Model-driven development of Web applications",
    "doi": "https://doi.org/10.1145/358108.358110",
    "publication_date": "2000-10-01",
    "publication_year": 2000,
    "authors": "Piero Fraternali; Paolo Paolini",
    "corresponding_authors": "",
    "abstract": "This paper describes a methodology for the development of WWW applications and a tool environment specifically tailored for the methodology. The methodology and the development environment are based upon models and techniques already used in the hypermedia, information systems, and software engineering fields, adapted and blended in an original mix. The foundation of the proposal is the conceptual design of WWW applications, using HDM-lite, a notation for the specification of structure, navigation, and presentation semantics. The conceptual schema is then translated into a “traditional” database schema, which describes both the organization of the content and the desired navigation and presentation features. The WWW pages can therefore be dynamically generated from the database content, following the navigation requests of the user. A CASE environment, called Autoweb System, offers a set of software tools, which assist the design and the execution of a WWW application, in all its different aspects, Real-life experiences of the use of the methodology and of the AutoWeb System in both the industrial and academic context are reported.",
    "cited_by_count": 168,
    "openalex_id": "https://openalex.org/W2077057017",
    "type": "article"
  },
  {
    "title": "The role of critiquing in cooperative problem solving",
    "doi": "https://doi.org/10.1145/123078.128727",
    "publication_date": "1991-04-01",
    "publication_year": 1991,
    "authors": "Gerhard Fischer; Andreas Lemke; Thomas W. Mastaglio; A. Morch",
    "corresponding_authors": "",
    "abstract": "article Free AccessThe role of critiquing in cooperative problem solving Authors: Gerhard Fischer University of Colorado, Boulder University of Colorado, BoulderView Profile , Andreas C. Lemke University of Colorado, Boulder University of Colorado, BoulderView Profile , Thomas Mastaglio University of Colorado, Boulder University of Colorado, BoulderView Profile , Andres I. Morch University of Colorado, Boulder University of Colorado, BoulderView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 9Issue 2pp 123–151https://doi.org/10.1145/123078.128727Published:01 April 1991Publication History 99citation1,235DownloadsMetricsTotal Citations99Total Downloads1,235Last 12 Months41Last 6 weeks9 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 162,
    "openalex_id": "https://openalex.org/W2165604170",
    "type": "article"
  },
  {
    "title": "Decoupled simulation in virtual reality with the MR toolkit",
    "doi": "https://doi.org/10.1145/159161.173948",
    "publication_date": "1993-07-01",
    "publication_year": 1993,
    "authors": "Chris Shaw; Mark Green; Jiandong Liang; Yunqi Sun",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Decoupled simulation in virtual reality with the MR toolkit Authors: Chris Shaw University of Alberta University of AlbertaView Profile , Mark Green University of Alberta University of AlbertaView Profile , Jiandong Liang University of Alberta University of AlbertaView Profile , Yunqi Sun University of Alberta University of AlbertaView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 11Issue 301 July 1993pp 287–317https://doi.org/10.1145/159161.173948Published:01 July 1993Publication History 129citation938DownloadsMetricsTotal Citations129Total Downloads938Last 12 Months52Last 6 weeks5 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 161,
    "openalex_id": "https://openalex.org/W2092248501",
    "type": "article"
  },
  {
    "title": "Sequential patterns in information systems development",
    "doi": "https://doi.org/10.1145/214174.214178",
    "publication_date": "1996-01-11",
    "publication_year": 1996,
    "authors": "Daniel Robey; Michael Newman",
    "corresponding_authors": "",
    "abstract": "We trace the process of developing and implementing a materials management system in one company over a 15-year period. Using a process research model developed by Newman and Robey, we identify 44 events in the process and define them as either encounters or episodes. Encounters are concentrated events, such as meetings and announcements, that separate episodes, which are events of longer duration. By examining the sequence of events over the 15 years of the case, we identify a pattern of repeated failure, followed by success. Our discussion centers on the value of detecting and displaying such patterns and the need for theoretical interpretation of recurring sequences of events. Five alternative theoretical perspectives, originally proposed by Kling, are used to interpret the sequential patterns identified by the model. We conclude that the form of the process model allows researchers who operate from different perspectives to enrich their understanding of the process of system development.",
    "cited_by_count": 158,
    "openalex_id": "https://openalex.org/W2048975853",
    "type": "article"
  },
  {
    "title": "Exceptions and exception handling in computerized information processes",
    "doi": "https://doi.org/10.1145/201040.201049",
    "publication_date": "1995-04-01",
    "publication_year": 1995,
    "authors": "Diane M. Strong; Steven Miller",
    "corresponding_authors": "",
    "abstract": "Exceptions, situations that cannot be correctly processed by computer systems, occur frequently in computer-based information processes. Five perspectives on exceptions provide insights into why exceptions occur and how they might be eliminated or more efficiently handled. We investigate these perspectives using an in-depth study of an operating information process that has frequent exceptions. Our results support the use of a total quality management (TQM) approach of eliminating exceptions for some exceptions, in particular, those caused by computer systems that are poor matches to organizational processes. However, some exceptions are explained better by a political system perspective of conflicting goals between subunits. For these exceptions and several other types, designing an integrated human-computer process will provide better performance than will eliminating exceptions and moving toward an entirely automated process.",
    "cited_by_count": 158,
    "openalex_id": "https://openalex.org/W2057000314",
    "type": "article"
  },
  {
    "title": "Unidraw: a framework for building domain-specific graphical editors",
    "doi": "https://doi.org/10.1145/98188.98197",
    "publication_date": "1990-07-01",
    "publication_year": 1990,
    "authors": "John Vlissides; Mark Linton",
    "corresponding_authors": "",
    "abstract": "Unidraw is a framework for creating graphical editors in domains such as technical and artistic drawing, music composition, and circuit design. The Unidraw architecture simplifies the construction of these editors by proving programming abstractions that are common across domains. Unidraw defines four basic abstractions: components define operations on components, and external representations define the mapping between components and the file format generated by the editor. Unidraw also supports multiple views, graphical connectivity, and dataflow between components. This paper describes the Unidraw design, implementation issues, and three experimental domain specific editors we have developed with Unidraw: a drawing editor, a user interface builder, and a schematic capture system. Our results indicate a substantial reduction in implementation time and effort compared with existing tools.",
    "cited_by_count": 157,
    "openalex_id": "https://openalex.org/W2094228499",
    "type": "article"
  },
  {
    "title": "Beyond intratransaction association analysis",
    "doi": "https://doi.org/10.1145/358108.358114",
    "publication_date": "2000-10-01",
    "publication_year": 2000,
    "authors": "Hongjun Lü; Ling Feng; Jiawei Han",
    "corresponding_authors": "",
    "abstract": "In this paper, we extend the scope of mining association rules from traditional single-dimensional intratransaction associations, to multidimensional intertransaction associations. Intratransaction associations are the associations among items with the same transaction , where the notion of the transaction could be the items bought by the same customer , the events happened on the same day , and so on. However, an intertransaction association describes the association relationships among different transactions , such as “if(company) A's stock goes up on day 1, B's stock will go down on day 2, but go up on day 4.” In this case, whether we treat company or day as the unit of transaction, the associated items belong to different transactions. Moreover, such an intertransaction association can be extended to associate multiple contextual properties in the same rule, so that multidimensional intertransaction associations can be defined and discovered. A two-dimensional intertransaction association rule example is “After McDonald and Burger King open branches, KFC will open a branch two months later and one mile away,” which involves two dimensions: time and space . Mining intertransaction associations poses more challenges on efficient processing than mining intratransaction associations. Interestingly, intratransaction association can be treated as a special case of intertransaction association from both a conceptual and algorithmic point of view. In this study, we introduce the notion of multidimensional intertransaction association rules, study their measurements— support and confidence—and develop algorithms for mining intertransaction associations by extension of Apriori. We overview our experience using the algorithms on both real-life and synthetic data sets. Further extensions of multidimensional intertransaction association rules and potential applications are also discussed.",
    "cited_by_count": 155,
    "openalex_id": "https://openalex.org/W2063529879",
    "type": "article"
  },
  {
    "title": "Burst tries",
    "doi": "https://doi.org/10.1145/506309.506312",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "Steffen Heinz; Justin Zobel; Hugh Williams",
    "corresponding_authors": "",
    "abstract": "Many applications depend on efficient management of large sets of distinct strings in memory. For example, during index construction for text databases a record is held for each distinct word in the text, containing the word itself and information such as counters. We propose a new data structure, the burst trie, that has significant advantages over existing options for such applications: it uses about the same memory as a binary search tree; it is as fast as a trie; and, while not as fast as a hash table, a burst trie maintains the strings in sorted or near-sorted order. In this paper we describe burst tries and explore the parameters that govern their performance. We experimentally determine good choices of parameters, and compare burst tries to other structures used for the same task, with a variety of data sets. These experiments show that the burst trie is particularly effective for the skewed frequency distributions common in text collections, and dramatically outperforms all other data structures for the task of managing strings while maintaining sort order.",
    "cited_by_count": 154,
    "openalex_id": "https://openalex.org/W2076747312",
    "type": "article"
  },
  {
    "title": "Enhancing relevance feedback in image retrieval using unlabeled data",
    "doi": "https://doi.org/10.1145/1148020.1148023",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Zhi‐Hua Zhou; Kejia Chen; Hongbin Dai",
    "corresponding_authors": "",
    "abstract": "Relevance feedback is an effective scheme bridging the gap between high-level semantics and low-level features in content-based image retrieval (CBIR). In contrast to previous methods which rely on labeled images provided by the user, this article attempts to enhance the performance of relevance feedback by exploiting unlabeled images existing in the database. Concretely, this article integrates the merits of semisupervised learning and active learning into the relevance feedback process. In detail, in each round of relevance feedback two simple learners are trained from the labeled data, that is, images from user query and user feedback. Each learner then labels some unlabeled images in the database for the other learner. After retraining with the additional labeled data, the learners reclassify the images in the database and then their classifications are merged. Images judged to be positive with high confidence are returned as the retrieval result, while those judged with low confidence are put into the pool which is used in the next round of relevance feedback. Experiments show that using semisupervised learning and active learning simultaneously in CBIR is beneficial, and the proposed method achieves better performance than some existing methods.",
    "cited_by_count": 154,
    "openalex_id": "https://openalex.org/W2156386254",
    "type": "article"
  },
  {
    "title": "Incremental clustering for dynamic information processing",
    "doi": "https://doi.org/10.1145/130226.134466",
    "publication_date": "1993-04-01",
    "publication_year": 1993,
    "authors": "Fazlı Can",
    "corresponding_authors": "Fazlı Can",
    "abstract": "Clustering of very large document databases is useful for both searching and browsing. The periodic updating of clusters is required due to the dynamic nature of databases. An algorithm for incremental clustering is introduced. The complexity and cost analysis of the algorithm together with an investigation of its expected behavior are presented. Through empirical testing it is shown that the algorithm achieves cost effectiveness and generates statistically valid clusters that are compatible with those of reclustering. The experimental evidence shows that the algorithm creates an effective and efficient retrieval environment.",
    "cited_by_count": 152,
    "openalex_id": "https://openalex.org/W2006636107",
    "type": "article"
  },
  {
    "title": "Multimedia document presentation, information extraction, and document formation in MINOS: a model and a system",
    "doi": "https://doi.org/10.1145/9760.9764",
    "publication_date": "1986-12-01",
    "publication_year": 1986,
    "authors": "Stavros Christodoulakis; Μαρία Θεοδωρίδου; F. Ho; M. Papa; A. Pathria",
    "corresponding_authors": "",
    "abstract": "MINOS is an object-oriented multimedia information system that provides integrated facilities for creating and managing complex multimedia objects. In this paper the model for multimedia documents supported by MINOS and its implementation is described. Described in particular are functions provided in MINOS that exploit the capabilities of a modern workstation equipped with image and voice input-output devices to accomplish an active multimedia document presentation and browsing within documents. These functions are powerful enough to support a variety of office applications. Also described are functions provided for the extraction of information from multimedia documents that exist in a large repository of information (multimedia document archiver) and functions that select and transform this information. Facilities for information sharing among objects of the archiver are described; an interactive multimedia editor that is used for the extraction and interactive creation of new information is outlined; finally, a multimedia document formatter that is used to synthesize a new multimedia document from extracted and interactively generated information is presented. This prototype system runs on a SUN-3 workstation running UNIX'\". An Instavox, directly addressable, analog device is used to store voice segments.",
    "cited_by_count": 152,
    "openalex_id": "https://openalex.org/W2054236430",
    "type": "article"
  },
  {
    "title": "A data model for flexible hypertext database systems",
    "doi": "https://doi.org/10.1145/64789.64993",
    "publication_date": "1989-01-03",
    "publication_year": 1989,
    "authors": "Frank Wm. Tompa",
    "corresponding_authors": "Frank Wm. Tompa",
    "abstract": "Hypertext and other page-oriented databases cannot be schematized in the same manner as record-oriented databases. As a result, most hypertext databases implicitly employ a data model based on a simple, unrestricted graph. This paper presents a hypergraph model for maintaining page-oriented databases in such a way that some of the functionality traditionally provided by database schemes can be available to hypertext databases. In particular, the model formalizes identification of commonality in the structure, set-at-a-time database access, and definition of user-specific views. An efficient implementation of the model is also discussed.",
    "cited_by_count": 148,
    "openalex_id": "https://openalex.org/W2005754849",
    "type": "article"
  },
  {
    "title": "Learning to crawl",
    "doi": "https://doi.org/10.1145/1095872.1095875",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Gautam Pant; Padmini Srinivasan",
    "corresponding_authors": "",
    "abstract": "Topical crawling is a young and creative area of research that holds the promise of benefiting from several sophisticated data mining techniques. The use of classification algorithms to guide topical crawlers has been sporadically suggested in the literature. No systematic study, however, has been done on their relative merits. Using the lessons learned from our previous crawler evaluation studies, we experiment with multiple versions of different classification schemes. The crawling process is modeled as a parallel best-first search over a graph defined by the Web. The classifiers provide heuristics to the crawler thus biasing it towards certain portions of the Web graph. Our results show that Naive Bayes is a weak choice for guiding a topical crawler when compared with Support Vector Machine or Neural Network. Further, the weak performance of Naive Bayes can be partly explained by extreme skewness of posterior probabilities generated by it. We also observe that despite similar performances, different topical crawlers cover subspaces on the Web with low overlap.",
    "cited_by_count": 147,
    "openalex_id": "https://openalex.org/W2017224880",
    "type": "article"
  },
  {
    "title": "Query enrichment for web-query classification",
    "doi": "https://doi.org/10.1145/1165774.1165776",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Dou Shen; Rong Pan; Jian-Tao Sun; Jeffrey Junfeng Pan; Kangheng Wu; Jie Yin; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "Web-search queries are typically short and ambiguous. To classify these queries into certain target categories is a difficult but important problem. In this article, we present a new technique called query enrichment, which takes a short query and maps it to intermediate objects. Based on the collected intermediate objects, the query is then mapped to target categories. To build the necessary mapping functions, we use an ensemble of search engines to produce an enrichment of the queries. Our technique was applied to the ACM Knowledge Discovery and Data Mining competition (ACM KDDCUP) in 2005, where we won the championship on all three evaluation metrics (precision, F1 measure, which combines precision and recall, and creativity, which is judged by the organizers) among a total of 33 teams worldwide. In this article, we show that, despite the difficulty of an abundance of ambiguous queries and lack of training data, our query-enrichment technique can solve the problem satisfactorily through a two-phase classification framework. We present a detailed description of our algorithm and experimental evaluation. Our best result for F1 and precision is 42.4% and 44.4%, respectively, which is 9.6% and 24.3% higher than those from the runner-ups, respectively.",
    "cited_by_count": 145,
    "openalex_id": "https://openalex.org/W2162993204",
    "type": "article"
  },
  {
    "title": "Efficient web browsing on handheld devices using page and form summarization",
    "doi": "https://doi.org/10.1145/503104.503109",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Orkut Buyukkokten; Oliver Kaljuvee; Héctor García-Molina; Andreas Paepcke; Terry Winograd",
    "corresponding_authors": "",
    "abstract": "We present a design and implementation for displaying and manipulating HTML pages on small handheld devices such as personal digital assistants (PDAs), or cellular phones. We introduce methods for summarizing parts of Web pages and HTML forms. Each Web page is broken into text units that can each be hidden, partially displayed, made fully visible, or summarized. A variety of methods are introduced that summarize the text units. In addition, HTML forms are also summarized by displaying just the text labels that prompt the use for input. We tested the relative performance of the summarization methods by asking human subjects to accomplish single-page information search tasks. We found that the combination of keywords and single-sentence summaries provides significant improvements in access times and number of required pen actions, as compared to other schemes. Our experiments also show that our algorithms can identify the appropriate labels for forms in 95% of the cases, allowing effective form support for small screens.",
    "cited_by_count": 143,
    "openalex_id": "https://openalex.org/W2076832658",
    "type": "article"
  },
  {
    "title": "DAIDA",
    "doi": "https://doi.org/10.1145/128756.128757",
    "publication_date": "1992-01-02",
    "publication_year": 1992,
    "authors": "Matthias Jarke; John Mylopoulos; Joachim W. Schmidt; Yannis Vassiliou",
    "corresponding_authors": "",
    "abstract": "We present a framework for the development of information systems based on the premise that the knowledge that influences the development process needs to somehow be captured, represented, and managed if the development process is to be rationalized. Experiences with a prototype environment developed in ESPRIT project DAIDA demonstrate the approach. The project has implemented an environment based on state-of-the-art languages for requirements modeling, design and implementation of information systems. In addition, the environment offers tools for aiding the mapping process from requirements to design and then to implementation, also for representing decisions reached during the development process. The development process itself is represented explicitly within the system, thus making the DAIDA development framework easier to comprehend, use, and modify.",
    "cited_by_count": 143,
    "openalex_id": "https://openalex.org/W2120613146",
    "type": "article"
  },
  {
    "title": "A semisupervised learning method to merge search engine results",
    "doi": "https://doi.org/10.1145/944012.944017",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Luo Si; Jamie Callan",
    "corresponding_authors": "",
    "abstract": "The proliferation of searchable text databases on local area networks and the Internet causes the problem of finding information that may be distributed among many disjoint text databases ( distributed information retrieval ). How to merge the results returned by selected databases is an important subproblem of the distributed information retrieval task. Previous research assumed that either resource providers cooperate to provide normalizing statistics or search clients download all retrieved documents and compute normalized scores without cooperation from resource providers.This article presents a semisupervised learning solution to the result merging problem. The key contribution is the observation that information used to create resource descriptions for resource selection can also be used to create a centralized sample database to guide the normalization of document scores returned by different databases. At retrieval time, the query is sent to the selected databases, which return database-specific document scores, and to a centralized sample database , which returns database-independent document scores. Documents that have both a database-specific score and a database-independent score serve as training data for learning to normalize the scores of other documents. An extensive set of experiments demonstrates that this method is more effective than the well-known CORI result-merging algorithm under a variety of conditions.",
    "cited_by_count": 142,
    "openalex_id": "https://openalex.org/W2118295805",
    "type": "article"
  },
  {
    "title": "Proximal nodes",
    "doi": "https://doi.org/10.1145/263479.263482",
    "publication_date": "1997-10-01",
    "publication_year": 1997,
    "authors": "Gonzalo Navarro; Ricardo Baeza‐Yates",
    "corresponding_authors": "",
    "abstract": "A model to query document databases by both their content and structure is presented. The goal is to obtain a query language that is expressive in practice while being efficiently implementable, features not present at the same time in previous work. The key ideas of the model are a set-oriented query language based on operations on nearby structure elements of one or more hierarchies, together with content and structural indexing and bottom-up evaluation. The model is evaluated in regard to expressiveness and efficiency, showing that it provides a good trade-off between both goals. Finally, it is shown how to include in the model other media different from text.",
    "cited_by_count": 141,
    "openalex_id": "https://openalex.org/W2004925874",
    "type": "article"
  },
  {
    "title": "The spatial metaphor for user interfaces: experimental tests of reference by location versus name",
    "doi": "https://doi.org/10.1145/5401.5405",
    "publication_date": "1986-01-01",
    "publication_year": 1986,
    "authors": "William Jones; Susan Dumais",
    "corresponding_authors": "",
    "abstract": "The enduring dichotomy between spatial and symbolic modes of representation and retrieval acquires an added pragmatic dimension through recent developments in computer-based information retrieval. The standard name-based approach to object reference is now supplemented on some systems by a spatial alternative-often driven by an office or desktop metaphor. Little rigorous evidence is available, however, to support the supposition that spatial memory in itself is more effective than symbolic memory. The accuracy of spatial versus symbolic reference was assessed in three experiments. In Experiment 1 accuracy of location reference in a location-only filing condition was initially comparable to that in a name-only condition, but deteriorated much more rapidly with increases in the number of objects filed. In Experiment 2 subjects placed objects in a two-dimensional space containing landmarks (drawings of a desk, table, filing cabinets, etc.) designed to evoke an office metaphor, and in Experiment 3 subjects placed objects in an actual, three-dimensional mock office. Neither of these enhancements served to improve significantly the accuracy of location reference, and performance remained below that of a name-only condition in Experiment 1. The results raise questions about the utility of spatial metaphor over symbolic filing and highlight the need for continuing research in which considerations of technological and economic feasibility are balanced by considerations of psychological utility.",
    "cited_by_count": 140,
    "openalex_id": "https://openalex.org/W1974170312",
    "type": "article"
  },
  {
    "title": "Information retrieval using a hypertext-based help system",
    "doi": "https://doi.org/10.1145/65943.65948",
    "publication_date": "1989-07-01",
    "publication_year": 1989,
    "authors": "F. R. Campagnoni; Kate Ehrlich",
    "corresponding_authors": "",
    "abstract": "Hypertext offers users a simple, flexible way to navigate through electronic information systems but at the potential risk of becoming lost in the network of interconnected pieces of information. A study was conducted on information retrieval using a commercial hypertext-based help system. It was found that the predominant search strategy was “browsing” (characterized by scanning tables of contents and paging through topics), rather than employing the indexes (\"analytical search\"). Although subjects did not get lost, individuals with better spatial visualization skills, as measured by a standardized test, were faster at retrieving information and returned to the top of the information hierarchy less often than those with poorer spatial visualization skills. These results support previous studies that have found a strong preference by users for browsing in hypertext systems and extend those findings to a new domain (help), a different type of user interface, and a different information architecture. In addition, the results demonstrate the importance of spatial visualization ability for efficient navigation and information retrieval in a hierarchical hypertext system.",
    "cited_by_count": 140,
    "openalex_id": "https://openalex.org/W2091316907",
    "type": "article"
  },
  {
    "title": "Optimum polynomial retrieval functions based on the probability ranking principle",
    "doi": "https://doi.org/10.1145/65943.65944",
    "publication_date": "1989-07-01",
    "publication_year": 1989,
    "authors": "Norbert Fuhr",
    "corresponding_authors": "Norbert Fuhr",
    "abstract": "We show that any approach to developing optimum retrieval functions is based on two kinds of assumptions: first, a certain form of representation for documents and requests, and second, additional simplifying assumptions that predefine the type of the retrieval function. Then we describe an approach for the development of optimum polynomial retrieval functions: request-document pairs ( f l , d m ) are mapped onto description vectors x ( f l , d m ), and a polynomial function e ( x ) is developed such that it yields estimates of the probability of relevance P( R | x ( f l , d m ) with minimum square errors. We give experimental results for the application of this approach to documents with weighted indexing as well as to documents with complex representations. In contrast to other probabilistic models, our approach yields estimates of the actual probabilities, it can handle very complex representations of documents and requests, and it can be easily applied to multivalued relevance scales. On the other hand, this approach is not suited to log-linear probabilistic models and it needs large samples of relevance feedback data for its application.",
    "cited_by_count": 138,
    "openalex_id": "https://openalex.org/W2012318340",
    "type": "article"
  },
  {
    "title": "Virtual reality for palmtop computers",
    "doi": "https://doi.org/10.1145/159161.159160",
    "publication_date": "1993-07-01",
    "publication_year": 1993,
    "authors": "George Fitzmaurice; Shumin Zhai; Mark Chignell",
    "corresponding_authors": "Mark Chignell",
    "abstract": "article Free Access Share on Virtual reality for palmtop computers Authors: George W. Fitzmaurice View Profile , Shumin Zhai View Profile , Mark H. Chignell View Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 11Issue 3July 1993 pp 197–218https://doi.org/10.1145/159161.159160Published:01 July 1993Publication History 100citation1,643DownloadsMetricsTotal Citations100Total Downloads1,643Last 12 Months79Last 6 weeks15 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 137,
    "openalex_id": "https://openalex.org/W2130351016",
    "type": "article"
  },
  {
    "title": "Queries and query processing in object-oriented database systems",
    "doi": "https://doi.org/10.1145/102675.102678",
    "publication_date": "1990-10-01",
    "publication_year": 1990,
    "authors": "David D. Straube; M. TAMER ÖZSU",
    "corresponding_authors": "",
    "abstract": "Object-oriented database mangement systems (OODBMS) combine the data abstraction and computational models of object-oriented programming languages with the query and performance capabilities of database management systems. A concise, formal data model for OODBMS has not been universally accepted, preventing detailed investigation of various system issues such as query processing. We define a data model that captures the essence of classification-based object-oriented systems and formalize concepts such as object identity, inheritence, and methods. The main topic of the paper is the presentation of a query processing methodology complete with an object calculus to object algebra translation are discussed in detail. The paper concludes with a discussion of equivalence-preserving transformation rules for object algebra expressions.",
    "cited_by_count": 136,
    "openalex_id": "https://openalex.org/W1985464228",
    "type": "article"
  },
  {
    "title": "QProber",
    "doi": "https://doi.org/10.1145/635484.635485",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Luis Gravano; Panagiotis G. Ipeirotis; Mehran Sahami",
    "corresponding_authors": "",
    "abstract": "The contents of many valuable Web-accessible databases are only available through search interfaces and are hence invisible to traditional Web \"crawlers.\" Recently, commercial Web sites have started to manually organize Web-accessible databases into Yahoo!-like hierarchical classification schemes. Here we introduce QProber, a modular system that automates this classification process by using a small number of query probes, generated by document classifiers. QProber can use a variety of types of classifiers to generate the probes. To classify a database, QProber does not retrieve or inspect any documents or pages from the database, but rather just exploits the number of matches that each query probe generates at the database in question. We have conducted an extensive experimental evaluation of QProber over collections of real documents, experimenting with different types of document classifiers and retrieval models. We have also tested our system with over one hundred Web-accessible databases. Our experiments show that our system has low overhead and achieves high classification accuracy across a variety of databases.",
    "cited_by_count": 136,
    "openalex_id": "https://openalex.org/W2116341550",
    "type": "article"
  },
  {
    "title": "Evolution of web site design patterns",
    "doi": "https://doi.org/10.1145/1095872.1095876",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Melody Y. Ivory; Rodrick Megraw",
    "corresponding_authors": "",
    "abstract": "The Web enables broad dissemination of information and services; however, the ways in which sites are designed can either facilitate or impede users' benefit from these resources. We present a longitudinal study of web site design from 2000 to 2003. We analyze over 150 quantitative measures of interface aspects (e.g., amount of text on pages, numbers and types of links, consistency, accessibility, etc.) for 22,000 pages and over 1,500 sites that received ratings from Internet professionals. We examine characteristics of highly rated sites and provide three perspectives on the evolution of web site design patterns: (1) descriptions of design patterns during each time period; (2) changes in design patterns across the three time periods; and (3) comparisons of design patterns to those that are recommended in the relevant literature (i.e., texts by recognized experts and user studies). We illustrate how design practices conform to or deviate from recommended practices and the consequent implications. We show that the most glaring deficiency of web sites, even for sites that are highly rated, is their inadequate accessibility, in particular for browser scripts, tables, and form elements.",
    "cited_by_count": 135,
    "openalex_id": "https://openalex.org/W1985995642",
    "type": "article"
  },
  {
    "title": "Genre taxonomy",
    "doi": "https://doi.org/10.1145/502795.502798",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Takeshi. Yoshioka; George Herman; JoAnne Yates; Wanda J. Orlikowski",
    "corresponding_authors": "",
    "abstract": "We propose a genre taxonomy as a knowledge repository of communicative structures or \"typified actions\" enacted by organizational members. The genre taxonomy is intended to help people make sense of diverse types of communicative actions and provide ideas for improving work processes that coordinate the communication of information. It engages several features to achieve this objective. First, the genre taxonomy represents the elements of both genres and genre systems as embedded in a social context reflecting the communicative questions why, what, who, when, where, and how (5W1H). In other words, the genre taxonomy represents the purpose, content, participants, timing, location, and form of communicative action. Second, the genre taxonomy distinguishes between widely recognized genres such as a report and specific genres such as a particular company's technical report, because the difference sheds light on the context of genre use. Third, the genre taxonomy represents use and evolution of a genre over time to help people understand how a genre is used and changed by a community over time. Fourth, the genre taxonomy represents aspects of information coordination via genres, thus providing ideas for improving work processes using genres. We have constructed a prototype of such a genre taxonomy using the Process Handbook, a process knowledge repository developed at MIT. We have included both widely recognized genres such as the memo and specific genres such as those used in the Process Handbook itself. We suggest that this genre taxonomy may be useful in the innovation of new document templates or methods for communication because it helps to clarify different possible uses of similar genres and explicates how genres play a coordination role among people and between people and their tasks.",
    "cited_by_count": 134,
    "openalex_id": "https://openalex.org/W2016278946",
    "type": "article"
  },
  {
    "title": "Access to, usage of, and outcomes from an electronic messaging system",
    "doi": "https://doi.org/10.1145/45945.214325",
    "publication_date": "1988-07-01",
    "publication_year": 1988,
    "authors": "Ronald E. Rice; Douglas E. Shook",
    "corresponding_authors": "",
    "abstract": "This study examines relationships among perceived accessibility to an electronic messaging system (EMS), computer-monitored and reported usage of the system by approximately 100 employees of one division of an aerospace firm, user's job type, perceived appropriateness of the EMS, and reported outcomes such as changes in effectiveness and use of paper-based media. Greater accessibility resulted in more usage and reported increases in effectiveness. Physical distance to a terminal affects the associations of other aspects of accessibility with usage and has a greater influence on these associations earlier in one's adoption process. Differences in job type showed statistically significant associations with usage, independent of the influence of accessibility. Computer-monitored and reported usage measures were only moderately correlated and were differentially associated with the access measures and with the two outcomes. The article ends by discussing implications for implementation and evaluation of computer-based communication systems, theories of media characteristics and information value, and methodological issues in using computer-monitored usage data.",
    "cited_by_count": 132,
    "openalex_id": "https://openalex.org/W1999484385",
    "type": "article"
  },
  {
    "title": "Strategies for encouraging successful adoption of office communication systems",
    "doi": "https://doi.org/10.1145/42196.42198",
    "publication_date": "1987-10-01",
    "publication_year": 1987,
    "authors": "Susan F. Ehrlich",
    "corresponding_authors": "Susan F. Ehrlich",
    "abstract": "The adoption of new computer communication systems into organizations requires behavioral change. Planning for successful adoption requires knowledge of individual organizational communication patterns and the relationship between those patterns and particular communication system solutions. This paper documents a sequence of studies of organizational communication. Needs for office communication systems were identified, as were social and psychological factors temporarily inhibiting their use. Strategies for assuring smooth adoption of such systems are highlighted.",
    "cited_by_count": 131,
    "openalex_id": "https://openalex.org/W1972753943",
    "type": "article"
  },
  {
    "title": "A text compression scheme that allows fast searching directly in the compressed file",
    "doi": "https://doi.org/10.1145/248625.248639",
    "publication_date": "1997-04-01",
    "publication_year": 1997,
    "authors": "Udi Manber",
    "corresponding_authors": "Udi Manber",
    "abstract": "A new text compression scheme is presented in this article. The main purpose of this scheme is to speed up string matching by searching the compressed file directly. The scheme requires no modification of the string-matching algorithm, which is used as a black box; any string-matching procedure can be used. Instead, the pattern is modified; only the outcome of the matching of the modified pattern against the compressed file is decompressed. Since the compressed file is smaller than the original file, the search is faster both in terms of I/O time and precessing time than a search in the original file. For typical text files, we achieve about 30% reduction of space and slightly less of search time. A 30% space saving is not competitive with good text compression schemes, and thus should not be used where space is the predominant concern. The intended applications of this scheme are files that are searched often, such as catalogs, bibliographic files, and address books. Such files are typically not compressed, but with this scheme they can remain compressed indefinitely, saving space while allowing faster search at the same time. A particular application to an information retrieval system that we developed is also discussed.",
    "cited_by_count": 131,
    "openalex_id": "https://openalex.org/W2062657631",
    "type": "article"
  },
  {
    "title": "Contexts—a partitioning concept for hypertext",
    "doi": "https://doi.org/10.1145/27636.27639",
    "publication_date": "1987-04-01",
    "publication_year": 1987,
    "authors": "Norman Delisle; Mayer D. Schwartz",
    "corresponding_authors": "",
    "abstract": "Hypertext systems provide good information management support for a wide variety of documentation efforts. These efforts range from developing software to writing a book. However, existing hypertext systems provide poor support for collaboration among teams of authors. This paper starts by briefly describing properties of several existing hypertext systems. Then several models for forming partitions in a hypertext database are examined and contexts, a partitioning scheme that supports multiperson cooperative efforts, are introduced. The semantic issues involved in defining contexts are explored in detail.",
    "cited_by_count": 131,
    "openalex_id": "https://openalex.org/W2116291147",
    "type": "article"
  },
  {
    "title": "Diplans: a new language for the study and implementation of coordination",
    "doi": "https://doi.org/10.1145/45941.45942",
    "publication_date": "1988-04-01",
    "publication_year": 1988,
    "authors": "Anatol W. Holt",
    "corresponding_authors": "Anatol W. Holt",
    "abstract": "In this paper the reader is introduced to coordination in the workplace as an object of scientific study and computer automation. Diplans are the expressions of a new graphical language used to describe plans of operation in human organizations. With diplans, systems of constraint, which may or may not take the form of procedure definitions, can be specified. Among the special strengths of diplans is their ability to render explicit the interactive aspects of complex work distributed over many people and places—in other words, coordination. Diplans are central to coordination technology, a new approach to developing support for cooperative work on heterogeneous computer networks.",
    "cited_by_count": 130,
    "openalex_id": "https://openalex.org/W2070913565",
    "type": "article"
  },
  {
    "title": "A high-level and flexible framework for implementing multiuser user interfaces",
    "doi": "https://doi.org/10.1145/146486.146495",
    "publication_date": "1992-10-01",
    "publication_year": 1992,
    "authors": "Prasun Dewan; Rajiv Choudhary",
    "corresponding_authors": "",
    "abstract": "We have developed a high-level and flexible framework for supporting the construction of multiuser interfaces. The framework is based on a generalized editing interaction model, which allows users to view programs as active data that can be concurrently edited by multiple users. It consists of several novel components including a refinement of both the Seeheim UIMS architecture and the distributed graphics architecture that explicitly addresses multiuser interaction; the abstractions of shared active variables and interaction variables, which allow users and applications to exchange information; a set of default collaboration rules designed to keep the collaboration-awareness low in multiuser programs; and a small but powerful set of primitives for overriding these rules. The framework allows users to be dynamically added and removed from a multiuser sesssion, different users to use different user interfaces to interact with an application, the modules interacting with a particular user to execute on the local workstation, and programmers to incrementally trade automation for flexibility. We have implemented the framework as part of a system called Suite . This paper motivates, describes, and illustrates the framework using the concrete example of Suite, discusses how it can be implemented in other kinds of systems, compares it with related work, discusses its shortcomings, and suggests directions for future work.",
    "cited_by_count": 129,
    "openalex_id": "https://openalex.org/W2085331906",
    "type": "article"
  },
  {
    "title": "Object specialization",
    "doi": "https://doi.org/10.1145/65935.65936",
    "publication_date": "1989-04-01",
    "publication_year": 1989,
    "authors": "Edward Sciore",
    "corresponding_authors": "Edward Sciore",
    "abstract": "Specialization hierarchies typically are treated as type-level constructs and are used to define various inheritance mechanisms. In this paper we consider specialization at the level of objects. We show that doing so creates a more flexible and powerful notion of inheritance by allowing objects to define their own inheritance path. Object specialization can also be used to model certain forms of versioning, implement data abstraction, and provide a “classless” prototype-based language interface to the user.",
    "cited_by_count": 129,
    "openalex_id": "https://openalex.org/W2294346714",
    "type": "article"
  },
  {
    "title": "Experiments with Oval",
    "doi": "https://doi.org/10.1145/201040.201047",
    "publication_date": "1995-04-01",
    "publication_year": 1995,
    "authors": "Thomas W. Malone; Kum‐Yew Lai; Christopher Fry",
    "corresponding_authors": "",
    "abstract": "This article describes a series of tests of the generality of a “radically tailorable” tool for cooperative work. Users of this system can create applications by combining and modifying four kinds of building blocks: objects, views, agents, and links . We found that user-level tailoring of these primitives can provide most of the functionality found in well-known cooperative work systems such as gIBIS, Coordinator, Lotus Notes, and Information Lens. These primitives, therefore, appear to provide an elementary “tailoring language” out of which a wide variety of integrated information management and collaboration applications can be constructed by end users.",
    "cited_by_count": 128,
    "openalex_id": "https://openalex.org/W1966229703",
    "type": "article"
  },
  {
    "title": "A formal model of annotations of digital content",
    "doi": "https://doi.org/10.1145/1292591.1292594",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Maristella Agosti; Nicola Ferro",
    "corresponding_authors": "",
    "abstract": "This article is a study of the themes and issues concerning the annotation of digital contents, such as textual documents, images, and multimedia documents in general. These digital contents are automatically managed by different kinds of digital library management systems and more generally by different kinds of information management systems. Even though this topic has already been partially studied by other researchers, the previous research work on annotations has left many open issues. These issues concern the lack of clarity about what an annotation is, what its features are, and how it is used. These issues are mainly due to the fact that models and systems for annotations have only been developed for specific purposes. As a result, there is only a fragmentary picture of the annotation and its management, and this is tied to specific contexts of use and lacks-general validity. The aim of the article is to provide a unified and integrated picture of the annotation, ranging from defining what an annotation is to providing a formal model. The key ideas of the model are: the distinction between the meaning and the sign of the annotation, which represent the semantics and the materialization of an annotation, respectively; the clear formalization of the temporal dimension involved with annotations; and the introduction of a distributed hypertext between digital contents and annotations. Therefore, the proposed formal model captures both syntactic and semantic aspects of the annotations. Furthermore, it is built on previously existing models and may be seen as an extension of them.",
    "cited_by_count": 128,
    "openalex_id": "https://openalex.org/W2014949296",
    "type": "article"
  },
  {
    "title": "Motion recovery for video content classification",
    "doi": "https://doi.org/10.1145/211430.211433",
    "publication_date": "1995-10-01",
    "publication_year": 1995,
    "authors": "Nevenka Dimitrova; Forouzan Golshani",
    "corresponding_authors": "",
    "abstract": "Like other types of digital information, video sequences must be classified based on the semantics of their contents. A more-precise and completer extraction of semantic information will result in a more-effective classification. The most-discernible difference between still images and moving pictures stems from movements and variations. Thus, to go from the realm of still-image repositories to video databases, we must be able to deal with motion. Particularly, we need the ability to classify objects appearing in a video sequence based on their characteristics and features such as shape or color, as well as their movements. By describing the movements that we derive from the process of motion analysis, we introduce a dual hierarchy consisting of spatial and temporal parts for video sequence representation. This gives us the flexibility to examine arbitrary sequences of frames at various levels of abstraction and to retrieve the associated temporal information (say, object trajectories) in addition to the spatial representation. Our algorithm for motion detection uses the motion compensation component of the MPEG video-encoding scheme and then computes trajectories for objects of interest. The specification of a language for retrieval of video based on the spatial as well as motion characteristics is presented.",
    "cited_by_count": 128,
    "openalex_id": "https://openalex.org/W2071959927",
    "type": "article"
  },
  {
    "title": "Evaluating implicit feedback models using searcher simulations",
    "doi": "https://doi.org/10.1145/1080343.1080347",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Ryen W. White; Ian Ruthven; Joemon M. Jose; C. J. van Rijsbergen",
    "corresponding_authors": "",
    "abstract": "In this article we describe an evaluation of relevance feedback (RF) algorithms using searcher simulations. Since these algorithms select additional terms for query modification based on inferences made from searcher interaction, not on relevance information searchers explicitly provide (as in traditional RF), we refer to them as implicit feedback models . We introduce six different models that base their decisions on the interactions of searchers and use different approaches to rank query modification terms. The aim of this article is to determine which of these models should be used to assist searchers in the systems we develop. To evaluate these models we used searcher simulations that afforded us more control over the experimental conditions than experiments with human subjects and allowed complex interaction to be modeled without the need for costly human experimentation. The simulation-based evaluation methodology measures how well the models learn the distribution of terms across relevant documents (i.e., learn what information is relevant) and how well they improve search effectiveness (i.e., create effective search queries). Our findings show that an implicit feedback model based on Jeffrey's rule of conditioning outperformed other models under investigation.",
    "cited_by_count": 127,
    "openalex_id": "https://openalex.org/W2071156242",
    "type": "article"
  },
  {
    "title": "Probabilistic static pruning of inverted files",
    "doi": "https://doi.org/10.1145/1658377.1658378",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "Roi Blanco; Álvaro Barreiro",
    "corresponding_authors": "",
    "abstract": "Information retrieval (IR) systems typically compress their indexes in order to increase their efficiency. Static pruning is a form of lossy data compression: it removes from the index, data that is estimated to be the least important to retrieval performance, according to some criterion. Generally, pruning criteria are derived from term weighting functions, which assign weights to terms according to their contribution to a document's contents. Usually, document-term occurrences that are assigned a low weight are ruled out from the index. The main assumption is that those entries contribute little to the document content. We present a novel pruning technique that is based on a probabilistic model of IR. We employ the Probability Ranking Principle as a decision criterion over which posting list entries are to be pruned. The proposed approach requires the estimation of three probabilities, combining them in such a way that we gather all the necessary information to apply the aforementioned criterion. We evaluate our proposed pruning technique on five TREC collections and various retrieval tasks, and show that in almost every situation it outperforms the state of the art in index pruning. The main contribution of this work is proposing a pruning technique that stems directly from the same source as probabilistic retrieval models, and hence is independent of the final model used for retrieval.",
    "cited_by_count": 122,
    "openalex_id": "https://openalex.org/W2078251464",
    "type": "article"
  },
  {
    "title": "Information scraps",
    "doi": "https://doi.org/10.1145/1402256.1402263",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Michael S. Bernstein; Max Van Kleek; David R. Karger; m.c. schraefel",
    "corresponding_authors": "",
    "abstract": "In this article we investigate information scraps —personal information where content has been scribbled on Post-it notes, scrawled on the corners of sheets of paper, stuck in our pockets, sent in email messages to ourselves, and stashed in miscellaneous digital text files. Information scraps encode information ranging from ideas and sketches to notes, reminders, shipment tracking numbers, driving directions, and even poetry. Although information scraps are ubiquitous, we have much still to learn about these loose forms of information practice. Why do we keep information scraps outside of our traditional PIM applications? What role do information scraps play in our overall information practice? How might PIM applications be better designed to accommodate and support information scraps' creation, manipulation and retrieval? We pursued these questions by studying the information scrap practices of 27 knowledge workers at five organizations. Our observations shed light on information scraps' content, form, media, and location. From this data, we elaborate on the typical information scrap lifecycle, and identify common roles that information scraps play: temporary storage, archiving, work-in-progress, reminding, and management of unusual data. These roles suggest a set of unmet design needs in current PIM tools: lightweight entry, unconstrained content, flexible use and adaptability, visibility, and mobility.",
    "cited_by_count": 121,
    "openalex_id": "https://openalex.org/W2076928167",
    "type": "article"
  },
  {
    "title": "A basis for information retrieval in context",
    "doi": "https://doi.org/10.1145/1361684.1361687",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Massimo Melucci",
    "corresponding_authors": "Massimo Melucci",
    "abstract": "Information retrieval (IR) models based on vector spaces have been investigated for a long time. Nevertheless, they have recently attracted much research interest. In parallel, context has been rediscovered as a crucial issue in information retrieval. This article presents a principled approach to modeling context and its role in ranking information objects using vector spaces. First, the article outlines how a basis of a vector space naturally represents context, both its properties and factors. Second, a ranking function computes the probability of context in the objects represented in a vector space, namely, the probability that a contextual factor has affected the preparation of an object.",
    "cited_by_count": 119,
    "openalex_id": "https://openalex.org/W2015419638",
    "type": "article"
  },
  {
    "title": "Online supervised spam filter evaluation",
    "doi": "https://doi.org/10.1145/1247715.1247717",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Gordon V. Cormack; Thomas R. Lynam",
    "corresponding_authors": "",
    "abstract": "Eleven variants of six widely used open-source spam filters are tested on a chronological sequence of 49086 e-mail messages received by an individual from August 2003 through March 2004. Our approach differs from those previously reported in that the test set is large, comprises uncensored raw messages, and is presented to each filter sequentially with incremental feedback. Misclassification rates and Receiver Operating Characteristic Curve measurements are reported, with statistical confidence intervals. Quantitative results indicate that content-based filters can eliminate 98% of spam while incurring 0.1% legitimate email loss. Qualitative results indicate that the risk of loss depends on the nature of the message, and that messages likely to be lost may be those that are less critical. More generally, our methodology has been encapsulated in a free software toolkit, which may used to conduct similar experiments.",
    "cited_by_count": 117,
    "openalex_id": "https://openalex.org/W2058737869",
    "type": "article"
  },
  {
    "title": "Description and performance analysis of signature file methods for office filing",
    "doi": "https://doi.org/10.1145/27641.28057",
    "publication_date": "1987-07-01",
    "publication_year": 1987,
    "authors": "Christos Faloutsos; Stavros Christodoulakis",
    "corresponding_authors": "",
    "abstract": "Signature files have attracted a lot of interest as an access method for text and specifically for messages in the office environment. Messages are stored sequentially in the message file, whereas their hash-coded abstractions (signatures) are stored sequentially in the signature file. To answer a query, the signature file is examined first, and many nonqualifying messages are immediately rejected. In this paper we examine the problem of designing signature extraction methods and studying their performance. We describe two old methods, generalize another one, and propose a new method and its variation. We provide exact and approximate formulas for the dependency between the false drop probability and the signature size for all the methods, and we show that the proposed method (VBC) achieves approximately ten times smaller false drop probability than the old methods, whereas it is well suited for collections of documents with variable document sizes.",
    "cited_by_count": 113,
    "openalex_id": "https://openalex.org/W2065694966",
    "type": "article"
  },
  {
    "title": "Contextual Video Recommendation by Multimodal Relevance and User Feedback",
    "doi": "https://doi.org/10.1145/1961209.1961213",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Tao Mei; Bo Yang; Xian‐Sheng Hua; Shipeng Li",
    "corresponding_authors": "",
    "abstract": "With Internet delivery of video content surging to an unprecedented level, video recommendation, which suggests relevant videos to targeted users according to their historical and current viewings or preferences, has become one of most pervasive online video services. This article presents a novel contextual video recommendation system, called VideoReach, based on multimodal content relevance and user feedback. We consider an online video usually consists of different modalities (i.e., visual and audio track, as well as associated texts such as query, keywords, and surrounding text). Therefore, the recommended videos should be relevant to current viewing in terms of multimodal relevance. We also consider that different parts of videos are with different degrees of interest to a user, as well as different features and modalities have different contributions to the overall relevance. As a result, the recommended videos should also be relevant to current users in terms of user feedback (i.e., user click-through). We then design a unified framework for VideoReach which can seamlessly integrate both multimodal relevance and user feedback by relevance feedback and attention fusion. VideoReach represents one of the first attempts toward contextual recommendation driven by video content and user click-through, without assuming a sufficient collection of user profiles available. We conducted experiments over a large-scale real-world video data and reported the effectiveness of VideoReach.",
    "cited_by_count": 109,
    "openalex_id": "https://openalex.org/W2137183034",
    "type": "article"
  },
  {
    "title": "Document processing in a relational database system",
    "doi": "https://doi.org/10.1145/357431.357433",
    "publication_date": "1983-04-01",
    "publication_year": 1983,
    "authors": "Michael Stonebraker; Heidi Stettner; Nadene Lynn; Joseph Kalash; Antonin Guttman",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Document processing in a relational database system Authors: Michael Stonebraker Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA Department of Electrical Engineering and Computer Science, University of California, Berkeley, CAView Profile , Heidi Stettner Lucas Films, Ltd., P.O. Box 2009, San Rafael, CA Lucas Films, Ltd., P.O. Box 2009, San Rafael, CAView Profile , Nadene Lynn Relational Technology, Inc., 2855 Telegraph Ave., Berkeley, CA Relational Technology, Inc., 2855 Telegraph Ave., Berkeley, CAView Profile , Joseph Kalash Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA Department of Electrical Engineering and Computer Science, University of California, Berkeley, CAView Profile , Antonin Guttman Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA Department of Electrical Engineering and Computer Science, University of California, Berkeley, CAView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 2April 1983 pp 143–158https://doi.org/10.1145/357431.357433Published:01 April 1983Publication History 87citation759DownloadsMetricsTotal Citations87Total Downloads759Last 12 Months63Last 6 weeks6 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 108,
    "openalex_id": "https://openalex.org/W1969316187",
    "type": "article"
  },
  {
    "title": "Automatic classification of Web queries using very large unlabeled query logs",
    "doi": "https://doi.org/10.1145/1229179.1229183",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Steven M. Beitzel; Eric C. Jensen; David D. Lewis; Abdur Chowdhury; Ophir Frieder",
    "corresponding_authors": "",
    "abstract": "Accurate topical classification of user queries allows for increased effectiveness and efficiency in general-purpose Web search systems. Such classification becomes critical if the system must route queries to a subset of topic-specific and resource-constrained back-end databases. Successful query classification poses a challenging problem, as Web queries are short, thus providing few features. This feature sparseness, coupled with the constantly changing distribution and vocabulary of queries, hinders traditional text classification. We attack this problem by combining multiple classifiers, including exact lookup and partial matching in databases of manually classified frequent queries, linear models trained by supervised learning, and a novel approach based on mining selectional preferences from a large unlabeled query log. Our approach classifies queries without using external sources of information, such as online Web directories or the contents of retrieved pages, making it viable for use in demanding operational environments, such as large-scale Web search services. We evaluate our approach using a large sample of queries from an operational Web search engine and show that our combined method increases recall by nearly 40% over the best single method while maintaining adequate precision. Additionally, we compare our results to those from the 2005 KDD Cup and find that we perform competitively despite our operational restrictions. This suggests it is possible to topically classify a significant portion of the query stream without requiring external sources of information, allowing for deployment in operationally restricted environments.",
    "cited_by_count": 108,
    "openalex_id": "https://openalex.org/W1995262888",
    "type": "article"
  },
  {
    "title": "The design requirements of office systems",
    "doi": "https://doi.org/10.1145/521.357416",
    "publication_date": "1984-05-24",
    "publication_year": 1984,
    "authors": "Giampio Bracchi; Barbara Pernici",
    "corresponding_authors": "",
    "abstract": "article Free AccessThe design requirements of office systems Authors: Giampio Bracchi Dipartimento di Elettronica, Politecnico di Milano, Piazza Leonardo da Vinci, 32, 20133 Milan, Italy Dipartimento di Elettronica, Politecnico di Milano, Piazza Leonardo da Vinci, 32, 20133 Milan, ItalyView Profile , Barbara Pernici Dipartimento di Elettronica, Politecnico di Milano, Piazza Leonardo da Vinci, 32, 20133 Milan, Italy Dipartimento di Elettronica, Politecnico di Milano, Piazza Leonardo da Vinci, 32, 20133 Milan, ItalyView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 2April 1984 pp 151–170https://doi.org/10.1145/521.357416Published:24 May 1984Publication History 75citation959DownloadsMetricsTotal Citations75Total Downloads959Last 12 Months72Last 6 weeks30 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 103,
    "openalex_id": "https://openalex.org/W2041592704",
    "type": "article"
  },
  {
    "title": "PageRank",
    "doi": "https://doi.org/10.1145/1629096.1629097",
    "publication_date": "2009-11-01",
    "publication_year": 2009,
    "authors": "Paolo Boldi; Massimo Santini; Sebastiano Vigna",
    "corresponding_authors": "",
    "abstract": "research-article Share on PageRank: Functional dependencies Authors: Paolo Boldi Università degli Studi di Milano, Milano, MI, Italy Università degli Studi di Milano, Milano, MI, ItalyView Profile , Massimo Santini Università degli Studi di Milano, Milano, MI, Italy Università degli Studi di Milano, Milano, MI, ItalyView Profile , Sebastiano Vigna Università degli Studi di Milano, Milano, MI, Italy Università degli Studi di Milano, Milano, MI, ItalyView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 27Issue 4Article No.: 19pp 1–23https://doi.org/10.1145/1629096.1629097Published:30 November 2009Publication History 71citation1,468DownloadsMetricsTotal Citations71Total Downloads1,468Last 12 Months42Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 101,
    "openalex_id": "https://openalex.org/W1965406039",
    "type": "article"
  },
  {
    "title": "Exploiting neighborhood knowledge for single document summarization and keyphrase extraction",
    "doi": "https://doi.org/10.1145/1740592.1740596",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Xiaojun Wan; Jianguo Xiao",
    "corresponding_authors": "",
    "abstract": "Document summarization and keyphrase extraction are two related tasks in the IR and NLP fields, and both of them aim at extracting condensed representations from a single text document. Existing methods for single document summarization and keyphrase extraction usually make use of only the information contained in the specified document. This article proposes using a small number of nearest neighbor documents to improve document summarization and keyphrase extraction for the specified document, under the assumption that the neighbor documents could provide additional knowledge and more clues. The specified document is expanded to a small document set by adding a few neighbor documents close to the document, and the graph-based ranking algorithm is then applied on the expanded document set to make use of both the local information in the specified document and the global information in the neighbor documents. Experimental results on the Document Understanding Conference (DUC) benchmark datasets demonstrate the effectiveness and robustness of our proposed approaches. The cross-document sentence relationships in the expanded document set are validated to be beneficial to single document summarization, and the word cooccurrence relationships in the neighbor documents are validated to be very helpful to single document keyphrase extraction.",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W2149795409",
    "type": "article"
  },
  {
    "title": "Enriching Documents with Examples",
    "doi": "https://doi.org/10.1145/2414782.2414783",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Jin-Han Kim; Sang-Hoon Lee; Seung-won Hwang; Sunghun Kim",
    "corresponding_authors": "",
    "abstract": "Software developers increasingly rely on information from the Web, such as documents or code examples on application programming interfaces (APIs), to facilitate their development processes. However, API documents often do not include enough information for developers to fully understand how to use the APIs, and searching for good code examples requires considerable effort. To address this problem, we propose a novel code example recommendation system that combines the strength of browsing documents and searching for code examples and returns API documents embedded with high-quality code example summaries mined from the Web. Our evaluation results show that our approach provides code examples with high precision and boosts programmer productivity.",
    "cited_by_count": 87,
    "openalex_id": "https://openalex.org/W2122156963",
    "type": "article"
  },
  {
    "title": "Stability of Recommendation Algorithms",
    "doi": "https://doi.org/10.1145/2382438.2382442",
    "publication_date": "2012-11-01",
    "publication_year": 2012,
    "authors": "Gediminas Adomavičius; Jingjing Zhang",
    "corresponding_authors": "",
    "abstract": "The article explores stability as a new measure of recommender systems performance. Stability is defined to measure the extent to which a recommendation algorithm provides predictions that are consistent with each other. Specifically, for a stable algorithm, adding some of the algorithm’s own predictions to the algorithm’s training data (for example, if these predictions were confirmed as accurate by users) would not invalidate or change the other predictions. While stability is an interesting theoretical property that can provide additional understanding about recommendation algorithms, we believe stability to be a desired practical property for recommender systems designers as well, because unstable recommendations can potentially decrease users’ trust in recommender systems and, as a result, reduce users’ acceptance of recommendations. In this article, we also provide an extensive empirical evaluation of stability for six popular recommendation algorithms on four real-world datasets. Our results suggest that stability performance of individual recommendation algorithms is consistent across a variety of datasets and settings. In particular, we find that model-based recommendation algorithms consistently demonstrate higher stability than neighborhood-based collaborative filtering techniques. In addition, we perform a comprehensive empirical analysis of many important factors (e.g., the sparsity of original rating data, normalization of input data, the number of new incoming ratings, the distribution of incoming ratings, the distribution of evaluation data, etc.) and report the impact they have on recommendation stability.",
    "cited_by_count": 84,
    "openalex_id": "https://openalex.org/W2144294167",
    "type": "article"
  },
  {
    "title": "Fast Ranking with Additive Ensembles of Oblivious and Non-Oblivious Regression Trees",
    "doi": "https://doi.org/10.1145/2987380",
    "publication_date": "2016-12-12",
    "publication_year": 2016,
    "authors": "Domenico Dato; Claudio Lucchese; Franco Maria Nardini; Salvatore Orlando; Raffaele Perego; Nicola Tonellotto; Rossano Venturini",
    "corresponding_authors": "",
    "abstract": "Learning-to-Rank models based on additive ensembles of regression trees have been proven to be very effective for scoring query results returned by large-scale Web search engines. Unfortunately, the computational cost of scoring thousands of candidate documents by traversing large ensembles of trees is high. Thus, several works have investigated solutions aimed at improving the efficiency of document scoring by exploiting advanced features of modern CPUs and memory hierarchies. In this article, we present Q uick S corer , a new algorithm that adopts a novel cache-efficient representation of a given tree ensemble, performs an interleaved traversal by means of fast bitwise operations, and supports ensembles of oblivious trees. An extensive and detailed test assessment is conducted on two standard Learning-to-Rank datasets and on a novel very large dataset we made publicly available for conducting significant efficiency tests. The experiments show unprecedented speedups over the best state-of-the-art baselines ranging from 1.9 × to 6.6 × . The analysis of low-level profiling traces shows that Q uick S corer efficiency is due to its cache-aware approach in terms of both data layout and access patterns and to a control flow that entails very low branch mis-prediction rates.",
    "cited_by_count": 84,
    "openalex_id": "https://openalex.org/W2566147423",
    "type": "article"
  },
  {
    "title": "A Time-Aware Personalized Point-of-Interest Recommendation via High-Order Tensor Factorization",
    "doi": "https://doi.org/10.1145/3057283",
    "publication_date": "2017-06-23",
    "publication_year": 2017,
    "authors": "Xin Li; Mingming Jiang; Huiting Hong; Lejian Liao",
    "corresponding_authors": "",
    "abstract": "Recently, location-based services (LBSs) have been increasingly popular for people to experience new possibilities, for example, personalized point-of-interest (POI) recommendations that leverage on the overlapping of user trajectories to recommend POI collaboratively. POI recommendation is yet challenging as it suffers from the problems known for the conventional recommendation tasks such as data sparsity and cold start, and to a much greater extent. In the literature, most of the related works apply collaborate filtering to POI recommendation while overlooking the personalized time-variant human behavioral tendency. In this article, we put forward a fourth-order tensor factorization-based ranking methodology to recommend users their interested locations by considering their time-varying behavioral trends while capturing their long-term preferences and short-term preferences simultaneously. We also propose to categorize the locations to alleviate data sparsity and cold-start issues, and accordingly new POIs that users have not visited can thus be bubbled up during the category ranking process. The tensor factorization is carefully studied to prune the irrelevant factors to the ranking results to achieve efficient POI recommendations. The experimental results validate the efficacy of our proposed mechanism, which outperforms the state-of-the-art approaches significantly.",
    "cited_by_count": 83,
    "openalex_id": "https://openalex.org/W2643577078",
    "type": "article"
  },
  {
    "title": "Personalized Context-Aware Point of Interest Recommendation",
    "doi": "https://doi.org/10.1145/3231933",
    "publication_date": "2018-10-03",
    "publication_year": 2018,
    "authors": "Mohammad Aliannejadi; Fábio Crestani",
    "corresponding_authors": "",
    "abstract": "Personalized recommendation of Points of Interest (POIs) plays a key role in satisfying users on Location-Based Social Networks (LBSNs). In this article, we propose a probabilistic model to find the mapping between user-annotated tags and locations’ taste keywords. Furthermore, we introduce a dataset on locations’ contextual appropriateness and demonstrate its usefulness in predicting the contextual relevance of locations. We investigate four approaches to use our proposed mapping for addressing the data sparsity problem: one model to reduce the dimensionality of location taste keywords and three models to predict user tags for a new location. Moreover, we present different scores calculated from multiple LBSNs and show how we incorporate new information from the mapping into a POI recommendation approach. Then, the computed scores are integrated using learning to rank techniques. The experiments on two TREC datasets show the effectiveness of our approach, beating state-of-the-art methods.",
    "cited_by_count": 83,
    "openalex_id": "https://openalex.org/W2964239943",
    "type": "article"
  },
  {
    "title": "Who, Where, When, and What",
    "doi": "https://doi.org/10.1145/2699667",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Quan Yuan; Gao Cong; Kaiqi Zhao; Zongyang Ma; Aixin Sun",
    "corresponding_authors": "",
    "abstract": "Micro-blogging services and location-based social networks, such as Twitter, Weibo, and Foursquare, enable users to post short messages with timestamps and geographical annotations. The rich spatial-temporal-semantic information of individuals embedded in these geo-annotated short messages provides exciting opportunity to develop many context-aware applications in ubiquitous computing environments. Example applications include contextual recommendation and contextual search. To obtain accurate recommendations and most relevant search results, it is important to capture users’ contextual information (e.g., time and location) and to understand users’ topical interests and intentions. While time and location can be readily captured by smartphones, understanding user’s interests and intentions calls for effective methods in modeling user mobility behavior. Here, user mobility refers to who visits which place at what time for what activity . That is, user mobility behavior modeling must consider user (Who), spatial (Where), temporal (When), and activity (What) aspects. Unfortunately, no previous studies on user mobility behavior modeling have considered all of the four aspects jointly, which have complex interdependencies. In our preliminary study, we propose the first solution named W 4 (short for Who, Where, When, and What) to discover user mobility behavior from the four aspects. In this article, we further enhance W 4 and propose a nonparametric Bayesian model named EW 4 (short for Enhanced W 4 ). EW 4 requires no parameter tuning and achieves better results over W 4 in our experiments. Given some of the four aspects of a user (e.g., time), our model is able to infer information of the other aspects (e.g., location and topical words). Thus, our model has a variety of context-aware applications, particularly in contextual search and recommendation. Experimental results on two real-world datasets show that the proposed model is effective in discovering users’ spatial-temporal topics. The model also significantly outperforms state-of-the-art baselines for various tasks including location prediction for tweets and requirement-aware location recommendation.",
    "cited_by_count": 82,
    "openalex_id": "https://openalex.org/W2020669710",
    "type": "article"
  },
  {
    "title": "Query modeling for entity search based on terms, categories, and examples",
    "doi": "https://doi.org/10.1145/2037661.2037667",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Krisztian Balog; Marc Bron; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Users often search for entities instead of documents, and in this setting, are willing to provide extra input, in addition to a series of query terms, such as category information and example entities. We propose a general probabilistic framework for entity search to evaluate and provide insights in the many ways of using these types of input for query modeling. We focus on the use of category information and show the advantage of a category-based representation over a term-based representation, and also demonstrate the effectiveness of category-based expansion using example entities. Our best performing model shows very competitive performance on the INEX-XER entity ranking and list completion tasks.",
    "cited_by_count": 81,
    "openalex_id": "https://openalex.org/W2104428806",
    "type": "article"
  },
  {
    "title": "Word-based self-indexes for natural language text",
    "doi": "https://doi.org/10.1145/2094072.2094073",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Antonio Fariña; Nieves R. Brisaboa; Gonzalo Navarro; Francisco Claude; Ángeles S. Places; Eduardo Rodríguez",
    "corresponding_authors": "",
    "abstract": "The inverted index supports efficient full-text searches on natural language text collections. It requires some extra space over the compressed text that can be traded for search speed. It is usually fast for single-word searches, yet phrase searches require more expensive intersections. In this article we introduce a different kind of index. It replaces the text using essentially the same space required by the compressed text alone (compression ratio around 35%). Within this space it supports not only decompression of arbitrary passages, but efficient word and phrase searches. Searches are orders of magnitude faster than those over inverted indexes when looking for phrases, and still faster on single-word searches when little space is available. Our new indexes are particularly fast at counting the occurrences of words or phrases. This is useful for computing relevance of words or phrases. We adapt self-indexes that succeeded in indexing arbitrary strings within compressed space to deal with large alphabets. Natural language texts are then regarded as sequences of words, not characters, to achieve word-based self-indexes. We design an architecture that separates the searchable sequence from its presentation aspects. This permits applying case folding, stemming, removing stopwords, etc. as is usual on inverted indexes.",
    "cited_by_count": 80,
    "openalex_id": "https://openalex.org/W2142905080",
    "type": "article"
  },
  {
    "title": "Learning to Recommend Descriptive Tags for Questions in Social Forums",
    "doi": "https://doi.org/10.1145/2559157",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Liqiang Nie; Yiliang Zhao; Xiangyu Wang; Jialie Shen; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Around 40% of the questions in the emerging social-oriented question answering forums have at most one manually labeled tag, which is caused by incomprehensive question understanding or informal tagging behaviors. The incompleteness of question tags severely hinders all the tag-based manipulations, such as feeds for topic-followers, ontological knowledge organization, and other basic statistics. This article presents a novel scheme that is able to comprehensively learn descriptive tags for each question. Extensive evaluations on a representative real-world dataset demonstrate that our scheme yields significant gains for question annotation, and more importantly, the whole process of our approach is unsupervised and can be extended to handle large-scale data.",
    "cited_by_count": 79,
    "openalex_id": "https://openalex.org/W2121887197",
    "type": "article"
  },
  {
    "title": "Collaborative Intent Prediction with Real-Time Contextual Data",
    "doi": "https://doi.org/10.1145/3041659",
    "publication_date": "2017-08-16",
    "publication_year": 2017,
    "authors": "Yu Sun; Nicholas Jing Yuan; Xing Xie; Kieran McDonald; Rui Zhang",
    "corresponding_authors": "",
    "abstract": "Intelligent personal assistants on mobile devices such as Apple’s Siri and Microsoft Cortana are increasingly important. Instead of passively reacting to queries, they provide users with brand new proactive experiences that aim to offer the right information at the right time. It is, therefore, crucial for personal assistants to understand users’ intent, that is, what information users need now. Intent is closely related to context. Various contextual signals, including spatio-temporal information and users’ activities, can signify users’ intent. It is, however, challenging to model the correlation between intent and context. Intent and context are highly dynamic and often sequentially correlated. Contextual signals are usually sparse, heterogeneous, and not simultaneously available. We propose an innovative collaborative nowcasting model to jointly address all these issues. The model effectively addresses the complex sequential and concurring correlation between context and intent and recognizes users’ real-time intent with continuously arrived contextual signals. We extensively evaluate the proposed model with real-world data sets from a commercial personal assistant. The results validate the effectiveness the proposed model, and demonstrate its capability of handling the real-time flow of contextual signals. The studied problem and model also provide inspiring implications for new paradigms of recommendation on mobile intelligent devices.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W2746626573",
    "type": "article"
  },
  {
    "title": "Practical linear-time <i>O</i> (1)-workspace suffix sorting for constant alphabets",
    "doi": "https://doi.org/10.1145/2493175.2493180",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Ge Nong",
    "corresponding_authors": "Ge Nong",
    "abstract": "This article presents an O ( n )-time algorithm called SACA-K for sorting the suffixes of an input string T [0, n -1] over an alphabet A [0, K -1]. The problem of sorting the suffixes of T is also known as constructing the suffix array (SA) for T . The theoretical memory usage of SACA-K is n log K + n log n + K log n bits. Moreover, we also have a practical implementation for SACA-K that uses n bytes + ( n + 256) words and is suitable for strings over any alphabet up to full ASCII, where a word is log n bits. In our experiment, SACA-K outperforms SA-IS that was previously the most time- and space-efficient linear-time SA construction algorithm (SACA). SACA-K is around 33% faster and uses a smaller deterministic workspace of K words, where the workspace is the space needed beyond the input string and the output SA. Given K = O (1), SACA-K runs in linear time and O (1) workspace. To the best of our knowledge, such a result is the first reported in the literature with a practical source code publicly available.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W1977174119",
    "type": "article"
  },
  {
    "title": "Misinformation in Online Social Networks",
    "doi": "https://doi.org/10.1145/2885494",
    "publication_date": "2016-04-11",
    "publication_year": 2016,
    "authors": "Huiling Zhang; Md Abdul Alim; Xiang Li; My T. Thai; Hien Nguyen",
    "corresponding_authors": "",
    "abstract": "Online social networks have become an effective and important social platform for communication, opinions exchange, and information sharing. However, they also make it possible for rapid and wide misinformation diffusion, which may lead to pernicious influences on individuals or society. Hence, it is extremely important and necessary to detect the misinformation propagation by placing monitors. In this article, we first define a general misinformation-detection problem for the case where the knowledge about misinformation sources is lacking, and show its equivalence to the influence-maximization problem in the reverse graph. Furthermore, considering node vulnerability, we aim to detect the misinformation reaching to a specific user. Therefore, we study a τ-Monitor Placement problem for cases where partial knowledge of misinformation sources is available and prove its # P complexity. We formulate a corresponding integer program, tackle exponential constraints, and propose a Minimum Monitor Set Construction (MMSC) algorithm, in which the cut-set 2 has been exploited in the estimation of reachability of node pairs. Moreover, we generalize the problem from a single target to multiple central nodes and propose another algorithm based on a Monte Carlo sampling technique. Extensive experiments on real-world networks show the effectiveness of proposed algorithms with respect to minimizing the number of monitors.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W2324763723",
    "type": "article"
  },
  {
    "title": "Computing Urban Traffic Congestions by Incorporating Sparse GPS Probe Data and Social Media Data",
    "doi": "https://doi.org/10.1145/3057281",
    "publication_date": "2017-07-11",
    "publication_year": 2017,
    "authors": "Senzhang Wang; Xiaoming Zhang; Cao Jianping; Lifang He; Leon Stenneth; Philip S. Yu; Zhoujun Li; Zhiqiu Huang",
    "corresponding_authors": "",
    "abstract": "Estimating urban traffic conditions of an arterial network with GPS probe data is a practically important while substantially challenging problem, and has attracted increasing research interests recently. Although GPS probe data is becoming a ubiquitous data source for various traffic related applications currently, they are usually insufficient for fully estimating traffic conditions of a large arterial network due to the low sampling frequency. To explore other data sources for more effectively computing urban traffic conditions, we propose to collect various traffic events such as traffic accident and jam from social media as complementary information. In addition, to further explore other factors that might affect traffic conditions, we also extract rich auxiliary information including social events, road features, Point of Interest (POI), and weather. With the enriched traffic data and auxiliary information collected from different sources, we first study the traffic co-congestion pattern mining problem with the aim of discovering which road segments geographically close to each other are likely to co-occur traffic congestion. A search tree based approach is proposed to efficiently discover the co-congestion patterns. These patterns are then used to help estimate traffic congestions and detect anomalies in a transportation network. To fuse the multisourced data, we finally propose a coupled matrix and tensor factorization model named TCE_R to more accurately complete the sparse traffic congestion matrix by collaboratively factorizing it with other matrices and tensors formed by other data. We evaluate the proposed model on the arterial network of downtown Chicago with 1,257 road segments whose total length is nearly 700 miles. The results demonstrate the superior performance of TCE_R by comprehensive comparison with existing approaches.",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W2735643103",
    "type": "article"
  },
  {
    "title": "The Characteristics of Voice Search",
    "doi": "https://doi.org/10.1145/3182163",
    "publication_date": "2018-03-13",
    "publication_year": 2018,
    "authors": "Ido Guy",
    "corresponding_authors": "Ido Guy",
    "abstract": "The growing popularity of mobile search and the advancement in voice recognition technologies have opened the door for web search users to speak their queries rather than type them. While this kind of voice search is still in its infancy, it is gradually becoming more widespread. In this article, we report a comprehensive voice search query log analysis of a commercial web search engine’s mobile application. We compare voice and text search by various aspects, with special focus on the semantic and syntactic characteristics of the queries. Our analysis suggests that voice queries focus more on audio-visual content and question answering and less on social networking and adult domains. In addition, voice queries are more commonly submitted on the go. We also conduct an empirical evaluation showing that the language of voice queries is closer to natural language than the language of text queries. Our analysis points out further differences between voice and text search. We discuss the implications of these differences for the design of future voice-enabled web search tools.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W2790894221",
    "type": "article"
  },
  {
    "title": "Brotli",
    "doi": "https://doi.org/10.1145/3231935",
    "publication_date": "2018-12-06",
    "publication_year": 2018,
    "authors": "Jyrki Alakuijala; Andrea Farruggia; Paolo Ferragina; Eugene Kliuchnikov; Robert Obryk; Zoltán Szabadka; Lode Vandevenne‎",
    "corresponding_authors": "",
    "abstract": "Brotli is an open source general-purpose data compressor introduced by Google in late 2013 and now adopted in most known browsers and Web servers. It is publicly available on GitHub and its data format was submitted as RFC 7932 in July 2016. Brotli is based on the Lempel-Ziv compression scheme and planned as a generic replacement of Gzip and ZLib. The main goal in its design was to compress data on the Internet, which meant optimizing the resources used at decoding time, while achieving maximal compression density. This article is intended to provide the first thorough, systematic description of the Brotli format as well as a detailed computational and experimental analysis of the main algorithmic blocks underlying the current encoder implementation, together with a comparison against compressors of different families constituting the state-of-the-art either in practice or in theory. This treatment will allow us to raise a set of new algorithmic and software engineering problems that deserve further attention from the scientific community.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W2903638214",
    "type": "article"
  },
  {
    "title": "A Deep Learning Architecture for Psychometric Natural Language Processing",
    "doi": "https://doi.org/10.1145/3365211",
    "publication_date": "2020-01-31",
    "publication_year": 2020,
    "authors": "Faizan Ahmad; Ahmed Abbasi; Jingjing Li; David G. Dobolyi; Richard G. Netemeyer; Gari D. Clifford; Hsinchun Chen",
    "corresponding_authors": "",
    "abstract": "Psychometric measures reflecting people’s knowledge, ability, attitudes, and personality traits are critical for many real-world applications, such as e-commerce, health care, and cybersecurity. However, traditional methods cannot collect and measure rich psychometric dimensions in a timely and unobtrusive manner. Consequently, despite their importance, psychometric dimensions have received limited attention from the natural language processing and information retrieval communities. In this article, we propose a deep learning architecture, PyNDA, to extract psychometric dimensions from user-generated texts. PyNDA contains a novel representation embedding, a demographic embedding, a structural equation model (SEM) encoder, and a multitask learning mechanism designed to work in unison to address the unique challenges associated with extracting rich, sophisticated, and user-centric psychometric dimensions. Our experiments on three real-world datasets encompassing 11 psychometric dimensions, including trust, anxiety, and literacy, show that PyNDA markedly outperforms traditional feature-based classifiers as well as the state-of-the-art deep learning architectures. Ablation analysis reveals that each component of PyNDA significantly contributes to its overall performance. Collectively, the results demonstrate the efficacy of the proposed architecture for facilitating rich psychometric analysis. Our results have important implications for user-centric information extraction and retrieval systems looking to measure and incorporate psychometric dimensions.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W3004561114",
    "type": "article"
  },
  {
    "title": "Interactive Intent Modeling for Exploratory Search",
    "doi": "https://doi.org/10.1145/3231593",
    "publication_date": "2018-10-03",
    "publication_year": 2018,
    "authors": "Tuukka Ruotsalo; Jaakko Peltonen; Manuel J. A. Eugster; Dorota Głowacka; Patrik Floréen; Petri Myllymäki; Giulio Jacucci; Samuel Kaski",
    "corresponding_authors": "",
    "abstract": "Exploratory search requires the system to assist the user in comprehending the information space and expressing evolving search intents for iterative exploration and retrieval of information. We introduce interactive intent modeling, a technique that models a user’s evolving search intents and visualizes them as keywords for interaction. The user can provide feedback on the keywords, from which the system learns and visualizes an improved intent estimate and retrieves information. We report experiments comparing variants of a system implementing interactive intent modeling to a control system. Data comprising search logs, interaction logs, essay answers, and questionnaires indicate significant improvements in task performance, information retrieval performance over the session, information comprehension performance, and user experience. The improvements in retrieval effectiveness can be attributed to the intent modeling and the effect on users’ task performance, breadth of information comprehension, and user experience are shown to be dependent on a richer visualization. Our results demonstrate the utility of combining interactive modeling of search intentions with interactive visualization of the models that can benefit both directing the exploratory search process and making sense of the information space. Our findings can help design personalized systems that support exploratory information seeking and discovery of novel information.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W2894958058",
    "type": "article"
  },
  {
    "title": "Explainable Product Search with a Dynamic Relation Embedding Model",
    "doi": "https://doi.org/10.1145/3361738",
    "publication_date": "2019-10-18",
    "publication_year": 2019,
    "authors": "Qingyao Ai; Yongfeng Zhang; Keping Bi; W. Bruce Croft",
    "corresponding_authors": "",
    "abstract": "Product search is one of the most popular methods for customers to discover products online. Most existing studies on product search focus on developing effective retrieval models that rank items by their likelihood to be purchased. However, they ignore the problem that there is a gap between how systems and customers perceive the relevance of items. Without explanations, users may not understand why product search engines retrieve certain items for them, which consequentially leads to imperfect user experience and suboptimal system performance in practice. In this work, we tackle this problem by constructing explainable retrieval models for product search. Specifically, we propose to model the “search and purchase” behavior as a dynamic relation between users and items, and create a dynamic knowledge graph based on both the multi-relational product data and the context of the search session. Ranking is conducted based on the relationship between users and items in the latent space, and explanations are generated with logic inferences and entity soft matching on the knowledge graph. Empirical experiments show that our model, which we refer to as the Dynamic Relation Embedding Model (DREM), significantly outperforms the state-of-the-art baselines and has the ability to produce reasonable explanations for search results.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2980918481",
    "type": "article"
  },
  {
    "title": "Large-Scale Question Tagging via Joint Question-Topic Embedding Learning",
    "doi": "https://doi.org/10.1145/3380954",
    "publication_date": "2020-02-28",
    "publication_year": 2020,
    "authors": "Liqiang Nie; Yongqi Li; Fuli Feng; Xuemeng Song; Meng Wang; Yinglong Wang",
    "corresponding_authors": "",
    "abstract": "Recent years have witnessed a flourishing of community-driven question answering (cQA), like Yahoo! Answers and AnswerBag, where people can seek precise information. After 2010, some novel cQA systems, including Quora and Zhihu, gained momentum. Besides interactions, the latter enables users to label the questions with topic tags that highlight the key points conveyed in the questions. In this article, we shed light on automatically annotating a newly posted question with topic tags that are predefined and preorganized into a directed acyclic graph. To accomplish this task, we present an end-to-end deep interactive embedding model to jointly learn the embeddings of questions and topics by projecting them into the same space for a similarity measure. In particular, we first learn the embeddings of questions and topic tags by two deep parallel models. Thereinto, we regularize the embeddings of topic tags via fully exploring their hierarchical structures, which is able to alleviate the problem of imbalanced topic distribution. Thereafter, we interact each question embedding with the topic tag matrix, i.e., all the topic tag embeddings. Following that, a sigmoid cross-entropy loss is appended to reward the positive question-topic pairs and penalize the negative ones. To justify our model, we have conducted extensive experiments on an unprecedented large-scale social QA dataset obtained from Zhihu.com, and the experimental results demonstrate that our model achieves superior performance to several state-of-the-art baselines.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W3009735700",
    "type": "article"
  },
  {
    "title": "A Graph-Based Approach for Mitigating Multi-Sided Exposure Bias in Recommender Systems",
    "doi": "https://doi.org/10.1145/3470948",
    "publication_date": "2021-11-16",
    "publication_year": 2021,
    "authors": "Masoud Mansoury; Himan Abdollahpouri; Mykola Pechenizkiy; Bamshad Mobasher; Robin Burke",
    "corresponding_authors": "",
    "abstract": "Fairness is a critical system-level objective in recommender systems that has been the subject of extensive recent research. A specific form of fairness is supplier exposure fairness, where the objective is to ensure equitable coverage of items across all suppliers in recommendations provided to users. This is especially important in multistakeholder recommendation scenarios where it may be important to optimize utilities not just for the end user but also for other stakeholders such as item sellers or producers who desire a fair representation of their items. This type of supplier fairness is sometimes accomplished by attempting to increase aggregate diversity to mitigate popularity bias and to improve the coverage of long-tail items in recommendations. In this article, we introduce FairMatch, a general graph-based algorithm that works as a post-processing approach after recommendation generation to improve exposure fairness for items and suppliers. The algorithm iteratively adds high-quality items that have low visibility or items from suppliers with low exposure to the users’ final recommendation lists. A comprehensive set of experiments on two datasets and comparison with state-of-the-art baselines show that FairMatch, although it significantly improves exposure fairness and aggregate diversity, maintains an acceptable level of relevance of the recommendations.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W3182641134",
    "type": "article"
  },
  {
    "title": "Reinforcement Learning–based Collective Entity Alignment with Adaptive Features",
    "doi": "https://doi.org/10.1145/3446428",
    "publication_date": "2021-05-05",
    "publication_year": 2021,
    "authors": "Weixin Zeng; Xiang Zhao; Jiuyang Tang; Xuemin Lin; Paul Groth",
    "corresponding_authors": "",
    "abstract": "Entity alignment (EA) is the task of identifying the entities that refer to the same real-world object but are located in different knowledge graphs (KGs). For entities to be aligned, existing EA solutions treat them separately and generate alignment results as ranked lists of entities on the other side. Nevertheless, this decision-making paradigm fails to take into account the interdependence among entities. Although some recent efforts mitigate this issue by imposing the 1-to-1 constraint on the alignment process, they still cannot adequately model the underlying interdependence and the results tend to be sub-optimal. To fill in this gap, in this work, we delve into the dynamics of the decision-making process, and offer a reinforcement learning (RL)–based model to align entities collectively. Under the RL framework, we devise the coherence and exclusiveness constraints to characterize the interdependence and restrict collective alignment. Additionally, to generate more precise inputs to the RL framework, we employ representative features to capture different aspects of the similarity between entities in heterogeneous KGs, which are integrated by an adaptive feature fusion strategy. Our proposal is evaluated on both cross-lingual and mono-lingual EA benchmarks and compared against state-of-the-art solutions. The empirical results verify its effectiveness and superiority.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W3157819612",
    "type": "article"
  },
  {
    "title": "A Review on Question Generation from Natural Language Text",
    "doi": "https://doi.org/10.1145/3468889",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Ruqing Zhang; Jiafeng Guo; Lu Chen; Yixing Fan; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "Question generation is an important yet challenging problem in Artificial Intelligence (AI), which aims to generate natural and relevant questions from various input formats, e.g., natural language text, structure database, knowledge base, and image. In this article, we focus on question generation from natural language text, which has received tremendous interest in recent years due to the widespread applications such as data augmentation for question answering systems. During the past decades, many different question generation models have been proposed, from traditional rule-based methods to advanced neural network-based methods. Since there have been a large variety of research works proposed, we believe it is the right time to summarize the current status, learn from existing methodologies, and gain some insights for future development. In contrast to existing reviews, in this survey, we try to provide a more comprehensive taxonomy of question generation tasks from three different perspectives, i.e., the types of the input context text, the target answer, and the generated question. We take a deep look into existing models from different dimensions to analyze their underlying ideas, major design principles, and training strategies We compare these models through benchmark tasks to obtain an empirical understanding of the existing techniques. Moreover, we discuss what is missing in the current literature and what are the promising and desired future directions.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W3196385594",
    "type": "review"
  },
  {
    "title": "Combining Graph Convolutional Neural Networks and Label Propagation",
    "doi": "https://doi.org/10.1145/3490478",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Hongwei Wang; Jure Leskovec",
    "corresponding_authors": "",
    "abstract": "Label Propagation Algorithm (LPA) and Graph Convolutional Neural Networks (GCN) are both message passing algorithms on graphs. Both solve the task of node classification, but LPA propagates node label information across the edges of the graph, while GCN propagates and transforms node feature information. However, while conceptually similar, theoretical relationship between LPA and GCN has not yet been systematically investigated. Moreover, it is unclear how LPA and GCN can be combined under a unified framework to improve the performance. Here we study the relationship between LPA and GCN in terms of feature/label influence , in which we characterize how much the initial feature/label of one node influences the final feature/label of another node in GCN/LPA. Based on our theoretical analysis, we propose an end-to-end model that combines GCN and LPA. In our unified model, edge weights are learnable, and the LPA serves as regularization to assist the GCN in learning proper edge weights that lead to improved performance. Our model can also be seen as learning the weights of edges based on node labels, which is more direct and efficient than existing feature-based attention models or topology-based diffusion models. In a number of experiments for semi-supervised node classification and knowledge-graph-aware recommendation, our model shows superiority over state-of-the-art baselines.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W3217672792",
    "type": "article"
  },
  {
    "title": "Sequential-Knowledge-Aware Next POI Recommendation: A Meta-Learning Approach",
    "doi": "https://doi.org/10.1145/3460198",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Yue Cui; Hao Sun; Yan Zhao; Hongzhi Yin; Kai Zheng",
    "corresponding_authors": "",
    "abstract": "Accurately recommending the next point of interest (POI) has become a fundamental problem with the rapid growth of location-based social networks. However, sparse, imbalanced check-in data and diverse user check-in patterns pose severe challenges for POI recommendation tasks. Knowledge-aware models are known to be primary in leveraging these problems. However, as most knowledge graphs are constructed statically, sequential information is yet integrated. In this work, we propose a meta-learned sequential-knowledge-aware recommender (Meta-SKR), which utilizes sequential, spatio-temporal, and social knowledge to recommend the next POI for a location-based social network user. The framework mainly contains four modules. First, in the graph construction module, a novel type of knowledge graph—the sequential knowledge graph, which is sensitive to the check-in order of POIs—is built to model users’ check-in patterns. To deal with the problem of data sparsity, a meta-learning module based on latent embedding optimization is then introduced to generate user-conditioned parameters of the subsequent sequential-knowledge-aware embedding module, where representation vectors of entities (nodes) and relations (edges) are learned. In this embedding module, gated recurrent units are adapted to distill intra- and inter-sequential knowledge graph information. We also design a novel knowledge-aware attention mechanism to capture information surrounding a given node. Finally, POI recommendation is provided by inferring potential links of knowledge graphs in the prediction module. Evaluations on three real-world check-in datasets show that Meta-SKR can achieve high recommendation accuracy even with sparse data.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W3203589076",
    "type": "article"
  },
  {
    "title": "Multilingual Review-aware Deep Recommender System via Aspect-based Sentiment Analysis",
    "doi": "https://doi.org/10.1145/3432049",
    "publication_date": "2021-01-14",
    "publication_year": 2021,
    "authors": "Peng Liu; Lemei Zhang; Jon Atle Gulla",
    "corresponding_authors": "",
    "abstract": "With the dramatic expansion of international markets, consumers write reviews in different languages, which poses a new challenge for Recommender Systems (RSs) dealing with this increasing amount of multilingual information. Recent studies that leverage deep-learning techniques for review-aware RSs have demonstrated their effectiveness in modelling fine-grained user-item interactions through the aspects of reviews. However, most of these models can neither take full advantage of the contextual information from multilingual reviews nor discriminate the inherent ambiguity of words originated from the user’s different tendency in writing. To this end, we propose a novel Multilingual Review-aware Deep Recommendation Model (MrRec) for rating prediction tasks. MrRec mainly consists of two parts: (1) Multilingual aspect-based sentiment analysis module (MABSA), which aims to jointly extract aligned aspects and their associated sentiments in different languages simultaneously with only requiring overall review ratings. (2) Multilingual recommendation module that learns aspect importances of both the user and item with considering different contributions of multiple languages and estimates aspect utility via a dual interactive attention mechanism integrated with aspect-specific sentiments from MABSA. Finally, overall ratings can be inferred by a prediction layer adopting the aspect utility value and aspect importance as inputs. Extensive experimental results on nine real-world datasets demonstrate the superior performance and interpretability of our model.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W3119339920",
    "type": "article"
  },
  {
    "title": "Unbiased Learning to Rank",
    "doi": "https://doi.org/10.1145/3439861",
    "publication_date": "2021-02-17",
    "publication_year": 2021,
    "authors": "Qingyao Ai; Tao Yang; Huazheng Wang; Jiaxin Mao",
    "corresponding_authors": "",
    "abstract": "How to obtain an unbiased ranking model by learning to rank with biased user feedback is an important research question for IR. Existing work on unbiased learning to rank (ULTR) can be broadly categorized into two groups—the studies on unbiased learning algorithms with logged data, namely, the offline unbiased learning, and the studies on unbiased parameters estimation with real-time user interactions, namely, the online learning to rank. While their definitions of unbiasness are different, these two types of ULTR algorithms share the same goal—to find the best models that rank documents based on their intrinsic relevance or utility. However, most studies on offline and online unbiased learning to rank are carried in parallel without detailed comparisons on their background theories and empirical performance. In this article, we formalize the task of unbiased learning to rank and show that existing algorithms for offline unbiased learning and online learning to rank are just the two sides of the same coin. We evaluate eight state-of-the-art ULTR algorithms and find that many of them can be used in both offline settings and online environments with or without minor modifications. Further, we analyze how different offline and online learning paradigms would affect the theoretical foundation and empirical effectiveness of each algorithm on both synthetic and real search data. Our findings provide important insights and guidelines for choosing and deploying ULTR algorithms in practice.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W3130740428",
    "type": "article"
  },
  {
    "title": "HyperSoRec: Exploiting Hyperbolic User and Item Representations with Multiple Aspects for Social-aware Recommendation",
    "doi": "https://doi.org/10.1145/3463913",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Hao Wang; Defu Lian; Hanghang Tong; Qi Liu; Zhenya Huang; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "Social recommendation has achieved great success in many domains including e-commerce and location-based social networks. Existing methods usually explore the user-item interactions or user-user connections to predict users’ preference behaviors. However, they usually learn both user and item representations in Euclidean space, which has large limitations for exploring the latent hierarchical property in the data. In this article, we study a novel problem of hyperbolic social recommendation, where we aim to learn the compact but strong representations for both users and items. Meanwhile, this work also addresses two critical domain-issues, which are under-explored. First, users often make trade-offs with multiple underlying aspect factors to make decisions during their interactions with items. Second, users generally build connections with others in terms of different aspects, which produces different influences with aspects in social network. To this end, we propose a novel graph neural network (GNN) framework with multiple aspect learning, namely, HyperSoRec. Specifically, we first embed all users, items, and aspects into hyperbolic space with superior representations to ensure their hierarchical properties. Then, we adapt a GNN with novel multi-aspect message-passing-receiving mechanism to capture different influences among users. Next, to characterize the multi-aspect interactions of users on items, we propose an adaptive hyperbolic metric learning method by introducing learnable interactive relations among different aspects. Finally, we utilize the hyperbolic translational distance to measure the plausibility in each user-item pair for recommendation. Experimental results on two public datasets clearly demonstrate that our HyperSoRec not only achieves significant improvement for recommendation performance but also shows better representation ability in hyperbolic space with strong robustness and reliability.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W3201966249",
    "type": "article"
  },
  {
    "title": "Personalizing Medication Recommendation with a Graph-Based Approach",
    "doi": "https://doi.org/10.1145/3488668",
    "publication_date": "2021-11-22",
    "publication_year": 2021,
    "authors": "Suman Bhoi; Mong Li Lee; Wynne Hsu; Hao Sen Andrew Fang; Ngiap Chuan Tan",
    "corresponding_authors": "",
    "abstract": "The broad adoption of electronic health records (EHRs) has led to vast amounts of data being accumulated on a patient’s history, diagnosis, prescriptions, and lab tests. Advances in recommender technologies have the potential to utilize this information to help doctors personalize the prescribed medications. However, existing medication recommendation systems have yet to make use of all these information sources in a seamless manner, and they do not provide a justification on why a particular medication is recommended. In this work, we design a two-stage personalized medication recommender system called PREMIER that incorporates information from the EHR. We utilize the various weights in the system to compute the contributions from the information sources for the recommended medications. Our system models the drug interaction from an external drug database and the drug co-occurrence from the EHR as graphs. Experiment results on MIMIC-III and a proprietary outpatient dataset show that PREMIER outperforms state-of-the-art medication recommendation systems while achieving the best tradeoff between accuracy and drug-drug interaction. Case studies demonstrate that the justifications provided by PREMIER are appropriate and aligned to clinical practices.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W4200046635",
    "type": "article"
  },
  {
    "title": "Personalized and Explainable Employee Training Course Recommendations: A Bayesian Variational Approach",
    "doi": "https://doi.org/10.1145/3490476",
    "publication_date": "2021-12-08",
    "publication_year": 2021,
    "authors": "Chao Wang; Hengshu Zhu; Peng Wang; Chen Zhu; Xi Zhang; Enhong Chen; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "As a major component of strategic talent management, learning and development (L&amp;D) aims at improving the individual and organization performances through planning tailored training for employees to increase and improve their skills and knowledge. While many companies have developed the learning management systems (LMSs) for facilitating the online training of employees, a long-standing important issue is how to achieve personalized training recommendations with the consideration of their needs for future career development. To this end, in this article, we present a focused study on the explainable personalized online course recommender system for enhancing employee training and development. Specifically, we first propose a novel end-to-end hierarchical framework, namely Demand-aware Collaborative Bayesian Variational Network (DCBVN), to jointly model both the employees’ current competencies and their career development preferences in an explainable way. In DCBVN, we first extract the latent interpretable representations of the employees’ competencies from their skill profiles with autoencoding variational inference based topic modeling. Then, we develop an effective demand recognition mechanism for learning the personal demands of career development for employees. In particular, all the above processes are integrated into a unified Bayesian inference view for obtaining both accurate and explainable recommendations. Furthermore, for handling the employees with sparse or missing skill profiles, we develop an improved version of DCBVN, called the Demand-aware Collaborative Competency Attentive Network (DCCAN) framework , by considering the connectivity among employees. In DCCAN, we first build two employee competency graphs from learning and working aspects. Then, we design a graph-attentive network and a multi-head integration mechanism to infer one’s competency information from her neighborhood employees. Finally, we can generate explainable recommendation results based on the competency representations. Extensive experimental results on real-world data clearly demonstrate the effectiveness and the interpretability of both of our frameworks, as well as their robustness on sparse and cold-start scenarios.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W4200412261",
    "type": "article"
  },
  {
    "title": "Revisiting Negative Sampling vs. Non-sampling in Implicit Recommendation",
    "doi": "https://doi.org/10.1145/3522672",
    "publication_date": "2022-03-25",
    "publication_year": 2022,
    "authors": "Chong Chen; Weizhi Ma; Min Zhang; Chenyang Wang; Yiqun Liu; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Recommendation systems play an important role in alleviating the information overload issue. Generally, a recommendation model is trained to discern between positive (liked) and negative (disliked) instances for each user. However, under the open-world assumption, there are only positive instances but no negative instances from users’ implicit feedback, which poses the imbalanced learning challenge of lacking negative samples. To address this, two types of learning strategies have been proposed before, the negative sampling strategy and non-sampling strategy. The first strategy samples negative instances from missing data (i.e., unlabeled data), while the non-sampling strategy regards all the missing data as negative. Although learning strategies are known to be essential for algorithm performance, the in-depth comparison of negative sampling and non-sampling has not been sufficiently explored by far. To bridge this gap, we systematically analyze the role of negative sampling and non-sampling for implicit recommendation in this work. Specifically, we first theoretically revisit the objection of negative sampling and non-sampling. Then, with a careful setup of various representative recommendation methods, we explore the performance of negative sampling and non-sampling in different scenarios. Our results empirically show that although negative sampling has been widely applied to recent recommendation models, it is non-trivial for uniform sampling methods to show comparable performance to non-sampling learning methods. Finally, we discuss the scalability and complexity of negative sampling and non-sampling and present some open problems and future research topics that are worth being further explored.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W4221030716",
    "type": "article"
  },
  {
    "title": "PRADA: Practical Black-box Adversarial Attacks against Neural Ranking Models",
    "doi": "https://doi.org/10.1145/3576923",
    "publication_date": "2022-12-16",
    "publication_year": 2022,
    "authors": "Chen Wu; Ruqing Zhang; Jiafeng Guo; Maarten de Rijke; Yixing Fan; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "Neural ranking models (NRMs) have shown remarkable success in recent years, especially with pre-trained language models. However, deep neural models are notorious for their vulnerability to adversarial examples. Adversarial attacks may become a new type of web spamming technique given our increased reliance on neural information retrieval models. Therefore, it is important to study potential adversarial attacks to identify vulnerabilities of NRMs before they are deployed. In this article, we introduce the Word Substitution Ranking Attack (WSRA) task against NRMs, which aims at promoting a target document in rankings by adding adversarial perturbations to its text. We focus on the decision-based black-box attack setting, where the attackers cannot directly get access to the model information, but can only query the target model to obtain the rank positions of the partial retrieved list. This attack setting is realistic in real-world search engines. We propose a novel Pseudo Relevance-based ADversarial ranking Attack method (PRADA) that learns a surrogate model based on Pseudo Relevance Feedback (PRF) to generate gradients for finding the adversarial perturbations. Experiments on two web search benchmark datasets show that PRADA can outperform existing attack strategies and successfully fool the NRM with small indiscernible perturbations of text.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W4224330422",
    "type": "article"
  },
  {
    "title": "Poisoning GNN-based Recommender Systems with Generative Surrogate-based Attacks",
    "doi": "https://doi.org/10.1145/3567420",
    "publication_date": "2022-10-19",
    "publication_year": 2022,
    "authors": "Thanh Toan Nguyen; Nguyen Duc Khang Quach; Thành Tâm Nguyên; Thanh Trung Huynh; Viet Hung Vu; Phi Le Nguyen; Jun Jo; Quoc Viet Hung Nguyen",
    "corresponding_authors": "",
    "abstract": "With recent advancements in graph neural networks (GNN), GNN-based recommender systems (gRS) have achieved remarkable success in the past few years. Despite this success, existing research reveals that gRSs are still vulnerable to poison attacks , in which the attackers inject fake data to manipulate recommendation results as they desire. This might be due to the fact that existing poison attacks (and countermeasures) are either model-agnostic or specifically designed for traditional recommender algorithms (e.g., neighborhood-based, matrix-factorization-based, or deep-learning-based RSs) that are not gRS. As gRSs are widely adopted in the industry, the problem of how to design poison attacks for gRSs has become a need for robust user experience. Herein, we focus on the use of poison attacks to manipulate item promotion in gRSs. Compared to standard GNNs, attacking gRSs is more challenging due to the heterogeneity of network structure and the entanglement between users and items. To overcome such challenges, we propose GSPAttack —a generative surrogate-based poison attack framework for gRSs. GSPAttack tailors a learning process to surrogate a recommendation model as well as generate fake users and user-item interactions while preserving the data correlation between users and items for recommendation accuracy. Although maintaining high accuracy for other items rather than the target item seems counterintuitive, it is equally crucial to the success of a poison attack. Extensive evaluations on four real-world datasets revealed that GSPAttack outperforms all baselines with competent recommendation performance and is resistant to various countermeasures.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W4306789986",
    "type": "article"
  },
  {
    "title": "Knowledge-Enhanced Attributed Multi-Task Learning for Medicine Recommendation",
    "doi": "https://doi.org/10.1145/3527662",
    "publication_date": "2022-04-14",
    "publication_year": 2022,
    "authors": "Yingying Zhang; Xian Wu; Quan Fang; Shengsheng Qian; Changsheng Xu",
    "corresponding_authors": "",
    "abstract": "Medicine recommendation systems target to recommend a set of medicines given a set of symptoms which play a crucial role in assisting doctors in their daily clinics. Existing approaches are either rule-based or supervised. However, the former heavily relies on expert labeling, which is time-consuming and costly to collect, and the latter suffers from the data sparse problem. To automate medicine recommendation on sparse data, we propose MedRec, which introduces two graphs in modeling: (1) a knowledge graph connecting diseases, medicines, symptoms, and examinations; (2) an attribute graph connecting medicines via shared attributes and molecular structures. These two graphs enhance the connectivity between symptoms and medicines, which thus alleviate the data sparse problem. By learning the interrelationship between diseases, medicines, symptoms and examinations and the inner relationship within medicine, we can acquire unified embedding representations of symptoms and medicines which can be used in medicine recommendation. The experimental results show that the proposed model outperforms state-of-the-art methods. In addition, we find that these two tasks: learning graph representation and medical recommendation can benefit each other.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W4224035645",
    "type": "article"
  },
  {
    "title": "Few-shot Aspect Category Sentiment Analysis via Meta-learning",
    "doi": "https://doi.org/10.1145/3529954",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Bin Liang; Xiang Li; Lin Gui; Yonghao Fu; Yulan He; Min Yang; Ruifeng Xu",
    "corresponding_authors": "",
    "abstract": "Existing aspect-based/category sentiment analysis methods have shown great success in detecting sentiment polarity toward a given aspect in a sentence with supervised learning, where the training and inference stages share the same pre-defined set of aspects. However, in practice, the aspect categories are changing rather than keeping fixed over time. Dealing with unseen aspect categories is under-explored in existing methods. In this article, we formulate a new few-shot aspect category sentiment analysis (FSACSA) task, which aims to effectively predict the sentiment polarity of previously unseen aspect categories. To this end, we propose a novel Aspect-Focused Meta-Learning (AFML) framework that constructs aspect-aware and aspect-contrastive representations from external knowledge to match the target aspect with aspects in the training set. Concretely, we first construct two auxiliary contrastive sentences for a given sentence with the incorporation of external knowledge, enabling the learning of sentence representations with a better generalization. Then, we devise an aspect-focused induction network to leverage the contextual sentiment toward a given aspect to refine the label vectors. Furthermore, we employ the episode-based meta-learning algorithm to train the whole network, so as to learn to generalize to novel aspects. Extensive experiments on multiple real-life datasets show that our proposed AFML framework achieves the state-of-the-art results for the FSACSA task.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W4224212929",
    "type": "article"
  },
  {
    "title": "Sequential Recommendation with Multiple Contrast Signals",
    "doi": "https://doi.org/10.1145/3522673",
    "publication_date": "2022-03-14",
    "publication_year": 2022,
    "authors": "Chenyang Wang; Weizhi Ma; Chong Chen; Min Zhang; Yiqun Liu; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Sequential recommendation has become a trending research topic for its capability to capture dynamic user intents based on historical interaction sequence. To train a sequential recommendation model, it is a common practice to optimize the next-item recommendation task with a pairwise ranking loss. In this paper, we revisit this typical training method from the perspective of contrastive learning and find it can be taken as a specialized contrastive learning task conceptually and mathematically, named context-target contrast . Further, to leverage other self-supervised signals in user interaction sequences, we propose another contrastive learning task to encourage sequences after augmentation, as well as sequences with the same target item, to have similar representations, called context-context contrast . A general framework, ContraRec, is designed to unify the two kinds of contrast signals, leading to a holistic joint-learning framework for sequential recommendation with different contrastive learning tasks. Besides, various sequential recommendation methods (e.g., GRU4Rec, Caser, and BERT4Rec) can be easily integrated as the base sequence encoder in our ContraRec framework. Extensive experiments on three public datasets demonstrate that ContraRec achieves superior performance compared to state-of-the-art sequential recommendation methods.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W4220894025",
    "type": "article"
  },
  {
    "title": "Curriculum Pre-training Heterogeneous Subgraph Transformer for Top- <i>N</i> Recommendation",
    "doi": "https://doi.org/10.1145/3528667",
    "publication_date": "2022-07-18",
    "publication_year": 2022,
    "authors": "Hui Wang; Kun Zhou; Wayne Xin Zhao; Jingyuan Wang; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "To characterize complex and heterogeneous side information in recommender systems, the heterogeneous information network (HIN) has shown superior performance and attracted much research attention. In HIN, the rich entities, relations, and paths can be utilized to model the correlations of users and items; such a task setting is often called HIN-based recommendation . Although HIN provides a general approach to modeling rich side information, it lacks special consideration on the goal of the recommendation task. The aggregated context from the heterogeneous graph is likely to incorporate irrelevant information, and the learned representations are not specifically optimized according to the recommendation task. Therefore, there is a need to rethink how to leverage the useful information from HIN to accomplish the recommendation task. To address the above issues, we propose a Curriculum pre-training based HEterogeneous Subgraph Transformer (called CHEST ) with new data characterization , representation model, and learning algorithm . Specifically, we consider extracting useful information from HIN to compose the interaction-specific heterogeneous subgraph, containing highly relevant context information for recommendation. Then, we capture the rich semantics (e.g., graph structure and path semantics) within the subgraph via a heterogeneous subgraph Transformer, where we encode the subgraph into multi-slot sequence representations. Besides, we design a curriculum pre-training strategy to provide an elementary-to-advanced learning process. The elementary course focuses on capturing local context information within the subgraph, and the advanced course aims to learn global context information. In this way, we gradually capture useful semantic information from HIN for modeling user-item interactions. Extensive experiments conducted on four real-world datasets demonstrate the superiority of our proposed method over a number of competitive baselines, especially when only limited training data is available.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W3172632637",
    "type": "article"
  },
  {
    "title": "Disentangled Representations Learning for Multi-target Cross-domain Recommendation",
    "doi": "https://doi.org/10.1145/3572835",
    "publication_date": "2022-12-02",
    "publication_year": 2022,
    "authors": "Xiaobo Guo; Shaoshuai Li; Naicheng Guo; Jiangxia Cao; Xiaolei Liu; Qiongxu Ma; Runsheng Gan; Yunan Zhao",
    "corresponding_authors": "",
    "abstract": "Data sparsity has been a long-standing issue for accurate and trustworthy recommendation systems (RS). To alleviate the problem, many researchers pay much attention to cross-domain recommendation (CDR), which aims at transferring rich knowledge from related source domains to enhance the recommendation performance of sparse target domain. To reach the knowledge transferring purpose, recent CDR works always focus on designing different pairwise directed or undirected information transferring strategies between source and target domains. However, such pairwise transferring idea is difficult to adapt to multi-target CDR scenarios directly, e.g., transferring knowledge between multiple domains and improving their performance simultaneously, as such strategies may lead the following issues: (1) When the number of domains increases, the number of transferring modules will grow exponentially, which causes heavy computation complexity. (2) A single pairwise transferring module could only capture the relevant information of two domains, but ignores the correlated information of other domains, which may limit the transferring effectiveness. (3) When a sparse domain serves as the source domain during the pairwise transferring, it would easily leads the negative transfer problem, and the untrustworthy information may hurt the target domain recommendation performance. In this article, we consider the key challenge of the multi-target CDR task: How to identify the most valuable trustworthy information over multiple domains and transfer such information efficiently to avoid the negative transfer problem? To fulfill the above challenge, we propose a novel end-to-end model termed as DR-MTCDR , standing for D isentangled R epresentations learning for M ulti- T arget CDR . DR-MTCDR aims at transferring the trustworthy domain-shared information across domains, which has the two major advantages in both efficiency and effectiveness: (1) For efficiency, DR-MTCDR utilizes a unified module on all domains to capture disentangled domain-shared information and domain-specific information, which could support all domain recommendation and be insensitive to the number of domains. (2) For effectiveness, based on the disentangled domain-shared and domain-specific information, DR-MTCDR has the capability to lead positive effect and make trustworthy recommendation for each domain. Empirical evaluations on datasets from both public datasets and real-world large-scale financial datasets have shown that the proposed framework outperforms other state-of-the-art baselines.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W4311185032",
    "type": "article"
  },
  {
    "title": "Fine-Grained Interaction Modeling with Multi-Relational Transformer for Knowledge Tracing",
    "doi": "https://doi.org/10.1145/3580595",
    "publication_date": "2023-01-19",
    "publication_year": 2023,
    "authors": "Jiajun Cui; Zeyuan Chen; Aimin Zhou; Jianyong Wang; Wei Zhang",
    "corresponding_authors": "",
    "abstract": "Knowledge tracing, the goal of which is predicting students’ future performance given their past question response sequences to trace their knowledge states, is pivotal for computer-aided education and intelligent tutoring systems. Although many technical efforts have been devoted to modeling students based on their question-response sequences, fine-grained interaction modeling between question-response pairs within each sequence is underexplored. This causes question-response representations less contextualized and further limits student modeling. To address this issue, we first conduct a data analysis and reveal the existence of complex cross effects between different question-response pairs within a sequence. Consequently, we propose MRT-KT, a multi-relational transformer for knowledge tracing, to enable fine-grained interaction modeling between question-response pairs. It introduces a novel relation encoding scheme based on knowledge concepts and student performance. Comprehensive experimental results show that MRT-KT outperforms state-of-the-art knowledge tracing methods on four widely-used datasets, validating the effectiveness of considering fine-grained interaction for knowledge tracing.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W4317433458",
    "type": "article"
  },
  {
    "title": "Efficient On-Device Session-Based Recommendation",
    "doi": "https://doi.org/10.1145/3580364",
    "publication_date": "2023-01-13",
    "publication_year": 2023,
    "authors": "Xin Xia; Junliang Yu; Qinyong Wang; Chaoqun Yang; Quoc Viet Hung Nguyen; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "On-device session-based recommendation systems have been achieving increasing attention on account of the low energy/resource consumption and privacy protection while providing promising recommendation performance. To fit the powerful neural session-based recommendation models in resource-constrained mobile devices, tensor-train decomposition and its variants have been widely applied to reduce memory footprint by decomposing the embedding table into smaller tensors, showing great potential in compressing recommendation models. However, these model compression techniques significantly increase the local inference time due to the complex process of generating index lists and a series of tensor multiplications to form item embeddings. The resultant on-device recommender fails to provide real-time responses and recommendations. To improve the online recommendation efficiency, we propose to learn compositional encoding-based compact item representations. Specifically, each item is represented by a compositional code that consists of several codewords, and we learn embedding vectors to represent each codeword instead of each item. Then the composition of the codeword embedding vectors from different embedding matrices (i.e., codebooks) forms the item embedding. Since the size of codebooks can be extremely small, the recommender model is thus able to fit in resource-constrained devices and save the codebooks for fast local inference. Besides, to prevent the loss of model capacity caused by compression, we propose a bidirectional self-supervised knowledge distillation framework. Extensive experimental results on two benchmark datasets demonstrate that compared with existing methods, the proposed on-device recommender not only achieves an 8x inference speedup with a large compression ratio but also shows superior recommendation performance. The code is released at https://github.com/xiaxin1998/EODRec.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W4315977643",
    "type": "article"
  },
  {
    "title": "A Variational Neural Architecture for Skill-based Team Formation",
    "doi": "https://doi.org/10.1145/3589762",
    "publication_date": "2023-04-04",
    "publication_year": 2023,
    "authors": "Radin Hamidi Rad; Hossein Fani; Ebrahim Bagheri; Mehdi Kargar; Divesh Srivastava; Jaroslaw Szlichta",
    "corresponding_authors": "",
    "abstract": "Team formation is concerned with the identification of a group of experts who have a high likelihood of effectively collaborating with each other to satisfy a collection of input skills. Solutions to this task have mainly adopted graph operations and at least have the following limitations: (1) they are computationally demanding, as they require finding shortest paths on large collaboration networks; (2) they use various types of heuristics to reduce the exploration space over the collaboration network to become practically feasible; therefore, their results are not necessarily optimal; and (3) they are not well-suited for collaboration network structures given the sparsity of these networks. Our work proposes a variational Bayesian neural network architecture that learns representations for teams whose members have collaborated with each other in the past. The learned representations allow our proposed approach to mine teams that have a past collaborative history and collectively cover the requested desirable set of skills. Through our experiments, we demonstrate that our approach shows stronger performance compared to a range of strong team formation techniques from both quantitative and qualitative perspectives.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W4362554832",
    "type": "article"
  },
  {
    "title": "Coarse-to-Fine Knowledge-Enhanced Multi-Interest Learning Framework for Multi-Behavior Recommendation",
    "doi": "https://doi.org/10.1145/3606369",
    "publication_date": "2023-06-28",
    "publication_year": 2023,
    "authors": "Chang Meng; Ziqi Zhao; Wei Guo; Yingxue Zhang; Haolun Wu; Chen Gao; Dong Li; Xiu Li; Ruiming Tang",
    "corresponding_authors": "",
    "abstract": "Multi-types of behaviors (e.g., clicking, carting, purchasing, etc.) widely exist in most real-world recommendation scenarios, which are beneficial to learn users’ multi-faceted preferences. As dependencies are explicitly exhibited by the multiple types of behaviors, effectively modeling complex behavior dependencies is crucial for multi-behavior prediction. The state-of-the-art multi-behavior models learn behavior dependencies indistinguishably with all historical interactions as input. However, different behaviors may reflect different aspects of user preference, which means that some irrelevant interactions may play as noises to the target behavior to be predicted. To address the aforementioned limitations, we introduce multi-interest learning to the multi-behavior recommendation. More specifically, we propose a novel Coarse-to-fine Knowledge-enhanced Multi-interest Learning (CKML) framework to learn shared and behavior-specific interests for different behaviors. CKML introduces two advanced modules, namely Coarse-grained Interest Extracting (CIE) and Fine-grained Behavioral Correlation (FBC) , which work jointly to capture fine-grained behavioral dependencies. CIE uses knowledge-aware information to extract initial representations of each interest. FBC incorporates a dynamic routing scheme to further assign each behavior among interests. Empirical results on three real-world datasets verify the effectiveness and efficiency of our model in exploiting multi-behavior data.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4382396965",
    "type": "article"
  },
  {
    "title": "Contextualized Knowledge Graph Embedding for Explainable Talent Training Course Recommendation",
    "doi": "https://doi.org/10.1145/3597022",
    "publication_date": "2023-08-08",
    "publication_year": 2023,
    "authors": "Yang Yang; Zhang Chubing; Xin Song; Zheng Dong; Hengshu Zhu; Wenjie Li",
    "corresponding_authors": "",
    "abstract": "Learning and development, or L&amp;D, plays an important role in talent management, which aims to improve the knowledge and capabilities of employees through a variety of performance-oriented training activities. Recently, with the rapid development of enterprise management information systems, many research efforts and industrial practices have been devoted to building personalized employee training course recommender systems. Nevertheless, a widespread challenge is how to provide explainable recommendations with the consideration of different learning motivations from talents. To this end, we propose CKGE, a contextualized knowledge graph (KG) embedding approach for developing an explainable training course recommender system. A novel perspective of CKGE is to integrate both the contextualized neighbor semantics and high-order connections as motivation-aware information for learning effective representations of talents and courses. Specifically, in CKGE, for each entity pair (i.e., the talent-course pair), we first construct a meta-graph, including the neighbors of each entity and the meta-paths between entities as motivation-aware information. Then, we develop a novel KG-based Transformer, which can serialize entities and paths in the meta-graph as a sequential input, with the specially designed relational attention and structural encoding mechanisms to better model the global dependence of KG structured data. Meanwhile, the local path mask prediction can effectively reveal the importance of different paths. As a result, CKGE not only can make precise predictions but also can discriminate the saliencies of meta-paths in characterizing corresponding preferences. Extensive experiments on real-world and public datasets clearly validate the effectiveness and interpretability of CKGE compared with state-of-the-art baselines.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4385658818",
    "type": "article"
  },
  {
    "title": "Retrieval for Extremely Long Queries and Documents with RPRS: A Highly Efficient and Effective Transformer-based Re-Ranker",
    "doi": "https://doi.org/10.1145/3631938",
    "publication_date": "2023-11-11",
    "publication_year": 2023,
    "authors": "Arian Askari; Suzan Verberne; Amin Abolghasemi; Wessel Kraaij; Gabriella Pasi",
    "corresponding_authors": "",
    "abstract": "Retrieval with extremely long queries and documents is a well-known and challenging task in information retrieval and is commonly known as Query-by-Document (QBD) retrieval. Specifically designed Transformer models that can handle long input sequences have not shown high effectiveness in QBD tasks in previous work. We propose a Re-Ranker based on the novel Proportional Relevance Score (RPRS) to compute the relevance score between a query and the top- k candidate documents. Our extensive evaluation shows RPRS obtains significantly better results than the state-of-the-art models on five different datasets. Furthermore, RPRS is highly efficient, since all documents can be pre-processed, embedded, and indexed before query time that gives our re-ranker the advantage of having a complexity of O(N) , where N is the total number of sentences in the query and candidate documents. Furthermore, our method solves the problem of the low-resource training in QBD retrieval tasks as it does not need large amounts of training data and has only three parameters with a limited range that can be optimized with a grid search even if a small amount of labeled data is available. Our detailed analysis shows that RPRS benefits from covering the full length of candidate documents and queries.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4388594219",
    "type": "article"
  },
  {
    "title": "The Impact of Judgment Variability on the Consistency of Offline Effectiveness Measures",
    "doi": "https://doi.org/10.1145/3596511",
    "publication_date": "2023-05-20",
    "publication_year": 2023,
    "authors": "Lida Rashidi; Justin Zobel; Alistair Moffat",
    "corresponding_authors": "",
    "abstract": "Measurement of the effectiveness of search engines is often based on use of relevance judgments. It is well known that judgments can be inconsistent between judges, leading to discrepancies that potentially affect not only scores but also system relativities and confidence in the experimental outcomes. We take the perspective that the relevance judgments are an amalgam of perfect relevance assessments plus errors; making use of a model of systematic errors in binary relevance judgments that can be tuned to reflect the kind of judge that is being used, we explore the behavior of measures of effectiveness as error is introduced. Using a novel methodology in which we examine the distribution of “true” effectiveness measurements that could be underlying measurements based on sets of judgments that include error, we find that even moderate amounts of error can lead to conclusions such as orderings of systems that statistical tests report as significant but are nonetheless incorrect. Further, in these results the widely used recall-based measures AP and NDCG are notably more fragile in the presence of judgment error than is the utility-based measure RBP, but all the measures failed under even moderate error rates. We conclude that knowledge of likely error rates in judgments is critical to interpretation of experimental outcomes.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4377140377",
    "type": "article"
  },
  {
    "title": "Counterfactual Explanation for Fairness in Recommendation",
    "doi": "https://doi.org/10.1145/3643670",
    "publication_date": "2024-01-29",
    "publication_year": 2024,
    "authors": "Xiangmeng Wang; Qian Li; Dianer Yu; Qing Li; Guandong Xu",
    "corresponding_authors": "",
    "abstract": "Fairness-aware recommendation alleviates discrimination issues to build trustworthy recommendation systems. Explaining the causes of unfair recommendations is critical, as it promotes fairness diagnostics, and thus secures users’ trust in recommendation models. Existing fairness explanation methods suffer high computation burdens due to the large-scale search space and the greedy nature of the explanation search process. Besides, they perform feature-level optimizations with continuous values, which are not applicable to discrete attributes such as gender and age. In this work, we adopt counterfactual explanations from causal inference and propose to generate attribute-level counterfactual explanations, adapting to discrete attributes in recommendation models. We use real-world attributes from Heterogeneous Information Networks (HINs) to empower counterfactual reasoning on discrete attributes. We propose a Counterfactual Explanation for Fairness (CFairER) that generates attribute-level counterfactual explanations from HINs for item exposure fairness. Our CFairER conducts off-policy reinforcement learning to seek high-quality counterfactual explanations, with attentive action pruning reducing the search space of candidate counterfactuals. The counterfactual explanations help to provide rational and proximate explanations for model fairness, while the attentive action pruning narrows the search space of attributes. Extensive experiments demonstrate our proposed model can generate faithful explanations while maintaining favorable recommendation performance.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4391323272",
    "type": "article"
  },
  {
    "title": "Average User-Side Counterfactual Fairness for Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3656639",
    "publication_date": "2024-04-11",
    "publication_year": 2024,
    "authors": "Pengyang Shao; Le Wu; Kun Zhang; Defu Lian; Richang Hong; Yong Li; Meng Wang",
    "corresponding_authors": "",
    "abstract": "Recently, the user-side fairness issue in Collaborative Filtering (CF) algorithms has gained considerable attention, arguing that results should not discriminate an individual or a sub-user group based on users’ sensitive attributes (e.g., gender). Researchers have proposed fairness-aware CF models by decreasing statistical associations between predictions and sensitive attributes. A more natural idea is to achieve model fairness from a causal perspective. The remaining challenge is that we have no access to interventions, i.e., the counterfactual world that produces recommendations when each user has changed the sensitive attribute value. To this end, we first borrow the Rubin-Neyman potential outcome framework to define average causal effects of sensitive attributes. Next, we show that removing causal effects of sensitive attributes is equal to average counterfactual fairness in CF. Then, we use the propensity re-weighting paradigm to estimate the average causal effects of sensitive attributes and formulate the estimated causal effects as an additional regularization term. To the best of our knowledge, we are one of the first few attempts to achieve counterfactual fairness from the causal effect estimation perspective in CF, which frees us from building sophisticated causal graphs. Finally, experiments on three real-world datasets show the superiority of our proposed model.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4394717863",
    "type": "article"
  },
  {
    "title": "Cooking with Conversation: Enhancing User Engagement and Learning with a Knowledge-Enhancing Assistant",
    "doi": "https://doi.org/10.1145/3649500",
    "publication_date": "2024-03-15",
    "publication_year": 2024,
    "authors": "Alexander Frummet; Alessandro Speggiorin; David Elsweiler; Anton Leuski; Jeff Dalton",
    "corresponding_authors": "",
    "abstract": "We present two empirical studies to investigate users’ expectations and behaviours when using digital assistants, such as Alexa and Google Home, in a kitchen context: First, a survey (N = 200) queries participants on their expectations for the kinds of information that such systems should be able to provide. While consensus exists on expecting information about cooking steps and processes, younger participants who enjoy cooking express a higher likelihood of expecting details on food history or the science of cooking. In a follow-up Wizard-of-Oz study (N = 48), users were guided through the steps of a recipe either by an active wizard that alerted participants to information it could provide or a passive wizard who only answered questions that were provided by the user. The active policy led to almost double the number of conversational utterances and 1.5 times more knowledge-related user questions compared to the passive policy. Also, it resulted in 1.7 times more knowledge communicated than the passive policy. We discuss the findings in the context of related work and reveal implications for the design and use of such assistants for cooking and other purposes such as DIY and craft tasks, as well as the lessons we learned for evaluating such systems.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4392864419",
    "type": "article"
  },
  {
    "title": "Multi-Behavior Recommendation with Personalized Directed Acyclic Behavior Graphs",
    "doi": "https://doi.org/10.1145/3696417",
    "publication_date": "2024-09-19",
    "publication_year": 2024,
    "authors": "Xi Zhu; Fake Lin; Ziwei Zhao; Tong Xu; Xiangyu Zhao; Zikai Yin; Xueying Li; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "A well-developed recommendation system can not only leverage multi-typed interactions (such as page view, add-to-cart, and purchase) to better identify user preferences, but also demonstrate high performance, low complexity, and strong interpretability. However, many existing solutions for multi-behavior recommendation fall short of intuitive modeling of real-world scenarios, leading to overly complex models with massive parameters and cumbersome components. In particular, they share two critical limitations: (1) Some pioneering models are built upon the strict assumption of cascade effects across behaviors, which contradicts multifarious behavior paths in practical applications. (2) Existing approaches fail to explicitly capture the unique idiosyncrasies of users and even neglect the inherent nature of items involved in the multi-behavior interactions. To this end, we propose a novel Directed Acyclic Graph Convolutional Network (DA-GCN) for the multi-behavior recommendation task. Specifically, we pinpoint the partial order relations within the monotonic behavior chain and extend it to personalized directed acyclic behavior graphs to exploit behavior dependencies. Then, a GCN-based directed edge encoder is employed to distill rich collaborative signals embodied by each directed edge. In light of the information flows over the directed acyclic structure, we propose an attentive aggregation module to gather messages from all potential antecedent behaviors, representing distinct perspectives to understand the terminated behavior. Thus, we obtain comprehensive representations for the follow-up behavior through learnable distributions over its preceding behaviors, explicitly reflecting personalized interactive patterns of users and underlying properties of items simultaneously. Finally, we design a customized multi-task learning objective for flexible joint optimization. Extensive experiments on public benchmarking datasets fully demonstrate the superiority of DA-GCN with significant performance improvement and computational efficiency over a wide range of state-of-the-art methods. Our code is available at https://github.com/xizhu1022/DA-GCN .",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4402639612",
    "type": "article"
  },
  {
    "title": "Post-Training Attribute Unlearning in Recommender Systems",
    "doi": "https://doi.org/10.1145/3701987",
    "publication_date": "2024-11-06",
    "publication_year": 2024,
    "authors": "Chaochao Chen; Yizhao Zhang; Yuyuan Li; Jun Wang; Lianyong Qi; Xiaolong Xu; Xiaolin Zheng; Jianwei Yin",
    "corresponding_authors": "",
    "abstract": "With the growing privacy concerns in recommender systems, recommendation unlearning is getting increasing attention. Existing studies predominantly use training data, i.e., model inputs, as unlearning target. However, attackers can extract private information from the model even if it has not been explicitly encountered during training. We name this unseen information as attribute and treat it as unlearning target. To protect the sensitive attribute of users, Attribute Unlearning (AU) aims to make target attributes indistinguishable. In this paper, we focus on a strict but practical setting of AU, namely Post-Training Attribute Unlearning (PoT-AU), where unlearning can only be performed after the training of the recommendation model is completed. To address the PoT-AU problem in recommender systems, we propose a two-component loss function. The first component is distinguishability loss, where we design a distribution-based measurement to make attribute labels indistinguishable from attackers. We further extend this measurement to handle multi-class attribute cases with efficient computational overhead. The second component is regularization loss, where we explore a function-space measurement that effectively maintains recommendation performance compared to parameter-space regularization. We use stochastic gradient descent algorithm to optimize our proposed loss. Extensive experiments on four real-world datasets demonstrate the effectiveness of our proposed methods.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4404108380",
    "type": "article"
  },
  {
    "title": "User Behavior Simulation with Large Language Model-based Agents for Recommender Systems",
    "doi": "https://doi.org/10.1145/3708985",
    "publication_date": "2024-12-20",
    "publication_year": 2024,
    "authors": "Lei Wang; Jingsen Zhang; Hao Yang; Z. P. Chen; Jiakai Tang; Zeyu Zhang; Xu Chen; Yankai Lin; Hao Sun; Ruihua Song; Wayne Xin Zhao; Jun Xu; Zhicheng Dou; Jun Wang; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Simulating high quality user behavior data has always been a fundamental yet challenging problem in human-centered applications such as recommendation systems, social networks, among many others. The major difficulty of user behavior simulation originates from the intricate mechanism of human cognitive and decision processes. Recently, substantial evidence have suggested that by learning huge amounts of web knowledge, large language models (LLMs) can achieve human-like intelligence and generalization capabilities. Inspired by such capabilities, in this paper, we take an initial step to study the potential of using LLMs for user behavior simulation in the recommendation domain. To make LLMs act like humans, we design profile, memory and action modules to equip them, building LLM-based agents to simulate real users. To enable interactions between different agents and observe their behavior patterns, we design a sandbox environment, where each agent can interact with the recommendation system, and different agents can converse with their friends via one-to-one chatting or one-to-many social broadcasting. In the experiments, we first demonstrate the believability of the agent-generated behaviors based on both subjective and objective evaluations. Then, to show the potential applications of our method, we simulate and study two social phenomenons including (1) information cocoons and (2) user conformity behaviors. We find that controlling the personalization degree of recommendation algorithms and improving the heterogeneity of user social relations can be two effective strategies for alleviating the problem of information cocoon, and the conformity behaviors can be highly influenced by the amount of user social relations. To advance this direction, we have released our project at https://github.com/RUC-GSAI/YuLan-Rec .",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4405643789",
    "type": "article"
  },
  {
    "title": "Inter- and Intra- Similarity Preserved Counterfactual Incentive Effect Estimation for Recommendation Systems",
    "doi": "https://doi.org/10.1145/3722104",
    "publication_date": "2025-03-06",
    "publication_year": 2025,
    "authors": "Fan Wang; Lianyong Qi; Weiming Liu; Bowen Yu; Jintao Chen; Yanwei Xu",
    "corresponding_authors": "",
    "abstract": "Personalized incentives are crucial for boosting user engagement and increasing platform revenues. Many studies have utilized uplift modeling to estimate the conditional average treatment effects (CATEs) of incentives and then allocate them under cost constraints. However, identifying which users should receive such incentives remains challenging, posing a selection bias problem. Traditional representation-based approaches mitigate bias by balancing treated and controlled distributions but overlook local similarity information. Recognizing that similar users should exhibit similar outcomes, it is vital to preserve both intra-similarity within treatment groups and inter-similarity between covariate and representation spaces. Moreover, existing methods primarily focus on CATE accuracy, neglecting the ranking ability vital for uplift modeling. We propose the Similarity Preserved Counterfactual Incentive Effect Estimation ( S-CIEE ) method, comprising three modules: (1) an Intra-Similarity Preservation Regularizer via Fused Gromov-Wasserstein Optimal Transport, (2) an Inter-Similarity Preservation Regularizer using a similarity constraint, and (3) a Rank-Aware Learning module for uplift ranking. Comprehensive experiments on one semi-synthetic and two real-world datasets show S-CIEE improves both CATE accuracy and uplift modeling performance.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4408188391",
    "type": "article"
  },
  {
    "title": "Debiased Recommendation via Wasserstein Causal Balancing",
    "doi": "https://doi.org/10.1145/3725731",
    "publication_date": "2025-06-16",
    "publication_year": 2025,
    "authors": "Hao Wang; Zhichao Chen; Honglei Zhang; Zhengnan Li; Licheng Pan; Haoxuan Li; Mingming Gong",
    "corresponding_authors": "",
    "abstract": "Recommendation systems are pivotal in improving user experience on various digital platforms. However, observational training data in recommendation systems introduce selection bias, which leads to a distributional discrepancy between training data and real-world scenarios, resulting in suboptimal performance. Current causal debiasing methods such as inverse propensity score and doubly robust rely on accurately estimated propensity scores, typically optimized through negative log-likelihood (NLL) minimization. However, recent studies have highlighted the limitations of this approach, as perfect NLL minimization may not adequately correct for selection bias. To address this issue, we propose Wasserstein Balancing Metric (WBM), a novel metric that measures and enhances the balancing capacity of propensity scores in causal debiasing methods by minimizing the Wasserstein discrepancy between reweighted populations. On the basis, we introduce IPS-WBM and DR-WBM, incorporating WBM as a regularizer in standard inverse propensity score and doubly robust estimators, which enhances causal balancing capacity without introducing additional bias. Extensive experiments on three real-world recommendation datasets demonstrate that our methods improve the causal balancing capability of learned propensities and enhance debiasing performance.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4411346340",
    "type": "article"
  },
  {
    "title": "A flexible authorization mechanism for relational data management systems",
    "doi": "https://doi.org/10.1145/306686.306687",
    "publication_date": "1999-04-01",
    "publication_year": 1999,
    "authors": "Elisa Bertino; Sushil Jajodia; Pierangela Samarati",
    "corresponding_authors": "",
    "abstract": "In this article, we present an authorization model that can be used to express a number of discretionary access control policies for relational data management systems. The model permits both positive and negative authorizations and supports exceptions at the same time. The model is flexible in that the users can specify, for each authorization they grant, whether the authorization can allow for exceptions or whether it must be strongly obeyed. It provides authorization management for groups with exceptions at any level of the group hierarchy, and temporary suspension of authorizations. The model supports ownership together with decentralized administration of authorizations. Administrative privileges can also be restricted so that owners retain control over their tables.",
    "cited_by_count": 130,
    "openalex_id": "https://openalex.org/W2040830570",
    "type": "article"
  },
  {
    "title": "Methods for information server selection",
    "doi": "https://doi.org/10.1145/297117.297123",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "David Hawking; Paul B. Thistlewaite",
    "corresponding_authors": "",
    "abstract": "The problem of using a broker to select a subset of available information servers in order to achieve a good trade-off between document retrieval effectiveness and cost is addressed. Server selection methods which are capable of operating in the absence of global information, and where servers have no knowledge of brokers, are investigated. A novel method using Lightweight Probe queries (LWP method) is compared with several methods based on data from past query processing, while Random and Optimal server rankings serve as controls. Methods are evaluated, using TREC data and relevance judgments, by computing ratios, both empirical and ideal, of recall and early precision for the subset versus the complete set of available servers. Estimates are also made of the best-possible performance of each of the methods. LWP and Topic Similarity methods achieved best results, each being capable of retrieving about 60% of the relevant documents for only one-third of the cost of querying all servers. Subject to the applicable cost model, the LWP method is likely to be preferred because it is suited to dynamic environments. The good results obtained with a simple automatic LWP implementation were replicated using different data and a larger set of query topics.",
    "cited_by_count": 125,
    "openalex_id": "https://openalex.org/W2125725207",
    "type": "article"
  },
  {
    "title": "Metric details for natural-language spatial relations",
    "doi": "https://doi.org/10.1145/291128.291129",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "Max J. Egenhofer; Abdul Rashid Mohamed Shariff",
    "corresponding_authors": "",
    "abstract": "Spatial relations often are desired answers that a geographic information system (GIS) should generate in response to a user's query. Current GIS's provide only rudimentary support for processing and interpreting natural-language-like spatial relations, because their models and representations are primarily quantitative, while natural-language spatial relations are usually dominated by qualitative properties. Studies of the use of spatial relations in natural language showed that topology accounts for a significant portion of the geometric properties. This article develops a formal model that captures metric details for the description of natural-language spatial relations. The metric details are expressed as refinements of the categories identified by the 9-intersection, a model for topological spatial relations, and provide a more precise measure than does topology alone as to whether a geometric configuration matches with a spatial term or not. Similarly, these measures help in identifying the spatial term that describes a particular configuration. Two groups of metric details are derived: splitting ratios as the normalized values of lengths and areas of intersections; and closeness measures as the normalized distances between disjoint object parts. The resulting model of topological and metric properties was calibrated for 64 spatial terms in English, providing values for the best fit as well as value ranges for the significant parameters of each term. Three examples demonstrate how the framework and its calibrated values are used to determine the best spatial term for a relationship between two geometric objects.",
    "cited_by_count": 119,
    "openalex_id": "https://openalex.org/W2015428026",
    "type": "article"
  },
  {
    "title": "Coverage, relevance, and ranking",
    "doi": "https://doi.org/10.1145/944012.944015",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Caroline M. Eastman; Bernard J. Jansen",
    "corresponding_authors": "",
    "abstract": "Research has reported that about 10% of Web searchers utilize advanced query operators, with the other 90% using extremely simple queries. It is often assumed that the use of query operators, such as Boolean operators and phrase searching, improves the effectiveness of Web searching. We test this assumption by examining the effects of query operators on the performance of three major Web search engines. We selected one hundred queries from the transaction log of a Web search service. Each of these original queries contained query operators such as AND, OR, MUST APPEAR (+), or PHRASE (\" \"). We then removed the operators from these one hundred advanced queries. We submitted both the original and modified queries to three major Web search engines; a total of 600 queries were submitted and 5,748 documents evaluated. We compared the results from the original queries with the operators to the results from the modified queries without the operators. We examined the results for changes in coverage, relative precision, and ranking of relevant documents. The use of most query operators had no significant effect on coverage, relative precision, or ranking, although the effect varied depending on the search engine. We discuss implications for the effectiveness of searching techniques as currently taught, for future information retrieval system design, and for future research.",
    "cited_by_count": 118,
    "openalex_id": "https://openalex.org/W2149600263",
    "type": "article"
  },
  {
    "title": "WebQuilt: A Proxy-based Approach to Remote Web Usability Testing",
    "doi": null,
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Jason Hong; Jeffrey Heer; Sarah Waterson; James A. Landay",
    "corresponding_authors": "",
    "abstract": "WebQuilt is a web logging and visualization system that helps web design teams run usability tests (both local and remote) and analyze the collected data. Logging is done through a proxy, overcoming many of the problems with server-side and client-side logging. Captured usage traces can be aggregated and visualized in a zooming interface that shows the web pages people viewed. The visualization also shows the most common paths taken through the web site for a given task, as well as the optimal path for that task, as designated by the designer. This paper discusses the architecture of WebQuilt and describes how it can be extended for new kinds of analyses and visualizations.",
    "cited_by_count": 114,
    "openalex_id": "https://openalex.org/W2001051966",
    "type": "article"
  },
  {
    "title": "On automated message processing in electronic commerce and work support systems",
    "doi": "https://doi.org/10.1145/263479.263480",
    "publication_date": "1997-10-01",
    "publication_year": 1997,
    "authors": "Steven O. Kimbrough; Scott A. Moore",
    "corresponding_authors": "",
    "abstract": "Electronic messaging, whether in an office environment or for electronic commerce, is normally carried out in natural language, even when supported by information systems. For a variety of reasons, it would be useful if electronic messaging systems could have semantic access to, that is, access to the meanings and contents of, the messages they process. Given that natural language understanding is not a practicable alternative, there remain three approaches to delivering systems with semantic access: electronic data interchange (EDI), tagged messages, and the development of a formal language for business communication (FLBC). We favor the latter approach. In this article we compare and contrast these three approaches, present a theoretical basis for an FLBC (using speech act theory), and describe a prototype implementation.",
    "cited_by_count": 112,
    "openalex_id": "https://openalex.org/W1977281680",
    "type": "article"
  },
  {
    "title": "Partially shared views: a scheme for communicating among groups that use different type hierarchies",
    "doi": "https://doi.org/10.1145/78915.78916",
    "publication_date": "1990-01-03",
    "publication_year": 1990,
    "authors": "Jintae Lee; Thomas W. Malone",
    "corresponding_authors": "",
    "abstract": "Many computer systems are based on various types of messages, forms, or other objects. When users of such systems need to communicate with people who use different object types, some kind of translation is necessary. In this paper, we explore the space of general solutions to this translation problem and propose a scheme that synthesizes these solutions. After first illustrating the problem in the Object Lens system, we identify two partly conflicting objectives that any translation scheme should satisfy: preservation of meaning and autonomous evolution of group languages. Then we partition the space of possible solutions to this problem in terms of the set theoretic relations between group languages and a common language. This leads to five primary solution classes and we illustrate and evaluate each one. Finally, we describe a composite scheme, called Partially Shared Views, that combines many of the best features of the other schemes. A key insight of the analysis is that partially shared type hierarchies allow “foreign” object types to be automatically translated into their nearest common “ancestor” types. The partial interoperability attained in this way makes possible flexible standards from which people can benefit from whatever agreements they do have without having to agree on everything. Even though our examples deal primarily with extensions to the Object Lens system, the analysis also suggests how other kinds of systems, such as EDI applications, might exploit specialization hierarchies of object types to simplify the translation problem.",
    "cited_by_count": 112,
    "openalex_id": "https://openalex.org/W2040731343",
    "type": "article"
  },
  {
    "title": "Interface and data architecture for query preview in networked information systems",
    "doi": "https://doi.org/10.1145/314516.314522",
    "publication_date": "1999-07-01",
    "publication_year": 1999,
    "authors": "Catherine Plaisant; Ben Shneiderman; Khoa Doan; Tom Bruns",
    "corresponding_authors": "",
    "abstract": "There are numerous problems associated with formulating queries on networked information systems. These include increased data volume and complexity, accompanied by slow network access. This article proposes a new approach to a network query user interfaces that consists of two phases: query preview and query refinement. This new approach is based on the concepts of dynamic queries and query previews, which guides users in rapidly and dynamically eliminating undesired records, reducing the data volume to a manageable size, and refining queries locally before submission over a network. Examples of two applications are given: a Restaurant Finder and a prototype for NASA's Earth Observing Systems Data Information Systems (EOSDIS). Data architecture is discussed, and user feedback is presented.",
    "cited_by_count": 111,
    "openalex_id": "https://openalex.org/W2039986606",
    "type": "article"
  },
  {
    "title": "Query processing in a multimedia document system",
    "doi": "https://doi.org/10.1145/42279.42281",
    "publication_date": "1988-01-01",
    "publication_year": 1988,
    "authors": "Elisa Bertino; Fausto Rabbiti; Simon Gibbs",
    "corresponding_authors": "",
    "abstract": "Query processing in a multimedia document system is described. Multimedia documents are information objects containing formatted data, text, image, graphics, and voice. The query language is based on a conceptual document model that allows the users to formulate queries on both document content and structure. The architecture of the system is outlined, with focus on the storage organization in which both optical and magnetic devices can coexist. Query processing and the different strategies evaluated by our optimization algorithm are discussed.",
    "cited_by_count": 106,
    "openalex_id": "https://openalex.org/W2067301867",
    "type": "article"
  },
  {
    "title": "Design of the Mneme persistent object store",
    "doi": "https://doi.org/10.1145/96105.96109",
    "publication_date": "1990-04-01",
    "publication_year": 1990,
    "authors": "J. Eliot B. Moss",
    "corresponding_authors": "J. Eliot B. Moss",
    "abstract": "The Mneme project is an investigation of techniques for integrating programming language and database features to provide better support for cooperative, information-intensive tasks such as computer-aided software engineering. The project strategy is to implement efficient, distributed, persistent programming languages. We report here on the Mneme persistent object store, a fundamental component of the project, discussing its design and initial prototype. Mneme stores objects in a simple and general format, preserving object identity and object interrelationships. Specific goals for the store include portability, extensibility (especially with respect to object management policies), and performance. The model of memory that the store aims at is a single, cooperatively-shared heap, distributed across a collection of networked computers. The initial prototype is intended mainly to explore performance issues and to support object-oriented persistent programming languages. We include performance measurements from the prototype as well as more qualitative results.",
    "cited_by_count": 105,
    "openalex_id": "https://openalex.org/W1967998883",
    "type": "article"
  },
  {
    "title": "New techniques for best-match retrieval",
    "doi": "https://doi.org/10.1145/96105.96111",
    "publication_date": "1990-04-01",
    "publication_year": 1990,
    "authors": "Dennis Shasha; Tsong-Li Wang",
    "corresponding_authors": "",
    "abstract": "A scheme to answer best-match queries from a file containing a collection of objects is described. A best-match query is to find the objects in the file that are closest (according to some (dis)similarity measure) to a given target. Previous work [5, 331] suggests that one can reduce the number of comparisons required to achieve the desired results using the triangle inequality, starting with a data structure for the file that reflects some precomputed intrafile distances. We generalize the technique to allow the optimum use of any given set of precomputed intrafile distances. Some empirical results are presented which illustrate the effectiveness of our scheme, and its performance relative to previous algorithms.",
    "cited_by_count": 103,
    "openalex_id": "https://openalex.org/W1982524776",
    "type": "article"
  },
  {
    "title": "A video retrieval and sequencing system",
    "doi": "https://doi.org/10.1145/211430.211431",
    "publication_date": "1995-10-01",
    "publication_year": 1995,
    "authors": "Tat‐Seng Chua; Li-Qun Ruan",
    "corresponding_authors": "",
    "abstract": "Video is an effective medium for capturing the events in the real world around us, and a vast amount of video materials exists, covering a wide range of applications. However, widespread use of video in computer applications is often impeded by the lack of effective tools to manage video information systematically. This article discusses the design and implementation of a frame-based video retrieval and sequencing system (VRSS). The system is designed to support the entire process of video information management: segmenting, indexing, retrieving, and sequencing of video data. A semiautomatic tool is developed to divide video sequences into meaningful shots. Each video shot is logged using text descriptions, audio dialogue, and cinematic attributes. A two-layered, concept-based model is used as the basis for accurately retrieving relevant video shots based on users' free-text queries. A cinematic, rule-based, virtual editing tool is also developed to sequence the video shots retrieved for presentation within a specified time constraint. The system has been tested on a video documentary on the NUS (National University of Singapore) engineering faculty. The results of video retrieval experiments are encouraging.",
    "cited_by_count": 102,
    "openalex_id": "https://openalex.org/W1996204097",
    "type": "article"
  },
  {
    "title": "A prototype electronic encyclopedia",
    "doi": "https://doi.org/10.1145/3864.3865",
    "publication_date": "1985-01-02",
    "publication_year": 1985,
    "authors": "Stephen A. Weyer; Alan Borning",
    "corresponding_authors": "",
    "abstract": "We describe a prototype electronic encyclopedia implemented on a powerful personal computer, in which user interface, media presentation, and knowledge representation techniques are applied to improving access to a knowledge resource. In itself, an electronic encyclopedia is an important information resource, but this work also illustrates the issues and approaches for many types of electronic information retrieval environments. In the prototype we make dynamic use of the structure and semantics of the text articles and index of an existing encyclopedia, while experimenting with other forms of representation, such as simulation and videodisc images. We present a long-term vision of an intelligent user-interface agent; summarize previous work related to futuristic encyclopedias, electronic books, decision support systems, and knowledge libraries; and outline current and potential research directions.",
    "cited_by_count": 101,
    "openalex_id": "https://openalex.org/W2044710750",
    "type": "article"
  },
  {
    "title": "A semantic network-based design methodology for XML documents",
    "doi": "https://doi.org/10.1145/582415.582417",
    "publication_date": "2002-10-01",
    "publication_year": 2002,
    "authors": "Ling Feng; Elizabeth Chang; Tharam S. Dillon",
    "corresponding_authors": "",
    "abstract": "The eXtensible Markup Language (XML) is fast emerging as the dominant standard for describing and interchanging data among various systems and databases on the Internet. It offers the Document Type Definition (DTD) as a formalism for defining the syntax and structure of XML documents. The XML Schema definition language, as a replacement for the DTD, provides more rich facilities for defining and constraining the content of XML documents. However, it does not concentrate on the semantics that underlies these documents, representing a logical data model rather than a conceptual model. To enable efficient business application development in large-scale electronic commerce environments, it is necessary to describe and model real-world data semantics and their complex interrelationships. In this article, we describe a design methodology for XML documents. The aim is to enforce XML conceptual modeling power and bridge the gap between software development and XML document structures. The proposed methodology is comprised of two design levels: the semantic level and the schema level . The first level is based on a semantic network, which provides semantic modeling of XML through four major components: a set of atomic and complex nodes, representing real-world objects; a set of directed edges, representing semantic relationships between the objects; a set of labels denoting different types of semantic relationships, including aggregation, generalization, association , and of-property relationships; and finally a set of constraints defined over nodes and edges to constrain semantic relationships and object domains. The other level of the proposed methodology is concerned with detailed XML schema design, including element/attribute declarations and simple/complex type definitions . The mapping between the two design levels is proposed to transform the XML semantic model into the XML Schema, based on which XML documents can be systematically created, managed, and validated.",
    "cited_by_count": 101,
    "openalex_id": "https://openalex.org/W2113655056",
    "type": "article"
  },
  {
    "title": "An efficient normalized maximum likelihood algorithm for DNA sequence compression",
    "doi": "https://doi.org/10.1145/1055709.1055711",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Gergely Korodi; Ioan Tăbuş",
    "corresponding_authors": "",
    "abstract": "This article presents an efficient algorithm for DNA sequence compression, which achieves the best compression ratios reported over a test set commonly used for evaluating DNA compression programs. The algorithm introduces many refinements to a compression method that combines: (1) encoding by a simple normalized maximum likelihood (NML) model for discrete regression, through reference to preceding approximate matching blocks, (2) encoding by a first order context coding and (3) representing strings in clear, to make efficient use of the redundancy sources in DNA data, under fast execution times. One of the main algorithmic features is the constraint on the matching blocks to include reasonably long contiguous matches, which not only reduces significantly the search time, but also can be used to modify the NML model to exploit the constraint for getting smaller code lengths. The algorithm handles the changing statistics of DNA data in an adaptive way and by predictively encoding the matching pointers it is successful in compressing long approximate matches. Apart from comparison with previous DNA encoding methods, we present compression results for the recently published human genome data.",
    "cited_by_count": 99,
    "openalex_id": "https://openalex.org/W2090667881",
    "type": "article"
  },
  {
    "title": "Evaluating hypermedia and learning",
    "doi": "https://doi.org/10.1145/174608.174609",
    "publication_date": "1994-01-02",
    "publication_year": 1994,
    "authors": "Gary Marchionini; Gregory Crane",
    "corresponding_authors": "",
    "abstract": "The Perseus Project has developed a hypermedia corpus of materials related to the ancient Greek world. The materials include a variety of texts and images, and tools for using these materials and navigating the sytem. Results from a three-year evaluation of Perseus use in a variety of college settings are described. The evaluation assessed both this particular system and the application of the technological genre to information management and to learning. The evaluation used a variety of methods to address questions about learning and teaching with hypermedia and to guide the development of early versions of the system. Results illustrate that such environments offer potential for accelerating learning and for supporting new types of learning and teaching; that students and instructors must develop new strategies for learning and teaching with such technology; and that institutions must develop infrastructural support for such technology. The results also illustrate the importance of well-designed interfaces and different types of assignments on user performance.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W1976350025",
    "type": "article"
  },
  {
    "title": "A rule-based message filtering system",
    "doi": "https://doi.org/10.1145/45945.214327",
    "publication_date": "1988-07-01",
    "publication_year": 1988,
    "authors": "Stephen M. Pollock",
    "corresponding_authors": "Stephen M. Pollock",
    "abstract": "Much computerized support for knowledge workers has consisted of tools to handle low-level functions such as distribution, storage, and retrieval of information. However, the higher level processes of making decisions and taking actions with respect to this information have not been supported to the same degree. This paper describes the ISCREEN prototype system for screening text messages. ISCREEN includes a high-level interface for users to define rules, a component that screens text messages, and a conflict detection component that examines rules for inconsistencies. An explanation component uses text generation to answer user queries about past or potential system actions based on Grice's conversational maxims.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W2019580127",
    "type": "article"
  },
  {
    "title": "Project Nick: meetings augmentation and analysis",
    "doi": "https://doi.org/10.1145/27636.27638",
    "publication_date": "1987-04-01",
    "publication_year": 1987,
    "authors": "Peter J. Cook; Clarence A. Ellis; Mike Graf; Gail L. Rein; Tom E. C. Smith",
    "corresponding_authors": "",
    "abstract": "The Software Technology Program of MCC is investigating the early part of the design process, before requirements are established, for large-scale distributed systems. Face-to-face meetings are an important activity during this phase of a project since they provide a medium for direction, exploration, and consensus building. Project Nick is attempting to apply automated facilities to the process, conduct, and semantic capture of design meetings. Primary topics covered in this paper are meeting analysis, meeting augmentation, and a model of meeting progression that serves as the framework for our work.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W2067882823",
    "type": "article"
  },
  {
    "title": "Work at home for computer professionals: current attitudes and future prospects",
    "doi": "https://doi.org/10.1145/76158.76891",
    "publication_date": "1989-10-01",
    "publication_year": 1989,
    "authors": "Margrethe H. Olson",
    "corresponding_authors": "Margrethe H. Olson",
    "abstract": "The subject of this paper is work performed in the home with computer and communications technology, also known as telecommuting . The article reports on two studies of work at home: a quasi-experimental field study of organizational telecommuting pilot programs, and an attitude survey comparing computer professionals who work at home to employees doing similar jobs in traditional office settings. The results of the field study demonstrated that working in the home had little impact on employee performance; however, supervisors were not comfortable with remote workers and preferred their employees to be on site. In the survey, work in the home was related to lower job satisfaction, lower organizational commitment, and higher role conflict. The survey also included computer professionals who worked at home in addition to the regular work day. The author suggests that performing additional unpaid work in the home after regular work hours may be an important trend that merits further investigation. The studies demonstrate that while computer and communications technology have the potential to relax constraints on information work in terms of space and time, in today's traditional work environments, corporate culture and management style limit acceptance of telecommuting as a substitute for office work.",
    "cited_by_count": 97,
    "openalex_id": "https://openalex.org/W2115516886",
    "type": "article"
  },
  {
    "title": "An exploratory evaluation of three interfaces for browsing large hierarchical tables of contents",
    "doi": "https://doi.org/10.1145/185462.185483",
    "publication_date": "1994-10-01",
    "publication_year": 1994,
    "authors": "Richard Chimera; Ben Shneiderman",
    "corresponding_authors": "",
    "abstract": "Three different interfaces were used to browse a large (1296 items) table of contents. A fully expanded stable interface, expand/contract interface, and multipane interface were studied in a between-groups experiment with 41 novice participants. Nine timed fact retrieval tasks were performed; each task is analyzed and discussed separately. We found that both the expand/contract and multipane interfaces produced significantly faster times than the stable interface for many tasks using this large hierarchy; other advantages of the expand/contract and multipane interfaces over the stable interface are discussed. The animation characteristics of the expand/contract interface appear to play a major role. Refinements to the multipane and expand/contract interfaces are suggested. A predictive model for measuring navigation effort of each interface is presented.",
    "cited_by_count": 97,
    "openalex_id": "https://openalex.org/W2137009113",
    "type": "article"
  },
  {
    "title": "Interactive specification of flexible user interface displays",
    "doi": "https://doi.org/10.1145/98188.98201",
    "publication_date": "1990-07-01",
    "publication_year": 1990,
    "authors": "Scott E. Hudson; Shamim P. Mohamed",
    "corresponding_authors": "",
    "abstract": "One of the problems with conventional UIMSs is that very often there is no graphical way to specify interfaces. This paper describes OPUS , the user interface editor of the Penguims UIMS. This system allows the presentation component of graphical user interfaces to be specified interactively in a graphical notation without explicit programming. The Penguims UIMS supports an underlying model of computation based loosely on spreadsheets. In particular, it supports incremental computations based on a system of equations (one-way constraints) over a set of named values (spreadsheet cells). These equations are used to provide immediate feedback at all levels of the interface. They are used to incrementally determine the position and dynamic appearance of the individual interactor objects that make up the interface. They are also used to connect the presentation directly to underlying application data thereby supporting semantic feedback. The OPUS user interface editor employs a special graphical notation for specifying the presentation component of a user interface. This notation allows the power of the underlying computational model to be expressed simply and quickly. The resulting presentations are very flexible in nature. They can automatically respond to changes in the size and position of display objects and can directly support derivation of their appearance from application data objects.",
    "cited_by_count": 96,
    "openalex_id": "https://openalex.org/W2066419381",
    "type": "article"
  },
  {
    "title": "Fast phrase querying with combined indexes",
    "doi": "https://doi.org/10.1145/1028099.1028102",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "Hugh Williams; Justin Zobel; Dirk Bahle",
    "corresponding_authors": "",
    "abstract": "Search engines need to evaluate queries extremely fast, a challenging task given the quantities of data being indexed. A significant proportion of the queries posed to search engines involve phrases. In this article we consider how phrase queries can be efficiently supported with low disk overheads. Our previous research has shown that phrase queries can be rapidly evaluated using nextword indexes, but these indexes are twice as large as conventional inverted files. Alternatively, special-purpose phrase indexes can be used, but it is not feasible to index all phrases. We propose combinations of nextword indexes and phrase indexes with inverted files as a solution to this problem. Our experiments show that combined use of a partial nextword, partial phrase, and conventional inverted index allows evaluation of phrase queries in a quarter the time required to evaluate such queries with an inverted file alone; the additional space overhead is only 26% of the size of the inverted file.",
    "cited_by_count": 94,
    "openalex_id": "https://openalex.org/W1981732427",
    "type": "article"
  },
  {
    "title": "Communications design for Co-oP: a group decision support system",
    "doi": "https://doi.org/10.1145/6168.6169",
    "publication_date": "1986-04-01",
    "publication_year": 1986,
    "authors": "Tung Bui; Matthias Jarke",
    "corresponding_authors": "",
    "abstract": "Decision Support Systems (DSSs), computer-based systems intended to assist managers in preparing and analyzing decisions, have been single-user systems for most of the past decade. Only recently has DSS research begun to study the implications of the fact that most complex managerial decisions involve multiple decision makers and analysts. A number of tools for facilitating group decisions have been proposed under the label Group Decision Support Systems (GDSSs). One of the most important functions of a GDSS is to provide problem-oriented services for communication among decision makers. On the basis of an analysis of the communication requirements in various group decision settings, this paper presents an architecture for defining and enforcing dynamic application-level protocols that organize decision group interaction. The architecture has been implemented on a network of personal computers in Co-oP, a GDSS for cooperative group decision making based on interactive, multiple-criteria decision methods.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W2091184160",
    "type": "article"
  },
  {
    "title": "An algebra for structured office documents",
    "doi": "https://doi.org/10.1145/65935.65939",
    "publication_date": "1989-04-01",
    "publication_year": 1989,
    "authors": "Ralf Hartmut Güting; Roberto V. Zicari; David M. Choy",
    "corresponding_authors": "",
    "abstract": "We describe a data model for structured office information objects, which we generically call “documents,” and a practically useful algebraic language for the retrieval and manipulation of such objects. Documents are viewed as hierarchical structures; their layout (presentation) aspect is to be treated separately. The syntax and semantics of the language are defined precisely in terms of the formal model, an extended relational algebra. The proposed approach has several new features, some of which are particularly useful for the management of office information. The data model is based on nested sequences of tuples rather than nested relations. Therefore, sorting and sequence operations and the explicit handling of duplicates can be described by the model. Furthermore, this is the first model based on a many-sorted instead of a one-sorted algebra, which means that atomic data values as well as nested structures are objects of the algebra. As a consequence, arithmetic operations, aggregate functions, and so forth can be treated inside the model and need not be introduced as query language extensions to the model. Many-sorted algebra also allows arbitrary algebra expressions (with Boolean result) to be admitted as selection or join conditions and the results of arbitrary expressions to be embedded into tuples. In contrast to other formal models, this algebra can be used directly as a rich query language for office documents with precisely defined semantics.",
    "cited_by_count": 91,
    "openalex_id": "https://openalex.org/W2049652711",
    "type": "article"
  },
  {
    "title": "Interface design and multivariate analysis of UNIX command use",
    "doi": "https://doi.org/10.1145/357417.357421",
    "publication_date": "1984-01-01",
    "publication_year": 1984,
    "authors": "Stephen José Hanson; Robert E. Kraut; James M. Farber",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Interface design and multivariate analysis of UNIX command use Authors: Stephen José Hanson 3D-468 (of the Bell Operating Co.) CSO, Murray Hill, NJ 3D-468 (of the Bell Operating Co.) CSO, Murray Hill, NJView Profile , Robert E. Kraut 3D-551 (of the Bell Operating Co.) CSO, Murray Hill, NJ 3D-551 (of the Bell Operating Co.) CSO, Murray Hill, NJView Profile , James M. Farber 3J-319, AT&T Information Systems Laboratories, Lincroft, NJ 3J-319, AT&T Information Systems Laboratories, Lincroft, NJView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 1Jan. 1984 pp 42–57https://doi.org/10.1145/357417.357421Online:01 January 1984Publication History 65citation694DownloadsMetricsTotal Citations65Total Downloads694Last 12 Months18Last 6 weeks5 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W2056685268",
    "type": "article"
  },
  {
    "title": "Inter-organization networks, computer integration, and shifts in interdependence",
    "doi": "https://doi.org/10.1145/119311.119314",
    "publication_date": "1991-10-01",
    "publication_year": 1991,
    "authors": "Paul Hart; Deborah Estrin",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Inter-organization networks, computer integration, and shifts in interdependence: the case of the semiconductor industry Authors: Paul Hart Florida Atlantic Univ., Boca Raton Florida Atlantic Univ., Boca RatonView Profile , Deborah Estrin Univ. of Southern California, Los Angeles Univ. of Southern California, Los AngelesView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 9Issue 4pp 370–398https://doi.org/10.1145/119311.119314Published:01 October 1991Publication History 63citation1,052DownloadsMetricsTotal Citations63Total Downloads1,052Last 12 Months33Last 6 weeks3 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W2169657404",
    "type": "article"
  },
  {
    "title": "Unified relevance models for rating prediction in collaborative filtering",
    "doi": "https://doi.org/10.1145/1361684.1361689",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Jun Wang; Arjen P. de Vries; Marcel Reinders",
    "corresponding_authors": "",
    "abstract": "Collaborative filtering aims at predicting a user's interest for a given item based on a collection of user profiles. This article views collaborative filtering as a problem highly related to information retrieval, drawing an analogy between the concepts of users and items in recommender systems and queries and documents in text retrieval. We present a probabilistic user-to-item relevance framework that introduces the concept of relevance into the related problem of collaborative filtering. Three different models are derived, namely, a user-based , an item-based , and a unified relevance model , and we estimate their rating predictions from three sources: the user's own ratings for different items, other users' ratings for the same item, and ratings from different but similar users for other but similar items. To reduce the data sparsity encountered when estimating the probability density function of the relevance variable, we apply the nonparametric (data-driven) density estimation technique known as the Parzen-window method (or kernel-based density estimation). Using a Gaussian window function, the similarity between users and/or items would, however, be based on Euclidean distance. Because the collaborative filtering literature has reported improved prediction accuracy when using cosine similarity, we generalize the Parzen-window method by introducing a projection kernel . Existing user-based and item-based approaches correspond to two simplified instantiations of our framework. User-based and item-based collaborative filterings represent only a partial view of the prediction problem, where the unified relevance model brings these partial views together under the same umbrella. Experimental results complement the theoretical insights with improved recommendation accuracy. The unified model is more robust to data sparsity because the different types of ratings are used in concert.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W2054675234",
    "type": "article"
  },
  {
    "title": "Task support in an office system",
    "doi": "https://doi.org/10.1145/1206.1483",
    "publication_date": "1984-08-23",
    "publication_year": 1984,
    "authors": "W. Bruce Croft; Lawrence S. Lefkowitz",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Task support in an office system Authors: W Bruce Croft University of Massachusetts University of MassachusettsView Profile , Lawrence S. Lefkowitz University of Massachusetts University of MassachusettsView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 3pp 197–212https://doi.org/10.1145/1206.1483Published:23 August 1984Publication History 69citation523DownloadsMetricsTotal Citations69Total Downloads523Last 12 Months37Last 6 weeks4 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 87,
    "openalex_id": "https://openalex.org/W2611742346",
    "type": "article"
  },
  {
    "title": "An exploration of the principles underlying redundancy-based factoid question answering",
    "doi": "https://doi.org/10.1145/1229179.1229180",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Jimmy Lin",
    "corresponding_authors": "Jimmy Lin",
    "abstract": "The so-called “redundancy-based” approach to question answering represents a successful strategy for mining answers to factoid questions such as “Who shot Abraham Lincoln?” from the World Wide Web. Through contrastive and ablation experiments with Aranea, a system that has performed well in several TREC QA evaluations, this work examines the underlying assumptions and principles behind redundancy-based techniques. Specifically, we develop two theses: that stable characteristics of data redundancy allow factoid systems to rely on external “black box” components, and that despite embodying a data-driven approach, redundancy-based methods encode a substantial amount of knowledge in the form of heuristics. Overall, this work attempts to address the broader question of “what really matters” and to provide guidance for future researchers.",
    "cited_by_count": 86,
    "openalex_id": "https://openalex.org/W2042719229",
    "type": "article"
  },
  {
    "title": "KNOs: KNowledge acquisition, dissemination, and manipulation Objects",
    "doi": "https://doi.org/10.1145/22890.23001",
    "publication_date": "1987-01-01",
    "publication_year": 1987,
    "authors": "D. Tsichritzis; Eugene Fiume; S. Gibbs; Oscar Nierstrasz",
    "corresponding_authors": "",
    "abstract": "Most object-oriented systems lack two useful facilities: the ability of objects to migrate to new environments and the ability of objects to acquire new operations dynamically. This paper proposes Knos, an object-oriented environment that supports these actions. Knos' operations, data structures, and communication mechanisms are discussed. Knos objects “learn” by exporting and importing new or modified operations. The use of such objects as intellectual support tools is outlined. In particular, various applications involving cooperation, negotiation, and apprenticeship among objects are described.",
    "cited_by_count": 85,
    "openalex_id": "https://openalex.org/W2062058751",
    "type": "article"
  },
  {
    "title": "Supporting organizational problem solving with a work station",
    "doi": "https://doi.org/10.1145/357423.357427",
    "publication_date": "1983-01-01",
    "publication_year": 1983,
    "authors": "Gerald Barber",
    "corresponding_authors": "Gerald Barber",
    "abstract": "article Free Access Share on Supporting organizational problem solving with a work station Author: Gerald Barber INRIA, B.P. 150, 78150 Rocquencourt, France INRIA, B.P. 150, 78150 Rocquencourt, FranceView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 1Jan. 1983 pp 45–67https://doi.org/10.1145/357423.357427Published:01 January 1983Publication History 64citation522DownloadsMetricsTotal Citations64Total Downloads522Last 12 Months22Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 82,
    "openalex_id": "https://openalex.org/W2003819945",
    "type": "article"
  },
  {
    "title": "Bounded coordinate system indexing for real-time video clip search",
    "doi": "https://doi.org/10.1145/1508850.1508855",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Zi Huang; Heng Tao Shen; Jie Shao; Xiaofang Zhou; Bin Cui",
    "corresponding_authors": "",
    "abstract": "Recently, video clips have become very popular online. The massive influx of video clips has created an urgent need for video search engines to facilitate retrieving relevant clips. Different from traditional long videos, a video clip is a short video often expressing a moment of significance. Due to the high complexity of video data, efficient video clip search from large databases turns out to be very challenging. We propose a novel video clip representation model called the Bounded Coordinate System (BCS), which is the first single representative capturing the dominating content and content—changing trends of a video clip. It summarizes a video clip by a coordinate system, where each of its coordinate axes is identified by principal component analysis (PCA) and bounded by the range of data projections along the axis. The similarity measure of BCS considers the operations of translation, rotation, and scaling for coordinate system matching. Particularly, rotation and scaling reflect the difference of content tendencies. Compared with the quadratic time complexity of existing methods, the time complexity of measuring BCS similarity is linear. The compact video representation together with its linear similarity measure makes real-time search from video clip collections feasible. To further improve the retrieval efficiency for large video databases, a two-dimensional transformation method called Bidistance Transformation (BDT) is introduced to utilize a pair of optimal reference points with respect to bidirectional axes in BCS. Our extensive performance study on a large database of more than 30,000 video clips demonstrates that BCS achieves very high search accuracy according to human judgment. This indicates that content tendencies are important in determining the meanings of video clips and confirms that BCS can capture the inherent moment of video clip to some extent that better resembles human perception. In addition, BDT outperforms existing indexing methods greatly. Integration of the BCS model and BDT indexing can achieve real-time search from large video clip databases.",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W1989409200",
    "type": "article"
  },
  {
    "title": "Identifying Opportunities for Valuable Encounters",
    "doi": "https://doi.org/10.1145/2751557",
    "publication_date": "2015-07-14",
    "publication_year": 2015,
    "authors": "Julia M. Mayer; Quentin Jones; Starr Roxanne Hiltz",
    "corresponding_authors": "",
    "abstract": "Mobile social matching systems have the potential to transform the way we make new social ties, but only if we are able to overcome the many challenges that exist as to how systems can utilize contextual data to recommend interesting and relevant people to users and facilitate valuable encounters between strangers. This article outlines how context and mobility influence people's motivations to meet new people and presents innovative design concepts for mediating mobile encounters through context-aware social matching systems. Findings from two studies are presented. The first, a survey study (n = 117) explored the concept of contextual rarity of shared user attributes as a measure to improve desirability in mobile social matches. The second, an interview study (n = 58) explored people's motivations to meet others in various contexts. From these studies we derived a set of novel context-aware social matching concepts, including contextual sociability and familiarity as an indicator of opportune social context; contextual engagement as an indicator of opportune personal context; and contextual rarity, oddity, and activity partnering as an indicator of opportune relational context. The findings of these studies establish the importance of different contextual factors and frame the design space of context-aware social matching systems.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W1974643919",
    "type": "article"
  },
  {
    "title": "Inferring Dynamic User Interests in Streams of Short Texts for User Clustering",
    "doi": "https://doi.org/10.1145/3072606",
    "publication_date": "2017-07-17",
    "publication_year": 2017,
    "authors": "Shangsong Liang; Zhaochun Ren; Yukun Zhao; Jun Ma; Emine Yılmaz; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "User clustering has been studied from different angles. In order to identify shared interests, behavior-based methods consider similar browsing or search patterns of users, whereas content-based methods use information from the contents of the documents visited by the users. So far, content-based user clustering has mostly focused on static sets of relatively long documents. Given the dynamic nature of social media, there is a need to dynamically cluster users in the context of streams of short texts. User clustering in this setting is more challenging than in the case of long documents, as it is difficult to capture the users’ dynamic topic distributions in sparse data settings. To address this problem, we propose a dynamic user clustering topic model (UCT). UCT adaptively tracks changes of each user’s time-varying topic distributions based both on the short texts the user posts during a given time period and on previously estimated distributions. To infer changes, we propose a Gibbs sampling algorithm where a set of word pairs from each user is constructed for sampling. UCT can be used in two ways: (1) as a short-term dependency model that infers a user’s current topic distribution based on the user’s topic distributions during the previous time period only, and (2) as a long-term dependency model that infers a user’s current topic distributions based on the user’s topic distributions during multiple time periods in the past. The clustering results are explainable and human-understandable, in contrast to many other clustering algorithms. For evaluation purposes, we work with a dataset consisting of users and tweets from each user. Experimental results demonstrate the effectiveness of our proposed short-term and long-term dependency user clustering models compared to state-of-the-art baselines.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W2736274677",
    "type": "article"
  },
  {
    "title": "Discovering tasks from search engine query logs",
    "doi": "https://doi.org/10.1145/2493175.2493179",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Claudio Lucchese; Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri; Gabriele Tolomei",
    "corresponding_authors": "",
    "abstract": "Although Web search engines still answer user queries with lists of ten blue links to webpages, people are increasingly issuing queries to accomplish their daily tasks (e.g., finding a recipe , booking a flight , reading online news , etc.). In this work, we propose a two-step methodology for discovering tasks that users try to perform through search engines. First, we identify user tasks from individual user sessions stored in search engine query logs. In our vision, a user task is a set of possibly noncontiguous queries (within a user search session), which refer to the same need. Second, we discover collective tasks by aggregating similar user tasks, possibly performed by distinct users. To discover user tasks, we propose query similarity functions based on unsupervised and supervised learning approaches. We present a set of query clustering methods that exploit these functions in order to detect user tasks. All the proposed solutions were evaluated on a manually-built ground truth, and two of them performed better than state-of-the-art approaches. To detect collective tasks, we propose four methods that cluster previously discovered user tasks, which in turn are represented by the bag-of-words extracted from their composing queries. These solutions were also evaluated on another manually-built ground truth.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W1994305268",
    "type": "article"
  },
  {
    "title": "Task-Based Information Interaction Evaluation",
    "doi": "https://doi.org/10.1145/2699660",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Kalervo Järvelin; Pertti Vakkari; Paavo Arvola; Feza Baskaya; Anni Järvelin; Jaana Kekäläinen; Heikki Keskustalo; Sanna Kumpulainen; Miamaria Saastamoinen; Reijo Savolainen; Eero Sormunen",
    "corresponding_authors": "",
    "abstract": "Evaluation is central in research and development of information retrieval (IR). In addition to designing and implementing new retrieval mechanisms, one must also show through rigorous evaluation that they are effective. A major focus in IR is IR mechanisms’ capability of ranking relevant documents optimally for the users, given a query. Searching for information in practice involves searchers, however, and is highly interactive. When human searchers have been incorporated in evaluation studies, the results have often suggested that better ranking does not necessarily lead to better search task, or work task, performance. Therefore, it is not clear which system or interface features should be developed to improve the effectiveness of human task performance. In the present article, we focus on the evaluation of task-based information interaction (TBII). We give special emphasis to learning tasks to discuss TBII in more concrete terms. Information interaction is here understood as behavioral and cognitive activities related to task planning, searching information items, selecting between them, working with them, and synthesizing and reporting. These five generic activities contribute to task performance and outcome and can be supported by information systems. In an attempt toward task-based evaluation, we introduce program theory as the evaluation framework. Such evaluation can investigate whether a program consisting of TBII activities and tools works and how it works and, further, provides a causal description of program (in)effectiveness. Our goal in the present article is to structure TBII on the basis of the five generic activities and consider the evaluation of each activity using the program theory framework. Finally, we combine these activity-based program theories in an overall evaluation framework for TBII. Such an evaluation is complex due to the large number of factors affecting information interaction. Instead of presenting tested program theories, we illustrate how the evaluation of TBII should be accomplished using the program theory framework in the evaluation of systems and behaviors, and their interactions, comprehensively in context.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2013726998",
    "type": "article"
  },
  {
    "title": "Detecting Fake Medical Web Sites Using Recursive Trust Labeling",
    "doi": "https://doi.org/10.1145/2382438.2382441",
    "publication_date": "2012-11-01",
    "publication_year": 2012,
    "authors": "Ahmed Abbasi; Fatemeh Zahedi; Siddharth Kaza",
    "corresponding_authors": "",
    "abstract": "Fake medical Web sites have become increasingly prevalent. Consequently, much of the health-related information and advice available online is inaccurate and/or misleading. Scores of medical institution Web sites are for organizations that do not exist and more than 90% of online pharmacy Web sites are fraudulent. In addition to monetary losses exacted on unsuspecting users, these fake medical Web sites have severe public safety ramifications. According to a World Health Organization report, approximately half the drugs sold on the Web are counterfeit, resulting in thousands of deaths. In this study, we propose an adaptive learning algorithm called recursive trust labeling (RTL). RTL uses underlying content and graph-based classifiers, coupled with a recursive labeling mechanism, for enhanced detection of fake medical Web sites. The proposed method was evaluated on a test bed encompassing nearly 100 million links between 930,000 Web sites, including 1,000 known legitimate and fake medical sites. The experimental results revealed that RTL was able to significantly improve fake medical Web site detection performance over 19 comparison content and graph-based methods, various meta-learning techniques, and existing adaptive learning approaches, with an overall accuracy of over 94%. Moreover, RTL was able to attain high performance levels even when the training dataset composed of as little as 30 Web sites. With the increased popularity of eHealth and Health 2.0, the results have important implications for online trust, security, and public safety.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2039704177",
    "type": "article"
  },
  {
    "title": "Neural Vector Spaces for Unsupervised Information Retrieval",
    "doi": "https://doi.org/10.1145/3196826",
    "publication_date": "2018-06-26",
    "publication_year": 2018,
    "authors": "C Gysel; Maarten de Rijke; Evangelos Kanoulas",
    "corresponding_authors": "",
    "abstract": "We propose the Neural Vector Space Model (NVSM), a method that learns representations of documents in an unsupervised manner for news article retrieval. In the NVSM paradigm, we learn low-dimensional representations of words and documents from scratch using gradient descent and rank documents according to their similarity with query representations that are composed from word representations. We show that NVSM performs better at document ranking than existing latent semantic vector space methods. The addition of NVSM to a mixture of lexical language models and a state-of-the-art baseline vector space model yields a statistically significant increase in retrieval effectiveness. Consequently, NVSM adds a complementary relevance signal. Next to semantic matching, we find that NVSM performs well in cases where lexical matching is needed. NVSM learns a notion of term specificity directly from the document collection without feature engineering. We also show that NVSM learns regularities related to Luhn significance. Finally, we give advice on how to deploy NVSM in situations where model selection (e.g., cross-validation) is infeasible. We find that an unsupervised ensemble of multiple models trained with different hyperparameter values performs better than a single cross-validated model. Therefore, NVSM can safely be used for ranking documents without supervised relevance judgments.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W2743327679",
    "type": "article"
  },
  {
    "title": "Authorship Attribution Based on Specific Vocabulary",
    "doi": "https://doi.org/10.1145/2180868.2180874",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Jacques Savoy",
    "corresponding_authors": "Jacques Savoy",
    "abstract": "In this article we propose a technique for computing a standardized Z score capable of defining the specific vocabulary found in a text (or part thereof) compared to that of an entire corpus. Assuming that the term occurrence follows a binomial distribution, this method is then applied to weight terms (words and punctuation symbols in the current study), representing the lexical specificity of the underlying text. In a final stage, to define an author profile we suggest averaging these text representations and then applying them along with a distance measure to derive a simple and efficient authorship attribution scheme. To evaluate this algorithm and demonstrate its effectiveness, we develop two experiments, the first based on 5,408 newspaper articles ( Glasgow Herald ) written in English by 20 distinct authors and the second on 4,326 newspaper articles ( La Stampa ) written in Italian by 20 distinct authors. These experiments demonstrate that the suggested classification scheme tends to perform better than the Delta rule method based on the most frequent words, better than the chi-square distance based on word profiles and punctuation marks, better than the KLD scheme based on a predefined set of words, and better than the naïve Bayes approach.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2014792680",
    "type": "article"
  },
  {
    "title": "Digital Wildfires",
    "doi": "https://doi.org/10.1145/2893478",
    "publication_date": "2016-04-20",
    "publication_year": 2016,
    "authors": "Helena Webb; Pete Burnap; Rob Procter; Omer Rana; Bernd Carsten Stahl; Matthew Williams; William Housley; Adam Edwards; Marina Jirotka",
    "corresponding_authors": "",
    "abstract": "Social media platforms provide an increasingly popular means for individuals to share content online. Whilst this produces undoubted societal benefits, the ability for content to be spontaneously posted and reposted creates an ideal environment for rumour and false/malicious information to spread rapidly. When this occurs it can cause significant harm and can be characterised as a “digital wildfire.” In this article, we demonstrate that the propagation and regulation of digital wildfires form important topics for research and conduct an overview of existing work in this area. We outline the relevance of a range of work from the computational and social sciences, including a series of insights into the propagation of rumour and false/malicious information. We argue that significant research gaps remain—for instance, there is an absence of systematic studies on the effects of digital wildfires and there is a need to combine empirical research with a consideration of how the responsible governance of social media can be determined. We propose an agenda for research that establishes a methodology to explore in full the propagation and regulation of unverified content on social media. This agenda promotes high-quality interdisciplinary research that will also inform policy debates.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2338533289",
    "type": "article"
  },
  {
    "title": "Automatically Learning Topics and Difficulty Levels of Problems in Online Judge Systems",
    "doi": "https://doi.org/10.1145/3158670",
    "publication_date": "2018-03-07",
    "publication_year": 2018,
    "authors": "Wayne Xin Zhao; Wenhui Zhang; Yulan He; Xing Xie; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Online Judge (OJ) systems have been widely used in many areas, including programming, mathematical problems solving, and job interviews. Unlike other online learning systems, such as Massive Open Online Course, most OJ systems are designed for self-directed learning without the intervention of teachers. Also, in most OJ systems, problems are simply listed in volumes and there is no clear organization of them by topics or difficulty levels. As such, problems in the same volume are mixed in terms of topics or difficulty levels. By analyzing large-scale users’ learning traces, we observe that there are two major learning modes (or patterns). Users either practice problems in a sequential manner from the same volume regardless of their topics or they attempt problems about the same topic, which may spread across multiple volumes. Our observation is consistent with the findings in classic educational psychology. Based on our observation, we propose a novel two-mode Markov topic model to automatically detect the topics of online problems by jointly characterizing the two learning modes. For further predicting the difficulty level of online problems, we propose a competition-based expertise model using the learned topic information. Extensive experiments on three large OJ datasets have demonstrated the effectiveness of our approach in three different tasks, including skill topic extraction, expertise competition prediction and problem recommendation.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2792805964",
    "type": "article"
  },
  {
    "title": "Behavioral dynamics on the web",
    "doi": "https://doi.org/10.1145/2493175.2493181",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Kira Radinsky; Krysta M. Svore; Susan Dumais; Milad Shokouhi; Jaime Teevan; Alex Bocharov; Eric Horvitz",
    "corresponding_authors": "",
    "abstract": "The queries people issue to a search engine and the results clicked following a query change over time. For example, after the earthquake in Japan in March 2011, the query japan spiked in popularity and people issuing the query were more likely to click government-related results than they would prior to the earthquake. We explore the modeling and prediction of such temporal patterns in Web search behavior. We develop a temporal modeling framework adapted from physics and signal processing and harness it to predict temporal patterns in search behavior using smoothing, trends, periodicities, and surprises. Using current and past behavioral data, we develop a learning procedure that can be used to construct models of users' Web search activities. We also develop a novel methodology that learns to select the best prediction model from a family of predictive models for a given query or a class of queries. Experimental results indicate that the predictive models significantly outperform baseline models that weight historical evidence the same for all queries. We present two applications where new methods introduced for the temporal modeling of user behavior significantly improve upon the state of the art. Finally, we discuss opportunities for using models of temporal dynamics to enhance other areas of Web search and information retrieval.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W2142076420",
    "type": "article"
  },
  {
    "title": "Cost-Aware Collaborative Filtering for Travel Tour Recommendations",
    "doi": "https://doi.org/10.1145/2559169",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Yong Ge; Hui Xiong; Alexander Tuzhilin; Qi Liu",
    "corresponding_authors": "",
    "abstract": "Advances in tourism economics have enabled us to collect massive amounts of travel tour data. If properly analyzed, this data could be a source of rich intelligence for providing real-time decision making and for the provision of travel tour recommendations. However, tour recommendation is quite different from traditional recommendations, because the tourist’s choice is affected directly by the travel costs, which includes both financial and time costs. To that end, in this article, we provide a focused study of cost-aware tour recommendation. Along this line, we first propose two ways to represent user cost preference. One way is to represent user cost preference by a two-dimensional vector. Another way is to consider the uncertainty about the cost that a user can afford and introduce a Gaussian prior to model user cost preference. With these two ways of representing user cost preference, we develop different cost-aware latent factor models by incorporating the cost information into the probabilistic matrix factorization (PMF) model, the logistic probabilistic matrix factorization (LPMF) model, and the maximum margin matrix factorization (MMMF) model, respectively. When applied to real-world travel tour data, all the cost-aware recommendation models consistently outperform existing latent factor models with a significant margin.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2066653584",
    "type": "article"
  },
  {
    "title": "DeepMob",
    "doi": "https://doi.org/10.1145/3057280",
    "publication_date": "2017-06-23",
    "publication_year": 2017,
    "authors": "Xuan Song; Ryosuke Shibasaki; Nicholos Jing Yuan; Xing Xie; Tao Li; Ryutaro Adachi",
    "corresponding_authors": "",
    "abstract": "The frequency and intensity of natural disasters has increased significantly in recent decades, and this trend is expected to continue. Hence, understanding and predicting human evacuation behavior and mobility will play a vital role in planning effective humanitarian relief, disaster management, and long-term societal reconstruction. However, existing models are shallow models, and it is difficult to apply them for understanding the “deep knowledge” of human mobility. Therefore, in this study, we collect big and heterogeneous data (e.g., GPS records of 1.6 million users over 3 years, data on earthquakes that have occurred in Japan over 4 years, news report data, and transportation network data), and we build an intelligent system, namely, DeepMob, for understanding and predicting human evacuation behavior and mobility following different types of natural disasters. The key component of DeepMob is based on a deep learning architecture that aims to understand the basic laws that govern human behavior and mobility following natural disasters, from big and heterogeneous data. Furthermore, based on the deep learning model, DeepMob can accurately predict or simulate a person’s future evacuation behaviors or evacuation routes under different disaster conditions. Experimental results and validations demonstrate the efficiency and superior performance of our system, and suggest that human mobility following disasters may be predicted and simulated more easily than previously thought.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2714779472",
    "type": "article"
  },
  {
    "title": "Adversarial Distillation for Efficient Recommendation with External Knowledge",
    "doi": "https://doi.org/10.1145/3281659",
    "publication_date": "2018-12-13",
    "publication_year": 2018,
    "authors": "Xu Chen; Yongfeng Zhang; Hongteng Xu; Zheng Qin; Hongyuan Zha",
    "corresponding_authors": "",
    "abstract": "Integrating external knowledge into the recommendation system has attracted increasing attention in both industry and academic communities. Recent methods mostly take the power of neural network for effective knowledge representation to improve the recommendation performance. However, the heavy deep architectures in existing models are usually incorporated in an embedded manner, which may greatly increase the model complexity and lower the runtime efficiency. To simultaneously take the power of deep learning for external knowledge modeling as well as maintaining the model efficiency at test time, we reformulate the problem of recommendation with external knowledge into a generalized distillation framework . The general idea is to free the complex deep architecture into a separate model, which is only used in the training phrase, while abandoned at test time. In particular, in the training phrase, the external knowledge is processed by a comprehensive teacher model to produce valuable information to teach a simple and efficient student model. Once the framework is learned, the teacher model is abandoned, and only the succinct yet enhanced student model is used to make fast predictions at test time. In this article, we specify the external knowledge as user review, and to leverage it in an effective manner, we further extend the traditional generalized distillation framework by designing a Selective Distillation Network (SDNet) with adversarial adaption and orthogonality constraint strategies to make it more robust to noise information. Extensive experiments verify that our model can not only improve the performance of rating prediction, but also can significantly reduce time consumption when making predictions as compared with several state-of-the-art methods.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2903574258",
    "type": "article"
  },
  {
    "title": "Power Law Distributions in Information Retrieval",
    "doi": "https://doi.org/10.1145/2816815",
    "publication_date": "2016-02-16",
    "publication_year": 2016,
    "authors": "Casper Petersen; Jakob Grue Simonsen; Christina Lioma",
    "corresponding_authors": "",
    "abstract": "Several properties of information retrieval (IR) data, such as query frequency or document length, are widely considered to be approximately distributed as a power law. This common assumption aims to focus on specific characteristics of the empirical probability distribution of such data (e.g., its scale-free nature or its long/fat tail). This assumption, however, may not be always true. Motivated by recent work in the statistical treatment of power law claims, we investigate two research questions: (i) To what extent do power law approximations hold for term frequency, document length, query frequency, query length, citation frequency, and syntactic unigram frequency? And (ii) what is the computational cost of replacing ad hoc power law approximations with more accurate distribution fitting? We study 23 TREC and 5 non-TREC datasets and compare the fit of power laws to 15 other standard probability distributions. We find that query frequency and 5 out of 24 term frequency distributions are best approximated by a power law. All remaining properties are better approximated by the Inverse Gaussian, Generalized Extreme Value, Negative Binomial, or Yule distribution. We also find the overhead of replacing power law approximations by more informed distribution fitting to be negligible, with potential gains to IR tasks like index compression or test collection generation for IR evaluation.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2275236596",
    "type": "article"
  },
  {
    "title": "Transfer Learning to Infer Social Ties across Heterogeneous Networks",
    "doi": "https://doi.org/10.1145/2746230",
    "publication_date": "2016-04-13",
    "publication_year": 2016,
    "authors": "Jie Tang; Tiancheng Lou; Jon Kleinberg; Sen Wu",
    "corresponding_authors": "",
    "abstract": "Interpersonal ties are responsible for the structure of social networks and the transmission of information through these networks. Different types of social ties have essentially different influences on people. Awareness of the types of social ties can benefit many applications, such as recommendation and community detection. For example, our close friends tend to move in the same circles that we do, while our classmates may be distributed into different communities. Though a bulk of research has focused on inferring particular types of relationships in a specific social network, few publications systematically study the generalization of the problem of predicting social ties across multiple heterogeneous networks. In this work, we develop a framework referred to as TranFG for classifying the type of social relationships by learning across heterogeneous networks. The framework incorporates social theories into a factor graph model, which effectively improves the accuracy of predicting the types of social relationships in a target network by borrowing knowledge from a different source network. We also present several active learning strategies to further enhance the inferring performance. To scale up the model to handle really large networks, we design a distributed learning algorithm for the proposed model. We evaluate the proposed framework (TranFG) on six different networks and compare with several existing methods. TranFG clearly outperforms the existing methods on multiple metrics. For example, by leveraging information from a coauthor network with labeled advisor-advisee relationships, TranFG is able to obtain an F1-score of 90% (8%--28% improvements over alternative methods) for predicting manager-subordinate relationships in an enterprise email network. The proposed model is efficient. It takes only a few minutes to train the proposed transfer model on large networks containing tens of thousands of nodes.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2336938381",
    "type": "article"
  },
  {
    "title": "Examining Additivity and Weak Baselines",
    "doi": "https://doi.org/10.1145/2882782",
    "publication_date": "2016-06-09",
    "publication_year": 2016,
    "authors": "Sadegh Kharazmi; Falk Scholer; David Vallet; Mark Sanderson",
    "corresponding_authors": "",
    "abstract": "We present a study of which baseline to use when testing a new retrieval technique. In contrast to past work, we show that measuring a statistically significant improvement over a weak baseline is not a good predictor of whether a similar improvement will be measured on a strong baseline. Sometimes strong baselines are made worse when a new technique is applied. We investigate whether conducting comparisons against a range of weaker baselines can increase confidence that an observed effect will also show improvements on a stronger baseline. Our results indicate that this is not the case -- at best, testing against a range of baselines means that an experimenter can be more confident that the new technique is unlikely to significantly harm a strong baseline. Examining recent past work, we present evidence that the information retrieval (IR) community continues to test against weak baselines. This is unfortunate as, in light of our experiments, we conclude that the only way to be confident that a new technique is a contribution is to compare it against nothing less than the state of the art.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2410091547",
    "type": "article"
  },
  {
    "title": "Personalised Reranking of Paper Recommendations Using Paper Content and User Behavior",
    "doi": "https://doi.org/10.1145/3312528",
    "publication_date": "2019-03-16",
    "publication_year": 2019,
    "authors": "Xinyi Li; Yifan Chen; Benjamin Pettit; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Academic search engines have been widely used to access academic papers, where users’ information needs are explicitly represented as search queries. Some modern recommender systems have taken one step further by predicting users’ information needs without the presence of an explicit query. In this article, we examine an academic paper recommender that sends out paper recommendations in email newsletters, based on the users’ browsing history on the academic search engine. Specifically, we look at users who regularly browse papers on the search engine, and we sign up for the recommendation newsletters for the first time. We address the task of reranking the recommendation candidates that are generated by a production system for such users. We face the challenge that the users on whom we focus have not interacted with the recommender system before, which is a common scenario that every recommender system encounters when new users sign up. We propose an approach to reranking candidate recommendations that utilizes both paper content and user behavior. The approach is designed to suit the characteristics unique to our academic recommendation setting. For instance, content similarity measures can be used to find the closest match between candidate recommendations and the papers previously browsed by the user. To this end, we use a knowledge graph derived from paper metadata to compare entity similarities (papers, authors, and journals) in the embedding space. Since the users on whom we focus have no prior interactions with the recommender system, we propose a model to learn a mapping from users’ browsed articles to user clicks on the recommendations. We combine both content and behavior into a hybrid reranking model that outperforms the production baseline significantly, providing a relative 13% increase in Mean Average Precision and 28% in Precision@1. Moreover, we provide a detailed analysis of the model components, highlighting where the performance boost comes from. The obtained insights reveal useful components for the reranking process and can be generalized to other academic recommendation settings as well, such as the utility of graph embedding similarity. Also, recent papers browsed by users provide stronger evidence for recommendation than historical ones.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2923988880",
    "type": "article"
  },
  {
    "title": "Robust Unsupervised Cross-modal Hashing for Multimedia Retrieval",
    "doi": "https://doi.org/10.1145/3389547",
    "publication_date": "2020-06-05",
    "publication_year": 2020,
    "authors": "Miaomiao Cheng; Liping Jing; Michael K. Ng",
    "corresponding_authors": "",
    "abstract": "With the quick development of social websites, there are more opportunities to have different media types (such as text, image, video, etc.) describing the same topic from large-scale heterogeneous data sources. To efficiently identify the inter-media correlations for multimedia retrieval, unsupervised cross-modal hashing (UCMH) has gained increased interest due to the significant reduction in computation and storage. However, most UCMH methods assume that the data from different modalities are well paired. As a result, existing UCMH methods may not achieve satisfactory performance when partially paired data are given only. In this article, we propose a new-type of UCMH method called robust unsupervised cross-modal hashing ( RUCMH ). The major contribution lies in jointly learning modal-specific hash function, exploring the correlations among modalities with partial or even without any pairwise correspondence, and preserving the information of original features as much as possible. The learning process can be modeled via a joint minimization problem, and the corresponding optimization algorithm is presented. A series of experiments is conducted on four real-world datasets (Wiki, MIRFlickr, NUS-WIDE, and MS-COCO). The results demonstrate that RUCMH can significantly outperform the state-of-the-art unsupervised cross-modal hashing methods, especially for the partially paired case, which validates the effectiveness of RUCMH.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W3033276647",
    "type": "article"
  },
  {
    "title": "CRSAL",
    "doi": "https://doi.org/10.1145/3394592",
    "publication_date": "2020-06-13",
    "publication_year": 2020,
    "authors": "Xuhui Ren; Hongzhi Yin; Tong Chen; Hao Wang; Quoc Viet Hung Nguyen; Zi Huang; Xiangliang Zhang",
    "corresponding_authors": "",
    "abstract": "Recommender systems have been attracting much attention from both academia and industry because of their ability to capture user interests and generate personalized item recommendations. As the life pace in contemporary society speeds up, traditional recommender systems are inevitably limited by their disconnected interaction styles and low adaptivity to users’ evolving demands. Consequently, conversational recommender systems emerge as a prospective research area, where an intelligent dialogue agent is integrated with a recommender system. Conversational recommender systems possess the ability to accurately understand end-users’ intent or request and generate human-like dialogue responses when performing recommendations. However, existing conversational recommender systems only allow the systems to ask users for more preference information, while users’ further questions and concerns about the recommended items (e.g., enquiring the location of a recommended restaurant) can hardly be addressed. Though the recent task-oriented dialogue systems allow for two-way communications, they are not easy to train because of their high dependence on human guidance in terms of user intent recognition and system response generation. Hence, to enable two-way human-machine communications and tackle the challenges brought by manually crafted rules, we propose Conversational Recommender System with Adversarial Learning (CRSAL), a novel end-to-end system to tackle the task of conversational recommendation. In CRSAL, we innovatively design a fully statistical dialogue state tracker coupled with a neural policy agent to precisely capture each user’s intent from limited dialogue data and generate conversational recommendation actions. We further develop an adversarial Actor-Critic reinforcement learning approach to adaptively refine the quality of generated system actions, thus ensuring coherent human-like dialogue responses. Extensive experiments on two benchmark datasets fully demonstrate the superiority of CRSAL on conversational recommendation tasks.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W3035098003",
    "type": "article"
  },
  {
    "title": "Exploiting Cross-session Information for Session-based Recommendation with Graph Neural Networks",
    "doi": "https://doi.org/10.1145/3382764",
    "publication_date": "2020-05-23",
    "publication_year": 2020,
    "authors": "Ruihong Qiu; Zi Huang; Jingjing Li; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "Different from the traditional recommender system, the session-based recommender system introduces the concept of the session , i.e., a sequence of interactions between a user and multiple items within a period, to preserve the user’s recent interest. The existing work on the session-based recommender system mainly relies on mining sequential patterns within individual sessions, which are not expressive enough to capture more complicated dependency relationships among items. In addition, it does not consider the cross-session information due to the anonymity of the session data, where the linkage between different sessions is prevented. In this article, we solve these problems with the graph neural networks technique. First, each session is represented as a graph rather than a linear sequence structure, based on which a novel F ull G raph N eural N etwork (FGNN) is proposed to learn complicated item dependency. To exploit and incorporate cross-session information in the individual session’s representation learning, we further construct a B roadly C onnected S ession (BCS) graph to link different sessions and a novel Mask-Readout function to improve session embedding based on the BCS graph. Extensive experiments have been conducted on two e-commerce benchmark datasets, i.e., Yoochoose and Diginetica , and the experimental results demonstrate the superiority of our proposal through comparisons with state-of-the-art session-based recommender models.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W3178807794",
    "type": "article"
  },
  {
    "title": "Multi-Stage Conversational Passage Retrieval: An Approach to Fusing Term Importance Estimation and Neural Query Rewriting",
    "doi": "https://doi.org/10.1145/3446426",
    "publication_date": "2021-09-01",
    "publication_year": 2021,
    "authors": "Sheng-Chieh Lin; Jheng-Hong Yang; Rodrigo Nogueira; Ming-Feng Tsai; Chuan‐Ju Wang; Jimmy Lin",
    "corresponding_authors": "",
    "abstract": "Conversational search plays a vital role in conversational information seeking. As queries in information seeking dialogues are ambiguous for traditional ad hoc information retrieval (IR) systems due to the coreference and omission resolution problems inherent in natural language dialogue, resolving these ambiguities is crucial. In this article, we tackle conversational passage retrieval, an important component of conversational search, by addressing query ambiguities with query reformulation integrated into a multi-stage ad hoc IR system. Specifically, we propose two conversational query reformulation (CQR) methods: (1) term importance estimation and (2) neural query rewriting. For the former, we expand conversational queries using important terms extracted from the conversational context with frequency-based signals. For the latter, we reformulate conversational queries into natural, stand-alone, human-understandable queries with a pretrained sequence-to-sequence model. Detailed analyses of the two CQR methods are provided quantitatively and qualitatively, explaining their advantages, disadvantages, and distinct behaviors. Moreover, to leverage the strengths of both CQR methods, we propose combining their output with reciprocal rank fusion, yielding state-of-the-art retrieval effectiveness, 30% improvement in terms of NDCG@3 compared to the best submission of Text REtrieval Conference (TREC) Conversational Assistant Track (CAsT) 2019.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W3198536471",
    "type": "article"
  },
  {
    "title": "Multi-Graph Heterogeneous Interaction Fusion for Social Recommendation",
    "doi": "https://doi.org/10.1145/3466641",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Chengyuan Zhang; Yang Wang; Lei Zhu; Jiayu Song; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "With the rapid development of online social recommendation system, substantial methods have been proposed. Unlike traditional recommendation system, social recommendation performs by integrating social relationship features, where there are two major challenges, i.e., early summarization and data sparsity. Thus far, they have not been solved effectively. In this article, we propose a novel social recommendation approach, namely Multi-Graph Heterogeneous Interaction Fusion (MG-HIF), to solve these two problems. Our basic idea is to fuse heterogeneous interaction features from multi-graphs, i.e., user–item bipartite graph and social relation network, to improve the vertex representation learning. A meta-path cross-fusion model is proposed to fuse multi-hop heterogeneous interaction features via discrete cross-correlations. Based on that, a social relation GAN is developed to explore latent friendships of each user. We further fuse representations from two graphs by a novel multi-graph information fusion strategy with attention mechanism. To the best of our knowledge, this is the first work to combine meta-path with social relation representation. To evaluate the performance of MG-HIF, we compare MG-HIF with seven states of the art over four benchmark datasets. The experimental results show that MG-HIF achieves better performance.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W3204479763",
    "type": "article"
  },
  {
    "title": "Why or Why Not? The Effect of Justification Styles on Chatbot Recommendations",
    "doi": "https://doi.org/10.1145/3441715",
    "publication_date": "2021-10-22",
    "publication_year": 2021,
    "authors": "Daricia Wilkinson; Öznur Alkan; Q. Vera Liao; Massimiliano Mattetti; Inge Vejsbjerg; Bart P. Knijnenburg; Elizabeth Daly",
    "corresponding_authors": "",
    "abstract": "Chatbots or conversational recommenders have gained increasing popularity as a new paradigm for Recommender Systems (RS). Prior work on RS showed that providing explanations can improve transparency and trust, which are critical for the adoption of RS. Their interactive and engaging nature makes conversational recommenders a natural platform to not only provide recommendations but also justify the recommendations through explanations. The recent surge of interest inexplainable AI enables diverse styles of justification, and also invites questions on how styles of justification impact user perception. In this article, we explore the effect of “why” justifications and “why not” justifications on users’ perceptions of explainability and trust. We developed and tested a movie-recommendation chatbot that provides users with different types of justifications for the recommended items. Our online experiment ( n = 310) demonstrates that the “why” justifications (but not the “why not” justifications) have a significant impact on users’ perception of the conversational recommender. Particularly, “why” justifications increase users’ perception of system transparency, which impacts perceived control, trusting beliefs and in turn influences users’ willingness to depend on the system’s advice. Finally, we discuss the design implications for decision-assisting chatbots.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W3209280074",
    "type": "article"
  },
  {
    "title": "Conversations with Search Engines: SERP-based Conversational Response Generation",
    "doi": "https://doi.org/10.1145/3432726",
    "publication_date": "2021-08-16",
    "publication_year": 2021,
    "authors": "Pengjie Ren; Zhumin Chen; Zhaochun Ren; Evangelos Kanoulas; Christof Monz; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "In this article, we address the problem of answering complex information needs by conducting conversations with search engines , in the sense that users can express their queries in natural language and directly receive the information they need from a short system response in a conversational manner. Recently, there have been some attempts towards a similar goal, e.g., studies on Conversational Agent s (CAs) and Conversational Search (CS). However, they either do not address complex information needs in search scenarios or they are limited to the development of conceptual frameworks and/or laboratory-based user studies. We pursue two goals in this article: (1) the creation of a suitable dataset, the Search as a Conversation (SaaC) dataset, for the development of pipelines for conversations with search engines, and (2) the development of a state-of-the-art pipeline for conversations with search engines, Conversations with Search Engines (CaSE), using this dataset. SaaC is built based on a multi-turn conversational search dataset, where we further employ workers from a crowdsourcing platform to summarize each relevant passage into a short, conversational response. CaSE enhances the state-of-the-art by introducing a supporting token identification module and a prior-aware pointer generator, which enables us to generate more accurate responses. We carry out experiments to show that CaSE is able to outperform strong baselines. We also conduct extensive analyses on the SaaC dataset to show where there is room for further improvement beyond CaSE. Finally, we release the SaaC dataset and the code for CaSE and all models used for comparison to facilitate future research on this topic.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W3195014936",
    "type": "article"
  },
  {
    "title": "The Simpson’s Paradox in the Offline Evaluation of Recommendation Systems",
    "doi": "https://doi.org/10.1145/3458509",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Amir H. Jadidinejad; Craig Macdonald; Iadh Ounis",
    "corresponding_authors": "",
    "abstract": "Recommendation systems are often evaluated based on user’s interactions that were collected from an existing, already deployed recommendation system. In this situation, users only provide feedback on the exposed items and they may not leave feedback on other items since they have not been exposed to them by the deployed system. As a result, the collected feedback dataset that is used to evaluate a new model is influenced by the deployed system, as a form of closed loop feedback. In this article, we show that the typical offline evaluation of recommender systems suffers from the so-called Simpson’s paradox. Simpson’s paradox is the name given to a phenomenon observed when a significant trend appears in several different sub-populations of observational data but disappears or is even reversed when these sub-populations are combined together. Our in-depth experiments based on stratified sampling reveal that a very small minority of items that are frequently exposed by the deployed system plays a confounding factor in the offline evaluation of recommendation systems. In addition, we propose a novel evaluation methodology that takes into account the confounder, i.e., the deployed system’s characteristics. Using the relative comparison of many recommendation models as in the typical offline evaluation of recommender systems, and based on the Kendall rank correlation coefficient, we show that our proposed evaluation methodology exhibits statistically significant improvements of 14% and 40% on the examined open loop datasets (Yahoo! and Coat), respectively, in reflecting the true ranking of systems with an open loop (randomised) evaluation in comparison to the standard evaluation.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W3198076800",
    "type": "article"
  },
  {
    "title": "Meta-evaluation of Conversational Search Evaluation Metrics",
    "doi": "https://doi.org/10.1145/3445029",
    "publication_date": "2021-09-01",
    "publication_year": 2021,
    "authors": "Zeyang Liu; Ke Zhou; Max L. Wilson",
    "corresponding_authors": "",
    "abstract": "Conversational search systems, such as Google assistant and Microsoft Cortana, enable users to interact with search systems in multiple rounds through natural language dialogues. Evaluating such systems is very challenging, given that any natural language responses could be generated, and users commonly interact for multiple semantically coherent rounds to accomplish a search task. Although prior studies proposed many evaluation metrics, the extent of how those measures effectively capture user preference remain to be investigated. In this article, we systematically meta-evaluate a variety of conversational search metrics. We specifically study three perspectives on those metrics: (1) reliability : the ability to detect “actual” performance differences as opposed to those observed by chance; (2) fidelity : the ability to agree with ultimate user preference; and (3) intuitiveness : the ability to capture any property deemed important: adequacy, informativeness, and fluency in the context of conversational search. By conducting experiments on two test collections, we find that the performance of different metrics vary significantly across different scenarios, whereas consistent with prior studies, existing metrics only achieve weak correlation with ultimate user preference and satisfaction. METEOR is, comparatively speaking, the best existing single-turn metric considering all three perspectives. We also demonstrate that adapted session-based evaluation metrics can be used to measure multi-turn conversational search, achieving moderate concordance with user satisfaction. To our knowledge, our work establishes the most comprehensive meta-evaluation for conversational search to date.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W3157974261",
    "type": "article"
  },
  {
    "title": "Popularity Bias in False-positive Metrics for Recommender Systems Evaluation",
    "doi": "https://doi.org/10.1145/3452740",
    "publication_date": "2021-05-25",
    "publication_year": 2021,
    "authors": "Elisa Mena-Maldonado; Rocío Cañamares; Pablo Castells; Yongli Ren; Mark Sanderson",
    "corresponding_authors": "",
    "abstract": "We investigate the impact of popularity bias in false-positive metrics in the offline evaluation of recommender systems. Unlike their true-positive complements, false-positive metrics reward systems that minimize recommendations disliked by users. Our analysis is, to the best of our knowledge, the first to show that false-positive metrics tend to penalise popular items, the opposite behavior of true-positive metrics—causing a disagreement trend between both types of metrics in the presence of popularity biases. We present a theoretical analysis of the metrics that identifies the reason that the metrics disagree and determines rare situations where the metrics might agree—the key to the situation lies in the relationship between popularity and relevance distributions, in terms of their agreement and steepness —two fundamental concepts we formalize. We then examine three well-known datasets using multiple popular true- and false-positive metrics on 16 recommendation algorithms. Specific datasets are chosen to allow us to estimate both biased and unbiased metric values. The results of the empirical study confirm and illustrate our analytical findings. With the conditions of the disagreement of the two types of metrics established, we then determine under which circumstances true-positive or false-positive metrics should be used by researchers of offline evaluation in recommender systems. 1",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W3164231466",
    "type": "article"
  },
  {
    "title": "How Am I Doing?: Evaluating Conversational Search Systems Offline",
    "doi": "https://doi.org/10.1145/3451160",
    "publication_date": "2021-08-17",
    "publication_year": 2021,
    "authors": "Aldo Lipani; Ben Carterette; Emine Yılmaz",
    "corresponding_authors": "",
    "abstract": "As conversational agents like Siri and Alexa gain in popularity and use, conversation is becoming a more and more important mode of interaction for search. Conversational search shares some features with traditional search, but differs in some important respects: conversational search systems are less likely to return ranked lists of results (a SERP), more likely to involve iterated interactions, and more likely to feature longer, well-formed user queries in the form of natural language questions. Because of these differences, traditional methods for search evaluation (such as the Cranfield paradigm) do not translate easily to conversational search. In this work, we propose a framework for offline evaluation of conversational search, which includes a methodology for creating test collections with relevance judgments, an evaluation measure based on a user interaction model, and an approach to collecting user interaction data to train the model. The framework is based on the idea of “subtopics”, often used to model novelty and diversity in search and recommendation, and the user model is similar to the geometric browsing model introduced by RBP and used in ERR. As far as we know, this is the first work to combine these ideas into a comprehensive framework for offline evaluation of conversational search.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W3193746305",
    "type": "article"
  },
  {
    "title": "Toward Personalized Answer Generation in E-Commerce via Multi-perspective Preference Modeling",
    "doi": "https://doi.org/10.1145/3507782",
    "publication_date": "2022-02-01",
    "publication_year": 2022,
    "authors": "Yang Deng; Yaliang Li; Wenxuan Zhang; Bolin Ding; Wai Lam",
    "corresponding_authors": "",
    "abstract": "Recently, Product Question Answering (PQA) on E-Commerce platforms has attracted increasing attention as it can act as an intelligent online shopping assistant and improve the customer shopping experience. Its key function, automatic answer generation for product-related questions, has been studied by aiming to generate content-preserving while question-related answers. However, an important characteristic of PQA, i.e., personalization, is neglected by existing methods. It is insufficient to provide the same “completely summarized” answer to all customers, since many customers are more willing to see personalized answers with customized information only for themselves, by taking into consideration their own preferences toward product aspects or information needs. To tackle this challenge, we propose a novel Personalized Answer GEneration method with multi-perspective preference modeling, which explores historical user-generated contents to model user preference for generating personalized answers in PQA. Specifically, we first retrieve question-related user history as external knowledge to model knowledge-level user preference. Then, we leverage the Gaussian Softmax distribution model to capture latent aspect-level user preference. Finally, we develop a persona-aware pointer network to generate personalized answers in terms of both content and style by utilizing personal user preference and dynamic user vocabulary. Experimental results on real-world E-Commerce QA datasets demonstrate that the proposed method outperforms existing methods by generating informative and customized answers and show that answer generation in E-Commerce can benefit from personalization.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W4221103197",
    "type": "article"
  },
  {
    "title": "MEGCF: Multimodal Entity Graph Collaborative Filtering for Personalized Recommendation",
    "doi": "https://doi.org/10.1145/3544106",
    "publication_date": "2022-06-13",
    "publication_year": 2022,
    "authors": "Kang Liu; Feng Xue; Dan Guo; Le Wu; Shujie Li; Richang Hong",
    "corresponding_authors": "",
    "abstract": "In most E-commerce platforms, whether the displayed items trigger the user’s interest largely depends on their most eye-catching multimodal content. Consequently, increasing efforts focus on modeling multimodal user preference, and the pressing paradigm is to incorporate complete multimodal deep features of the items into the recommendation module. However, the existing studies ignore the mismatch problem between multimodal feature extraction (MFE) and user interest modeling (UIM) . That is, MFE and UIM have different emphases. Specifically, MFE is migrated from and adapted to upstream tasks such as image classification. In addition, it is mainly a content-oriented and non-personalized process, while UIM, with its greater focus on understanding user interaction, is essentially a user-oriented and personalized process. Therefore, the direct incorporation of MFE into UIM for purely user-oriented tasks, tends to introduce a large number of preference-independent multimodal noise and contaminate the embedding representations in UIM. This paper aims at solving the mismatch problem between MFE and UIM, so as to generate high-quality embedding representations and better model multimodal user preferences. Towards this end, we develop a novel model, m ultimodal e ntity g raph c ollaborative f iltering, short for MEGCF. The UIM of the proposed model captures the semantic correlation between interactions and the features obtained from MFE, thus making a better match between MFE and UIM. More precisely, semantic-rich entities are first extracted from the multimodal data, since they are more relevant to user preferences than other multimodal information. These entities are then integrated into the user-item interaction graph. Afterwards, a symmetric linear Graph Convolution Network (GCN) module is constructed to perform message propagation over the graph, in order to capture both high-order semantic correlation and collaborative filtering signals. Finally, the sentiment information from the review data are used to fine-grainedly weight neighbor aggregation in the GCN, as it reflects the overall quality of the items, and therefore it is an important modality information related to user preferences. Extensive experiments demonstrate the effectiveness and rationality of MEGCF. 1",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W4282549812",
    "type": "article"
  },
  {
    "title": "Toward Equivalent Transformation of User Preferences in Cross Domain Recommendation",
    "doi": "https://doi.org/10.1145/3522762",
    "publication_date": "2022-03-09",
    "publication_year": 2022,
    "authors": "Xu Chen; Ya Zhang; Ivor W. Tsang; Yuangang Pan; Jingchao Su",
    "corresponding_authors": "",
    "abstract": "Cross domain recommendation (CDR) is one popular research topic in recommender systems. This article focuses on a popular scenario for CDR where different domains share the same set of users but no overlapping items. The majority of recent methods have explored the shared-user representation to transfer knowledge across domains. However, the idea of shared-user representation resorts to learning the overlapped features of user preferences and suppresses the domain-specific features. Other works try to capture the domain-specific features by an MLP mapping but require heuristic human knowledge of choosing samples to train the mapping. In this article, we attempt to learn both features of user preferences in a more principled way. We assume that each user’s preferences in one domain can be expressed by the other one, and these preferences can be mutually converted to each other with the so-called equivalent transformation. Based on this assumption, we propose an equivalent transformation learner (ETL), which models the joint distribution of user behaviors across domains. The equivalent transformation in ETL relaxes the idea of shared-user representation and allows the learned preferences in different domains to preserve the domain-specific features as well as the overlapped features. Extensive experiments on three public benchmarks demonstrate the effectiveness of ETL compared with recent state-of-the-art methods. Codes and data are available online: https://github.com/xuChenSJTU/ETL-master.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W3084675360",
    "type": "article"
  },
  {
    "title": "Revisiting Graph-based Recommender Systems from the Perspective of Variational Auto-Encoder",
    "doi": "https://doi.org/10.1145/3573385",
    "publication_date": "2022-12-01",
    "publication_year": 2022,
    "authors": "Yi Zhang; Yiwen Zhang; Dengcheng Yan; Shuiguang Deng; Yun Yang",
    "corresponding_authors": "",
    "abstract": "Graph-based recommender system has attracted widespread attention and produced a series of research results. Because of the powerful high-order connection modeling capabilities of the Graph Neural Network, the performance of these graph-based recommender systems are far superior to those of traditional neural network-based collaborative filtering models. However, from both analytical and empirical perspectives, the apparent performance improvement is accompanied with a significant time overhead, which is noticeable in large-scale graph topologies. More importantly, the intrinsic data-sparsity problem substantially limits the performance of graph-based recommender systems, which compelled us to revisit graph-based recommendation from a novel perspective. In this article, we focus on analyzing the time complexity of graph-based recommender systems to make it more suitable for real large-scale application scenarios. We propose a novel end-to-end graph recommendation model called the Collaborative Variational Graph Auto-Encoder (CVGA), which uses the information propagation and aggregation paradigms to encode user–item collaborative relationships on the user–item interaction bipartite graph. These relationships are utilized to infer the probability distribution of user behavior for parameter estimation rather than learning user or item embeddings. By doing so, we reconstruct the whole user–item interaction graph according to the known probability distribution in a feasible and elegant manner. From the perspective of the graph auto-encoder, we convert the graph recommendation task into a graph generation problem and are able to do it with approximately linear time complexity. Extensive experiments on four real-world benchmark datasets demonstrate that CVGA can be trained at a faster speed while maintaining comparable performance over state-of-the-art baselines for graph-based recommendation tasks. Further analysis shows that CVGA can effectively mitigate the data sparsity problem and performs equally well on large-scale datasets.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W4311057500",
    "type": "article"
  },
  {
    "title": "A Systematic Analysis on the Impact of Contextual Information on Point-of-Interest Recommendation",
    "doi": "https://doi.org/10.1145/3508478",
    "publication_date": "2022-02-01",
    "publication_year": 2022,
    "authors": "Hossein A. Rahmani; Mohammad Aliannejadi; Mitra Baratchi; Fábio Crestani",
    "corresponding_authors": "",
    "abstract": "As the popularity of Location-based Social Networks increases, designing accurate models for Point-of-Interest (POI) recommendation receives more attention. POI recommendation is often performed by incorporating contextual information into previously designed recommendation algorithms. Some of the major contextual information that has been considered in POI recommendation are the location attributes (i.e., exact coordinates of a location, category, and check-in time), the user attributes (i.e., comments, reviews, tips, and check-in made to the locations), and other information, such as the distance of the POI from user’s main activity location and the social tie between users. The right selection of such factors can significantly impact the performance of the POI recommendation. However, previous research does not consider the impact of the combination of these different factors. In this article, we propose different contextual models and analyze the fusion of different major contextual information in POI recommendation. The major contributions of this article are as follows: (i) providing an extensive survey of context-aware location recommendation; (ii) quantifying and analyzing the impact of different contextual information (e.g., social, temporal, spatial, and categorical) in the POI recommendation on available baselines and two new linear and non-linear models, which can incorporate all the major contextual information into a single recommendation model; and (iii) evaluating the considered models using two well-known real-world datasets. Our results indicate that while modeling geographical and temporal influences can improve recommendation quality, fusing all other contextual information into a recommendation model is not always the best strategy.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W4220953416",
    "type": "article"
  },
  {
    "title": "Graph Neural Pre-training for Recommendation with Side Information",
    "doi": "https://doi.org/10.1145/3568953",
    "publication_date": "2022-12-02",
    "publication_year": 2022,
    "authors": "Siwei Liu; Zaiqiao Meng; Craig Macdonald; Iadh Ounis",
    "corresponding_authors": "",
    "abstract": "Leveraging the side information associated with entities (i.e., users and items) to enhance recommendation systems has been widely recognized as an essential modeling dimension. Most of the existing approaches address this task by the integration-based scheme , which incorporates the entity side information by combining the recommendation objective with an extra side information-aware objective. Despite the growing progress made by the existing integration-based approaches, they are largely limited by the potential conflicts between the two objectives. Moreover, the heterogeneous side information among entities is still under-explored in these systems. In this article, we propose a novel pre-training scheme to leverage the entity side information by pre-training entity embeddings using the multi-graph neural network. Instead of jointly training with two objectives, our pre-training scheme first pre-trains two representation models under the entity multi/single relational graphs constructed by their side information and then fine-tunes their embeddings under an existing general representation-based recommendation model. Our proposed multi-graph and single-graph neural networks can generate within-entity knowledge-encapsulated embeddings, while capturing the heterogeneity from the entity side information simultaneously, thereby improving the performance of the underlying recommendation model. An extensive evaluation of our pre-training scheme fine-tuned under four general representation-based recommender models, namely, MF, NCF, NGCF, and LightGCN, shows that effectively pre-training embeddings with both the user’s and item’s side information can significantly improve these original models in terms of both effectiveness and stability.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W4311119072",
    "type": "article"
  },
  {
    "title": "Dynamic Graph Reasoning for Conversational Open-Domain Question Answering",
    "doi": "https://doi.org/10.1145/3498557",
    "publication_date": "2022-01-11",
    "publication_year": 2022,
    "authors": "Yongqi Li; Wenjie Li; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "In recent years, conversational agents have provided a natural and convenient access to useful information in people’s daily life, along with a broad and new research topic, conversational question answering (QA). On the shoulders of conversational QA, we study the conversational open-domain QA problem, where users’ information needs are presented in a conversation and exact answers are required to extract from the Web. Despite its significance and value, building an effective conversational open-domain QA system is non-trivial due to the following challenges: (1) precisely understand conversational questions based on the conversation context; (2) extract exact answers by capturing the answer dependency and transition flow in a conversation; and (3) deeply integrate question understanding and answer extraction. To address the aforementioned issues, we propose an end-to-end Dynamic Graph Reasoning approach to Conversational open-domain QA (DGRCoQA for short). DGRCoQA comprises three components, i.e., a dynamic question interpreter (DQI), a graph reasoning enhanced retriever (GRR), and a typical Reader, where the first one is developed to understand and formulate conversational questions while the other two are responsible to extract an exact answer from the Web. In particular, DQI understands conversational questions by utilizing the QA context, sourcing from predicted answers returned by the Reader, to dynamically attend to the most relevant information in the conversation context. Afterwards, GRR attempts to capture the answer flow and select the most possible passage that contains the answer by reasoning answer paths over a dynamically constructed context graph . Finally, the Reader, a reading comprehension model, predicts a text span from the selected passage as the answer. DGRCoQA demonstrates its strength in the extensive experiments conducted on a benchmark dataset. It significantly outperforms the existing methods and achieves the state-of-the-art performance.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W4206104244",
    "type": "article"
  },
  {
    "title": "Neural Architecture Search for GNN-Based Graph Classification",
    "doi": "https://doi.org/10.1145/3584945",
    "publication_date": "2023-02-20",
    "publication_year": 2023,
    "authors": "Lanning Wei; Huan Zhao; Zhiqiang He; Quanming Yao",
    "corresponding_authors": "",
    "abstract": "Graph classification is an important problem with applications across many domains, for which graph neural networks (GNNs) have been state-of-the-art (SOTA) methods. In the literature, to adopt GNNs for the graph classification task, there are two groups of methods: global pooling and hierarchical pooling. The global pooling methods obtain the graph representation vectors by globally pooling all of the node embeddings together at the end of several GNN layers, whereas the hierarchical pooling methods provide one extra pooling operation between the GNN layers to extract hierarchical information and improve the graph representations. Both global and hierarchical pooling methods are effective in different scenarios. Due to highly diverse applications, it is challenging to design data-specific pooling methods with human expertise. To address this problem, we propose PAS (Pooling Architecture Search) to design adaptive pooling architectures by using the neural architecture search (NAS). To enable the search space design, we propose a unified pooling framework consisting of four modules: Aggregation, Pooling, Readout, and Merge. Two variants, PAS-G and PAS-NE, are provided to design the pooling operations in different scales. A set of candidate operations is designed in the search space using this framework. Then, existing human-designed pooling methods, including global and hierarchical ones, can be incorporated. To enable efficient search, a coarsening strategy is developed to continuously relax the search space, and then a differentiable search method can be adopted. We conduct extensive experiments on six real-world datasets, including the large-scale datasets MR and ogbg-molhiv. Experimental results in this article demonstrate the effectiveness and efficiency of the proposed PAS in designing the pooling architectures for graph classification. The Top-1 performance on two Open Graph Benchmark (OGB) datasets 1 further indicates the utility of PAS when facing diverse realistic data. The implementation of PAS is available at: https://github.com/AutoML-Research/PAS.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4321372691",
    "type": "article"
  },
  {
    "title": "Information Retrieval Evaluation Measures Defined on Some Axiomatic Models of Preferences",
    "doi": "https://doi.org/10.1145/3632171",
    "publication_date": "2023-11-08",
    "publication_year": 2023,
    "authors": "Fernando Giner",
    "corresponding_authors": "Fernando Giner",
    "abstract": "Information retrieval (IR) evaluation measures are essential for capturing the relevance of documents to topics and determining the task performance efficiency of retrieval systems. The study of IR evaluation measures through their formal properties enables a better understanding of their suitability for a specific task. Some works have modeled the effectiveness of retrieval measures with axioms, heuristics, or desirable properties, leading to order relationships on the set where they are defined. Each of these ordering structures constitutes an axiomatic model of preferences (AMP), which can be considered as an “ideal” scenario of retrieval. Based on lattice theory and on the representational theory of measurement, this work formally explores numeric, metric, and scale properties of some effectiveness measures defined on AMPs. In some of these scenarios, retrieval measures are completely determined from the scores of a subset of document rankings: join-irreducible elements. All the possible metrics and pseudometrics, defined on these structures are expressed in terms of the join-irreducible elements. The deduced scale properties of the precision, recall, F -measure, RBP , DCG , and AP confirm some recent results in the IR field.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4388492166",
    "type": "article"
  },
  {
    "title": "Hierarchical Transformer with Spatio-temporal Context Aggregation for Next Point-of-interest Recommendation",
    "doi": "https://doi.org/10.1145/3597930",
    "publication_date": "2023-08-04",
    "publication_year": 2023,
    "authors": "Jiayi Xie; Zhenzhong Chen",
    "corresponding_authors": "",
    "abstract": "Next point-of-interest (POI) recommendation is a critical task in location-based social networks, yet remains challenging due to a high degree of variation and personalization exhibited in user movements. In this work, we explore the latent hierarchical structure composed of multi-granularity short-term structural patterns in user check-in sequences. We propose a Spatio-Temporal context AggRegated Hierarchical Transformer (STAR-HiT) for next POI recommendation, which employs stacked hierarchical encoders to recursively encode the spatio-temporal context and explicitly locate subsequences of different granularities. More specifically, in each encoder, the global attention layer captures the spatio-temporal context of the sequence, while the local attention layer performed within each subsequence enhances subsequence modeling using the local context. The sequence partition layer infers positions and lengths of subsequences from the global context adaptively, such that semantics in subsequences can be well preserved. Finally, the subsequence aggregation layer fuses representations within each subsequence to form the corresponding subsequence representation, thereby generating a new sequence of higher-level granularity. The stacking of hierarchical encoders captures the latent hierarchical structure of the check-in sequence, which is used to predict the next visiting POI. Extensive experiments on three public datasets demonstrate that the proposed model achieves superior performance while providing explanations for recommendations.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4385583963",
    "type": "article"
  },
  {
    "title": "Multimodal Dialog Systems with Dual Knowledge-enhanced Generative Pretrained Language Model",
    "doi": "https://doi.org/10.1145/3606368",
    "publication_date": "2023-10-06",
    "publication_year": 2023,
    "authors": "Xiaolin Chen; Xuemeng Song; Liqiang Jing; Shuo Li; Linmei Hu; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "Text response generation for multimodal task-oriented dialog systems, which aims to generate the proper text response given the multimodal context, is an essential yet challenging task. Although existing efforts have achieved compelling success, they still suffer from two pivotal limitations: (1) overlook the benefit of generative pretraining and (2) ignore the textual context-related knowledge . To address these limitations, we propose a novel dual knowledge-enhanced generative pretrained language mode for multimodal task-oriented dialog systems (DKMD), consisting of three key components: dual knowledge selection , dual knowledge-enhanced context learning , and knowledge-enhanced response generation . To be specific, the dual knowledge selection component aims to select the related knowledge according to both textual and visual modalities of the given context. Thereafter, the dual knowledge-enhanced context learning component targets seamlessly, integrating the selected knowledge into the multimodal context learning from both global and local perspectives, where the cross-modal semantic relation is also explored. Moreover, the knowledge-enhanced response generation component comprises a revised BART decoder, where an additional dot-product knowledge-decoder attention sub-layer is introduced for explicitly utilizing the knowledge to advance the text response generation. Extensive experiments on a public dataset verify the superiority of the proposed DKMD over state-of-the-art competitors.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4387398451",
    "type": "article"
  },
  {
    "title": "Pseudo Relevance Feedback with Deep Language Models and Dense Retrievers: Successes and Pitfalls",
    "doi": "https://doi.org/10.1145/3570724",
    "publication_date": "2023-01-10",
    "publication_year": 2023,
    "authors": "Hang Li; Ahmed Mourad; Shengyao Zhuang; Bevan Koopman; Guido Zuccon",
    "corresponding_authors": "",
    "abstract": "Pseudo Relevance Feedback (PRF) is known to improve the effectiveness of bag-of-words retrievers. At the same time, deep language models have been shown to outperform traditional bag-of-words rerankers. However, it is unclear how to integrate PRF directly with emergent deep language models. This article addresses this gap by investigating methods for integrating PRF signals with rerankers and dense retrievers based on deep language models. We consider text-based, vector-based and hybrid PRF approaches and investigate different ways of combining and scoring relevance signals. An extensive empirical evaluation was conducted across four different datasets and two task settings (retrieval and ranking). Text-based PRF results show that the use of PRF had a mixed effect on deep rerankers across different datasets. We found that the best effectiveness was achieved when (i) directly concatenating each PRF passage with the query, searching with the new set of queries, and then aggregating the scores; (ii) using Borda to aggregate scores from PRF runs. Vector-based PRF results show that the use of PRF enhanced the effectiveness of deep rerankers and dense retrievers over several evaluation metrics. We found that higher effectiveness was achieved when (i) the query retains either the majority or the same weight within the PRF mechanism, and (ii) a shallower PRF signal (i.e., a smaller number of top-ranked passages) was employed, rather than a deeper signal. Our vector-based PRF method is computationally efficient; thus, this represents a general PRF method others can use with deep rerankers and dense retrievers.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4315481736",
    "type": "article"
  },
  {
    "title": "Automatic Skill-Oriented Question Generation and Recommendation for Intelligent Job Interviews",
    "doi": "https://doi.org/10.1145/3604552",
    "publication_date": "2023-06-14",
    "publication_year": 2023,
    "authors": "Chuan Qin; Hengshu Zhu; D. Z. Shen; Ying Sun; Kaichun Yao; Peng Wang; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "Job interviews are the most widely accepted method for companies to select suitable candidates, and a critical challenge is finding the right questions to ask job candidates. Moreover, there is a lack of integrated tools for automatically generating interview questions and recommending the right questions to interviewers. To this end, in this paper, we propose an intelligent system for assisting job interviews, namely, DuerQues. To build this system, we first investigate how to automatically generate skill-oriented interview questions in a scalable way by learning external knowledge from online knowledge-sharing communities. Along this line, we develop a novel distantly supervised skill entity recognition method to identify skill entities from large-scale search queries and web page titles with less need for human annotation. Additionally, we propose a neural generative model for generating skill-oriented interview questions. In particular, we introduce a data-driven solution to create high-quality training instances and design a learning algorithm to improve the performance of question generation. Furthermore, we exploit click-through data from query logs and design a recommender system for recommending suitable questions to interviewers. Specifically, we introduce a graph-enhanced algorithm to efficiently recommend suitable questions given a set of queried skills. Finally, extensive experiments on real-world datasets demonstrate the effectiveness of our DuerQues system in terms of the quality of generated skill-oriented questions and the performance of question recommendation.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4380447165",
    "type": "article"
  },
  {
    "title": "SMLP4Rec: An Efficient All-MLP Architecture for Sequential Recommendations",
    "doi": "https://doi.org/10.1145/3637871",
    "publication_date": "2023-12-18",
    "publication_year": 2023,
    "authors": "Jingtong Gao; Xiangyu Zhao; Muyang Li; Minghao Zhao; Runze Wu; Ruocheng Guo; Yiding Liu; Dawei Yin",
    "corresponding_authors": "",
    "abstract": "Self-attention models have achieved the state-of-the-art performance in sequential recommender systems by capturing the sequential dependencies among user–item interactions. However, they rely on adding positional embeddings to the item sequence to retain the sequential information, which may break the semantics of item embeddings due to the heterogeneity between these two types of embeddings. In addition, most existing works assume that such dependencies exist solely in the item embeddings, but neglect their existence among the item features. In our previous study, we proposed a novel sequential recommendation model, i.e., MLP4Rec, based on the recent advances of MLP-Mixer architectures, which is naturally sensitive to the order of items in a sequence because matrix elements related to different positions of a sequence will be given different weights in training. We developed a tri-directional fusion scheme to coherently capture sequential, cross-channel, and cross-feature correlations with linear computational complexity as well as much fewer model parameters than existing self-attention methods. However, the cascading mixer structure, the large number of normalization layers between different mixer layers, and the noise generated by these operations limit the efficiency of information extraction and the effectiveness of MLP4Rec. In this extended version, we propose a novel framework – SMLP4Rec for sequential recommendation to address the aforementioned issues. The new framework changes the flawed cascading structure to a parallel mode, and integrates normalization layers to minimize their impact on the model’s efficiency while maximizing their effectiveness. As a result, the training speed and prediction accuracy of SMLP4Rec are vastly improved in comparison to MLP4Rec. Extensive experimental results demonstrate that the proposed method is significantly superior to the state-of-the-art approaches. The implementation code is available online to ease reproducibility.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4389893572",
    "type": "article"
  },
  {
    "title": "Triple Sequence Learning for Cross-domain Recommendation",
    "doi": "https://doi.org/10.1145/3638351",
    "publication_date": "2023-12-22",
    "publication_year": 2023,
    "authors": "Haokai Ma; Ruobing Xie; Lei Meng; Xin Chen; Xu Zhang; Leyu Lin; Jie Zhou",
    "corresponding_authors": "",
    "abstract": "Cross-domain recommendation (CDR) aims at leveraging the correlation of users’ behaviors in both the source and target domains to improve the user preference modeling in the target domain. Conventional CDR methods typically explore the dual-relations between the source and target domains’ behaviors. However, this may ignore the informative mixed behaviors that naturally reflect the user’s global preference. To address this issue, we present a novel framework, termed triple sequence learning for cross-domain recommendation (Tri-CDR), which jointly models the source, target, and mixed behavior sequences to highlight the global and target preference and precisely model the triple correlation in CDR. Specifically, Tri-CDR independently models the hidden representations for the triple behavior sequences and proposes a triple cross-domain attention (TCA) method to emphasize the informative knowledge related to both user’s global and target-domain preference. To comprehensively explore the cross-domain correlations, we design a triple contrastive learning (TCL) strategy that simultaneously considers the coarse-grained similarities and fine-grained distinctions among the triple sequences, ensuring the alignment while preserving information diversity in multi-domain. We conduct extensive experiments and analyses on six cross-domain settings. The significant improvements of Tri-CDR with different sequential encoders verify its effectiveness and universality. The source code is available at https://github.com/hulkima/Tri-CDR .",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4390105435",
    "type": "article"
  },
  {
    "title": "Collaborative Sequential Recommendations via Multi-View GNN-Transformers",
    "doi": "https://doi.org/10.1145/3649436",
    "publication_date": "2024-03-15",
    "publication_year": 2024,
    "authors": "Tianze Luo; Yong Liu; Sinno Jialin Pan",
    "corresponding_authors": "",
    "abstract": "Sequential recommendation systems aim to exploit users’ sequential behavior patterns to capture their interaction intentions and improve recommendation accuracy. Existing sequential recommendation methods mainly focus on modeling the items’ chronological relationships in each individual user behavior sequence, which may not be effective in making accurate and robust recommendations. On the one hand, the performance of existing sequential recommendation methods is usually sensitive to the length of a user’s behavior sequence (i.e., the list of a user’s historically interacted items). On the other hand, besides the context information in each individual user behavior sequence, the collaborative information among different users’ behavior sequences is also crucial to make accurate recommendations. However, this kind of information is usually ignored by existing sequential recommendation methods. In this work, we propose a new sequential recommendation framework, which encodes the context information in each individual user behavior sequence as well as the collaborative information among the behavior sequences of different users, through building a local dependency graph for each item. We conduct extensive experiments to compare the proposed model with state-of-the-art sequential recommendation methods on five benchmark datasets. The experimental results demonstrate that the proposed model is able to achieve better recommendation performance than existing methods, by incorporating collaborative information.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4392864387",
    "type": "article"
  },
  {
    "title": "Privacy-preserving Cross-domain Recommendation with Federated Graph Learning",
    "doi": "https://doi.org/10.1145/3653448",
    "publication_date": "2024-03-21",
    "publication_year": 2024,
    "authors": "Changxin Tian; Yuexiang Xie; Xu Chen; Yaliang Li; Wayne Xin Zhao",
    "corresponding_authors": "",
    "abstract": "As people inevitably interact with items across multiple domains or various platforms, cross-domain recommendation (CDR) has gained increasing attention. However, the rising privacy concerns limit the practical applications of existing CDR models, since they assume that full or partial data are accessible among different domains. Recent studies on privacy-aware CDR models neglect the heterogeneity from multiple-domain data and fail to achieve consistent improvements in cross-domain recommendation; thus, it remains a challenging task to conduct effective CDR in a privacy-preserving way. In this article, we propose a novel, as far as we know, federated graph learning approach for Privacy-Preserving Cross-Domain Recommendation (PPCDR) to capture users’ preferences based on distributed multi-domain data and improve recommendation performance for all domains without privacy leakage. The main idea of PPCDR is to model both global preference among multiple domains and local preference at a specific domain for a given user, which characterizes the user’s shared and domain-specific tastes toward the items for interaction. Specifically, in the private update process of PPCDR, we design a graph transfer module for each domain to fuse global and local user preferences and update them based on local domain data. In the federated update process, through applying the local differential privacy technique for privacy-preserving, we collaboratively learn global user preferences based on multi-domain data and adapt these global preferences to heterogeneous domain data via personalized aggregation. In this way, PPCDR can effectively approximate the multi-domain training process that directly shares local interaction data in a privacy-preserving way. Extensive experiments on three CDR datasets demonstrate that PPCDR consistently outperforms competitive single- and cross-domain baselines and effectively protects domain privacy.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4393041761",
    "type": "article"
  },
  {
    "title": "FDKT: Towards an Interpretable Deep Knowledge Tracing via Fuzzy Reasoning",
    "doi": "https://doi.org/10.1145/3656167",
    "publication_date": "2024-04-05",
    "publication_year": 2024,
    "authors": "Fei Liu; Chenyang Bu; Haotian Zhang; Le Wu; Kui Yu; Xuegang Hu",
    "corresponding_authors": "",
    "abstract": "In educational data mining, knowledge tracing (KT) aims to model learning performance based on student knowledge mastery. Deep-learning-based KT models perform remarkably better than traditional KT and have attracted considerable attention. However, most of them lack interpretability, making it challenging to explain why the model performed well in the prediction. In this paper, we propose an interpretable deep KT model, referred to as fuzzy deep knowledge tracing (FDKT) via fuzzy reasoning. Specifically, we formalize continuous scores into several fuzzy scores using the fuzzification module. Then, we input the fuzzy scores into the fuzzy reasoning module (FRM). FRM is designed to deduce the current cognitive ability, based on which the future performance was predicted. FDKT greatly enhanced the intrinsic interpretability of deep-learning-based KT through the interpretation of the deduction of student cognition. Furthermore, it broadened the application of KT to continuous scores. Improved performance with regard to both the advantages of FDKT was demonstrated through comparisons with the state-of-the-art models.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4393992786",
    "type": "article"
  },
  {
    "title": "When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs",
    "doi": "https://doi.org/10.1145/3702639",
    "publication_date": "2024-11-05",
    "publication_year": 2024,
    "authors": "Marialena Bevilacqua; Kezia Oketch; Ruiyang Qin; Will Stamey; Xinyuan Zhang; Yi Gan; Kai Yang; Ahmed Abbasi",
    "corresponding_authors": "",
    "abstract": "The use of machine learning (ML) models to assess and score textual data has become increasingly pervasive in an array of contexts including natural language processing, information retrieval, search and recommendation, and credibility assessment of online content. A significant disruption at the intersection of ML and text are text-generating large-language models (LLMs) such as generative pre-trained transformers (GPTs). We empirically assess the differences in how ML-based scoring models trained on human content assess the quality of content generated by humans versus GPTs. To do so, we propose an analysis framework that encompasses essay scoring ML-models, human and ML-generated essays, and a statistical model that parsimoniously considers the impact of type of respondent, prompt genre, and the ML model used for assessment model. A rich testbed is utilized that encompasses 18,460 human-generated and GPT-based essays. Results of our benchmark analysis reveal that LLMs and transformer pretrained language models (PLMs) more accurately score human essay quality as compared to CNN/RNN and feature-based ML methods. Interestingly, we find that LLMs and transformer PLMs tend to score GPT-generated text 10-20% higher on average, relative to human-authored documents. Conversely, traditional deep learning and feature-based ML models score human text considerably higher. Further analysis reveals that even though the LLMs and transformer PLMs are exclusively fine-tuned on human text, they more prominently attend to certain tokens appearing only in GPT-generated text, possibly (in part) due to familiarity/overlap in pre-training. Our framework and results have implications for text classification settings where automated scoring of text is likely to be disrupted by generative AI.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4404058379",
    "type": "article"
  },
  {
    "title": "A Thorough Performance Benchmarking on Lightweight Embedding-based Recommender Systems",
    "doi": "https://doi.org/10.1145/3712589",
    "publication_date": "2025-01-17",
    "publication_year": 2025,
    "authors": "Hung Vinh Tran; Tong Chen; Quoc Viet Hung Nguyen; Zi Huang; Lizhen Cui; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "Since the creation of the Web, recommender systems (RSs) have been an indispensable personalization mechanism in information filtering. Most state-of-the-art RSs primarily depend on categorical features such as user and item IDs, and use embedding vectors to encode their information for accurate recommendations, resulting in an excessively large embedding table owing to the immense feature corpus. To prevent the heavily parameterized embedding table from harming RSs’ scalability, both academia and industry have seen increasing efforts compressing RS embeddings, and this trend is further amplified by the recent uptake in edge computing for online services. However, despite the prosperity of existing lightweight embedding-based RSs (LERSs), a strong diversity is seen in the evaluation protocols adopted across publications, resulting in obstacles when relating the reported performance of those LERSs to their real-world usability. On the other hand, among the two fundamental recommendation tasks, namely traditional collaborative filtering and content-based recommendation, despite their common goal of achieving lightweight embeddings, the outgoing LERSs are designed and evaluated with a straightforward “either-or” choice between the two tasks. Consequently, the lack of discussions on a method's cross-task transferability will likely hinder the development of unified, more scalable solutions for production environments. Motivated by these unresolved issues, this study aims to systematically investigate existing LERSs’ performance, efficiency, and cross-task transferability via a thorough benchmarking process. To create a generic, task-independent baseline, we propose an efficient embedding compression approach based on magnitude pruning, which is proven to be an easy-to-deploy yet highly competitive baseline that outperforms various complex LERSs. Our study reveals the distinct performance of different LERSs across the two recommendation tasks, shedding light on their effectiveness and generalizability under different settings. Furthermore, to account for edge-based recommendation – an increasingly popular use case of LERSs, we have also deployed and tested all LERSs on a Raspberry Pi 4, where their efficiency bottleneck is exposed compared with GPU-based deployment. Finally, we conclude this paper with critical summaries on the performance comparison, suggestions on model selection based on task objectives, and underexplored challenges around the applicability of existing LERSs for future research. To encourage and support future LERS research, we publish all source codes and data, checkpoints, and documentation at https://github.com/chenxing1999/recsys-benchmark .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4406495324",
    "type": "article"
  },
  {
    "title": "Reinforced Prompt Personalization for Recommendation with Large Language Models",
    "doi": "https://doi.org/10.1145/3716320",
    "publication_date": "2025-02-04",
    "publication_year": 2025,
    "authors": "Wenyu Mao; Jiancan Wu; Jiawei Chen; Chongming Gao; Xiang Wang; Xiangnan He",
    "corresponding_authors": "",
    "abstract": "Designing effective prompts can empower LLMs to understand user preferences and provide recommendations with intent comprehension and knowledge utilization capabilities. Nevertheless, recent studies predominantly concentrate on task-wise prompting, developing fixed prompt templates shared across all users in a given recommendation task ( e.g., rating or ranking). Although convenient, task-wise prompting overlooks individual user differences, leading to inaccurate analysis of user interests. In this work, we introduce the concept of instance-wise prompting, aiming at personalizing discrete prompts for individual users. Toward this end, we propose Reinforced Prompt Personalization (RPP) to realize it automatically. To improve efficiency and quality, RPP personalizes prompts at the sentence level rather than searching in the vast vocabulary word-by-word. Specifically, RPP breaks down the prompt into four patterns, tailoring patterns based on multi-agent and combining them. Then the personalized prompts interact with LLMs (environment) iteratively, to boost LLMs’ recommending performance (reward). In addition to RPP, to improve the scalability of action space, our proposal of RPP+ dynamically refines the selected actions with LLMs throughout the iterative process. Extensive experiments on various datasets demonstrate the superiority of RPP/RPP+ over traditional recommender models, few-shot methods, and other prompt-based methods, underscoring the significance of instance-wise prompting in LLMs for recommendation. Our code is available at https://github.com/maowenyu-11/RPP .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4407134979",
    "type": "article"
  },
  {
    "title": "Comprehend Then Predict: Prompting Large Language Models for Recommendation with Semantic and Collaborative Data",
    "doi": "https://doi.org/10.1145/3716499",
    "publication_date": "2025-02-07",
    "publication_year": 2025,
    "authors": "Zhiang Dong; Liya Hu; Jingyuan Chen; Zhihua Wang; Fei Wu",
    "corresponding_authors": "",
    "abstract": "Recommender systems primarily utilize user-item interactions ( i.e. , collaborative information) and auxiliary textual information ( i.e. , semantic information) to infer user preferences and provide recommendations. With the advancement in large language models (LLMs), attempts have been made to incorporate their remarkable language comprehension capabilities into recommendation tasks. However, existing LLM4Rec methods face challenges in seamlessly integrating both collaborative and semantic information, as there is an inherent gap between these two types of data. Moreover, these methods struggle to capture the fine-grained distinctions in user preferences, which are essential in recommendation tasks, due to the loss design of LLMs. To address these issues, we propose a multi-stage prompt tuning method for leveraging pre-trained LLMs in various recommendation tasks, named SCRec . Specifically, SCRec leverages S emantic and C ollaborative information as supervision signals in two distinct stages: the semantic prompt-tuning stage and the collaborative prompt-tuning stage. This method breaks down user and item representations into semantic and collaborative perspectives, enabling a pre-trained LLM to first deduce the qualitative preferences of users over items from semantic information, and then generate quantitative recommendations from collaborative information. In addition, we propose a meta-mapping approach to provide personalized mapping functions for encoding collaborative information and integrate a novel numeric-informed head based on MSE loss for LLM in the second stage, which helps to better capture fine-grained distinctions in user preferences. Experiments on three public datasets for rating prediction and top-N recommendation tasks demonstrate that our method surpasses both conventional and LLM-based techniques, showing the strength of sequentially merging semantic and collaborative information in recommendation tasks.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4407252812",
    "type": "article"
  },
  {
    "title": "ARTS: A General and Efficient Multi-Task Self-Prompt Framework for Explainable Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3717833",
    "publication_date": "2025-02-14",
    "publication_year": 2025,
    "authors": "Zunlong Liu; Yang Xu; Gao Cong; Lei Zhu; Qinjun Qiu; Huaxiang Zhang",
    "corresponding_authors": "",
    "abstract": "Providing sequential recommendations along with easily comprehensible natural language explanations can significantly enhance users’ trust in the recommender systems. However, this approach presents two key challenges: 1) The different objectives of the two tasks make it challenging to achieve joint optimization and mutual enhancement. 2) The simultaneous generation of accurate sequential recommendations and high-quality natural language explanations presents serious challenges to the model’s time and space efficiency. To address these challenges, we propose a general and efficient multi-task self-prompt framework for explainable sequential recommendation (ARTS), which improves collaboration performance and time and space efficiency of multi-task modules based on the generated personalized semantic prompts. Specifically, we propose a self-prompt generator that transfers the user’s global behavior features into the continuous prompt, achieving efficient information sharing among multi-task modules. Additionally, we design a personalized prompt-based short sequence inputs strategy under the pre-training and prompt-tuning paradigm, which achieves mutual enhancement among the multi-task modules and significantly improves the model’s time and space efficiency. Extensive experiments have verified that the proposed ARTS outperforms the state-of-the-art methods in both sequential recommendation and explanation generation tasks. The generality, efficiency and effectiveness of each module of the framework have also been validated through various experiments 1 .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4407564391",
    "type": "article"
  },
  {
    "title": "Hierarchical Gating Network for Cross-Domain Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3715321",
    "publication_date": "2025-03-03",
    "publication_year": 2025,
    "authors": "Shuliang Wang; Jiabao Zhu; Yi Wang; Chen Ma; Xin Zhao; Yansen Zhang; Ziqiang Yuan; Sijie Ruan",
    "corresponding_authors": "",
    "abstract": "Cross-domain sequential recommendation (CDSR) utilizes data from multiple domains to recommend the user’s next interaction based on his latest interaction sequence. Currently, many cross-domain sequential recommendation algorithms have been proven to achieve good recommendation performance. However, these algorithms overlook the influence of users’ long-term behavioral patterns and general interests when extracting their current preferences. In this article, we propose a Hierarchical Gating Network for Cross-Domain Sequential Recommendation (HGNCDSR). Specifically, we simultaneously train single-domain and cross-domain interaction sequences, utilizing a hierarchical gating network to capture user interest representations in single-domain and cross-domain, respectively. A feature gating and an instance gating are applied respectively to extract user interests at item feature level and instance level. While learning current preferences from behavior sequences, user representations that reflect behavioral patterns and general interests are simultaneously learned and strengthened. Additionally, we employ the item–item product to model the relationships between candidate items and those in the interaction sequence. Both current interests and item relevance are considered simultaneously, integrating single-domain and cross-domain user preferences to predict the user’s next interaction. We design extensive experiments to show that HGNCDSR has better recommendation performance than other state-of-the-art models.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4408112514",
    "type": "article"
  },
  {
    "title": "Using Chao’s Estimator as a Stopping Criterion for Technology-Assisted Review",
    "doi": "https://doi.org/10.1145/3724116",
    "publication_date": "2025-03-17",
    "publication_year": 2025,
    "authors": "Michiel Pieter Bron; P.G.M. van der Heijden; Ad Feelders; Arno Siebes",
    "corresponding_authors": "",
    "abstract": "Technology-Assisted Review (TAR) aims to reduce the human effort required for screening processes such as abstract screening for systematic literature reviews. Human reviewers label documents as relevant or irrelevant during this process, while the system incrementally updates a prediction model based on the reviewers’ previous decisions. After each model update, the system proposes new documents it deems relevant, to prioritize relevant documents over irrelevant ones. A stopping criterion is necessary to guide users in stopping the review process to minimize the number of missed relevant documents and the number of read irrelevant documents. In this paper, we propose and evaluate a new ensemble-based Active Learning strategy and a stopping criterion based on Chao’s Population Size Estimator that estimates the prevalence of relevant documents in the dataset. Our simulation study demonstrates that this criterion performs well on several datasets and is compared to other methods presented in the literature.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4408528803",
    "type": "article"
  },
  {
    "title": "QUADEN: Discovering Latent Neighbors for Sparse Users and Items Across Interaction Quadrants in Recommender System",
    "doi": "https://doi.org/10.1145/3725886",
    "publication_date": "2025-03-26",
    "publication_year": 2025,
    "authors": "Nakarin Sritrakool; Saranya Maneeroj; Atsuhiro Takasu",
    "corresponding_authors": "",
    "abstract": "Many recommender systems leverage Graph Neural Networks to capture user-item relations for delivering recommendations. However, the representation of nodes heavily relies on neighbors, causing limited neighbor nodes (sparse nodes) to lack expressive representation. Existing works discovered latent neighbors for sparse nodes but ignored node sparsity, resulting in the neighbor misallocation problem due to overlooking quality and quantity aspects. We propose discovering high-quality latent neighbors by progressively transferring knowledge from dense nodes by categorizing user-item interactions into four quadrants (dense user-dense item, dense user-sparse item, sparse user-dense item, and sparse user-sparse item). We leverage the node sparsity to determine the optimal quantity of latent neighbors. We propose a Domain Adaptation Network for transferring knowledge from dense to sparse quadrants without encountering the domain misalignment problem arising from the distinct representations between dense and sparse quadrants. An Enrichment Network is proposed to address the inexpressive representation problem due to limited observed interactions by enriching the sparse node representation. A Heterogeneous Graph Neural Network architecture is proposed to capture multiple relations between dense/sparse users and items. Experimental results on three benchmark datasets demonstrate the superiority of the proposed method over Graph Neural Network baselines, both with and without latent neighbors.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4408871261",
    "type": "article"
  },
  {
    "title": "PolyCF: Towards Optimal Spectral Graph Filters for Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3728464",
    "publication_date": "2025-04-07",
    "publication_year": 2025,
    "authors": "Yifang Qin; Wei Ju; Yiyang Gu; Ziyue Qiao; Zhiping Xiao; Ming Zhang",
    "corresponding_authors": "",
    "abstract": "Collaborative Filtering (CF) is a pivotal research area in recommender systems that capitalizes on collaborative similarities between users and items to provide personalized recommendations. With the remarkable achievements of node embedding-based Graph Neural Networks (GNNs), we explore the upper bounds of expressiveness inherent to embedding-based methodologies, and tackle the challenges by reframing the CF task as a graph-signal processing problem. To this end, we propose PolyCF, a flexible graph signal filter that leverages polynomial graph filters to process interaction signals. PolyCF exhibits the capability to capture spectral features across multiple eigenspaces through a series of Generalized Gram filters, and is able to approximate the optimal polynomial response function for recovering missing interactions. A graph optimization objective and a pair-wise ranking objective are jointly used to optimize the parameters of the convolution kernel. Experiments on three widely adopted datasets demonstrate the superiority of PolyCF over the state-of-the-art CF methods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4409218275",
    "type": "article"
  },
  {
    "title": "Query Performance Prediction using Relevance Judgments Generated by Large Language Models",
    "doi": "https://doi.org/10.1145/3736402",
    "publication_date": "2025-05-19",
    "publication_year": 2025,
    "authors": "Chuan Meng; Negar Arabzadeh; Arian Askari; Mohammad Aliannejadi; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Query performance prediction (QPP) aims to estimate the retrieval quality of a search system for a query without human relevance judgments. Previous QPP methods typically return a single scalar value and do not require the predicted values to approximate a specific information retrieval (IR) evaluation measure, leading to certain drawbacks: (i) a single scalar is insufficient to accurately represent different IR evaluation measures, especially when metrics do not highly correlate, and (ii) a single scalar limits the interpretability of QPP methods because solely using a scalar is insufficient to explain QPP results. To address these issues, we propose a QPP framework using automatically gen erated re levance judgments (QPP-GenRE), which decomposes QPP into independent subtasks of predicting the relevance of each item in a ranked list to a given query. This allows us to predict any IR evaluation measure using the generated relevance judgments as pseudo-labels. This also allows us to interpret predicted IR evaluation measures, and identify, track, and rectify errors in generated relevance judgments to improve QPP quality. We predict an item’s relevance by using open source large language models (LLMs) to ensure scientific reproducibility. We face two main challenges: (i) excessive computational costs of judging an entire corpus for predicting a metric considering recall, and (ii) limited performance in prompting open source LLMs in a zero-/few-shot manner. To solve the challenges, we devise an approximation strategy to predict an IR measure considering recall and propose to fine-tune open source LLMs using human-labeled relevance judgments. Experiments on the TREC 2019–2022 deep learning tracks and CAsT-19–20 datasets show that QPP-GenRE achieves state-of-the-art QPP quality for both lexical and neural rankers.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4410502462",
    "type": "article"
  },
  {
    "title": "Causality-Inspired Fair Representation Learning for Multimodal Recommendation",
    "doi": "https://doi.org/10.1145/3744240",
    "publication_date": "2025-06-09",
    "publication_year": 2025,
    "authors": "Weixin Chen; Li Chen; Yongxin Ni; Yuhan Zhao",
    "corresponding_authors": "",
    "abstract": "Recently, multimodal recommendations (MMR) have gained increasing attention for alleviating the data sparsity problem of traditional recommender systems by incorporating modality-based representations. Although MMR exhibits notable improvement in recommendation accuracy, we empirically validate that an increase in the quantity or variety of modalities leads to a higher degree of users’ sensitive information leakage due to entangled causal relationships, risking fair representation learning. On the other hand, existing fair representation learning approaches are mostly based on the assumption that sensitive information is solely leaked from users’ interaction data and do not explicitly model the causal relationships introduced by multimodal data, which limits their applicability in multimodal scenarios. To address this limitation, we propose a novel fair multimodal recommendation approach (dubbed FMMRec) through causality-inspired fairness-oriented modal disentanglement and relation-aware fairness learning. Particularly, we disentangle biased and filtered modal embeddings inspired by causal inference techniques, enabling the mining of modality-based unfair and fair user-user relations, thereby enhancing the fairness and informativeness of user representations. By addressing the causal effects of sensitive attributes on user preferences, our approach aims to achieve counterfactual fairness in multimodal recommendations. Experiments on two public datasets demonstrate the superiority of our FMMRec relative to the state-of-the-art baselines. Our source code is available at https://github.com/WeixinChen98/FMMRec .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4411134774",
    "type": "article"
  },
  {
    "title": "Large Language Models for Information Retrieval: A Survey",
    "doi": "https://doi.org/10.1145/3748304",
    "publication_date": "2025-09-05",
    "publication_year": 2025,
    "authors": "Yutao Zhu; Huaying Yuan; Shuting Wang; Jiongnan Liu; Wenhan Liu; Chenlong Deng; Haonan Chen; Zheng Liu; Zhicheng Dou; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs) has revolutionized natural language processing due to their remarkable language understanding, generation, and reasoning abilities. Consequently, recent research has sought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate existing methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence of LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, readers, and search agents.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4414014501",
    "type": "article"
  },
  {
    "title": "A statechart-based model for hypermedia applications",
    "doi": "https://doi.org/10.1145/366836.366869",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Maria Cristina Ferreira de Oliveira; Marcelo Augusto Santos Turine; Paulo César Masiero",
    "corresponding_authors": "",
    "abstract": "This paper presents a formal definition for HMBS (Hypermedia Model Based on Statecharts). HMBS uses the structure and execution semantics of statecharts to specify both the structural organization and the browsing semantics of hypermedia applications. Statecharts are an extension of finite-state machines and the model is thus a generalization of hypergraph-based hypertext models. Some of the most important features of HMBS are its ability to model hierarchy and synchronization of information; provision of mechanisms for specifying access structures, navigational contexts, access control, multiple tailored versions,and hierarchical views. Analysis of the underlying statechart machine allows verification of page reachability, valid paths, and other properties, thus providing mechanisms to support authors in the development of structured applications.",
    "cited_by_count": 101,
    "openalex_id": "https://openalex.org/W2001233447",
    "type": "article"
  },
  {
    "title": "A corpus analysis approach for automatic query expansion and its extension to multiple databases",
    "doi": "https://doi.org/10.1145/314516.314519",
    "publication_date": "1999-07-01",
    "publication_year": 1999,
    "authors": "Susan Gauch; Jianying Wang; Satya Mahesh Rachakonda",
    "corresponding_authors": "",
    "abstract": "Searching online text collections can be both rewarding and frustrating. While valuable information can be found, typically many irrelevant documents are also retrieved, while many relevant ones are missed. Terminology mismatches between the user's query and document contents are a main cause of retrieval failures. Expanding a user's query with related words can improve search performances, but finding and using related words is an open problem. This research uses corpus analysis techniques to automatically discover similar words directly from the contents of the databases which are not tagged with part-of-speech labels. Using these similarities, user queries are automatically expanded, resulting in conceptual retrieval rather than requiring exact word matches between queries and documents. We are able to achieve a 7.6% improvement for TREC 5 queries and up to a 28.5% improvement on the narrow-domain Cystic Fibrosis collection. This work has been extended to multidatabase collections where each subdatabase has a collection-specific similarity matrix associated with it. If the best matrix is selected, substantial search improvements are possible. Various techniques to select the appropriate matrix for a particular query are analyzed, and a 4.8% improvement in the results is validated.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W2156927361",
    "type": "article"
  },
  {
    "title": "Theory of keyblock-based image retrieval",
    "doi": "https://doi.org/10.1145/506309.506313",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "Lei Zhu; A. Rao; Aldong Zhang",
    "corresponding_authors": "",
    "abstract": "The success of text-based retrieval motivates us to investigate analogous techniques which can support the querying and browsing of image data. However, images differ significantly from text both syntactically and semantically in their mode of representing and expressing information. Thus, the generalization of information retrieval from the text domain to the image domain is non-trivial. This paper presents a framework for information retrieval in the image domain which supports content-based querying and browsing of images. A critical first step to establishing such a framework is to construct a codebook of \"keywords\" for images which is analogous to the dictionary for text documents. We refer to such \"keywords\" in the image domain as \"keyblocks.\" In this paper, we first present various approaches to generating a codebook containing keyblocks at different resolutions. Then we present a keyblock-based approach to content-based image retrieval. In this approach, each image is encoded as a set of one-dimensional index codes linked to the keyblocks in the codebook, analogous to considering a text document as a linear list of keywords. Generalizing upon text-based information retrieval methods, we then offer various techniques for image-based information retrieval. By comparing the performance of this approach with conventional techniques using color and texture features, we demonstrate the effectiveness of the keyblock-based approach to content-based image retrieval.",
    "cited_by_count": 96,
    "openalex_id": "https://openalex.org/W1999412262",
    "type": "article"
  },
  {
    "title": "A network approach to probabilistic information retrieval",
    "doi": "https://doi.org/10.1145/203052.203067",
    "publication_date": "1995-07-01",
    "publication_year": 1995,
    "authors": "K. L. Kwok",
    "corresponding_authors": "K. L. Kwok",
    "abstract": "In this article we show how probabilistic information retrieval based on document components may be implemented as a feedforward (feedbackward) artificial neural network. The network supports adaptation of connection weights as well as the growing of new edges between queries and terms based on user relevance feedback data for training, and it reflects query modification and expansion in information retrieval. A learning rule is applied that can also be viewed as supporting sequential learning using a harmonic sequence learning rate. Experimental results with four standard small collections and a large Wall Street Journal collection (173,219 documents) show that performance of feedback improves substantially over no feedback, and further gains are obtained when queries are expanded with terms from the feedback documents. The effect is much more pronounced in small collections than in the large collection. Query expansion may be considered as a tool for both precision and recall enhancement. In particular, small query expansion levels of about 30 terms can achieve most of the gains at the low-recall high-precision region, while larger expansion levels continue to provide gains at the high-recall low-precision region of a precision recall curve.",
    "cited_by_count": 91,
    "openalex_id": "https://openalex.org/W1965108324",
    "type": "article"
  },
  {
    "title": "A nested-graph model for the representation and manipulation of complex objects",
    "doi": "https://doi.org/10.1145/174608.174610",
    "publication_date": "1994-01-02",
    "publication_year": 1994,
    "authors": "Alexandra Poulovassilis; Mark Levene",
    "corresponding_authors": "",
    "abstract": "Three recent trends in database research are object-oriented and deductive databases and graph-based user interfaces. We draw these trends together in a data model we call the Hypernode Model. The single data structure of this model is the hypernode , a graph whose nodes can themselves be graphs. Hypernodes are typed, and types, too, are nested graphs. We give the theoretical foundations of hypernodes and types, and we show that type checking is tractable. We show also how conventional type-forming operators can be simulated by our graph types, including cyclic types. The Hypernode Model comes equipped with a rule-based query language called Hyperlog, which is complete with respect to computation and update. We define the operational semantics of Hyperlog and show that the evaluation can be performed efficiently. We discuss also the use of Hyperlog for supporting database browsing, an essential feature of Hypertext databases. We compare our work with other graph-based data models—unlike previous graph-based models, the Hypernode Model provides inherent support for data abstraction via its nesting of graphs. Finally, we briefly discuss the implementation of a DBMS based on the Hypernode Model.",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W2032566068",
    "type": "article"
  },
  {
    "title": "XIRQL",
    "doi": "https://doi.org/10.1145/984321.984326",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Norbert Fuhr; Kai Groβjohann",
    "corresponding_authors": "",
    "abstract": "XIRQL (\"circle\") is an XML query language that incorporates imprecision and vagueness for both structural and content-oriented query conditions. The corresponding uncertainty is handled by a consistent probabilistic model. The core features of XIRQL are (1) document ranking based on index term weighting, (2) specificity-oriented search for retrieving the most relevant parts of documents, (3) datatypes with vague predicates for dealing with specific types of content and (4) structural vagueness for vague interpretation of structural query conditions. A XIRQL database may contain several classes of documents, where all documents in a class conform to the same DTD; links between documents also are supported. XIRQL queries are translated into a path algebra, which can be processed by our HyREX retrieval engine.",
    "cited_by_count": 89,
    "openalex_id": "https://openalex.org/W2104804211",
    "type": "article"
  },
  {
    "title": "TROLL",
    "doi": "https://doi.org/10.1145/226163.226166",
    "publication_date": "1996-04-01",
    "publication_year": 1996,
    "authors": "Ralf Jungclaus; Gunter Saake; Thorsten Hartmann; Cristina Sernadas",
    "corresponding_authors": "",
    "abstract": "TROLL is a language particularly suited for the early stages of information system development, when the universe of discourse must be described. In TROLL the descriptions of the static and dynamic aspects of entities are integrated into object descriptions. Sublanguages for data terms, for first-order and temporal assertions, and for processes, are used to describe respectively the static properties, the behavior, and the evolution over time of objects. TROLL organizes system design through object-orientation and the support of abstractions such as classification, specialization, roles, and aggregation. Language features for state interactions and dependencies among components support the composition of the system from smaller modules, as does the facility of defining interfaces on top of object descriptions.",
    "cited_by_count": 86,
    "openalex_id": "https://openalex.org/W2000069466",
    "type": "article"
  },
  {
    "title": "Efficient passage ranking for document databases",
    "doi": "https://doi.org/10.1145/326440.326445",
    "publication_date": "1999-10-01",
    "publication_year": 1999,
    "authors": "Marcin Kaszkiel; Justin Zobel; Ron Sacks‐Davis",
    "corresponding_authors": "",
    "abstract": "Queries to text collections are resolved by ranking the documents in the collection and returning the highest-scoring documents to the user. An alternative retrieval method is to rank passages, that is, short fragments of documents, a strategy that can improve effectiveness and identify relevant material in documents that are too large for users to consider as a whole. However, ranking of passages can considerably increase retrieval costs. In this article we explore alternative query evaluation techniques, and develop new tecnhiques for evaluating queries on passages. We show experimentally that, appropriately implemented, effective passage retrieval is practical in limited memory on a desktop machine. Compared to passage ranking with adaptations of current document ranking algorithms, our new “DO-TOS” passage-ranking algorithm requires only a fraction of the resources, at the cost of a small loss of effectiveness.",
    "cited_by_count": 86,
    "openalex_id": "https://openalex.org/W2026095310",
    "type": "article"
  },
  {
    "title": "Lessons learned from SUIT, the simple user interface toolkit",
    "doi": "https://doi.org/10.1145/146486.146489",
    "publication_date": "1992-10-01",
    "publication_year": 1992,
    "authors": "Randy Pausch; Matthew Conway; Robert DeLine",
    "corresponding_authors": "",
    "abstract": "In recent years, the computer science community has realized the advantages of GUIs (Graphical User Interfaces). Because high-quality GUIs are difficult to build, support tools such as UIMSs, UI Toolkits, and Interface Builders have been developed. Although these tools are powerful, they typically make two assumptions: first, that the programmer has some familiarity with the GUI model, and second, that he is willing to invest several weeks becoming proficient with the tool. These tools typically operate only on specific platforms, such as DOS, the Macintosh, or UNIX/X-windows. The existing tools are beyond the reach of most undergraduate computer science majors, or professional programmers who wish to quickly build GUIs without investing the time to become specialists in GUI design. For this class of users, we developed SUIT , the S imple U ser I interface T oolkit. SUIT is an attempt to distill the fundamental components of an interface builder and GUI toolkit, and to explain those concepts with the tool itself, all in a short period of time. We have measured that college juniors with no previous GUI programming experience can use SUIT productively after less than three hours. SUIT is a C subroutine library which provides an external control UIMS, an interactive layout editor, and a set of standard “widgets,” such as sliders, buttons, and check boxes. SUIT-based applications run transparently across the Macintosh, DOS, and UNIX/X platforms. SUIT has been exported to hundreds of external sites on the internet. This paper describes SUIT's architecture, the design decisions we made during its development, and the lessons we learned from extensive observations of over 120 users.",
    "cited_by_count": 85,
    "openalex_id": "https://openalex.org/W2110843817",
    "type": "article"
  },
  {
    "title": "Anchor text mining for translation of Web queries",
    "doi": "https://doi.org/10.1145/984321.984324",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Wen‐Hsiang Lu; Lee‐Feng Chien; Hsi-Jian Lee",
    "corresponding_authors": "",
    "abstract": "To discover translation knowledge in diverse data resources on the Web, this article proposes an effective approach to finding translation equivalents of query terms and constructing multilingual lexicons through the mining of Web anchor texts and link structures. Although Web anchor texts are wide-scoped hypertext resources, not every particular pair of languages contains sufficient anchor texts for effective extraction of translations for Web queries. For more generalized applications, the approach is designed based on a transitive translation model. The translation equivalents of a query term can be extracted via its translation in an intermediate language. To reduce interference from translation errors, the approach further integrates a competitive linking algorithm into the process of determining the most probable translation. A series of experiments has been conducted, including performance tests on term translation extraction, cross-language information retrieval, and translation suggestions for practical Web search services, respectively. The obtained experimental results have shown that the proposed approach is effective in extracting translations of unknown queries, is easy to combine with the probabilistic retrieval model to improve the cross-language retrieval performance, and is very useful when the considered language pairs lack a sufficient number of anchor texts. Based on the approach, an experimental system called LiveTrans has been developed for English--Chinese cross-language Web search.",
    "cited_by_count": 84,
    "openalex_id": "https://openalex.org/W2094154703",
    "type": "article"
  },
  {
    "title": "Bureaucracies as deontic systems",
    "doi": "https://doi.org/10.1145/45941.45944",
    "publication_date": "1988-04-01",
    "publication_year": 1988,
    "authors": "Ronald M. Lee",
    "corresponding_authors": "Ronald M. Lee",
    "abstract": "Bureaucratic offices are not only for clerical work, but more important, they are for officiating in the sense of issuing directives, granting permissions, enforcing prohibitions, waiving obligations, and so forth. Bureaucracies are thus deontic systems for organizational and social control. Conventional information processing approaches are inadequate for capturing these aspects of bureaucratic modeling. A logic-based representation that emphasizes deontic and performative aspects is proposed.",
    "cited_by_count": 82,
    "openalex_id": "https://openalex.org/W2102702767",
    "type": "article"
  },
  {
    "title": "Detection of video sequences using compact signatures",
    "doi": "https://doi.org/10.1145/1125857.1125858",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Justin Zobel; Timothy C. Hoad",
    "corresponding_authors": "",
    "abstract": "Digital representations are widely used for audiovisual content, enabling the creation of large online repositories of video, allowing access such as video on demand. However, the ease of copying and distribution of digital video makes piracy a growing concern for content owners. We investigate methods for identifying coderivative video content---that is, video clips that are derived from the same original source. By using dynamic programming to identify regions of similarity in video signatures, it is possible to efficiently and accurately identify coderivatives, even when these regions constitute only a small section of the clip being searched. We propose four new methods for producing compact video signatures, based on the way in which the video changes over time. The intuition is that such properties are likely to be preserved even when the video is badly degraded. We demonstrate that these signatures are insensitive to dramatic changes in video bitrate and resolution, two parameters that are often altered when reencoding. In the presence of mild degradations, our methods can accurately identify copies of clips that are as short as 5 s within a dataset 140 min long. These methods are much faster than previously proposed techniques; using a more compact signature, this query can be completed in a few milliseconds.",
    "cited_by_count": 80,
    "openalex_id": "https://openalex.org/W2081429741",
    "type": "article"
  },
  {
    "title": "Soft pattern matching models for definitional question answering",
    "doi": "https://doi.org/10.1145/1229179.1229182",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "Hang Cui; Min‐Yen Kan; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "We explore probabilistic lexico-syntactic pattern matching, also known as soft pattern matching, in a definitional question answering system. Most current systems use regular expression-based hard matching patterns to identify definition sentences. Such rigid surface matching often fares poorly when faced with language variations. We propose two soft matching models to address this problem: one based on bigrams and the other on the Profile Hidden Markov Model (PHMM). Both models provide a theoretically sound method to model pattern matching as a probabilistic process that generates token sequences. We demonstrate the effectiveness of the models on definition sentence retrieval for definitional question answering. We show that both models significantly outperform the state-of-the-art manually constructed hard matching patterns on recent TREC data. A critical difference between the two models is that the PHMM has a more complex topology. We experimentally show that the PHMM can handle language variations more effectively but requires more training data to converge. While we evaluate soft pattern models only on definitional question answering, we believe that both models are generic and can be extended to other areas where lexico-syntactic pattern matching can be applied.",
    "cited_by_count": 78,
    "openalex_id": "https://openalex.org/W2163563768",
    "type": "article"
  },
  {
    "title": "FORMANAGER",
    "doi": "https://doi.org/10.1145/1206.357413",
    "publication_date": "1984-08-23",
    "publication_year": 1984,
    "authors": "S. Bing Yao; Alan R. Hevner; Zhongzhi Shi; Da-Wei Luo",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on FORMANAGER: an office forms management system Authors: S. Bing Yao Database Systems Research Center, College of Business and Management, University of Maryland, College Park, MD Database Systems Research Center, College of Business and Management, University of Maryland, College Park, MDView Profile , Alan R. Hevner Database Systems Research Center, College of Business and Management, University of Maryland, College Park, MD Database Systems Research Center, College of Business and Management, University of Maryland, College Park, MDView Profile , Zhongzhi Shi Database Systems Research Center, College of Business and Management, University of Maryland, College Park, MD Database Systems Research Center, College of Business and Management, University of Maryland, College Park, MDView Profile , Dawei Luo Database Systems Research Center, College of Business and Management, University of Maryland, College Park, MD Database Systems Research Center, College of Business and Management, University of Maryland, College Park, MDView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 3pp 235–262https://doi.org/10.1145/1206.357413Published:23 August 1984Publication History 66citation781DownloadsMetricsTotal Citations66Total Downloads781Last 12 Months135Last 6 weeks20 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 77,
    "openalex_id": "https://openalex.org/W2016879718",
    "type": "article"
  },
  {
    "title": "Dynamic partitioning of signature files",
    "doi": "https://doi.org/10.1145/119311.119313",
    "publication_date": "1991-10-01",
    "publication_year": 1991,
    "authors": "Pavel Zezula; Fausto Rabitti; Paolo Tiberio",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Dynamic partitioning of signature files Authors: P. Zezula IEI-CNR, Pisa, Italy IEI-CNR, Pisa, ItalyView Profile , F. Rabitti IEI-CNR, Pisa, Italy IEI-CNR, Pisa, ItalyView Profile , P. Tiberio Univ. of Bologna, Bologna, Italy Univ. of Bologna, Bologna, ItalyView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 9Issue 4Oct. 1991 pp 336–367https://doi.org/10.1145/119311.119313Published:01 October 1991Publication History 55citation544DownloadsMetricsTotal Citations55Total Downloads544Last 12 Months15Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 77,
    "openalex_id": "https://openalex.org/W2054739439",
    "type": "article"
  },
  {
    "title": "Human factors challenges in creating a principal support office system—the speech filing system approach",
    "doi": "https://doi.org/10.1145/357442.357443",
    "publication_date": "1983-10-01",
    "publication_year": 1983,
    "authors": "John D. Gould; Stephen J. Boies",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Human factors challenges in creating a principal support office system—the speech filing system approach Authors: John D. Gould IBM Thomas J. Watson Research Center, Yorktown Heights, NY IBM Thomas J. Watson Research Center, Yorktown Heights, NYView Profile , Stephen J. Boies IBM Thomas J. Watson Research Center, Yorktown Heights, NY IBM Thomas J. Watson Research Center, Yorktown Heights, NYSearch about this author Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 4pp 273–298https://doi.org/10.1145/357442.357443Published:01 October 1983Publication History 76citation732DownloadsMetricsTotal Citations76Total Downloads732Last 12 Months43Last 6 weeks8 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2030070180",
    "type": "article"
  },
  {
    "title": "Computer analysis of user interfaces based on repetition in transcripts of user sessions",
    "doi": "https://doi.org/10.1145/119311.119312",
    "publication_date": "1991-10-01",
    "publication_year": 1991,
    "authors": "Antonio C. Siochi; Roger W. Ehrich",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Computer analysis of user interfaces based on repetition in transcripts of user sessions Authors: Antonio C. Siochi Christopher Newport College, Newport News, VA Christopher Newport College, Newport News, VAView Profile , Roger W. Ehrich Virginia Polytechnic Institute and State Univ., Blacksburg Virginia Polytechnic Institute and State Univ., BlacksburgView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 9Issue 4pp 309–335https://doi.org/10.1145/119311.119312Published:01 October 1991Publication History 44citation699DownloadsMetricsTotal Citations44Total Downloads699Last 12 Months30Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2075757647",
    "type": "article"
  },
  {
    "title": "Imprecise information and uncertainty in information systems",
    "doi": "https://doi.org/10.1145/96105.96113",
    "publication_date": "1990-04-01",
    "publication_year": 1990,
    "authors": "J.M. Morrissey",
    "corresponding_authors": "J.M. Morrissey",
    "abstract": "Information systems exist to model, store, and retrieve all types of data. Problems arise when some of the data are missing or imprecisely known or when an attribute is not applicable to a particular object. A consistent and useful treatment of such exceptions is necessary. The approach taken here is to allow any attribute value to be a regular precise value, a string denoting that the value is missing, a string denoting that the attribute is not applicable, or an imprecise value. The imprecise values introduce uncertainty into query evaluation, since it is no longer obvious which objects should be retrieved. To handle the uncertainty, two set of objects are retrieved in response to every query: the set of objects that are known to satisfy with complete certainty and the set that possibly satisfies the query with various degrees of uncertainty. Two methods of estimating this uncertainty, based on information theory, are proposed. The measure of uncertainty is used to rank objects for presentation to a user.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2129566336",
    "type": "article"
  },
  {
    "title": "A market-based approach to recommender systems",
    "doi": "https://doi.org/10.1145/1080343.1080344",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Yan Zheng Wei; Luc Moreau; Nicholas R. Jennings",
    "corresponding_authors": "",
    "abstract": "Recommender systems have been widely advocated as a way of coping with the problem of information overload for knowledge workers. Given this, multiple recommendation methods have been developed. However, it has been shown that no one technique is best for all users in all situations. Thus we believe that effective recommender systems should incorporate a wide variety of such techniques and that some form of overarching framework should be put in place to coordinate the various recommendations so that only the best of them (from whatever source) are presented to the user. To this end, we show that a marketplace, in which the various recommendation methods compete to offer their recommendations to the user, can be used in this role. Specifically, this article presents the principled design of such a marketplace (including the auction protocol, the reward mechanism, and the bidding strategies of the individual recommendation agents) and evaluates the market's capability to effectively coordinate multiple methods. Through analysis and simulation, we show that our market is capable of shortlisting recommendations in decreasing order of user perceived quality and of correlating the individual agent's internal quality rating to the user's perceived quality.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W2160326364",
    "type": "article"
  },
  {
    "title": "Exploring memory in email refinding",
    "doi": "https://doi.org/10.1145/1402256.1402260",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "David Elsweiler; Mark Baillie; Ian Ruthven",
    "corresponding_authors": "",
    "abstract": "Human memory plays an important role in personal information management (PIM). Several scholars have noted that people refind information based on what they remember and it has been shown that people adapt their management strategies to compensate for the limitations of memory. Nevertheless, little is known about what people tend to remember about their personal information and how they use their memories to refind. The aim of this article is to increase our understanding of the role that memory plays in the process of refinding personal information. Concentrating on email re-finding, we report on a user study that investigates what attributes of email messages participants remember when trying to refind. We look at how the attributes change in different scenarios and examine the factors which impact on what is remembered.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W2041583667",
    "type": "article"
  },
  {
    "title": "Message files",
    "doi": "https://doi.org/10.1145/357423.357429",
    "publication_date": "1983-01-01",
    "publication_year": 1983,
    "authors": "Dennis Tsichritzis; Stavros Christodoulakis",
    "corresponding_authors": "",
    "abstract": "article Free AccessMessage files Authors: Dennis Tsichritzis Computer Systems Research Group, University of Toronto, Toronto, M55 IAI, Canada Computer Systems Research Group, University of Toronto, Toronto, M55 IAI, CanadaView Profile , Stavros Christodoulakis Computer Systems Research Group, University of Toronto, Toronto, M55 IAI, Canada Computer Systems Research Group, University of Toronto, Toronto, M55 IAI, CanadaView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 1Jan. 1983 pp 88–98https://doi.org/10.1145/357423.357429Published:01 January 1983Publication History 61citation379DownloadsMetricsTotal Citations61Total Downloads379Last 12 Months12Last 6 weeks3 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W2294484634",
    "type": "article"
  },
  {
    "title": "Electronic calendars in the office: an assessment of user needs and current technology",
    "doi": "https://doi.org/10.1145/3864.3868",
    "publication_date": "1985-01-02",
    "publication_year": 1985,
    "authors": "Christine M. Kincaid; Pierre B. Dupont; A.R. Kaye",
    "corresponding_authors": "",
    "abstract": "Manufacturers of integrated electronic office systems have included electronic versions of the calendar in almost every system they offer. This paper describes a survey of office workers, carried out to examine their use both of paper calendars and of electronic calendars that are commercially available as part of integrated office systems. It assesses the degree to which electronic calendars meet the needs of users. Our survey shows that the simple paper calendar is a tool whose power and flexibility is matched by few, if any, of the current commercially available electronic calendars. Recommendations for features that should be included in electronic calendars and automatic schedulers are included.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W1964994389",
    "type": "article"
  },
  {
    "title": "Precision recall with user modeling (PRUM)",
    "doi": "https://doi.org/10.1145/1198296.1198297",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Benjamin Piwowarski; Patrick Gallinari; Georges Dupret",
    "corresponding_authors": "",
    "abstract": "Standard Information Retrieval (IR) metrics are not well suited for new paradigms like XML or Web IR in which retrievable information units are document elements and/or sets of related documents. Part of the problem stems from the classical hypotheses on the user models: They do not take into account the structural or logical context of document elements or the possibility of navigation between units. This article proposes an explicit and formal user model that encompasses a large variety of user behaviors. Based on this model, we extend the probabilistic precision-recall metric to deal with the new IR paradigms.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W2032958446",
    "type": "article"
  },
  {
    "title": "A few good topics",
    "doi": "https://doi.org/10.1145/1629096.1629099",
    "publication_date": "2009-11-01",
    "publication_year": 2009,
    "authors": "John Guiver; Stefano Mizzaro; Stephen Robertson",
    "corresponding_authors": "",
    "abstract": "We consider the issue of evaluating information retrieval systems on the basis of a limited number of topics. In contrast to statistically-based work on sample sizes, we hypothesize that some topics or topic sets are better than others at predicting true system effectiveness, and that with the right choice of topics, accurate predictions can be obtained from small topics sets. Using a variety of effectiveness metrics and measures of goodness of prediction, a study of a set of TREC and NTCIR results confirms this hypothesis, and provides evidence that the value of a topic set for this purpose does generalize.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W1976076261",
    "type": "article"
  },
  {
    "title": "Toward a semantic granularity model for domain-specific information retrieval",
    "doi": "https://doi.org/10.1145/1993036.1993039",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Xin Yan; Raymond Y.K. Lau; Dawei Song; Xue Li; Jian Ma",
    "corresponding_authors": "",
    "abstract": "Both similarity-based and popularity-based document ranking functions have been successfully applied to information retrieval (IR) in general. However, the dimension of semantic granularity also should be considered for effective retrieval. In this article, we propose a semantic granularity-based IR model that takes into account the three dimensions, namely similarity, popularity, and semantic granularity, to improve domain-specific search. In particular, a concept-based computational model is developed to estimate the semantic granularity of documents with reference to a domain ontology. Semantic granularity refers to the levels of semantic detail carried by an information item. The results of our benchmark experiments confirm that the proposed semantic granularity based IR model performs significantly better than the similarity-based baseline in both a bio-medical and an agricultural domain. In addition, a series of user-oriented studies reveal that the proposed document ranking functions resemble the implicit ranking functions exercised by humans. The perceived relevance of the documents delivered by the granularity-based IR system is significantly higher than that produced by a popular search engine for a number of domain-specific search tasks. To the best of our knowledge, this is the first study regarding the application of semantic granularity to enhance domain-specific IR.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2004319612",
    "type": "article"
  },
  {
    "title": "GRAS",
    "doi": "https://doi.org/10.1145/2037661.2037664",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Jiaul H. Paik; Mandar Mitra; Swapan K. Parui; Kalervo Järvelin",
    "corresponding_authors": "",
    "abstract": "A novel graph-based language-independent stemming algorithm suitable for information retrieval is proposed in this article. The main features of the algorithm are retrieval effectiveness, generality, and computational efficiency. We test our approach on seven languages (using collections from the TREC, CLEF, and FIRE evaluation platforms) of varying morphological complexity. Significant performance improvement over plain word-based retrieval, three other language-independent morphological normalizers, as well as rule-based stemmers is demonstrated.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2026227174",
    "type": "article"
  },
  {
    "title": "Fidelity, Soundness, and Efficiency of Interleaved Comparison Methods",
    "doi": "https://doi.org/10.1145/2536736.2536737",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Katja Hofmann; Shimon Whiteson; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Ranker evaluation is central to the research into search engines, be it to compare rankers or to provide feedback for learning to rank. Traditional evaluation approaches do not scale well because they require explicit relevance judgments of document-query pairs, which are expensive to obtain. A promising alternative is the use of interleaved comparison methods, which compare rankers using click data obtained when interleaving their rankings. In this article, we propose a framework for analyzing interleaved comparison methods. An interleaved comparison method has fidelity if the expected outcome of ranker comparisons properly corresponds to the true relevance of the ranked documents. It is sound if its estimates of that expected outcome are unbiased and consistent. It is efficient if those estimates are accurate with only little data. We analyze existing interleaved comparison methods and find that, while sound, none meet our criteria for fidelity. We propose a probabilistic interleave method, which is sound and has fidelity. We show empirically that, by marginalizing out variables that are known, it is more efficient than existing interleaved comparison methods. Using importance sampling we derive a sound extension that is able to reuse historical data collected in previous comparisons of other ranker pairs.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2073248814",
    "type": "article"
  },
  {
    "title": "Using Replicates in Information Retrieval Evaluation",
    "doi": "https://doi.org/10.1145/3086701",
    "publication_date": "2017-08-29",
    "publication_year": 2017,
    "authors": "Ellen M. Voorhees; Daniel V. Samarov; Ian Soboroff",
    "corresponding_authors": "",
    "abstract": "This article explores a method for more accurately estimating the main effect of the system in a typical test-collection-based evaluation of information retrieval systems, thus increasing the sensitivity of system comparisons. Randomly partitioning the test document collection allows for multiple tests of a given system and topic (replicates). Bootstrap ANOVA can use these replicates to extract system-topic interactions—something not possible without replicates—yielding a more precise value for the system effect and a narrower confidence interval around that value. Experiments using multiple TREC collections demonstrate that removing the topic-system interactions substantially reduces the confidence intervals around the system effect as well as increases the number of significant pairwise differences found. Further, the method is robust against small changes in the number of partitions used, against variability in the documents that constitute the partitions, and the measure of effectiveness used to quantify system effectiveness.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2750746504",
    "type": "article"
  },
  {
    "title": "Summarizing figures, tables, and algorithms in scientific publications to augment search results",
    "doi": "https://doi.org/10.1145/2094072.2094075",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Sumit Bhatia; Prasenjit Mitra",
    "corresponding_authors": "",
    "abstract": "Increasingly, special-purpose search engines are being built to enable the retrieval of document-elements like tables, figures, and algorithms [Bhatia et al. 2010; Liu et al. 2007; Hearst et al. 2007]. These search engines present a thumbnail view of document-elements, some document metadata such as the title of the papers and their authors, and the caption of the document-element. While some authors in some disciplines write carefully tailored captions, generally, the author of a document assumes that the caption will be read in the context of the text in the document. When the caption is presented out of context as in a document-element-search-engine result, it may not contain enough information to help the end-user understand what the content of the document-element is. Consequently, end-users examining document-element search results would want a short “synopsis” of this information presented along with the document-element. Having access to the synopsis allows the end-user to quickly understand the content of the document-element without having to download and read the entire document as examining the synopsis takes a shorter time than finding information about a document element by downloading, opening and reading the file. Furthermore, it may allow the end-user to examine more results than they would otherwise. In this paper, we present the first set of methods to extract this useful information (synopsis) related to document-elements automatically. We use Naïve Bayes and support vector machine classifiers to identify relevant sentences from the document text based on the similarity and the proximity of the sentences with the caption and the sentences in the document text that refer to the document-element. We compare the two classification methods and study the effects of different features used. We also investigate the problem of choosing the optimum synopsis-size that strikes a balance between the information content and the size of the generated synopses. A user study is also performed to measure how the synopses generated by our proposed method compare with other state-of-the-art approaches.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W1989135279",
    "type": "article"
  },
  {
    "title": "Modeling Term Associations for Probabilistic Information Retrieval",
    "doi": "https://doi.org/10.1145/2590988",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Jiashu Zhao; Jimmy Xiangji Huang; Ye Zheng",
    "corresponding_authors": "",
    "abstract": "Traditionally, in many probabilistic retrieval models, query terms are assumed to be independent. Although such models can achieve reasonably good performance, associations can exist among terms from a human being’s point of view. There are some recent studies that investigate how to model term associations/dependencies by proximity measures. However, the modeling of term associations theoretically under the probabilistic retrieval framework is still largely unexplored. In this article, we introduce a new concept cross term , to model term proximity, with the aim of boosting retrieval performance. With cross terms, the association of multiple query terms can be modeled in the same way as a simple unigram term. In particular, an occurrence of a query term is assumed to have an impact on its neighboring text. The degree of the query-term impact gradually weakens with increasing distance from the place of occurrence. We use shape functions to characterize such impacts. Based on this assumption, we first propose a bigram CRoss TErm Retrieval ( CRTER 2 ) model as the basis model, and then recursively propose a generalized n-gram CRoss TErm Retrieval ( CRTER n ) model for n query terms, where n &gt; 2. Specifically, a bigram cross term occurs when the corresponding query terms appear close to each other, and its impact can be modeled by the intersection of the respective shape functions of the query terms. For an n-gram cross term, we develop several distance metrics with different properties and employ them in the proposed models for ranking. We also show how to extend the language model using the newly proposed cross terms. Extensive experiments on a number of TREC collections demonstrate the effectiveness of our proposed models.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2052842594",
    "type": "article"
  },
  {
    "title": "About learning models with multiple query-dependent features",
    "doi": "https://doi.org/10.1145/2493175.2493176",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Craig Macdonald; Rodrygo L. T. Santos; Iadh Ounis; Ben He",
    "corresponding_authors": "",
    "abstract": "Several questions remain unanswered by the existing literature concerning the deployment of query-dependent features within learning to rank. In this work, we investigate three research questions in order to empirically ascertain best practices for learning-to-rank deployments. (i) Previous work in data fusion that pre-dates learning to rank showed that while different retrieval systems could be effectively combined, the combination of multiple models within the same system was not as effective. In contrast, the existing learning-to-rank datasets (e.g., LETOR), often deploy multiple weighting models as query-dependent features within a single system, raising the question as to whether such a combination is needed. (ii) Next, we investigate whether the training of weighting model parameters, traditionally required for effective retrieval, is necessary within a learning-to-rank context. (iii) Finally, we note that existing learning-to-rank datasets use weighting model features calculated on different fields (e.g., title, content, or anchor text), even though such weighting models have been criticized in the literature. Experiments addressing these three questions are conducted on Web search datasets, using various weighting models as query-dependent and typical query-independent features, which are combined using three learning-to-rank techniques. In particular, we show and explain why multiple weighting models should be deployed as features. Moreover, we unexpectedly find that training the weighting model's parameters degrades learned model's effectiveness. Finally, we show that computing a weighting model separately for each field is less effective than more theoretically-sound field-based weighting models.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2077789969",
    "type": "article"
  },
  {
    "title": "Approaches to Exploring Category Information for Question Retrieval in Community Question-Answer Archives",
    "doi": "https://doi.org/10.1145/2180868.2180869",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Xin Cao; Gao Cong; Bin Cui; Christian S. Jensen; Quan Yuan",
    "corresponding_authors": "",
    "abstract": "Community Question Answering (CQA) is a popular type of service where users ask questions and where answers are obtained from other users or from historical question-answer pairs. CQA archives contain large volumes of questions organized into a hierarchy of categories. As an essential function of CQA services, question retrieval in a CQA archive aims to retrieve historical question-answer pairs that are relevant to a query question. This article presents several new approaches to exploiting the category information of questions for improving the performance of question retrieval, and it applies these approaches to existing question retrieval models, including a state-of-the-art question retrieval model. Experiments conducted on real CQA data demonstrate that the proposed techniques are effective and efficient and are capable of outperforming a variety of baseline methods significantly.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2120284981",
    "type": "article"
  },
  {
    "title": "MWI-Sum",
    "doi": "https://doi.org/10.1145/2809786",
    "publication_date": "2015-09-21",
    "publication_year": 2015,
    "authors": "Elena Baralis; Luca Cagliero; Alessandro Fiori; Paolo Garza",
    "corresponding_authors": "",
    "abstract": "Multidocument summarization addresses the selection of a compact subset of highly informative sentences, i.e., the summary, from a collection of textual documents. To perform sentence selection, two parallel strategies have been proposed: (a) apply general-purpose techniques relying on data mining or information retrieval techniques, and/or (b) perform advanced linguistic analysis relying on semantics-based models (e.g., ontologies) to capture the actual sentence meaning. Since there is an increasing need for processing documents written in different languages, the attention of the research community has recently focused on summarizers based on strategy (a). This article presents a novel multilingual summarizer, namely MWI-Sum (Multilingual Weighted Itemset-based Summarizer), that exploits an itemset-based model to summarize collections of documents ranging over the same topic. Unlike previous approaches, it extracts frequent weighted itemsets tailored to the analyzed collection and uses them to drive the sentence selection process. Weighted itemsets represent correlations among multiple highly relevant terms that are neglected by previous approaches. The proposed approach makes minimal use of language-dependent analyses. Thus, it is easily applicable to document collections written in different languages. Experiments performed on benchmark and real-life collections, English-written and not, demonstrate that the proposed approach performs better than state-of-the-art multilingual document summarizers.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2014601737",
    "type": "article"
  },
  {
    "title": "Volunteerism Tendency Prediction via Harvesting Multiple Social Networks",
    "doi": "https://doi.org/10.1145/2832907",
    "publication_date": "2016-02-16",
    "publication_year": 2016,
    "authors": "Xuemeng Song; Zhaoyan Ming; Liqiang Nie; Yiliang Zhao; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Volunteers have always been extremely crucial and in urgent need for nonprofit organizations (NPOs) to sustain their continuing operations. However, it is expensive and time-consuming to recruit volunteers using traditional approaches. In the Web 2.0 era, abundant and ubiquitous social media data opens a door to the possibility of automatic volunteer identification. In this article, we aim to fully explore this possibility by proposing a scheme that is able to predict users’ volunteerism tendency from user-generated contents collected from multiple social networks based on a conceptual volunteering decision model. We conducted comprehensive experiments to investigate the effectiveness of our proposed scheme and further discussed its generalizibility and extendability. This novel interdisciplinary research will potentially inspire more promising and important human-centered applications.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2335082123",
    "type": "article"
  },
  {
    "title": "Understanding the Purpose of Permission Use in Mobile Apps",
    "doi": "https://doi.org/10.1145/3086677",
    "publication_date": "2017-07-11",
    "publication_year": 2017,
    "authors": "Haoyu Wang; Yuanchun Li; Yao Guo; Yuvraj Agarwal; Jason Hong",
    "corresponding_authors": "",
    "abstract": "Mobile apps frequently request access to sensitive data, such as location and contacts. Understanding the purpose of why sensitive data is accessed could help improve privacy as well as enable new kinds of access control. In this article, we propose a text mining based method to infer the purpose of sensitive data access by Android apps. The key idea we propose is to extract multiple features from app code and then use those features to train a machine learning classifier for purpose inference. We present the design, implementation, and evaluation of two complementary approaches to infer the purpose of permission use, first using purely static analysis, and then using primarily dynamic analysis. We also discuss the pros and cons of both approaches and the trade-offs involved.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2734721836",
    "type": "article"
  },
  {
    "title": "Selective Search",
    "doi": "https://doi.org/10.1145/2738035",
    "publication_date": "2015-04-23",
    "publication_year": 2015,
    "authors": "Anagha Kulkarni; Jamie Callan",
    "corresponding_authors": "",
    "abstract": "The traditional search solution for large collections divides the collection into subsets ( shards ), and processes the query against all shards in parallel ( exhaustive search ). The search cost and the computational requirements of this approach are often prohibitively high for organizations with few computational resources. This article investigates and extends an alternative: selective search , an approach that partitions the dataset based on document similarity to obtain topic-based shards , and searches only a few shards that are estimated to contain relevant documents for the query. We propose shard creation techniques that are scalable, efficient, self-reliant, and create topic-based shards with low variance in size, and high density of relevant documents. The experimental results demonstrate that the effectiveness of selective search is on par with that of exhaustive search, and the corresponding search costs are substantially lower with the former. Also, the majority of the queries perform as well or better with selective search. An oracle experiment that uses optimal shard ranking for a query indicates that selective search can outperform the effectiveness of exhaustive search. Comparison with a query optimization technique shows higher improvements in efficiency with selective search. The overall best efficiency is achieved when the two techniques are combined in an optimized selective search approach.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W1984918470",
    "type": "article"
  },
  {
    "title": "Query Performance Prediction Using Reference Lists",
    "doi": "https://doi.org/10.1145/2926790",
    "publication_date": "2016-06-09",
    "publication_year": 2016,
    "authors": "Anna Shtok; Oren Kurland; David Carmel",
    "corresponding_authors": "",
    "abstract": "The task of query performance prediction is to estimate the effectiveness of search performed in response to a query when no relevance judgments are available. We present a novel probabilistic analysis of the performance prediction task. The analysis gives rise to a general prediction framework that uses pseudo-effective or ineffective document lists that are retrieved in response to the query. These lists serve as reference to the result list at hand, the effectiveness of which we want to predict. We show that many previously proposed prediction methods can be explained using our framework. More generally, we shed new light on existing prediction methods and establish formal common grounds to seemingly different prediction approaches. In addition, we formally demonstrate the connection between prediction using reference lists and fusion of retrieved lists, and provide empirical support to this connection. Through an extensive empirical exploration, we study various factors that affect the quality of prediction using reference lists.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2418896762",
    "type": "article"
  },
  {
    "title": "Comparing Pointwise and Listwise Objective Functions for Random-Forest-Based Learning-to-Rank",
    "doi": "https://doi.org/10.1145/2866571",
    "publication_date": "2016-08-17",
    "publication_year": 2016,
    "authors": "Muhammad Ibrahim; Mark Carman",
    "corresponding_authors": "",
    "abstract": "Current random-forest (RF)-based learning-to-rank (LtR) algorithms use a classification or regression framework to solve the ranking problem in a pointwise manner. The success of this simple yet effective approach coupled with the inherent parallelizability of the learning algorithm makes it a strong candidate for widespread adoption. In this article, we aim to better understand the effectiveness of RF-based rank-learning algorithms with a focus on the comparison between pointwise and listwise approaches. We introduce what we believe to be the first listwise version of an RF-based LtR algorithm. The algorithm directly optimizes an information retrieval metric of choice (in our case, NDCG) in a greedy manner. Direct optimization of the listwise objective functions is computationally prohibitive for most learning algorithms, but possible in RF since each tree maximizes the objective in a coordinate-wise fashion. Computational complexity of the listwise approach is higher than the pointwise counterpart; hence for larger datasets, we design a hybrid algorithm that combines a listwise objective in the early stages of tree construction and a pointwise objective in the latter stages. We also study the effect of the discount function of NDCG on the listwise algorithm. Experimental results on several publicly available LtR datasets reveal that the listwise/hybrid algorithm outperforms the pointwise approach on the majority (but not all) of the datasets. We then investigate several aspects of the two algorithms to better understand the inevitable performance tradeoffs. The aspects include examining an RF-based unsupervised LtR algorithm and comparing individual tree strength. Finally, we compare the the investigated RF-based algorithms with several other LtR algorithms.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2507731896",
    "type": "article"
  },
  {
    "title": "Trip Recommendation Meets Real-World Constraints",
    "doi": "https://doi.org/10.1145/2948065",
    "publication_date": "2016-09-08",
    "publication_year": 2016,
    "authors": "Chenyi Zhang; Hongwei Liang; Ke Wang",
    "corresponding_authors": "",
    "abstract": "As location-based social network (LBSN) services become increasingly popular, trip recommendation that recommends a sequence of points of interest (POIs) to visit for a user emerges as one of many important applications of LBSNs. Personalized trip recommendation tailors to users’ specific tastes by learning from past check-in behaviors of users and their peers. Finding the optimal trip that maximizes user’s experiences for a given time budget constraint is an NP-hard problem and previous solutions do not consider three practical and important constraints. One constraint is POI availability , where a POI may be only available during a certain time window. Another constraint is uncertain traveling time , where the traveling time between two POIs is uncertain. In addition, the diversity of the POIs included in the trip plays an important role in user’s final adoptions. This work presents efficient solutions to personalized trip recommendation by incorporating these constraints and leveraging them to prune the search space. We evaluated the efficiency and effectiveness of our solutions on real-life LBSN datasets.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2515155379",
    "type": "article"
  },
  {
    "title": "Sentence Relations for Extractive Summarization with Deep Neural Networks",
    "doi": "https://doi.org/10.1145/3200864",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Pengjie Ren; Zhumin Chen; Zhaochun Ren; Furu Wei; Liqiang Nie; Jun Ma; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Sentence regression is a type of extractive summarization that achieves state-of-the-art performance and is commonly used in practical systems. The most challenging task within the sentence regression framework is to identify discriminative features to represent each sentence. In this article, we study the use of sentence relations, e.g., Contextual Sentence Relations (CSR), Title Sentence Relations (TSR), and Query Sentence Relations (QSR), so as to improve the performance of sentence regression. CSR, TSR, and QSR refer to the relations between a main body sentence and its local context, its document title, and a given query, respectively. We propose a deep neural network model, Sentence Relation-based Summarization (SRSum), that consists of five sub-models, PriorSum, CSRSum, TSRSum, QSRSum, and SFSum. PriorSum encodes the latent semantic meaning of a sentence using a bi-gram convolutional neural network. SFSum encodes the surface information of a sentence, e.g., sentence length, sentence position, and so on. CSRSum, TSRSum, and QSRSum are three sentence relation sub-models corresponding to CSR, TSR, and QSR, respectively. CSRSum evaluates the ability of each sentence to summarize its local contexts. Specifically, CSRSum applies a CSR-based word-level and sentence-level attention mechanism to simulate the context-aware reading of a human reader, where words and sentences that have anaphoric relations or local summarization abilities are easily remembered and paid attention to. TSRSum evaluates the semantic closeness of each sentence with respect to its title, which usually reflects the main ideas of a document. TSRSum applies a TSR-based attention mechanism to simulate people’s reading ability with the main idea (title) in mind. QSRSum evaluates the relevance of each sentence with given queries for the query-focused summarization. QSRSum applies a QSR-based attention mechanism to simulate the attentive reading of a human reader with some queries in mind. The mechanism can recognize which parts of the given queries are more likely answered by a sentence under consideration. Finally as a whole, SRSum automatically learns useful latent features by jointly learning representations of query sentences, content sentences, and title sentences as well as their relations. We conduct extensive experiments on six benchmark datasets, including generic multi-document summarization and query-focused multi-document summarization. On both tasks, SRSum achieves comparable or superior performance compared with state-of-the-art approaches in terms of multiple ROUGE metrics.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2800631850",
    "type": "article"
  },
  {
    "title": "Belief Dynamics and Biases in Web Search",
    "doi": "https://doi.org/10.1145/2746229",
    "publication_date": "2015-05-04",
    "publication_year": 2015,
    "authors": "Ryen W. White; Eric Horvitz",
    "corresponding_authors": "",
    "abstract": "We investigate how beliefs about the efficacy of medical interventions are influenced by searchers' exposure to information on retrieved Web pages. We present a methodology for measuring participants' beliefs and confidence about the efficacy of treatment before, during, and after search episodes. We consider interventions studied in the Cochrane collection of meta-analyses. We extract related queries from search engine logs and consider the Cochrane assessments as ground truth. We analyze the dynamics of belief over time and show the influence of prior beliefs and confidence at the end of sessions. We present evidence for confirmation bias and for anchoring-and-adjustment during search and retrieval. Then, we build predictive models to estimate postsearch beliefs using sets of features about behavior and content. The findings provide insights about the influence of Web content on the beliefs of people and have implications for the design of search systems.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W1885634126",
    "type": "article"
  },
  {
    "title": "Social-Sensed Image Search",
    "doi": "https://doi.org/10.1145/2590974",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Peng Cui; Shaowei Liu; Wenwu Zhu; Huanbo Luan; Tat‐Seng Chua; Shiqiang Yang",
    "corresponding_authors": "",
    "abstract": "Although Web search techniques have greatly facilitate users’ information seeking, there are still quite a lot of search sessions that cannot provide satisfactory results, which are more serious in Web image search scenarios. How to understand user intent from observed data is a fundamental issue and of paramount significance in improving image search performance. Previous research efforts mostly focus on discovering user intent either from clickthrough behavior in user search logs (e.g., Google), or from social data to facilitate vertical image search in a few limited social media platforms (e.g., Flickr). This article aims to combine the virtues of these two information sources to complement each other, that is, sensing and understanding users’ interests from social media platforms and transferring this knowledge to rerank the image search results in general image search engines. Toward this goal, we first propose a novel social-sensed image search framework, where both social media and search engine are jointly considered. To effectively and efficiently leverage these two kinds of platforms, we propose an example-based user interest representation and modeling method, where we construct a hybrid graph from social media and propose a hybrid random-walk algorithm to derive the user-image interest graph. Moreover, we propose a social-sensed image reranking method to integrate the user-image interest graph from social media and search results from general image search engines to rerank the images by fusing their social relevance and visual relevance. We conducted extensive experiments on real-world data from Flickr and Google image search, and the results demonstrated that the proposed methods can significantly improve the social relevance of image search results while maintaining visual relevance well.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W1970364187",
    "type": "article"
  },
  {
    "title": "Gaussian Processes for Rumour Stance Classification in Social Media",
    "doi": "https://doi.org/10.1145/3295823",
    "publication_date": "2019-02-13",
    "publication_year": 2019,
    "authors": "Michał Łukasik; Kalina Bontcheva; Trevor Cohn; Arkaitz Zubiaga; Maria Liakata; Rob Procter",
    "corresponding_authors": "",
    "abstract": "Social media tend to be rife with rumours while new reports are released piecemeal during breaking news. Interestingly, one can mine multiple reactions expressed by social media users in those situations, exploring their stance towards rumours, ultimately enabling the flagging of highly disputed rumours as being potentially false. In this work, we set out to develop an automated, supervised classifier that uses multi-task learning to classify the stance expressed in each individual tweet in a conversation around a rumour as either supporting, denying or questioning the rumour. Using a Gaussian Process classifier, and exploring its effectiveness on two datasets with very different characteristics and varying distributions of stances, we show that our approach consistently outperforms competitive baseline classifiers. Our classifier is especially effective in estimating the distribution of different types of stance associated with a given rumour, which we set forth as a desired characteristic for a rumour-tracking system that will show both ordinary users of Twitter and professional news practitioners how others orient to the disputed veracity of a rumour, with the final aim of establishing its actual truth value.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2963704432",
    "type": "article"
  },
  {
    "title": "Next and Next New POI Recommendation via Latent Behavior Pattern Inference",
    "doi": "https://doi.org/10.1145/3354187",
    "publication_date": "2019-09-19",
    "publication_year": 2019,
    "authors": "Xin Li; Dongcheng Han; Jing He; Lejian Liao; Mingzhong Wang",
    "corresponding_authors": "",
    "abstract": "Next and next new point-of-interest (POI) recommendation are essential instruments in promoting customer experiences and business operations related to locations. However, due to the sparsity of the check-in records, they still remain insufficiently studied. In this article, we propose to utilize personalized latent behavior patterns learned from contextual features, e.g., time of day, day of week, and location category, to improve the effectiveness of the recommendations. Two variations of models are developed, including GPDM, which learns a fixed pattern distribution for all users; and PPDM, which learns personalized pattern distribution for each user. In both models, a soft-max function is applied to integrate the personalized Markov chain with the latent patterns, and a sequential Bayesian Personalized Ranking (S-BPR) is applied as the optimization criterion. Then, Expectation Maximization (EM) is in charge of finding optimized model parameters. Extensive experiments on three large-scale commonly adopted real-world LBSN data sets prove that the inclusion of location category and latent patterns helps to boost the performance of POI recommendations. Specifically, our models in general significantly outperform other state-of-the-art methods for both next and next new POI recommendation tasks. Moreover, our models are capable of making accurate recommendations regardless of the short/long duration or distance.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2983662436",
    "type": "article"
  },
  {
    "title": "Using Collection Shards to Study Retrieval Performance Effect Sizes",
    "doi": "https://doi.org/10.1145/3310364",
    "publication_date": "2019-03-19",
    "publication_year": 2019,
    "authors": "Nicola Ferro; Yubin Kim; Mark Sanderson",
    "corresponding_authors": "",
    "abstract": "Despite the bulk of research studying how to more accurately compare the performance of IR systems, less attention is devoted to better understanding the different factors that play a role in such performance and how they interact. This is the case of shards, i.e., partitioning a document collection into sub-parts, which are used for many different purposes, ranging from efficiency to selective search or making test collection evaluation more accurate. In all these cases, there is empirical knowledge supporting the importance of shards, but we lack actual models that allow us to measure the impact of shards on system performance and how they interact with topics and systems. We use the general linear mixed model framework and present a model that encompasses the experimental factors of system, topic, shard, and their interaction effects. This detailed model allows us to more accurately estimate differences between the effect of various factors. We study shards created by a range of methods used in prior work and better explain observations noted in prior work in a principled setting and offer new insights. Notably, we discover that the topic*shard interaction effect, in particular, is a large effect almost globally across all datasets, an observation that, to our knowledge, has not been measured before.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2923053417",
    "type": "article"
  },
  {
    "title": "Overview of the Special Issue on Trust and Veracity of Information in Social Media",
    "doi": "https://doi.org/10.1145/2870630",
    "publication_date": "2016-04-11",
    "publication_year": 2016,
    "authors": "Symeon Papadopoulos; Kalina Bontcheva; Eva Jaho; Mihai Lupu; Carlos Castillo",
    "corresponding_authors": "",
    "abstract": "research-article Share on Overview of the Special Issue on Trust and Veracity of Information in Social Media Authors: Symeon Papadopoulos Centre for Research and Technology Hellas; Thessaloniki, Greece Centre for Research and Technology Hellas; Thessaloniki, GreeceView Profile , Kalina Bontcheva University of Sheffield, Sheffield, UK University of Sheffield, Sheffield, UKView Profile , Eva Jaho Athens Technology Center, Athens, Greece Athens Technology Center, Athens, GreeceView Profile , Mihai Lupu Vienna University of Technology, Vienna, Austria Vienna University of Technology, Vienna, AustriaView Profile , Carlos Castillo Sapienza University of Rome, Rome, Italy Sapienza University of Rome, Rome, ItalyView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 34Issue 3May 2016 Article No.: 14pp 1–5https://doi.org/10.1145/2870630Published:11 April 2016Publication History 20citation1,578DownloadsMetricsTotal Citations20Total Downloads1,578Last 12 Months57Last 6 weeks12 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2321006848",
    "type": "article"
  },
  {
    "title": "How Does Domain Expertise Affect Users’ Search Interaction and Outcome in Exploratory Search?",
    "doi": "https://doi.org/10.1145/3223045",
    "publication_date": "2018-07-17",
    "publication_year": 2018,
    "authors": "Jiaxin Mao; Yiqun Liu; Noriko Kando; Min Zhang; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "People often conduct exploratory search to explore unfamiliar information space and learn new knowledge. While supporting the highly dynamic and interactive exploratory search is still challenging for the search system, we want to investigate which factors can make the exploratory search successful and satisfying from the user’s perspective. Previous research suggests that domain experts have different search strategies and are more successful in finding domain-specific information, but how the domain expertise level will influence users’ interaction and search outcomes in exploratory search, especially in different knowledge domains, is still unclear. In this work, via a carefully designed user study that involves 30 participants, we investigate the influence of domain expertise levels on the interaction and outcome of exploratory search in three different domains: environment, medicine, and politics. We record participants’ search behaviors, including their explicit feedback and eye fixation sequences, in a laboratory setting. With this dataset, we identify both domain-independent and domain-dependent effects on user behaviors and search outcomes. Our results extend existing research on the effect of domain expertise in search and suggest different strategies for exploiting domain expertise to support exploratory search in different knowledge domains.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2883128230",
    "type": "article"
  },
  {
    "title": "A Multi-Label Classification Method Using a Hierarchical and Transparent Representation for Paper-Reviewer Recommendation",
    "doi": "https://doi.org/10.1145/3361719",
    "publication_date": "2020-01-31",
    "publication_year": 2020,
    "authors": "Dong Zhang; Shu Zhao; Zhen Duan; Jie Chen; Yanping Zhang; Jie Tang",
    "corresponding_authors": "",
    "abstract": "The paper-reviewer recommendation task is of significant academic importance for conference chairs and journal editors. It aims to recommend appropriate experts in a discipline to comment on the quality of papers of others in that discipline. How to effectively and accurately recommend reviewers for the submitted papers is a meaningful and still tough task. Generally, the relationship between a paper and a reviewer often depends on the semantic expressions of them. Creating a more expressive representation can make the peer-review process more robust and less arbitrary. So the representations of a paper and a reviewer are very important for the paper-reviewer recommendation. Actually, a reviewer or a paper often belongs to multiple research fields, which increases difficulty in paper-reviewer recommendation. In this article, we propose a Multi-Label Classification method using a HIErarchical and transPArent Representation named Hiepar-MLC . First, we introduce HIErarchical and transPArent Representation (Hiepar) to express the semantic information of the reviewer and the paper. Hiepar is learned from a two-level bidirectional gated recurrent unit based network applying the attention mechanism. It is capable of capturing the two-level hierarchical information (word-sentence-document) and highlighting the elements in reviewers or papers to support the labels. This word-sentence-document information mirrors the hierarchical structure of a reviewer or a paper and captures the exact semantics of them. Then we transform the paper-reviewer recommendation problem into a multi-level classification issue, whose multiple research labels exactly guide the learning process. It is flexible in that we can select any multi-label classification method to solve the paper-reviewer recommendation problem. Further, we propose a simple multi-label-based reviewer assignment (MLBRA) strategy to select the appropriate reviewers. It is interesting in that we also explore the paper-reviewer recommendation in the coarse-grain granularity. Extensive experiments on the real-world dataset consisting of the papers in the ACM Digital Library show that Hiepar-MLC achieves better label prediction performance than the existing representation alternatives. In addition, with the MLBRA strategy, we show the effectiveness and the feasibility of our transformation from paper-reviewer recommendation to multi-label classification.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W3005236729",
    "type": "article"
  },
  {
    "title": "Modeling Embedding Dimension Correlations via Convolutional Neural Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3357154",
    "publication_date": "2019-09-13",
    "publication_year": 2019,
    "authors": "Xiaoyu Du; Xiangnan He; Fajie Yuan; Jinhui Tang; Zhiguang Qin; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "As the core of recommender systems, collaborative filtering (CF) models the affinity between a user and an item from historical user-item interactions, such as clicks, purchases, and so on. Benefiting from the strong representation power, neural networks have recently revolutionized the recommendation research, setting up a new standard for CF. However, existing neural recommender models do not explicitly consider the correlations among embedding dimensions, making them less effective in modeling the interaction function between users and items. In this work, we emphasize on modeling the correlations among embedding dimensions in neural networks to pursue higher effectiveness for CF. We propose a novel and general neural collaborative filtering framework—namely, ConvNCF, which is featured with two designs: (1) applying outer product on user embedding and item embedding to explicitly model the pairwise correlations between embedding dimensions, and (2) employing convolutional neural network above the outer product to learn the high-order correlations among embedding dimensions. To justify our proposal, we present three instantiations of ConvNCF by using different inputs to represent a user and conduct experiments on two real-world datasets. Extensive results verify the utility of modeling embedding dimension correlations with ConvNCF, which outperforms several competitive CF methods.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2972724570",
    "type": "article"
  },
  {
    "title": "Neural Feature-aware Recommendation with Signed Hypergraph Convolutional Network",
    "doi": "https://doi.org/10.1145/3423322",
    "publication_date": "2020-11-10",
    "publication_year": 2020,
    "authors": "Xu Chen; Kun Xiong; Yongfeng Zhang; Long Xia; Dawei Yin; Jimmy Xiangji Huang",
    "corresponding_authors": "",
    "abstract": "Understanding user preference is of key importance for an effective recommender system. For comprehensive user profiling, many efforts have been devoted to extract user feature-level preference from the review information. Despite effectiveness, existing methods mostly assume linear relationships among the users, items, and features, and the collaborative information is usually utilized in an implicit and insufficient manner, which limits the recommender capacity in modeling users’ diverse preferences. For bridging this gap, in this article, we propose to formulate user feature-level preferences by a neural signed hypergraph and carefully design the information propagation paths for diffusing collaborative filtering signals in a more effective manner. By taking the advantages of the neural model’s powerful expressiveness, the complex relationship patterns among users, items, and features are sufficiently discovered and well utilized. By infusing graph structure information into the embedding process, the collaborative information is harnessed in a more explicit and effective way. We conduct comprehensive experiments on real-world datasets to demonstrate the superiorities of our model.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W3102793640",
    "type": "article"
  },
  {
    "title": "Emotion Dynamics of Public Opinions on Twitter",
    "doi": "https://doi.org/10.1145/3379340",
    "publication_date": "2020-03-04",
    "publication_year": 2020,
    "authors": "Debashis Naskar; Sanasam Ranbir Singh; Durgesh Kumar; Sukumar Nandi; Eva Onaindía",
    "corresponding_authors": "",
    "abstract": "Recently, social media has been considered the fastest medium for information broadcasting and sharing. Considering the wide range of applications such as viral marketing, political campaigns, social advertisement, and so on, influencing characteristics of users or tweets have attracted several researchers. It is observed from various studies that influential messages or users create a high impact on a social ecosystem. In this study, we assume that public opinion on a social issue on Twitter carries a certain degree of emotion, and there is an emotion flow underneath the Twitter network. In this article, we investigate social dynamics of emotion present in users’ opinions and attempt to understand (i) changing characteristics of users’ emotions toward a social issue over time, (ii) influence of public emotions on individuals’ emotions, (iii) cause of changing opinion by social factors, and so on. We study users’ emotion dynamics over a collection of 17.65M tweets with 69.36K users and observe 63% of the users are likely to change their emotional state against the topic into their subsequent tweets. Tweets were coming from the member community shows higher influencing capability than the other community sources. It is also observed that retweets influence users more than hashtags, mentions, and replies.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W3009600231",
    "type": "article"
  },
  {
    "title": "Exploiting Positional Information for Session-Based Recommendation",
    "doi": "https://doi.org/10.1145/3473339",
    "publication_date": "2021-11-16",
    "publication_year": 2021,
    "authors": "Ruihong Qiu; Zi Huang; Tong Chen; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "For present e-commerce platforms, it is important to accurately predict users’ preference for a timely next-item recommendation. To achieve this goal, session-based recommender systems are developed, which are based on a sequence of the most recent user-item interactions to avoid the influence raised from outdated historical records. Although a session can usually reflect a user’s current preference, a local shift of the user’s intention within the session may still exist. Specifically, the interactions that take place in the early positions within a session generally indicate the user’s initial intention, while later interactions are more likely to represent the latest intention. Such positional information has been rarely considered in existing methods, which restricts their ability to capture the significance of interactions at different positions. To thoroughly exploit the positional information within a session, a theoretical framework is developed in this paper to provide an in-depth analysis of the positional information. We formally define the properties of forward-awareness and backward-awareness to evaluate the ability of positional encoding schemes in capturing the initial and the latest intention. According to our analysis, existing positional encoding schemes are generally forward-aware only, which can hardly represent the dynamics of the intention in a session. To enhance the positional encoding scheme for the session-based recommendation, a dual positional encoding (DPE) is proposed to account for both forward-awareness and backward-awareness . Based on DPE, we propose a novel Positional Recommender (PosRec) model with a well-designed Position-aware Gated Graph Neural Network module to fully exploit the positional information for session-based recommendation tasks. Extensive experiments are conducted on two e-commerce benchmark datasets, Yoochoose and Diginetica and the experimental results show the superiority of the PosRec by comparing it with the state-of-the-art session-based recommender models.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W3180733313",
    "type": "article"
  },
  {
    "title": "Multi-interest Diversification for End-to-end Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3475768",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Wanyu Chen; Pengjie Ren; Fei Cai; Fei Sun; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Sequential recommenders capture dynamic aspects of users’ interests by modeling sequential behavior. Previous studies on sequential recommendations mostly aim to identify users’ main recent interests to optimize the recommendation accuracy; they often neglect the fact that users display multiple interests over extended periods of time, which could be used to improve the diversity of lists of recommended items. Existing work related to diversified recommendation typically assumes that users’ preferences are static and depend on post-processing the candidate list of recommended items. However, those conditions are not suitable when applied to sequential recommendations. We tackle sequential recommendation as a list generation process and propose a unified approach to take accuracy as well as diversity into consideration, called multi-interest, diversified, sequential recommendation . Particularly, an implicit interest mining module is first used to mine users’ multiple interests, which are reflected in users’ sequential behavior. Then an interest-aware, diversity promoting decoder is designed to produce recommendations that cover those interests. For training, we introduce an interest-aware, diversity promoting loss function that can supervise the model to learn to recommend accurate as well as diversified items. We conduct comprehensive experiments on four public datasets and the results show that our proposal outperforms state-of-the-art methods regarding diversity while producing comparable or better accuracy for sequential recommendation.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W3196572840",
    "type": "article"
  },
  {
    "title": "LegalGNN: Legal Information Enhanced Graph Neural Network for Recommendation",
    "doi": "https://doi.org/10.1145/3469887",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Jun Yang; Weizhi Ma; Min Zhang; Xin Zhou; Yiqun Liu; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Recommendation in legal scenario (Legal-Rec) is a specialized recommendation task that aims to provide potential helpful legal documents for users. While there are mainly three differences compared with traditional recommendation: (1) Both the structural connections and textual contents of legal information are important in the Legal-Rec scenario, which means feature fusion is very important here. (2) Legal-Rec users prefer the newest legal cases (the latest legal interpretation and legal practice), which leads to a severe new-item problem. (3) Different from users in other scenarios, most Legal-Rec users are expert and domain-related users. They often concentrate on several topics and have more stable information needs. So it is important to accurately model user interests here. To the best of our knowledge, existing recommendation work cannot handle these challenges simultaneously. To address these challenges, we propose a legal information enhanced graph neural network–based recommendation framework (LegalGNN). First, a unified legal content and structure representation model is designed for feature fusion, where the Heterogeneous Legal Information Network (HLIN) is constructed to connect the structural features (e.g., knowledge graph) and contextual features (e.g., the content of legal documents) for training. Second, to model user interests, we incorporate the queries users issued in legal systems into the HLIN and link them with both retrieved documents and inquired users. This extra information is not only helpful for estimating user preferences, but also valuable for cold users/items (with less interaction history) in this scenario. Third, a graph neural network with relational attention mechanism is applied to make use of high-order connections in HLIN for Legal-Rec. Experimental results on a real-world legal dataset verify that LegalGNN outperforms several state-of-the-art methods significantly. As far as we know, LegalGNN is the first graph neural model for legal recommendation.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W3204622772",
    "type": "article"
  },
  {
    "title": "Meaningful Answer Generation of E-Commerce Question-Answering",
    "doi": "https://doi.org/10.1145/3432689",
    "publication_date": "2021-02-03",
    "publication_year": 2021,
    "authors": "Shen Gao; Xiuying Chen; Zhaochun Ren; Dongyan Zhao; Rui Yan",
    "corresponding_authors": "",
    "abstract": "In e-commerce portals, generating answers for product-related questions has become a crucial task. In this article, we focus on the task of product-aware answer generation , which learns to generate an accurate and complete answer from large-scale unlabeled e-commerce reviews and product attributes. However, safe answer problems (i.e., neural models tend to generate meaningless and universal answers) pose significant challenges to text generation tasks, and e-commerce question-answering task is no exception. To generate more meaningful answers, in this article, we propose a novel generative neural model, called the Meaningful Product Answer Generator ( MPAG ), which alleviates the safe answer problem by taking product reviews, product attributes, and a prototype answer into consideration. Product reviews and product attributes are used to provide meaningful content, while the prototype answer can yield a more diverse answer pattern. To this end, we propose a novel answer generator with a review reasoning module and a prototype answer reader. Our key idea is to obtain the correct question-aware information from a large-scale collection of reviews and learn how to write a coherent and meaningful answer from an existing prototype answer. To be more specific, we propose a read-and-write memory consisting of selective writing units to conduct reasoning among these reviews . We then employ a prototype reader consisting of comprehensive matching to extract the answer skeleton from the prototype answer. Finally, we propose an answer editor to generate the final answer by taking the question and the above parts as input. Conducted on a real-world dataset collected from an e-commerce platform, extensive experimental results show that our model achieves state-of-the-art performance in terms of both automatic metrics and human evaluations. Human evaluation also demonstrates that our model can consistently generate specific and proper answers.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W3127555846",
    "type": "article"
  },
  {
    "title": "From Users’ Intentions to IF-THEN Rules in the Internet of Things",
    "doi": "https://doi.org/10.1145/3447264",
    "publication_date": "2021-08-16",
    "publication_year": 2021,
    "authors": "Fulvio Corno; Luigi De Russis; Alberto Monge Roffarello",
    "corresponding_authors": "",
    "abstract": "In the Internet of Things era, users are willing to personalize the joint behavior of their connected entities, i.e., smart devices and online service, by means of trigger-action rules such as “IF the entrance Nest security camera detects a movement, THEN blink the Philips Hue lamp in the kitchen.” Unfortunately, the spread of new supported technologies makes the number of possible combinations between triggers and actions continuously growing, thus motivating the need of assisting users in discovering new rules and functionality, e.g., through recommendation techniques. To this end, we present <?TeX $HeyTAP^2$?> , a semantic Conversational Search and Recommendation (CSR) system able to suggest pertinent IF-THEN rules that can be easily deployed in different contexts starting from an abstract user’s need. By exploiting a conversational agent, the user can communicate her current personalization intention by specifying a set of functionality at a high level, e.g., to decrease the temperature of a room when she left it. Stemming from this input, <?TeX $HeyTAP^2$?> implements a semantic recommendation process that takes into account ( a ) the current user’s intention , ( b ) the connected entities owned by the user, and ( c ) the user’s long-term preferences revealed by her profile. If not satisfied with the suggestions, then the user can converse with the system to provide further feedback, i.e., a short-term preference , thus allowing <?TeX $HeyTAP^2$?> to provide refined recommendations that better align with the original intention. We evaluate <?TeX $HeyTAP^2$?> by running different offline experiments with simulated users and real-world data. First, we test the recommendation process in different configurations, and we show that recommendation accuracy and similarity with target items increase as the interaction between the algorithm and the user proceeds. Then, we compare <?TeX $HeyTAP^2$?> with other similar baseline recommender systems. Results are promising and demonstrate the effectiveness of <?TeX $HeyTAP^2$?> in recommending IF-THEN rules that satisfy the current personalization intention of the user.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W3194967301",
    "type": "article"
  },
  {
    "title": "CHA: Categorical Hierarchy-based Attention for Next POI Recommendation",
    "doi": "https://doi.org/10.1145/3464300",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Hongyu Zang; Dongcheng Han; Xin Li; Zhifeng Wan; Mingzhong Wang",
    "corresponding_authors": "",
    "abstract": "Next Point-of-interest (POI) recommendation is a key task in improving location-related customer experiences and business operations, but yet remains challenging due to the substantial diversity of human activities and the sparsity of the check-in records available. To address these challenges, we proposed to explore the category hierarchy knowledge graph of POIs via an attention mechanism to learn the robust representations of POIs even when there is insufficient data. We also proposed a spatial-temporal decay LSTM and a Discrete Fourier Series-based periodic attention to better facilitate the capturing of the personalized behavior pattern. Extensive experiments on two commonly adopted real-world location-based social networks (LBSNs) datasets proved that the inclusion of the aforementioned modules helps to boost the performance of next and next new POI recommendation tasks significantly. Specifically, our model in general outperforms other state-of-the-art methods by a large margin.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W3197907940",
    "type": "article"
  },
  {
    "title": "A Generic Federated Recommendation Framework via Fake Marks and Secret Sharing",
    "doi": "https://doi.org/10.1145/3548456",
    "publication_date": "2022-07-11",
    "publication_year": 2022,
    "authors": "Zhaohao Lin; Weike Pan; Qiang Yang; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "With the implementation of privacy protection laws such as GDPR, it is increasingly difficult for organizations to legally collect users’ data. However, a typical machine learning-based recommendation algorithm requires the data to learn users’ preferences. Some recent works thus turn to develop federated learning-based recommendation algorithms, but most of them either cannot protect the users’ privacy well, or sacrifice the model accuracy. In this article, we propose a lossless and generic federated recommendation framework via fake marks and secret sharing (FMSS). Our FMSS can not only protect the two types of users’ privacy, i.e., rating values and rating behaviors, without sacrificing the recommendation performance, but can also be applied to most recommendation algorithms for rating prediction, item ranking, and sequential recommendation. Specifically, we extend existing fake items to fake marks, and combine it with secret sharing to perturb the data uploaded by the clients to a server. We then apply our FMSS to six representative recommendation algorithms, i.e., MF-MPC and NeuMF for rating prediction, eALS and VAE-CF for item ranking, and Fossil and GRU4Rec for sequential recommendation. The experimental results demonstrate that our FMSS is a lossless and generic framework, which is able to federate a series of different recommendation algorithms in a lossless and privacy-aware manner.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W4285015060",
    "type": "article"
  },
  {
    "title": "A Revisiting Study of Appropriate Offline Evaluation for Top- <i>N</i> Recommendation Algorithms",
    "doi": "https://doi.org/10.1145/3545796",
    "publication_date": "2022-06-27",
    "publication_year": 2022,
    "authors": "Wayne Xin Zhao; Zihan Lin; Zhichao Feng; Pengfei Wang; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "In recommender systems, top- N recommendation is an important task with implicit feedback data. Although the recent success of deep learning largely pushes forward the research on top- N recommendation, there are increasing concerns on appropriate evaluation of recommendation algorithms. It therefore is important to study how recommendation algorithms can be reliably evaluated and thoroughly verified. This work presents a large-scale, systematic study on six important factors from three aspects for evaluating recommender systems. We carefully select 12 top- N recommendation algorithms and eight recommendation datasets. Our experiments are carefully designed and extensively conducted with these algorithms and datasets. In particular, all the experiments in our work are implemented based on an open sourced recommendation library, Recbole [ 139 ], which ensures the reproducibility and reliability of our results. Based on the large-scale experiments and detailed analysis, we derive several key findings on the experimental settings for evaluating recommender systems. Our findings show that some settings can lead to substantial or significant differences in performance ranking of the compared algorithms. In response to recent evaluation concerns, we also provide several suggested settings that are specially important for performance comparison.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W4283587264",
    "type": "article"
  },
  {
    "title": "Feature-Level Attentive ICF for Recommendation",
    "doi": "https://doi.org/10.1145/3490477",
    "publication_date": "2022-03-09",
    "publication_year": 2022,
    "authors": "Zhiyong Cheng; Fan Liu; Shenghan Mei; Yangyang Guo; Lei Zhu; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "Item-based collaborative filtering (ICF) enjoys the advantages of high recommendation accuracy and ease in online penalization and thus is favored by the industrial recommender systems. ICF recommends items to a target user based on their similarities to the previously interacted items of the user. Great progresses have been achieved for ICF in recent years by applying advanced machine learning techniques (e.g., deep neural networks) to learn the item similarity from data. The early methods simply treat all the historical items equally and recently proposed methods attempt to distinguish the different importance of historical items when recommending a target item. Despite the progress, we argue that those ICF models neglect the diverse intents of users on adopting items (e.g., watching a movie because of the director, leading actors, or the visual effects). As a result, they fail to estimate the item similarity on a finer-grained level to predict the user’s preference to an item, resulting in sub-optimal recommendation. In this work, we propose a general feature-level attention method for ICF models. The key of our method is to distinguish the importance of different factors when computing the item similarity for a prediction. To demonstrate the effectiveness of our method, we design a light attention neural network to integrate both item-level and feature-level attention for neural ICF models. It is model-agnostic and easy-to-implement. We apply it to two baseline ICF models and evaluate its effectiveness on six public datasets. Extensive experiments show the feature-level attention enhanced models consistently outperform their counterparts, demonstrating the potential of differentiating user intents on the feature-level for ICF recommendation models.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W4220751150",
    "type": "article"
  },
  {
    "title": "Mitigating Popularity Bias for Users and Items with Fairness-centric Adaptive Recommendation",
    "doi": "https://doi.org/10.1145/3564286",
    "publication_date": "2022-09-19",
    "publication_year": 2022,
    "authors": "Zhongzhou Liu; Yuan Fang; Min Wu",
    "corresponding_authors": "",
    "abstract": "Recommendation systems are popular in many domains. Researchers usually focus on the effectiveness of recommendation (e.g., precision) but neglect the popularity bias that may affect the fairness of the recommendation, which is also an important consideration that could influence the benefits of users and item providers. A few studies have been proposed to deal with the popularity bias, but they often face two limitations. Firstly, most studies only consider fairness for one side—either users or items, without achieving fairness jointly for both. Secondly, existing methods are not sufficiently tailored to each individual user or item to cope with the varying extent and nature of popularity bias. To alleviate these limitations, in this paper, we propose FAiR , a f airness-centric model that a dapt i vely mitigates the popularity bias in both users and items for r ecommendation. Concretely, we design explicit fairness discriminators to mitigate the popularity bias for each user and item locally, and an implicit discriminator to preserve fairness globally. Moreover, we dynamically adapt the model to different input users and items to handle the differences in their popularity bias. Finally, we conduct extensive experiments to demonstrate that our model significantly outperforms state-of-the-art baselines in fairness metrics, while remaining competitive in effectiveness.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W4296448463",
    "type": "article"
  },
  {
    "title": "A Multi-strategy-based Pre-training Method for Cold-start Recommendation",
    "doi": "https://doi.org/10.1145/3544107",
    "publication_date": "2022-10-26",
    "publication_year": 2022,
    "authors": "Bowen Hao; Hongzhi Yin; Jing Zhang; Cuiping Li; Hong Chen",
    "corresponding_authors": "",
    "abstract": "The cold-start issue is a fundamental challenge in Recommender Systems. The recent self-supervised learning (SSL) on Graph Neural Networks (GNNs) model, PT-GNN, pre-trains the GNN model to reconstruct the cold-start embeddings and has shown great potential for cold-start recommendation. However, due to the over-smoothing problem, PT-GNN can only capture up to 3-order relation, which cannot provide much useful auxiliary information to depict the target cold-start user or item. Besides, the embedding reconstruction task only considers the intra-correlations within the subgraph of users and items, while ignoring the inter-correlations across different subgraphs. To solve the above challenges, we propose a multi-strategy-based pre-training method for cold-start recommendation (MPT), which extends PT-GNN from the perspective of model architecture and pretext tasks to improve the cold-start recommendation performance. 1 Specifically, in terms of the model architecture, in addition to the short-range dependencies of users and items captured by the GNN encoder, we introduce a Transformer encoder to capture long-range dependencies. In terms of the pretext task, in addition to considering the intra-correlations of users and items by the embedding reconstruction task, we add an embedding contrastive learning task to capture inter-correlations of users and items. We train the GNN and Transformer encoders on these pretext tasks under the meta-learning setting to simulate the real cold-start scenario, making the model able to be easily and rapidly adapted to new cold-start users and items. Experiments on three public recommendation datasets show the superiority of the proposed MPT model against the vanilla GNN models, the pre-training GNN model on user/item embedding inference, and the recommendation task.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4200630830",
    "type": "article"
  },
  {
    "title": "Efficient Query-based Black-box Attack against Cross-modal Hashing Retrieval",
    "doi": "https://doi.org/10.1145/3559758",
    "publication_date": "2022-09-03",
    "publication_year": 2022,
    "authors": "Lei Zhu; Tianshi Wang; Jingjing Li; Zheng Zhang; Jialie Shen; Xinhua Wang",
    "corresponding_authors": "",
    "abstract": "Deep cross-modal hashing retrieval models inherit the vulnerability of deep neural networks. They are vulnerable to adversarial attacks, especially for the form of subtle perturbations to the inputs. Although many adversarial attack methods have been proposed to handle the robustness of hashing retrieval models, they still suffer from two problems: (1) Most of them are based on the white-box settings, which is usually unrealistic in practical application. (2) Iterative optimization for the generation of adversarial examples in them results in heavy computation. To address these problems, we propose an Efficient Query-based Black-Box Attack (EQB 2 A) against deep cross-modal hashing retrieval, which can efficiently generate adversarial examples for the black-box attack. Specifically, by sending a few query requests to the attacked retrieval system, the cross-modal retrieval model stealing is performed based on the neighbor relationship between the retrieved results and the query, thus obtaining the knockoffs to substitute the attacked system. A multi-modal knockoffs-driven adversarial generation is proposed to achieve efficient adversarial example generation. While the entire network training converges, EQB 2 A can efficiently generate adversarial examples by forward-propagation with only given benign images. Experiments show that EQB 2 A achieves superior attacking performance under the black-box setting.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4294409011",
    "type": "article"
  },
  {
    "title": "On the User Behavior Leakage from Recommender System Exposure",
    "doi": "https://doi.org/10.1145/3568954",
    "publication_date": "2022-10-21",
    "publication_year": 2022,
    "authors": "Xin Xin; Jiyuan Yang; Hanbing Wang; Jun Ma; Pengjie Ren; Hengliang Luo; Xinlei Shi; Zhumin Chen; Zhaochun Ren",
    "corresponding_authors": "",
    "abstract": "Modern recommender systems are trained to predict users’ potential future interactions from users’ historical behavior data. During the interaction process, despite the data coming from the user side, recommender systems also generate exposure data to provide users with personalized recommendation slates. Compared with the sparse user behavior data, the system exposure data are much larger in volume since only very few exposed items would be clicked by the user. In addition, user historical behavior data are privacy sensitive and commonly protected with careful access authorization. However, the large volume of recommender exposure data generated by the service provider itself usually receives less attention and could be accessed within a relatively larger scope of various information seekers or even potential adversaries. In this article, we investigate the problem of user behavior data leakage in the field of recommender systems. We show that the privacy-sensitive user past behavior data can be inferred through the modeling of system exposure. In other words, one can infer which items the user has clicked just from the observation of current system exposure for this user . Given the fact that system exposure data could be widely accessed from a relatively larger scope, we believe that user past behavior privacy has a high risk of leakage in recommender systems. More precisely, we conduct an attack model whose input is the current recommended item slate (i.e., system exposure) for the user while the output is the user’s historical behavior. Specifically, we exploit an encoder-decoder structure to construct the attack model and apply different encoding and decoding strategies to verify attack performance. Experimental results on two real-world datasets indicate a great danger of user behavior data leakage. To address the risk, we propose a two-stage privacy-protection mechanism that first selects a subset of items from the exposure slate and then replaces the selected items with uniform or popularity-based exposure. Experimental evaluation reveals a trade-off effect between the recommendation accuracy and the privacy disclosure risk, which is an interesting and important topic for privacy concerns in recommender systems.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4307168805",
    "type": "article"
  },
  {
    "title": "Enhancing Recommendation with Search Data in a Causal Learning Manner",
    "doi": "https://doi.org/10.1145/3582425",
    "publication_date": "2023-02-01",
    "publication_year": 2023,
    "authors": "Zihua Si; Zhongxiang Sun; Xiao Zhang; Jun Xu; Yang Song; Xiaoxue Zang; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Recommender systems are currently widely used in various applications helping people filter information. Existing models always embed the rich information for recommendation, such as items, users, and contexts in real-value vectors, and make predictions based on these vectors. In the view of causal inference, the associations between representation vectors and user feedback are inevitably a mixture of the causal part that describes why a user prefers an item, and the non-causal part that merely reflects the statistical dependencies, for example, the display ranking position and sales promotion. However, most recommender systems assume the user-item interactions are only affected by user preferences, neglecting the striking differences between these two associations. To address this problem, we propose a model-agnostic causal learning framework called IV4Rec+ that can effectively decompose the embedding vectors into these two parts. Moreover, two strategies are proposed to utilize search queries as instrumental variables: IV4Rec+(I) only decomposes the item embeddings, while IV4Rec+(UI) decomposes both user and item embeddings. IV4Rec+ is a model-agnostic design that can be applied to many existing recommender systems, e.g., DIN, NRHUB, and SRGNN. Extensive experiments on three datasets show that IV4Rec+ significantly facilitates the performance of recommender systems and outperforms state-of-the-art frameworks.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4319798365",
    "type": "article"
  },
  {
    "title": "AdaTaskRec: An Adaptive Task Recommendation Framework in Spatial Crowdsourcing",
    "doi": "https://doi.org/10.1145/3593582",
    "publication_date": "2023-05-05",
    "publication_year": 2023,
    "authors": "Yan Zhao; Liwei Deng; Kai Zheng",
    "corresponding_authors": "",
    "abstract": "Spatial crowdsourcing is one of the prime movers for the orchestration of location-based tasks, and task recommendation is a crucial means to help workers discover attractive tasks. While a number of existing studies have focused on modeling workers' geographical preferences in task recommendation, they ignore the phenomenon of workers' travel intention drifts across geographical areas, i.e., workers tend to have different intentions when they travel in different areas, which discounts the task recommendation quality of existing methods especially for workers that travel in unfamiliar out-of-Town areas. To address this problem, we propose an Adaptive Task Recommendation (AdaTaskRec) framework. Specifically, we first give a novel two-module worker preference learning architecture that can calculate workers' preferences for POIs (that tasks are associated with) in different areas adaptively based on workers' current locations. If we detect that a worker is in the hometown area, then we apply the hometown preference learning module, which hybrids different strategies to aggregate workers' travel intentions into their preferences while considering the transition and the sequence patterns among locations. Otherwise, we invoke the out-of-Town preference learning module, which is to capture workers' preferences by learning their travel intentions and transferring their hometown preferences into their out-of-Town ones. Additionally, to improve task recommendation effectiveness, we propose a dynamic top-k recommendation method that sets different k values dynamically according to the numbers of neighboring workers and tasks. We also give an extra-reward-based and a fair top-k recommendation method, which introduce the extra rewards for tasks based on their recommendation rounds and consider exposure-based fairness of tasks, respectively. Extensive experiments offer insight into the effectiveness of the proposed framework.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4372346777",
    "type": "article"
  },
  {
    "title": "An Analysis of Fusion Functions for Hybrid Retrieval",
    "doi": "https://doi.org/10.1145/3596512",
    "publication_date": "2023-05-20",
    "publication_year": 2023,
    "authors": "Sebastian Bruch; Siyu Gai; Amir Ingber",
    "corresponding_authors": "",
    "abstract": "We study hybrid search in text retrieval where lexical and semantic search are fused together with the intuition that the two are complementary in how they model relevance. In particular, we examine fusion by a convex combination (CC) of lexical and semantic scores, as well as the Reciprocal Rank Fusion (RRF) method, and identify their advantages and potential pitfalls. Contrary to existing studies, we find RRF to be sensitive to its parameters; that the learning of a CC fusion is generally agnostic to the choice of score normalization; that CC outperforms RRF in in-domain and out-of-domain settings; and finally, that CC is sample efficient, requiring only a small set of training examples to tune its only parameter to a target domain.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4377138005",
    "type": "article"
  },
  {
    "title": "Dynamic Multimodal Fusion via Meta-Learning Towards Micro-Video Recommendation",
    "doi": "https://doi.org/10.1145/3617827",
    "publication_date": "2023-08-30",
    "publication_year": 2023,
    "authors": "Han Liu; Yinwei Wei; Fan Liu; Wenjie Wang; Liqiang Nie; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Multimodal information (e.g., visual, acoustic, and textual) has been widely used to enhance representation learning for micro-video recommendation. For integrating multimodal information into a joint representation of micro-video, multimodal fusion plays a vital role in the existing micro-video recommendation approaches. However, the static multimodal fusion used in previous studies is insufficient to model the various relationships among multimodal information of different micro-videos. In this article, we develop a novel meta-learning-based multimodal fusion framework called Meta Multimodal Fusion (MetaMMF), which dynamically assigns parameters to the multimodal fusion function for each micro-video during its representation learning. Specifically, MetaMMF regards the multimodal fusion of each micro-video as an independent task. Based on the meta information extracted from the multimodal features of the input task, MetaMMF parameterizes a neural network as the item-specific fusion function via a meta learner. We perform extensive experiments on three benchmark datasets, demonstrating the significant improvements over several state-of-the-art multimodal recommendation models, like MMGCN, LATTICE, and InvRL. Furthermore, we lighten our model by adopting canonical polyadic decomposition to improve the training efficiency, and validate its effectiveness through experimental results. Codes are available at https://github.com/hanliu95/MetaMMF .",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4386289268",
    "type": "article"
  },
  {
    "title": "Relieving Popularity Bias in Interactive Recommendation: A Diversity-Novelty-Aware Reinforcement Learning Approach",
    "doi": "https://doi.org/10.1145/3618107",
    "publication_date": "2023-09-01",
    "publication_year": 2023,
    "authors": "Xiaoyu Shi; Quanliang Liu; Hong Xie; Di Wu; Bo Peng; Mingsheng Shang; Defu Lian",
    "corresponding_authors": "",
    "abstract": "While personalization increases the utility of item recommendation, it also suffers from the issue of popularity bias. However, previous methods emphasize adopting supervised learning models to relieve popularity bias in the static recommendation, ignoring the dynamic transfer of user preference and amplification effects of the feedback loop in the recommender system (RS). In this paper, we focus on studying this issue in the interactive recommendation. We argue that diversification and novelty are both equally crucial for improving user satisfaction of IRS in the aforementioned setting. To achieve this goal, we propose a D iversity- N ovelty- a ware I nteractive R ecommendation framework (DNaIR) that augments offline reinforcement learning (RL) to increase the exposure rate of long-tail items with high quality. Its main idea is first to aggregate the item similarity, popularity, and quality into the reward model to help the planning of RL policy. It then designs a diversity-aware stochastic action generator to achieve an efficient and lightweight DNaIR algorithm. Extensive experiments are conducted on the three real-world datasets and an authentic RL environment (Virtual-Taobao). The experiments show that our model can better and full use of the long-tail items to improve recommendation satisfaction, especially those low popularity items with high-quality ones, thus achieving state-of-the-art performance.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4386370543",
    "type": "article"
  },
  {
    "title": "Robust Collaborative Filtering to Popularity Distribution Shift",
    "doi": "https://doi.org/10.1145/3627159",
    "publication_date": "2023-10-12",
    "publication_year": 2023,
    "authors": "An Zhang; Wenchang Ma; Jingnan Zheng; Xiang Wang; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "In leading collaborative filtering (CF) models, representations of users and items are prone to learn popularity bias in the training data as shortcuts. The popularity shortcut tricks are good for in-distribution (ID) performance but poorly generalized to out-of-distribution (OOD) data, i.e., when popularity distribution of test data shifts w.r.t. the training one. To close the gap, debiasing strategies try to assess the shortcut degrees and mitigate them from the representations. However, there exist two deficiencies: (1) when measuring the shortcut degrees, most strategies only use statistical metrics on a single aspect (i.e., item frequency on item and user frequency on user aspect), failing to accommodate the compositional degree of a user-item pair; (2) when mitigating shortcuts, many strategies assume that the test distribution is known in advance. This results in low-quality debiased representations. Worse still, these strategies achieve OOD generalizability with a sacrifice on ID performance. In this work, we present a simple yet effective debiasing strategy, PopGo, which quantifies and reduces the interaction-wise popularity shortcut without any assumptions on the test data. It first learns a shortcut model, which yields a shortcut degree of a user-item pair based on their popularity representations. Then, it trains the CF model by adjusting the predictions with the interaction-wise shortcut degrees. By taking both causal- and information-theoretical looks at PopGo, we can justify why it encourages the CF model to capture the critical popularity-agnostic features while leaving the spurious popularity-relevant patterns out. We use PopGo to debias two high-performing CF models (MF, LightGCN) on four benchmark datasets. On both ID and OOD test sets, PopGo achieves significant gains over the state-of-the-art debiasing strategies (e.g., DICE, MACR).",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4387580087",
    "type": "article"
  },
  {
    "title": "Manipulating Visually Aware Federated Recommender Systems and Its Countermeasures",
    "doi": "https://doi.org/10.1145/3630005",
    "publication_date": "2023-10-23",
    "publication_year": 2023,
    "authors": "Wei Yuan; Shilong Yuan; Chaoqun Yang; Quoc Viet Hung Nguyen; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "Federated recommender systems (FedRecs) have been widely explored recently due to their capability to safeguard user data privacy. These systems enable a central server to collaboratively learn recommendation models by sharing public parameters with clients, providing privacy-preserving solutions. However, this collaborative approach also creates a vulnerability that allows adversaries to manipulate FedRecs. Existing works on FedRec security already reveal that items can easily be promoted by malicious users via model poisoning attacks, but all of them mainly focus on FedRecs with only collaborative information (i.e., user–item interactions). We contend that these attacks are effective primarily due to the data sparsity of collaborative signals. In light of this, we propose a method to address data sparsity and model poisoning threats by incorporating product visual information. Intriguingly, our empirical findings demonstrate that the inclusion of visual information renders all existing model poisoning attacks ineffective. Nevertheless, the integration of visual information also introduces a new avenue for adversaries to manipulate federated recommender systems, as this information typically originates from external sources. To assess such threats, we propose a novel form of poisoning attack tailored for visually aware FedRecs, namely image poisoning attacks, where adversaries can gradually modify the uploaded image with human-unaware perturbations to manipulate item ranks during the FedRecs’ training process. Moreover, we provide empirical evidence showcasing a heightened threat when image poisoning attacks are combined with model poisoning attacks, resulting in easier manipulation of the federated recommendation systems. To ensure the safe utilization of visual information, we employ a diffusion model in visually aware FedRecs to purify each uploaded image and detect the adversarial images. Extensive experiments conducted with two FedRecs on two datasets demonstrate the effectiveness and generalization of our proposed attacks and defenses.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4387868958",
    "type": "article"
  },
  {
    "title": "Spatio-temporal Contrastive Learning-enhanced GNNs for Session-based Recommendation",
    "doi": "https://doi.org/10.1145/3626091",
    "publication_date": "2023-10-04",
    "publication_year": 2023,
    "authors": "Zhongwei Wan; Xin Liu; Benyou Wang; Jiezhong Qiu; Boyu Li; Ting Guo; Guangyong Chen; Yang Wang",
    "corresponding_authors": "",
    "abstract": "Session-based recommendation (SBR) systems aim to utilize the user’s short-term behavior sequence to predict the next item without the detailed user profile. Most recent works try to model the user preference by treating the sessions as between-item transition graphs and utilize various graph neural networks (GNNs) to encode the representations of pair-wise relations among items and their neighbors. Some of the existing GNN-based models mainly focus on aggregating information from the view of spatial graph structure, which ignores the temporal relations within neighbors of an item during message passing and the information loss results in a sub-optimal problem. Other works embrace this challenge by incorporating additional temporal information but lack sufficient interaction between the spatial and temporal patterns. To address this issue, inspired by the uniformity and alignment properties of contrastive learning techniques, we propose a novel framework called Session-based Recommendation with Spatio-temporal Contrastive Learning-enhanced GNNs (RESTC). The idea is to supplement the GNN-based main supervised recommendation task with the temporal representation via an auxiliary cross-view contrastive learning mechanism. Furthermore, a novel global collaborative filtering graph embedding is leveraged to enhance the spatial view in the main task. Extensive experiments demonstrate the significant performance of RESTC compared with the state-of-the-art baselines. We release our source code at https://github.com/SUSTechBruce/RESTC-Source-code .",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4387344337",
    "type": "article"
  },
  {
    "title": "MCRPL: A Pretrain, Prompt, and Fine-tune Paradigm for Non-overlapping Many-to-one Cross-domain Recommendation",
    "doi": "https://doi.org/10.1145/3641860",
    "publication_date": "2024-01-22",
    "publication_year": 2024,
    "authors": "Hao Liu; Lei Guo; Lei Zhu; Yongqiang Jiang; Min Gao; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "Cross-domain Recommendation is the task that tends to improve the recommendations in the sparse target domain by leveraging the information from other rich domains. Existing methods of cross-domain recommendation mainly focus on overlapping scenarios by assuming users are totally or partially overlapped, which are taken as bridges to connect different domains. However, this assumption does not always hold, since it is illegal to leak users’ identity information to other domains. Conducting Non-overlapping MCR (NMCR) is challenging, since (1) the absence of overlapping information prevents us from directly aligning different domains, and this situation may get worse in the MCR scenario, and (2) the distribution between source and target domains makes it difficult for us to learn common information across domains. To overcome the above challenges, we focus on NMCR and devise MCRPL as our solution. To address Challenge 1, we first learn shared domain-agnostic and domain-dependent prompts and pre-train them in the pre-training stage. To address Challenge 2, we further update the domain-dependent prompts with other parameters kept fixed to transfer the domain knowledge to the target domain. We conduct experiments on five real-world domains, and the results show the advance of our MCRPL method compared with several recent SOTA baselines. Moreover, our source codes have been publicly released. 1",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4391103882",
    "type": "article"
  },
  {
    "title": "DHyper: A Recurrent Dual Hypergraph Neural Network for Event Prediction in Temporal Knowledge Graphs",
    "doi": "https://doi.org/10.1145/3653015",
    "publication_date": "2024-03-18",
    "publication_year": 2024,
    "authors": "Xing Tang; Ling Chen; Hongyu Shi; Dandan Lyu",
    "corresponding_authors": "",
    "abstract": "Event prediction is a vital and challenging task in temporal knowledge graphs (TKGs), which have played crucial roles in various applications. Recently, many graph neural networks based approaches are proposed to model the graph structure information in TKGs. However, these approaches only construct graphs based on quadruplets and model the pairwise correlation between entities, which fail to capture the high-order correlations among entities. To this end, we propose DHyper, a recurrent Dual Hypergraph neural network for event prediction in TKGs, which simultaneously models the influences of the high-order correlations among both entities and relations. Specifically, a dual hypergraph learning module is proposed to discover the high-order correlations among entities and among relations in a parameterized way. A dual hypergraph message passing network is introduced to perform the information aggregation and representation fusion on the entity hypergraph and the relation hypergraph. Extensive experiments on six real-world datasets demonstrate that DHyper achieves the state-of-the-art performances, outperforming the best baseline by an average of 13.09%, 4.26%, 17.60%, and 18.03% in MRR, Hits@1, Hits@3, and Hits@10, respectively.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4392911065",
    "type": "article"
  },
  {
    "title": "FIT-RAG: Black-Box RAG with Factual Information and Token Reduction",
    "doi": "https://doi.org/10.1145/3676957",
    "publication_date": "2024-07-09",
    "publication_year": 2024,
    "authors": "Yuren Mao; Xuemei Dong; Wenyi Xu; Yunjun Gao; Bin Wei; Ying Zhang",
    "corresponding_authors": "",
    "abstract": "Due to the extraordinarily large number of parameters, fine-tuning Large Language Models (LLMs) to update long-tail or out-of-date knowledge is impractical in lots of applications. To avoid fine-tuning, we can alternatively treat a LLM as a black-box (i.e., freeze the parameters of the LLM) and augment it with a Retrieval-Augmented Generation (RAG) system, namely black-box RAG. Recently, black-box RAG has achieved success in knowledge-intensive tasks and has gained much attention. Existing black-box RAG methods typically fine-tune the retriever to cater to LLMs’ preferences and concatenate all the retrieved documents as the input, which suffers from two issues: (1) Ignorance of Factual Information. The LLM preferred documents may not contain the factual information for the given question, which can mislead the retriever and hurt the effectiveness of black-box RAG; (2) Waste of Tokens. Simply concatenating all the retrieved documents brings large amounts of unnecessary tokens for LLMs, which degenerates the efficiency of black-box RAG. To address these issues, this paper proposes a novel black-box RAG framework which utilizes the factual information in the retrieval and reduces the number of tokens for augmentation, dubbed FIT-RAG. FIT-RAG utilizes the factual information by constructing a bi-label document scorer which takes the factual information and LLMs’ preferences as labels respectively. Besides, it reduces the tokens by introducing a self-knowledge recognizer and a sub-document-level token reducer, which enables FIT-RAG to avoid unnecessary augmentation and reduce augmentation tokens as much as possible. FIT-RAG achieves both superior effectiveness and efficiency, which is validated by extensive experiments across three open-domain question-answering datasets: TriviaQA, NQ and PopQA. FIT-RAG can improve the answering accuracy of Llama2-13B-Chat by 14.3% on TriviaQA, 19.9% on NQ and 27.5% on PopQA, respectively. Furthermore, it can save approximately half of the tokens on average across the three datasets.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4400460572",
    "type": "article"
  },
  {
    "title": "A Survey on Recommender Systems using Graph Neural Network",
    "doi": "https://doi.org/10.1145/3694784",
    "publication_date": "2024-09-06",
    "publication_year": 2024,
    "authors": "V. D. Anand; Ashish Kumar Maurya",
    "corresponding_authors": "",
    "abstract": "The expansion of the Internet has resulted in a change in the flow of information. With the vast amount of digital information generated online, it is easy for users to feel overwhelmed. Finding the specific information can be a challenge, and it can be difficult to distinguish credible sources from unreliable ones. This has made recommender system (RS) an integral part of the information services framework. These systems alleviate users from information overload by analyzing users’ past preferences and directing only desirable information toward users. Traditional RSs use approaches like collaborative and content-based filtering to generate recommendations. Recently, these systems have evolved to a whole new level, intuitively optimizing recommendations using deep network models. Graph Neural Networks (GNNs) have become one of the most widely used approaches in RSs, capturing complex relationships between users and items using graphs. In this survey, we provide a literature review of the latest research efforts done on GNN-based RSs. We present an overview of RS, discuss its generalized pipeline and evolution with changing learning approaches. Furthermore, we explore basic GNN architecture and its variants used in RSs, their applications, and some critical challenges for future research.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4402306238",
    "type": "article"
  },
  {
    "title": "Relational Prompt-based Pre-trained Language Models for Social Event Detection",
    "doi": "https://doi.org/10.1145/3695869",
    "publication_date": "2024-09-13",
    "publication_year": 2024,
    "authors": "Pu Li; Xiaoyan Yu; Hao Peng; Yantuan Xian; Linqin Wang; Li Sun; Jingyun Zhang; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "Social Event Detection (SED) aims to identify significant events from social streams, and has a wide application ranging from public opinion analysis to risk management. In recent years, Graph Neural Network (GNN) based solutions have achieved state-of-the-art performance. However, GNN-based methods often struggle with missing and noisy edges between messages, affecting the quality of learned message embedding. Moreover, these methods statically initialize node embedding before training, which, in turn, limits the ability to learn from message texts and relations simultaneously. In this paper, we approach social event detection from a new perspective based on Pre-trained Language Models (PLMs), and present \\(\\mathrm{RPLM}_{SED}\\) ( R elational prompt-based P re-trained L anguage M odels for S ocial E vent D etection). We first propose a new pairwise message modeling strategy to construct social messages into message pairs with multi-relational sequences. Secondly, a new multi-relational prompt-based pairwise message learning mechanism is proposed to learn more comprehensive message representation from message pairs with multi-relational prompts using PLMs. Thirdly, we design a new clustering constraint to optimize the encoding process by enhancing intra-cluster compactness and inter-cluster dispersion, making the message representation more distinguishable. We evaluate the \\(\\mathrm{RPLM}_{SED}\\) on three real-world datasets, demonstrating that the \\(\\mathrm{RPLM}_{SED}\\) model achieves state-of-the-art performance in offline, online, low-resource, and long-tail distribution scenarios for social event detection tasks.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4402515701",
    "type": "article"
  },
  {
    "title": "A Noise-Oriented and Redundancy-Aware Instance Selection Framework",
    "doi": "https://doi.org/10.1145/3705000",
    "publication_date": "2024-11-20",
    "publication_year": 2024,
    "authors": "Washington Cunha; Alejandro Moreo; Andrea Esuli; Fabrizio Sebastiani; Leonardo Rocha; Marcos André Gonçalves",
    "corresponding_authors": "",
    "abstract": "Fine-tuning transformer-based deep learning models is currently at the forefront of natural language processing (NLP) and information retrieval (IR) tasks. However, fine-tuning these transformers for specific tasks, especially when dealing with ever-expanding volumes of data, constant retraining requirements, and budget constraints, can be computationally and financially costly, requiring substantial energy consumption and contributing to carbon dioxide emissions. This article focuses on advancing the state-of-the-art (SOTA) on instance selection (IS) – a range of document filtering techniques designed to select the most representative documents for the sake of training. The objective is to either maintain or enhance classification effectiveness while reducing the overall training (fine-tuning) total processing time. In our prior research, we introduced the E2SC framework, a redundancy-oriented IS method focused on transformers and large datasets – currently the state-of-the-art in IS. Nonetheless, important research questions remained unanswered in our previous work, mostly due to E2SC's sole emphasis on redundancy. In this article, we take our research a step further by proposing biO-IS – an extended bi - ob jective i nstance s election solution, a novel IS framework aimed at simultaneously removing redundant and noisy instances from the training. biO-IS estimates redundancy based on scalable, fast, and calibrated weak classifiers and captures noise with the support of a new entropy-based step. We also propose a novel iterative process to estimate near-optimum reduction rates for both steps. Our extended solution is able to reduce the training sets by 41% on average (up to 60%) while maintaining the effectiveness in all tested datasets, with speedup gains of 1.67 on average (up to 2.46x). No other baseline, not even our previous SOTA solution, was capable of achieving results with this level of quality, considering the tradeoff among training reduction, effectiveness, and speedup. To ensure reproducibility, our documentation, code, and datasets can be accessed on GitHub – https://github.com/waashk/bio-is .",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4404534353",
    "type": "article"
  },
  {
    "title": "A robust framework for content-based retrieval by spatial similarity in image databases",
    "doi": "https://doi.org/10.1145/306686.306689",
    "publication_date": "1999-04-01",
    "publication_year": 1999,
    "authors": "Essam A. El-Kwae; Mansur R. Kabuka",
    "corresponding_authors": "",
    "abstract": "A framework for retrieving images by spatial similarity (FRISS) in ima ge databases is presented. In this framework, a robust retrieval by spatial similarity (RSS) algorithm is defined as one that incorporates both directional and topological spatial constraints, retrieves similar images, and recognized images even after they undergo translation, scaling, rotation (both perfect and multiple), or any arbitrary combination of transformatioins. The FRISS framework is discussed and used as a base for comparing various existing RSS algorithms. Analysis shows that none of them satisfies all the FRISS specifications. An algorithm, SIM dtc , is then presented. SIM dtc introduces the concept of a rotation correction angle (RCA) to align objects in one image spatially closer to matching objects in another image for more accurate similarity assessment. Similarity between two images is a function of the number of common objects between them and the closeness of directional and topological spatial relationships between object pairs in both images. The SIM dtc retrieval is invariant under translation, scaling, and perfect rotation, and the algorithm is able to rank multiple rotation variants. The algorithm was tested using synthetic images and the TESSA image database. Analysis shows the robustness of the SIM dtc algorithm over current algorithms.",
    "cited_by_count": 83,
    "openalex_id": "https://openalex.org/W2024439383",
    "type": "article"
  },
  {
    "title": "WebQuilt",
    "doi": "https://doi.org/10.1145/502115.502118",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "WebQuilt is a web logging and visualization system that helps web design teams run usability tests (both local and remote) and analyze the collected data. Logging is done through a proxy, overcoming many of the problems with server-side and client-side logging. Captured usage traces can be aggregated and visualized in a zooming interface that shows the web pages people viewed. The visualization also shows the most common paths taken through the web site for a given task, as well as the optimal path for that task, as designated by the designer. This paper discusses the architecture of WebQuilt and describes how it can be extended for new kinds of analyses and visualizations.",
    "cited_by_count": 79,
    "openalex_id": "https://openalex.org/W4242757675",
    "type": "article"
  },
  {
    "title": "Some inconsistencies and misidentified modeling assumptions in probabilistic information retrieval",
    "doi": "https://doi.org/10.1145/195705.195735",
    "publication_date": "1995-01-02",
    "publication_year": 1995,
    "authors": "William S. Cooper",
    "corresponding_authors": "William S. Cooper",
    "abstract": "article Free Access Share on Some inconsistencies and misidentified modeling assumptions in probabilistic information retrieval Author: William S. Cooper Univ. of California, Berkeley Univ. of California, BerkeleyView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 13Issue 1Jan. 1995 pp 100–111https://doi.org/10.1145/195705.195735Published:02 January 1995Publication History 50citation748DownloadsMetricsTotal Citations50Total Downloads748Last 12 Months21Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 78,
    "openalex_id": "https://openalex.org/W2001664274",
    "type": "article"
  },
  {
    "title": "Hyperdocuments as automata",
    "doi": "https://doi.org/10.1145/267954.267955",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "P. David Stotts; Richard Furuta; Cyrano Ruiz Cabarrus",
    "corresponding_authors": "",
    "abstract": "We present a view of hyperdocuments in which each document encodes its own browsing semantics in its links. This requires a mental shift in how a hyperdocument is thought of abstractly. Instead of treating the links of a document as defining a static directed graph, they are thought of as defining an abstract program, termed the links-automaton of the document. A branching temporal logic notation, termed HTL*, is introduced for specifying properties a document should exhibit during browsing. An automated program verification technique called model checking is used to verify that browsing specifications in a subset of HTL* are met by the behavior defined in the links-automation. We illustrate the generality of these techniques by applying them first to several Trellis documents and then to a Hyperties document.",
    "cited_by_count": 78,
    "openalex_id": "https://openalex.org/W2048779903",
    "type": "article"
  },
  {
    "title": "Evaluation of model-based retrieval effectiveness with OCR text",
    "doi": "https://doi.org/10.1145/214174.214180",
    "publication_date": "1996-01-11",
    "publication_year": 1996,
    "authors": "Kazem Taghva; Julie Borsack; Allen Condit",
    "corresponding_authors": "",
    "abstract": "We give a comprehensive report on our experiments with retrieval from OCR-generated text using systems based on standard models of retrieval. More specifically, we show that average precision and recall is not affected by OCR errors across systems for several collections. The collections used in these experiments include both actual OCR-generated text and standard information retrieval collections corrupted through the simulation of OCR errors. Both the actual and simulation experiments include full-text and abstract-length documents. We also demonstrate that the ranking and feedback methods associated with these models are generally not robust enough to deal with OCR errors. It is further shown that the OCR errors and garbage strings generated from the mistranslation of graphic objects increase the size of the index by a wide margin. We not only point out problems that can arise from applying OCR text within an information retrieval environment, we also suggest solutions to overcome some of these problems.",
    "cited_by_count": 77,
    "openalex_id": "https://openalex.org/W2093168600",
    "type": "article"
  },
  {
    "title": "Query-independent evidence in home page finding",
    "doi": "https://doi.org/10.1145/858476.858479",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Trystan Upstill; Nick Craswell; David Hawking",
    "corresponding_authors": "",
    "abstract": "Hyperlink recommendation evidence, that is, evidence based on the structure of a web's link graph, is widely exploited by commercial Web search systems. However there is little published work to support its popularity. Another form of query-independent evidence, URL-type, has been shown to be beneficial on a home page finding task. We compared the usefulness of these types of evidence on the home page finding task, combined with both content and anchor text baselines. Our experiments made use of five query sets spanning three corpora---one enterprise crawl, and the WT10g and VLC2 Web test collections.We found that, in optimal conditions, all of the query-independent methods studied (in-degree, URL-type, and two variants of PageRank) offered a better than random improvement on a content-only baseline. However, only URL-type offered a better than random improvement on an anchor text baseline. In realistic settings, for either baseline, only URL-type offered consistent gains. In combination with URL-type the anchor text baseline was more useful for finding popular home pages, but URL-type with content was more useful for finding randomly selected home pages. We conclude that a general home page finding system should combine evidence from document content, anchor text, and URL-type classification.",
    "cited_by_count": 77,
    "openalex_id": "https://openalex.org/W2142510125",
    "type": "article"
  },
  {
    "title": "Semantic data modeling of hypermedia associations",
    "doi": "https://doi.org/10.1145/151480.151521",
    "publication_date": "1993-01-02",
    "publication_year": 1993,
    "authors": "John L. Schnase; John J. Leggett; David L. Hicks; Ron L. Szabo",
    "corresponding_authors": "",
    "abstract": "Many important issues in the design and implementation of hypermedia system functionality focus on the way interobject connections are represented, manipulated, and stored. A prototypic system called HB1 is being designed to meet the storage needs of next-generation hypermedia system architectures. HB1 is referred to as a hyperbase management system (HBMS) because it supports, not only the storage and manipulation of information, but the storage and manipulation of the connectivity data that link information together to form hypermedia. Among HB1's distinctions is its use of a semantic network database system to manage physical storage. Here, basic semantic modeling concepts as they apply to hypermedia systems are reviewed, and experiences using a semantic database system in HB1 are discussed. Semantic data models attempt to provide more powerful mechanisms for structuring objects than are provided by traditional approaches. In HB1, it was necessary to abstract interobject connectivity, behaviors, and information for hypermedia. Building on top of a semantic database system facilitated such a separation and made the structural aspects of hypermedia conveniently accessible to manipulation. This becomes particularly important in the implementation of structure-related operations such as structural queries. Our experience suggests that an integrated semantic object-oriented database paradigm appears to be superior to purely relational, semantic, or object-oriented methodologies for representing the structurally complex interrelationships that arise in hypermedia.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2037728063",
    "type": "article"
  },
  {
    "title": "Comparing the performance of collection selection algorithms",
    "doi": "https://doi.org/10.1145/944012.944016",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Allison L. Powell; James C. French",
    "corresponding_authors": "",
    "abstract": "The proliferation of online information resources increases the importance of effective and efficient information retrieval in a multicollection environment. Multicollection searching is cast in three parts: collection selection (also referred to as database selection), query processing and results merging. In this work, we focus our attention on the evaluation of the first step, collection selection.In this article, we present a detailed discussion of the methodology that we used to evaluate and compare collection selection approaches, covering both test environments and evaluation measures. We compare the CORI , CVV and gGLOSS collection selection approaches using six test environments utilizing three document testbeds. We note similar trends in performance among the collection selection approaches, but the CORI approach consistently outperforms the other approaches, suggesting that effective collection selection can be achieved using limited information about each collection.The contributions of this work are both the assembled evaluation methodology as well as the application of that methodology to compare collection selection approaches in a standardized environment.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2038526807",
    "type": "article"
  },
  {
    "title": "Evaluating the performance of distributed architectures for information retrieval using a variety of workloads",
    "doi": "https://doi.org/10.1145/333135.333136",
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "Brendon Cahoon; Kathryn S. McKinley; Zhihong Lu",
    "corresponding_authors": "",
    "abstract": "The information explosion across the Internet and elswhere offers access to an increasing number of document collections. In order for users to effectively access these collections, information retrieval (IR) systems must provide coordinated, concurrent, and distributed access. In this article, we explore how to achieve scalable performance in a distributed system for collection sizes ranging from 1GB to 128GB. We implement a fully functional distributed IR system based on a multithreaded version of the Inquery simulation model. We measure performance as a function of system parameters such as client command rate, number of document collections, ter ms per query, query term frequency, number of answers returned, and command mixture. Our results show that it is important to model both query and document commands because the heterogeneity of commands significantly impacts performance. Based on our results, we recommend simple changes to the prototype and evaluate the changes using the simulator. Because of the significant resource demands of information retrieval, it is not difficult to generate workloads that overwhelm system resources regardless of the architecture. However under some realistic workloads, we demonstrate system organizations for which response time gracefully degrades as the workload increases and performance scales with the number of processors. This scalable architecture includes a surprisingly small number of brokers through which a large number of clients and servers communicate.",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2164806720",
    "type": "article"
  },
  {
    "title": "The role of another spatial dimension in software visualization",
    "doi": "https://doi.org/10.1145/159161.155370",
    "publication_date": "1993-07-01",
    "publication_year": 1993,
    "authors": "Hideki Koike",
    "corresponding_authors": "Hideki Koike",
    "abstract": "article Free Access Share on The role of another spatial dimension in software visualization Author: Hideki Koike View Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 11Issue 3July 1993 pp 266–286https://doi.org/10.1145/159161.155370Online:01 July 1993Publication History 46citation928DownloadsMetricsTotal Citations46Total Downloads928Last 12 Months32Last 6 weeks6 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 73,
    "openalex_id": "https://openalex.org/W2044013641",
    "type": "article"
  },
  {
    "title": "Chimera",
    "doi": "https://doi.org/10.1145/352595.352596",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Kenneth M. Anderson; Richard N. Taylor; E. James Whitehead",
    "corresponding_authors": "",
    "abstract": "Emerging software development environments are characterized by heterogeneity: they are composed of diverse object stores, user interfaces, and tools. This paper presents an approach for providing hypermedia services in this heterogeneous setting. Central notions of the approach include the following: anchors are established with respect to interactive views of objects, rather than the objects themselves; composable, n -ary links can be established between anchors on different views of objects which may be stored in distinct object bases; viewers may be implemented in different programming languages; and, hypermedia services are provided to multiple, concurrently active, viewers. The paper describes the approach, supporting architecture, and lessons learned. Related work in the areas of supporing heterogeneity and hypermedia data modeling is discussed. The system has been employed in a variety of contexts including research, development, and education.",
    "cited_by_count": 73,
    "openalex_id": "https://openalex.org/W2107191673",
    "type": "article"
  },
  {
    "title": "Historical spatio-temporal aggregation",
    "doi": "https://doi.org/10.1145/1055709.1055713",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Yufei Tao; Dimitris Papadias",
    "corresponding_authors": "",
    "abstract": "Spatio-temporal databases store information about the positions of individual objects over time. However, in many applications such as traffic supervision or mobile communication systems, only summarized data, like the number of cars in an area for a specific period, or phone-calls serviced by a cell each day, is required. Although this information can be obtained from operational databases, its computation is expensive, rendering online processing inapplicable. In this paper, we present specialized methods, which integrate spatio-temporal indexing with pre-aggregation. The methods support dynamic spatio-temporal dimensions for the efficient processing of historical aggregate queries without a priori knowledge of grouping hierarchies. The superiority of the proposed techniques over existing methods is demonstrated through a comprehensive probabilistic analysis and an extensive experimental evaluation.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W2085676663",
    "type": "article"
  },
  {
    "title": "Distributed content-based visual information retrieval system on peer-to-peer networks",
    "doi": "https://doi.org/10.1145/1010614.1010619",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "Irwin King; Cheuk Hang Ng; Ka Cheung Sia",
    "corresponding_authors": "",
    "abstract": "With the recent advances of distributed computing, the limitation of information retrieval from a centralized image collection can be removed by allowing distributed image data sources to interact with each other for data storage sharing and information retrieval. In this article, we present our design and implementation of DISCOVIR: DIStributed COntent-based Visual Information Retrieval system using the Peer-to-Peer (P2P) Network. We describe the system architecture and detail the interactions among various system modules. Specifically, we propose a Firework Query Model for distributed information retrieval, which aims to reduce the network traffic of query passing in the network. We carry out experiments to show the distributed image retrieval system and the Firework information retrieval algorithm. The results show that the algorithm reduces network traffic while increases searching performance.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W2113983313",
    "type": "article"
  },
  {
    "title": "A speech-act-based negotiation protocol",
    "doi": "https://doi.org/10.1145/185462.185477",
    "publication_date": "1994-10-01",
    "publication_year": 1994,
    "authors": "Man Kit Chang; Carson Woo",
    "corresponding_authors": "",
    "abstract": "Existing negotiation protocols used in Distributed Artificial Intelligence (DAI) systems rarely take into account the results from negotiation research. We propose a negotiation protocol, SANP (Speech-Act-based Negotiation Protocol), which is based on Ballmer and Brennenstuhl's speech act classification and on negotiation analysis literature. The protocol is implemented as a domain-independent system using Strudel, which is an electronic mail toolkit. A small study tested the potential use of the protocol. Although a number of limitations were found in the study, the protocol appears to have potential in domains without these limitations, and it can serve as a building block to design more general negotiation protocols.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W2032165060",
    "type": "article"
  },
  {
    "title": "Knowledge-based search tactics for an intelligent intermediary system",
    "doi": "https://doi.org/10.1145/65943.65947",
    "publication_date": "1989-07-01",
    "publication_year": 1989,
    "authors": "Philip J. Smith; Steven J. Shute; Beb Galdes; Mark Chignell",
    "corresponding_authors": "",
    "abstract": "Research on the nature of knowledge-based systems for bibliographic information retrieval is summarized. Knowledge-based search tactics are then considered in terms of their role in the functioning of a semantically based search system for bibliographic information retrieval, EP-X. This system uses such tactics to actively assist users in defining or refining their topics of interest. It does so by applying these tactics to a knowledge base describing topics in a particular domain and to a database describing the contents of individual documents in terms of these topics. This paper, then, focuses on the two central concepts behind EP-X: semantically based search and knowledge-based search tactics.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2004942105",
    "type": "article"
  },
  {
    "title": "Integrating expert systems with group decision support systems",
    "doi": "https://doi.org/10.1145/103731.103735",
    "publication_date": "1991-01-03",
    "publication_year": 1991,
    "authors": "Milam Aiken; Olivia R. Liu Sheng; Douglas R. Vogel",
    "corresponding_authors": "",
    "abstract": "Expert systems are powerful tools that serve as adjuncts to decision making and have found wide applicability in a wide variety of areas. Integrating expert systems with group decision support systems has the potential to enhance the quality and effeciency of group communication, negotiation, and collaborative work. This paper examines possible synergies between the two technologies and provides a survey of current partially-integrated systems. Finally, a prototype design of a highly-integrated system is described with directions for further research.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2163172858",
    "type": "article"
  },
  {
    "title": "Multidocument summarization",
    "doi": "https://doi.org/10.1145/984321.984323",
    "publication_date": "2004-04-01",
    "publication_year": 2004,
    "authors": "Manuel Jesús Maña López; Manuel de Buenaga Rodríguez; José M. Gómez-Hidalgo",
    "corresponding_authors": "",
    "abstract": "A more and more generalized problem in effective information access is the presence in the same corpus of multiple documents that contain similar information. Generally, users may be interested in locating, for a topic addressed by a group of similar documents, one or several particular aspects. This kind of task, called instance or aspectual retrieval, has been explored in several TREC Interactive Tracks. In this article, we propose in addition to the classification capacity of clustering techniques, the possibility of offering a indicative extract about the contents of several sources by means of multidocument summarization techniques. Two kinds of summaries are provided. The first one covers the similarities of each cluster of documents retrieved. The second one shows the particularities of each document with respect to the common topic in the cluster. The document multitopic structure has been used in order to determine similarities and differences of topics in the cluster of documents. The system is independent of document domain and genre. An evaluation of the proposed system with users proves significant improvements in effectiveness. The results of previous experiments that have compared clustering algorithms are also reported.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W1982633109",
    "type": "article"
  },
  {
    "title": "Partitioned signature files: design issues and performance evaluation",
    "doi": "https://doi.org/10.1145/65935.65937",
    "publication_date": "1989-04-01",
    "publication_year": 1989,
    "authors": "Dik Lun Lee; Chun-Wu Roger Leng",
    "corresponding_authors": "",
    "abstract": "A signature file acts as a filtering mechanism to reduce the amount of text that needs to be searched for a query. Unfortunately, the signature file itself must be exhaustively searched, resulting in degraded performance for a large file size. We propose to use a deterministic algorithm to divide a signature file into partitions, each of which contains signatures with the same “key.” The signature keys in a partition can be extracted and represented as the partition's key. The search can then be confined to the subset of partitions whose keys match the query key. Our main concern here is to study methods for obtaining the keys and their performance in terms of their ability to reduce the search space. Owing to the reduction of search space, partitioning a signature file has a direct benefit in a sequential search (single-processor) environment. In a parallel environment, search can be conducted in parallel effectively by allocating one or more partitions to a processor. Partitioning the signature tile with a deterministic method (as opposed to a random partitioning scheme) provides intraquery parallelism as well as interquery parallelism. In this paper, we outline the criteria for evaluating partitioning schemes. Three algorithms are described and studied. An analytical study of the performance of the algorithms is provided and the results are verified with simulation.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W2063567735",
    "type": "article"
  },
  {
    "title": "BAROQUE: a browser for relational databases",
    "doi": "https://doi.org/10.1145/6168.6172",
    "publication_date": "1986-04-01",
    "publication_year": 1986,
    "authors": "Amihai Motro",
    "corresponding_authors": "Amihai Motro",
    "abstract": "The standard, most efficient method to retrieve information from databases can be described as systematic retrieval: The needs of the user are described in a formal query, and the database management system retrieves the data promptly. There are several situations, however, in which systematic retrieval is difficult or even impossible. In such situations exploratory search (browsing) is a helpful alternative. This paper describes a new user interface, called BAROQUE, that implements exploratory searches in relational databases. BAROQUE requires few formal skills from its users. It does not assume knowledge of the principles of the relational data model or familiarity with the organization of the particular database being accessed. It is especially helpful when retrieval targets are vague or cannot be specified satisfactorily. BAROQUE establishes a view of the relational database that resembles a semantic network, and provides several intuitive functions for scanning it. The network integrates both schema and data, and supports access by value. BAROQUE can be implemented on top of any basic relational database management system but can be modified to take advantage of additional capabilities and enhancements often present in relational systems.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W2143906105",
    "type": "article"
  },
  {
    "title": "Integrating an object server with other worlds",
    "doi": "https://doi.org/10.1145/22890.23000",
    "publication_date": "1987-01-01",
    "publication_year": 1987,
    "authors": "Alan Purdy; Bruce Schuchardt; David Maier",
    "corresponding_authors": "",
    "abstract": "Object-oriented database servers are beginning to appear on the commercial market in response to a demand by application developers for increased modeling power in database systems. Before these new servers can enhance the productivity of application designers, systems designers must provide simple interfaces to them from both procedural and object-oriented languages. This paper first describes a successful interface between an object server and two procedural languages (C and Pascal). Because C and Pascal do not support the object-oriented paradigm application, designers using these languages must deal with database objects in less than natural ways. Fortunately, workstations supporting object-oriented languages have the potential for interacting with database objects in a much more integrated manner. To integrate these object-oriented workstations with an object server, we provide a design framework based on the notion of workstation agent objects representing principal objects in the database. We distinguish two types of agents: proxies , which forward most messages to the principal objects, and deputies , which can cache state for their principal and act with more autonomy. The interaction of cache, transaction, and message management strategies makes the implementation of deputies a nontrivial problem. The agent metaphor is being used currently to integrate an object server with a Smalltalk-8O™ workstation.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W2071282627",
    "type": "article"
  },
  {
    "title": "Storing text retrieval systems on CD-ROM: compression and encryption considerations",
    "doi": "https://doi.org/10.1145/65943.65946",
    "publication_date": "1989-07-01",
    "publication_year": 1989,
    "authors": "Shmuel T. Klein; Abraham Bookstein; Scott Deerwester",
    "corresponding_authors": "",
    "abstract": "The emergence of the CD-ROM as a storage medium for full-text databases raises the question of the maximum size database that can be contained by this medium. As an example, the problem of storing the Trésor de la Langue Française on a CD-ROM is examined in this paper. The text alone of this database is 700 megabytes long, more than a CD-ROM can hold. In addition, the dictionary and concordance needed to access these data must be stored. A further constraint is that some of the material is copyrighted, and it is desirable that such material be difficult to decode except through software provided by the system. Pertinent approaches to compression of the various files are reviewed, and the compression of the text is related to the problem of data encryption: Specifically, it is shown that, under simple models of text generation, Huffman encoding produces a bit-string indistinguishable from a representation of coin flips.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W1996465407",
    "type": "article"
  },
  {
    "title": "Towards a belief-revision-based adaptive and context-sensitive information retrieval system",
    "doi": "https://doi.org/10.1145/1344411.1344414",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Raymond Y.K. Lau; Peter Bruza; Dawei Song",
    "corresponding_authors": "",
    "abstract": "In an adaptive information retrieval (IR) setting, the information seekers' beliefs about which terms are relevant or nonrelevant will naturally fluctuate. This article investigates how the theory of belief revision can be used to model adaptive IR. More specifically, belief revision logic provides a rich representation scheme to formalize retrieval contexts so as to disambiguate vague user queries. In addition, belief revision theory underpins the development of an effective mechanism to revise user profiles in accordance with information seekers' changing information needs. It is argued that information retrieval contexts can be extracted by means of the information-flow text mining method so as to realize a highly autonomous adaptive IR system. The extra bonus of a belief-based IR model is that its retrieval behavior is more predictable and explanatory. Our initial experiments show that the belief-based adaptive IR system is as effective as a classical adaptive IR system. To our best knowledge, this is the first successful implementation and evaluation of a logic-based adaptive IR model which can efficiently process large IR collections.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2084259014",
    "type": "article"
  },
  {
    "title": "SEAVE: a mechanism for verifying user presuppositions in query systems",
    "doi": "https://doi.org/10.1145/9760.9762",
    "publication_date": "1986-12-01",
    "publication_year": 1986,
    "authors": "Amihai Motro",
    "corresponding_authors": "Amihai Motro",
    "abstract": "Every information system incorporates a database component, and a frequent activity of users of information systems is to present it with queries. These queries reflect the presuppositions of their authors about the system and the information it contains. With most query processors, queries that are based on erroneous presuppositions often result in null answers. These fake nulls are misleading, since they do not point out the user's erroneous presuppositions (and can even be interpreted as their affirmation). This article describes the SEAVE mechanism for extracting presuppositions from queries and verifying their correctness. The verification is done against three repositories of information: the actual data, their integrity constraints, and their completeness assertions. Consequently, queries that reflect erroneous presuppositions are answered with informative messages instead of null answers, and user-system communication is thus improved (an aspect that is particularly important in systems that often are accessed by naive users). First, the principles of SEAVE are described abstractly. Then, specific algorithms for implementing it with relational databases are presented, including a new method for storing knowledge and an efficient algorithm for processing queries against the knowledge.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2161561171",
    "type": "article"
  },
  {
    "title": "Integrating diverse knowledge sources in text recognition",
    "doi": "https://doi.org/10.1145/357423.357428",
    "publication_date": "1983-01-01",
    "publication_year": 1983,
    "authors": "Sargur N. Srihari; Jonathan J. Hull; Ramesh Choudhari",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Integrating diverse knowledge sources in text recognition Authors: Sargur N. Srihari Department of Computer Science, State University of New York at Buffalo, Amherst, NY Department of Computer Science, State University of New York at Buffalo, Amherst, NYView Profile , Jonathan J. Hull Department of Computer Science, State University of New York at Buffalo, Amherst, NY Department of Computer Science, State University of New York at Buffalo, Amherst, NYView Profile , Ramesh Choudhari Department of Computer Science, State University of New York at Buffalo, Amherst, NY Department of Computer Science, State University of New York at Buffalo, Amherst, NYView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 1Jan. 1983 pp 68–87https://doi.org/10.1145/357423.357428Online:01 January 1983Publication History 45citation685DownloadsMetricsTotal Citations45Total Downloads685Last 12 Months15Last 6 weeks3 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W1997204547",
    "type": "article"
  },
  {
    "title": "A data modeling approach for office information systems",
    "doi": "https://doi.org/10.1145/357442.357444",
    "publication_date": "1983-10-01",
    "publication_year": 1983,
    "authors": "Simon Gibbs; D. Tsichritzis",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on A data modeling approach for office information systems Authors: Simon Gibbs Computer Systems Research Group, University of Toronto, Toronto, Ont., Canada M5S 1A4 Computer Systems Research Group, University of Toronto, Toronto, Ont., Canada M5S 1A4View Profile , Dionysis Tsichritzis Computer Systems Research Group, University of Toronto, Toronto, Ont., Canada M5S 1A4 Computer Systems Research Group, University of Toronto, Toronto, Ont., Canada M5S 1A4View Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 401 October 1983pp 299–319https://doi.org/10.1145/357442.357444Published:01 October 1983Publication History 51citation759DownloadsMetricsTotal Citations51Total Downloads759Last 12 Months30Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2003509178",
    "type": "article"
  },
  {
    "title": "Implementing ranking strategies using text signatures",
    "doi": "https://doi.org/10.1145/42279.45947",
    "publication_date": "1988-01-01",
    "publication_year": 1988,
    "authors": "W. Bruce Croft; Pasquale Savino",
    "corresponding_authors": "",
    "abstract": "Signature files provide an efficient access method for text in documents, but retrieval is usually limited to finding documents that contain a specified Boolean pattern of words. Effective retrieval requires that documents with similar meanings be found through a process of plausible inference. The simplest way of implementing this retrieval process is to rank documents in order of their probability of relevance. In this paper techniques are described for implementing probabilistic ranking strategies with sequential and bit-sliced signature tiles and the limitations of these implementations with regard to their effectiveness are pointed out. A detailed comparison is made between signature-based ranking techniques and ranking using term-based document representatives and inverted files. The comparison shows that term-based representations are at least competitive (in terms of efficiency) with signature files and, in some situations, superior.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2004100431",
    "type": "article"
  },
  {
    "title": "combinFormation",
    "doi": "https://doi.org/10.1145/1416950.1416955",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Andruid Kerne; Eunyee Koh; Steven M. Smith; Andrew M. Webb; Blake Dworaczyk",
    "corresponding_authors": "",
    "abstract": "combinFormation is a mixed-initiative creativity support tool for searching, browsing, organizing, and integrating information. Images and text are connected to represent surrogates (enhanced bookmarks), optimizing the use of human cognitive facilities. Composition, an alternative to lists and spatial hypertext, is used to represent a collection of surrogates as a connected whole, using principles from art and design. This facilitates the creative process of information discovery , in which humans develop new ideas while finding and collecting information. To provoke the user to think about the large space of potentially relevant information resources, a generative agent proactively engages in collecting information resources, forming image and text surrogates, and composing them visually. The agent develops the collection and its visual representation over time, enabling the user to see ideas and relationships. To keep the human in control, we develop interactive mechanisms for authoring the composition and directing the agent. In a field study in an interdisciplinary course on The Design Process, over a hundred students alternated using combinFormation and Google+Word to collect prior work on information discovery invention assignments. The students that used combinFormation's mixed-initiative composition of image and text surrogates performed better.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2004793379",
    "type": "article"
  },
  {
    "title": "Creating and exploiting a comparable corpus in cross-language information retrieval",
    "doi": "https://doi.org/10.1145/1198296.1198300",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Tuomas Talvensaari; Jorma Laurikkala; Kalervo Järvelin; Martti Juhola; Heikki Keskustalo",
    "corresponding_authors": "",
    "abstract": "We present a method for creating a comparable text corpus from two document collections in different languages. The collections can be very different in origin. In this study, we build a comparable corpus from articles by a Swedish news agency and a U.S. newspaper. The keys with best resolution power were extracted from the documents of one collection, the source collection, by using the relative average term frequency (RATF) value. The keys were translated into the language of the other collection, the target collection, with a dictionary-based query translation program. The translated queries were run against the target collection and an alignment pair was made if the retrieved documents matched given date and similarity score criteria. The resulting comparable collection was used as a similarity thesaurus to translate queries along with a dictionary-based translator. The combined approaches outperformed translation schemes where dictionary-based translation or corpus translation was used alone.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W1976381247",
    "type": "article"
  },
  {
    "title": "Semantic clustering of XML documents",
    "doi": "https://doi.org/10.1145/1658377.1658380",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "Andrea Tagarelli; Sergio Greco",
    "corresponding_authors": "",
    "abstract": "Dealing with structure and content semantics underlying semistructured documents is challenging for any task of document management and knowledge discovery conceived for such data. In this work we address the novel problem of clustering semantically related XML documents according to their structure and content features. XML features are generated by enriching syntactic with semantic information based on a lexical knowledge base. The backbone of the proposed framework for the semantic clustering of XML documents is a data representation model that exploits the notion of tree tuple to identify semantically cohesive substructures in XML documents and represent them as transactional data. This framework is equipped with two clustering algorithms based on different paradigms, namely centroid-based partitional clustering and frequent-itemset-based hierarchical clustering. An extensive experimental evaluation was conducted on real data sets from various domains, showing the significance of our approach as a solution for the semantic clustering of XML documents.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2011511839",
    "type": "article"
  },
  {
    "title": "Does a one-size recommendation system fit all? the effectiveness of collaborative filtering based recommendation systems across different domains and search modes",
    "doi": "https://doi.org/10.1145/1292591.1292595",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Il Im; Alexander Hars",
    "corresponding_authors": "",
    "abstract": "Collaborative filtering (CF) is a personalization technology that generates recommendations for users based on others' evaluations. CF is used by numerous e-commerce Web sites for providing personalized recommendations. Although much research has focused on refining collaborative filtering algorithms, little is known about the effects of user and domain characteristics on the accuracy of collaborative filtering systems. In this study, the effects of two factors—product domain and users' search mode—on the accuracy of CF are investigated. The effects of those factors are tested using data collected from two experiments in two different product domains, and from two large CF datasets, EachMovie and Book-Crossing. The study shows that the search mode of the users strongly influences the accuracy of the recommendations. CF works better when users look for specific information than when they search for general information. The accuracy drops significantly when data from different modes are mixed. The study also shows that CF is more accurate for knowledge domains than for consumer product domains. The results of this study imply that for more accurate recommendations, collaborative filtering systems should be able to identify and handle users' mode of search, even within the same domain and user group.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2032117234",
    "type": "article"
  },
  {
    "title": "Clustering-based incremental web crawling",
    "doi": "https://doi.org/10.1145/1852102.1852103",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Qingzhao Tan; Prasenjit Mitra",
    "corresponding_authors": "",
    "abstract": "When crawling resources, for example, number of machines, crawl-time, and so on, are limited, so a crawler has to decide an optimal order in which to crawl and recrawl Web pages. Ideally, crawlers should request only those Web pages that have changed since the last crawl; in practice, a crawler may not know whether a Web page has changed before downloading it. In this article, we identify features of Web pages that are correlated to their change frequency. We design a crawling algorithm that clusters Web pages based on features that correlate to their change frequencies obtained by examining past history. The crawler downloads a sample of Web pages from each cluster, and depending upon whether a significant number of these Web pages have changed in the last crawl cycle, it decides whether to recrawl the entire cluster. To evaluate the performance of our incremental crawler, we develop an evaluation framework that measures which crawling policy results in the best search results for the end-user. We run experiments on a real Web data set of about 300,000 distinct URLs distributed among 210 Web sites. The results demonstrate that the clustering-based sampling algorithm effectively clusters the pages with similar change patterns, and our clustering-based crawling algorithm outperforms existing algorithms in that it can improve the quality of the user experience for those who query the search engine.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W1988497390",
    "type": "article"
  },
  {
    "title": "PageRank without hyperlinks",
    "doi": "https://doi.org/10.1145/1852102.1852104",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Oren Kurland; Lillian Lee",
    "corresponding_authors": "",
    "abstract": "The ad hoc retrieval task is to find documents in a corpus that are relevant to a query. Inspired by the PageRank and HITS (hubs and authorities) algorithms for Web search, we propose a structural reranking approach to ad-hoc retrieval that applies to settings with no hyperlink information. We reorder the documents in an initially retrieved set by exploiting implicit asymmetric relationships among them. We consider generation links , which indicate that the language model induced from one document assigns high probability to the text of another. We study a number of reranking criteria based on measures of centrality in the graphs formed by generation links, and show that integrating centrality into standard language-model-based retrieval is quite effective at improving precision at top ranks; the best resultant performance is comparable, and often superior, to that of a state-of-the-art pseudo-feedback-based retrieval approach. In addition, we demonstrate the merits of our language-model-based method for inducing interdocument links by comparing it to previously suggested notions of interdocument similarities (e.g., cosines within the vector-space model).We also show that ourmethods for inducing centrality are substantially more effective than approaches based on document-specific characteristics, several of which are novel to this study.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2092552912",
    "type": "article"
  },
  {
    "title": "Regularized Latent Semantic Indexing",
    "doi": "https://doi.org/10.1145/2414782.2414787",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Quan Wang; Jun Xu; Hang Li; Nick Craswell",
    "corresponding_authors": "",
    "abstract": "Topic modeling provides a powerful way to analyze the content of a collection of documents. It has become a popular tool in many research areas, such as text mining, information retrieval, natural language processing, and other related fields. In real-world applications, however, the usefulness of topic modeling is limited due to scalability issues. Scaling to larger document collections via parallelization is an active area of research, but most solutions require drastic steps, such as vastly reducing input vocabulary. In this article we introduce Regularized Latent Semantic Indexing (RLSI)---including a batch version and an online version, referred to as batch RLSI and online RLSI, respectively---to scale up topic modeling. Batch RLSI and online RLSI are as effective as existing topic modeling techniques and can scale to larger datasets without reducing input vocabulary. Moreover, online RLSI can be applied to stream data and can capture the dynamic evolution of topics. Both versions of RLSI formalize topic modeling as a problem of minimizing a quadratic loss function regularized by ℓ1 and/or ℓ2 norm. This formulation allows the learning process to be decomposed into multiple suboptimization problems which can be optimized in parallel, for example, via MapReduce. We particularly propose adopting ℓ1 norm on topics and ℓ2 norm on document representations to create a model with compact and readable topics and which is useful for retrieval. In learning, batch RLSI processes all the documents in the collection as a whole, while online RLSI processes the documents in the collection one by one. We also prove the convergence of the learning of online RLSI. Relevance ranking experiments on three TREC datasets show that batch RLSI and online RLSI perform better than LSI, PLSI, LDA, and NMF, and the improvements are sometimes statistically significant. Experiments on a Web dataset containing about 1.6 million documents and 7 million terms, demonstrate a similar boost in performance.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2169681319",
    "type": "article"
  },
  {
    "title": "A General SIMD-Based Approach to Accelerating Compression Algorithms",
    "doi": "https://doi.org/10.1145/2735629",
    "publication_date": "2015-03-23",
    "publication_year": 2015,
    "authors": "Wayne Xin Zhao; Xudong Zhang; Daniel Lemire; Dongdong Shan; Jian‐Yun Nie; Hongfei Yan; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Compression algorithms are important for data oriented tasks, especially in the era of Big Data. Modern processors equipped with powerful SIMD instruction sets, provide us an opportunity for achieving better compression performance. Previous research has shown that SIMD-based optimizations can multiply decoding speeds. Following these pioneering studies, we propose a general approach to accelerate compression algorithms. By instantiating the approach, we have developed several novel integer compression algorithms, called Group-Simple, Group-Scheme, Group-AFOR, and Group-PFD, and implemented their corresponding vectorized versions. We evaluate the proposed algorithms on two public TREC datasets, a Wikipedia dataset and a Twitter dataset. With competitive compression ratios and encoding speeds, our SIMD-based algorithms outperform state-of-the-art non-vectorized algorithms with respect to decoding speeds.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W1999003664",
    "type": "article"
  },
  {
    "title": "Sentimental Spidering",
    "doi": "https://doi.org/10.1145/2382438.2382443",
    "publication_date": "2012-11-01",
    "publication_year": 2012,
    "authors": "Tianjun Fu; Ahmed Abbasi; Daniel Zeng; Hsinchun Chen",
    "corresponding_authors": "",
    "abstract": "Despite the increased prevalence of sentiment-related information on the Web, there has been limited work on focused crawlers capable of effectively collecting not only topic-relevant but also sentiment-relevant content. In this article, we propose a novel focused crawler that incorporates topic and sentiment information as well as a graph-based tunneling mechanism for enhanced collection of opinion-rich Web content regarding a particular topic. The graph-based sentiment (GBS) crawler uses a text classifier that employs both topic and sentiment categorization modules to assess the relevance of candidate pages. This information is also used to label nodes in web graphs that are employed by the tunneling mechanism to improve collection recall. Experimental results on two test beds revealed that GBS was able to provide better precision and recall than seven comparison crawlers. Moreover, GBS was able to collect a large proportion of the relevant content after traversing far fewer pages than comparison methods. GBS outperformed comparison methods on various categories of Web pages in the test beds, including collection of blogs, Web forums, and social networking Web site content. Further analysis revealed that both the sentiment classification module and graph-based tunneling mechanism played an integral role in the overall effectiveness of the GBS crawler.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2092073019",
    "type": "article"
  },
  {
    "title": "Local Representative-Based Matrix Factorization for Cold-Start Recommendation",
    "doi": "https://doi.org/10.1145/3108148",
    "publication_date": "2017-08-29",
    "publication_year": 2017,
    "authors": "Lei Shi; Wayne Xin Zhao; Yi-Dong Shen",
    "corresponding_authors": "",
    "abstract": "Cold-start recommendation is one of the most challenging problems in recommender systems. An important approach to cold-start recommendation is to conduct an interview for new users, called the interview-based approach . Among the interview-based methods, Representative-Based Matrix Factorization (RBMF) [24] provides an effective solution with appealing merits: it represents users over selected representative items, which makes the recommendations highly intuitive and interpretable. However, RBMF only utilizes a global set of representative items to model all users. Such a representation is somehow too strict and may not be flexible enough to capture varying users’ interests. To address this problem, we propose a novel interview-based model to dynamically create meaningful user groups using decision trees and then select local representative items for different groups. A two-round interview is performed for a new user. In the first round, l 1 global questions are issued for group division, while in the second round, l 2 local-group-specific questions are given to derive local representation. We collect the feedback on the (l 1 +l 2 ) items to learn the user representations. By putting these steps together, we develop a joint optimization model, named local representative-based matrix factorization , for new user recommendations. Extensive experiments on three public datasets have demonstrated the effectiveness of the proposed model compared with several competitive baselines.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2752904570",
    "type": "article"
  },
  {
    "title": "Suffix Array Construction in External Memory Using D-Critical Substrings",
    "doi": "https://doi.org/10.1145/2518175",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Ge Nong; Wai Hong Chan; Sen Zhang; Xiao Feng Guan",
    "corresponding_authors": "",
    "abstract": "We present a new suffix array construction algorithm that aims to build, in external memory, the suffix array for an input string of length n measured in the magnitude of tens of Giga characters over a constant or integer alphabet. The core of this algorithm is adapted from the framework of the original internal memory SA-DS algorithm that samples fixed-size d-critical substrings. This new external-memory algorithm, called EM-SA-DS, uses novel cache data structures to construct a suffix array in a sequential scanning manner with good data spatial locality: data is read from or written to disk sequentially. On the assumed external-memory model with RAM capacity Ω (( nB ) 0.5 ), disk capacity O ( n ), and size of each I/O block B , all measured in log n -bit words, the I/O complexity of EM-SA-DS is O ( n / B ). This work provides a general cache-based solution that could be further exploited to develop external-memory solutions for other suffix-array-related problems, for example, computing the longest-common-prefix array, using a modern personal computer with a typical memory configuration of 4GB RAM and a single disk.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2150957098",
    "type": "article"
  },
  {
    "title": "Transfer joint embedding for cross-domain named entity recognition",
    "doi": "https://doi.org/10.1145/2457465.2457467",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Sinno Jialin Pan; Zhiqiang Toh; Jian Su",
    "corresponding_authors": "",
    "abstract": "Named Entity Recognition (NER) is a fundamental task in information extraction from unstructured text. Most previous machine-learning-based NER systems are domain-specific, which implies that they may only perform well on some specific domains (e.g., Newswire ) but tend to adapt poorly to other related but different domains (e.g., Weblog ). Recently, transfer learning techniques have been proposed to NER. However, most transfer learning approaches to NER are developed for binary classification, while NER is a multiclass classification problem in nature. Therefore, one has to first reduce the NER task to multiple binary classification tasks and solve them independently. In this article, we propose a new transfer learning method, named Transfer Joint Embedding (TJE), for cross-domain multiclass classification, which can fully exploit the relationships between classes (labels), and reduce domain difference in data distributions for transfer learning. More specifically, we aim to embed both labels (outputs) and high-dimensional features (inputs) from different domains (e.g., a source domain and a target domain) into a unified low-dimensional latent space, where 1) each label is represented by a prototype and the intrinsic relationships between labels can be measured by Euclidean distance; 2) the distance in data distributions between the source and target domains can be reduced; 3) the source domain labeled data are closer to their corresponding label-prototypes than others. After the latent space is learned, classification on the target domain data can be done with the simple nearest neighbor rule in the latent space. Furthermore, in order to scale up TJE, we propose an efficient algorithm based on stochastic gradient descent (SGD). Finally, we apply the proposed TJE method for NER across different domains on the ACE 2005 dataset, which is a benchmark in Natural Language Processing (NLP). Experimental results demonstrate the effectiveness of TJE and show that TJE can outperform state-of-the-art transfer learning approaches to NER.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2088212442",
    "type": "article"
  },
  {
    "title": "Diversifying Query Auto-Completion",
    "doi": "https://doi.org/10.1145/2910579",
    "publication_date": "2016-06-09",
    "publication_year": 2016,
    "authors": "Fei Cai; Ridho Reinanda; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Query auto-completion assists web search users in formulating queries with a few keystrokes, helping them to avoid spelling mistakes and to produce clear query expressions, and so on. Previous work on query auto-completion mainly centers around returning a list of completions to users, aiming to push queries that are most likely intended by the user to the top positions but ignoring the redundancy among the query candidates in the list. Thus, semantically related queries matching the input prefix are often returned together. This may push valuable suggestions out of the list, given that only a limited number of candidates can be shown to the user, which may result in a less than optimal search experience. In this article, we consider the task of diversifying query auto-completion, which aims to return the correct query completions early in a ranked list of candidate completions and at the same time reduce the redundancy among query auto-completion candidates. We develop a greedy query selection approach that predicts query completions based on the current search popularity of candidate completions and on the aspects of previous queries in the same search session. The popularity of completion candidates at query time can be directly aggregated from query logs. However, query aspects are implicitly expressed by previous clicked documents in the search context. To determine the query aspect, we categorize clicked documents of a query using a hierarchy based on the open directory project. Bayesian probabilistic matrix factorization is applied to derive the distribution of queries over all aspects. We quantify the improvement of our greedy query selection model against a state-of-the-art baseline using two large-scale, real-world query logs and show that it beats the baseline in terms of well-known metrics used in query auto-completion and diversification. In addition, we conduct a side-by-side experiment to verify the effectiveness of our proposal.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2410226802",
    "type": "article"
  },
  {
    "title": "AWARE",
    "doi": "https://doi.org/10.1145/3110217",
    "publication_date": "2017-08-29",
    "publication_year": 2017,
    "authors": "Marco Ferrante; Nicola Ferro; Maria Maistro",
    "corresponding_authors": "",
    "abstract": "We propose the Assessor-driven Weighted Averages for Retrieval Evaluation (AWARE) probabilistic framework, a novel methodology for dealing with multiple crowd assessors that may be contradictory and/or noisy. By modeling relevance judgements and crowd assessors as sources of uncertainty, AWARE takes the expectation of a generic performance measure, like Average Precision, composed with these random variables. In this way, it approaches the problem of aggregating different crowd assessors from a new perspective, that is, directly combining the performance measures computed on the ground truth generated by the crowd assessors instead of adopting some classification technique to merge the labels produced by them. We propose several unsupervised estimators that instantiate the AWARE framework and we compare them with state-of-the-art approaches, that is,Majoriity Vote and Expectation Maximization, on TREC collections. We found that AWARE approaches improve in terms of their capability of correctly ranking systems and predicting their actual performance scores.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2752644629",
    "type": "article"
  },
  {
    "title": "Latent Discriminative Models for Social Emotion Detection with Emotional Dependency",
    "doi": "https://doi.org/10.1145/2749459",
    "publication_date": "2015-07-28",
    "publication_year": 2015,
    "authors": "Xiaojun Quan; Qifan Wang; Ying Zhang; Luo Si; Wenyin Liu",
    "corresponding_authors": "",
    "abstract": "Sentiment analysis of such opinionated online texts as reviews and comments has received increasingly close attention, yet most of the work is intended to deal with the detection of authors’ emotion. In contrast, this article presents our study of the social emotion detection problem, the objective of which is to identify the evoked emotions of readers by online documents such as news articles. A novel Latent Discriminative Model (LDM) is proposed for this task. LDM works by introducing intermediate hidden variables to model the latent structure of input text corpora. To achieve this, it defines a joint distribution over emotions and latent variables, conditioned on the observed text documents. Moreover, we assume that social emotions are not independent but correlated with one another, and the dependency of them is capable of providing additional guidance to LDM in the training process. The inclusion of this emotional dependency into LDM gives rise to a new Emotional Dependency-based LDM (eLDM). We evaluate the proposed models through a series of empirical evaluations on two real-world corpora of news articles. Experimental results verify the effectiveness of LDM and eLDM in social emotion detection.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2092415370",
    "type": "article"
  },
  {
    "title": "Geoparsing and Geosemantics for Social Media",
    "doi": "https://doi.org/10.1145/2842604",
    "publication_date": "2016-04-11",
    "publication_year": 2016,
    "authors": "Stuart E. Middleton; Vadims Krivcovs",
    "corresponding_authors": "",
    "abstract": "In recent years, there has been a growing trend to use publicly available social media sources within the field of journalism. Breaking news has tight reporting deadlines, measured in minutes not days, but content must still be checked and rumors verified. As such, journalists are looking at automated content analysis to prefilter large volumes of social media content prior to manual verification. This article describes a real-time social media analytics framework for journalists. We extend our previously published geoparsing approach to improve its scalability and efficiency. We develop and evaluate a novel approach to geosemantic feature extraction, classifying evidence in terms of situatedness, timeliness, confirmation, and validity. Our approach works for new unseen news topics. We report results from four experiments using five Twitter datasets crawled during different English-language news events. One of our datasets is the standard TREC 2012 microblog corpus. Our classification results are promising, with F1 scores varying by class from 0.64 to 0.92 for unseen event types. We lastly report results from two case studies during real-world news stories, showcasing different ways our system can assist journalists filter and cross-check content as they examine the trust and veracity of content and sources.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2316346277",
    "type": "article"
  },
  {
    "title": "TISoN",
    "doi": "https://doi.org/10.1145/2858791",
    "publication_date": "2016-04-26",
    "publication_year": 2016,
    "authors": "Sana Hamdi; Alda Lopes Gançarski; Amel Bouzeghoub; Sadok Ben Yahia",
    "corresponding_authors": "",
    "abstract": "Trust systems represent a significant trend in decision support for social networks’ service provision. The basic idea is to allow users to rate each other even without being direct neighbours. In this case, the purpose is to derive a trust score for a given user, which could be of help to decide whether to trust other users or not. In this article, we investigate the properties of trust propagation within social networks, based on the notion of transitivity , and we introduce the TISoN model to generate and evaluate T rust I nference within online So cial N etworks. To do so, ( i ) we develop a novel TPS algorithm for T rust P ath S earching where we define neighbours’ priority based on their direct trust degrees, and then select trusted paths while controlling the path length; and, ( ii ) we develop different TIM algorithms for T rust I nference M easuring and build a trust network. In addition, we analyse existing algorithms and we demonstrate that our proposed model better computes transitive trust values than do the existing models. We conduct extensive experiments on a real online social network dataset, Advogato. Experimental results show that our work is scalable and generates better results than do the pioneering approaches of the literature.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2344221985",
    "type": "article"
  },
  {
    "title": "Understanding and Supporting Cross-Device Web Search for Exploratory Tasks with Mobile Touch Interactions",
    "doi": "https://doi.org/10.1145/2738036",
    "publication_date": "2015-04-23",
    "publication_year": 2015,
    "authors": "Shuguang Han; Zhen Yue; Daqing He",
    "corresponding_authors": "",
    "abstract": "Mobile devices enable people to look for information at the moment when their information needs are triggered. While experiencing complex information needs that require multiple search sessions, users may utilize desktop computers to fulfill information needs started on mobile devices. Under the context of mobile-to-desktop web search, this article analyzes users’ behavioral patterns and compares them to the patterns in desktop-to-desktop web search. Then, we examine several approaches of using Mobile Touch Interactions (MTIs) to infer relevant content so that such content can be used for supporting subsequent search queries on desktop computers. The experimental data used in this article was collected through a user study involving 24 participants and six properly designed cross-device web search tasks. Our experimental results show that (1) users’ mobile-to-desktop search behaviors do significantly differ from desktop-to-desktop search behaviors in terms of information exploration, sense-making and repeated behaviors. (2) MTIs can be employed to predict the relevance of click-through documents, but applying document-level relevant content based on the predicted relevance does not improve search performance. (3) MTIs can also be used to identify the relevant text chunks at a fine-grained subdocument level. Such relevant information can achieve better search performance than the document-level relevant content. In addition, such subdocument relevant information can be combined with document-level relevance to further improve the search performance. However, the effectiveness of these methods relies on the sufficiency of click-through documents. (4) MTIs can also be obtained from the Search Engine Results Pages (SERPs). The subdocument feedbacks inferred from this set of MTIs even outperform the MTI-based subdocument feedback from the click-through documents.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2064971756",
    "type": "article"
  },
  {
    "title": "Joint Modeling of Participant Influence and Latent Topics for Recommendation in Event-based Social Networks",
    "doi": "https://doi.org/10.1145/3183712",
    "publication_date": "2018-03-13",
    "publication_year": 2018,
    "authors": "Yi Liao; Wai Lam; Lidong Bing; Xin Shen",
    "corresponding_authors": "",
    "abstract": "Event-based social networks (EBSNs) are becoming popular in recent years. Users can publish a planned event on an EBSN website, calling for other users to participate in the event. When a user is making a decision on whether to participate in an event in EBSNs, one aspect for consideration is existing participants defined as users who have agreed to join this event. Existing participants of the event may affect the decision of the user, to which we refer as participant influence. However, participant influence is not well studied by previous works. In this article, we propose an event recommendation model that considers participant influence, and exploits the influence of existing participants on the decisions of new participants based on Poisson factorization. The effect of participant influence is associated with the target event, the host group of the event, and the location of the event. Furthermore, our proposed model can extract latent event topics from event text descriptions, and characterize events, groups, and locations by distributions of event topics. Associations between latent event topics and participant influence are exploited for improving event recommendation. Besides making event recommendation, the proposed model is able to reveal the semantic properties of the participant influence between two users semantically. We have conducted extensive experiments on some datasets extracted from a real-world EBSN. Our proposed model achieves superior event recommendation performance over several state-of-the-art models. The results demonstrate that the consideration of participant influence can improve event recommendation.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2793484810",
    "type": "article"
  },
  {
    "title": "Unsupervised Learning of Parsimonious General-Purpose Embeddings for User and Location Modeling",
    "doi": "https://doi.org/10.1145/3182165",
    "publication_date": "2018-03-13",
    "publication_year": 2018,
    "authors": "Jing Yang; Carsten Eickhoff",
    "corresponding_authors": "",
    "abstract": "Many social network applications depend on robust representations of spatio-temporal data. In this work, we present an embedding model based on feed-forward neural networks which transforms social media check-ins into dense feature vectors encoding geographic, temporal, and functional aspects for modeling places, neighborhoods, and users. We employ the embedding model in a variety of applications including location recommendation , urban functional zone study , and crime prediction . For location recommendation , we propose a Spatio-Temporal Embedding Similarity algorithm (STES) based on the embedding model. In a range of experiments on real life data collected from Foursquare, we demonstrate our model’s effectiveness at characterizing places and people and its applicability in aforementioned problem domains. Finally, we select eight major cities around the globe and verify the robustness and generality of our model by porting pre-trained models from one city to another, thereby alleviating the need for costly local training.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2786997513",
    "type": "article"
  },
  {
    "title": "Learning to Adaptively Rank Document Retrieval System Configurations",
    "doi": "https://doi.org/10.1145/3231937",
    "publication_date": "2018-10-30",
    "publication_year": 2018,
    "authors": "Romain Deveaud; Josiane Mothe; Zia Ullah; Jian‐Yun Nie",
    "corresponding_authors": "",
    "abstract": "Modern Information Retrieval (IR) systems have become more and more complex, involving a large number of parameters. For example, a system may choose from a set of possible retrieval models (BM25, language model, etc.), or various query expansion parameters, whose values greatly influence the overall retrieval effectiveness. Traditionally, these parameters are set at a system level based on training queries, and the same parameters are then used for different queries. We observe that it may not be easy to set all these parameters separately, since they can be dependent. In addition, a global setting for all queries may not best fit all individual queries with different characteristics. The parameters should be set according to these characteristics. In this article, we propose a novel approach to tackle this problem by dealing with the entire system configurations (i.e., a set of parameters representing an IR system behaviour) instead of selecting a single parameter at a time. The selection of the best configuration is cast as a problem of ranking different possible configurations given a query. We apply learning-to-rank approaches for this task. We exploit both the query features and the system configuration features in the learning-to-rank method so that the selection of configuration is query dependent. The experiments we conducted on four TREC ad hoc collections show that this approach can significantly outperform the traditional method to tune system configuration globally (i.e., grid search) and leads to higher effectiveness than the top performing systems of the TREC tracks. We also perform an ablation analysis on the impact of different features on the model learning capability and show that query expansion features are among the most important for adaptive systems.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2898640137",
    "type": "article"
  },
  {
    "title": "Seed-Guided Topic Model for Document Filtering and Classification",
    "doi": "https://doi.org/10.1145/3238250",
    "publication_date": "2018-12-06",
    "publication_year": 2018,
    "authors": "Chenliang Li; Shiqian Chen; Jian Xing; Aixin Sun; Zongyang Ma",
    "corresponding_authors": "",
    "abstract": "One important necessity is to filter out the irrelevant information and organize the relevant information into meaningful categories. However, developing text classifiers often requires a large number of labeled documents as training examples. Manually labeling documents is costly and time-consuming. More importantly, it becomes unrealistic to know all the categories covered by the documents beforehand. Recently, a few methods have been proposed to label documents by using a small set of relevant keywords for each category, known as dataless text classification . In this article, we propose a seed-guided topic model for the dataless text filtering and classification (named DFC). Given a collection of unlabeled documents, and for each specified category a small set of seed words that are relevant to the semantic meaning of the category, DFC filters out the irrelevant documents and classifies the relevant documents into the corresponding categories through topic influence. DFC models two kinds of topics: category-topics and general-topics . Also, there are two kinds of category-topics: relevant-topics and irrelevant-topics. Each relevant-topic is associated with one specific category, representing its semantic meaning. The irrelevant-topics represent the semantics of the unknown categories covered by the document collection. And the general-topics capture the global semantic information. DFC assumes that each document is associated with a single category-topic and a mixture of general-topics. A novelty of the model is that DFC learns the topics by exploiting the explicit word co-occurrence patterns between the seed words and regular words (i.e., non-seed words) in the document collection. A document is then filtered, or classified, based on its posterior category-topic assignment. Experiments on two widely used datasets show that DFC consistently outperforms the state-of-the-art dataless text classifiers for both classification with filtering and classification without filtering. In many tasks, DFC can also achieve comparable or even better classification accuracy than the state-of-the-art supervised learning solutions. Our experimental results further show that DFC is insensitive to the tuning parameters. Moreover, we conduct a thorough study about the impact of seed words for existing dataless text classification techniques. The results reveal that it is not using more seed words but the document coverage of the seed words for the corresponding category that affects the dataless classification performance.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2904614016",
    "type": "article"
  },
  {
    "title": "Toward Dynamic User Intention",
    "doi": "https://doi.org/10.1145/3432244",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Chenyang Wang; Weizhi Ma; Min Zhang; Chong Chen; Yiqun Liu; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "User intention is an important factor to be considered for recommender systems, which always changes dynamically in different contexts. Recent studies (represented by sequential recommendation) begin to focus on predicting what users want beyond what users like, which are better at capturing user intention and have attracted a surge of interest. However, user intention modeling is non-trivial, because it is generally influenced by various factors, among which item relations and their temporal evolutionary effects are of great importance. For example, consumption of a cellphone will have varying impacts on the demands for its relational items: For complements, the demands are likely to be promoted in the short term; while for substitutes, the long-term effect may take advantage, because users do not need another cellphone immediately. Moreover, the temporal evolutions of different relational effects vary across different domains, which makes it challenging to adaptively take them into consideration. As a result, most existing studies only loosely incorporate item relations by encoding their semantics into embeddings, neglecting fine-grained time-aware effects. In this work, we propose Knowledge-aware Dynamic Attention (KDA) to take both relational effects and their temporal evolutions into consideration. Specifically, to model dynamic impacts of historical relational interactions on user intention, we aggregate the history sequence into relation-specific embeddings, where the attention weight consists of two parts. First, we measure the relational intensity between historical items and the target item to model the absolute degree of influence in terms of each relation. Second, to model how the relational effects drift with time, we innovatively introduce Fourier transform with learnable frequency-domain embeddings to estimate temporal decay functions of different relations adaptively. Subsequently, the self-attention mechanism is leveraged to derive the final representation of the whole history sequence, which reflects the dynamic user intention and will be applied to generate the recommendation list. Extensive experiments in three real-world datasets indicate the proposed KDA model significantly outperforms the state-of-the-art methods on the Top- K recommendation task. Moreover, the proposed Fourier-based method opens up a new avenue to adaptively integrate temporal dynamics into general neural models.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W3114085555",
    "type": "article"
  },
  {
    "title": "Memory-Augmented Dialogue Management for Task-Oriented Dialogue Systems",
    "doi": "https://doi.org/10.1145/3317612",
    "publication_date": "2019-07-08",
    "publication_year": 2019,
    "authors": "Zheng Zhang; Minlie Huang; Zhongzhou Zhao; Feng Ji; Haiqing Chen; Xiaoyan Zhu",
    "corresponding_authors": "",
    "abstract": "Dialogue management (DM) is responsible for predicting the next action of a dialogue system according to the current dialogue state and thus plays a central role in task-oriented dialogue systems. Since DM requires having access not only to local utterances but also to the global semantics of the entire dialogue session, modeling the long-range history information is a critical issue. To this end, we propose MAD, a novel memory-augmented dialogue management model that employs a memory controller and two additional memory structures (i.e., a slot-value memory and an external memory). The slot-value memory tracks the dialogue state by memorizing and updating the values of semantic slots (i.e., cuisine, price, and location), and the external memory augments the representation of hidden states of traditional recurrent neural networks by storing more context information. To update the dialogue state efficiently, we also propose slot-level attention on user utterances to extract specific semantic information for each slot. Experiments show that our model can obtain state-of-the-art performance and outperforms existing baselines.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2963289713",
    "type": "article"
  },
  {
    "title": "Bots in Social and Interaction Networks",
    "doi": "https://doi.org/10.1145/3419369",
    "publication_date": "2020-10-17",
    "publication_year": 2020,
    "authors": "Marcelo Mendoza; Maurizio Tesconi; Stefano Cresci",
    "corresponding_authors": "",
    "abstract": "The rise of bots and their influence on social networks is a hot topic that has aroused the interest of many researchers. Despite the efforts to detect social bots, it is still difficult to distinguish them from legitimate users. Here, we propose a simple yet effective semi-supervised method that allows distinguishing between bots and legitimate users with high accuracy. The method learns a joint representation of social connections and interactions between users by leveraging graph-based representation learning. Then, on the proximity graph derived from user embeddings, a sample of bots is used as seeds for a label propagation algorithm. We demonstrate that when the label propagation is done according to pairwise account proximity, our method achieves F 1 = 0.93, whereas other state-of-the-art techniques achieve F 1 ≤ 0.87. By applying our method to a large dataset of retweets, we uncover the presence of different clusters of bots in the network of Twitter interactions. Interestingly, such clusters feature different degrees of integration with legitimate users. By analyzing the interactions produced by the different clusters of bots, our results suggest that a significant group of users was systematically exposed to content produced by bots and to interactions with bots, indicating the presence of a selective exposure phenomenon.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W3103365091",
    "type": "article"
  },
  {
    "title": "Towards Question-based High-recall Information Retrieval",
    "doi": "https://doi.org/10.1145/3388640",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Jie Zou; Evangelos Kanoulas",
    "corresponding_authors": "",
    "abstract": "While continuous active learning algorithms have proven effective in finding most of the relevant documents in a collection, the cost for locating the last few remains high for applications such as Technology-assisted Reviews (TAR). To locate these last few but significant documents efficiently, Zou et al. [2018] have proposed a novel interactive algorithm. The algorithm is based on constructing questions about the presence or absence of entities in the missing relevant documents. The hypothesis made is that entities play a central role in documents carrying key information and that the users are able to answer questions about the presence or absence of an entity in the missing relevance documents. Based on this, a Sequential Bayesian Search-based approach that selects the optimal sequence of questions to ask was devised. In this work, we extend Zou et al. [2018] by (a) investigating the noise tolerance of the proposed algorithm; (b) proposing an alternative objective function to optimize, which accounts for user “erroneous” answers; (c) proposing a method that sequentially decides the best point to stop asking questions to the user; and (d) conducting a small user study to validate some of the assumptions made by Zou et al. [2018]. Furthermore, all experiments are extended to demonstrate the effectiveness of the proposed algorithms not only in the phase of abstract appraisal (i.e., finding the abstracts of potentially relevant documents in a collection) but also finding the documents to be included in the review (i.e., finding the subset of those relevant abstracts for which the article remains relevant). The experimental results demonstrate that the proposed algorithms can greatly improve performance, requiring reviewing fewer irrelevant documents to find the last relevant ones compared to state-of-the-art methods, even in the case of noisy answers. Further, they show that our algorithm learns to stop asking questions at the right time. Last, we conduct a small user study involving an expert reviewer. The user study validates some of the assumptions made in this work regarding the user’s willingness to answer the system questions and the extent of it, as well as the ability of the user to answer these questions.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W3035600984",
    "type": "article"
  },
  {
    "title": "Knowledge Preserving and Distribution Alignment for Heterogeneous Domain Adaptation",
    "doi": "https://doi.org/10.1145/3469856",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Hanrui Wu; Qingyao Wu; Michael K. Ng",
    "corresponding_authors": "",
    "abstract": "Domain adaptation aims at improving the performance of learning tasks in a target domain by leveraging the knowledge extracted from a source domain. To this end, one can perform knowledge transfer between these two domains. However, this problem becomes extremely challenging when the data of these two domains are characterized by different types of features, i.e., the feature spaces of the source and target domains are different, which is referred to as heterogeneous domain adaptation (HDA). To solve this problem, we propose a novel model called Knowledge Preserving and Distribution Alignment (KPDA), which learns an augmented target space by jointly minimizing information loss and maximizing domain distribution alignment. Specifically, we seek to discover a latent space, where the knowledge is preserved by exploiting the Laplacian graph terms and reconstruction regularizations. Moreover, we adopt the Maximum Mean Discrepancy to align the distributions of the source and target domains in the latent space. Mathematically, KPDA is formulated as a minimization problem with orthogonal constraints, which involves two projection variables. Then, we develop an algorithm based on the Gauss–Seidel iteration scheme and split the problem into two subproblems, which are solved by searching algorithms based on the Barzilai–Borwein (BB) stepsize. Promising results demonstrate the effectiveness of the proposed method.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W3197202805",
    "type": "article"
  },
  {
    "title": "Graph Neural Collaborative Topic Model for Citation Recommendation",
    "doi": "https://doi.org/10.1145/3473973",
    "publication_date": "2021-11-17",
    "publication_year": 2021,
    "authors": "Qianqian Xie; Yutao Zhu; Jimin Huang; Pan Du; Jian‐Yun Nie",
    "corresponding_authors": "",
    "abstract": "Due to the overload of published scientific articles, citation recommendation has long been a critical research problem for automatically recommending the most relevant citations of given articles. Relational topic models (RTMs) have shown promise on citation prediction via joint modeling of document contents and citations. However, existing RTMs can only capture pairwise or direct (first-order) citation relationships among documents. The indirect (high-order) citation links have been explored in graph neural network–based methods, but these methods suffer from the well-known explainability problem. In this article, we propose a model called Graph Neural Collaborative Topic Model that takes advantage of both relational topic models and graph neural networks to capture high-order citation relationships and to have higher explainability due to the latent topic semantic structure. Experiments on three real-world citation datasets show that our model outperforms several competitive baseline methods on citation recommendation. In addition, we show that our approach can learn better topics than the existing approaches. The recommendation results can be well explained by the underlying topics.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W3215214493",
    "type": "article"
  },
  {
    "title": "Dual Gated Graph Attention Networks with Dynamic Iterative Training for Cross-Lingual Entity Alignment",
    "doi": "https://doi.org/10.1145/3471165",
    "publication_date": "2021-11-17",
    "publication_year": 2021,
    "authors": "Zhiwen Xie; Runjie Zhu; Kunsong Zhao; Jin Liu; Guangyou Zhou; Jimmy Xiangji Huang",
    "corresponding_authors": "",
    "abstract": "Cross-lingual entity alignment has attracted considerable attention in recent years. Past studies using conventional approaches to match entities share the common problem of missing important structural information beyond entities in the modeling process. This allows graph neural network models to step in. Most existing graph neural network approaches model individual knowledge graphs (KGs) separately with a small amount of pre-aligned entities served as anchors to connect different KG embedding spaces. However, this characteristic can cause several major problems, including performance restraint due to the insufficiency of available seed alignments and ignorance of pre-aligned links that are useful in contextual information in-between nodes. In this article, we propose DuGa-DIT, a dual gated graph attention network with dynamic iterative training, to address these problems in a unified model. The DuGa-DIT model captures neighborhood and cross-KG alignment features by using intra-KG attention and cross-KG attention layers. With the dynamic iterative process, we can dynamically update the cross-KG attention score matrices, which enables our model to capture more cross-KG information. We conduct extensive experiments on two benchmark datasets and a case study in cross-lingual personalized search. Our experimental results demonstrate that DuGa-DIT outperforms state-of-the-art methods.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W3217040326",
    "type": "article"
  },
  {
    "title": "What and How long: Prediction of Mobile App Engagement",
    "doi": "https://doi.org/10.1145/3464301",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Yuan Tian; Ke Zhou; Dan Pelleg",
    "corresponding_authors": "",
    "abstract": "User engagement is crucial to the long-term success of a mobile app. Several metrics, such as dwell time, have been used for measuring user engagement. However, how to effectively predict user engagement in the context of mobile apps is still an open research question. For example, do the mobile usage contexts (e.g., time of day) in which users access mobile apps impact their dwell time? Answers to such questions could help mobile operating system and publishers to optimize advertising and service placement. In this article, we first conduct an empirical study for assessing how user characteristics, temporal features, and the short/long-term contexts contribute to gains in predicting users’ app dwell time on the population level. The comprehensive analysis is conducted on large app usage logs collected through a mobile advertising company. The dataset covers more than 12K anonymous users and 1.3 million log events. Based on the analysis, we further investigate a novel mobile app engagement prediction problem—can we predict simultaneously what app the user will use next and how long he/she will stay on that app? We propose several strategies for this joint prediction problem and demonstrate that our model can improve the performance significantly when compared with the state-of-the-art baselines. Our work can help mobile system developers in designing a better and more engagement-aware mobile app user experience.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W3196693533",
    "type": "article"
  },
  {
    "title": "Scalable Representation Learning for Dynamic Heterogeneous Information Networks via Metagraphs",
    "doi": "https://doi.org/10.1145/3485189",
    "publication_date": "2022-03-09",
    "publication_year": 2022,
    "authors": "Fang Yang; Xiang Zhao; Peixin Huang; Weidong Xiao; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Content representation is a fundamental task in information retrieval. Representation learning is aimed at capturing features of an information object in a low-dimensional space. Most research on representation learning for heterogeneous information networks (HINs) focuses on static HINs. In practice, however, networks are dynamic and subject to constant change. In this article, we propose a novel and scalable representation learning model, M-DHIN , to explore the evolution of a dynamic HIN. We regard a dynamic HIN as a series of snapshots with different time stamps. We first use a static embedding method to learn the initial embeddings of a dynamic HIN at the first time stamp. We describe the features of the initial HIN via metagraphs, which retains more structural and semantic information than traditional path-oriented static models. We also adopt a complex embedding scheme to better distinguish between symmetric and asymmetric metagraphs. Unlike traditional models that process an entire network at each time stamp, we build a so-called change dataset that only includes nodes involved in a triadic closure or opening process, as well as newly added or deleted nodes. Then, we utilize the above metagraph-based mechanism to train on the change dataset. As a result of this setup, M-DHIN is scalable to large dynamic HINs since it only needs to model the entire HIN once while only the changed parts need to be processed over time. Existing dynamic embedding models only express the existing snapshots and cannot predict the future network structure. To equip M-DHIN with this ability, we introduce an LSTM-based deep autoencoder model that processes the evolution of the graph via an LSTM encoder and outputs the predicted graph. Finally, we evaluate the proposed model, M-DHIN , on real-life datasets and demonstrate that it significantly and consistently outperforms state-of-the-art models.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4221136088",
    "type": "article"
  },
  {
    "title": "Ranking Models for the Temporal Dimension of Text",
    "doi": "https://doi.org/10.1145/3565481",
    "publication_date": "2022-10-04",
    "publication_year": 2022,
    "authors": "Stefano Rizzo; Matteo Brucato; Danilo Montesi",
    "corresponding_authors": "",
    "abstract": "Temporal features of text have been shown to improve clustering and organization of documents, text classification, visualization, and ranking. Temporal ranking models consider the temporal expressions found in text (e.g., “in 2021” or “last year”) as time units, rather than as keywords, to define a temporal relevance and improve ranking. This article introduces a new class of ranking models called Temporal Metric Space Models (TMSM), based on a new domain for representing temporal information found in documents and queries, where each temporal expression is represented as a time interval . Furthermore, we introduce a new frequency-based baseline called Temporal BM25 (TBM25). We evaluate the effectiveness of each proposed metric against a purely textual baseline, as well as several variations of the metrics themselves, where we change the aggregate function, the time granularity and the combination weight. Our extensive experiments on five test collections show statistically significant improvements of TMSM and TBM25 over state-of-the-art temporal ranking models. Combining the temporal similarity scores with the text similarity scores always improves the results, when the combination weight is between 2% and 6% for the temporal scores. This is true also for test collections where only 5% of queries contain explicit temporal expressions.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4301395474",
    "type": "article"
  },
  {
    "title": "User Perception of Recommendation Explanation: Are Your Explanations What Users Need?",
    "doi": "https://doi.org/10.1145/3565480",
    "publication_date": "2022-11-17",
    "publication_year": 2022,
    "authors": "Hongyu Lu; Weizhi Ma; Yifan Wang; Min Zhang; Xiang Wang; Yiqun Liu; Tat‐Seng Chua; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "As recommender systems become increasingly important in daily human decision-making, users are demanding convincing explanations to understand why they get the specific recommendation results. Although a number of explainable recommender systems have recently been proposed, there still lacks an understanding of what users really need in a recommendation explanation. The actual reason behind users’ intention to examine and consume (e.g., click and watch a movie) can be the window to answer this question and is named as self-explanation in this work. In addition, humans usually make recommendations accompanied by explanations, but there remain fewer studies on how humans explain and what we can learn from human-generated explanations. To investigate these questions, we conduct a novel multi-role, multi-session user study in which users interact with multiple types of system-generated explanations as well as human-generated explanations, namely peer-explanation . During the study, users’ intentions, expectations, and experiences are tracked in several phases, including before and after the users are presented with an explanation and after the content is examined. Through comprehensive investigations, three main findings have been made: First, we observe not only the positive but also the negative effects of explanations, and the impact varies across different types of explanations. Moreover, human-generated explanation, peer-explanation , performs better in increasing user intentions and helping users to better construct preferences, which results in better user satisfaction. Second, based on users’ self-explanation , the information accuracy is measured and found to be a major factor associated with user satisfaction. Some other factors, such as unfamiliarity and similarity, are also discovered and summarized. Third, through annotations of the information aspects used in the human-generated self-explanation and peer-explanation , patterns of how humans explain are investigated, including what information and how much information is utilized. In addition, based on the findings, a human-inspired explanation approach is proposed and found to increase user satisfaction, revealing the potential improvement of further incorporating more human patterns in recommendation explanations. These findings have shed light on the deeper understanding of the recommendation explanation and further research on its evaluation and generation. Furthermore, the collected data, including human-generated explanations by both the external peers and the users’ selves, will be released to support future research works on explanation evaluation.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4309618087",
    "type": "article"
  },
  {
    "title": "Adversarial Auto-encoder Domain Adaptation for Cold-start Recommendation with Positive and Negative Hypergraphs",
    "doi": "https://doi.org/10.1145/3544105",
    "publication_date": "2022-06-13",
    "publication_year": 2022,
    "authors": "Hanrui Wu; Jinyi Long; Nuosi Li; Dahai Yu; Michael K. Ng",
    "corresponding_authors": "",
    "abstract": "This article presents a novel model named Adversarial Auto-encoder Domain Adaptation to handle the recommendation problem under cold-start settings. Specifically, we divide the hypergraph into two hypergraphs, i.e., a positive hypergraph and a negative one. Below, we adopt the cold-start user recommendation for illustration. After achieving positive and negative hypergraphs, we apply hypergraph auto-encoders to them to obtain positive and negative embeddings of warm users and items. Additionally, we employ a multi-layer perceptron to get warm and cold-start user embeddings called regular embeddings. Subsequently, for warm users, we assign positive and negative pseudo-labels to their positive and negative embeddings, respectively, and treat their positive and regular embeddings as the source and target domain data, respectively. Then, we develop a matching discriminator to jointly minimize the classification loss of the positive and negative warm user embeddings and the distribution gap between the positive and regular warm user embeddings. In this way, warm users’ positive and regular embeddings are connected. Since the positive hypergraph maintains the relations between positive warm user and item embeddings, and the regular warm and cold-start user embeddings follow a similar distribution, the regular cold-start user embedding and positive item embedding are bridged to discover their relationship. The proposed model can be easily extended to handle the cold-start item recommendation by changing inputs. We perform extensive experiments on real-world datasets for both cold-start user and cold-start item recommendations. Promising results in terms of precision, recall, normalized discounted cumulative gain, and hit rate verify the effectiveness of the proposed method.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4282567554",
    "type": "article"
  },
  {
    "title": "A Relative Information Gain-based Query Performance Prediction Framework with Generated Query Variants",
    "doi": "https://doi.org/10.1145/3545112",
    "publication_date": "2022-06-23",
    "publication_year": 2022,
    "authors": "Suchana Datta; Debasis Ganguly; Mandar Mitra; Derek Greene",
    "corresponding_authors": "",
    "abstract": "Query performance prediction (QPP) methods, which aim to predict the performance of a query, often rely on evidences in the form of different characteristic patterns in the distribution of Retrieval Status Values (RSVs). However, for neural IR models, it is usually observed that the RSVs are often less reliable for QPP because they are bounded within short intervals, different from the situation for statistical models. To address this limitation, we propose a model-agnostic QPP framework that gathers additional evidences by leveraging information from the characteristic patterns of RSV distributions computed over a set of automatically generated query variants, relative to that of the current query. Specifically, the idea behind our proposed method—Weighted Relative Information Gain (WRIG), is that a substantial relative decrease or increase in the standard deviation of the RSVs of the query variants is likely to be a relative indicator of how easy or difficult the original query is. To cater for the absence of human-annotated query variants in real-world scenarios, we further propose an automatic query variant generation method. This can produce variants in a controlled manner by substituting terms from the original query with new ones sampled from a weighted distribution, constructed either via a relevance model or with the help of an embedded representation of query terms. Our experiments on the TREC-Robust, ClueWeb09B, and MS MARCO datasets show that WRIG, by the use of this relative changes in QPP estimate, leads to significantly better results than a state-of-the-art baseline method that leverages information from (manually created) query variants by the application of additive smoothing [ 64 ]. The results also show that our approach can improve the QPP effectiveness of neural retrieval approaches in particular.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4283322704",
    "type": "article"
  },
  {
    "title": "A Consistent Dual-MRC Framework for Emotion-cause Pair Extraction",
    "doi": "https://doi.org/10.1145/3558548",
    "publication_date": "2022-08-22",
    "publication_year": 2022,
    "authors": "Zifeng Cheng; Zhiwei Jiang; Yafeng Yin; Cong Wang; Shiping Ge; Qing Gu",
    "corresponding_authors": "",
    "abstract": "Emotion-cause pair extraction (ECPE) is a recently proposed task that aims to extract the potential clause pairs of emotions and its corresponding causes in a document. In this article, we propose a new paradigm for the ECPE task. We cast the task as a two-turn machine reading comprehension (MRC) task, i.e., the extraction of emotions and causes is transformed to the task of identifying answer clauses from the input document specific to a query. This two-turn MRC formalization brings several key advantages: First, the QA manner provides an explicit pairing way to identify causes specific to the target emotion; second, it provides a natural way of jointly modeling the emotion extraction, the cause extraction, and the pairing of emotion and cause; and third, it allows us to exploit the well-developed MRC models. Based on the two-turn MRC formalization, we propose a dual-MRC framework to extract emotion-cause pairs in a dual-direction way, which enables a more comprehensive coverage of all pairing cases. Furthermore, we propose a consistent training strategy for the second-turn query, so the model is able to filter the errors produced by the first turn at inference. Experiments on two benchmark datasets demonstrate that our method outperforms previous methods and achieves state-of-the-art performance. All the code and data of this work can be obtained at https://github.com/zifengcheng/CD-MRC .",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4292595691",
    "type": "article"
  },
  {
    "title": "Understanding Relevance Judgments in Legal Case Retrieval",
    "doi": "https://doi.org/10.1145/3569929",
    "publication_date": "2022-10-28",
    "publication_year": 2022,
    "authors": "Yunqiu Shao; Yueyue Wu; Yiqun Liu; Jiaxin Mao; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Legal case retrieval, which aims to retrieve relevant cases given a query case, has drawn increasing research attention in recent years. While much research has worked on developing automatic retrieval models, how to characterize relevance in this specialized information retrieval (IR) task is still an open question. Towards an in-depth understanding of relevance judgments, we conduct a laboratory user study that involves 72 participants of different domain expertise. In the user study, we collect the relevance score along with detailed explanations for the relevance judgment and various measures of the judgment process. From the collected data, we observe that both the subjective (e.g., domain expertise) and objective (e.g., query/case property) factors influence the relevance judgment process. By investigating the collected user explanations, we identify task-specific patterns of user attention distribution and re-think the criteria for relevance judgments. Moreover, we investigate the similarity in attention distribution between models and users. Further, we propose a two-stage framework that utilizes user attention to improve relevance estimation for legal case retrieval. Our study sheds light on understanding relevance judgments in legal case retrieval and provides implications for improving the design of corresponding retrieval systems.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W4307713853",
    "type": "article"
  },
  {
    "title": "An Adaptive Graph Pre-training Framework for Localized Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3555372",
    "publication_date": "2022-08-10",
    "publication_year": 2022,
    "authors": "Yiqi Wang; Chaozhuo Li; Zheng Liu; Mingzheng Li; Jiliang Tang; Xing Xie; Lei Chen; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "Graph neural networks (GNNs) have been widely applied in the recommendation tasks and have achieved very appealing performance. However, most GNN-based recommendation methods suffer from the problem of data sparsity in practice. Meanwhile, pre-training techniques have achieved great success in mitigating data sparsity in various domains such as natural language processing (NLP) and computer vision (CV) . Thus, graph pre-training has the great potential to alleviate data sparsity in GNN-based recommendations. However, pre-training GNNs for recommendations faces unique challenges. For example, user-item interaction graphs in different recommendation tasks have distinct sets of users and items, and they often present different properties. Therefore, the successful mechanisms commonly used in NLP and CV to transfer knowledge from pre-training tasks to downstream tasks such as sharing learned embeddings or feature extractors are not directly applicable to existing GNN-based recommendations models. To tackle these challenges, we delicately design an adaptive graph pre-training framework for localized collaborative filtering (ADAPT) . It does not require transferring user/item embeddings, and is able to capture both the common knowledge across different graphs and the uniqueness for each graph simultaneously. Extensive experimental results have demonstrated the effectiveness and superiority of ADAPT.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4226271223",
    "type": "article"
  },
  {
    "title": "Proactive Privacy-preserving Learning for Cross-modal Retrieval",
    "doi": "https://doi.org/10.1145/3545799",
    "publication_date": "2022-06-28",
    "publication_year": 2022,
    "authors": "Peng-Fei Zhang; Guangdong Bai; Hongzhi Yin; Zi Huang",
    "corresponding_authors": "",
    "abstract": "Deep cross-modal retrieval techniques have recently achieved remarkable performance, which also poses severe threats to data privacy potentially. Nowadays, enormous user-generated contents that convey personal information are released and shared on the Internet. One may abuse a retrieval system to pinpoint sensitive information of a particular Internet user, causing privacy leakage. In this article, we propose a data-centric Proactive Privacy-preserving Cross-modal Learning algorithm that fulfills the protection purpose by employing a generator to transform original data into adversarial data with quasi-imperceptible perturbations before releasing them. When the data source is infiltrated, the inside adversarial data can confuse retrieval models under the attacker’s control to make erroneous predictions. We consider the protection under a realistic and challenging setting where the prior knowledge of malicious models is agnostic. To handle this, a surrogate retrieval model is instead introduced, acting as the target to fool. The whole network is trained under a game-theoretical framework, where the generator and the retrieval model persistently evolve to fight against each other. To facilitate the optimization, a Gradient Reversal Layer module is inserted between two models, enabling a one-step learning fashion. Extensive experiments on widely used realistic datasets prove the effectiveness of the proposed method.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W4283693981",
    "type": "article"
  },
  {
    "title": "Contrastive Graph Prompt-tuning for Cross-domain Recommendation",
    "doi": "https://doi.org/10.1145/3618298",
    "publication_date": "2023-09-02",
    "publication_year": 2023,
    "authors": "Zixuan Yi; Iadh Ounis; Craig Macdonald",
    "corresponding_authors": "",
    "abstract": "Recommender systems commonly suffer from the long-standing data sparsity problem where insufficient user-item interaction data limits the systems’ ability to make accurate recommendations. This problem can be alleviated using cross-domain recommendation techniques. In particular, in a cross-domain setting, knowledge sharing between domains permits improved effectiveness on the target domain. While recent cross-domain recommendation techniques used a pre-training configuration, we argue that such techniques lead to a low fine-tuning efficiency, especially when using large neural models. In recent language models, prompts have been used for parameter-efficient and time-efficient tuning of the models on the downstream tasks—these prompts represent a tunable latent vector that permits to freeze the rest of the language model’s parameters. To address the cross-domain recommendation task in an efficient manner, we propose a novel Personalised Graph Prompt-based Recommendation (PGPRec) framework, which leverages the efficiency benefits from prompt-tuning. In such a framework, we develop personalised and item-wise graph prompts based on relevant items to those items the user has interacted with. In particular, we apply Contrastive Learning to generate the pre-trained embeddings, to allow an increased generalisability in the pre-training stage, and to ensure an effective prompt-tuning stage. To evaluate the effectiveness of our PGPRec framework in a cross-domain setting, we conduct an extensive evaluation with the top- k recommendation task and perform a cold-start analysis. The obtained empirical results on four Amazon Review datasets show that our proposed PGPRec framework can reduce up to 74% of the tuned parameters with a competitive performance and achieves an 11.41% improved performance compared to the strongest baseline in a cold-start scenario.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4386392742",
    "type": "article"
  },
  {
    "title": "Multi-auxiliary Augmented Collaborative Variational Auto-encoder for Tag Recommendation",
    "doi": "https://doi.org/10.1145/3578932",
    "publication_date": "2023-01-31",
    "publication_year": 2023,
    "authors": "Jing Yi; Xubin Ren; Zhenzhong Chen",
    "corresponding_authors": "",
    "abstract": "Recommending appropriate tags to items can facilitate content organization, retrieval, consumption, and other applications, where hybrid tag recommender systems have been utilized to integrate collaborative information and content information for better recommendations. In this article, we propose a multi-auxiliary augmented collaborative variational auto-encoder (MA-CVAE) for tag recommendation, which couples item collaborative information and item multi-auxiliary information, i.e., content and social graph, by defining a generative process. Specifically, the model learns deep latent embeddings from different item auxiliary information using variational auto-encoders (VAE), which could form a generative distribution over each auxiliary information by introducing a latent variable parameterized by deep neural network. Moreover, to recommend tags for new items, item multi-auxiliary latent embeddings are utilized as a surrogate through the item decoder for predicting recommendation probabilities of each tag, where reconstruction losses are added in the training phase to constrain the generation for feedback predictions via different auxiliary embeddings. In addition, an inductive variational graph auto-encoder is designed to infer latent embeddings of new items in the test phase, such that item social information could be exploited for new items. Extensive experiments on MovieLens and citeulike datasets demonstrate the effectiveness of our method.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4318618444",
    "type": "article"
  },
  {
    "title": "Learning from Hierarchical Structure of Knowledge Graph for Recommendation",
    "doi": "https://doi.org/10.1145/3595632",
    "publication_date": "2023-07-11",
    "publication_year": 2023,
    "authors": "Yingrong Qin; Chen Gao; Shuangqing Wei; Yue Wang; Depeng Jin; Jian Yuan; Lin Zhang; Dong Li; Jianye Hao; Yong Li",
    "corresponding_authors": "",
    "abstract": "Knowledge graphs (KGs) can help enhance recommendations, especially for the data-sparsity scenarios with limited user-item interaction data. Due to the strong power of representation learning of graph neural networks (GNNs), recent works of KG-based recommendation deploy GNN models to learn from both knowledge graph and user-item bipartite interaction graph. However, these works have not well considered the hierarchical structure of knowledge graph, leading to sub-optimal results. Despite the benefit of hierarchical structure, leveraging it is challenging since the structure is always partly-observed. In this work, we first propose to reveal unknown hierarchical structures with a supervised signal detection method and then exploit the hierarchical structure with disentangling representation learning. We conduct experiments on two large-scale datasets, of which the results well verify the superiority and rationality of the proposed method. Further experiments of ablation study with respect to key model designs have demonstrated the effectiveness and rationality of our proposed model. The code is available at https://github.com/tsinghua-fib-lab/HIKE .",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4383879002",
    "type": "article"
  },
  {
    "title": "Relevance Feedback with Brain Signals",
    "doi": "https://doi.org/10.1145/3637874",
    "publication_date": "2023-12-18",
    "publication_year": 2023,
    "authors": "Ziyi Ye; Xiaohui Xie; Qingyao Ai; Yiqun Liu; Zhihong Wang; Weihang Su; Min Zhang",
    "corresponding_authors": "",
    "abstract": "The Relevance Feedback (RF) process relies on accurate and real-time relevance estimation of feedback documents to improve retrieval performance. Since collecting explicit relevance annotations imposes an extra burden on the user, extensive studies have explored using pseudo-relevance signals and implicit feedback signals as substitutes. However, such signals are indirect indicators of relevance and suffer from complex search scenarios where user interactions are absent or biased. Recently, the advances in portable and high-precision brain-computer interface (BCI) devices have shown the possibility to monitor user’s brain activities during search process. Brain signals can directly reflect user’s psychological responses to search results and thus it can act as additional and unbiased RF signals. To explore the effectiveness of brain signals in the context of RF, we propose a novel RF framework that combines BCI-based RF with pseudo-relevance signals and implicit signals to improve the performance of document re-ranking. The experimental results on the user study dataset show that incorporating brain signals leads to significant performance improvement in our RF framework. Besides, we observe that brain signals perform particularly well in several hard search scenarios, especially when implicit signals as feedback are missing or noisy. This reveals when and how to exploit brain signals in the context of RF.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4389914541",
    "type": "article"
  },
  {
    "title": "FairGap: Fairness-Aware Recommendation via Generating Counterfactual Graph",
    "doi": "https://doi.org/10.1145/3638352",
    "publication_date": "2023-12-22",
    "publication_year": 2023,
    "authors": "Wei Chen; Yiqing Wu; Zhao Zhang; Fuzhen Zhuang; Zhongshi He; Ruobing Xie; Feng Xia",
    "corresponding_authors": "",
    "abstract": "The emergence of Graph Neural Networks (GNNs) has greatly advanced the development of recommendation systems. Recently, many researchers have leveraged GNN-based models to learn fair representations for users and items. However, current GNN-based models suffer from biased user–item interaction data, which negatively impacts recommendation fairness. Although there have been several studies employing adversarial learning to mitigate this issue in recommendation systems, they mostly focus on modifying the model training approach with fairness regularization and neglect direct intervention of biased interaction. In contrast to these models, this article introduces a novel perspective by directly intervening in observed interactions to generate a counterfactual graph (called FairGap) that is not influenced by sensitive node attributes, enabling us to learn fair representations for users and items easily. We design FairGap to answer the key counterfactual question: “Would interactions with an item remain unchanged if a user’s sensitive attributes were concealed?”. We also provide theoretical proofs to show that our learning strategy via the counterfactual graph is unbiased in expectation. Moreover, we propose a fairness-enhancing mechanism to continuously improve user fairness in the graph-based recommendation. Extensive experimental results against state-of-the-art competitors and base models on three real-world datasets validate the effectiveness of our proposed model.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4390134877",
    "type": "article"
  },
  {
    "title": "Understanding Diversity in Session-based Recommendation",
    "doi": "https://doi.org/10.1145/3600226",
    "publication_date": "2023-05-30",
    "publication_year": 2023,
    "authors": "Yin Qing; Hui Fang; Zhu Sun; Yew-Soon Ong",
    "corresponding_authors": "",
    "abstract": "Current session-based recommender systems (SBRSs) mainly focus on maximizing recommendation accuracy, while few studies have been devoted to improve diversity beyond accuracy. Meanwhile, it is unclear how the accuracy-oriented SBRSs perform in terms of diversity. In addition, the asserted “tradeoff” relationship between accuracy and diversity has been increasingly questioned in the literature. Toward the aforementioned issues, we conduct a holistic study to particularly examine the recommendation performance of representative SBRSs w.r.t. both accuracy and diversity, striving for better understanding of the diversity-related issues for SBRSs and providing guidance on designing diversified SBRSs. Particularly, for a fair and thorough comparison, we deliberately select state-of-the-art non-neural, deep neural, and diversified SBRSs by covering more scenarios with appropriate experimental setups, e.g., representative datasets, evaluation metrics, and hyper-parameter optimization technique. The source code can be obtained via github.com/qyin863/Understanding-Diversity-in-SBRSs . Our empirical results unveil that (1) non-diversified methods can also obtain satisfying performance on diversity, which can even surpass diversified ones, and (2) the relationship between accuracy and diversity is quite complex. Besides the “tradeoff” relationship, they can be positively correlated with each other, that is, having a same-trend (win–win or lose–lose) relationship, which varies across different methods and datasets. Additionally, we further identify three possible influential factors on diversity in SBRSs (i.e., granularity of item categorization, session diversity of datasets, and length of recommendation lists) and offer an intuitive guideline and a potential solution regarding learned item embeddings for more effective session-based recommendation.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4379093238",
    "type": "article"
  },
  {
    "title": "DA-DAN: A Dual Adversarial Domain Adaption Network for Unsupervised Non-overlapping Cross-domain Recommendation",
    "doi": "https://doi.org/10.1145/3617825",
    "publication_date": "2023-08-26",
    "publication_year": 2023,
    "authors": "Lei Guo; Hao Liu; Lei Zhu; Weili Guan; Zhiyong Cheng",
    "corresponding_authors": "",
    "abstract": "Unsupervised Non-overlapping Cross-domain Recommendation (UNCR) is the task that recommends source domain items to the target domain users, which is more challenging as the users are non-overlapped, and its learning process is unsupervised. Unsupervised Non-overlapping Cross-domain Recommendation UNCR is still unsolved due to the following: (1) Previous studies need extra auxiliary information to learn transferable features when aligning two domains, which is unrealistic and hard to obtain due to privacy concerns. (2) Since the adoption of the shared network, existing works cannot well eliminate the domain-specific features in the common feature space, which may incorporate domain noise and harm the cross-domain recommendation. In this work, we propose a domain adaption-based method, namely DA-DAN, to address the above challenges. Specifically, to let DA-DAN be free of auxiliary information, we learn users’ preferences by only exploring their sequential patterns, and propose an improved self-attention layer to model them. To well eliminate the domain-specific features from the common feature space, we resort to a dual generative adversarial network with a multi-target adversarial loss, where two generators and discriminators are leveraged to model each domain separately. Experimental results on three real-world datasets demonstrate the advantage of DA-DAN compared with the state-of-the-art recommendation baselines. Moreover, our source codes have been publicly released. 1",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4386190240",
    "type": "article"
  },
  {
    "title": "Understanding and Predicting User Satisfaction with Conversational Recommender Systems",
    "doi": "https://doi.org/10.1145/3624989",
    "publication_date": "2023-09-21",
    "publication_year": 2023,
    "authors": "Clemencia Siro; Mohammad Aliannejadi; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "User satisfaction depicts the effectiveness of a system from the user’s perspective. Understanding and predicting user satisfaction is vital for the design of user-oriented evaluation methods for conversational recommender systems (CRSs) . Current approaches rely on turn-level satisfaction ratings to predict a user’s overall satisfaction with CRS. These methods assume that all users perceive satisfaction similarly, failing to capture the broader dialogue aspects that influence overall user satisfaction. We investigate the effect of several dialogue aspects on user satisfaction when interacting with a CRS. To this end, we annotate dialogues based on six aspects (i.e., relevance , interestingness , understanding , task-completion , interest-arousal , and efficiency ) at the turn and dialogue levels. We find that the concept of satisfaction varies per user. At the turn level, a system’s ability to make relevant recommendations is a significant factor in satisfaction. We adopt these aspects as features for predicting response quality and user satisfaction. We achieve an F1-score of 0.80 in classifying dissatisfactory dialogues, and a Pearson’s r of 0.73 for turn-level response quality estimation, demonstrating the effectiveness of the proposed dialogue aspects in predicting user satisfaction and being able to identify dialogues where the system is failing. With this article, we release our annotated data. 1",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4386928872",
    "type": "article"
  },
  {
    "title": "Bi-preference Learning Heterogeneous Hypergraph Networks for Session-based Recommendation",
    "doi": "https://doi.org/10.1145/3631940",
    "publication_date": "2023-11-07",
    "publication_year": 2023,
    "authors": "Xiaokun Zhang; Bo Xu; Fenglong Ma; Chenliang Li; Yuan Lin; Hongfei Lin",
    "corresponding_authors": "",
    "abstract": "Session-based recommendation intends to predict next purchased items based on anonymous behavior sequences. Numerous economic studies have revealed that item price is a key factor influencing user purchase decisions. Unfortunately, existing methods for session-based recommendation only aim at capturing user interest preference, while ignoring user price preference. Actually, there are primarily two challenges preventing us from accessing price preference. First, the price preference is highly associated to various item features (i.e., category and brand), which asks us to mine price preference from heterogeneous information. Second, price preference and interest preference are interdependent and collectively determine user choice, necessitating that we jointly consider both price and interest preference for intent modeling. To handle above challenges, we propose a novel approach Bi-Preference Learning Heterogeneous Hypergraph Networks (BiPNet) for session-based recommendation. Specifically, the customized heterogeneous hypergraph networks with a triple-level convolution are devised to capture user price and interest preference from heterogeneous features of items. Besides, we develop a Bi-Preference Learning schema to explore mutual relations between price and interest preference and collectively learn these two preferences under the multi-task learning architecture. Extensive experiments on multiple public datasets confirm the superiority of BiPNet over competitive baselines. Additional research also supports the notion that the price is crucial for the task.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4388454975",
    "type": "article"
  },
  {
    "title": "Knowledge-Enhanced Conversational Recommendation via Transformer-Based Sequential Modeling",
    "doi": "https://doi.org/10.1145/3677376",
    "publication_date": "2024-07-12",
    "publication_year": 2024,
    "authors": "Jie Zou; Aixin Sun; Cheng Long; Evangelos Kanoulas",
    "corresponding_authors": "",
    "abstract": "In conversational recommender systems (CRSs), conversations usually involve a set of items and item-related entities or attributes, e.g., director is a related entity of a movie. These items and item-related entities are often mentioned along the development of a dialog, leading to potential sequential dependencies among them. However, most of existing CRSs neglect these potential sequential dependencies. In this article, we first propose a Transformer-based sequential conversational recommendation method, named TSCR, to model the sequential dependencies in the conversations to improve CRS. In TSCR, we represent conversations by items and the item-related entities, and construct user sequences to discover user preferences by considering both the mentioned items and item-related entities. Based on the constructed sequences, we deploy a Cloze task to predict the recommended items along a sequence. Meanwhile, in certain domains, knowledge graphs formed by the items and their related entities are readily available, which provide various different kinds of associations among them. Given that TSCR does not benefit from such knowledge graphs, we then propose a knowledge graph enhanced version of TSCR, called TSCRKG. In specific, we leverage the knowledge graph to offline initialize our model TSCRKG, and augment the user sequence of conversations (i.e., sequence of the mentioned items and item-related entities in the conversation) with multi-hop paths in the knowledge graph. Experimental results demonstrate that our TSCR model significantly outperforms state-of-the-art baselines, and the enhanced version TSCRKG further improves recommendation performance on top of TSCR.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4400581058",
    "type": "article"
  },
  {
    "title": "Denoising Heterogeneous Graph Pre-training Framework for Recommendation",
    "doi": "https://doi.org/10.1145/3706632",
    "publication_date": "2024-12-05",
    "publication_year": 2024,
    "authors": "Lei Sang; Yu Wang; Yiwen Zhang; Xindong Wu",
    "corresponding_authors": "",
    "abstract": "Heterogeneous graph neural networks (HGNN) have exhibited significant performance gains by modeling the information propagation process in graph-structured data for recommender systems. However, existing HGNN-based Recommendation still face two challenges: 1) They overlook the rich semantics brought by the combination of different meta-paths, making it difficult to capture the importance of various meta-paths; 2) when HGNN use meta-paths to capture high-order information, they are susceptible to noise data, as noise from connected nodes can create cumulative effects on a target node in the graph. To tackle these issues, we propose a new model called the Denoising Heterogeneous Graph Pre-training Framework ( DHGPF ) to enhance recommendation tasks. This framework has two stages: pre-training and training. In the pre-training stage, we assign learnable weights to different meta-paths and use a simplified multi-layer graph convolution network to automatically aggregate semantic information from different meta-path combinations. This approach can capture the importance of these paths. The training stage focuses on reducing noise using gating mechanism and denoising structure learning methods. These methods accomplish the denoising process through information filtering. Our model was evaluated on three real-world datasets, demonstrating that DHGPF outperforms other state-of-the-art recommendation methods. We have further organized the source code of the paper at https://github.com/wangyu0627/DHGPF .",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4405078106",
    "type": "article"
  },
  {
    "title": "PTF-FSR: A Parameter Transmission-Free Federated Sequential Recommender System",
    "doi": "https://doi.org/10.1145/3708344",
    "publication_date": "2024-12-12",
    "publication_year": 2024,
    "authors": "Wei Yuan; Chaoqun Yang; Liang Qu; Quoc Viet Hung Nguyen; Guanhua Ye; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "Sequential recommender systems, as a specialized branch of recommender systems that can capture users’ dynamic preferences for more accurate and timely recommendations, have made significant progress. Recently, due to increasing concerns about user data privacy, some researchers have implemented federated learning for sequential recommendation, a.k.a., Federated Sequential Recommender Systems (FedSeqRecs), in which a public sequential recommender model is shared and frequently transmitted between a central server and clients to achieve collaborative learning. Although these solutions mitigate user privacy to some extent, they present two significant limitations that affect their practical usability: (1) They require a globally shared sequential recommendation model. However, in real-world scenarios, the recommendation model constitutes a critical intellectual property for platform and service providers. Therefore, service providers may be reluctant to disclose their meticulously developed models. (2) The communication costs are high as they correlate with the number of model parameters. This becomes particularly problematic as the current FedSeqRec will be inapplicable when sequential recommendation marches into a large language model era. To overcome the above challenges, this paper proposes a parameter transmission-free federated sequential recommendation framework (PTF-FSR), which ensures both model and data privacy protection to meet the privacy needs of service providers and system users alike. Furthermore, since PTF-FSR only transmits prediction results under privacy protection, which are independent of model sizes, this new federated learning architecture can accommodate more complex and larger sequential recommendation models. Extensive experiments conducted on three widely used recommendation datasets, employing various sequential recommendation models from both ID-based and ID-free paradigms, demonstrate the effectiveness and generalization capability of our proposed framework. To facilitate future research in this direction, we release our code at https://github.com/hi-weiyuan/PTF-FSR .",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4405319402",
    "type": "article"
  },
  {
    "title": "Predicting Representations of Information Needs from Digital Activity Context",
    "doi": "https://doi.org/10.1145/3639819",
    "publication_date": "2024-01-15",
    "publication_year": 2024,
    "authors": "Tung Vuong; Tuukka Ruotsalo",
    "corresponding_authors": "",
    "abstract": "Information retrieval systems often consider search-session and immediately preceding web-browsing history as the context for predicting users' present information needs. However, such context is only available when a user's information needs originate from web context or when users have issued preceding queries in the search session. Here, we study the effect of more extensive context information recorded from users' everyday digital activities by monitoring all information interacted with and communicated using personal computers. Twenty individuals were recruited for 14 days of 24/7 continuous monitoring of their digital activities, including screen contents, clicks, and operating system logs on Web and non-Web applications. Using this data, a transformer architecture is applied to model the digital activity context and predict representations of personalized information needs. Subsequently, the representations of information needs are used for query prediction, query auto-completion, selected search result prediction, and Web search re-ranking. The predictions of the models are evaluated against the ground truth data obtained from the activity recordings. The results reveal that the models accurately predict representations of information needs improving over the conventional search session and web-browsing contexts. The results indicate that the present practice for utilizing users' contextual information is limited and can be significantly extended to achieve improved search interaction support and performance.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4390880310",
    "type": "article"
  },
  {
    "title": "MCN4Rec: Multi-level Collaborative Neural Network for Next Location Recommendation",
    "doi": "https://doi.org/10.1145/3643669",
    "publication_date": "2024-01-29",
    "publication_year": 2024,
    "authors": "Shuzhe Li; Wei Chen; Bin Wang; Chao Huang; Yanwei Yu; Junyu Dong",
    "corresponding_authors": "",
    "abstract": "Next location recommendation plays an important role in various location-based services, yielding great value for both users and service providers. Existing methods usually model temporal dependencies with explicit time intervals or learn representation from customized point of interest (POI) graphs with rich context information to capture the sequential patterns among POIs. However, this problem is perceptibly complex, because various factors, e.g., users’ preferences, spatial locations, time contexts, activity category semantics, and temporal relations, need to be considered together, while most studies lack sufficient consideration of the collaborative signals. Toward this goal, we propose a novel M ulti-Level C ollaborative Neural N etwork for next location Rec ommendation (MCN4Rec). Specifically, we design a multi-level view representation learning with level-wise contrastive learning to collaboratively learn representation from local and global perspectives to capture complex heterogeneous relationships among user, POI, time, and activity categories. Then, a causal encoder-decoder is applied to the learned representations of check-in sequences to recommend the next location. Extensive experiments on four real-world check-in mobility datasets demonstrate that our model significantly outperforms the existing state-of-the-art baselines for the next location recommendation. Ablation study further validates the benefits of the collaboration of the designed sub-modules. The source code is available at https://github.com/quai-mengxiang/MCN4Rec .",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4391322761",
    "type": "article"
  },
  {
    "title": "ELAKT: Enhancing Locality for Attentive Knowledge Tracing",
    "doi": "https://doi.org/10.1145/3652601",
    "publication_date": "2024-03-14",
    "publication_year": 2024,
    "authors": "Yanjun Pu; Fang Liu; Rongye Shi; Haitao Yuan; Ruibo Chen; Tianhao Peng; Wenjun Wu",
    "corresponding_authors": "",
    "abstract": "Knowledge tracing models based on deep learning can achieve impressive predictive performance by leveraging attention mechanisms. However, there still exist two challenges in attentive knowledge tracing (AKT): First, the mechanism of classical models of AKT demonstrates relatively low attention when processing exercise sequences with shifting knowledge concepts (KC), making it difficult to capture the comprehensive state of knowledge across sequences. Second, classical models do not consider stochastic behaviors, which negatively affects models of AKT in terms of capturing anomalous knowledge states. This article proposes a model of AKT, called Enhancing Locality for Attentive Knowledge Tracing (ELAKT), that is a variant of the deep KT model. The proposed model leverages the encoder module of the transformer to aggregate knowledge embedding generated by both exercises and responses over all timesteps. In addition, it uses causal convolutions to aggregate and smooth the states of local knowledge. The ELAKT model uses the states of comprehensive KCs to introduce a prediction correction module to forecast the future responses of students to deal with noise caused by stochastic behaviors. The results of experiments demonstrated that the ELAKT model consistently outperforms state-of-the-art baseline KT models.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4392806396",
    "type": "article"
  },
  {
    "title": "Discrete Federated Multi-behavior Recommendation for Privacy-Preserving Heterogeneous One-Class Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3652853",
    "publication_date": "2024-03-18",
    "publication_year": 2024,
    "authors": "Enyue Yang; Weike Pan; Qiang Yang; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "Recently, federated recommendation has become a research hotspot mainly because of users’ awareness of privacy in data. As a recent and important recommendation problem, in heterogeneous one-class collaborative filtering (HOCCF), each user may involve of two different types of implicit feedback, that is, examinations and purchases. So far, privacy-preserving HOCCF has received relatively little attention. Existing federated recommendation works often overlook the fact that some privacy sensitive behaviors such as purchases should be collected to ensure the basic business imperatives in e-commerce for example. Hence, the user privacy constraints can and should be relaxed while deploying a recommendation system in real scenarios. In this article, we study the federated multi-behavior recommendation problem under the assumption that purchase behaviors can be collected. Moreover, there are two additional challenges that need to be addressed when deploying federated recommendation. One is the low storage capacity for users’ devices to store all the item vectors, and the other is the low computational power for users to participate in federated learning. To release the potential of privacy-preserving HOCCF, we propose a novel framework, named discrete federated multi-behavior recommendation (DFMR), which allows the collection of the business necessary behaviors (i.e., purchases) by the server. As to reduce the storage overhead, we use discrete hashing techniques, which can compress the parameters down to 1.56% of the real-valued parameters. To further improve the computation-efficiency, we design a memorization strategy in the cache updating module to accelerate the training process. Extensive experiments on four public datasets show the superiority of our DFMR in terms of both accuracy and efficiency.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4392915638",
    "type": "article"
  },
  {
    "title": "On the Opportunities and Challenges of Offline Reinforcement Learning for Recommender Systems",
    "doi": "https://doi.org/10.1145/3661996",
    "publication_date": "2024-04-29",
    "publication_year": 2024,
    "authors": "Xiaocong Chen; Siyu Wang; Julian McAuley; Dietmar Jannach; Lina Yao",
    "corresponding_authors": "",
    "abstract": "Reinforcement learning serves as a potent tool for modeling dynamic user interests within recommender systems, garnering increasing research attention of late. However, a significant drawback persists: its poor data efficiency, stemming from its interactive nature. The training of reinforcement learning-based recommender systems demands expensive online interactions to amass adequate trajectories, essential for agents to learn user preferences. This inefficiency renders reinforcement learning-based recommender systems a formidable undertaking, necessitating the exploration of potential solutions. Recent strides in offline reinforcement learning present a new perspective. Offline reinforcement learning empowers agents to glean insights from offline datasets and deploy learned policies in online settings. Given that recommender systems possess extensive offline datasets, the framework of offline reinforcement learning aligns seamlessly. Despite being a burgeoning field, works centered on recommender systems utilizing offline reinforcement learning remain limited. This survey aims to introduce and delve into offline reinforcement learning within recommender systems, offering an inclusive review of existing literature in this domain. Furthermore, we strive to underscore prevalent challenges, opportunities, and future pathways, poised to propel research in this evolving field.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4396216288",
    "type": "article"
  },
  {
    "title": "Multi-Hop Multi-View Memory Transformer for Session-Based Recommendation",
    "doi": "https://doi.org/10.1145/3663760",
    "publication_date": "2024-05-08",
    "publication_year": 2024,
    "authors": "Xingrui Zhuo; Shengsheng Qian; Jun Hu; Fuxin Dai; Kangyi Lin; Gongqing Wu",
    "corresponding_authors": "",
    "abstract": "A Session-Based Recommendation (SBR) seeks to predict users’ future item preferences by analyzing their interactions with previously clicked items. In recent approaches, Graph Neural Networks (GNNs) have been commonly applied to capture item relations within a session to infer user intentions. However, these GNN-based methods typically struggle with feature ambiguity between the sequential session information and the item conversion within an item graph, which may impede the model’s ability to accurately infer user intentions. In this article, we propose a novel Multi-hop Multi-view Memory Transformer (M 3 T) to effectively integrate the sequence-view information and relation conversion (graph-view information) of items in a session. First, we propose a Multi-view Memory Transformer (M 2 T) module to concurrently obtain multi-view information of items. Then, a set of trainable memory matrices are employed to store sharable item features, which mitigates cross-view item feature ambiguity. To comprehensively capture latent user intentions, an M 3 T framework is designed to integrate user intentions across different hops of an item graph. Specifically, a k-order power method is proposed to manage the item graph to alleviate the over-smoothing problem when obtaining high-order relations of items. Extensive experiments conducted on three real-world datasets demonstrate the superiority of our method.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4396726959",
    "type": "article"
  },
  {
    "title": "MvStHgL: Multi-view Hypergraph Learning with Spatial-temporal Periodic Interests for Next POI Recommendation",
    "doi": "https://doi.org/10.1145/3664651",
    "publication_date": "2024-08-19",
    "publication_year": 2024,
    "authors": "Jingmin An; Ming Gao; Jiafu Tang",
    "corresponding_authors": "",
    "abstract": "Providing potential next point-of-interest (POI) suggestions for users has become a prominent task in location-based social networks, which receives more and more attention from the industry and academia and it remains challenging due to highly dynamic and personalized interactions in user movements. Currently, state-of-the-art works develop various graph- and sequential-based learning methods to model user-POI interactions and transition regularities. However, there are still two significant shortcomings in these works: (1) ignoring personalized spatial and temporal-aspect interactive characteristics capable of exhibiting periodic interests of users and (2) insufficiently leveraging the sequential patterns of interactions for beyond-pairwise high-order collaborative signals among users’ sequences. To jointly address these challenges, we propose a novel multi-view hypergraph learning with spatial-temporal periodic interests for next POI recommendation (MvStHgL). In the local view, we attempt to learn the POI representation of each interaction via jointing periodic characteristics of spatial and temporal aspects. In the global view, we design a hypergraph by regarding interactive sequences as hyperedges to capture high-order collaborative signals across users, for further POI representations. More specifically, the output of POI representations in the local view is used for the initialized embedding, and the aggregation and propagation in the hypergraph are performed by a novel Node-to-Hypergraph-to-Node scheme. Furthermore, the captured POI embeddings are applied to achieve sequential dependency modeling for next POI prediction. Extensive experiments on three real-world datasets demonstrate that our proposed model outperforms the state-of-the-art models.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4396793140",
    "type": "article"
  },
  {
    "title": "A Contrastive Pretrain Model with Prompt Tuning for Multi-center Medication Recommendation",
    "doi": "https://doi.org/10.1145/3706631",
    "publication_date": "2025-01-03",
    "publication_year": 2025,
    "authors": "Qidong Liu; Zhaopeng Qiu; Xiangyu Zhao; Xian Wu; Zijian Zhang; Tong Xu; Feng Tian",
    "corresponding_authors": "",
    "abstract": "Medication recommendation is one of the most critical health-related applications, which has attracted extensive research interest recently. Most existing works focus on a single hospital with abundant medical data. However, many small hospitals only have a few records, which hinders applying existing medication recommendation works to the real world. Thus, we seek to explore a more practical setting, i.e. , multi-center medication recommendation. In this setting, most hospitals have few records, but the total number of records is large. Though small hospitals may benefit from total affluent records, it is also faced with the challenge that the data distributions between various hospitals are much different. In this work, we introduce a novel con T rastive pr E train M odel with P rompt T uning ( TEMPT ) for multi-center medication recommendation, which includes two stages of pretraining and finetuning. We first design two self-supervised tasks for the pretraining stage to learn general medical knowledge. They are mask prediction and contrastive tasks, which extract the intra- and inter-relationships of input diagnosis and procedures. Furthermore, we devise a novel prompt tuning method to capture the specific information of each hospital rather than adopting the common finetuning. On the one hand, the proposed prompt tuning can better learn the heterogeneity of each hospital to fit various distributions. On the other hand, it can also relieve the catastrophic forgetting problem of finetuning. To validate the proposed model, we conduct extensive experiments on the public eICU, a multi-center medical dataset. The experimental results illustrate the effectiveness of our model. The implementation code is available to ease the reproducibility 1 .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406024872",
    "type": "article"
  },
  {
    "title": "Domain Counterfactual Data Augmentation for Explainable Recommendation",
    "doi": "https://doi.org/10.1145/3711856",
    "publication_date": "2025-01-10",
    "publication_year": 2025,
    "authors": "Yi Yu; Kazunari Sugiyama; Adam Jatowt",
    "corresponding_authors": "",
    "abstract": "Providing explanations for recommendation decisions is crucial for enhancing user trust and satisfaction in recommender systems. However, existing generative methods often produce generic, repetitive explanation texts that fail to reflect the true reasons behind user interests and item attributes. Thus, it is important to address this degeneration issue in recommendation explanations. This work tackles a key problem in explainable recommendation: understanding how explanation degeneration occurs and improving explanation quality by mitigating it. We argue that examining the causal mechanism underlying the data generation process is key to addressing this problem. Along this line, we identify a neglected hidden variable, which we refer to as textual attributes . Textual attributes encompass various aspects, such as text style, word frequency distributions, and more. Just like user persona and item attributes in traditional recommender systems, textual attributes also shape the nature of explanations. Our analysis of the causal graph reveals the underlying cause of the model's degeneration. To address this issue, we propose a novel learning method called Domain for Counterfactual Reasoning (D4C). By using the auxiliary domain to generate counterfactual data and combining it with factual data, this approach helps the model focus more on the causal contributions of users and items during training. Extensive experiments on five real-world datasets from various platforms demonstrate the effectiveness of our approach.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406243060",
    "type": "article"
  },
  {
    "title": "Structure-Aware Conversational Legal Case Retrieval",
    "doi": "https://doi.org/10.1145/3711854",
    "publication_date": "2025-01-16",
    "publication_year": 2025,
    "authors": "Bulou Liu; Yiran Hu; Qingyao Ai; Yueyue Wu; Yiqun Liu; Chenliang Li; Fan Zhang; Weixing Shen; Chong Chen; Qi Tian",
    "corresponding_authors": "",
    "abstract": "Legal case retrieval is an important task in information retrieval that aims to retrieve relevant cases for given query cases. Conversational search paradigms have been shown to improve the search experience in legal case retrieval. However, there are two challenges in applying conversational search to legal scenarios. Firstly, legal search conversations often focus on different parts of legal case documents, but existing models struggle to capture the complex structural information and extract accurate relevance signals. Secondly, collecting large-scale conversational search datasets is costly, making it difficult to build reliable conversational legal case retrieval models. To address these challenges, we propose a Structure-Aware Matching Model (SAMM) for conversational legal case retrieval. SAMM extracts matching signals between conversational utterances and segments of the legal cases to incorporate structural information. We decouple the conversational search task into three subtasks and design pretraining tasks to overcome the lack of training data. Additionally, we create ConvLegal, the largest conversational legal case retrieval dataset to the best of our knowledge, for better evaluation of different methods. We train and evaluate SAMM and baselines on both a public dataset (CLCR) and ConvLegal. Experimental results demonstrate that SAMM outperforms existing models in legal case retrieval and conversational search.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406469500",
    "type": "article"
  },
  {
    "title": "Augmentation with Neighboring Information for Conversational Recommendation",
    "doi": "https://doi.org/10.1145/3712588",
    "publication_date": "2025-01-17",
    "publication_year": 2025,
    "authors": "Yuanxing Liu; Jiahuan Pei; Weinan Zhang; Ming Li; Wanxiang Che; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Conversational recommender systems (CRSs) suggest items to users by understanding their needs and preferences from natural language conversations. While users can freely express preferences, modeling needs and preferences solely from users’ conversations is challenging due to the sparsity of the available information. Prior work introduces external resources to enrich information expressed in conversations. Obtaining such resources is challenging and not always effective. Can learning intrinsic relations among conversations and items enhance information without the use of external resources? Inspired by collaborative filtering, we propose to use so-called neighboring relations within training data, i.e., relations between conversations, items, and similar conversations and items, to enhance our algorithmic understanding of CRSs. We propose a neighboring relations enhanced conversational recommender system (NR-CRS) and study how neighboring relations improve CRSs from two angles: (i) We mine preference information from neighboring conversations to enhance the modeling of user representations and learning of user preferences. (ii) We generate negative samples based on neighboring items to extend the data available for training CRSs. Experiments on the ReDial dataset show that NR-CRS outperforms the state-of-the-art baseline by 11.3%–20.6% regarding recommendation performance while generating informative and diverse responses. We also assess the capabilities of large language models (LLMs) (i.e., Llama 2, Llama 3, and Chinese-Alpaca2) for CRSs. While the generated responses exhibit enhanced fluency and informativeness, recommending target items with LLMs remains challenging; we recommend that LLMs be used as a decoding base for NR-CRS to generate relevant and informative responses.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406495284",
    "type": "article"
  },
  {
    "title": "Graph-Enhanced Prompt Learning for Cross-Domain Contract Element Extraction",
    "doi": "https://doi.org/10.1145/3715100",
    "publication_date": "2025-01-28",
    "publication_year": 2025,
    "authors": "Zihan Wang; Hanbing Wang; Pengjie Ren; Zhumin Chen; Maarten de Rijke; Zhaochun Ren",
    "corresponding_authors": "",
    "abstract": "Cross-domain contract element extraction (CEE) aims to transfer knowledge from a source domain to facilitate the extraction of legally relevant elements (e.g., contract dates or payments) from contracts in a target domain. To achieve this goal, recent studies encode the domain-invariant relations between elements and legal clause types, and enhance performance through bidirectional supervision between the CEE task and the clause classification task. However, two challenges remain unresolved: (i) data sparsity due to expensive annotation costs and a large number of element types, and (ii) label discrepancies among element types across domains, both of which severely impede effective knowledge transfer from the source to the target domain. Recent developments in prompt learning have shown promising performance in low-resource settings. Drawing inspiration from these advances, we propose a novel framework, graph-enhanced prompt learning (GEPL), for the cross-domain CEE task to address these challenges. GEPL includes two kinds of prompt: (i) instance-oriented prompts, and (ii) label-oriented prompts. Given the input instances, instance-oriented prompts are automatically generated by retrieving relevant examples in the training data, providing auxiliary supervision to enhance the transfer process in low-resource scenarios. To mitigate label discrepancies across different domains, we identify relations among element types using mutual-information criteria and transform these into label-oriented prompt templates. On this basis, a multi-task training strategy is designed to simultaneously optimize the representations of the original input sentence and prompts, enabling GEPL to better understand the tasks and capture label relations in both source and target domains. Empirical results on cross-domain CEE datasets indicate that GEPL significantly outperforms state-of-the-art baselines. Moreover, extensive experiments reveal that GEPL achieves state-of-theart performance on cross-domain named entity recognition datasets and demonstrates a high level of generalizability. Our code is released at https://github.com/WZH-NLP/GEPL .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4406903449",
    "type": "article"
  },
  {
    "title": "A Unified Prompt-aware Framework for Personalized Search and Explanation Generation",
    "doi": "https://doi.org/10.1145/3716131",
    "publication_date": "2025-02-04",
    "publication_year": 2025,
    "authors": "Haobo Zhang; Qiannan Zhu; Zhicheng Dou",
    "corresponding_authors": "",
    "abstract": "Product search is crucial for users to find and purchase products they need. Personalized product search, which models users’ search intent and provides tailored results, has become a prominent research problem in industry and academia. Recent studies often leverage knowledge graphs (KGs) to improve search performance and generate explanations for search results. However, existing KG-based methods treat search and explanation tasks separately and explore paths in KGs as explanations, creating a gap between search results and generated explanations. Also, path-formed explanations in KGs are not flexible enough to build correlations with the user’s current query. To address these challenges, we propose P-PEG, a unified prompt-aware framework for personalized product search and explanation generation. P-PEG leverages a pre-trained language model (PLM) and search signal to enhance the generation of user-understandable explanations. We introduce a prompt learning technique and design prompt generators for search and explanation generation tasks based on a fixed PLM. By incorporating search results in explanation-based prompts, we bridge the gap between search results and explanations, facilitating better interaction. Additionally, we utilize the user’s current query, historical search log, and KGs to personalize the explanations and inject task knowledge into PLM. Experimental results show that P-PEG outperforms existing methods in the explanation generation task of the three datasets and the search task of the Electronics dataset, and achieves comparable performance in the search task of the Cellphones &amp; Accessories and CD &amp; Vinyl datasets.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4407135369",
    "type": "article"
  },
  {
    "title": "Vague Preference Policy Learning for Conversational Recommendation",
    "doi": "https://doi.org/10.1145/3717831",
    "publication_date": "2025-02-20",
    "publication_year": 2025,
    "authors": "Gangyi Zhang; Chongming Gao; Wenqiang Lei; Xiaojie Guo; Shijun Li; Hongshen Chen; Zhuozhi Ding; Sulong Xu; Lingfei Wu",
    "corresponding_authors": "",
    "abstract": "Conversational recommendation systems (CRS) effectively address information asymmetry by dynamically eliciting user preferences through multi-turn interactions. However, existing CRS methods commonly assume that users have clear, definite preferences for one or multiple target items. This assumption can lead to over-trusting user feedback, treating accepts/rejects as definitive signals to filter items and reduce the candidate space, potentially causing over-filtering and excluding relevant alternatives. In reality, users often exhibit vague preferences, lacking well-defined inclinations for certain attribute types (e.g., color, pattern), and their decision-making process during interactions is rarely binary. Instead, users’ choices are relative, reflecting a range of preferences rather than strict likes or dislikes. To address this issue, we introduce a novel scenario called Vague Preference Multi-round Conversational Recommendation (VPMCR), which employs a soft estimation mechanism to assign non-zero confidence scores to all candidate items, accommodating users’ vague and dynamic preferences while mitigating over-filtering. In the VPMCR setting, we introduce a solution called Vague Preference Policy Learning (VPPL), which consists of two main components: Ambiguity-aware Soft Estimation (ASE) and Dynamism-aware Policy Learning (DPL). ASE aims to accommodate the ambiguity in user preferences by estimating preference scores for both directed and inferred preferences, employing a choice-based approach and a time-aware preference decay strategy. DPL implements a policy learning framework, leveraging the preference distribution from ASE, to guide the conversation and adapt to changes in users’ preferences for making recommendations or querying attributes. Extensive experiments conducted on diverse datasets demonstrate the effectiveness of VPPL within the VPMCR framework, outperforming existing methods and setting a new benchmark for CRS research. Our work represents a significant advancement in accommodating the inherent ambiguity and relative decision-making processes exhibited by users, improving the overall performance and applicability of CRS in real-world settings.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4407769958",
    "type": "article"
  },
  {
    "title": "Intrinsic and Extrinsic Factor Disentanglement for Recommendation in Various Context Scenarios",
    "doi": "https://doi.org/10.1145/3722553",
    "publication_date": "2025-03-18",
    "publication_year": 2025,
    "authors": "Yixin Su; Wei Jiang; Fangquan Lin; Cheng Yang; Sarah Erfani; Junhao Gan; Yunxiang Zhao; Ruixuan Li; Rui Zhang",
    "corresponding_authors": "",
    "abstract": "In recommender systems, the patterns of user behaviors (e.g., purchase, click) may vary greatly in different contexts (e.g., time and location). This is because user behavior is jointly determined by two types of factors: intrinsic factors , which reflect consistent user preference, and extrinsic factors , which reflect external incentives that may vary in different contexts. Differentiating between intrinsic and extrinsic factors helps learn user behaviors better. However, existing studies have only considered differentiating them from a single, pre-defined context (e.g., time or location), ignoring the fact that a user's extrinsic factors may be influenced by the interplay of various contexts at the same time. In this paper, we propose the Intrinsic-Extrinsic Disentangled Recommendation (IEDR) model, a generic framework that differentiates intrinsic from extrinsic factors considering various contexts simultaneously, enabling more accurate differentiation of factors and hence the improvement of recommendation accuracy. IEDR contains a context-invariant contrastive learning component to capture intrinsic factors, and a disentanglement component to extract extrinsic factors under the interplay of various contexts. The two components work together to achieve effective factor learning. Extensive experiments on real-world datasets demonstrate IEDR’s effectiveness in learning disentangled factors and significantly improving recommendation accuracy by up to 4% in NDCG.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4408564211",
    "type": "article"
  },
  {
    "title": "How Vital is the Jurisprudential Relevance: Law Article Intervened Legal Case Retrieval and Matching",
    "doi": "https://doi.org/10.1145/3725729",
    "publication_date": "2025-03-21",
    "publication_year": 2025,
    "authors": "Nuo Xu; Pinghui Wang; Zi Liang; Junzhou Zhao; Xiaohong Guan",
    "corresponding_authors": "",
    "abstract": "Legal case retrieval aims to automatically scour comparable legal cases based on a given query, which is crucial for offering relevant precedents to support the judgment in intelligent legal systems. Due to similar goals, it is often associated with a similar case matching task. To address them, a daunting challenge is assessing the uniquely defined legal-rational similarity within the judicial domain, which distinctly deviates from the semantic similarities in general text retrieval. Past works either tagged domain-specific factors or incorporated reference laws to capture legal-rational information. However, their heavy reliance on expert or unrealistic assumptions restricts their practical applicability in real-world scenarios. In this paper, we propose an end-to-end model named LCM-LAI to solve the above challenges. Through meticulous theoretical analysis, LCM-LAI employs a dependent multitask learning framework to capture legal-rational information within legal cases by a law article prediction subtask, without any additional assumptions in inference. In addition, LCM-LAI proposes an article-aware attention mechanism to evaluate the legal-rational similarity between across-case sentences based on the law distribution, which is more effective than semantic similarity. We perform a series of exhaustive experiments that include two different tasks that involving four real-world datasets. The results demonstrate that LCM-LAI achieves state-of-the-art performance.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4408692836",
    "type": "article"
  },
  {
    "title": "Learning Human Feedback from Large Language Models for Content Quality-aware Recommendation",
    "doi": "https://doi.org/10.1145/3727144",
    "publication_date": "2025-03-28",
    "publication_year": 2025,
    "authors": "Huili Wang; Chuhan Wu; Yongfeng Huang; Tao Qi",
    "corresponding_authors": "",
    "abstract": "Recommender systems are widely employed to mitigate information overload by tailoring online content to individual preferences. Existing recommendation methods typically focus on optimizing the relevance between candidate item content and user historical behaviors. However, these methods often neglect the quality of recommended content, which can negatively affect user experience and hinder the long-term growth of platforms. In fact, addressing this issue is particularly challenging, as signal on content quality feedback is typically sparse in the user interaction data (e.g., clicks) commonly used for model training. In this paper, we propose a human feedback alignment framework for recommender system (HFAR), which leverages well-aligned large language models s to simulate human feedback on content quality to enhance recommendation. Specifically, we propose a multi-task learning-based knowledge transfer framework to infuse recommendation models with an awareness of fine-grained feedback on content quality from targeted perspectives.Furthermore, we develop a contrastive learning-based feedback integration mechanism to embed targeted human feedback into the ranking strategy to enable quality-aware recommendation decision-making. Besides, we propose a multi-objective joint training framework to optimize the model jointly under utility and quality objectives. Experiments show that HFAR achieves a maximum improvement of 84.78% in recommendation quality, while maintaining both recommendation accuracy and efficiency.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4408930350",
    "type": "article"
  },
  {
    "title": "Fusing Predictive and Large Language Models for Actionable Recommendations In Creative Marketing",
    "doi": "https://doi.org/10.1145/3725885",
    "publication_date": "2025-04-09",
    "publication_year": 2025,
    "authors": "Qi Yang; Aleksandr Farseev; Marlo Ongpin; Alfred Huang; Yu-Yi Chu-Farseeva; Dong‐Ling You; Kirill Lepikhin; Sergey Nikolenko",
    "corresponding_authors": "",
    "abstract": "The opaqueness of modern digital advertising, exemplified by large platforms such as Meta Ads , raises concerns regarding their control over audience targeting, pricing structures, and ad relevancy assessments. Locked in place by network effects, these natural monopolies attract countless advertisers who rely on subjective intuition, with billions of dollars lost on ineffective social media advertisements. The platforms’ algorithms rely on huge amounts of data unavailable to advertisers, and the algorithms themselves are opaque too, so advertisers often cannot make informed decisions. To promote transparency and help individual advertisers, we first propose novel ways to optimize advertising strategies, predicting click-through rates of novel advertising content based on the content itself. However, advertisers face both opaqueness and a vast abundance of data: a large platform has so many competitor ads that it is hard to derive meaningful insights. Drawing inspiration from the success of large language models (LLM), we propose a system that merges multimodal LLMs and pretrained AI models with an emphasis on digital marketing and advertising data analysis. Leveraging the capabilities of LLMs and incorporating explainability features, including modern text-image models, we aim to improve efficiency and produce synergy between human marketers and AI systems.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4409292137",
    "type": "article"
  },
  {
    "title": "HEK-CL: Hierarchical Enhanced Knowledge-Aware Contrastive Learning for Recommendation",
    "doi": "https://doi.org/10.1145/3728463",
    "publication_date": "2025-04-08",
    "publication_year": 2025,
    "authors": "Meng Yuan; Zhao Zhang; Wei Chen; Chu Zhao; Tong Cai; Fuzhen Zhuang; Rui Liu; Deqing Wang",
    "corresponding_authors": "",
    "abstract": "Recently, there has been an emergence of self-supervised recommendation methods that integrate knowledge graphs. Upon conducting a comprehensive review of contrastive learning (CL) in recommender systems, we conclude that existing methods solely focus on data view generation (the first phase) while neglecting the equally pivotal data view alignment (the second phase). However, due to the complexity and variability of real-world graph data, regardless of the graph augmentation strategy employed, it may be unrealistic to expect all entities to benefit from contrastive learning. In this paper, we propose a H ierarchical E nhanced K nowledge-Aware C ontrastive L earning (HEK-CL) method for recommendation. Overall, we aim to hierarchically carry out enhancement strategies in both the first and second phases of knowledge-aware contrastive learning: 1) From the perspective of enhancing data view generation, we focus on combining non-Euclidean representation learning with graph denoising modules. Owing to the unified space's ability to learn the ideal curvature from data distributions, the quality of embeddings for graph data has seen enhancements; 2) From the perspective of enhancing data view alignment, we propose a hyperbolic robust contrastive loss, named HRCL. Through rigorous theoretical analysis and experiments, we demonstrate that HRCL provides a more balanced and equitable training process for all entities than InfoNCE. Numerous experiments on the three real-world datasets show that our HEK-CL outperforms state-of-the-art baselines.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4409309507",
    "type": "article"
  },
  {
    "title": "CaGE: A Causality-inspired Graph Neural Network Explainer for Recommender Systems",
    "doi": "https://doi.org/10.1145/3729224",
    "publication_date": "2025-04-10",
    "publication_year": 2025,
    "authors": "Shuo Yu; Yicong Li; Shuo Wang; Tao Tang; Qiang Zhang; Jingjing Zhou; Ivan Lee; Feng Xia",
    "corresponding_authors": "",
    "abstract": "Generating post-hoc causal explanations for graph neural network-based recommender systems is vital for enhancing the credibility and interpretability of recommendations. Existing model-agnostic explainers primarily capture statistical correlations between topological information and recommendation outcomes. However, they often fail to identify true causal relationships due to their model-agnostic design and the challenges posed by heterogeneous graph structures. To address these limitations, we propose a causality-inspired graph neural network explainer for recommender systems, namely CaGE, which generates explanations reflecting causality in recommendation scenarios without accessing the internal parameters of the recommender system. Unlike previous explainers that rely on correlation-based learning, CaGE leverages heterogeneous interventional distributions to eliminate backdoor paths of non-causal variables in the structural causal model of the recommendation task, ensuring causation is accurately captured. Specifically, CaGE incorporates backdoor adjustment based on heterogeneous interventional distributions and causal contrastive learning to optimize a set of heterogeneous soft masks that disentangle causation from non-causation. Additionally, a causality-inspired meta-path search strategy is employed to represent causation as paths between users and recommended items, further enhancing explanation readability. Extensive experiments are conducted on three recommendation datasets, and the experimental results illustrate the superior fidelity of CaGE as compared to state-of-the-art baselines.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4409330055",
    "type": "article"
  },
  {
    "title": "Causal Time-aware News Recommendations with Large Language Models",
    "doi": "https://doi.org/10.1145/3729422",
    "publication_date": "2025-04-15",
    "publication_year": 2025,
    "authors": "Sirui Huang; Qian Li; Haoran Yang; Dianer Yu; Qing Li; Guandong Xu",
    "corresponding_authors": "",
    "abstract": "Predicting user satisfaction over time is crucial in news recommendations, as users’ preferences are significantly influenced by various time-variant factors. Traditional correlation-based recommenders often suffer from redundant relationships, which can undermine their effectiveness over time. This work takes a time-aware causal approach to news recommendations, treating exposed news at a predicted time as the treatment variable and the resulting user satisfaction as the outcome variable. Capturing the evolving causal effects of exposed news items on user satisfaction poses significant challenges, particularly stemming from the need to model complex dependencies among time-variant covariates, such as news popularity and recency, as well as to effectively leverage the inherent user preferences embedded in time-invariant covariates. To these ends, we propose the CA u S al T ime-aware Rec ommender, named CAST-Rec , which accounts for the causal influences of both time-variant and time-invariant covariates. Specifically, we model the intricate causal dependencies among time-variant covariates through a series of transformer-based causal blocks. For time-invariant covariates, we utilize the semantic understanding and generative capabilities of large language models (LLMs) to infer inherent user preferences while mitigating potential confounding effects. Extensive experiments demonstrate the superior performance of CAST-Rec compared to various news recommendation models and across multiple LLM implementations.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4409478906",
    "type": "article"
  },
  {
    "title": "WebGLM: Towards an Efficient and Reliable Web-Enhanced Question Answering System",
    "doi": "https://doi.org/10.1145/3729421",
    "publication_date": "2025-04-18",
    "publication_year": 2025,
    "authors": "Hanyu Lai; Xiao Liu; Hao Yu; Yifan Xu; Iat Long Iong; Shuntian Yao; Aohan Zeng; Zhengxiao Du; Yuxiao Dong; Jie Tang",
    "corresponding_authors": "",
    "abstract": "We present WebGLM, an enhanced Large Language Model (LLM)-based retrieval question-answering system based on the ChatGLM3-6B, offering significant improvements over previous systems. We aim to augment a pre-trained LLM with web search and reliable retrieval capabilities while being efficient for real-world deployments. Leveraging LLM’s in-context learning ability and a robust filter strategy, we create a high-quality training dataset and address the hallucination issue with a self-check mechanism. Our base model, ChatGLM3-6B, excels in extracting critical information and generating desired responses. We tackle the decline in retrieval effectiveness for complex queries with a keywording technique and incorporate more web content for references. We align with user preferences by training a human preference-aware scorer and employing DPO training for direct alignment. Extensive experiments, including human evaluations and the Turing test, demonstrate WebGLM’s superior performance against leading web-enhanced question-answering systems, significantly enhancing performance and efficiency. The code, demo, and data are at https://github.com/THUDM/WebGLM .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4409572830",
    "type": "article"
  },
  {
    "title": "Causal Structure Representation Learning of Unobserved Confounders in Latent Space for Recommendation",
    "doi": "https://doi.org/10.1145/3731447",
    "publication_date": "2025-04-22",
    "publication_year": 2025,
    "authors": "Hangtong Xu; Yuanbo Xu; Chaozhuo Li; Fuzhen Zhuang",
    "corresponding_authors": "",
    "abstract": "Inferring user preferences from users’ historical feedback is a valuable problem in recommender systems. Conventional approaches often rely on the assumption that user preferences in the feedback data are equivalent to the real user preferences without additional noise, which simplifies the problem modeling. However, there are various confounders during user-item interactions, such as weather and even the recommendation system itself. Therefore, neglecting the influence of confounders will result in inaccurate user preferences and suboptimal performance of the model. Furthermore, the unobservability of confounders poses a challenge in further addressing the problem. Along these lines, we refine the problem and propose a more rational solution to mitigate the influence of unobserved confounders. Specifically, we consider the influence of unobserved confounders, disentangle them from user preferences in the latent space, and employ causal graphs to model their interdependencies without specific labels. By ingeniously combining local and global causal graphs, we capture the user-specific effects of confounders on user preferences. Finally, we propose our model based on Variational Autoencoders, named C ausal S tructure A ware V ariational A uto e ncoders (CSA-VAE) and theoretically demonstrate the identifiability of the obtained causal graph. We conducted extensive experiments on one synthetic dataset and nine real-world datasets with different scales, including three unbiased datasets and six normal datasets, where the average performance boost against several state-of-the-art baselines achieves up to 9.55%, demonstrating the superiority of our model. Furthermore, users can control their recommendation list by manipulating the learned causal representations of confounders, generating potentially more diverse recommendation results. Our code is available at Code-link 1 .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4409667646",
    "type": "article"
  },
  {
    "title": "Beyond Sequential Patterns: Rethinking Healthcare Predictions with Contextual Insights",
    "doi": "https://doi.org/10.1145/3733234",
    "publication_date": "2025-04-29",
    "publication_year": 2025,
    "authors": "Chuang Zhao; Hui Tang; Hongke Zhao; Xiaomeng Li",
    "corresponding_authors": "",
    "abstract": "Healthcare predictions, such as readmission prediction, stand as a cornerstone of societal well-being, exerting a profound influence on individual health outcomes and communal vitality. Existing research primarily employs advanced graph neural networks and sequential algorithms for patient modeling, with a focus on discerning the connections and sequential patterns inherent in Electronic Health Records (EHRs). However, the heterogeneity of entity interactions, the locality of EHR data, and the oversight of target relevance hinder further improvements. To address these limitations, we introduce a novel framework B eyond S equential P atterns (BSP), which facilitates precise healthcare predictions by incorporating tri-contextual information. Specifically, we establish a symptom-driven hypergraph network with four semantic hyperedges tailored to the intricacies of the healthcare scenario, such as ontology. This serves as a global context, tracking the heterogeneous entity collaboration within and across patients. Moreover, we construct an extensive knowledge graph leveraging existing medical databases and large language models. By sampling and refining knowledge subgraphs as local context, we bolster the semantic associations of medical entities from closed-set EHR data to the open world. Finally, we introduce the candidate context, an explicit entity-relation loss. It enforces the neighbor consistency between the target and the representation during optimization, thus accounting for correlations among targets. Extensive experiments and rigorous robustness analysis on five tasks derived from four large medical datasets underscore the BSP’s superiority over the leading baselines, with improvements of 11%, 3%, 11%, 3.5%, and 2% across five tasks, demonstrating the efficacy of incorporating diverse contexts.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4409917894",
    "type": "article"
  },
  {
    "title": "Emotion-aware Personalized Music Recommendation with a Heterogeneity-aware Deep Bayesian Network",
    "doi": "https://doi.org/10.1145/3733233",
    "publication_date": "2025-04-29",
    "publication_year": 2025,
    "authors": "Erkang Jing; Yezheng Liu; Yidong Chai; Shuo Yu; Longshun Liu; Y. V. Jiang; Yang Wang",
    "corresponding_authors": "",
    "abstract": "Music recommender systems play a critical role in music streaming platforms by providing users with music that they are likely to enjoy. Recent studies have shown that user emotions can influence users’ preferences for music moods. However, existing emotion-aware music recommender systems (EMRSs) explicitly or implicitly assume that users’ actual emotional states expressed through identical emotional words are homogeneous. They also assume that users’ music mood preferences are homogeneous under the same emotional state. In this article, we propose four types of heterogeneity that an EMRS should account for: emotion heterogeneity across users, emotion heterogeneity within a user, music mood preference heterogeneity across users, and music mood preference heterogeneity within a user. We further propose a Heterogeneity-aware Deep Bayesian Network (HDBN) to model these assumptions. The HDBN mimics a user’s decision process of choosing music with four components: personalized prior user emotion distribution modeling, posterior user emotion distribution modeling, user grouping, and Bayesian neural network-based music mood preference prediction. We constructed two datasets, called EmoMusicLJ and EmoMusicLJ-small, to validate our method. Extensive experiments demonstrate that our method significantly outperforms baseline approaches on metrics of HR, Precision, NDCG, and MRR. Ablation studies and case studies further validate the effectiveness of our HDBN. The source code and datasets are available at https://github.com/jingrk/HDBN .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4409919933",
    "type": "article"
  },
  {
    "title": "TFGIN: Tight-Fitting Graph Inference Network for Table-based Fact Verification",
    "doi": "https://doi.org/10.1145/3734520",
    "publication_date": "2025-05-06",
    "publication_year": 2025,
    "authors": "Lianwei Wu; Kang Wang; Kunlin Nie; Sensen Guo; Chao Gao; Zhen Wang; Shudong Li",
    "corresponding_authors": "",
    "abstract": "Fact verification task has emerged as an essential research topic recently due to abundant fake news spreading on the Internet. The task based on unstructured data (i.e., news) has achieved great development, but the task based on structured data (i.e., table) is still in the primary development period. The existing methods usually construct complete heterogeneous graph networks around statement, table, and program subgraphs, and then infer to learn similar semantics on them for fact verification. However, they generally connect the nodes with the same content between subgraphs directly to frame a larger graph network, which has serious sparsity in connections, especially when subgraphs possess limited semantics. To this end, we propose tight-fitting graph inference network (TFGIN), which innovatively builds tight-fitting graphs (TF-graph) to strengthen the connections of subgraphs, and designs inference modeling layer (IML) to learn coherence evidence for fact verification. Specifically, different from traditional connection ways, the constructed TF-graph enhances inter-graph and intra-graph connections of subgraphs through subgraph segmentation and interaction guidance mechanisms. Inference modeling layer could reason the semantics with strong correlation and high consistency as explainable evidence. Experiments on three competitive datasets confirm the superiority and scalability of our TFGIN.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4410118875",
    "type": "article"
  },
  {
    "title": "Efficient Multi-task Prompt Tuning for Recommendation",
    "doi": "https://doi.org/10.1145/3736403",
    "publication_date": "2025-05-19",
    "publication_year": 2025,
    "authors": "Ting Bai; Le Huang; Yue Yu; Cheng Yang; Chao-Ju Hou; Zhe Zhao; Chuan Shi",
    "corresponding_authors": "",
    "abstract": "With the expansion of business scenarios, real recommender systems are facing challenges in dealing with the constantly emerging new tasks in multi-task learning frameworks. In this article, we attempt to improve the generalization ability of multi-task recommendations when dealing with new tasks. A novel two-stage prompt-tuning MTL framework (MPT-Rec) is proposed to address task irrelevance and training efficiency problems in multi-task recommender systems. Specifically, we disentangle the task-specific and task-sharing information in the multi-task pre-training stage and then use task-aware prompts to transfer knowledge from other tasks to the new task effectively. By freezing parameters in the pre-training tasks, MPT-Rec solves the negative impacts that may be brought by the new task and greatly reduces the training costs. Extensive experiments on three real-world datasets show the effectiveness of our proposed multi-task learning framework. MPT-Rec achieves the best performance compared to the SOTA multi-task learning method on three real-world datasets. Besides, it maintains comparable model performance but vastly improves the training efficiency (i.e., with up to 10% parameters in the full-training way) in the new task learning. Our code is publicly available at https://github.com/BAI-LAB/MPT-Rec .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4410502499",
    "type": "article"
  },
  {
    "title": "Genomics-Enhanced Cancer Risk Prediction for Personalized LLMs-Driven Healthcare Recommender Systems",
    "doi": "https://doi.org/10.1145/3745022",
    "publication_date": "2025-06-20",
    "publication_year": 2025,
    "authors": "Kezhi Lu; Jie Lü; Hanshi Xu; Kairui Guo; Qian Zhang; Hua Lin; Mark Grosser; Yi Zhang; Guangquan Zhang",
    "corresponding_authors": "",
    "abstract": "Cancer risk prediction is a cornerstone of personalized medicine that offers opportunities for early detection and preventive interventions. However, the current models are designed to predict cancer risk face several challenges. First, most rely on traditional statistical methods, which struggle to capture the complexity of genetic, family medical history, and lifestyle factors. Hence, the accuracy of these models is limited. Additionally, the models neglect to integrate multidimensional data sources, particularly genetic information like single nucleotide polymorphisms (SNPs), which could enhance prediction accuracy. Third, while the system might effectively predict risk, it cannot translate those predictions into actionable healthcare recommendations to reduce cancer risk. In this study, we address all three of these limitations. With a focus on six prevalent cancers – we extracted SNPs data from the UK Biobank and designed a novel risk prediction model for cancer and personalized healthcare recommendations based upon the mixture of experts (MoE) paradigm and large language models (LLMs) respectively. Named MoE-HRS, experts based two router networks for separate processing by the Transformer and the convolutional neural network (CNN). Experiments on UK Biobank data show that our model outperforms state-of-the-art cancer risk prediction models. To bridge the gap between risk prediction and practical healthcare applications, we devised a healthcare recommender system powered by LLMs. This approach holds promise for enhancing early detection rates and promoting preventive healthcare management 1 .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4411489267",
    "type": "article"
  },
  {
    "title": "Utilizing Large Language Model for Conversational Information Seeking via Dual-Query Generation and Joint-Encoding",
    "doi": "https://doi.org/10.1145/3742423",
    "publication_date": "2025-06-25",
    "publication_year": 2025,
    "authors": "Junmei Wang; Fengjing Zhang; X.X. Chen; Pengjun He; Ellen Anne Huang; Jimmy Xiangji Huang",
    "corresponding_authors": "",
    "abstract": "Conversational retrieval leverages multi-turn conversations to meet users’ information needs, and accurately understanding the new intent has become a significant challenge in this field. Recently, the language comprehension and reasoning capabilities of large language models offer a viable solution to these challenges. In this paper, we propose a new Dual-Query Generation and Joint-Encoding method by utilizing Large Language Model for Conversational Information Seeking, abbreviated as DQ-CIS. Specifically, we propose a dual-query generation approach that leverages both open-source and closed-source large language models (LLMs) to generate two complementary queries: a full-rewrite query that preserves the context semantics of the conversation and a condensed-rewrite query that emphasizes the core intent of the current query. Additionally, to better express the semantic information of the query, we propose a dual-query joint-encoding method, which enhances the thematic expression of query vectors by treating the dual-query as semantic complementary. A query coverage fine-tuned semantic matching method is also introduced to improve result relevance and ranking by fine-tuning the original retrieval scores by ColBERT. We conducted a number of experiments on seven publicly available conversational retrieval datasets. The results show that compared with other models, DQ-CIS has strong competitiveness in both retrieval efficiency and retrieval results.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4411644201",
    "type": "article"
  },
  {
    "title": "Semantic Relation Guided Dual-view Contrastive Learning for Session-based Recommendations",
    "doi": "https://doi.org/10.1145/3750724",
    "publication_date": "2025-07-30",
    "publication_year": 2025,
    "authors": "Qian Zhang; Shoujin Wang; Longbing Cao; Defu Lian; Haibo Zhang; Wenpeng Lü",
    "corresponding_authors": "",
    "abstract": "Session-based Recommender Systems (SBRSs) aim to recommend the next item to users based on their historical interactions with items within or between sessions. A session is constituted by a sequence of interactions between the user and items within a continuous period. Existing SBRSs often focus on modeling co-occurrence-based inter-item transitions within or between sessions only. They generally overlook intrinsic inter-item semantic relations. Specifically, in practice, many items are substitutable or complementary to each other. Such relations provide significant signals to guide user interaction behaviours as well as the next-item recommendations. Moreover, existing works overlook the fact that user behaviours are driven simultaneously by both user intent and item attributes, failing to consider the implicit item characteristics embedded within. Such practice leads to entangled user intent and latent item characteristics, bringing unnecessary interference between these two aspects, impeding accurate modeling of each aspect, ultimately significantly impeding recommendation performance. To bridge these gaps, we propose a novel framework called S emantic relation guided dual-view C ontrastive L earning for S ession-based R ecommendations (SCL-SR). SCL-SR introduces a novel semantic relation-guided contrastive learning module to capture additional supervision signals from both user intent view and item attribute view to guide the next-item prediction better. Then, we propose a novel intent-attribute disentangler to effectively mitigate the interference between user intent and latent item characteristics for further improving the recommendation performance. Extensive experiments on three real-world datasets demonstrate the significant superiority of SCL-SR over the state-of-the-art approaches, including achieving substantial improvements ranging from 7.10% to 12.82% on the Tmall dataset 1 .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4412812712",
    "type": "article"
  },
  {
    "title": "Causal Variational Inference for Deconfounded Multi-Behavior Recommendation",
    "doi": "https://doi.org/10.1145/3745023",
    "publication_date": "2025-07-08",
    "publication_year": 2025,
    "authors": "Yuzhe Chen; Jie Cao; Youquan Wang; Jia Wu; Huanhuan Chen; Guandong Xu",
    "corresponding_authors": "",
    "abstract": "Multi-Behavior Recommendation (MBR) aims to model personalized user preferences by integrating diverse interaction behaviors (e.g., page view, favorite, add to cart, purchase). However, latent confounders such as contextual influences and social relationships can obscure the true causal effects in real-world scenarios, thereby confounding the model’s prediction. Although existing MBR research extensively explores behavioral dependencies and heterogeneity, it frequently overlooks the impact of latent confounders, thereby limiting its ability to capture users’ genuine preferences. To address the limitations of existing methods, we identify two key challenges in MBR: (1) how to infer latent confounders, and (2) how to mitigate their influence across multi-behavior interactions. To this end, we propose Causal Variational Inference for Deconfounded (CVID) MBR. CVID employs a variational graph autoencoder to model latent uncertainty in multi-behavior interactions and introduces a confounder inference module to generate behavior-specific latent confounders via variational inference. In the conditional diffusion module, noise is progressively injected during the forward process to simulate the dynamic evolution of user preferences, while the reverse process leverages the inferred latent confounders to guide denoising through back-door adjustment, thereby recovering the true causal effects between multi-behavior interactions and the model’s prediction. Extensive experiments on public multi-behavior datasets demonstrate that CVID consistently outperforms state-of-the-art baselines in mitigating confounding effects and improving recommendation accuracy, validating its effectiveness and superiority.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4414159289",
    "type": "article"
  },
  {
    "title": "Peer-to-peer data trading to preserve information",
    "doi": "https://doi.org/10.1145/506309.506310",
    "publication_date": "2002-04-01",
    "publication_year": 2002,
    "authors": "Brian F. Cooper; Héctor García-Molina",
    "corresponding_authors": "",
    "abstract": "Data archiving systems rely on replication to preserve information. This paper discusses how a network of autonomous archiving sites can trade data to achieve the most reliable replication. A series of binary trades among sites produces a peer-to-peer archiving network. Two trading algorithms are examined, one based on trading collections (even if they are different sizes) and another based on trading equal sized blocks of space (which can then store collections). The concept of deeds is introduced; deeds track the blocks of space owned by one site at another. Policies for tuning these algorithms to provide the highest reliability, for example by changing the order in which sites are contacted and offered trades, are discussed. Finally, simulation results are presented that reveal which policies are best. The experiments indicate that a digital archive can achieve the best reliability by trading blocks of space (deeds), and that following certain policies will allow that site to maximize its reliability.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2027807428",
    "type": "article"
  },
  {
    "title": "Local versus global link information in the Web",
    "doi": "https://doi.org/10.1145/635484.635486",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Pável Calado; Berthier Ribeiro‐Neto; Nívio Ziviani; Edleno Silva de Moura; Ilmério Silva",
    "corresponding_authors": "",
    "abstract": "Information derived from the cross-references among the documents in a hyperlinked environment, usually referred to as link information, is considered important since it can be used to effectively improve document retrieval. Depending on the retrieval strategy, link information can be local or global. Local link information is derived from the set of documents returned as answers to the current user query. Global link information is derived from all the documents in the collection. In this work, we investigate how the use of local link information compares to the use of global link information. For the comparison, we run a series of experiments using a large document collection extracted from the Web. For our reference collection, the results indicate that the use of local link information improves precision by 74&amp;percnt;. When global link information is used, precision improves by 35&amp;percnt;. However, when only the first 10 documents in the ranking are considered, the average gain in precision obtained with the use of global link information is higher than the gain obtained with the use of local link information. This is an interesting result since it provides insight and justification for the use of global link information in major Web search engines, where users are mostly interested in the first 10 answers. Furthermore, global information can be computed in the background, which allows speeding up query processing.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W2031317221",
    "type": "article"
  },
  {
    "title": "Natural-language retrieval of images based on descriptive captions",
    "doi": "https://doi.org/10.1145/230538.230539",
    "publication_date": "1996-07-01",
    "publication_year": 1996,
    "authors": "Eugene J. Guglielmo; Neil C. Rowe",
    "corresponding_authors": "",
    "abstract": "We describe a prototype intelligent information retrieval system that uses natural-language understanding to efficiently locate captioned data. Multimedia data generally require captions to explain their features and significance. Such descriptive captions often rely on long nominal compounds (strings of consecutive nouns) which create problems of disambiguating word sence. In our system, captions and user queries are parsed and interpreted to produce a logical form using a detailed theory of the meaning of nominal compounds. A fine-grain match can then compare the logical form of the query to the logical forms for each caption. To improve system efficiency, we first perform a coarse-grain match with index files, using nouns and verbs extracted from the query. Our experiments with randomly selected queries and captions from an existing image library show an increase of 30% in precision and 50% in recall over the keyphrase approach currently used. Our processing times have a median of seven seconds as compared to eight minutes for the existing system, and our system is much easier to use.",
    "cited_by_count": 64,
    "openalex_id": "https://openalex.org/W2122840266",
    "type": "article"
  },
  {
    "title": "Beneath the surface of organizational processes",
    "doi": "https://doi.org/10.1145/358108.358111",
    "publication_date": "2000-10-01",
    "publication_year": 2000,
    "authors": "Gary Katzenstein; F. Javier Lerch",
    "corresponding_authors": "",
    "abstract": "This paper raises the question, “What is an effective representation framework for organizational process design?” By combining our knowledge of existing process models with data from a field study, the paper develops criteria for an effective process representation. Using these criteria and the case study, the paper integrates the process redesign and information system literatures to develop a representation framework that captures a process' social context. The paper argues that this social context framework, which represents people's motivations, social relationships, and social constraints, gives redesigners a richer sense of the process and allows process redesigners to simultaneously change social and logistic systems. The paper demonstrates the framework and some of its benefits and limitations.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W1982264970",
    "type": "article"
  },
  {
    "title": "Recursive hashing functions for <i>n</i> -grams",
    "doi": "https://doi.org/10.1145/256163.256168",
    "publication_date": "1997-07-01",
    "publication_year": 1997,
    "authors": "Jonathan Cohen",
    "corresponding_authors": "Jonathan Cohen",
    "abstract": "Many indexing, retrieval, and comparison methods are based on counting or cataloguing n -grams in streams of symbols. The fastest method of implementing such operations is through the use of hash tables. Rapid hashing of consecutive n -grams is best done using a recursive hash function, in which the hash value of the current n -gram is drived from the hash value of its predecessor. This article generalizes recursive hash functions found in the literature and proposes new methods offering superior performance. Experimental results demonstrate substantial speed improvement over conventional approaches, while retaining near-ideal hash value distribution.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W1984081611",
    "type": "article"
  },
  {
    "title": "Fractal views",
    "doi": "https://doi.org/10.1145/203052.203065",
    "publication_date": "1995-07-01",
    "publication_year": 1995,
    "authors": "Hideki Koike",
    "corresponding_authors": "Hideki Koike",
    "abstract": "Computer users often must view large amounts of information through video displays which are physically limited in size. Although some methods, which automatically display/erase information units based on their degrees of importance, have been proposed, they lack an ability to keep the total amount of displayed information nearly constant. We propose a new method for information display based on fractal theory. By regarding the information structures used in computers as complex objects, we can abstract these objects as well as control their amount. Using our method, (1) the total amount of information is kept nearly constant even when users change their focuses of attention and (2) this amount can be set flexibly. Through mathematical analysis, we show our method's ability to control the amount. An application to program display is also shown. When this method is applied to the display of structured programs, it provides fisheye-like views which integrate local details around the focal point and major landmarks further away.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2002163217",
    "type": "article"
  },
  {
    "title": "Computing graphical queries over XML data",
    "doi": "https://doi.org/10.1145/502795.502797",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Sara Comai; Ernesto Damiani; Piero Fraternali",
    "corresponding_authors": "",
    "abstract": "The rapid evolution of XML from a mere data exchange format to a universal syntax for encoding domain-specific information raises the need for new query languages specifically conceived to address the characteristics of XML. Such languages should be able not only to extract information from XML documents, but also to apply powerful transformation and restructuring operators, based on a well-defined semantics. Moreover, XML queries should be natural to write and understand, as nontechnical persons also are expected to access the large XML information bases supporting their businesses. This article describes XML-GL, a graphical query language for XML data. XML-GL's uniqueness is in the definition of a graph-based syntax to express a wide variety of XML queries, ranging from simple selections to expressive data transformations involving grouping, aggregation, and arithmetic calculations. XML-GL has an operational semantics based on the notion of graph matching, which serves as a guideline both for the implementation of native processors, and for the adoption of XML-GL as a front-end to any of the XML query languages that are presently under discussion as the standard paradigm for querying XML data.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W2010265760",
    "type": "article"
  },
  {
    "title": "Improving retrieval feedback with multiple term-ranking function combination",
    "doi": "https://doi.org/10.1145/568727.568728",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Claudio Carpineto; Giovanni Romano; Vittorio Giannini",
    "corresponding_authors": "",
    "abstract": "In this article we consider methods for automatic query expansion from top retrieved documents (i.e., retrieval feedback) that make use of various functions for scoring expansion terms within Rocchio's classical reweighting scheme. An analytical comparison shows that the retrieval performance of methods based on distinct term-scoring functions is comparable on the whole query set but differs considerably on single queries, consistent with the fact that the ordered sets of expansion terms suggested for each query by the different functions are largely uncorrelated. Motivated by these findings, we argue that the results of multiple functions can be merged, by analogy with ensembling classifiers, and present a simple combination technique based on the rank values of the suggested terms. The combined retrieval feedback method is effective not only with respect to unexpanded queries but also to any individual method, with notable improvements on the system's precision. Furthermore, the combined method is robust with respect to variation of experimental parameters and it is beneficial even when the same information needs are expressed with shorter queries.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W1974782086",
    "type": "article"
  },
  {
    "title": "Structured hypertext with domain semantics",
    "doi": "https://doi.org/10.1145/291128.291132",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "Weigang Wang; Roy Rada",
    "corresponding_authors": "",
    "abstract": "One important facet of current hypertext research involves using knowledge-based techniques to develop and maintain document structures. A semantic net is one such technique. However, most semantic-net-based hypertext systems leave the linking consistency of the net to individual users. Users without guidance may accidentally introduce structural and relational inconsistencies in the semantic nets. The relational inconsistency hinders the creation of domain information models. The structural inconsistency leads to unstable documents, especially when a document is composed by computation with traversal algorithms. This work tackles to above problems by integrating logical structure and domain semantics into a semantic net. A semantic-net-based structured-hypertext model has been formalized. The model preserves structural and relational consistency after changes to the semantic net. The hypertext system (RICH) based on this model has been implemented and tested. The RICH system can define and enforce a set of rules to maintain to integrity of the semantic net and provide particular support for creating multihierarchies with the reuse of existing contents and structures. Users have found such flexible but enforceable semantics to be helpful.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W1989452229",
    "type": "article"
  },
  {
    "title": "Building a distributed full-text index for the web",
    "doi": "https://doi.org/10.1145/502115.502116",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Sergey Melink; Sriram Raghavan; Beverly Yang; Héctor García-Molina",
    "corresponding_authors": "",
    "abstract": "We identify crucial design issues in building a distributed inverted index for a large collection of Web pages. We introduce a novel pipelining technique for structuring the core index-building system that substantially reduces the index construction time. We also propose a storage scheme for creating and managing inverted files using an embedded database system. We suggest and compare different strategies for collecting global statistics from distributed inverted indexes. Finally, we present performance results from experiments on a testbed distributed Web indexing system that we have implemented.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W3003506064",
    "type": "article"
  },
  {
    "title": "PROXHY",
    "doi": "https://doi.org/10.1145/119311.119315",
    "publication_date": "1991-10-01",
    "publication_year": 1991,
    "authors": "Charles J. Kacmar; John J. Leggett",
    "corresponding_authors": "",
    "abstract": "article Free AccessPROXHY: a process-oriented extensible hypertext architecture Authors: Charles J. Kacmar Florida State Univ., Tallahassee Florida State Univ., TallahasseeView Profile , John J. Leggett Texas A & M Univ., College Station Texas A & M Univ., College StationView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 9Issue 4pp 399–419https://doi.org/10.1145/119311.119315Published:01 October 1991Publication History 42citation354DownloadsMetricsTotal Citations42Total Downloads354Last 12 Months10Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W1964786194",
    "type": "article"
  },
  {
    "title": "Order-preserving minimal perfect hash functions and information retrieval",
    "doi": "https://doi.org/10.1145/125187.125200",
    "publication_date": "1991-07-01",
    "publication_year": 1991,
    "authors": "Edward A. Fox; Qi Fan Chen; Amjad M. Daoud; Lenwood S. Heath",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Order-preserving minimal perfect hash functions and information retrieval Authors: Edward A. Fox Virginia Polytechnic Institute and State Univ., Blacksburg Virginia Polytechnic Institute and State Univ., BlacksburgView Profile , Qi Fan Chen Virginia Polytechnic Institute and State Univ., Blacksburg Virginia Polytechnic Institute and State Univ., BlacksburgView Profile , Amjad M. Daoud Virginia Polytechnic Institute and State Univ., Blacksburg Virginia Polytechnic Institute and State Univ., BlacksburgView Profile , Lenwood S. Heath Virginia Polytechnic Institute and State Univ., Blacksburg Virginia Polytechnic Institute and State Univ., BlacksburgView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 9Issue 3July 1991 pp 281–308https://doi.org/10.1145/125187.125200Online:01 July 1991Publication History 38citation1,246DownloadsMetricsTotal Citations38Total Downloads1,246Last 12 Months104Last 6 weeks19 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2059417738",
    "type": "article"
  },
  {
    "title": "Ad Hoc, self-supervising peer-to-peer search networks",
    "doi": "https://doi.org/10.1145/1059981.1059983",
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "Brian F. Cooper; Héctor García-Molina",
    "corresponding_authors": "",
    "abstract": "Peer-to-peer search networks are a popular and widely deployed means of searching massively distributed digital information repositories. Unfortunately, as such networks grow, peers may become overloaded processing messages from other peers. This article examines how to reduce the load on nodes in P2P networks by allowing them to self-organize into a relatively efficient network, and then self-tune to make the network even more efficient. Two local operations used by a peer are introduced: connect() , in which the peer forms an ad hoc search or index link to another peer, and break() , in which the peer breaks a link that is producing too much load. By replacing fixed rules with dynamic local decision-making, such “self-supervising” networks can better adjust to network conditions. Different ways to implement connect() and break() are described, and the network structures that form under different configurations are examined. Simulation results indicate that the ad hoc networks formed using the described techniques are more efficient than popular supernode topologies for several important scenarios. Results for the fault tolerance and search latency of such ad hoc networks are also presented.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2030544494",
    "type": "article"
  },
  {
    "title": "Region proximity in metric spaces and its use for approximate similarity search",
    "doi": "https://doi.org/10.1145/763693.763696",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "Giuseppe Amato; Fausto Rabitti; Pasquale Savino; Pavel Zezula",
    "corresponding_authors": "",
    "abstract": "Similarity search structures for metric data typically bound object partitions by ball regions. Since regions can overlap, a relevant issue is to estimate the proximity of regions in order to predict the number of objects in the regions' intersection. This paper analyzes the problem using a probabilistic approach and provides a solution that effectively computes the proximity through realistic heuristics that only require small amounts of auxiliary data. An extensive simulation to validate the technique is provided. An application is developed to demonstrate how the proximity measure can be successfully applied to the approximate similarity search. Search speedup is achieved by ignoring data regions whose proximity to the query region is smaller than a user-defined threshold. This idea is implemented in a metric tree environment for the similarity range and \"nearest neighbors\" queries. Several measures of efficiency and effectiveness are applied to evaluate proposed approximate search algorithms on real-life data sets. An analytical model is developed to relate proximity parameters and the quality of search. Improvements of two orders of magnitude are achieved for moderately approximated search results. We demonstrate that the precision of proximity measures can significantly influence the quality of approximated algorithms.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2157727297",
    "type": "article"
  },
  {
    "title": "iVIBRATE",
    "doi": "https://doi.org/10.1145/1148020.1148024",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Keke Chen; Ling Liu",
    "corresponding_authors": "",
    "abstract": "With continued advances in communication network technology and sensing technology, there is astounding growth in the amount of data produced and made available through cyberspace. Efficient and high-quality clustering of large datasets continues to be one of the most important problems in large-scale data analysis. A commonly used methodology for cluster analysis on large datasets is the three-phase framework of sampling/summarization, iterative cluster analysis, and disk-labeling. There are three known problems with this framework which demand effective solutions. The first problem is how to effectively define and validate irregularly shaped clusters, especially in large datasets. Automated algorithms and statistical methods are typically not effective in handling these particular clusters. The second problem is how to effectively label the entire data on disk (disk-labeling) without introducing additional errors, including the solutions for dealing with outliers, irregular clusters, and cluster boundary extension. The third obstacle is the lack of research about issues related to effectively integrating the three phases. In this article, we describe iVIBRATE---an interactive visualization-based three-phase framework for clustering large datasets. The two main components of iVIBRATE are its VISTA visual cluster-rendering subsystem which invites human interplay into the large-scale iterative clustering process through interactive visualization, and its adaptive ClusterMap labeling subsystem which offers visualization-guided disk-labeling solutions that are effective in dealing with outliers, irregular clusters, and cluster boundary extension. Another important contribution of iVIBRATE development is the identification of the special issues presented in integrating the two components and the sampling approach into a coherent framework, as well as the solutions for improving the reliability of the framework and for minimizing the amount of errors generated within the cluster analysis process. We study the effectiveness of the iVIBRATE framework through a walkthrough example dataset of a million records and we experimentally evaluate the iVIBRATE approach using both real-life and synthetic datasets. Our results show that iVIBRATE can efficiently involve the user in the clustering process and generate high-quality clustering results for large datasets.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2055141025",
    "type": "article"
  },
  {
    "title": "A distributed object-oriented database system supporting shared and private databases",
    "doi": "https://doi.org/10.1145/103731.103733",
    "publication_date": "1991-01-03",
    "publication_year": 1991,
    "authors": "Won Bae Kim; Nat Ballou; Jorge F. Garza; Darrell Woelk",
    "corresponding_authors": "",
    "abstract": "ORION-2 is a commercially available, federated, object-oriented database management system designed and implemented at MCC. One major architectural innovation in ORION-2 is the coexistence of a shared databese and a number of private databases. The shared database is accessible to all authorized users of the system, while each private database is accessible to only the user who owns it. A distributed database system with a shared database and private databases for individual users is a natural architecture for data-intensive application environments on a network of workstations, notably computer-aided design and engineering systems. This paper discusses the benefits and limitations of such a system and explores the impact of such an architecture on the semantics and implementation of some of the key functions of a database system, notably queries, database schema, and versions. Although the issues are discussed in the context of an object-oriented data model, the results (at least significant portions thereof) are applicable to database systems supporting other data models.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2073034409",
    "type": "article"
  },
  {
    "title": "Experiments with a component theory of probabilistic information retrieval based on single terms as document components",
    "doi": "https://doi.org/10.1145/102675.102677",
    "publication_date": "1990-10-01",
    "publication_year": 1990,
    "authors": "K. L. Kwok",
    "corresponding_authors": "K. L. Kwok",
    "abstract": "A component theory of information retrieval using single content terms as component for queries and documents was reviewed and experimented with. The theory has the advantages of being able to (1) bootstrap itself, that is, define initial term weights naturally based on the fact that items are self relevent; (2) make use of within-item term frequencies; (3) account for query-focused and document-focused indexing and retrieval strategies cooperatively; and (4) allow for component-specific feedback if such information is available. Retrieval results with four collections support the effectiveness of all the first three aspects, except for predictive retrieval. At the initial indexing stage, the retrieval theory performed much more consistantly across collections than croft's model and provided results comparable to Salton's tf*idf approach. An inverse collection term frequency (ICTF) formula was also tested that performed much better than the inverse document frequency (IDF). With full feedback retrospective retrieval, the component theory performed substantially better than Croft's, because of the highly specific nature of document-focused feedback. Repetitive retireval results with partial relevance feedback mirrored those for the retrospective. However, for the important case of predictive retrieval using residual ranking, results were not unequivocal.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2028747520",
    "type": "article"
  },
  {
    "title": "User evaluation of Físchlár-News",
    "doi": "https://doi.org/10.1145/1148020.1148021",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Hyowon Lee; Alan F. Smeaton; Noel E. O’Connor; Barry Smyth",
    "corresponding_authors": "",
    "abstract": "Technological developments in content-based analysis of digital video information are undergoing much progress, with ideas for fully automatic systems now being proposed and demonstrated. Yet because we do not yet have robust operational video retrieval systems that can be deployed and used, the usual HCI practise of conducting a usage study and an informed iterative system design is thus not possible. Físchlár-News is one of the first automatic, content-based broadcast news analysis and archival systems that process broadcast news video so that users can search, browse, and play it in an easy-to-use manner with a conventional web browser. The system incorporates a number of state-of-the-art research components, some of which are not yet considered mature technology, yet it has been built to be robust enough to be deployed to users who are interested in access to daily news throughout a university campus. In this article we report and discuss a user-evaluation study conducted with 16 users, each of whom utilized the system freely for a one month period. Results from a detailed qualitative analysis are presented, looking at collected questionnaires, incident diaries, and interaction-log data. The findings suggest that our users employed the system in conjunction with their other news update methods, such as watching TV news at home and browsing online news websites at their workplace, their major concerns being up-to-dateness and coverage of the news content. They tried to accommodate the system to fit their established web browsing habits, and they found local news content and the ability to play self-contained news stories on their desktop as major values of the system. Our study also resulted in a detailed wishlist of new features which will help in the further development of both our and others' systems.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2031869261",
    "type": "article"
  },
  {
    "title": "Supporting distributed office problem solving in organizations",
    "doi": "https://doi.org/10.1145/214427.214428",
    "publication_date": "1986-07-01",
    "publication_year": 1986,
    "authors": "Carson Woo; Frederick H. Lochovsky",
    "corresponding_authors": "",
    "abstract": "To improve the effectiveness of office workers in their decision making, office systems have been built to support (rather than replace) their judgment. However, these systems model office work in a centralized environment, and/or they can only support a single office worker. Office work that is divided into specialized domains handled by different office workers (where cooperation is needed in order to accomplish the work) is not supported. In this paper, we will present a model that supports office problem solving in a logically distributed environment. (In some systems, information is geographically distributed for performance purposes rather than for conceptual need. The term, logically , is therefore used to indicate the logical need of organizing information without having to worry about the physical location of the information.) In particular, cooperative tools that can be used to support office workers during the process of their problem solving is discussed.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W1982568283",
    "type": "article"
  },
  {
    "title": "Taxonomy generation for text segments",
    "doi": "https://doi.org/10.1145/1095872.1095873",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Shui‐Lung Chuang; Lee‐Feng Chien",
    "corresponding_authors": "",
    "abstract": "It is crucial in many information systems to organize short text segments, such as keywords in documents and queries from users, into a well-formed taxonomy. In this article, we address the problem of taxonomy generation for diverse text segments with a general and practical approach that uses the Web as an additional knowledge source. Unlike long documents, short text segments typically do not contain enough information to extract reliable features. This work investigates the possibilities of using highly ranked search-result snippets to enrich the representation of text segments. A hierarchical clustering algorithm is then designed for creating the hierarchical topic structure of text segments. Text segments with close concepts can be grouped together in a cluster, and relevant clusters linked at the same or near levels. Different from traditional clustering algorithms, which tend to produce cluster hierarchies with a very unnatural shape, the algorithm tries to produce a more natural and comprehensive tree hierarchy. Extensive experiments were conducted on different domains of text segments, including subject terms, people names, paper titles, and natural language questions. The obtained experimental results have shown the potential of the proposed approach, which provides a basis for the in-depth analysis of text segments on a larger scale and is believed able to benefit many information systems.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2020125353",
    "type": "article"
  },
  {
    "title": "DirichletRank",
    "doi": "https://doi.org/10.1145/1344411.1344416",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Xuanhui Wang; Tao Tao; Jian-Tao Sun; Azadeh Shakery; ChengXiang Zhai",
    "corresponding_authors": "",
    "abstract": "Link-based ranking algorithms are among the most important techniques to improve web search. In particular, the PageRank algorithm has been successfully used in the Google search engine and has been attracting much attention recently. However, we find that PageRank has a “zero-one gap” problem which, to the best of our knowledge, has not been addressed in any previous work. This problem can be potentially exploited to spam PageRank results and make the state-of-the-art link-based antispamming techniques ineffective. The zero-one gap problem arises as a result of the current ad hoc way of computing transition probabilities in the random surfing model. We therefore propose a novel DirichletRank algorithm which calculates these probabilities using Bayesian estimation with a Dirichlet prior. DirichletRank is a variant of PageRank, but does not have the problem of zero-one gap and can be analytically shown substantially more resistant to some link spams than PageRank. Experiment results on TREC data show that DirichletRank can achieve better retrieval accuracy than PageRank due to its more reasonable allocation of transition probabilities. More importantly, experiments on the TREC dataset and another real web dataset from the Webgraph project show that, compared with the original PageRank, DirichletRank is more stable under link perturbation and is significantly more robust against both manually identified web spams and several simulated link spams. DirichletRank can be computed as efficiently as PageRank, and thus is scalable to large-scale web applications.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2051644806",
    "type": "article"
  },
  {
    "title": "Cost-benefit methodology for office systems",
    "doi": "https://doi.org/10.1145/27641.28059",
    "publication_date": "1987-07-01",
    "publication_year": 1987,
    "authors": "Peter G. Sassone",
    "corresponding_authors": "Peter G. Sassone",
    "abstract": "The time savings times salary (TSTS) approach is a widely used methodology for the financial justification of office information systems, yet its theoretical basis is largely unexplored. In this paper, we identify its underlying economic model, including five critical assumptions. We find that the model, though somewhat restrictive, is not unreasonable. However, we find that the time-saving-times-salary calculation, per se, is implicitly based on a very particular assumption about how saved time will be used. This assumption has neither a behavioral nor normative basis, and we conclude that the TSTS calculation is not meaningful in most cases. An alternate approach, the hedonic wage model, is proposed. This model overcomes most of the deficiencies of the TSTS approach, although it has somewhat greater data requirements and computational complexity. A case study illustrating the use of the hedonic wage model is presented.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2052801301",
    "type": "article"
  },
  {
    "title": "eXtended cumulated gain measures for the evaluation of content-oriented XML retrieval",
    "doi": "https://doi.org/10.1145/1185877.1185883",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Gabriella Kazai; Mounia Lalmas",
    "corresponding_authors": "",
    "abstract": "We propose and evaluate a family of measures, the eXtended Cumulated Gain (XCG) measures, for the evaluation of content-oriented XML retrieval approaches. Our aim is to provide an evaluation framework that allows the consideration of dependency among XML document components. In particular, two aspects of dependency are considered: (1) near-misses, which are document components that are structurally related to relevant components, such as a neighboring paragraph or container section, and (2) overlap, which regards the situation wherein the same text fragment is referenced multiple times, for example, when a paragraph and its container section are both retrieved. A further consideration is that the measures should be flexible enough so that different models of user behavior may be instantiated within. Both system- and user-oriented aspects are investigated and both recall and precision-like qualities are measured. We evaluate the reliability of the proposed measures based on the INEX 2004 test collection. For example, the effects of assessment variation and topic set size on evaluation stability are investigated, and the upper and lower bounds of expected error rates are established. The evaluation demonstrates that the XCG measures are stable and reliable, and in particular, that the novel measures of effort-precision and gain-recall ( ep / gr ) show comparable behavior to established IR measures like precision and recall.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2071323102",
    "type": "article"
  },
  {
    "title": "How people recall, recognize, and reuse search results",
    "doi": "https://doi.org/10.1145/1402256.1402258",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Jaime Teevan",
    "corresponding_authors": "Jaime Teevan",
    "abstract": "When a person issues a query, that person has expectations about the search results that will be returned. These expectations can be based on the current information need, but are also influenced by how the searcher believes the search engine works, where relevant results are expected to be ranked, and any previous searches the individual has run on the topic. This paper looks in depth at how the expectations people develop about search result lists during an initial query affect their perceptions of and interactions with future repeat search result lists. Three studies are presented that give insight into how people recall, recognize, and reuse results. The first study (a study of recall ) explores what people recall about previously viewed search result lists. The second study (a study of recognition ) builds on the first to reveal that people often recognize a result list as one they have seen before even when it is quite different. As long as those aspects that the searcher remembers about the initial list remain the same, other aspects can change significantly. This is advantageous because, as the third study (a study of reuse ) shows, when a result list appears to have changed, people have trouble re-using the previously viewed content in the list. They are less likely to find what they are looking for, less happy with the result quality, more likely to find the task hard, and more likely to take a long time searching. Although apparent consistency is important for reuse, people's inability to recognize change makes consistency without stagnation possible. New relevant results can be presented where old results have been forgotten, making both old and new content easy to find.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2105769592",
    "type": "article"
  },
  {
    "title": "An architecture for object management in OIS",
    "doi": "https://doi.org/10.1145/1206.1207",
    "publication_date": "1984-08-23",
    "publication_year": 1984,
    "authors": "Matts Ahlsén; Anders Björnerstedt; Stefan Britts; Christer Hultén; Lars Söderlund",
    "corresponding_authors": "",
    "abstract": "article Free AccessAn architecture for object management in OIS Authors: Matts Ahlsen SYSLAB SYSLABView Profile , Anders Bjornerstedt SYSLAB SYSLABView Profile , Stefan Britts SYSLAB SYSLABView Profile , Christer Hulten SYSLAB SYSLABView Profile , Lars Soderlund SYSLAB SYSLABView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 3July 1984 pp 173–196https://doi.org/10.1145/1206.1207Published:23 August 1984Publication History 38citation345DownloadsMetricsTotal Citations38Total Downloads345Last 12 Months6Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2610788893",
    "type": "article"
  },
  {
    "title": "Robust result merging using sample-based score estimates",
    "doi": "https://doi.org/10.1145/1508850.1508852",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Milad Shokouhi; Justin Zobel",
    "corresponding_authors": "",
    "abstract": "In federated information retrieval, a query is routed to multiple collections and a single answer list is constructed by combining the results. Such metasearch provides a mechanism for locating documents on the hidden Web and, by use of sampling, can proceed even when the collections are uncooperative. However, the similarity scores for documents returned from different collections are not comparable, and, in uncooperative environments, document scores are unlikely to be reported. We introduce a new merging method for uncooperative environments, in which similarity scores for the sampled documents held for each collection are used to estimate global scores for the documents returned per query. This method requires no assumptions about properties such as the retrieval models used. Using experiments on a wide range of collections, we show that in many cases our merging methods are significantly more effective than previous techniques.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2023624732",
    "type": "article"
  },
  {
    "title": "Organizing and managing personal electronic files",
    "doi": "https://doi.org/10.1145/1402256.1402262",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Ben Hicks; Andy Dong; Rebecca Palmer; Hamish McAlpine",
    "corresponding_authors": "",
    "abstract": "This article deals with the organization and management of the computer files handled by mechanical engineers on their personal computers. In engineering organizations, a wide variety of electronic files (documents) are necessary to support both business processes and the activities of design and manufacture. Whilst a large number of files and hence information is formally archived, a significant amount of additional information and knowledge resides in electronic files on personal computers. The widespread use of these personal information stores means that all information is retained. However, its reuse is problematic for all but the individual as a result of the naming and organization of the files. To begin to address this issue, a study of the use and current practices for managing personal electronic files is described. The study considers the fundamental classes of files handled by engineers and analyses the organization of these files across the personal computers of 40 participants. The study involves a questionnaire and an electronic audit. The results of these qualitative and quantitative elements are used to elicit an understanding of the practices and requirements of engineers for managing personal electronic files. A potential scheme for naming and organizing personal electronic files is discussed as one possible way to satisfy these requirements. The aim of the scheme is to balance the personal nature of data storage with the need for personal records to be shared with others to support knowledge reuse in engineering organizations. Although this article is concerned with mechanical engineers, the issues dealt with are relevant to knowledge-based industries and, in particular, teams of knowledge workers.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W1966583887",
    "type": "article"
  },
  {
    "title": "User language model for collaborative personalized search",
    "doi": "https://doi.org/10.1145/1462198.1462203",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Gui-Rong Xue; Jie Han; Yong Yu; Qiang Yang",
    "corresponding_authors": "",
    "abstract": "Traditional personalized search approaches rely solely on individual profiles to construct a user model. They are often confronted by two major problems: data sparseness and cold-start for new individuals. Data sparseness refers to the fact that most users only visit a small portion of Web pages and hence a very sparse user-term relationship matrix is generated, while cold-start for new individuals means that the system cannot conduct any personalization without previous browsing history. Recently, community-based approaches were proposed to use the group's social behaviors as a supplement to personalization. However, these approaches only consider the commonality of a group of users and still cannot satisfy the diverse information needs of different users. In this article, we present a new approach, called collaborative personalized search. It considers not only the commonality factor among users for defining group user profiles and global user profiles, but also the specialties of individuals. Then, a statistical user language model is proposed to integrate the individual model, group user model and global user model together. In this way, the probability that a user will like a Web page is calculated through a two-step smoothing mechanism. First, a global user model is used to smooth the probability of unseen terms in the individual profiles and provide aggregated behavior of global users. Then, in order to precisely describe individual interests by looking at the behaviors of similar users, users are clustered into groups and group-user models are constructed. The group-user models are integrated into an overall model through a cluster-based language model. The behaviors of the group users can be utilized to enhance the performance of personalized search. This model can alleviate the two aforementioned problems and provide a more effective personalized search than previous approaches. Large-scale experimental evaluations are conducted to show that the proposed approach substantially improves the relevance of a search over several competitive methods.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2076006872",
    "type": "article"
  },
  {
    "title": "A novel framework for efficient automated singer identification in large music databases",
    "doi": "https://doi.org/10.1145/1508850.1508856",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Jialie Shen; John Shepherd; Bin Cui; Kian‐Lee Tan",
    "corresponding_authors": "",
    "abstract": "Over the past decade, there has been explosive growth in the availability of multimedia data, particularly image, video, and music. Because of this, content-based music retrieval has attracted attention from the multimedia database and information retrieval communities. Content-based music retrieval requires us to be able to automatically identify particular characteristics of music data. One such characteristic, useful in a range of applications, is the identification of the singer in a musical piece. Unfortunately, existing approaches to this problem suffer from either low accuracy or poor scalability. In this article, we propose a novel scheme, called Hybrid Singer Identifier (HSI), for efficient automated singer recognition. HSI uses multiple low-level features extracted from both vocal and nonvocal music segments to enhance the identification process; it achieves this via a hybrid architecture that builds profiles of individual singer characteristics based on statistical mixture models. An extensive experimental study on a large music database demonstrates the superiority of our method over state-of-the-art approaches in terms of effectiveness, efficiency, scalability, and robustness.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2066768226",
    "type": "article"
  },
  {
    "title": "Using topic themes for multi-document summarization",
    "doi": "https://doi.org/10.1145/1777432.1777436",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Sanda M. Harabagiu; Finley Lăcătuşu",
    "corresponding_authors": "",
    "abstract": "The problem of using topic representations for multidocument summarization (MDS) has received considerable attention recently. Several topic representations have been employed for producing informative and coherent summaries. In this article, we describe five previously known topic representations and introduce two novel representations of topics based on topic themes. We present eight different methods of generating multidocument summaries and evaluate each of these methods on a large set of topics used in past DUC workshops. Our evaluation results show a significant improvement in the quality of summaries based on topic themes over MDS methods that use other alternative topic representations.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2154895878",
    "type": "article"
  },
  {
    "title": "Engineering basic algorithms of an in-memory text search engine",
    "doi": "https://doi.org/10.1145/1877766.1877768",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Frederik Transier; Peter Sanders",
    "corresponding_authors": "",
    "abstract": "Inverted index data structures are the key to fast text search engines. We first investigate one of the predominant operation on inverted indexes, which asks for intersecting two sorted lists of document IDs of different lengths. We explore compression and performance of different inverted list data structures. In particular, we present Lookup , a new data structure that allows intersection in expected time linear in the smaller list. Based on this result, we present the algorithmic core of a full text data base that allows fast Boolean queries, phrase queries, and document reporting using less space than the input text. The system uses a carefully choreographed combination of classical data compression techniques and inverted-index-based search data structures. Our experiments show that inverted indexes are preferable over purely suffix-array-based techniques for in-memory (English) text search engines. A similar system is now running in practice in each core of the distributed data base engine TREX of SAP.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W1988679864",
    "type": "article"
  },
  {
    "title": "Statistical lattice-based spoken document retrieval",
    "doi": "https://doi.org/10.1145/1658377.1658379",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "Tee Kiah Chia; Khe Chai Sim; Haizhou Li; Hwee Tou Ng",
    "corresponding_authors": "",
    "abstract": "Recent research efforts on spoken document retrieval have tried to overcome the low quality of 1-best automatic speech recognition transcripts, especially in the case of conversational speech, by using statistics derived from speech lattices containing multiple transcription hypotheses as output by a speech recognizer. We present a method for lattice-based spoken document retrieval based on a statistical n -gram modeling approach to information retrieval. In this statistical lattice-based retrieval (SLBR) method, a smoothed statistical model is estimated for each document from the expected counts of words given the information in a lattice, and the relevance of each document to a query is measured as a probability under such a model. We investigate the efficacy of our method under various parameter settings of the speech recognition and lattice processing engines, using the Fisher English Corpus of conversational telephone speech. Experimental results show that our method consistently achieves better retrieval performance than using only the 1-best transcripts in statistical retrieval, outperforms a recently proposed lattice-based vector space retrieval method, and also compares favorably with a lattice-based retrieval method based on the Okapi BM25 model.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2075722833",
    "type": "article"
  },
  {
    "title": "Content redundancy in YouTube and its application to video tagging",
    "doi": "https://doi.org/10.1145/1993036.1993037",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "José San Pedro; Stefan Siersdorfer; Mark Sanderson",
    "corresponding_authors": "",
    "abstract": "The emergence of large-scale social Web communities has enabled users to share online vast amounts of multimedia content. An analysis of YouTube reveals a high amount of redundancy, in the form of videos with overlapping or duplicated content. We use robust content-based video analysis techniques to detect overlapping sequences between videos. Based on the output of these techniques, we present an in-depth study of duplication and content overlap in YouTube, and analyze various dependencies between content overlap and meta data such as video titles, views, video ratings, and tags. As an application, we show that content-based links provide useful information for generating new tag assignments. We propose different tag propagation methods for automatically obtaining richer video annotations. Experiments on video clustering and classification as well as a user evaluation demonstrate the viability of our approach.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2046637790",
    "type": "article"
  },
  {
    "title": "Upper-bound approximations for dynamic pruning",
    "doi": "https://doi.org/10.1145/2037661.2037662",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Craig Macdonald; Iadh Ounis; Nicola Tonellotto",
    "corresponding_authors": "",
    "abstract": "Dynamic pruning strategies for information retrieval systems can increase querying efficiency without decreasing effectiveness by using upper bounds to safely omit scoring documents that are unlikely to make the final retrieved set. Often, such upper bounds are pre-calculated at indexing time for a given weighting model. However, this precludes changing, adapting or training the weighting model without recalculating the upper bounds. Instead, upper bounds should be approximated at querying time from various statistics of each term to allow on-the-fly adaptation of the applied retrieval strategy. This article, by using uniform notation, formulates the problem of determining a term upper-bound given a weighting model and discusses the limitations of existing approximations. Moreover, we propose an upper-bound approximation using a constrained nonlinear maximization problem. We prove that our proposed upper-bound approximation does not impact the retrieval effectiveness of several modern weighting models from various different families. We also show the applicability of the approximation for the Markov Random Field proximity model. Finally, we empirically examine how the accuracy of the upper-bound approximation impacts the number of postings scored and the resulting efficiency in the context of several large Web test collections.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W1997214779",
    "type": "article"
  },
  {
    "title": "Fast candidate generation for real-time tweet search with bloom filter chains",
    "doi": "https://doi.org/10.1145/2493175.2493178",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Nima Asadi; Jimmy Lin",
    "corresponding_authors": "",
    "abstract": "The rise of social media and other forms of user-generated content have created the demand for real-time search: against a high-velocity stream of incoming documents, users desire a list of relevant results at the time the query is issued. In the context of real-time search on tweets, this work explores candidate generation in a two-stage retrieval architecture where an initial list of results is processed by a second-stage rescorer to produce the final output. We introduce Bloom filter chains, a novel extension of Bloom filters that can dynamically expand to efficiently represent an arbitrarily long and growing list of monotonically-increasing integers with a constant false positive rate. Using a collection of Bloom filter chains, a novel approximate candidate generation algorithm called BWand is able to perform both conjunctive and disjunctive retrieval. Experiments show that our algorithm is many times faster than competitive baselines and that this increased performance does not require sacrificing end-to-end effectiveness. Our results empirically characterize the trade-off space defined by output quality, query evaluation speed, and memory footprint for this particular search architecture.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2091154874",
    "type": "article"
  },
  {
    "title": "A Pólya Urn Document Language Model for Improved Information Retrieval",
    "doi": "https://doi.org/10.1145/2746231",
    "publication_date": "2015-05-04",
    "publication_year": 2015,
    "authors": "Ronan Cummins; Jiaul H. Paik; Yuanhua Lv",
    "corresponding_authors": "",
    "abstract": "The multinomial language model has been one of the most effective models of retrieval for more than a decade. However, the multinomial distribution does not model one important linguistic phenomenon relating to term dependency—that is, the tendency of a term to repeat itself within a document (i.e., word burstiness). In this article, we model document generation as a random process with reinforcement (a multivariate Pólya process) and develop a Dirichlet compound multinomial language model that captures word burstiness directly. We show that the new reinforced language model can be computed as efficiently as current retrieval models, and with experiments on an extensive set of TREC collections, we show that it significantly outperforms the state-of-the-art language model for a number of standard effectiveness metrics. Experiments also show that the tuning parameter in the proposed model is more robust than that in the multinomial language model. Furthermore, we develop a constraint for the verbosity hypothesis and show that the proposed model adheres to the constraint. Finally, we show that the new language model essentially introduces a measure closely related to idf, which gives theoretical justification for combining the term and document event spaces in tf-idf type schemes.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W1539587635",
    "type": "article"
  },
  {
    "title": "Unifying Virtual and Physical Worlds",
    "doi": "https://doi.org/10.1145/3052774",
    "publication_date": "2017-04-06",
    "publication_year": 2017,
    "authors": "Xiang Wang; Liqiang Nie; Xuemeng Song; Dongxiang Zhang; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Event-based social networking services, such as Meetup, are capable of linking online virtual interactions to offline physical activities. Compared to mono online social networking services (e.g., Twitter and Google+), such dual networks provide a complete picture of users’ online and offline behaviors that more often than not are compatible and complementary. In the light of this, we argue that joint learning over dual networks offers us a better way to comprehensively understand user behaviors and their underlying organizational principles. Despite its value, few efforts have been dedicated to jointly considering the following factors within a unified model: (1) local user contextualization, (2) global structure coherence, and (3) effectiveness evaluation. Toward this end, we propose a novel dual clustering model for community detection over dual networks to jointly model local consistency for a specific user and global consistency of partitioning results across networks. We theoretically derived its solution. In addition, we verified our model regarding multiple metrics from different aspects and applied it to the application of event attendance prediction.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2604849926",
    "type": "article"
  },
  {
    "title": "Unsupervised Visual and Textual Information Fusion in CBMIR Using Graph-Based Methods",
    "doi": "https://doi.org/10.1145/2699668",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Julien Ah-Pine; Gabriela Csurka; Stéphane Clinchant",
    "corresponding_authors": "",
    "abstract": "Multimedia collections are more than ever growing in size and diversity. Effective multimedia retrieval systems are thus critical to access these datasets from the end-user perspective and in a scalable way. We are interested in repositories of image/text multimedia objects and we study multimodal information fusion techniques in the context of content-based multimedia information retrieval. We focus on graph-based methods, which have proven to provide state-of-the-art performances. We particularly examine two such methods: cross-media similarities and random-walk-based scores. From a theoretical viewpoint, we propose a unifying graph-based framework, which encompasses the two aforementioned approaches. Our proposal allows us to highlight the core features one should consider when using a graph-based technique for the combination of visual and textual information. We compare cross-media and random-walk-based results using three different real-world datasets. From a practical standpoint, our extended empirical analyses allow us to provide insights and guidelines about the use of graph-based methods for multimodal information fusion in content-based multimedia information retrieval.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W1969780448",
    "type": "article"
  },
  {
    "title": "Content-Based Video Copy Detection Benchmarking at TRECVID",
    "doi": "https://doi.org/10.1145/2629531",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "George Awad; Paul Over; Wessel Kraaij",
    "corresponding_authors": "",
    "abstract": "This article presents an overview of the video copy detection benchmark which was run over a period of 4 years (2008--2011) as part of the TREC Video Retrieval (TRECVID) workshop series. The main contributions of the article include i) an examination of the evolving design of the evaluation framework and its components (system tasks, data, measures); ii) a high-level overview of results and best-performing approaches; and iii) a discussion of lessons learned over the four years. The content-based copy detection (CCD) benchmark worked with a large collection of synthetic queries, which is atypical for TRECVID, as was the use of a normalized detection cost framework. These particular evaluation design choices are motivated and appraised.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2141622653",
    "type": "article"
  },
  {
    "title": "Ranking-Oriented Collaborative Filtering",
    "doi": "https://doi.org/10.1145/2960408",
    "publication_date": "2016-09-21",
    "publication_year": 2016,
    "authors": "Shuaiqiang Wang; Shanshan Huang; Tie‐Yan Liu; Jun Ma; Zhumin Chen; Jari Veijalainen",
    "corresponding_authors": "",
    "abstract": "Collaborative filtering (CF) is one of the most effective techniques in recommender systems, which can be either rating oriented or ranking oriented. Ranking-oriented CF algorithms demonstrated significant performance gains in terms of ranking accuracy, being able to estimate a precise preference ranking of items for each user rather than the absolute ratings (as rating-oriented CF algorithms do). Conventional memory-based ranking-oriented CF can be referred to as pairwise algorithms. They represent each user as a set of preferences on each pair of items for similarity calculations and predictions. In this study, we propose ListCF, a novel listwise CF paradigm that seeks improvement in both accuracy and efficiency in comparison with pairwise CF. In ListCF, each user is represented as a probability distribution of the permutations over rated items based on the Plackett-Luce model, and the similarity between users is measured based on the Kullback--Leibler divergence between their probability distributions over the set of commonly rated items. Given a target user and the most similar users, ListCF directly predicts a total order of items for each user based on similar users’ probability distributions over permutations of the items. Besides, we also reveal insightful connections among pointwise, pairwise, and listwise CF algorithms from the perspective of the matrix representations. In addition, to make our algorithm more scalable and adaptive, we present an incremental algorithm for ListCF, which allows incrementally updating the similarities between users when certain user submits a new rating or updates an existing rating. Extensive experiments on benchmark datasets in comparison with the state-of-the-art approaches demonstrate the promise of our approach.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2522998206",
    "type": "article"
  },
  {
    "title": "Deriving User Preferences of Mobile Apps from Their Management Activities",
    "doi": "https://doi.org/10.1145/3015462",
    "publication_date": "2017-07-11",
    "publication_year": 2017,
    "authors": "Xuanzhe Liu; Wei Ai; Huoran Li; Jian Tang; Gang Huang; Feng Feng; Qiaozhu Mei",
    "corresponding_authors": "",
    "abstract": "App marketplaces host millions of mobile apps that are downloaded billions of times. Investigating how people manage mobile apps in their everyday lives creates a unique opportunity to understand the behavior and preferences of mobile device users, infer the quality of apps, and improve user experience. Existing literature provides very limited knowledge about app management activities, due to the lack of app usage data at scale. This article takes the initiative to analyze a very large app management log collected through a leading Android app marketplace. The dataset covers 5 months of detailed downloading, updating, and uninstallation activities, which involve 17 million anonymized users and 1 million apps. We present a surprising finding that the metrics commonly used to rank apps in app stores do not truly reflect the users’ real attitudes. We then identify behavioral patterns from the app management activities that more accurately indicate user preferences of an app even when no explicit rating is available. A systematic statistical analysis is designed to evaluate machine learning models that are trained to predict user preferences using these behavioral patterns, which features an inverse probability weighting method to correct the selection biases in the training process.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2735852510",
    "type": "article"
  },
  {
    "title": "Curious Cat--Mobile, Context-Aware Conversational Crowdsourcing Knowledge Acquisition",
    "doi": "https://doi.org/10.1145/3086686",
    "publication_date": "2017-08-16",
    "publication_year": 2017,
    "authors": "Luka Bradeško; Michael Witbrock; Janez Starc; Zala Herga; Marko Grobelnik; Dunja Mladenić",
    "corresponding_authors": "",
    "abstract": "Scaled acquisition of high-quality structured knowledge has been a longstanding goal of Artificial Intelligence research. Recent advances in crowdsourcing, the sheer number of Internet and mobile users, and the commercial availability of supporting platforms offer new tools for knowledge acquisition. This article applies context-aware knowledge acquisition that simultaneously satisfies users’ immediate information needs while extending its own knowledge using crowdsourcing. The focus is on knowledge acquisition on a mobile device, which makes the approach practical and scalable; in this context, we propose and implement a new KA approach that exploits an existing knowledge base to drive the KA process, communicate with the right people, and check for consistency of the user-provided answers. We tested the viability of the approach in experiments using our platform with real users around the world, and an existing large source of common-sense background knowledge. These experiments show that the approach is promising: the knowledge is estimated to be true and useful for users 95% of the time. Using context to proactively drive knowledge acquisition increased engagement and effectiveness (the number of new assertions/day/user increased for 175%). Using pre-existing and newly acquired knowledge also proved beneficial.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2748768308",
    "type": "article"
  },
  {
    "title": "Boosting Search Performance Using Query Variations",
    "doi": "https://doi.org/10.1145/3345001",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "Rodger Benham; Joel Mackenzie; Alistair Moffat; J. Shane Culpepper",
    "corresponding_authors": "",
    "abstract": "Rank fusion is a powerful technique that allows multiple sources of information to be combined into a single result set. However, to date fusion has not been regarded as being cost-effective in cases where strict per-query efficiency guarantees are required, such as in web search. In this work we propose a novel solution to rank fusion by splitting the computation into two parts -- one phase that is carried out offline to generate pre-computed centroid answers for queries with broadly similar information needs, and then a second online phase that uses the corresponding topic centroid to compute a result page for each query. We explore efficiency improvements to classic fusion algorithms whose costs can be amortized as a pre-processing step, and can then be combined with re-ranking approaches to dramatically improve effectiveness in multi-stage retrieval systems with little efficiency overhead at query time. Experimental results using the ClueWeb12B collection and the UQV100 query variations demonstrate that centroid-based approaches allow improved retrieval effectiveness at little or no loss in query throughput or latency, and with reasonable pre-processing requirements. We additionally show that queries that do not match any of the pre-computed clusters can be accurately identified and efficiently processed in our proposed ranking pipeline.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2979894627",
    "type": "article"
  },
  {
    "title": "Active Learning for Classification with Maximum Model Change",
    "doi": "https://doi.org/10.1145/3086820",
    "publication_date": "2017-08-31",
    "publication_year": 2017,
    "authors": "Wenbin Cai; Yexun Zhang; Ya Zhang; Siyuan Zhou; Wenquan Wang; Zhuoxiang Chen; Chris Ding",
    "corresponding_authors": "",
    "abstract": "Most existing active learning studies focus on designing sample selection algorithms. However, several fundamental problems deserve investigation to provide deep insight into active learning. In this article, we conduct an in-depth investigation on active learning for classification from the perspective of model change. We derive a general active learning framework for classification called maximum model change (MMC), which aims at querying the influential examples. The model change is quantified as the difference between the model parameters before and after training with the expanded training set. Inspired by the stochastic gradient update rule, the gradient of the loss with respect to a given candidate example is adopted to approximate the model change. This framework is applied to two popular classifiers: support vector machines and logistic regression. We analyze the convergence property of MMC and theoretically justify it. We explore the connection between MMC and uncertainty-based sampling to provide a uniform view. In addition, we discuss its potential usability to other learning models and show its applicability in a wide range of applications. We validate the MMC strategy on two kinds of benchmark datasets, the UCI repository and ImageNet, and show that it outperforms many state-of-the-art methods.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2752985199",
    "type": "article"
  },
  {
    "title": "TopPRF",
    "doi": "https://doi.org/10.1145/2956234",
    "publication_date": "2016-08-29",
    "publication_year": 2016,
    "authors": "Jun Miao; Jimmy Xiangji Huang; Jiashu Zhao",
    "corresponding_authors": "",
    "abstract": "Traditional pseudo relevance feedback (PRF) models choose top k feedback documents for query expansion and treat those documents equally. When k is determined, feedback terms are selected without considering the reliability of these documents for relevance. Because the performance of PRF is sensitive to the selection of feedback terms, noisy terms imported from these irrelevant documents or partially relevant documents will harm the final results extensively. Intuitively, terms in these documents should be considered less important for feedback term selection. Nonetheless, how to measure the reliability of feedback documents is a difficult problem. Recently, topic modeling has become more and more popular in the information retrieval (IR) area. In order to identify how reliable a feedback document is to be relevant, we attempt to adapt the topical information into PRF. However, topics are hard to be quantified and therefore the identification of topic is usually fuzzy. It is very challenging for integrating the obtained topical information effectively into IR and other text-processing-related areas. Current research work mainly focuses on mining relevant information from particular topics. This is extremely difficult when the boundaries of different topics are hard to define. In this article, we investigate a key factor of this problem, the topic number for topic modeling and how it makes topics “fuzzy.” To effectively and efficiently apply topical information, we propose a new probabilistic framework, “TopPRF,” and three models, TS-COS, TS-EU, and TS-Entropy, via integrating “Topic Space” (TS) information into pseudo relevance feedback. These methods discover how reliable a document is to be relevant through both term and topical information. When selecting feedback terms, candidate terms in more reliable feedback documents should obtain extra weights. Experimental results on various public collections justify that our proposed methods can significantly reduce the influence of “fuzzy topics” and obtain stable, good results over the strong baseline models. Our proposed probabilistic framework, TopPRF, and three topic-space-based models are capable of searching documents beyond traditional term matching only and provide a promising avenue for constructing better topic-space-based IR systems. Moreover, in-depth discussions and conclusions are made to help other researchers apply topical information effectively.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2507254902",
    "type": "article"
  },
  {
    "title": "A Probabilistic Lifestyle-Based Trajectory Model for Social Strength Inference from Human Trajectory Data",
    "doi": "https://doi.org/10.1145/2948064",
    "publication_date": "2016-09-03",
    "publication_year": 2016,
    "authors": "Wayne Xin Zhao; Ningnan Zhou; Wenhui Zhang; Ji-Rong Wen; Shan Wang; Edward Yi Chang",
    "corresponding_authors": "",
    "abstract": "With the pervasiveness of location-based social networks, it becomes increasingly important to consider the social characteristics of locations shared among persons. Several studies have been proposed to infer social strength by using trajectory similarity. However, these studies have two major shortcomings. First, they rely on the explicit co-occurrence of check-in locations. In this situation, a user pair of two friends who seldom share common locations or a user pair of two strangers who heavily share common visited locations will receive an unreliable estimation of the real social strength between them. Second, these studies do not consider how the overall trajectory patterns of users change with the varying of living styles. In this article, we propose a probabilistic generative model to mine latent lifestyle-related patterns from human trajectory data for inferring social strength. It can automatically learn functionality topics consisting of locations with similar service functions and transition probabilities over the set of functionality topics. Furthermore, a lifestyle is modeled as a unique transition probability matrix over the set of functionality topics. A user has a preference distribution over the set of lifestyles, and he or she is able to select over multiple lifestyles to adapt to different living contexts. The learned lifestyle-related patterns are subsequently used as features in a supervised learner for both strength estimation and link prediction. We conduct extensive experiments to evaluate the performance of the proposed method on two real-world datasets. The experimental results demonstrate the effectiveness of our proposed method.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2509835757",
    "type": "article"
  },
  {
    "title": "Social Question Answering",
    "doi": "https://doi.org/10.1145/2948063",
    "publication_date": "2016-09-03",
    "publication_year": 2016,
    "authors": "Piero Molino; Luca Maria Aiello; Pasquale Lops",
    "corresponding_authors": "",
    "abstract": "Community question answering (CQA) sites use a collaborative paradigm to satisfy complex information needs. Although the task of matching questions to their best answers has been tackled for more than a decade, the social question-answering practice is a complex process. The factors influencing the accuracy of question-answer matching are many and hard to disentangle. We approach the task from an application-oriented perspective, probing the space of several dimensions relevant to this problem: features, algorithms, and topics. We gather under a learning to rank framework the most extensive feature set used in literature to date, including 225 features from five different families. We test the power of such features in predicting the best answer to a question on the largest dataset from Yahoo Answers used for this task so far (40M answers) and provide a faceted analysis of the results along different topical areas and question types. We propose a novel family of distributional semantics measures that most of the time can seamlessly replace widely used linguistic similarity features, being more than one order of magnitude faster to compute and providing greater predictive power. The best feature set reaches an improvement between 11% and 26% in P@1 compared to recent well-established state-of-the-art methods.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2512715634",
    "type": "article"
  },
  {
    "title": "Efficient Learning-Based Recommendation Algorithms for Top- <i>N</i> Tasks and Top- <i>N</i> Workers in Large-Scale Crowdsourcing Systems",
    "doi": "https://doi.org/10.1145/3231934",
    "publication_date": "2018-10-30",
    "publication_year": 2018,
    "authors": "Mejdl Safran; Dunren Che",
    "corresponding_authors": "",
    "abstract": "The task and worker recommendation problems in crowdsourcing systems have brought up unique characteristics that are not present in traditional recommendation scenarios, i.e., the huge flow of tasks with short lifespans, the importance of workers’ capabilities, and the quality of the completed tasks. These unique features make traditional recommendation approaches no longer satisfactory for task and worker recommendation in crowdsourcing systems. In this article, we propose a two-tier data representation scheme (defining a worker--category suitability score and a worker--task attractiveness score ) to support personalized task and worker recommendations. We also extend two optimization methods, namely least mean square error and Bayesian personalized rank, to better fit the characteristics of task/worker recommendation in crowdsourcing systems. We then integrate the proposed representation scheme and the extended optimization methods along with the two adapted popular learning models, i.e., matrix factorization and kNN, and result in two lines of top- N recommendation algorithms for crowdsourcing systems: (1) Top- N -Tasks recommendation algorithms for discovering the top- N most suitable tasks for a given worker and (2) Top- N -Workers recommendation algorithms for identifying the top- N best workers for a task requester. An extensive experimental study is conducted that validates the effectiveness and efficiency of a broad spectrum of algorithms, accompanied by our analysis and the insights gained.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2895179543",
    "type": "article"
  },
  {
    "title": "ELSA",
    "doi": "https://doi.org/10.1145/3298987",
    "publication_date": "2019-01-16",
    "publication_year": 2019,
    "authors": "Luca Cagliero; Paolo Garza; Elena Baralis",
    "corresponding_authors": "",
    "abstract": "Sentence-based summarization aims at extracting concise summaries of collections of textual documents. Summaries consist of a worthwhile subset of document sentences. The most effective multilingual strategies rely on Latent Semantic Analysis (LSA) and on frequent itemset mining, respectively. LSA-based summarizers pick the document sentences that cover the most important concepts. Concepts are modeled as combinations of single-document terms and are derived from a term-by-sentence matrix by exploiting Singular Value Decomposition (SVD). Itemset-based summarizers pick the sentences that contain the largest number of frequent itemsets, which represent combinations of frequently co-occurring terms. The main drawbacks of existing approaches are (i) the inability of LSA to consider the correlation between combinations of multiple-document terms and the underlying concepts, (ii) the inherent redundancy of frequent itemsets because similar itemsets may be related to the same concept, and (iii) the inability of itemset-based summarizers to correlate itemsets with the underlying document concepts. To overcome the issues of both of the abovementioned algorithms, we propose a new summarization approach that exploits frequent itemsets to describe all of the latent concepts covered by the documents under analysis and LSA to reduce the potentially redundant set of itemsets to a compact set of uncorrelated concepts. The summarizer selects the sentences that cover the latent concepts with minimal redundancy. We tested the summarization algorithm on both multilingual and English-language benchmark document collections. The proposed approach performed significantly better than both itemset- and LSA-based summarizers, and better than most of the other state-of-the-art approaches.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2910880006",
    "type": "article"
  },
  {
    "title": "Jointly Learning Representations of Nodes and Attributes for Attributed Networks",
    "doi": "https://doi.org/10.1145/3377850",
    "publication_date": "2020-01-27",
    "publication_year": 2020,
    "authors": "Zaiqiao Meng; Shangsong Liang; Xiangliang Zhang; Richard McCreadie; Iadh Ounis",
    "corresponding_authors": "",
    "abstract": "Previous embedding methods for attributed networks aim at learning low-dimensional vector representations only for nodes but not for both nodes and attributes, resulting in the fact that node embeddings cannot be directly used to recover the correlations between nodes and attributes. However, capturing such correlations by embeddings is of great importance for many real-world applications, such as attribute inference and user profiling. Moreover, in real-world scenarios, many attributed networks evolve over time, with their nodes, links, and attributes changing from time to time. In this article, we study the problem of jointly learning low-dimensional representations of both nodes and attributes for static and dynamic attributed networks. To address this problem, we propose a Co-embedding model for Static Attributed Networks (CSAN), which jointly learns low-dimensional representations of both attributes and nodes in the same semantic space such that their affinities can be effectively captured and measured, and a Co-embedding model for Dynamic Attributed Networks (CDAN) to dynamically track low-dimensional representations of nodes and attributes over time. To obtain effective embeddings, both our co-embedding models, CSAN and CDAN, embed each node and attribute with means and variances of Gaussian distributions via variational auto-encoders. Our CDAN model formulates the dynamic changes of a dynamic attributed network by aggregating perturbation features from the nodes’ local neighborhoods as well as attributes’ associations such that the evolving patterns of the given network can be tracked. Experimental results on real-world networks demonstrate that our proposed embedding models outperform state-of-the-art non-dynamic and dynamic embedding models.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W3010920176",
    "type": "article"
  },
  {
    "title": "PONE",
    "doi": "https://doi.org/10.1145/3423168",
    "publication_date": "2020-11-13",
    "publication_year": 2020,
    "authors": "Tian Lan; Xian-Ling Mao; Wei Wei; Xiaoyan Gao; Heyan Huang",
    "corresponding_authors": "",
    "abstract": "Open-domain generative dialogue systems have attracted considerable attention over the past few years. Currently, how to automatically evaluate them is still a big challenge. As far as we know, there are three kinds of automatic evaluations for open-domain generative dialogue systems: (1) Word-overlap-based metrics; (2) Embedding-based metrics; (3) Learning-based metrics. Due to the lack of systematic comparison, it is not clear which kind of metrics is more effective. In this article, we first measure systematically all kinds of metrics to check which kind is best. Extensive experiments demonstrate that learning-based metrics are the most effective evaluation metrics for open-domain generative dialogue systems. Moreover, we observe that nearly all learning-based metrics depend on the negative sampling mechanism, which obtains extremely imbalanced and low-quality samples to train a score model. To address this issue, we propose a novel learning-based metric that significantly improves the correlation with human judgments by using augmented PO sitive samples and valuable NE gative samples, called PONE. Extensive experiments demonstrate that PONE significantly outperforms the state-of-the-art learning-based evaluation method. Besides, we have publicly released the codes of our proposed metric and state-of-the-art baselines. 1",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W3107013681",
    "type": "article"
  },
  {
    "title": "Local Variational Feature-Based Similarity Models for Recommending Top- <i>N</i> New Items",
    "doi": "https://doi.org/10.1145/3372154",
    "publication_date": "2020-02-11",
    "publication_year": 2020,
    "authors": "Yifan Chen; Yang Wang; Xiang Zhao; Hongzhi Yin; Ilya Markov; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "The top- N recommendation problem has been studied extensively. Item-based collaborative filtering recommendation algorithms show promising results for the problem. They predict a user’s preferences by estimating similarities between a target and user-rated items. Top- N recommendation remains a challenging task in scenarios where there is a lack of preference history for new items. Feature-based Similarity Models (FSMs) address this particular problem by extending item-based collaborative filtering by estimating similarity functions of item features. The quality of the estimated similarity function determines the accuracy of the recommendation. However, existing FSMs only estimate global similarity functions; i.e., they estimate using preference information across all users. Moreover, the estimated similarity functions are linear ; hence, they may fail to capture the complex structure underlying item features. In this article, we propose to improve FSMs by estimating local similarity functions, where each function is estimated for a subset of like-minded users. To capture global preference patterns, we extend the global similarity function from linear to nonlinear, based on the effectiveness of variational autoencoders. We propose a Bayesian generative model, called the Local Variational Feature-based Similarity Model, to encapsulate local and global similarity functions. We present a variational Expectation Minimization algorithm for efficient approximate inference. Extensive experiments on a large number of real-world datasets demonstrate the effectiveness of our proposed model.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3006130793",
    "type": "article"
  },
  {
    "title": "When to Stop Reviewing in Technology-Assisted Reviews",
    "doi": "https://doi.org/10.1145/3411755",
    "publication_date": "2020-09-30",
    "publication_year": 2020,
    "authors": "Dan Li; Evangelos Kanoulas",
    "corresponding_authors": "",
    "abstract": "Technology-Assisted Reviews (TAR) aim to expedite document reviewing (e.g., medical articles or legal documents) by iteratively incorporating machine learning algorithms and human feedback on document relevance. Continuous Active Learning (CAL) algorithms have demonstrated superior performance compared to other methods in efficiently identifying relevant documents. One of the key challenges for CAL algorithms is deciding when to stop displaying documents to reviewers. Existing work either lacks transparency—it provides an ad-hoc stopping point, without indicating how many relevant documents are still not found, or lacks efficiency by paying an extra cost to estimate the total number of relevant documents in the collection prior to the actual review. In this article, we handle the problem of deciding the stopping point of TAR under the continuous active learning framework by jointly training a ranking model to rank documents, and by conducting a “greedy” sampling to estimate the total number of relevant documents in the collection. We prove the unbiasedness of the proposed estimators under a with-replacement sampling design, while experimental results demonstrate that the proposed approach, similar to CAL, effectively retrieves relevant documents; but it also provides a transparent, accurate, and effective stopping point.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3089621169",
    "type": "article"
  },
  {
    "title": "Context-aware Target Apps Selection and Recommendation for Enhancing Personal Mobile Assistants",
    "doi": "https://doi.org/10.1145/3447678",
    "publication_date": "2021-05-05",
    "publication_year": 2021,
    "authors": "Mohammad Aliannejadi; Hamed Zamani; Fábio Crestani; W. Bruce Croft",
    "corresponding_authors": "",
    "abstract": "Users install many apps on their smartphones, raising issues related to information overload for users and resource management for devices. Moreover, the recent increase in the use of personal assistants has made mobile devices even more pervasive in users’ lives. This article addresses two research problems that are vital for developing effective personal mobile assistants: target apps selection and recommendation . The former is the key component of a unified mobile search system: a system that addresses the users’ information needs for all the apps installed on their devices with a unified mode of access. The latter, instead, predicts the next apps that the users would want to launch. Here we focus on context-aware models to leverage the rich contextual information available to mobile devices. We design an in situ study to collect thousands of mobile queries enriched with mobile sensor data (now publicly available for research purposes). With the aid of this dataset, we study the user behavior in the context of these tasks and propose a family of context-aware neural models that take into account the sequential, temporal, and personal behavior of users. We study several state-of-the-art models and show that the proposed models significantly outperform the baselines.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W3159096087",
    "type": "article"
  },
  {
    "title": "Assessing Top- Preferences",
    "doi": "https://doi.org/10.1145/3451161",
    "publication_date": "2021-05-05",
    "publication_year": 2021,
    "authors": "Charles L. A. Clarke; Alexandra Vtyurina; Mark D. Smucker",
    "corresponding_authors": "",
    "abstract": "Assessors make preference judgments faster and more consistently than graded judgments. Preference judgments can also recognize distinctions between items that appear equivalent under graded judgments. Unfortunately, preference judgments can require more than linear effort to fully order a pool of items, and evaluation measures for preference judgments are not as well established as those for graded judgments, such as NDCG. In this article, we explore the assessment process for partial preference judgments, with the aim of identifying and ordering the top items in the pool, rather than fully ordering the entire pool. To measure the performance of a ranker, we compare its output to this preferred ordering by applying a rank similarity measure. We demonstrate the practical feasibility of this approach by crowdsourcing partial preferences for the TREC 2019 Conversational Assistance Track, replacing NDCG with a new measure named compatibility . This new measure has its most striking impact when comparing modern neural rankers, where it is able to recognize significant improvements in quality that would otherwise be missed by NDCG.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3159852056",
    "type": "article"
  },
  {
    "title": "Learning from Substitutable and Complementary Relations for Graph-based Sequential Product Recommendation",
    "doi": "https://doi.org/10.1145/3464302",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Wei Zhang; Zeyuan Chen; Hongyuan Zha; Jianyong Wang",
    "corresponding_authors": "",
    "abstract": "Sequential product recommendation, aiming at predicting the products that a target user will interact with soon, has become a hotspot topic. Most of the sequential recommendation models focus on learning from users’ interacted product sequences in a purely data-driven manner. However, they largely overlook the knowledgeable substitutable and complementary relations between products. To address this issue, we propose a novel Substitutable and Complementary Graph-based Sequential Product Recommendation model, namely, SCG-SPRe. The innovations of SCG-SPRe lie in its two main modules: (1) The module of interactive graph neural networks jointly encodes the high-order product correlations in the substitutable graph and the complementary graph into two types of relation-specific product representations. (2) The module of kernel-enhanced transformer networks adaptively fuses multiple temporal kernels to characterize the unique temporal patterns between a candidate product to be recommended and any interacted product in a target behavior sequence. Thanks to the seamless integration of the two modules, SCG-SPRe obtains candidate-dependent user representations for different candidate products to compute the corresponding ranking scores. We conduct extensive experiments on three public datasets, demonstrating SCG-SPRe is superior to competitive sequential recommendation baselines and validating the benefits of explicitly modeling the product-product relations.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3204210724",
    "type": "article"
  },
  {
    "title": "Contextualized Knowledge-aware Attentive Neural Network: Enhancing Answer Selection with Knowledge",
    "doi": "https://doi.org/10.1145/3457533",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Yang Deng; Yuexiang Xie; Yaliang Li; Min Yang; Wai Lam; Ying Shen",
    "corresponding_authors": "",
    "abstract": "Answer selection, which is involved in many natural language processing applications, such as dialog systems and question answering (QA), is an important yet challenging task in practice, since conventional methods typically suffer from the issues of ignoring diverse real-world background knowledge. In this article, we extensively investigate approaches to enhancing the answer selection model with external knowledge from knowledge graph (KG). First, we present a context-knowledge interaction learning framework, Knowledge-aware Neural Network, which learns the QA sentence representations by considering a tight interaction with the external knowledge from KG and the textual information. Then, we develop two kinds of knowledge-aware attention mechanism to summarize both the context-based and knowledge-based interactions between questions and answers. To handle the diversity and complexity of KG information, we further propose a Contextualized Knowledge-aware Attentive Neural Network, which improves the knowledge representation learning with structure information via a customized Graph Convolutional Network and comprehensively learns context-based and knowledge-based sentence representation via the multi-view knowledge-aware attention mechanism. We evaluate our method on four widely used benchmark QA datasets, including WikiQA, TREC QA, InsuranceQA, and Yahoo QA. Results verify the benefits of incorporating external knowledge from KG and show the robust superiority and extensive applicability of our method.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3196704868",
    "type": "article"
  },
  {
    "title": "Knowledge-Guided Disentangled Representation Learning for Recommender Systems",
    "doi": "https://doi.org/10.1145/3464304",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Shanlei Mu; Yaliang Li; Wayne Xin Zhao; Siqing Li; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "In recommender systems, it is essential to understand the underlying factors that affect user-item interaction. Recently, several studies have utilized disentangled representation learning to discover such hidden factors from user-item interaction data, which shows promising results. However, without any external guidance signal, the learned disentangled representations lack clear meanings, and are easy to suffer from the data sparsity issue. In light of these challenges, we study how to leverage knowledge graph (KG) to guide the disentangled representation learning in recommender systems. The purpose for incorporating KG is twofold, making the disentangled representations interpretable and resolving data sparsity issue. However, it is not straightforward to incorporate KG for improving disentangled representations, because KG has very different data characteristics compared with user-item interactions. We propose a novel K nowledge-guided D isentangled R epresentations approach ( KDR ) to utilizing KG to guide the disentangled representation learning in recommender systems. The basic idea, is to first learn more interpretable disentangled dimensions (explicit disentangled representations) based on structural KG, and then align implicit disentangled representations learned from user-item interaction with the explicit disentangled representations. We design a novel alignment strategy based on mutual information maximization. It enables the KG information to guide the implicit disentangled representation learning, and such learned disentangled representations will correspond to semantic information derived from KG. Finally, the fused disentangled representations are optimized to improve the recommendation performance. Extensive experiments on three real-world datasets demonstrate the effectiveness of the proposed model in terms of both performance and interpretability.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3198272940",
    "type": "article"
  },
  {
    "title": "Topic Difficulty: Collection and Query Formulation Effects",
    "doi": "https://doi.org/10.1145/3470563",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "J. Shane Culpepper; Guglielmo Faggioli; Nicola Ferro; Oren Kurland",
    "corresponding_authors": "",
    "abstract": "Several recent studies have explored the interaction effects between topics, systems, corpora, and components when measuring retrieval effectiveness. However, all of these previous studies assume that a topic or information need is represented by a single query. In reality, users routinely reformulate queries to satisfy an information need. In recent years, there has been renewed interest in the notion of “query variations” which are essentially multiple user formulations for an information need. Like many retrieval models, some queries are highly effective while others are not. This is often an artifact of the collection being searched which might be more or less sensitive to word choice. Users rarely have perfect knowledge about the underlying collection, and so finding queries that work is often a trial-and-error process. In this work, we explore the fundamental problem of system interaction effects between collections, ranking models, and queries. To answer this important question, we formalize the analysis using ANalysis Of VAriance (ANOVA) models to measure multiple components effects across collections and topics by nesting multiple query variations within each topic. Our findings show that query formulations have a comparable effect size of the topic factor itself, which is known to be the factor with the greatest effect size in prior ANOVA studies. Both topic and formulation have a substantially larger effect size than any other factor, including the ranking algorithms and, surprisingly, even query expansion. This finding reinforces the importance of further research in understanding the role of query rewriting in IR related tasks.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3198734960",
    "type": "article"
  },
  {
    "title": "Improving Transformer-based Sequential Recommenders through Preference Editing",
    "doi": "https://doi.org/10.1145/3564282",
    "publication_date": "2022-09-24",
    "publication_year": 2022,
    "authors": "Muyang Ma; Pengjie Ren; Zhumin Chen; Zhaochun Ren; Huasheng Liang; Jun Ma; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "One of the key challenges in sequential recommendation is how to extract and represent user preferences. Traditional methods rely solely on predicting the next item. But user behavior may be driven by complex preferences. Therefore, these methods cannot make accurate recommendations when the available information user behavior is limited. To explore multiple user preferences, we propose a transformer-based sequential recommendation model, named MrTransformer ( M ulti-p r eference Transformer ). For training MrTransformer, we devise a preference-editing -based self-supervised learning (SSL) mechanism that explores extra supervision signals based on relations with other sequences. The idea is to force the sequential recommendation model to discriminate between common and unique preferences in different sequences of interactions. By doing so, the sequential recommendation model is able to disentangle user preferences into multiple independent preference representations so as to improve user preference extraction and representation. We carry out extensive experiments on five benchmark datasets. MrTransformer with preference editing significantly outperforms state-of-the-art sequential recommendation methods in terms of Recall, MRR, and NDCG. We find that long sequences of interactions from which user preferences are harder to extract and represent benefit most from preference editing.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3177158382",
    "type": "article"
  },
  {
    "title": "Learning to Learn a Cold-start Sequential Recommender",
    "doi": "https://doi.org/10.1145/3466753",
    "publication_date": "2022-02-01",
    "publication_year": 2022,
    "authors": "Xiaowen Huang; Jitao Sang; Jian Yu; Changsheng Xu",
    "corresponding_authors": "",
    "abstract": "The cold-start recommendation is an urgent problem in contemporary online applications. It aims to provide users whose behaviors are literally sparse with as accurate recommendations as possible. Many data-driven algorithms, such as the widely used matrix factorization, underperform because of data sparseness. This work adopts the idea of meta-learning to solve the user’s cold-start recommendation problem. We propose a meta-learning-based cold-start sequential recommendation framework called metaCSR, including three main components: Diffusion Representer for learning better user/item embedding through information diffusion on the interaction graph; Sequential Recommender for capturing temporal dependencies of behavior sequences; and Meta Learner for extracting and propagating transferable knowledge of prior users and learning a good initialization for new users. metaCSR holds the ability to learn the common patterns from regular users’ behaviors and optimize the initialization so that the model can quickly adapt to new users after one or a few gradient updates to achieve optimal performance. The extensive quantitative experiments on three widely used datasets show the remarkable performance of metaCSR in dealing with the user cold-start problem. Meanwhile, a series of qualitative analysis demonstrates that the proposed metaCSR has good generalization.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4210718984",
    "type": "article"
  },
  {
    "title": "Doubly Robust Estimation for Correcting Position Bias in Click Feedback for Unbiased Learning to Rank",
    "doi": "https://doi.org/10.1145/3569453",
    "publication_date": "2022-10-26",
    "publication_year": 2022,
    "authors": "Harrie Oosterhuis",
    "corresponding_authors": "Harrie Oosterhuis",
    "abstract": "Clicks on rankings suffer from position-bias: generally items on lower ranks are less likely to be examined - and thus clicked - by users, in spite of their actual preferences between items. The prevalent approach to unbiased click-based learning-to-rank (LTR) is based on counterfactual inverse-propensity-scoring (IPS) estimation. In contrast with general reinforcement learning, counterfactual doubly-robust (DR) estimation has not been applied to click-based LTR in previous literature. In this paper, we introduce a novel DR estimator that is the first DR approach specifically designed for position-bias. The difficulty with position-bias is that the treatment - user examination - is not directly observable in click data. As a solution, our estimator uses the expected treatment per rank, instead of the actual treatment that existing DR estimators use. Our novel DR estimator has more robust unbiasedness conditions than the existing IPS approach, and in addition, provides enormous decreases in variance: our experimental results indicate it requires several orders of magnitude fewer datapoints to converge at optimal performance. For the unbiased LTR field, our DR estimator contributes both increases in state-of-the-art performance and the most robust theoretical guarantees of all known LTR estimators.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4307539157",
    "type": "article"
  },
  {
    "title": "A Multi-channel Hierarchical Graph Attention Network for Open Event Extraction",
    "doi": "https://doi.org/10.1145/3528668",
    "publication_date": "2022-04-22",
    "publication_year": 2022,
    "authors": "Qizhi Wan; Changxuan Wan; Keli Xiao; Rong Hu; Dexi Liu",
    "corresponding_authors": "",
    "abstract": "Event extraction is an essential task in natural language processing. Although extensively studied, existing work shares issues in three aspects, including (1) the limitations of using original syntactic dependency structure, (2) insufficient consideration of the node level and type information in Graph Attention Network (GAT), and (3) insufficient joint exploitation of the node dependency type and part-of-speech (POS) encoding on the graph structure. To address these issues, we propose a novel framework for open event extraction in documents. Specifically, to obtain an enhanced dependency structure with powerful encoding ability, our model is capable of handling an enriched parallel structure with connected ellipsis nodes. Moreover, through a bidirectional dependency parsing graph, it considers the sequence of order structure and associates the ancestor and descendant nodes. Subsequently, we further exploit node information, such as the node level and type, to strengthen the aggregation of node features in our GAT. Finally, based on the coordination of triple-channel features (i.e., semantic, syntactic dependency and POS), the performance of event extraction is significantly improved. Extensive experiments are conducted to validate the effectiveness of our method, and the results confirm its superiority over the state-of-the-art baselines. Furthermore, in-depth analyses are provided to explore the essential factors determining the extraction performance.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4224245411",
    "type": "article"
  },
  {
    "title": "Causal Disentangled Recommendation against User Preference Shifts",
    "doi": "https://doi.org/10.1145/3593022",
    "publication_date": "2023-04-18",
    "publication_year": 2023,
    "authors": "Wenjie Wang; Xinyu Lin; Liuhui Wang; Fuli Feng; Yunshan Ma; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Recommender systems easily face the issue of user preference shifts. User representations will become out-of-date and lead to inappropriate recommendations if user preference has shifted over time. To solve the issue, existing work focuses on learning robust representations or predicting the shifting pattern. There lacks a comprehensive view to discover the underlying reasons for user preference shifts. To understand the preference shift, we abstract a causal graph to describe the generation procedure of user interaction sequences. Assuming user preference is stable within a short period, we abstract the interaction sequence as a set of chronological environments. From the causal graph, we find that the changes of some unobserved factors (e.g., becoming pregnant) cause preference shifts between environments. Besides, the fine-grained user preference over item categories sparsely affects the interactions with different items. Inspired by the causal graph, our key considerations to handle preference shifts lie in modeling the interaction generation procedure by: (1) capturing the preference shifts across environments for accurate preference prediction and (2) disentangling the sparse influence from user preference to interactions for accurate effect estimation of preference. To this end, we propose a Causal Disentangled Recommendation (CDR) framework, which captures preference shifts via a temporal variational autoencoder and learns the sparse influence from multiple environments. Specifically, an encoder is adopted to infer the unobserved factors from user interactions while a decoder is to model the interaction generation process. Besides, we introduce two learnable matrices to disentangle the sparse influence from user preference to interactions. Last, we devise a multi-objective loss to optimize CDR. Extensive experiments on three datasets show the superiority of CDR in enhancing the generalization ability under user preference shifts.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4366273490",
    "type": "article"
  },
  {
    "title": "Learning to Retrieve User Behaviors for Click-through Rate Estimation",
    "doi": "https://doi.org/10.1145/3579354",
    "publication_date": "2023-01-09",
    "publication_year": 2023,
    "authors": "Jiarui Qin; Weinan Zhang; Rong Su; Zhirong Liu; Weiwen Liu; Guangpeng Zhao; Hao Li; Ruiming Tang; Xiuqiang He; Yong Yu",
    "corresponding_authors": "",
    "abstract": "Click-through rate (CTR) estimation plays a crucial role in modern online personalization services. It is essential to capture users’ drifting interests by modeling sequential user behaviors to build an accurate CTR estimation model. However, as the users accumulate a large amount of behavioral data on the online platforms, the current CTR models have to truncate user behavior sequences and utilize the most recent behaviors, which leads to a problem that sequential patterns such as periodicity or long-term dependency are not contained in the recent behaviors but in far back history. However, it is non-trivial to model the entire user sequence by directly using it for two reasons. Firstly, the very long input sequences will make online inference time and system load infeasible. Secondly, the very long sequences contain much noise, thus making it difficult for CTR models to capture useful patterns effectively. To tackle this issue, we consider it from the input data perspective instead of designing more sophisticated yet complex models. As the entire user behavior sequence contains much noise, it is unnecessary to input the entire sequence. Instead, we could just retrieve only a small part of it as the input to the CTR model. In this article, we propose the U ser B ehavior R etrieval (UBR) framework which aims at learning to retrieve the most informative user behaviors according to each CTR estimation request. Retrieving only a small set of behaviors could alleviate the two problems of utilizing very long sequences (i.e., inference efficiency and noisy input). The distinguishing property of UBR is that it supports arbitrary and learnable retrieval functions instead of utilizing a fixed pre-defined function, which is different from the current retrieval-based methods. Offline evaluations on three large-scale real-world datasets demonstrate the superiority and efficacy of the UBR framework. We further deploy UBR at the Huawei App Store, where it achieves 6.6% of eCPM gain in the online A/B test and now serves the main traffic in the Huawei App Store advertising scenario.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4313828922",
    "type": "article"
  },
  {
    "title": "Ontology-aware Prescription Recommendation in Treatment Pathways Using Multi-evidence Healthcare Data",
    "doi": "https://doi.org/10.1145/3579994",
    "publication_date": "2023-01-12",
    "publication_year": 2023,
    "authors": "Zijun Yao; Bin Liu; Fei Wang; Daby Sow; Ying Li",
    "corresponding_authors": "",
    "abstract": "For care of chronic diseases (e.g., depression, diabetes, hypertension), it is critical to identify effective treatment pathways that aim to promptly update the medication following the change of patient state and disease progression. This task is challenging because the optimal treatment pathway for each patient needs to be personalized due to the significant heterogeneity among individuals. Therefore, it is naturally promising to investigate how to use the abundant electronic health records to recommend effective and safe prescriptions. However, prescription recommendation needs to consider multiple aspects of life-critical evidence, such as the information relevance in terms of medical concepts, the health condition in terms of diagnosis history, and the further constraint in terms of side information (e.g., patient demographics and drug side effects). To this end, in this article, we propose a novel prescription recommendation framework named OntoPath to predict the next drug in disease treatment pathways, by building an ontology-aware hierarchical-attention model that integrates multiple medical evidence from domain knowledge guidance, medical history profiling, and side information utilization. Specifically, our method can be characterized from three aspects: (1) by incorporating the longitudinal diagnosis history, we enrich the profiling of patients in terms of comprehensive health conditions, which can largely influence a drug’s outcome on individual patients; (2) using the hierarchical disease and drug ontology structures, we are able to model the domain-specific relevance between patients and drugs at multiple levels of granularity and achieve in-depth collaborative filtering; (3) we introduce a pre-training stage to enhance the discriminativeness of network representations, which helps us obtain a premium model initialization to further boost the final recommendation training. We perform extensive experiments on a large-scale depression cohort with over 37,000 patients from a real-world medical claims database. The quantitative and qualitative results demonstrate the effectiveness of OntoPath through the consistent outperformance over state-of-the-art prescription recommendation baselines and the interpretation of model mechanism in case studies.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4315779631",
    "type": "article"
  },
  {
    "title": "SetRank: A Setwise Bayesian Approach for Collaborative Ranking in Recommender System",
    "doi": "https://doi.org/10.1145/3626194",
    "publication_date": "2023-10-03",
    "publication_year": 2023,
    "authors": "Chao Wang; Hengshu Zhu; Chen Zhu; Chuan Qin; Enhong Chen; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "The recent development of recommender systems has a focus on collaborative ranking, which provides users with a sorted list rather than rating prediction. The sorted item lists can more directly reflect the preferences for users and usually perform better than rating prediction in practice. While considerable efforts have been made in this direction, the well-known pairwise and listwise approaches have still been limited by various challenges. Specifically, for the pairwise approaches, the assumption of independent pairwise preference is not always held in practice. Also, the listwise approaches cannot efficiently accommodate “ties” and unobserved data due to the precondition of the entire list permutation. To this end, in this article, we propose a novel setwise Bayesian approach for collaborative ranking, namely, SetRank, to inherently accommodate the characteristics of user feedback in recommender systems. SetRank aims to maximize the posterior probability of novel setwise preference structures and three implementations for SetRank are presented. We also theoretically prove that the bound of excess risk in SetRank can be proportional to \\(\\sqrt {M/N}\\) , where M and N are the numbers of items and users, respectively. Finally, extensive experiments on four real-world datasets clearly validate the superiority of SetRank compared with various state-of-the-art baselines.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4387311382",
    "type": "article"
  },
  {
    "title": "Contrastive Multi-view Interest Learning for Cross-domain Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3632402",
    "publication_date": "2023-11-09",
    "publication_year": 2023,
    "authors": "Tianzi Zang; Yanmin Zhu; Ruohan Zhang; Chunyang Wang; Ke Wang; Jiadi Yu",
    "corresponding_authors": "",
    "abstract": "Cross-domain recommendation (CDR), which leverages information collected from other domains, has been empirically demonstrated to effectively alleviate data sparsity and cold-start problems encountered in traditional recommendation systems. However, current CDR methods, including those considering time information, do not jointly model the general and current interests within and across domains, which is pivotal for accurately predicting users’ future interactions. In this article, we propose a Contrastive learning-enhanced Multi-View interest learning model (CMVCDR) for cross-domain sequential recommendation. Specifically, we design a static view and a sequential view to model uses’ general interests and current interests, respectively. We divide a user’s general interest representation into a domain-invariant part and a domain-specific part. A cross-domain contrastive learning objective is introduced to impose constraints for optimizing these representations. In the sequential view, we first devise an attention mechanism guided by users’ domain-invariant interest representations to distill cross-domain knowledge pertaining to domain-invariant factors while reducing noise from irrelevant factors. We further design a domain-specific interest-guided temporal information aggregation mechanism to generate users’ current interest representations. Extensive experiments demonstrate the effectiveness of our proposed model compared with state-of-the-art methods.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4388532091",
    "type": "article"
  },
  {
    "title": "A Unified Framework for Multi-Domain CTR Prediction via Large Language Models",
    "doi": "https://doi.org/10.1145/3698878",
    "publication_date": "2024-10-14",
    "publication_year": 2024,
    "authors": "Zichuan Fu; Xiangyang Li; Chuhan Wu; Yichao Wang; Kuicai Dong; Xiangyu Zhao; Mengchen Zhao; Huifeng Guo; Ruiming Tang",
    "corresponding_authors": "",
    "abstract": "Multi-Domain Click-Through Rate (MDCTR) prediction is crucial for online recommendation platforms, which involves providing personalized recommendation services to users in different domains. However, current MDCTR models are confronted with the following limitations. Firstly, due to varying data sparsity in different domains, models can easily be dominated by some specific domains, which leads to significant performance degradation in other domains (i.e., the “seesaw phenomenon”). Secondly, when new domain emerges, the scalability of existing methods is limited, making it difficult to adapt to the dynamic growth of the domain. Traditional MDCTR models usually use one-hot encoding for semantic information such as product titles, thus losing rich semantic information and leading to insufficient generalization of the model. In this paper, we propose a novel solution Uni-CTR to address these challenges. Uni-CTR leverages Large Language Model (LLM) to extract layer-wise semantic representations that capture domain commonalities, mitigating the seesaw phenomenon and enhancing generalization. Besides, it incorporates a pluggable domain-specific network to capture domain characteristics, ensuring scalability to dynamic domain growth. Experimental results on public datasets and industrial scenarios show that Uni-CTR significantly outperforms state-of-the-art (SOTA) models. In addition, Uni-CTR shows significant results in zero shot prediction. Code is available at https://anonymous.4open.science/r/multi-domain .",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4403395420",
    "type": "article"
  },
  {
    "title": "Predicate rewriting for translating Boolean queries in a heterogeneous information system",
    "doi": "https://doi.org/10.1145/297117.297120",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Chen-Chuan K. Chang; Héctor García-Molina; Andreas Paepcke",
    "corresponding_authors": "",
    "abstract": "Searching over heterogeneous information sources is difficult in part because of the nonuniform query languages. Our approach is to allow users to compose Boolean queries in one rich front-end language. For each user query and target source, we transform the user query into a subsuming query that can be supported by the source but that may return extra documents. The results are then processed by a filter query to yield the correct final results. In this article we introduce the architecture and associated mechanism for query translation. In particular, we discuss techniques for rewriting predicates in Boolean queries into native subsuming forms, which is a basis of translating complex queries. In addition, we present experimental results for evaluating the cost of postfiltering. We also discuss the drawbacks of this approach and cases when it may not be effective. We have implemented prototype versions of these mechanisms and demonstrated them on heterogeneous Boolean systems.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2150117670",
    "type": "article"
  },
  {
    "title": "Capturing, structuring, and representing ubiquitous audio",
    "doi": "https://doi.org/10.1145/159764.159761",
    "publication_date": "1993-10-01",
    "publication_year": 1993,
    "authors": "Debby Hindus; Chris Schmandt; Chris Horner",
    "corresponding_authors": "",
    "abstract": "Although talking is an integral part of collaboration, there has been little computer support for acquiring and accessing the contents of conversations. Our approach has focused on ubiquitous audio , or the unobtrusive capture of speech interactions in everyday work environments. Speech recognition technology cannot yet transcribe fluent conversational speech, so the words themselves are not available for organizing the captured interactions. Instead, the structure of an interaction is derived from acoustical information inherent in the stored speech and augmented by user interaction during or after capture. This article describes applications for capturing and structuring audio from office discussions and telephone calls, and mechanisms for later retrieval of these stored interactions. An important aspect of retrieval is choosing an appropriate visual representation, and this article describes the evolution of a family of representations across a range of applications. Finally, this work is placed within the broader context of desktop audio, mobile audio applications, and social implications.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W1968762078",
    "type": "article"
  },
  {
    "title": "The effect of accessing nonmatching documents on relevance feedback",
    "doi": "https://doi.org/10.1145/248625.248650",
    "publication_date": "1997-04-01",
    "publication_year": 1997,
    "authors": "Mark Dunlop",
    "corresponding_authors": "Mark Dunlop",
    "abstract": "Traditional information retrieval (IR) systems only allow users access to documents that match their current query, and therefore, users can only give relevance feedback on matching documents (or those with a matching strength greater than a set threshold. This article shows that, in systems that allow access to nonmatching documents (e.g., hybrid hypertext and information retrieval systems), the strength of the effect of giving relevance feedback varies between matching and nonmatching documents. For positive feedback the results shown here are encouraging, as they can be justified by an intuitive view of the process. However, for negative feedback the results show behavior that cannot easily be justified and that varies greatly depending on the model of feedback used.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2035798593",
    "type": "article"
  },
  {
    "title": "Toward a logical/physical theory of spreadsheet modeling",
    "doi": "https://doi.org/10.1145/195705.195708",
    "publication_date": "1995-01-02",
    "publication_year": 1995,
    "authors": "Tomás Isakowitz; Shimon Schocken; Henry C. Lucas",
    "corresponding_authors": "",
    "abstract": "In spite of the increasing sophistication and power of commercial spreadsheet packages, we still lack a formal theory or a methodology to support the construction and maintenance of spreadsheet models. Using a dual logical/physical perspective, we identify four principal components that characterize any spread sheet model: schema, data, editorial, and binding . We present a factoring algorithm for identifying and extracting these components from conventional spreadsheets with minimal user intervention, and a synthesis algorithm that assists users in the construction of executable spreadsheets from reusable model components. This approach opens new possibilities for applying object-oriented and model management techniques to support the construction, sharing, and reuse of spreadsheet models in organizations. Importantly, our approach to model management and the Windows-based prototype that we have developed are designed to coexist with, rather than replace , traditional spreadsheet programs. In other words, the users are not required to learn a new modeling language; instead, their logical models and data sets are extracted from their spreadsheets transparently, as a side-effect of using standard spreadsheet programs.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W3122827791",
    "type": "article"
  },
  {
    "title": "Incremental formalization with the hyper-object substrate",
    "doi": "https://doi.org/10.1145/306686.306690",
    "publication_date": "1999-04-01",
    "publication_year": 1999,
    "authors": "Frank Shipman; Raymond J. McCall",
    "corresponding_authors": "",
    "abstract": "Computers require formally represented information to perform computations that support users; yet users who have needed such support have often proved to be unable or unwilling to formalize it. To address this problem, this article introduces an approach called incremental formalization, in which, first, users express information informally and then the system aids them in formalizing it. Incremental formalization requires a system architecture the (1) integrates formal and informal representations and (2) supports progressive formalization of information. The system should have both tools to capture naturally available informal information and techniques to suggest possible formalizations of this information. The hyper-object substrate (HOS) was developed to satisfy these requirements. HOS has been applied to a number of problem domains, including network design, archeological site analysis, and neuroscience education. Users have been successful in adding informal information and then later formalizing it incrementally with the aid of the system. Our experience with HOS has reaffirmed the need for information spaces to evolve during use and has identified additional considerations in the design and instantiation of systems enabling and supporting incremental formalization",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2035721382",
    "type": "article"
  },
  {
    "title": "Search improvement via automatic query reformulation",
    "doi": "https://doi.org/10.1145/125187.125193",
    "publication_date": "1991-07-01",
    "publication_year": 1991,
    "authors": "Susan Gauch; John B. Smith",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Search improvement via automatic query reformulation Authors: Susan Gauch Univ. of North Carolina Univ. of North CarolinaView Profile , John B. Smith Univ. of North Carolina Univ. of North CarolinaView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 9Issue 3pp 249–280https://doi.org/10.1145/125187.125193Published:01 July 1991Publication History 26citation979DownloadsMetricsTotal Citations26Total Downloads979Last 12 Months18Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2060702445",
    "type": "article"
  },
  {
    "title": "A design method for “whole-hand” human-computer interaction",
    "doi": "https://doi.org/10.1145/159161.159159",
    "publication_date": "1993-07-01",
    "publication_year": 1993,
    "authors": "David J. Sturman; Lonnie K. Zeltzer",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on A design method for “whole-hand” human-computer interaction Authors: David J. Sturman View Profile , David Zeltzer View Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 11Issue 3July 1993 pp 219–238https://doi.org/10.1145/159161.159159Published:01 July 1993Publication History 34citation1,193DownloadsMetricsTotal Citations34Total Downloads1,193Last 12 Months41Last 6 weeks10 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W1993740557",
    "type": "article"
  },
  {
    "title": "A maximal figure-of-merit (MFoM)-learning approach to robust classifier design for text categorization",
    "doi": "https://doi.org/10.1145/1148020.1148022",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Sheng Gao; Wen Wu; Chin‐Hui Lee; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "We propose a maximal figure-of-merit (MFoM)-learning approach for robust classifier design, which directly optimizes performance metrics of interest for different target classifiers. The proposed approach, embedding the decision functions of classifiers and performance metrics into an overall training objective, learns the parameters of classifiers in a decision-feedback manner to effectively take into account both positive and negative training samples, thereby reducing the required size of positive training data. It has three desirable properties: (a) it is a performance metric, oriented learning; (b) the optimized metric is consistent in both training and evaluation sets; and (c) it is more robust and less sensitive to data variation, and can handle insufficient training data scenarios. We evaluate it on a text categorization task using the Reuters-21578 dataset. Training an F 1 -based binary tree classifier using MFoM, we observed significantly improved performance and enhanced robustness compared to the baseline and SVM, especially for categories with insufficient training samples. The generality for designing other metrics-based classifiers is also demonstrated by comparing precision, recall, and F 1 -based classifiers. The results clearly show consistency of performance between the training and evaluation stages for each classifier, and MFoM optimizes the chosen metric.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2013477326",
    "type": "article"
  },
  {
    "title": "Converting a textbook to hypertext",
    "doi": "https://doi.org/10.1145/146760.146791",
    "publication_date": "1992-07-01",
    "publication_year": 1992,
    "authors": "Roy Rada",
    "corresponding_authors": "Roy Rada",
    "abstract": "Traditional documents may be transformed into hypertext by first reflecting the document's logical markup in the hypertext (producing first-order hypertext) and then by adding links not evident in the document markup (producing second-order hypertext). In our transformation of a textbook to hypertext, the textbook is placed in an intermediate form based on a semantic net and is then placed into the four hypertext systems: Emacs-Info, Guide, HyperTies, and Super-Book. The first-order Guide and SuperBook hypertexts reflect a depth-first traversal of the semantic net, and the Emacs-Info and HyperTies hypertexts reflect a breadth-first traversal. The semantic net is augmented manually, and then new traversal programs automatically generate alternate outlines. An index based on work patterns in the textbook is also automatically generated for the second-order hypertext. Our suite of programs has been applied to a published textbook, and the resulting hypertexts are publicly available.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2025159368",
    "type": "article"
  },
  {
    "title": "A system for the static analysis of XPath",
    "doi": "https://doi.org/10.1145/1185877.1185882",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Pierre Genevès; Nabil Layaïda",
    "corresponding_authors": "",
    "abstract": "XPath is the standard language for navigating XML documents and returning a set of matching nodes. We present a sound and complete decision procedure for containment of XPath queries, as well as other related XPath decision problems such as satisfiability, equivalence, overlap, and coverage. The considered XPath fragment covers most of the language features used in practice. Specifically, we propose a unifying logic for XML, namely, the alternation-free modal μ-calculus with converse. We show how to translate major XML concepts such as XPath and regular XML types (including DTDs) into this logic. Based on these embeddings, we show how XPath decision problems, in the presence or absence of XML types, can be solved using a decision procedure for μ-calculus satisfiability. We provide a complexity analysis of our system together with practical experiments to illustrate the efficiency of the approach for realistic scenarios.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W1992381179",
    "type": "article"
  },
  {
    "title": "The constituent object parser: syntactic structure matching for information retrieval",
    "doi": "https://doi.org/10.1145/65943.65949",
    "publication_date": "1989-07-01",
    "publication_year": 1989,
    "authors": "Douglas P. Metzler; Stephanie W. Haas",
    "corresponding_authors": "",
    "abstract": "The Constituent Object Parser is a shallow syntactic parser designed to produce dependency tree representations of syntactic structure that can be used to specify the intended meanings of a sentence more precisely than can the key terms of the sentence alone. It is intended to improve the precision/recall performance of information retrieval and similar text processing applications by providing more powerful matching procedures. The dependency tree representation and the relationship between the intended use of this parser and its design is described, and several problems concerning the processing of ambiguous structures are discussed.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2073826624",
    "type": "article"
  },
  {
    "title": "Wireless intraoffice networks",
    "doi": "https://doi.org/10.1145/45945.45946",
    "publication_date": "1988-07-01",
    "publication_year": 1988,
    "authors": "Kaveh Pahlavan",
    "corresponding_authors": "Kaveh Pahlavan",
    "abstract": "An overview of the existing and growing demands for wireless office information networks is provided, and the existing research activities are assessed in some detail. The radio frequency (RF) and infrared (IR) communication technologies are examined as candidates for wireless intraoffice communications. The available bandwidths, according to federal regulations and characteristics of the channel for RF communications, are given. Digital narrow-band and wideband spread-spectrum RF communications are assessed in terms of supportable data rate or number of simultaneous users in one cell of a cellular architecture in an office environment. Various limitations of IR communications are discussed and existing systems and architectures are reviewed.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2035274407",
    "type": "article"
  },
  {
    "title": "Articulating information needs in XML query languages",
    "doi": "https://doi.org/10.1145/1185877.1185879",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Jaap Kamps; M. Marx; Maarten de Rijke; Börkur Sigurbjörnsson",
    "corresponding_authors": "",
    "abstract": "Document-centric XML is a mixture of text and structure. With the increased availability of document-centric XML documents comes a need for query facilities in which both structural constraints and constraints on the content of the documents can be expressed. How does the expressiveness of languages for querying XML documents help users to express their information needs? We address this question from both an experimental and a theoretical point of view. Our experimental analysis compares a structure-ignorant with a structure-aware retrieval approach using the test suite of the INEX XML Retrieval Evaluation Initiative. Theoretically, we create two mathematical models of users' knowledge of a set of documents and define query languages which exactly fit these models. One of these languages corresponds to an XML version of fielded search, the other to the INEX query language.Our main experimental findings are: First, while structure is used in varying degrees of complexity, two-thirds of the queries can be expressed in a fielded-search-like format which does not use the hierarchical structure of the documents. Second, three-quarters of the queries use constraints on the context of the elements to be returned; these contextual constraints cannot be captured by ordinary keyword queries. Third, structure is used as a search hint, and not as a strict requirement, when judged against the underlying information need. Fourth, the use of structure in queries functions as a precision enhancing device.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2115181285",
    "type": "article"
  },
  {
    "title": "The 3DIS: an extensible object-oriented information management environment",
    "doi": "https://doi.org/10.1145/76158.76892",
    "publication_date": "1989-10-01",
    "publication_year": 1989,
    "authors": "Hamideh Afsarmanesh; Dennis McLeod",
    "corresponding_authors": "",
    "abstract": "The 3-Dimensional Information Space (3DIS) is an extensible object-oriented framework for information management. It is specifically oriented toward supporting the database requirements for data-intensive information system applications in which (1) information objects of various levels of abstraction and modalities must be accommodated, (2) descriptive and structural information (metadata) is rich and dynamic, and (3) users who are not database experts must be able to design, manipulate, and evolve databases. In response to these needs, the 3DIS provides an approach in which data and the descriptive information about data are handled uniformly in an extensible framework. The 3DIS provides a simple, geometric, and formal representation of data which forms a basis for understanding, defining, and manipulating databases. Several prototype implementations based upon the 3DIS have been designed and implemented and are in experimental use.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2130319223",
    "type": "article"
  },
  {
    "title": "Summary in context",
    "doi": "https://doi.org/10.1145/1125857.1125861",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Daniel McDonald; Hsinchun Chen",
    "corresponding_authors": "",
    "abstract": "The use of text summaries in information-seeking research has focused on query-based summaries. Extracting content that resembles the query alone, however, ignores the greater context of the document. Such context may be central to the purpose and meaning of the document. We developed a generic, a query-based, and a hybrid summarizer, each with differing amounts of document context. The generic summarizer used a blend of discourse information and information obtained through traditional surface-level analysis. The query-based summarizer used only query-term information, and the hybrid summarizer used some discourse information along with query-term information. The validity of the generic summarizer was shown through an intrinsic evaluation using a well-established corpus of human-generated summaries. All three summarizers were then compared in an information-seeking experiment involving 297 subjects. Results from the information-seeking experiment showed that the generic summaries outperformed all others in the browse tasks, while the query-based and hybrid summaries outperformed the generic summary in the search tasks. Thus, the document context of generic summaries helped users browse, while such context was not helpful in search tasks. Such results are interesting given that generic summaries have not been studied in search tasks and the that majority of Internet search engines rely solely on query-based summaries.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W1986429008",
    "type": "article"
  },
  {
    "title": "LDC-1",
    "doi": "https://doi.org/10.1145/357417.357418",
    "publication_date": "1984-01-01",
    "publication_year": 1984,
    "authors": "Bruce W. Ballard; John C. Lusth; Nancy Lynn Tinkham",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on LDC-1: a transportable, knowledge-based natural language processor for office environments Authors: Bruce W. Ballard Dept. of Computer Science, Duke Univ., Durham, NC Dept. of Computer Science, Duke Univ., Durham, NCView Profile , John C. Lusth Dept. of Computer Science, Duke Univ., Durham, NC Dept. of Computer Science, Duke Univ., Durham, NCView Profile , Nancy L. Tinkham Dept. of Computer Science, Duke Univ., Durham, NC Dept. of Computer Science, Duke Univ., Durham, NCView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 1Jan. 1984 pp 1–25https://doi.org/10.1145/357417.357418Published:01 January 1984Publication History 24citation436DownloadsMetricsTotal Citations24Total Downloads436Last 12 Months19Last 6 weeks3 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2060583091",
    "type": "article"
  },
  {
    "title": "Cooperating knowledge-based assistants for the office",
    "doi": "https://doi.org/10.1145/42196.42197",
    "publication_date": "1987-10-01",
    "publication_year": 1987,
    "authors": "A.R. Kaye; G.M. Karam",
    "corresponding_authors": "",
    "abstract": "This paper presents an approach to high-level support of office workers by embedding office knowledge in a network of distributed cooperating knowledge-based or expert “assistants” and servers. These knowledge-based systems incorporate both factual and procedural knowledge and are capable of making use of existing conventional office technology. They constitute a form of computer-supported cooperative work. We describe a common architecture for our assistants and servers that incorporates several key features. Our systems are capable of supporting concurrent multiple consultations or tasks and have facilities for the interruption and resumption of consultations as appropriate. The various assistants and servers, which may reside on different machines, cooperate in solving problems or completing tasks by passing messages. We propose a taxonomy of the general office knowledge normally used by office workers, together with a frame and rule-based knowledge representation scheme. We also describe an experimental system, written in PROLOG, that incorporates the above design principles.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2065368039",
    "type": "article"
  },
  {
    "title": "On ranking techniques for desktop search",
    "doi": "https://doi.org/10.1145/1344411.1344417",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Sara Cohen; Carmel Domshlak; Naama Zwerdling",
    "corresponding_authors": "",
    "abstract": "Users tend to store huge amounts of files, of various formats, on their personal computers. As a result, finding a specific, desired file within the file system is a challenging task. This article addresses the desktop search problem by considering various techniques for ranking results of a search query over the file system. First, basic ranking techniques, which are based on various file features (e.g., file name, access date, file size, etc.), are considered and their effectiveness is empirically analyzed. Next, two learning-based ranking schemes are presented, and are shown to be significantly more effective than the basic ranking methods. Finally, a novel ranking technique, based on query selectiveness, is considered for use during the cold-start period of the system. This method is also shown to be empirically effective, even though it does not involve any learning.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W1985405940",
    "type": "article"
  },
  {
    "title": "Trusting spam reporters",
    "doi": "https://doi.org/10.1145/1416950.1416953",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Elena Zheleva; Aleksander Kołcz; Lise Getoor",
    "corresponding_authors": "",
    "abstract": "Spam is a growing problem; it interferes with valid email and burdens both email users and service providers. In this work, we propose a reactive spam-filtering system based on reporter reputation for use in conjunction with existing spam-filtering techniques. The system has a trust-maintenance component for users, based on their spam-reporting behavior. The challenge that we consider is that of maintaining a reliable system, not vulnerable to malicious users, that will provide early spam-campaign detection to reduce the costs incurred by users and systems. We report on the utility of a reputation system for spam filtering that makes use of the feedback of trustworthy users. We evaluate our proposed framework, using actual complaint feedback from a large population of users, and validate its spam-filtering performance on a collection of real email traffic over several weeks. To test the broader implication of the system, we create a model of the behavior of malicious reporters, and we simulate the system under various assumptions using a synthetic dataset.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W1983777919",
    "type": "article"
  },
  {
    "title": "Automatic metadata generation using associative networks",
    "doi": "https://doi.org/10.1145/1462198.1462199",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Marko A. Rodriguez; Johan Bollen; Herbert Van de Sompel",
    "corresponding_authors": "",
    "abstract": "In spite of its tremendous value, metadata is generally sparse and incomplete, thereby hampering the effectiveness of digital information services. Many of the existing mechanisms for the automated creation of metadata rely primarily on content analysis which can be costly and inefficient. The automatic metadata generation system proposed in this article leverages resource relationships generated from existing metadata as a medium for propagation from metadata-rich to metadata-poor resources. Because of its independence from content analysis, it can be applied to a wide variety of resource media types and is shown to be computationally inexpensive. The proposed method operates through two distinct phases. Occurrence and cooccurrence algorithms first generate an associative network of repository resources leveraging existing repository metadata. Second, using the associative network as a substrate, metadata associated with metadata-rich resources is propagated to metadata-poor resources by means of a discrete-form spreading activation algorithm. This article discusses the general framework for building associative networks, an algorithm for disseminating metadata through such networks, and the results of an experiment and validation of the proposed method using a standard bibliographic dataset.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2116127118",
    "type": "article"
  },
  {
    "title": "Dynamic lightweight text compression",
    "doi": "https://doi.org/10.1145/1777432.1777433",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Nieves R. Brisaboa; Antonio Fariña; Gonzalo Navarro; José R. Paramá",
    "corresponding_authors": "",
    "abstract": "We address the problem of adaptive compression of natural language text, considering the case where the receiver is much less powerful than the sender, as in mobile applications. Our techniques achieve compression ratios around 32% and require very little effort from the receiver. Furthermore, the receiver is not only lighter, but it can also search the compressed text with less work than that necessary to decompress it. This is a novelty in two senses: it breaks the usual compressor/decompressor symmetry typical of adaptive schemes, and it contradicts the long-standing assumption that only semistatic codes could be searched more efficiently than the uncompressed text. Our novel compression methods are preferable in several aspects over the existing adaptive and semistatic compressors for natural language texts.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2070641109",
    "type": "article"
  },
  {
    "title": "MUADDIB",
    "doi": "https://doi.org/10.1145/1629096.1629102",
    "publication_date": "2009-11-01",
    "publication_year": 2009,
    "authors": "Domenico Rosaci; Giuseppe M. L. Sarné; Salvatore Garruzzo",
    "corresponding_authors": "",
    "abstract": "Web recommender systems are Web applications capable of generating useful suggestions for visitors of Internet sites. However, in the case of large user communities and in presence of a high number of Web sites, these tasks are computationally onerous, even more if the client software runs on devices with limited resources. Moreover, the quality of the recommendations strictly depends on how the recommendation algorithm takes into account the currently used device. Some approaches proposed in the literature provide multidimensional recommendations considering, besides items and users, also the exploited device. However, these systems do not efficiently perform, since they assign to either the client or the server the arduous cost of computing recommendations. In this article, we argue that a fully distributed organization is a suitable solution to improve the efficiency of multidimensional recommender systems. In order to address these issues, we propose a novel distributed architecture, called MUADDIB, where each user's device is provided with a device assistant that autonomously retrieves information about the user's behavior. Moreover, a single profiler , associated with the user, periodically collects information coming from the different user's device assistants to construct a global user's profile. In order to generate recommendations, a recommender precomputes data provided by the profilers. This way, the site manager has only the task of suitably presenting the content of the site, while the computation of the recommendations is assigned to the other distributed components. Some experiments conducted on real data and using some well-known metrics show that the system works more effectively and efficiently than other device-based distributed recommenders.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2001979729",
    "type": "article"
  },
  {
    "title": "Exploring the music similarity space on the web",
    "doi": "https://doi.org/10.1145/1993036.1993038",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Markus Schedl; Tim Pohle; Peter Knees; Gerhard Widmer",
    "corresponding_authors": "",
    "abstract": "This article comprehensively addresses the problem of similarity measurement between music artists via text-based features extracted from Web pages. To this end, we present a thorough evaluation of different term-weighting strategies, normalization methods, aggregation functions, and similarity measurement techniques. In large-scale genre classification experiments carried out on real-world artist collections, we analyze several thousand combinations of settings/parameters that influence the similarity calculation process, and investigate in which way they impact the quality of the similarity estimates. Accurate similarity measures for music are vital for many applications, such as automated playlist generation, music recommender systems, music information systems, or intelligent user interfaces to access music collections by means beyond text-based browsing. Therefore, by exhaustively analyzing the potential of text-based features derived from artist-related Web pages, this article constitutes an important contribution to context-based music information research.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2049322458",
    "type": "article"
  },
  {
    "title": "Tuning the capacity of search engines",
    "doi": "https://doi.org/10.1145/1740592.1740593",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Diégo Puppin; Fabrizio Silvestri; Raffaele Perego; Ricardo Baeza‐Yates",
    "corresponding_authors": "",
    "abstract": "This article introduces an architecture for a document-partitioned search engine, based on a novel approach combining collection selection and load balancing, called load-driven routing . By exploiting the query-vector document model, and the incremental caching technique, our architecture can compute very high quality results for any query, with only a fraction of the computational load used in a typical document-partitioned architecture. By trading off a small fraction of the results, our technique allows us to strongly reduce the computing pressure to a search engine back-end; we are able to retrieve more than 2/3 of the top-5 results for a given query with only 10% the computing load needed by a configuration where the query is processed by each index partition. Alternatively, we can slightly increase the load up to 25% to improve precision and get more than 80% of the top-5 results. In fact, the flexibility of our system allows a wide range of different configurations, so as to easily respond to different needs in result quality or restrictions in computing power. More important, the system configuration can be adjusted dynamically in order to fit unexpected query peaks or unpredictable failures. This article wraps up some recent works by the authors, showing the results obtained by tests conducted on 6 million documents, 2,800,000 queries and real query cost timing as measured on an actual index.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2135764309",
    "type": "article"
  },
  {
    "title": "The task-dependent effect of tags and ratings on social media access",
    "doi": "https://doi.org/10.1145/1852102.1852107",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Maarten Clements; Arjen P. de Vries; Marcel Reinders",
    "corresponding_authors": "",
    "abstract": "Recently, online social networks have emerged that allow people to share their multimedia files, retrieve interesting content, and discover like-minded people. These systems often provide the possibility to annotate the content with tags and ratings. Using a random walk through the social annotation graph, we have combined these annotations into a retrieval model that effectively balances the personal preferences and opinions of like-minded users into a single relevance ranking for either content, tags, or people. We use this model to identify the influence of different annotation methods and system design aspects on common ranking tasks in social content systems. Our results show that a combination of rating and tagging information can improve tasks like search and recommendation. The optimal influence of both sources on the ranking is highly dependent on the retrieval task and system design. Results on content search and tag suggestion indicate that the profile created by a user's annotations can be used effectively to adapt the ranking to personal preferences. The random walk reduces sparsity problems by smoothly integrating indirectly related concepts in the relevance ranking, which is especially valuable for cold-start users or individual tagging systems like YouTube and Flickr.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2027186630",
    "type": "article"
  },
  {
    "title": "Exploiting query logs for cross-lingual query suggestions",
    "doi": "https://doi.org/10.1145/1740592.1740594",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Wei Gao; Cheng Niu; Jian‐Yun Nie; Ming Zhou; Kam‐Fai Wong; Hsiao-Wuen Hon",
    "corresponding_authors": "",
    "abstract": "Query suggestion aims to suggest relevant queries for a given query, which helps users better specify their information needs. Previous work on query suggestion has been limited to the same language. In this article, we extend it to cross-lingual query suggestion (CLQS): for a query in one language, we suggest similar or relevant queries in other languages. This is very important to the scenarios of cross-language information retrieval (CLIR) and other related cross-lingual applications. Instead of relying on existing query translation technologies for CLQS, we present an effective means to map the input query of one language to queries of the other language in the query log. Important monolingual and cross-lingual information such as word translation relations and word co-occurrence statistics, and so on, are used to estimate the cross-lingual query similarity with a discriminative model. Benchmarks show that the resulting CLQS system significantly outperforms a baseline system that uses dictionary-based query translation. Besides, we evaluate CLQS with French-English and Chinese-English CLIR tasks on TREC-6 and NTCIR-4 collections, respectively. The CLIR experiments using typical retrieval models demonstrate that the CLQS-based approach has significantly higher effectiveness than several traditional query translation methods. We find that when combined with pseudo-relevance feedback, the effectiveness of CLIR using CLQS is enhanced for different pairs of languages.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2046353967",
    "type": "article"
  },
  {
    "title": "Arnoldi versus GMRES for computing pageRank",
    "doi": "https://doi.org/10.1145/1777432.1777434",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Gang Wu; Yimin Wei",
    "corresponding_authors": "",
    "abstract": "PageRank is one of the most important ranking techniques used in today's search engines. A recent very interesting research track focuses on exploiting efficient numerical methods to speed up the computation of PageRank, among which the Arnoldi-type algorithm and the GMRES algorithm are competitive candidates. In essence, the former deals with the PageRank problem from an eigenproblem, while the latter from a linear system, point of view. However, there is little known about the relations between the two approaches for PageRank. In this article, we focus on a theoretical and numerical comparison of the two approaches. Numerical experiments illustrate the effectiveness of our theoretical results.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2085687199",
    "type": "article"
  },
  {
    "title": "Mining pure high-order word associations via information geometry for information retrieval",
    "doi": "https://doi.org/10.1145/2493175.2493177",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "Yuexian Hou; Xiaozhao Zhao; Dawei Song; Wenjie Li",
    "corresponding_authors": "",
    "abstract": "The classical bag-of-word models for information retrieval (IR) fail to capture contextual associations between words. In this article, we propose to investigate pure high-order dependence among a number of words forming an unseparable semantic entity, that is, the high-order dependence that cannot be reduced to the random coincidence of lower-order dependencies. We believe that identifying these pure high-order dependence patterns would lead to a better representation of documents and novel retrieval models. Specifically, two formal definitions of pure dependence—unconditional pure dependence (UPD) and conditional pure dependence (CPD)—are defined. The exact decision on UPD and CPD, however, is NP-hard in general. We hence derive and prove the sufficient criteria that entail UPD and CPD, within the well-principled information geometry (IG) framework, leading to a more feasible UPD/CPD identification procedure. We further develop novel methods for extracting word patterns with pure high-order dependence. Our methods are applied to and extensively evaluated on three typical IR tasks: text classification and text retrieval without and with query expansion.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2071225717",
    "type": "article"
  },
  {
    "title": "Web Query Reformulation via Joint Modeling of Latent Topic Dependency and Term Context",
    "doi": "https://doi.org/10.1145/2699666",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Lidong Bing; Wai Lam; Tak-Lam Wong; Shoaib Jameel",
    "corresponding_authors": "",
    "abstract": "An important way to improve users’ satisfaction in Web search is to assist them by issuing more effective queries. One such approach is query reformulation, which generates new queries according to the current query issued by users. A common procedure for conducting reformulation is to generate some candidate queries first, then a scoring method is employed to assess these candidates. Currently, most of the existing methods are context based. They rely heavily on the context relation of terms in the history queries and cannot detect and maintain the semantic consistency of queries. In this article, we propose a graphical model to score queries. The proposed model exploits a latent topic space, which is automatically derived from the query log, to detect semantic dependency of terms in a query and dependency among topics. Meanwhile, the graphical model also captures the term context in the history query by skip-bigram and n-gram language models. In addition, our model can be easily extended to consider users’ history search interests when we conduct query reformulation for different users. In the task of candidate query generation, we investigate a social tagging data resource—Delicious bookmark—to generate addition and substitution patterns that are employed as supplements to the patterns generated from query log data.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2006271460",
    "type": "article"
  },
  {
    "title": "User Modeling on Demographic Attributes in Big Mobile Social Networks",
    "doi": "https://doi.org/10.1145/3057278",
    "publication_date": "2017-07-11",
    "publication_year": 2017,
    "authors": "Yuxiao Dong; Nitesh V. Chawla; Jie Tang; Yang Yang; Yang Yang",
    "corresponding_authors": "",
    "abstract": "Users with demographic profiles in social networks offer the potential to understand the social principles that underpin our highly connected world, from individuals, to groups, to societies. In this article, we harness the power of network and data sciences to model the interplay between user demographics and social behavior and further study to what extent users’ demographic profiles can be inferred from their mobile communication patterns. By modeling over 7 million users and 1 billion mobile communication records, we find that during the active dating period (i.e., 18--35 years old), users are active in broadening social connections with males and females alike, while after reaching 35 years of age people tend to keep small, closed, and same-gender social circles. Further, we formalize the demographic prediction problem of inferring users’ gender and age simultaneously. We propose a factor graph-based WhoAmI method to address the problem by leveraging not only the correlations between network features and users’ gender/age, but also the interrelations between gender and age. In addition, we identify a new problem—coupled network demographic prediction across multiple mobile operators—and present a coupled variant of the WhoAmI method to address its unique challenges. Our extensive experiments demonstrate the effectiveness, scalability, and applicability of the WhoAmI methods. Finally, our study finds a greater than 80% potential predictability for inferring users’ gender from phone call behavior and 73% for users’ age from text messaging interactions.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2735108298",
    "type": "article"
  },
  {
    "title": "A Deep Bayesian Tensor-Based System for Video Recommendation",
    "doi": "https://doi.org/10.1145/3233773",
    "publication_date": "2018-12-13",
    "publication_year": 2018,
    "authors": "Wei Lü; Fu-Lai Chung; Wenhao Jiang; Martin Ester; Wei Liu",
    "corresponding_authors": "",
    "abstract": "With the availability of abundant online multi-relational video information, recommender systems that can effectively exploit these sorts of data and suggest creatively interesting items will become increasingly important. Recent research illustrates that tensor models offer effective approaches for complex multi-relational data learning and missing element completion. So far, most tensor-based user clustering models have focused on the accuracy of recommendation. Given the dynamic nature of online media, recommendation in this setting is more challenging as it is difficult to capture the users’ dynamic topic distributions in sparse data settings as well as to identify unseen items as candidates of recommendation. Targeting at constructing a recommender system that can encourage more creativity, a deep Bayesian probabilistic tensor framework for tag and item recommendation is proposed. During the score ranking processes, a metric called Bayesian surprise is incorporated to increase the creativity of the recommended candidates. The new algorithm, called Deep Canonical PARAFAC Factorization (DCPF), is evaluated on both synthetic and large-scale real-world problems. An empirical study for video recommendation demonstrates the superiority of the proposed model and indicates that it can better capture the latent patterns of interactions and generates interesting recommendations based on creative tag combinations.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2904119337",
    "type": "article"
  },
  {
    "title": "A Comparative Analysis of Interleaving Methods for Aggregated Search",
    "doi": "https://doi.org/10.1145/2668120",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Aleksandr Chuklin; Anne Schuth; Ke Zhou; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "A result page of a modern search engine often goes beyond a simple list of “10 blue links.” Many specific user needs (e.g., News, Image, Video) are addressed by so-called aggregated or vertical search solutions: specially presented documents, often retrieved from specific sources, that stand out from the regular organic Web search results. When it comes to evaluating ranking systems, such complex result layouts raise their own challenges. This is especially true for so-called interleaving methods that have arisen as an important type of online evaluation: by mixing results from two different result pages, interleaving can easily break the desired Web layout in which vertical documents are grouped together, and hence hurt the user experience. We conduct an analysis of different interleaving methods as applied to aggregated search engine result pages. Apart from conventional interleaving methods, we propose two vertical-aware methods: one derived from the widely used Team-Draft Interleaving method by adjusting it in such a way that it respects vertical document groupings, and another based on the recently introduced Optimized Interleaving framework. We show that our proposed methods are better at preserving the user experience than existing interleaving methods while still performing well as a tool for comparing ranking systems. For evaluating our proposed vertical-aware interleaving methods, we use real-world click data as well as simulated clicks and simulated ranking systems.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2007105673",
    "type": "article"
  },
  {
    "title": "X-Class",
    "doi": "https://doi.org/10.1145/2414782.2414785",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Gianni Costa; Riccardo Ortale; Ettore Ritacco",
    "corresponding_authors": "",
    "abstract": "The supervised classification of XML documents by structure involves learning predictive models in which certain structural regularities discriminate the individual document classes. Hitherto, research has focused on the adoption of prespecified substructures. This is detrimental for classification effectiveness, since the a priori chosen substructures may not accord with the structural properties of the XML documents. Therein, an unexplored question is how to choose the type of structural regularity that best adapts to the structures of the available XML documents. We tackle this problem through X-Class, an approach that handles all types of tree-like substructures and allows for choosing the most discriminatory one. Algorithms are designed to learn compact rule-based classifiers in which the chosen substructures discriminate the classes of XML documents. X-Class is studied across various domains and types of substructures. Its classification performance is compared against several rule-based and SVM-based competitors. Empirical evidence reveals that the classifiers induced by X-Class are compact, scalable, and at least as effective as the established competitors. In particular, certain substructures allow the induction of very compact classifiers that generally outperform the rule-based competitors in terms of effectiveness over all chosen corpora of XML data. Furthermore, such classifiers are substantially as effective as the SVM-based competitor, with the additional advantage of a high-degree of interpretability.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2025288138",
    "type": "article"
  },
  {
    "title": "Suggesting Points-of-Interest via Content-Based, Collaborative, and Hybrid Fusion Methods in Mobile Devices",
    "doi": "https://doi.org/10.1145/3125620",
    "publication_date": "2017-09-29",
    "publication_year": 2017,
    "authors": "Avi Arampatzis; Georgios Kalamatianos",
    "corresponding_authors": "",
    "abstract": "Recommending venues or points-of-interest (POIs) is a hot topic in recent years, especially for tourism applications and mobile users. We propose and evaluate several suggestion methods, taking an effectiveness, feasibility, efficiency, and privacy perspective. The task is addressed by two content-based methods (a Weighted kNN classifier and a Rated Rocchio personalized query), Collaborative Filtering methods, as well as several (rank-based or rating-based) methods of merging results of different systems. Effectiveness is evaluated on two standard benchmark datasets, provided and used by TREC’s Contextual Suggestion Tracks in 2015 and 2016. First, we enrich these datasets with more information on venues, collected from web services like Foursquare and Yelp; we make this extra data available for future experimentation. Then, we find that the content-based methods provide state-of-the-art effectiveness, the collaborative filtering variants mostly suffer from data sparsity problems in the current datasets, and the merging methods further improve results by mainly promoting the first relevant suggestion. Concerning mobile feasibility, efficiency, and user privacy, the content-based methods, especially Rated Rocchio, are the best. Collaborative filtering has the worst efficiency and privacy leaks. Our findings can be very useful for developing effective and efficient operational systems, respecting user privacy. Last, our experiments indicate that better benchmark datasets would be welcome, and the use of additional evaluation measures—more sensitive in recall—is recommended.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2758089162",
    "type": "article"
  },
  {
    "title": "Induced Sorting Suffixes in External Memory",
    "doi": "https://doi.org/10.1145/2699665",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Ge Nong; Wai Hong Chan; Sheng Qing Hu; Yi Wu",
    "corresponding_authors": "",
    "abstract": "We present in this article an external memory algorithm, called disk SA-IS (DSA-IS), to exactly emulate the induced sorting algorithm SA-IS previously proposed for sorting suffixes in RAM. DSA-IS is a new disk-friendly method for sequentially retrieving the preceding character of a sorted suffix to induce the order of the preceding suffix. For a size n string of a constant or integer alphabet, given the RAM capacity Ω (( nW ) 0.5 ), where W is the size of each I/O buffer that is large enough to amortize the overhead of each access to disk, both the CPU time and peak disk use of DSA-IS are O ( n ). Our experimental study shows that on average, DSA-IS achieves the best time and space results of all of the existing external memory algorithms based on the induced sorting principle.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2051246034",
    "type": "article"
  },
  {
    "title": "Time-Aware Click Model",
    "doi": "https://doi.org/10.1145/2988230",
    "publication_date": "2016-12-15",
    "publication_year": 2016,
    "authors": "Yiqun Liu; Xiaohui Xie; Chao Wang; Jian‐Yun Nie; Min Zhang; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Click-through information is considered as a valuable source of users’ implicit relevance feedback for commercial search engines. As existing studies have shown that the search result position in a search engine result page (SERP) has a very strong influence on users’ examination behavior, most existing click models are position based, assuming that users examine results from top to bottom in a linear fashion. Although these click models have been successful, most do not take temporal information into account. As many existing studies have shown, click dwell time and click sequence information are strongly correlated with users’ perceived relevance and search satisfaction. Incorporating temporal information may be important to improve performance of user click models for Web searches. In this article, we investigate the problem of properly incorporating temporal information into click models. We first carry out a laboratory eye-tracking study to analyze users’ examination behavior in different click sequences and find that the user common examination path among adjacent clicks is linear. Next, we analyze the user dwell time distribution in different search logs and find that we cannot simply use a click dwell time threshold (e.g., 30 seconds) to distinguish relevant/irrelevant results. Finally, we propose a novel time-aware click model (TACM), which captures the temporal information of user behavior. We compare the TACM to several existing click models using two real-world search engine logs. Experimental results show that the TACM outperforms other click models in terms of both predicting click behavior (perplexity) and estimating result relevance (NDCG).",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2560965260",
    "type": "article"
  },
  {
    "title": "Learning Informative Priors from Heterogeneous Domains to Improve Recommendation in Cold-Start User Domains",
    "doi": "https://doi.org/10.1145/2976737",
    "publication_date": "2016-12-12",
    "publication_year": 2016,
    "authors": "Liang Hu; Longbing Cao; Jian Cao; Zhiping Gu; Guandong Xu; Dingyu Yang",
    "corresponding_authors": "",
    "abstract": "In the real-world environment, users have sufficient experience in their focused domains but lack experience in other domains. Recommender systems are very helpful for recommending potentially desirable items to users in unfamiliar domains, and cross-domain collaborative filtering is therefore an important emerging research topic. However, it is inevitable that the cold-start issue will be encountered in unfamiliar domains due to the lack of feedback data. The Bayesian approach shows that priors play an important role when there are insufficient data, which implies that recommendation performance can be significantly improved in cold-start domains if informative priors can be provided. Based on this idea, we propose a Weighted Irregular Tensor Factorization (WITF) model to leverage multi-domain feedback data across all users to learn the cross-domain priors w.r.t. both users and items. The features learned from WITF serve as the informative priors on the latent factors of users and items in terms of weighted matrix factorization models. Moreover, WITF is a unified framework for dealing with both explicit feedback and implicit feedback. To prove the effectiveness of our approach, we studied three typical real-world cases in which a collection of empirical evaluations were conducted on real-world datasets to compare the performance of our model and other state-of-the-art approaches. The results show the superiority of our model over comparison models.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2565021098",
    "type": "article"
  },
  {
    "title": "Version-Aware Rating Prediction for Mobile App Recommendation",
    "doi": "https://doi.org/10.1145/3015458",
    "publication_date": "2017-06-23",
    "publication_year": 2017,
    "authors": "Yuan Yao; Wayne Xin Zhao; Yaojing Wang; Hanghang Tong; Feng Xu; Jian Lü",
    "corresponding_authors": "",
    "abstract": "With the great popularity of mobile devices, the amount of mobile apps has grown at a more dramatic rate than ever expected. A technical challenge is how to recommend suitable apps to mobile users. In this work, we identify and focus on a unique characteristic that exists in mobile app recommendation—that is, an app usually corresponds to multiple release versions. Based on this characteristic, we propose a fine-grain version-aware app recommendation problem. Instead of directly learning the users’ preferences over the apps, we aim to infer the ratings of users on a specific version of an app. However, the user-version rating matrix will be sparser than the corresponding user-app rating matrix, making existing recommendation methods less effective. In view of this, our approach has made two major extensions. First, we leverage the review text that is associated with each rating record; more importantly, we consider two types of version-based correlations. The first type is to capture the temporal correlations between multiple versions within the same app, and the second type of correlation is to capture the aggregation correlations between similar apps. Experimental results on a large dataset demonstrate the superiority of our approach over several competitive methods.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2708423399",
    "type": "article"
  },
  {
    "title": "Jointly Minimizing the Expected Costs of Review for Responsiveness and Privilege in E-Discovery",
    "doi": "https://doi.org/10.1145/3268928",
    "publication_date": "2018-11-19",
    "publication_year": 2018,
    "authors": "Douglas W. Oard; Fabrizio Sebastiani; Jyothi K. Vinjumur",
    "corresponding_authors": "",
    "abstract": "Discovery is an important aspect of the civil litigation process in the United States of America, in which all parties to a lawsuit are permitted to request relevant evidence from other parties. With the rapid growth of digital content, the emerging need for “e-discovery” has created a strong demand for techniques that can be used to review massive collections both for “responsiveness” (i.e., relevance) to the request and for “privilege” (i.e., presence of legally protected content that the party performing the review may have a right to withhold). In this process, the party performing the review may incur costs of two types, namely, annotation costs (deriving from the fact that human reviewers need to be paid for their work) and misclassification costs (deriving from the fact that failing to correctly determine the responsiveness or privilege of a document may adversely affect the interests of the parties in various ways). Relying exclusively on automatic classification would minimize annotation costs but could result in substantial misclassification costs, while relying exclusively on manual classification could generate the opposite consequences. This article proposes a risk minimization framework (called MINECORE, for “&lt;underline&gt;min&lt;/underline&gt;imizing the &lt;underline&gt;e&lt;/underline&gt;xpected &lt;underline&gt;co&lt;/underline&gt;sts of &lt;underline&gt;re&lt;/underline&gt;view”) that seeks to strike an optimal balance between these two extreme stands. In MINECORE (a) the documents are first automatically classified for both responsiveness and privilege, and then (b) some of the automatically classified documents are annotated by human reviewers for responsiveness (typically by junior reviewers) and/or, in cascade, for privilege (typically by senior reviewers), with the overall goal of minimizing the expected cost (i.e., the risk ) of the entire process. Risk minimization is achieved by optimizing, for both responsiveness and privilege, the choice of which documents to manually review. We present a simulation study in which classes from a standard text classification test collection (RCV1-v2) are used as surrogates for responsiveness and privilege. The results indicate that MINECORE can yield substantially lower total cost than any of a set of strong baselines.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2900833639",
    "type": "article"
  },
  {
    "title": "The Query Change Model",
    "doi": "https://doi.org/10.1145/2747874",
    "publication_date": "2015-05-13",
    "publication_year": 2015,
    "authors": "Grace Hui Yang; Dongyi Guan; Sicong Zhang",
    "corresponding_authors": "",
    "abstract": "Modern information retrieval (IR) systems exhibit user dynamics through interactivity. These dynamic aspects of IR, including changes found in data, users, and systems, are increasingly being utilized in search engines. Session search is one such IR task—document retrieval within a session. During a session, a user constantly modifies queries to find documents that fulfill an information need. Existing IR techniques for assisting the user in this task are limited in their ability to optimize over changes, learn with a minimal computational footprint, and be responsive. This article proposes a novel query change retrieval model (QCM), which uses syntactic editing changes between consecutive queries, as well as the relationship between query changes and previously retrieved documents, to enhance session search. We propose modeling session search as a Markov decision process (MDP). We consider two agents in this MDP: the user agent and the search engine agent. The user agent’s actions are query changes that we observe, and the search engine agent’s actions are term weight adjustments as proposed in this work. We also investigate multiple query aggregation schemes and their effectiveness on session search. Experiments show that our approach is highly effective and outperforms top session search systems in TREC 2011 and TREC 2012.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2257117461",
    "type": "article"
  },
  {
    "title": "Understanding Faceted Search from Data Science and Human Factor Perspectives",
    "doi": "https://doi.org/10.1145/3284101",
    "publication_date": "2019-01-11",
    "publication_year": 2019,
    "authors": "Xi Niu; Xiangyu Fan; Tao Zhang",
    "corresponding_authors": "",
    "abstract": "Faceted search has become a common feature on most search interfaces in e-commerce websites, digital libraries, government’s open information portals, and so on. Beyond the existing studies on developing algorithms for faceted search and empirical studies on facet usage, this study investigated user real-time interactions with facets over the course of a search from both data science and human factor perspectives. It adopted a Random Forest (RF) model to successfully predict facet use using search dynamic variables. In addition, the RF model provided a ranking of variables by their predictive power, which suggests that the search process follows rhythmic flow of a sequence within which facet addition is mostly influenced by its immediately preceding action. In the follow-up user study, we found that participants used facets at critical points from the beginning to end of search sessions. Participants used facets for distinctive reasons at different stages. They also used facets implicitly without applying the facets to their search. Most participants liked the faceted search, although a few participants were concerned about the choice overload introduced by facets. The results of this research can be used to understand information seekers and propose or refine a set of practical design guidelines for faceted search.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2909095913",
    "type": "article"
  },
  {
    "title": "The Effects of Working Memory, Perceptual Speed, and Inhibition in Aggregated Search",
    "doi": "https://doi.org/10.1145/3322128",
    "publication_date": "2019-05-16",
    "publication_year": 2019,
    "authors": "Jaime Arguello; Bogeum Choi",
    "corresponding_authors": "",
    "abstract": "Prior work has studied how different characteristics of individual users (e.g., personality traits and cognitive abilities) can impact search behaviors and outcomes. We report on a laboratory study ( N = 32) that investigated the effects of three different cognitive abilities (perceptual speed, working memory, and inhibition) in the context of aggregated search. Aggregated search systems combine results from multiple heterogeneous sources (or verticals ) in a unified presentation. Participants in our study interacted with two different aggregated search interfaces (a within-subjects design) that differed based on the extent to which the layout distinguished between results originating from different verticals. The interleaved interface merged results from different verticals in a fairly unconstrained fashion. Conversely, the blocked interface displayed results from the same vertical as a group, displayed each group of vertical results in the same region on the SERP for every query, and used a border around each group of vertical results to help distinguish among results from different sources. We investigated three research questions (RQ1--RQ3). Specifically, we investigated the effects of the interface condition and each cognitive ability on three types of outcomes: (RQ1) participants’ levels of workload, (RQ2) participants’ levels of user engagement, and (RQ3) participants’ search behaviors. Our results found different main and interaction effects. Perceptual speed and inhibition did not significantly affect participants’ workload and user engagement but significantly affected their search behaviors. Specifically, with the interleaved interface, participants with lower perceptual speed had more difficulty finding relevant results on the SERP, and participants with lower inhibitory attention control searched at a slower pace. Working memory did not have a strong effect on participants’ behaviors but had several significant effects on the levels of workload and user engagement reported by participants. Specifically, participants with lower working memory reported higher levels of workload and lower levels of user engagement. We discuss implications of our results for designing aggregated search interfaces that are well suited for users with different cognitive abilities.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2946144951",
    "type": "article"
  },
  {
    "title": "Funnelling",
    "doi": "https://doi.org/10.1145/3326065",
    "publication_date": "2019-05-31",
    "publication_year": 2019,
    "authors": "Andrea Esuli; Alejandro Moreo; Fabrizio Sebastiani",
    "corresponding_authors": "",
    "abstract": "Cross-lingual Text Classification (CLC) consists of automatically classifying, according to a common set C of classes, documents each written in one of a set of languages L , and doing so more accurately than when “naïvely” classifying each document via its corresponding language-specific classifier. To obtain an increase in the classification accuracy for a given language, the system thus needs to also leverage the training examples written in the other languages. We tackle “multilabel” CLC via funnelling , a new ensemble learning method that we propose here. Funnelling consists of generating a two-tier classification system where all documents, irrespective of language, are classified by the same (second-tier) classifier. For this classifier, all documents are represented in a common, language-independent feature space consisting of the posterior probabilities generated by first-tier, language-dependent classifiers. This allows the classification of all test documents, of any language, to benefit from the information present in all training documents, of any language. We present substantial experiments, run on publicly available multilingual text collections, in which funnelling is shown to significantly outperform a number of state-of-the-art baselines. All code and datasets (in vector form) are made publicly available.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2963967134",
    "type": "article"
  },
  {
    "title": "Enhancing Personalized Recommendation by Implicit Preference Communities Modeling",
    "doi": "https://doi.org/10.1145/3352592",
    "publication_date": "2019-10-31",
    "publication_year": 2019,
    "authors": "Lin Xiao; Min Zhang; Yiqun Liu; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Recommender systems aim to capture user preferences and provide accurate recommendations to users accordingly. For each user, there usually exist others with similar preferences, and a collection of users may also have similar preferences with each other, thus forming a community. However, such communities may not necessarily be explicitly given, and the users inside the same communities may not know each other; they are formally defined and named Implicit Preference Communities (IPCs) in this article. By enriching user preferences with the information of other users in the communities, the performance of recommender systems can also be enhanced. Historical explicit ratings are a good resource to construct the IPCs of users but is usually sparse. Meanwhile, user preferences are easily affected by their social connections, which can be jointly used for IPC modeling with the ratings. However, this imposes two challenges for model design. First, the rating and social domains are heterogeneous; thus, it is challenging to coordinate social information and rating behaviors for a same learning task. Therefore, transfer learning is a good strategy for IPC modeling. Second, the communities are not explicitly labeled, and existing supervised learning approaches do not fit the requirement of IPC modeling. As co-clustering is an effective unsupervised learning approach for discovering block structures in high-dimensional data, it is a cornerstone for discovering the structure of IPCs. In this article, we propose a recommendation model with Implicit Preference Communities from user ratings and social connections. To tackle the unsupervised learning limitation, we design a Bayesian probabilistic graphical model to capture the IPC structure for recommendation. Meanwhile, following the spirit of transfer learning, both rating behaviors and social connections are introduced into the model by parameter sharing. Moreover, Gibbs sampling-based algorithms are proposed for parameter inferences of the models. Furthermore, to meet the need for online scenarios when the data arrive sequentially as a stream, a novel online sampling-based parameter inference algorithm for recommendation is proposed. To the best of our knowledge, this is the first attempt to propose and formally define the concept of IPC.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2990670023",
    "type": "article"
  },
  {
    "title": "Learning Unsupervised Knowledge-Enhanced Representations to Reduce the Semantic Gap in Information Retrieval",
    "doi": "https://doi.org/10.1145/3417996",
    "publication_date": "2020-09-11",
    "publication_year": 2020,
    "authors": "Maristella Agosti; Stefano Marchesin; Gianmaria Silvello",
    "corresponding_authors": "",
    "abstract": "The semantic mismatch between query and document terms—i.e., the semantic gap—is a long-standing problem in Information Retrieval (IR). Two main linguistic features related to the semantic gap that can be exploited to improve retrieval are synonymy and polysemy. Recent works integrate knowledge from curated external resources into the learning process of neural language models to reduce the effect of the semantic gap. However, these knowledge-enhanced language models have been used in IR mostly for re-ranking and not directly for document retrieval. We propose the Semantic-Aware Neural Framework for IR (SAFIR), an unsupervised knowledge-enhanced neural framework explicitly tailored for IR. SAFIR jointly learns word, concept, and document representations from scratch. The learned representations encode both polysemy and synonymy to address the semantic gap. SAFIR can be employed in any domain where external knowledge resources are available. We investigate its application in the medical domain where the semantic gap is prominent and there are many specialized and manually curated knowledge resources. The evaluation on shared test collections for medical literature retrieval shows the effectiveness of SAFIR in terms of retrieving and ranking relevant documents most affected by the semantic gap.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3086232317",
    "type": "article"
  },
  {
    "title": "Improving Implicit Recommender Systems with Auxiliary Data",
    "doi": "https://doi.org/10.1145/3372338",
    "publication_date": "2020-01-31",
    "publication_year": 2020,
    "authors": "Jingtao Ding; Guanghui Yu; Yong Li; Xiangnan He; Depeng Jin",
    "corresponding_authors": "",
    "abstract": "Most existing recommender systems leverage the primary feedback only, despite the fact that users also generate a large amount of auxiliary feedback. These feedback usually indicate different user preferences when comparing to the primary feedback directly used to optimize the system performance. For example, in E-commerce sites, view data is easily accessible, which provides a valuable yet weaker signal than the primary feedback of purchase. In this work, we improve implicit feedback-based recommender systems (dubbed Implicit Recommender Systems ) by integrating auxiliary view data into matrix factorization (MF). To exploit different preference levels, we propose both pointwise and pairwise models in terms of how to leverage users’ viewing behaviors. The latter model learns the pairwise ranking relations among purchased, viewed, and non-viewed interactions, being more effective and flexible than the former pointwise MF method. However, such a pairwise formulation poses a computational efficiency problem in learning the model. To address this problem, we design a new learning algorithm based on the element-wise Alternating Least Squares (eALS) learner. Notably, our designed algorithm can efficiently learn model parameters from the whole user-item matrix (including all missing data), with a rather low time complexity that is dependent on the observed data only. Extensive experiments on two real-world datasets demonstrate that our method outperforms several state-of-the-art MF methods by 6.43%∼ 6.75%. Our implementation is available at https://github.com/dingjingtao/Auxiliary_enhanced_ALS.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3009464535",
    "type": "article"
  },
  {
    "title": "Nonuniform Hyper-Network Embedding with Dual Mechanism",
    "doi": "https://doi.org/10.1145/3388924",
    "publication_date": "2020-05-05",
    "publication_year": 2020,
    "authors": "Jie Huang; Chuan Chen; Fanghua Ye; Weibo Hu; Zibin Zheng",
    "corresponding_authors": "",
    "abstract": "Network embedding which aims to learn the low-dimensional representations for vertices in networks has been extensively studied in recent years. Although there are various models designed for networks with different properties and different structures for different tasks, most of them are only applied to normal networks which only contain pairwise relationships between vertices. In many realistic cases, relationships among objects are not pairwise and such relationships can be better modeled by a hyper-network in which each edge can connect an uncertain number of vertices. In this article, we focus on two properties of hyper-networks: nonuniform and dual property. In order to make full use of these two properties, we firstly propose a flexible model called Hyper2vec to learn the embeddings of hyper-networks by applying a biased second order random walk strategy to hyper-networks in the framework of Skip-gram. Then, we combine the features of hyperedges by considering the dual hyper-networks to build a further model called NHNE based on 1D convolutional neural networks, and train a tuplewise similarity function for the nonuniform relationships in hyper-networks. Extensive experiments demonstrate the significant effectiveness of our methods for hyper-network embedding.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3021581561",
    "type": "article"
  },
  {
    "title": "Integrating Collaboration and Leadership in Conversational Group Recommender Systems",
    "doi": "https://doi.org/10.1145/3462759",
    "publication_date": "2021-08-17",
    "publication_year": 2021,
    "authors": "Carl W David; María Salamó; Ludovico Boratto",
    "corresponding_authors": "",
    "abstract": "Recent observational studies highlight the importance of considering the interactions between users in the group recommendation process, but to date their integration has been marginal. In this article, we propose a collaborative model based on the social interactions that take place in a web-based conversational group recommender system. The collaborative model allows the group recommender to implicitly infer the different roles within the group, namely, collaborative and leader user(s). Moreover, it serves as the basis of several novel collaboration-based consensus strategies that integrate both individual and social interactions in the group recommendation process. A live-user evaluation confirms that our approach accurately identifies the collaborative and leader users in a group and produces more effective recommendations.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3195948647",
    "type": "article"
  },
  {
    "title": "A Game Theory Approach for Estimating Reliability of Crowdsourced Relevance Assessments",
    "doi": "https://doi.org/10.1145/3480965",
    "publication_date": "2021-11-17",
    "publication_year": 2021,
    "authors": "Yashar Moshfeghi; Álvaro Francisco Huertas-Rosero",
    "corresponding_authors": "",
    "abstract": "In this article, we propose an approach to improve quality in crowdsourcing (CS) tasks using Task Completion Time (TCT) as a source of information about the reliability of workers in a game-theoretical competitive scenario. Our approach is based on the hypothesis that some workers are more risk-inclined and tend to gamble with their use of time when put to compete with other workers. This hypothesis is supported by our previous simulation study. We test our approach with 35 topics from experiments on the TREC-8 collection being assessed as relevant or non-relevant by crowdsourced workers both in a competitive (referred to as “Game”) and non-competitive (referred to as “Base”) scenario. We find that competition changes the distributions of TCT, making them sensitive to the quality (i.e., wrong or right) and outcome (i.e., relevant or non-relevant) of the assessments. We also test an optimal function of TCT as weights in a weighted majority voting scheme. From probabilistic considerations, we derive a theoretical upper bound for the weighted majority performance of cohorts of 2, 3, 4, and 5 workers, which we use as a criterion to evaluate the performance of our weighting scheme. We find our approach achieves a remarkable performance, significantly closing the gap between the accuracy of the obtained relevance judgements and the upper bound. Since our approach takes advantage of TCT, which is an available quantity in any CS tasks, we believe it is cost-effective and, therefore, can be applied for quality assurance in crowdsourcing for micro-tasks.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3217465958",
    "type": "article"
  },
  {
    "title": "Graph Co-Attentive Session-based Recommendation",
    "doi": "https://doi.org/10.1145/3486711",
    "publication_date": "2021-12-01",
    "publication_year": 2021,
    "authors": "Zhiqiang Pan; Fei Cai; Wanyu Chen; Honghui Chen",
    "corresponding_authors": "",
    "abstract": "Session-based recommendation aims to generate recommendations merely based on the ongoing session, which is a challenging task. Previous methods mainly focus on modeling the sequential signals or the transition relations between items in the current session using RNNs or GNNs to identify user’s intent for recommendation. Such models generally ignore the dynamic connections between the local and global item transition patterns, although the global information is taken into consideration by exploiting the global-level pair-wise item transitions. Moreover, existing methods that mainly adopt the cross-entropy loss with softmax generally face a serious over-fitting problem, harming the recommendation accuracy. Thus, in this article, we propose a Graph Co-Attentive Recommendation Machine (GCARM) for session-based recommendation. In detail, we first design a Graph Co-Attention Network (GCAT) to consider the dynamic correlations between the local and global neighbors of each node during the information propagation. Then, the item-level dynamic connections between the output of the local and global graphs are modeled to generate the final item representations. After that, we produce the prediction scores and design a Max Cross-Entropy (MCE) loss to prevent over-fitting. Extensive experiments are conducted on three benchmark datasets, i.e., Diginetica, Gowalla, and Yoochoose. The experimental results show that GCARM can achieve the state-of-the-art performance in terms of Recall and MRR, especially on boosting the ranking of the target item.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W3216767838",
    "type": "article"
  },
  {
    "title": "Exploiting Group Information for Personalized Recommendation with Graph Neural Networks",
    "doi": "https://doi.org/10.1145/3464764",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Zhiqiang Tian; Yezheng Liu; Jianshan Sun; Yuanchun Jiang; Mingyue Zhu",
    "corresponding_authors": "",
    "abstract": "Personalized recommendation has become more and more important for users to quickly find relevant items. The key issue of the recommender system is how to model user preferences. Previous work mostly employed user historical data to learn users’ preferences, but faced with the data sparsity problem. The prevalence of online social networks promotes increasing online discussion groups, and users in the same group often have similar interests and preferences. Therefore, it is necessary to integrate group information for personalized recommendation. The existing work on group-information-enhanced recommender systems mainly relies on the item information related to the group, which is not expressive enough to capture the complicated preference dependency relationships between group users and the target user. In this article, we solve the problem with the graph neural networks. Specifically, the relationship between users and items, the item preferences of groups, and the groups that users participate in are constructed as bipartite graphs, respectively, and the user preferences for items are learned end to end through the graph neural network. The experimental results on the Last.fm and Douban Movie datasets show that considering group preferences can improve the recommendation performance and demonstrate the superiority on sparse users compared",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3204879380",
    "type": "article"
  },
  {
    "title": "Learning Text-image Joint Embedding for Efficient Cross-modal Retrieval with Deep Feature Engineering",
    "doi": "https://doi.org/10.1145/3490519",
    "publication_date": "2021-12-01",
    "publication_year": 2021,
    "authors": "Zhongwei Xie; Ling Liu; Yanzhao Wu; Luo Zhong; Lin Li",
    "corresponding_authors": "",
    "abstract": "This paper introduces a two-phase deep feature engineering framework for efficient learning of semantics enhanced joint embedding, which clearly separates the deep feature engineering in data preprocessing from training the text-image joint embedding model. We use the Recipe1M dataset for the technical description and empirical validation. In preprocessing, we perform deep feature engineering by combining deep feature engineering with semantic context features derived from raw text-image input data. We leverage LSTM to identify key terms, deep NLP models from the BERT family, TextRank, or TF-IDF to produce ranking scores for key terms before generating the vector representation for each key term by using word2vec. We leverage wideResNet50 and word2vec to extract and encode the image category semantics of food images to help semantic alignment of the learned recipe and image embeddings in the joint latent space. In joint embedding learning, we perform deep feature engineering by optimizing the batch-hard triplet loss function with soft-margin and double negative sampling, taking into account also the category-based alignment loss and discriminator-based alignment loss. Extensive experiments demonstrate that our SEJE approach with deep feature engineering significantly outperforms the state-of-the-art approaches.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3208601917",
    "type": "article"
  },
  {
    "title": "STARec: Adaptive Learning with Spatiotemporal and Activity Influence for POI Recommendation",
    "doi": "https://doi.org/10.1145/3485631",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Weiyu Ji; Xiangchen Meng; Yujie Zhang",
    "corresponding_authors": "",
    "abstract": "POI recommendation has become an essential means to help people discover attractive places. Intuitively, activities have an important impact on users’ decision-making, because users select POIs to attend corresponding activities. However, many existing studies ignore the social motivation of user behaviors and regard all check-ins as influenced only by individual user interests. As a result, they cannot model user preferences accurately, which degrades recommendation effectiveness. In this article, from the perspective of activities, this study proposes a probabilistic generative model called STARec. Specifically, based on the social effect of activities, STARec defines users’ social preferences as distinct from their individual interests and combines these with individual user activity interests to effectively depict user preferences. Moreover, the inconsistency between users’ social preferences and their decisions is modeled. An activity frequency feature is introduced to acquire accurate user social preferences because of close correlation between these and the key impact factor of corresponding check-ins. An alias sampling-based training method was used to accelerate training. Extensive experiments were conducted on two real-world datasets. Experimental results demonstrated that the proposed STARec model achieves superior performance in terms of high recommendation accuracy, robustness to data sparsity, effectiveness in handling cold-start problems, efficiency, and interpretability.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3215033458",
    "type": "article"
  },
  {
    "title": "Efficient Document-at-a-Time and Score-at-a-Time Query Evaluation for Learned Sparse Representations",
    "doi": "https://doi.org/10.1145/3576922",
    "publication_date": "2022-12-15",
    "publication_year": 2022,
    "authors": "Joel Mackenzie; Andrew Trotman; Jimmy Lin",
    "corresponding_authors": "",
    "abstract": "Researchers have had much recent success with ranking models based on so-called learned sparse representations generated by transformers. One crucial advantage of this approach is that such models can exploit inverted indexes for top- k retrieval, thereby leveraging decades of work on efficient query evaluation. Yet, there remain many open questions about how these learned representations fit within the existing literature, which our work aims to tackle using four representative learned sparse models. We find that impact weights generated by transformers appear to greatly reduce opportunities for skipping and early exiting optimizations in well-studied document-at-a-time ( DaaT ) approaches. Similarly, “off-the-shelf” application of score-at-a-time ( SaaT ) processing exhibits a mismatch between these weights and assumptions behind accumulator management strategies. Building on these observations, we present solutions to address deficiencies with both DaaT and SaaT approaches, yielding substantial speedups in query evaluation. Our detailed empirical analysis demonstrates that both methods lie on the effectiveness–efficiency Pareto frontier, indicating that the optimal choice for deployment depends on operational constraints.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4311609640",
    "type": "article"
  },
  {
    "title": "Multi-level Attention-based Domain Disentanglement for BCDR",
    "doi": "https://doi.org/10.1145/3576925",
    "publication_date": "2022-12-19",
    "publication_year": 2022,
    "authors": "Xinyue Zhang; Jingjing Li; Hongzu Su; Lei Zhu; Heng Tao Shen",
    "corresponding_authors": "",
    "abstract": "Cross-domain recommendation aims to exploit heterogeneous information from a data-sufficient domain (source domain) to transfer knowledge to a data-scarce domain (target domain). A majority of existing methods focus on unidirectional transfer that leverages the domain-shared information to facilitate the recommendation of the target domain. Nevertheless, it is more beneficial to improve the recommendation performance of both domains simultaneously via a dual transfer learning schema, which is known as bidirectional cross-domain recommendation (BCDR). Existing BCDR methods have their limitations, since they only perform bidirectional transfer learning based on domain-shared representations while neglecting rich information that is private to each domain. In this article, we argue that users may have domain-biased preferences due to the characteristics of that domain. Namely, the domain-specific preference information also plays a critical role in the recommendation. To effectively leverage the domain-specific information, we propose a M ulti-level A ttention-based D omain D isentanglement framework dubbed MADD for BCDR, which explicitly leverages the attention mechanism to construct personalized preference with both domain-invariant and domain-specific features obtained by disentangling raw user embeddings. Specifically, the domain-invariant feature is exploited by domain-adversarial learning while the domain-specific feature is learned by imposing an orthogonal loss. We then conduct a reconstruction process on disentangled features to ensure semantic-sufficiency. After that, we devise a multi-level attention mechanism for these disentangled features, which determines their contributions to the final personalized user preference embedding by dynamically learning the attention scores of individual features. We train the model in a multi-task learning fashion to benefit both domains. Extensive experiments on real-world datasets demonstrate that our model significantly outperforms state-of-the-art cross-domain recommendation approaches.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4313410623",
    "type": "article"
  },
  {
    "title": "Preference-aware Graph Attention Networks for Cross-Domain Recommendations with Collaborative Knowledge Graph",
    "doi": "https://doi.org/10.1145/3576921",
    "publication_date": "2022-12-16",
    "publication_year": 2022,
    "authors": "Yakun Li; Lei Hou; Juanzi Li",
    "corresponding_authors": "",
    "abstract": "Knowledge graphs (KGs) can provide users with semantic information and relations among numerous entities and nodes, which can greatly facilitate the performance of recommender systems. However, existing KG-based approaches still suffer from severe data sparsity and may not be effective in capturing the preference features of similar entities across domains. Therefore, in this article, we propose a P reference-aware G raph A ttention network model with C ollaborative K nowledge G raph ( PGACKG ) for cross-domain recommendations. Preference-aware entity embeddings with some collaborative signals are first obtained by exploiting the graph-embedding model, which can transform entities and items in the collaborative knowledge graph into semantic preference spaces. To better learn user preference features, we devise a preference-aware graph attention network framework that aggregates the preference features of similar entities within domains and across domains. In this framework, multi-hop reasoning is employed to assist in the generation of preference features within domains, and the node random walk based on frequency visits is proposed to gather similar preferences across domains for target entities. Then, the final preference features of entities are fused, while a novel C ross-domain B ayesian P ersonalized R anking ( CBPR ) is proposed to improve cross-domain recommendation accuracy. Extensive empirical experiments on four real-world datasets demonstrate that our proposed approach consistently outperforms state-of-the-art baselines. Furthermore, our PGACKG achieves strong performance in different ablation scenarios, and the interaction sparsity experiments also demonstrate that our proposed approach can significantly alleviate the data sparsity issue.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W4313476061",
    "type": "article"
  },
  {
    "title": "“What Can I Cook with these Ingredients?” - Understanding Cooking-Related Information Needs in Conversational Search",
    "doi": "https://doi.org/10.1145/3498330",
    "publication_date": "2022-01-11",
    "publication_year": 2022,
    "authors": "Alexander Frummet; David Elsweiler; Bernd Ludwig",
    "corresponding_authors": "",
    "abstract": "As conversational search becomes more pervasive, it becomes increasingly important to understand the users’ underlying information needs when they converse with such systems in diverse domains. We conduct an in situ study to understand information needs arising in a home cooking context as well as how they are verbally communicated to an assistant. A human experimenter plays this role in our study. Based on the transcriptions of utterances, we derive a detailed hierarchical taxonomy of diverse information needs occurring in this context, which require different levels of assistance to be solved. The taxonomy shows that needs can be communicated through different linguistic means and require different amounts of context to be understood. In a second contribution, we perform classification experiments to determine the feasibility of predicting the type of information need a user has during a dialogue using the turn provided. For this multi-label classification problem, we achieve average F1 measures of 40% using BERT-based models. We demonstrate with examples which types of needs are difficult to predict and show why, concluding that models need to include more context information in order to improve both information need classification and assistance to make such systems usable.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4205231570",
    "type": "article"
  },
  {
    "title": "perCLTV: A General System for Personalized Customer Lifetime Value Prediction in Online Games",
    "doi": "https://doi.org/10.1145/3530012",
    "publication_date": "2022-04-23",
    "publication_year": 2022,
    "authors": "Shiwei Zhao; Runze Wu; Jianrong Tao; Manhu Qu; Minghao Zhao; Changjie Fan; Hongke Zhao",
    "corresponding_authors": "",
    "abstract": "Online games make up the largest segment of the booming global game market in terms of revenue as well as players. Unlike games that sell games at one time for profit, online games make money from in-game purchases by a large number of engaged players. Therefore, Customer Lifetime Value (CLTV) is particularly vital for game companies to improve marketing decisions and increase game revenues. Nowadays, as virtual game worlds are becoming increasingly innovative, complex, and diverse, the CLTV of massive players is highly personalized. That is, different players may have very different patterns of CLTV, especially on churn and payment. However, current solutions are inadequate in terms of personalization and thus limit predictive performance. First, most methods just attempt to address either task of CLTV, i.e., churn or payment, and only consider the personalization from one of them. Second, the correlation between churn and payment has not received enough attention and its personalization has not been fully explored yet. Last, most solutions around this line are conducted based on historical data where the evaluation is not convincing enough without real-world tests. To tackle these problems, we propose a general system to predict personalized customer lifetime value in online games, named perCLTV. To be specific, we revisit the personalized CLTV prediction problem from the two sub-tasks of churn prediction and payment prediction in a sequential gated multi-task learning fashion. On this basis, we develop a generalized framework to model CLTV across games in distinct genres by heterogeneous player behavior data, including individual behavior sequential data and social behavior graph data. Comprehensive experiments on three real-world datasets validate the effectiveness and rationality of perCLTV, which significantly outperforms other baseline methods. Our work has been implemented and deployed in many online games released from NetEase Games. Online A/B testing in production shows that perCLTV achieves a prominent improvement in two precision marketing applications of popup recommendation and churn intervention.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W4293236189",
    "type": "article"
  },
  {
    "title": "Poincaré Heterogeneous Graph Neural Networks for Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3568395",
    "publication_date": "2023-01-11",
    "publication_year": 2023,
    "authors": "Naicheng Guo; Xiaolei Liu; Shaoshuai Li; Qiongxu Ma; Kaixin Gao; Bing Han; Lin Zheng; Sheng Guo; Xiaobo Guo",
    "corresponding_authors": "",
    "abstract": "Sequential recommendation (SR) learns users’ preferences by capturing the sequential patterns from users’ behaviors evolution. As discussed in many works, user–item interactions of SR generally present the intrinsic power-law distribution, which can be ascended to hierarchy-like structures. Previous methods usually handle such hierarchical information by making user–item sectionalization empirically under Euclidean space, which may cause distortion of user–item representation in real online scenarios. In this article, we propose a Poincaré-based heterogeneous graph neural network named Poincaré Heterogeneous Graph Neural Networks for Sequential Recommendation (PHGR) to model the sequential pattern information as well as hierarchical information contained in the data of SR scenarios simultaneously. Specifically, for the purpose of explicitly capturing the hierarchical information, we first construct a weighted user–item heterogeneous graph by aliening all the user–item interactions to improve the perception domain of each user from a global view. Then the output of the global representation would be used to complement the local directed item–item homogeneous graph convolution. By defining a novel hyperbolic inner product operator, the global and local graph representation learning are directly conducted in Poincaré ball instead of commonly used projection operation between Poincaré ball and Euclidean space, which could alleviate the cumulative error issue of general bidirectional translation process. Moreover, for the purpose of explicitly capturing the sequential dependency information, we design two types of temporal attention operations under Poincaré ball space. Empirical evaluations on datasets from the public and financial industry show that PHGR outperforms several comparison methods.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4315647008",
    "type": "article"
  },
  {
    "title": "Topic-aware Intention Network for Explainable Recommendation with Knowledge Enhancement",
    "doi": "https://doi.org/10.1145/3579993",
    "publication_date": "2023-01-19",
    "publication_year": 2023,
    "authors": "Qiming Li; Zhao Zhang; Fuzhen Zhuang; Yongjun Xu; Chao Li",
    "corresponding_authors": "",
    "abstract": "Recently, recommender systems based on knowledge graphs (KGs) have become a popular research direction. Graph neural network (GNN) is the key technology of KG-based recommendation systems. However, existing GNNs have a significant flaw: They cannot explicitly model users' intent in recommendations. Intent plays an essential role in users' behaviors. For example, users may first generate an intent to purchase a certain group of items and then select a specific item from the group based on their preferences. Therefore, explicitly modeling intent has a positive significance for improving recommendation performance and providing explanations for recommendations. In this article, we propose a new model called Topic-aware Intention Network (TIN) for explainable recommendations with KGs. TIN models user representations from both preference and intent views. Specifically, we design a relational attention graph neural network to selectively aggregate information in KG to learn user preferences, and we propose a knowledge-enhanced topic model to learn user intent, which is viewed as topics hidden in user behavior sequences. Finally, we obtain the user representation by fusing user preference and intent through an attention network. The experimental results show that our proposed model outperforms the state-of-the-art methods and can generate reasonable explanations for the recommendation results.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4317502663",
    "type": "article"
  },
  {
    "title": "TSSuBERT: How to Sum Up Multiple Years of Reading in a Few Tweets",
    "doi": "https://doi.org/10.1145/3581786",
    "publication_date": "2023-01-21",
    "publication_year": 2023,
    "authors": "Alexis Dusart; Karen Pinel-Sauvagnat; Gilles Hubert",
    "corresponding_authors": "",
    "abstract": "The development of deep neural networks and the emergence of pre-trained language models such as BERT allow to increase performance on many NLP tasks. However, these models do not meet the same popularity for tweet stream summarization, which is probably because their computation limitation requires to drastically truncate the textual input. Our contribution in this article is threefold. First, we propose a neural model to automatically and incrementally summarize huge tweet streams. This extractive model combines in an original way pre-trained language models and vocabulary frequency based representations to predict tweet salience. An additional advantage of the model is that it automatically adapts the size of the output summary according to the input tweet stream. Second, we detail an original methodology to construct tweet stream summarization datasets requiring little human effort. Third, we release the TES 2012-2016 dataset constructed using the aforementioned methodology. Baselines, oracle summaries, gold standard, and qualitative assessments are made publicly available. To evaluate our approach, we conducted extensive quantitative experiments using three different tweet collections as well as an additional qualitative evaluation. Results show that our method outperforms state-of-the-art ones. We believe that this work opens avenues of research for incremental summarization, which has not received much attention yet.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4317659198",
    "type": "article"
  },
  {
    "title": "Bounding System-Induced Biases in Recommender Systems with a Randomized Dataset",
    "doi": "https://doi.org/10.1145/3582002",
    "publication_date": "2023-01-24",
    "publication_year": 2023,
    "authors": "Dugang Liu; Pengxiang Cheng; Zinan Lin; Xiaolian Zhang; Zhenhua Dong; Rui Zhang; Xiuqiang He; Weike Pan; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "Debiased recommendation with a randomized dataset has shown very promising results in mitigating system-induced biases. However, it still lacks more theoretical insights or an ideal optimization objective function compared with the other more well-studied routes without a randomized dataset. To bridge this gap, we study the debiasing problem from a new perspective and propose to directly minimize the upper bound of an ideal objective function, which facilitates a better potential solution to system-induced biases. First, we formulate a new ideal optimization objective function with a randomized dataset. Second, according to the prior constraints that an adopted loss function may satisfy, we derive two different upper bounds of the objective function: a generalization error bound with triangle inequality and a generalization error bound with separability. Third, we show that most existing related methods can be regarded as the insufficient optimization of these two upper bounds. Fourth, we propose a novel method called debiasing approximate upper bound ( DUB ) with a randomized dataset, which achieves a more sufficient optimization of these upper bounds. Finally, we conduct extensive experiments on a public dataset and a real product dataset to verify the effectiveness of our DUB.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4317884287",
    "type": "article"
  },
  {
    "title": "Debiased Recommendation with User Feature Balancing",
    "doi": "https://doi.org/10.1145/3580594",
    "publication_date": "2023-02-15",
    "publication_year": 2023,
    "authors": "Mengyue Yang; Guohao Cai; Furui Liu; Jiarui Jin; Zhenhua Dong; Xiuqiang He; Jianye Hao; Weiqi Shao; Jun Wang; Xu Chen",
    "corresponding_authors": "",
    "abstract": "Debiased recommendation has recently attracted increasing attention from both industry and academic communities. Traditional models mostly rely on the inverse propensity score (IPS), which can be hard to estimate and may suffer from the high variance issue. To alleviate these problems, in this article, we propose a novel debiased recommendation framework based on user feature balancing. The general idea is to introduce a projection function to adjust user feature distributions, such that the ideal unbiased learning objective can be upper bounded by a solvable objective purely based on the offline dataset. In the upper bound, the projected user distributions are expected to be equal given different items. From the causal inference perspective, this requirement aims to remove the causal relation from the user to the item, which enables us to achieve unbiased recommendation, bypassing the computation of IPS. To efficiently balance the user distributions upon each item pair, we propose three strategies, including clipping, sampling, and adversarial learning to improve the training process. For more robust optimization, we deploy an explicit model to capture the potential latent confounders in recommendation systems. To the best of our knowledge, this article is the first work on debiased recommendation based on confounder balancing. In the experiments, we compare our framework with many state-of-the-art methods based on synthetic, semi-synthetic, and real-world datasets. Extensive experiments demonstrate that our model is effective in promoting the recommendation performance.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4320890308",
    "type": "article"
  },
  {
    "title": "Learning Multi-turn Response Selection in Grounded Dialogues with Reinforced Knowledge and Context Distillation",
    "doi": "https://doi.org/10.1145/3584701",
    "publication_date": "2023-02-16",
    "publication_year": 2023,
    "authors": "Jiazhan Feng; Chongyang Tao; Xueliang Zhao; Dongyan Zhao",
    "corresponding_authors": "",
    "abstract": "Recently, knowledge-grounded dialogue systems have gained increasing attention. Great efforts have been made to build response matching models where all dialogue content and knowledge sentences are leveraged. However, knowledge redundancy and distraction of irrelevant dialogue content often exist in knowledge-grounded conversations, which may affect the matching process and lead to inferior performance. In addition, irrelevant dialogue history and excessive knowledge also hinder the exploitation of popular pre-trained language models (PLMs) due to the limitation of input length. To address these challenges, we propose a new knowledge-grounded dialogue model based on PLMs, where a knowledge selector and a context selector are designed for filtering out irrelevant knowledge sentences and redundant dialogue history, respectively. Considering the lack of labeled data for the learning of two selectors, we pre-train them with weakly-supervised tasks and then jointly conduct the optimization of knowledge and context selection and fine-tuning of PLMs for response ranking with reinforcement learning (RL). By this means, the dialogue model can distill more accurate and concise knowledge and dialogue content for subsequent response ranking module, and the overall model can converge and perform better. We conduct experiments on two benchmarks and evaluation results indicate that our model can significantly outperform the state-of-the-art methods.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4321109541",
    "type": "article"
  },
  {
    "title": "Group-Based Personalized News Recommendation with Long- and Short-Term Fine-Grained Matching",
    "doi": "https://doi.org/10.1145/3584946",
    "publication_date": "2023-02-21",
    "publication_year": 2023,
    "authors": "Hongyan Xu; Qiyao Peng; Hongtao Liu; Yueheng Sun; Wenjun Wang",
    "corresponding_authors": "",
    "abstract": "Personalized news recommendation aims to help users find news content they prefer, which has attracted increasing attention recently. There are two core issues in news recommendation: learning news representation and matching candidate news with user interests. In this context, “candidate” indicates potential for interest. Due to the superior ability to understand natural language demonstrated by Pretrained Language Models (PLMs), recent works utilize PLMs (e.g., BERT) to strengthen news modeling, obtaining more accurate user interest matching and achieving notable improvement in news recommendation. However, the existing PLM-based methods are usually incapable of fully exploring the fine-grained (i.e., word-level) relatedness between user behaviors and candidate news due to the heavy computational cost brought by PLMs. In this article, we propose a group-based personalized news recommendation method with long- and short-term matching mechanisms between users and candidate news based on PLMs to learn fine-grained matching efficiently and effectively. In our approach, we design to group user historical clicked news into chunks with quite shorter news sequences according to their clicked timestamps, which could alleviate the computation issues of PLMs. PLMs are applied in each group jointly with the candidate news to capture their word-level interaction, and global group-level matching is learned across different groups. In addition, the group-based mechanism could be naturally adapted for long- and short-term user representation learning, in which we build users’ long preferences from the representations of all groups and treat the last group as short interests, respectively. Finally, we employ a gate network to dynamically unify the group-level, long- and short-term representations, yielding comprehensive user-news matching effectively. Extensive experiments are conducted on two real-world datasets. The results show that our proposed method achieves superior performance in news recommendations.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4321454786",
    "type": "article"
  },
  {
    "title": "A Multi-channel Next POI Recommendation Framework with Multi-granularity Check-in Signals",
    "doi": "https://doi.org/10.1145/3592789",
    "publication_date": "2023-04-13",
    "publication_year": 2023,
    "authors": "Zhu Sun; Yu Lei; Lu Zhang; Chen Li; Yew-Soon Ong; Jie Zhang",
    "corresponding_authors": "",
    "abstract": "Current study on next point-of-interest (POI) recommendation mainly explores user sequential transitions with the fine-grained individual-user POI check-in trajectories only, which suffers from the severe check-in data sparsity issue. In fact, coarse-grained signals (i.e., region- and global-level check-ins) in such sparse check-ins would also benefit to augment user preference learning. Specifically, our data analysis unveils that user movement exhibits noticeable patterns w.r.t. the regions of visited POIs. Meanwhile, the global all-user check-ins can help reflect sequential regularities shared by the crowd. We are, therefore, inspired to propose the MCMG: a Multi-Channel next POI recommendation framework with Multi-Granularity signals categorized from two orthogonal perspectives, i.e., fine-coarse grained check-ins at either POI/region level or local/global level. The MCMG is equipped with three modules, namely, global user behavior encoder, local multi-channel (i.e., region, category, and POI channels) encoder, and region-aware weighting strategy. Such design enables MCMG to be capable of capturing both fine- and coarse-grained sequential regularities as well as exploring the dynamic impact of multi-channel by differentiating the check-in patterns w.r.t. visited regions. Extensive experiments on four real-world datasets show that our MCMG significantly outperforms state-of-the-art next POI recommendation approaches.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4365451515",
    "type": "article"
  },
  {
    "title": "A Reusable Model-agnostic Framework for Faithfully Explainable Recommendation and System Scrutability",
    "doi": "https://doi.org/10.1145/3605357",
    "publication_date": "2023-06-18",
    "publication_year": 2023,
    "authors": "Zhichao Xu; Hansi Zeng; Juntao Tan; Zuohui Fu; Yongfeng Zhang; Qingyao Ai",
    "corresponding_authors": "",
    "abstract": "State-of-the-art industrial-level recommender system applications mostly adopt complicated model structures such as deep neural networks. While this helps with the model performance, the lack of system explainability caused by these nearly blackbox models also raises concerns and potentially weakens the users’ trust in the system. Existing work on explainable recommendation mostly focuses on designing interpretable model structures to generate model-intrinsic explanations. However, most of them have complex structures, and it is difficult to directly apply these designs onto existing recommendation applications due to the effectiveness and efficiency concerns. However, while there have been some studies on explaining recommendation models without knowing their internal structures (i.e., model-agnostic explanations), these methods have been criticized for not reflecting the actual reasoning process of the recommendation model or, in other words, faithfulness . How to develop model-agnostic explanation methods and evaluate them in terms of faithfulness is mostly unknown. In this work, we propose a reusable evaluation pipeline for model-agnostic explainable recommendation. Our pipeline evaluates the quality of model-agnostic explanation from the perspectives of faithfulness and scrutability. We further propose a model-agnostic explanation framework for recommendation and verify it with the proposed evaluation pipeline. Extensive experiments on public datasets demonstrate that our model-agnostic framework is able to generate explanations that are faithful to the recommendation model. We additionally provide quantitative and qualitative study to show that our explanation framework could enhance the scrutability of blackbox recommendation model. With proper modification, our evaluation pipeline and model-agnostic explanation framework could be easily migrated to existing applications. Through this work, we hope to encourage the community to focus more on faithfulness evaluation of explainable recommender systems.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4381125108",
    "type": "article"
  },
  {
    "title": "Alleviating Video-length Effect for Micro-video Recommendation",
    "doi": "https://doi.org/10.1145/3617826",
    "publication_date": "2023-08-29",
    "publication_year": 2023,
    "authors": "Yuhan Quan; Jingtao Ding; Chen Gao; Nian Li; Lingling Yi; Depeng Jin; Yong Li",
    "corresponding_authors": "",
    "abstract": "Micro-video platforms such as TikTok are extremely popular nowadays. One important feature is that users no longer select interested videos from a set; instead, they either watch the recommended video or skip to the next one. As a result, the time length of users’ watching behavior becomes the most important signal for identifying preferences. However, our empirical data analysis has shown a video-length effect that long videos can more easily receive a higher value of average view time, and thus adopting such view-time labels for measuring user preferences can easily induce a biased model that favors the longer videos. In this article, we propose a V ideo L ength D ebiasing Rec ommendation (VLDRec) method to alleviate such an effect for micro-video recommendation. VLDRec designs the data labeling approach and the sample generation module that better capture user preferences in a view-time-oriented manner. It further leverages the multi-task learning technique to jointly optimize the above samples with the original biased ones. Extensive experiments show that VLDRec can improve users’ view time by 1.81% and 11.32% on two real-world datasets, given a recommendation list of a fixed overall video length, compared with the best baseline method. Moreover, VLDRec is also more effective in matching users’ interests in terms of the video content.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4386251372",
    "type": "article"
  },
  {
    "title": "Invisible Black-Box Backdoor Attack against Deep Cross-Modal Hashing Retrieval",
    "doi": "https://doi.org/10.1145/3650205",
    "publication_date": "2024-03-02",
    "publication_year": 2024,
    "authors": "Tianshi Wang; Fengling Li; Lei Zhu; Jingjing Li; Zheng Zhang; Heng Tao Shen",
    "corresponding_authors": "",
    "abstract": "Deep cross-modal hashing has promoted the field of multi-modal retrieval due to its excellent efficiency and storage, but its vulnerability to backdoor attacks is rarely studied. Notably, current deep cross-modal hashing methods inevitably require large-scale training data, resulting in poisoned samples with imperceptible triggers that can easily be camouflaged into the training data to bury backdoors in the victim model. Nevertheless, existing backdoor attacks focus on the uni-modal vision domain, while the multi-modal gap and hash quantization weaken their attack performance. In addressing the aforementioned challenges, we undertake an invisible black-box backdoor attack against deep cross-modal hashing retrieval in this article. To the best of our knowledge, this is the first attempt in this research field. Specifically, we develop a flexible trigger generator to generate the attacker’s specified triggers, which learns the sample semantics of the non-poisoned modality to bridge the cross-modal attack gap. Then, we devise an input-aware injection network, which embeds the generated triggers into benign samples in the form of sample-specific stealth and realizes cross-modal semantic interaction between triggers and poisoned samples. Owing to the knowledge-agnostic of victim models, we enable any cross-modal hashing knockoff to facilitate the black-box backdoor attack and alleviate the attack weakening of hash quantization. Moreover, we propose a confusing perturbation and mask strategy to induce the high-performance victim models to focus on imperceptible triggers in poisoned samples. Extensive experiments on benchmark datasets demonstrate that our method has a state-of-the-art attack performance against deep cross-modal hashing retrieval. Besides, we investigate the influences of transferable attacks, few-shot poisoning, multi-modal poisoning, perceptibility, and potential defenses on backdoor attacks. Our codes and datasets are available at https://github.com/tswang0116/IB3A.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4392347638",
    "type": "article"
  },
  {
    "title": "Distributional Fairness-aware Recommendation",
    "doi": "https://doi.org/10.1145/3652854",
    "publication_date": "2024-03-18",
    "publication_year": 2024,
    "authors": "Hao Yang; Xian Wu; Zhaopeng Qiu; Yefeng Zheng; Xu Chen",
    "corresponding_authors": "",
    "abstract": "Fairness has been gradually recognized as a significant problem in the recommendation domain. Previous models usually achieve fairness by reducing the average performance gap between different user groups. However, the average performance may not sufficiently represent all the characteristics of the performances in a user group. Thus, equivalent average performance may not mean the recommender model is fair, for example, the variance of the performances can be different. To alleviate this problem, in this article, we define a novel type of fairness, where we require that the performance distributions across different user groups should be similar. We prove that with the same performance distribution, the numerical characteristics of the group performance, including the expectation, variance, and any higher-order moment, are also the same. To achieve distributional fairness, we propose a generative and adversarial training framework. Specifically, we regard the recommender model as the generator to compute the performance for each user in different groups, and then we deploy a discriminator to judge which group the performance is drawn from. By iteratively optimizing the generator and the discriminator, we can theoretically prove that the optimal generator (the recommender model) can indeed lead to the equivalent performance distributions. To smooth the adversarial training process, we propose a novel dual curriculum learning strategy for optimal scheduling of training samples. Additionally, we tailor our framework to better suit top-N recommendation tasks by incorporating softened ranking metrics as measures of performance discrepancies. We conduct extensive experiments based on real-world datasets to demonstrate the effectiveness of our model.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4392910965",
    "type": "article"
  },
  {
    "title": "Deep Coupling Network for Multivariate Time Series Forecasting",
    "doi": "https://doi.org/10.1145/3653447",
    "publication_date": "2024-03-21",
    "publication_year": 2024,
    "authors": "Kun Yi; Qi Zhang; Hui He; Kaize Shi; Liang Hu; Ning An; Zhendong Niu",
    "corresponding_authors": "",
    "abstract": "Multivariate time series (MTS) forecasting is crucial in many real-world applications. To achieve accurate MTS forecasting, it is essential to simultaneously consider both intra- and inter-series relationships among time series data. However, previous work has typically modeled intra- and inter-series relationships separately and has disregarded multi-order interactions present within and between time series data, which can seriously degrade forecasting accuracy. In this article, we reexamine intra- and inter-series relationships from the perspective of mutual information and accordingly construct a comprehensive relationship learning mechanism tailored to simultaneously capture the intricate multi-order intra- and inter-series couplings. Based on the mechanism, we propose a novel deep coupling network for MTS forecasting, named DeepCN, which consists of a coupling mechanism dedicated to explicitly exploring the multi-order intra- and inter-series relationships among time series data concurrently, a coupled variable representation module aimed at encoding diverse variable patterns, and an inference module facilitating predictions through one forward step. Extensive experiments conducted on seven real-world datasets demonstrate that our proposed DeepCN achieves superior performance compared with the state-of-the-art baselines.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4393041492",
    "type": "article"
  },
  {
    "title": "Listwise Generative Retrieval Models via a Sequential Learning Process",
    "doi": "https://doi.org/10.1145/3653712",
    "publication_date": "2024-03-22",
    "publication_year": 2024,
    "authors": "Yubao Tang; Ruqing Zhang; Jiafeng Guo; Maarten de Rijke; Wei Chen; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "Recently, a novel generative retrieval (GR) paradigm has been proposed, where a single sequence-to-sequence model is learned to directly generate a list of relevant document identifiers (docids) given a query. Existing GR models commonly employ maximum likelihood estimation (MLE) for optimization: This involves maximizing the likelihood of a single relevant docid given an input query, with the assumption that the likelihood for each docid is independent of the other docids in the list. We refer to these models as the pointwise approach in this article. While the pointwise approach has been shown to be effective in the context of GR, it is considered sub-optimal due to its disregard for the fundamental principle that ranking involves making predictions about lists. In this article, we address this limitation by introducing an alternative listwise approach, which empowers the GR model to optimize the relevance at the docid list level. Specifically, we view the generation of a ranked docid list as a sequence learning process: At each step, we learn a subset of parameters that maximizes the corresponding generation likelihood of the i th docid given the (preceding) top i -1 docids. To formalize the sequence learning process, we design a positional conditional probability for GR. To alleviate the potential impact of beam search on the generation quality during inference, we perform relevance calibration on the generation likelihood of model-generated docids according to relevance grades. We conduct extensive experiments on representative binary and multi-graded relevance datasets. Our empirical results demonstrate that our method outperforms state-of-the-art GR baselines in terms of retrieval performance.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4393096553",
    "type": "article"
  },
  {
    "title": "City Matters! A Dual-Target Cross-City Sequential POI Recommendation Model",
    "doi": "https://doi.org/10.1145/3664284",
    "publication_date": "2024-08-19",
    "publication_year": 2024,
    "authors": "Ke Sun; Chenliang Li; Tieyun Qian",
    "corresponding_authors": "",
    "abstract": "Existing sequential Point of Interest (POI) recommendation methods overlook a fact that each city exhibits distinct characteristics and totally ignore the city signature. In this study, we claim that city matters in sequential POI recommendation and fully exploring city signature can highlight the characteristics of each city and facilitate cross-city complementary learning. To this end, we consider the two-city scenario and propose a Dual-Target Cross-City Sequential POI Recommendation model (DCSPR) to achieve the purpose of complementary learning across cities. On one hand, DCSPR respectively captures geographical and cultural characteristics for each city by mining intra-city regions and intra-city functions of POIs. On the other hand, DCSPR builds a transfer channel between cities based on intra-city functions, and adopts a novel transfer strategy to transfer useful cultural characteristics across cities by mining inter-city functions of POIs. Moreover, to utilize these captured characteristics for sequential POI recommendation, DCSPR involves a new region- and function-aware network for each city to learn transition patterns from multiple views. Extensive experiments conducted on two real-world datasets with four cities demonstrate the effectiveness of DCSPR .",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4396794084",
    "type": "article"
  },
  {
    "title": "Adversarial Item Promotion on Visually-Aware Recommender Systems by Guided Diffusion",
    "doi": "https://doi.org/10.1145/3666088",
    "publication_date": "2024-05-28",
    "publication_year": 2024,
    "authors": "Lijian Chen; Wei Yuan; Tong Chen; Guanhua Ye; Quoc Viet Hung Nguyen; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "Visually-aware recommender systems have found widespread applications in domains where visual elements significantly contribute to the inference of users’ potential preferences. While the incorporation of visual information holds the promise of enhancing recommendation accuracy and alleviating the cold-start problem, it is essential to point out that the inclusion of item images may introduce substantial security challenges. Some existing works have shown that the item provider can manipulate item exposure rates to its advantage by constructing adversarial images. However, these works cannot reveal the real vulnerability of visually-aware recommender systems because (1) the generated adversarial images are markedly distorted, rendering them easily detected by human observers; and (2) the effectiveness of these attacks is inconsistent and even ineffective in some scenarios or datasets. To shed light on the real vulnerabilities of visually-aware recommender systems when confronted with adversarial images, this article introduces a novel attack method, Item Promotion by Diffusion Generated Image (IPDGI). Specifically, IPDGI employs a guided diffusion model to generate adversarial samples designed to promote the exposure rates of target items (e.g., long-tail items). Taking advantage of accurately modeling benign images’ distribution by diffusion models, the generated adversarial images have high fidelity with original images, ensuring the stealth of our IPDGI. To demonstrate the effectiveness of our proposed methods, we conduct extensive experiments on two commonly used e-commerce recommendation datasets (Amazon Beauty and Amazon Baby) with several typical visually-aware recommender systems. The experimental results show that our attack method significantly improves both the performance of promoting the long-tailed (i.e., unpopular) items and the quality of generated adversarial images.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4399087926",
    "type": "article"
  },
  {
    "title": "Our Model Achieves Excellent Performance on MovieLens: What Does It Mean?",
    "doi": "https://doi.org/10.1145/3675163",
    "publication_date": "2024-07-01",
    "publication_year": 2024,
    "authors": "Yu-Chen Fan; Yitong Ji; Jie Zhang; Aixin Sun",
    "corresponding_authors": "",
    "abstract": "A typical benchmark dataset for recommender system (RecSys) evaluation consists of user-item interactions generated on a platform within a time period. The interaction generation mechanism partially explains why a user interacts with (e.g., like, purchase, rate) an item, and the context of when a particular interaction happened. In this study, we conduct a meticulous analysis of the MovieLens dataset and explain the potential impact of using the dataset for evaluating recommendation algorithms. We make a few main findings from our analysis. First, there are significant differences in user interactions at the different stages when a user interacts with the MovieLens platform. The early interactions largely define the user portrait which affect the subsequent interactions. Second, user interactions are highly affected by the candidate movies that are recommended by the platform's internal recommendation algorithm(s). Third, changing the order of user interactions makes it more difficult for sequential algorithms to capture the progressive interaction process. We further discuss the discrepancy between the interaction generation mechanism that is employed by the MovieLens system and that of typical real-world recommendation scenarios. That is, the MovieLens dataset records \\(\\langle user-MovieLens\\rangle\\) interactions, but not \\(\\langle user-movie\\rangle\\) interactions. All research articles using the MovieLens dataset model the \\(\\langle user-MovieLens\\rangle\\) rather than the \\(\\langle user-movie\\rangle\\) interactions, making their results less generalizable to many practical recommendation scenarios in real-world settings. In summary, the MovieLens platform demonstrates an efficient and effective way of collecting user preferences to address cold-starts. However, models that achieve excellent recommendation accuracy on the MovieLens dataset may not demonstrate superior performance in practice , for at least two kinds of differences: (1) the differences in the contexts of user-item interaction generation, and (2) the differences in user knowledge about the item collections. While results on MovieLens can be useful as a reference, they should not be solely relied upon as the primary justification for the effectiveness of a recommendation system model.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4400199659",
    "type": "article"
  },
  {
    "title": "On Elastic Language Models",
    "doi": "https://doi.org/10.1145/3677375",
    "publication_date": "2024-07-12",
    "publication_year": 2024,
    "authors": "Chen Zhang; Benyou Wang; Dawei Song",
    "corresponding_authors": "",
    "abstract": "Large-scale pretrained language models have achieved compelling performance in a wide range of language understanding and information retrieval tasks. While their large scales ensure capacity, they also hinder deployment. Knowledge distillation offers an opportunity to compress a large language model to a small one, in order to reach a reasonable latency-performance tradeoff. However, for scenarios where the number of requests (e.g., queries submitted to a search engine) is highly variant, the static tradeoff attained by the compressed language model might not always fit. Once a model is assigned with a static tradeoff, it could be inadequate in that the latency is too high when the number of requests is large, or the performance is too low when the number of requests is small. To this end, we propose an elastic language model ( ElasticLM ) that elastically adjusts the tradeoff according to the request stream. The basic idea is to introduce a compute elasticity to the compressed language model, so that the tradeoff could vary on-the-fly along a scalable and controllable compute. Specifically, we impose an elastic structure to equip ElasticLM with compute elasticity and design an elastic optimization method to learn ElasticLM under compute elasticity. To serve ElasticLM , we apply an elastic schedule. Considering the specificity of information retrieval, we adapt ElasticLM to dense retrieval and reranking, and present an ElasticDenser and an ElasticRanker, respectively. Offline evaluation is conducted on a language understanding benchmark GLUE, and several information retrieval tasks including Natural Question, Trivia QA and MS MARCO. The results show that ElasticLM along with ElasticDenser and ElasticRanker can perform correctly and competitively compared with an array of static baselines. Furthermore, an online simulation with concurrency is also carried out. The results demonstrate that ElasticLM can provide elastic tradeoffs with respect to varying request stream.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4400581101",
    "type": "article"
  },
  {
    "title": "AdaGIN: Adaptive Graph Interaction Network for Click-Through Rate Prediction",
    "doi": "https://doi.org/10.1145/3681785",
    "publication_date": "2024-07-25",
    "publication_year": 2024,
    "authors": "Lei Sang; Honghao Li; Yiwen Zhang; Yi Zhang; Yun Yang",
    "corresponding_authors": "",
    "abstract": "The goal of click-through rate (CTR) prediction in recommender systems is to effectively work with input features. However, existing CTR prediction models face three main issues. First, many models use a basic approach for feature combinations, leading to noise and reduced accuracy. Second, there is no consideration for the varying importance of features in different interaction orders, affecting model performance. Third, current model architectures struggle to capture different interaction signals from various semantic spaces, leading to sub-optimal performance. To address these issues, we propose the Adaptive Graph Interaction Network (AdaGIN) with the Graph Neural Networks-based Feature Interaction Module (GFIM), the Multi-semantic Feature Interaction Module (MFIM), and the Negative Feedback-based Search (NFS) algorithm. GFIM explicitly aggregates information between features and assesses their importance, while MFIM captures information from different semantic spaces. NFS uses negative feedback to optimize model complexity. Experimental results show AdaGIN outperforms existing models on large-scale public benchmark datasets.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4400976979",
    "type": "article"
  },
  {
    "title": "Cluster-based Graph Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3687481",
    "publication_date": "2024-08-12",
    "publication_year": 2024,
    "authors": "Fan Liu; Shuai Zhao; Zhiyong Cheng; Liqiang Nie; Mohan Kankanhalli",
    "corresponding_authors": "",
    "abstract": "Graph Convolution Networks (GCNs) have significantly succeeded in learning user and item representations for recommendation systems. The core of their efficacy is the ability to explicitly exploit the collaborative signals from both the first- and high-order neighboring nodes. However, most existing GCN-based methods overlook the multiple interests of users while performing high-order graph convolution. Thus, the noisy information from unreliable neighbor nodes (e.g., users with dissimilar interests) negatively impacts the representation learning of the target node. Additionally, conducting graph convolution operations without differentiating high-order neighbors suffers the over-smoothing issue when stacking more layers, resulting in performance degradation. In this article, we aim to capture more valuable information from high-order neighboring nodes while avoiding noise for better representation learning of the target node. To achieve this goal, we propose a novel GCN-based recommendation model, termed Cluster-based Graph Collaborative Filtering (ClusterGCF). This model performs high-order graph convolution on cluster-specific graphs, which are constructed by capturing the multiple interests of users and identifying the common interests among them. Specifically, we design an unsupervised and optimizable soft node clustering approach to classify user and item nodes into multiple clusters. Based on the soft node clustering results and the topology of the user–item interaction graph, we assign the nodes with probabilities for different clusters to construct the cluster-specific graphs. To evaluate the effectiveness of ClusterGCF, we conducted extensive experiments on four publicly available datasets. Experimental results demonstrate that our model can significantly improve recommendation performance.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4401510933",
    "type": "article"
  },
  {
    "title": "Simplify to the Limit! Embedding-less Graph Collaborative Filtering for Recommender Systems",
    "doi": "https://doi.org/10.1145/3701230",
    "publication_date": "2024-10-19",
    "publication_year": 2024,
    "authors": "Yi Zhang; Yiwen Zhang; Lei Sang; Victor S. Sheng",
    "corresponding_authors": "",
    "abstract": "The tremendous positive driving effect of Graph Convolutional Network (GCN) and Graph Contrastive Learning (GCL) for recommender systems has become a consensus. GCN encoders are extensively used in recommendation models for capturing high-order connectivities between users and items, whereas GCL accelerates the training of recommendation tasks by adding extra supervision signals from contrastive objectives. However, little attention has been paid on corresponding theories that are truly tailored to recommendation tasks. From the technical perspective, Collaborative Filtering (CF) is seen as an important factor in recommender systems. It is applied to measure user-user, item-item, and user-item similarities rather than to achieve better clustering or node classification results. Besides, heuristic-based data augmentation may not be hold true in the field of recommender systems as it requires additional training costs and introduces noises that will corrupt the interaction graph structure and the semantic information of nodes. To tackle these limitations, we propose a novel Embedding-less Graph Collaborative Filtering (EGCF) for recommendation, which is tailor-made for the problem mentioned for CF and further simplifies existing solutions. Structurally, it consists of two parts: embedding-less GCN and embedding-less GCL. The former improves user-item affinity by streamlining user-type embeddings and carrying out iterative graph convolution. And the latter utilizes three-type contrastive objectives to directly measure the alignment and the uniformity of users, items, and interaction pairs, respectively, avoiding any type of data augmentation or multi-view construction. Even though EGCF has been extremely streamlined, extensive experimental results on three classical datasets demonstrate the effectiveness of EGCF in terms of recommendation accuracy and training efficiency. The code and used datasets are released at https://github.com/BlueGhostYi/ID-GRec.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4403560363",
    "type": "article"
  },
  {
    "title": "Disentangled Dynamic Graph Attention Network for Out-of-distribution Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3701988",
    "publication_date": "2024-10-29",
    "publication_year": 2024,
    "authors": "Zeyang Zhang; Xin Wang; Haibo Chen; Haoyang Li; Wenwu Zhu",
    "corresponding_authors": "",
    "abstract": "Sequential recommendation, leveraging user-item interaction histories to provide personalized and timely suggestions, has drawn significant research interest recently. With the power of exploiting spatio-temporal dynamics, dynamic graph neural networks (DyGNNs) show great potential in sequential recommendation by modeling the dynamic relationship between users and items. However, spatio-temporal distribution shifts naturally exist in out-of-distribution sequential recommendation, where both user-item relationships and temporal sequences demonstrate pattern shifts. The out-of-distribution scenarios may lead to the failure of existing DyGNNs in handling spatio-temporal distribution shifts in sequential recommendation, given that the patterns they exploit tend to be variant w.r.t labels under distribution shifts. In this paper, we propose D isentangled I ntervention-based D ynamic graph A ttention networks with I nvariance Promotion ( I-DIDA ) to handle spatio-temporal distribution shifts in sequential recommendation by discovering and utilizing invariant patterns, ie , structures and features whose predictive abilities are stable across distribution shifts. Specifically, we first propose a disentangled spatio-temporal attention network to capture the variant and invariant patterns. By utilizing the disentangled patterns, we design a spatio-temporal intervention mechanism to create multiple interventional distributions and an environment inference module to infer the latent spatio-temporal environments, and minimize the invariance loss to leverage the invariant patterns with stable predictive abilities under distribution shifts. Extensive experiments demonstrate the superiority of our method over state-of-the-art sequential recommendation baselines under distribution shifts.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4403862104",
    "type": "article"
  },
  {
    "title": "Shortest-substring retrieval and ranking",
    "doi": "https://doi.org/10.1145/333135.333137",
    "publication_date": "2000-01-01",
    "publication_year": 2000,
    "authors": "Charles L. A. Clarke; Gordon V. Cormack",
    "corresponding_authors": "",
    "abstract": "We present a model for arbitrary passage retrieval using Boolean queries. The model is applied to the task of ranking documents, or other structural elements, in the order of their expected relevance. Features such as phrase matching, truncation, and stemming integrate naturally into the model. Properties of Boolean algebra are obeyed, and the exact-match semantics of Boolean retrieval are preserved. Simple inverted-list file structures provide an efficient implementation. Retrieval effectiveness is comparable to that of standard ranking techniques. Since global statistics are not used, the method is of particular value in distributed environments. Since ranking is based on arbitrary passages, the structural elements to be ranked may be specified at query time and do not need to be restricted to predefined elements.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2035512259",
    "type": "article"
  },
  {
    "title": "Self-spacial join selectivity estimation using fractal concepts",
    "doi": "https://doi.org/10.1145/279339.279342",
    "publication_date": "1998-04-01",
    "publication_year": 1998,
    "authors": "Alberto Belussi; Christos Faloutsos",
    "corresponding_authors": "",
    "abstract": "The problem of selectivity estimation for queries of nontraditional databases is still an open issue. In this article, we examine the problem of selectivity estimation for some types of spatial queries in databases containing real data . We have shown earlier [Faloutsos and Kamel 1994] that real point sets typically have a nonuniform distribution, violating consistently the uniformity and independence assumptions. Moreover, we demonstrated that the theory of fractals can help to describe real point sets. In this article we show how the concept of fractal dimension, i.e., (noninteger) dimension, can lead to the solution for the selectivity estimation problem in spatial databases. Among the infinite family of fractal dimensions, we consider here the Hausdorff fractal dimension D 0 and the “Correlation” fractal dimension D 2 . Specifically, we show that (a) the average number of neighbors for a given point set follows a power law, with D 2 as exponent, and (b) the average number of nonempty range queries follows a power law with E − D 0 as exponent ( E is the dimension of the embedding space). We present the formulas to estimate the selectivity for “biased” range queries, for self-spatial joins, and for the average number of nonempty range queries. The result of some experiments on real and synthetic point sets are shown. Our formulas achieve very low relative errors, typically about 10%, versus 40%–100% of the formulas that are based on the uniformity and independence assumptions.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2079348595",
    "type": "article"
  },
  {
    "title": "A hierarchical access control model for video database systems",
    "doi": "https://doi.org/10.1145/763693.763695",
    "publication_date": "2003-04-01",
    "publication_year": 2003,
    "authors": "Elisa Bertino; Jianping Fan; Elena Ferrari; Mohand-Saïd Hacid; Ahmed K. Elmagarmid; Xingquan Zhu",
    "corresponding_authors": "",
    "abstract": "Content-based video database access control is becoming very important, but it depends on the progresses of the following related research issues: (a) efficient video analysis for supporting semantic visual concept representation; (b) effective video database indexing structure; (c) the development of suitable video database models; and (d) the development of access control models tailored to the characteristics of video data. In this paper, we propose a novel approach to support multilevel access control in video databases. Our access control technique combines a video database indexing mechanism with a hierarchical organization of visual concepts (i.e., video database indexing units), so that different classes of users can access different video elements or even the same video element with different quality levels according to their permissions. These video elements, which, in our access control mechanism, are used for specifying the authorization objects, can be a semantic cluster, a subcluster, a video scene, a video shot, a video frame, or even a salient object (i.e., region of interest). In the paper, we first introduce our techniques for obtaining these multilevel video access units. We also propose a hierarchical video database indexing technique to support our multilevel video access control mechanism. Then, we present an innovative access control model which is able to support flexible multilevel access control to video elements. Moreover, the application of our multilevel video database modeling, representation, and indexing for MPEG-7 is discussed.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2030866632",
    "type": "article"
  },
  {
    "title": "Logical and physical design issues for smart card databases",
    "doi": "https://doi.org/10.1145/858476.858478",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Cristiana Bolchini; Fabio Salice; Fabio A. Schreiber; Letizia Tanca",
    "corresponding_authors": "",
    "abstract": "The design of very small databases for smart cards and for portable embedded systems is deeply constrained by the peculiar features of the physical medium. We propose a joint approach to the logical and physical database design phases and evaluate several data structures with respect to the performance, power consumption, and endurance parameters of read/program operations on the Flash-EEPROM storage medium.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2120125737",
    "type": "article"
  },
  {
    "title": "The use of dynamic contexts to improve casual internet searching",
    "doi": "https://doi.org/10.1145/858476.858477",
    "publication_date": "2003-07-01",
    "publication_year": 2003,
    "authors": "Gondy Leroy; Ann Lally; Hsinchun Chen",
    "corresponding_authors": "",
    "abstract": "Research has shown that most users' online information searches are suboptimal. Query optimization based on a relevance feedback or genetic algorithm using dynamic query contexts can help casual users search the Internet. These algorithms can draw on implicit user feedback based on the surrounding links and text in a search engine result set to expand user queries with a variable number of keywords in two manners. Positive expansion adds terms to a user's keywords with a Boolean \"and,\" negative expansion adds terms to the user's keywords with a Boolean \"not.\" Each algorithm was examined for three user groups, high, middle, and low achievers, who were classified according to their overall performance. The interactions of users with different levels of expertise with different expansion types or algorithms were evaluated. The genetic algorithm with negative expansion tripled recall and doubled precision for low achievers, but high achievers displayed an opposed trend and seemed to be hindered in this condition. The effect of other conditions was less substantial.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2142965909",
    "type": "article"
  },
  {
    "title": "An experimental multimedia mail system",
    "doi": "https://doi.org/10.1145/42279.42280",
    "publication_date": "1988-01-01",
    "publication_year": 1988,
    "authors": "J. Postel; Gregory G. Finn; Alan R. Katz; Joyce K. Reynolds",
    "corresponding_authors": "",
    "abstract": "A computer-based experimental multimedia mail system that allows the user to read, create, edit, send, and receive messages containing text, images, and voice is discussed.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W1997582462",
    "type": "article"
  },
  {
    "title": "Set-based vector model",
    "doi": "https://doi.org/10.1145/1095872.1095874",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Bruno Pôssas; Nívio Ziviani; Wagner Meira; Berthier Ribeiro‐Neto",
    "corresponding_authors": "",
    "abstract": "This work presents a new approach for ranking documents in the vector space model. The novelty lies in two fronts. First, patterns of term co-occurrence are taken into account and are processed efficiently. Second, term weights are generated using a data mining technique called association rules. This leads to a new ranking mechanism called the set-based vector model . The components of our model are no longer index terms but index termsets, where a termset is a set of index terms. Termsets capture the intuition that semantically related terms appear close to each other in a document. They can be efficiently obtained by limiting the computation to small passages of text. Once termsets have been computed, the ranking is calculated as a function of the termset frequency in the document and its scarcity in the document collection. Experimental results show that the set-based vector model improves average precision for all collections and query types evaluated, while keeping computational costs small. For the 2-gigabyte TREC-8 collection, the set-based vector model leads to a gain in average precision figures of 14.7% and 16.4% for disjunctive and conjunctive queries, respectively, with respect to the standard vector space model. These gains increase to 24.9% and 30.0%, respectively, when proximity information is taken into account. Query processing times are larger but, on average, still comparable to those obtained with the standard vector model (increases in processing time varied from 30% to 300%). Our results suggest that the set-based vector model provides a correlation-based ranking formula that is effective with general collections and computationally practical.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2023613961",
    "type": "article"
  },
  {
    "title": "A novel document retrieval method using the discrete wavelet transform",
    "doi": "https://doi.org/10.1145/1080343.1080345",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Laurence A. F. Park; Kotagiri Ramamohanarao; Marimuthu Palaniswami",
    "corresponding_authors": "",
    "abstract": "Current information retrieval methods either ignore the term positions or deal with exact term positions; the former can be seen as coarse document resolution, the latter as fine document resolution. We propose a new spectral-based information retrieval method that is able to utilize many different levels of document resolution by examining the term patterns that occur in the documents. To do this, we take advantage of the multiresolution analysis properties of the wavelet transform. We show that we are able to achieve higher precision when compared to vector space and proximity retrieval methods, while producing fast query times and using a compact index.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2085938017",
    "type": "article"
  },
  {
    "title": "ASK is transportable in half a dozen ways",
    "doi": "https://doi.org/10.1145/3914.3983",
    "publication_date": "1985-04-01",
    "publication_year": 1985,
    "authors": "Bozena Henisz Thompson; Frederick B. Thompson",
    "corresponding_authors": "",
    "abstract": "This paper is a discussion of the technical issues and solutions encountered in making the ASK System transportable. A natural language system can be “transportable” in a number of ways. Although transportability to a new domain is most prominent, other ways are also important if the system is to have viability in the commercial marketplace. On the one hand, transporting a system to a new domain may start with the system prior to adding any domain of knowledge and extend it to incorporate the new domain. On the other hand, one may wish to add to a system that already has knowledge of one domain the knowledge concerning a second domain, that is, to extend the system to cover this second domain. In the context of ASK, it has been natural to implement extending and then achieve transportability as a special case. In this paper, we consider six ways in which the ASK System can be extended to include new capabilities: Special-purpose applications, such as those to accommodate standard office tasks, would make use of these various means of extension.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2032551631",
    "type": "article"
  },
  {
    "title": "A transient hypergraph-based model for data access",
    "doi": "https://doi.org/10.1145/96105.96107",
    "publication_date": "1990-04-01",
    "publication_year": 1990,
    "authors": "Carolyn Watters; Michael Shepherd",
    "corresponding_authors": "",
    "abstract": "Two major methods of accessing data in current database systems are querying and browsing. The more traditional query method returns an answer set that may consist of data values (DBMS), items containing the answer (full text), or items referring the user to items containing the answer (bibliographic). Browsing within a database, as best exemplified by hypertext systems, consists of viewing a database item and linking to related items on the basis of some attribute or attribute value. A model of data access has been developed that supports both query and browse access methods. The model is based on hypergraph representation of data instances. The hyperedges and nodes are manipulated through a set of operators to compose new nodes and to instantiate new links dynamically, resulting in transient hypergraphs. These transient hypergraphs are virtual structures created in response to user queries, and lasting only as long as the query session. The model provides a framework for general data access that accommodates user-directed browsing and querying, as well as traditional models of information and data retrieval, such as the Boolean, vector space, and probabilistic models. Finally, the relational database model is shown to provide a reasonable platform for the implementation of this transient hypergraph-based model of data access.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2072020103",
    "type": "article"
  },
  {
    "title": "A model for naming, addressing and routing",
    "doi": "https://doi.org/10.1145/9760.9761",
    "publication_date": "1986-12-01",
    "publication_year": 1986,
    "authors": "Bernard M. Hauzeur",
    "corresponding_authors": "Bernard M. Hauzeur",
    "abstract": "Naming and addressing are areas in which there is still a need for clarification. Many definitions for names, addresses, and routes have been proposed, but the exact relations among these concepts are obscure. A taxonomy of names, addresses, and routes is presented. First, we identify names and routes as the essential concepts of communication. Then, addresses are introduced as an intermediate form that eases the process of mapping between names and routes; an original definition of an address is thus proposed. Relations among names, addresses, and routes are explained with the concept of mapping. On this basis, a general model relating names, addresses, and routes is built and then applied recursively throughout a layered architecture, leading to a layered naming and addressing model which may play the same role for naming and addressing features that the OS1 reference model plays for the definition of services and protocols. Finally, the model is particularized to a typical network architecture. The model may also be applied to non-OSI layered systems; naming, addressing, and routing issues in any network architecture could be a particular instance of this layered model.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2040373443",
    "type": "article"
  },
  {
    "title": "Office-by-example: an integrated office system and database manager",
    "doi": "https://doi.org/10.1145/42196.42200",
    "publication_date": "1987-10-01",
    "publication_year": 1987,
    "authors": "Kyu-Young Whang; Art Ammann; Anthony Bolmarcich; Maria Hanrahan; Guy Hochgesang; Kuan‐Tsae Huang; Al Khorasani; Ravi Krishnamurthy; Gary H. Sockut; Paula Sweeney; Vance Waddle; Moshé M. Zloof",
    "corresponding_authors": "",
    "abstract": "Office-by-Example (OBE) is an integrated office information system that has been under development at IBM Research. OBE, an extension of Query-by-Example, supports various office features such as database tables, word processing, electronic mail, graphics, images, and so forth. These seemingly heterogeneous features are integrated through a language feature called example elements . Applications involving example elements are processed by the database manager, an integrated part of the OBE system. In this paper we describe the facilities and architecture of the OBE system and discuss the techniques for integrating heterogeneous objects.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W1985828665",
    "type": "article"
  },
  {
    "title": "A generator of direct manipulation office systems",
    "doi": "https://doi.org/10.1145/6168.6171",
    "publication_date": "1986-04-01",
    "publication_year": 1986,
    "authors": "Scott E. Hudson; Roger King",
    "corresponding_authors": "",
    "abstract": "A system for generating direct manipulation office systems is described. In these systems, the user directly manipulates graphical representations of office entities instead of dealing with these entities abstractly through a command language or menu system. These systems employ a new semantic data model to describe office entities. New techniques based on attribute grammars and incremental attribute evaluation are used to implement this data model in an efficient manner. In addition, the system provides a means of generating sophisticated graphics-based user interfaces that are integrated with the underlying semantic model. Finally, the generated systems contain a general user reversal and recovery (or undo) mechanism that allows them to be much more tolerant of human errors.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2099634336",
    "type": "article"
  },
  {
    "title": "A database design methodology and tool for information systems",
    "doi": "https://doi.org/10.1145/3864.3869",
    "publication_date": "1985-01-02",
    "publication_year": 1985,
    "authors": "Roger King; Dennis McLeod",
    "corresponding_authors": "",
    "abstract": "A model and methodology for describing the information objects in an office information system and how such objects flow among the components of such a system are presented. The model and methodology support the specification of information objects at multiple levels of abstraction. An interactive prototype design tool based on the methodology and model has been designed and experimentally implemented.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2093200179",
    "type": "article"
  },
  {
    "title": "The design of Star's records processing",
    "doi": "https://doi.org/10.1145/357423.357425",
    "publication_date": "1983-01-01",
    "publication_year": 1983,
    "authors": "Robert Purvy; Jerry Farrell; Paul Klose",
    "corresponding_authors": "",
    "abstract": "article Free AccessThe design of Star's records processing: data processing for the noncomputer professional Authors: Robert Purvy Xerox-OSD, 830 S. Nash St., El Segundo, CA Xerox-OSD, 830 S. Nash St., El Segundo, CAView Profile , Jerry Farrell Xerox-OSD, 3333 Coyote Hill Road, Palo Alto, CA Xerox-OSD, 3333 Coyote Hill Road, Palo Alto, CAView Profile , Paul Klose Xerox-OSD, 830 S. Nash St., El Segundo, CA Xerox-OSD, 830 S. Nash St., El Segundo, CAView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 1Jan. 1983 pp 3–24https://doi.org/10.1145/357423.357425Published:01 January 1983Publication History 30citation547DownloadsMetricsTotal Citations30Total Downloads547Last 12 Months18Last 6 weeks5 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2024308018",
    "type": "article"
  },
  {
    "title": "Incremental cluster-based retrieval using compressed cluster-skipping inverted files",
    "doi": "https://doi.org/10.1145/1361684.1361688",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "İsmail Sengör Altıngövde; Engin Demir; Fazlı Can; Özgür Ulusoy",
    "corresponding_authors": "",
    "abstract": "We propose a unique cluster-based retrieval (CBR) strategy using a new cluster-skipping inverted file for improving query processing efficiency. The new inverted file incorporates cluster membership and centroid information along with the usual document information into a single structure. In our incremental-CBR strategy, during query evaluation, both best(-matching) clusters and the best(-matching) documents of such clusters are computed together with a single posting-list access per query term. As we switch from term to term, the best clusters are recomputed and can dynamically change. During query-document matching, only relevant portions of the posting lists corresponding to the best clusters are considered and the rest are skipped. The proposed approach is essentially tailored for environments where inverted files are compressed, and provides substantial efficiency improvement while yielding comparable, or sometimes better, effectiveness figures. Our experiments with various collections show that the incremental-CBR strategy using a compressed cluster-skipping inverted file significantly improves CPU time efficiency, regardless of query length. The new compressed inverted file imposes an acceptable storage overhead in comparison to a typical inverted file. We also show that our approach scales well with the collection size.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2082496345",
    "type": "article"
  },
  {
    "title": "Answering XML queries by means of data summaries",
    "doi": "https://doi.org/10.1145/1247715.1247716",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Elena Baralis; Paolo Garza; Elisa Quintarelli; Letizia Tanca",
    "corresponding_authors": "",
    "abstract": "XML is a rather verbose representation of semistructured data, which may require huge amounts of storage space. We propose a summarized representation of XML data, based on the concept of instance pattern, which can both provide succinct information and be directly queried. The physical representation of instance patterns exploits itemsets or association rules to summarize the content of XML datasets. Instance patterns may be used for (possibly partially) answering queries, either when fast and approximate answers are required, or when the actual dataset is not available, for example, it is currently unreachable. Experiments on large XML documents show that instance patterns allow a significant reduction in storage space, while preserving almost entirely the completeness of the query result. Furthermore, they provide fast query answers and show good scalability on the size of the dataset, thus overcoming the document size limitation of most current XQuery engines.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2091478531",
    "type": "article"
  },
  {
    "title": "Assessing multivariate Bernoulli models for information retrieval",
    "doi": "https://doi.org/10.1145/1361684.1361690",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "David E. Losada; Leif Azzopardi",
    "corresponding_authors": "",
    "abstract": "Although the seminal proposal to introduce language modeling in information retrieval was based on a multivariate Bernoulli model, the predominant modeling approach is now centered on multinomial models. Language modeling for retrieval based on multivariate Bernoulli distributions is seen inefficient and believed less effective than the multinomial model. In this article, we examine the multivariate Bernoulli model with respect to its successor and examine its role in future retrieval systems. In the context of Bayesian learning, these two modeling approaches are described, contrasted, and compared both theoretically and computationally. We show that the query likelihood following a multivariate Bernoulli distribution introduces interesting retrieval features which may be useful for specific retrieval tasks such as sentence retrieval. Then, we address the efficiency aspect and show that algorithms can be designed to perform retrieval efficiently for multivariate Bernoulli models, before performing an empirical comparison to study the behaviorial aspects of the models. A series of comparisons is then conducted on a number of test collections and retrieval tasks to determine the empirical and practical differences between the different models. Our results indicate that for sentence retrieval the multivariate Bernoulli model can significantly outperform the multinomial model. However, for the other tasks the multinomial model provides consistently better performance (and in most cases significantly so). An analysis of the various retrieval characteristics reveals that the multivariate Bernoulli model tends to promote long documents whose nonquery terms are informative. While this is detrimental to the task of document retrieval (documents tend to contain considerable nonquery content), it is valuable for other tasks such as sentence retrieval, where the retrieved elements are very short and focused.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2050727066",
    "type": "article"
  },
  {
    "title": "Information filtering and query indexing for an information retrieval model",
    "doi": "https://doi.org/10.1145/1462198.1462202",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Christos Tryfonopoulos; Manolis Koubarakis; Yannis Drougas",
    "corresponding_authors": "",
    "abstract": "In the information filtering paradigm, clients subscribe to a server with continuous queries or profiles that express their information needs. Clients can also publish documents to servers. Whenever a document is published, the continuous queries satisfying this document are found and notifications are sent to appropriate clients. This article deals with the filtering problem that needs to be solved efficiently by each server: Given a database of continuous queries db and a document d , find all queries q ∈ db that match d . We present data structures and indexing algorithms that enable us to solve the filtering problem efficiently for large databases of queries expressed in the model AWP . AWP is based on named attributes with values of type text, and its query language includes Boolean and word proximity operators.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2109140363",
    "type": "article"
  },
  {
    "title": "Mining near-duplicate graph for cluster-based reranking of web video search results",
    "doi": "https://doi.org/10.1145/1852102.1852108",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Zi Huang; Bo Hu; Hong Cheng; Heng Tao Shen; Hongyan Liu; Xiaofang Zhou",
    "corresponding_authors": "",
    "abstract": "Recently, video search reranking has been an effective mechanism to improve the initial text-based ranking list by incorporating visual consistency among the result videos. While existing methods attempt to rerank all the individual result videos, they suffer from several drawbacks. In this article, we propose a new video reranking paradigm called cluster-based video reranking (CVR). The idea is to first construct a video near-duplicate graph representing the visual similarity relationship among videos, followed by identifying the near-duplicate clusters from the video near-duplicate graph, then ranking the obtained near-duplicate clusters based on cluster properties and intercluster links, and finally for each ranked cluster, a representative video is selected and returned. Compared to existing methods, the new CVR ranks clusters and exhibits several advantages, including superior reranking by utilizing more reliable cluster properties, fast reranking on a small number of clusters, diverse and representative results. Particularly, we formulate the near-duplicate cluster identification as a novel maximally cohesive subgraph mining problem. By leveraging the designed cluster scoring properties indicating the cluster's importance and quality, random walk is applied over the near-duplicate cluster graph to rank clusters. An extensive evaluation study proves the novelty and superiority of our proposals over existing methods.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2037650152",
    "type": "article"
  },
  {
    "title": "Comparison of methods for language-dependent and language-independent query-by-example spoken term detection",
    "doi": "https://doi.org/10.1145/2328967.2328971",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Javier Tejedor; Michal Fapšo; Igor Szöke; Jaň Černocký; František Grézl",
    "corresponding_authors": "",
    "abstract": "This article investigates query-by-example (QbE) spoken term detection (STD), in which the query is not entered as text, but selected in speech data or spoken. Two feature extractors based on neural networks (NN) are introduced: the first producing phone-state posteriors and the second making use of a compressive NN layer. They are combined with three different QbE detectors: while the Gaussian mixture model/hidden Markov model (GMM/HMM) and dynamic time warping (DTW) both work on continuous feature vectors, the third one, based on weighted finite-state transducers (WFST), processes phone lattices. QbE STD is compared to two standard STD systems with text queries: acoustic keyword spotting and WFST-based search of phone strings in phone lattices. The results are reported on four languages (Czech, English, Hungarian, and Levantine Arabic) using standard metrics: equal error rate (EER) and two versions of popular figure-of-merit (FOM). Language-dependent and language-independent cases are investigated; the latter being particularly interesting for scenarios lacking standard resources to train speech recognition systems. While the DTW and GMM/HMM approaches produce the best results for a language-dependent setup depending on the target language, the GMM/HMM approach performs the best dealing with a language-independent setup. As far as WFSTs are concerned, they are promising as they allow for indexing and fast search.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2104283211",
    "type": "article"
  },
  {
    "title": "Static index pruning in web search engines",
    "doi": "https://doi.org/10.1145/2094072.2094074",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "İsmail Sengör Altıngövde; Rifat Ozcan; Özgür Ulusoy",
    "corresponding_authors": "",
    "abstract": "Static index pruning techniques permanently remove a presumably redundant part of an inverted file, to reduce the file size and query processing time. These techniques differ in deciding which parts of an index can be removed safely; that is, without changing the top-ranked query results. As defined in the literature, the query view of a document is the set of query terms that access to this particular document, that is, retrieves this document among its top results. In this paper, we first propose using query views to improve the quality of the top results compared against the original results. We incorporate query views in a number of static pruning strategies, namely term-centric, document-centric, term popularity based and document access popularity based approaches, and show that the new strategies considerably outperform their counterparts especially for the higher levels of pruning and for both disjunctive and conjunctive query processing. Additionally, we combine the notions of term and document access popularity to form new pruning strategies, and further extend these strategies with the query views. The new strategies improve the result quality especially for the conjunctive query processing, which is the default and most common search mode of a search engine.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2137250554",
    "type": "article"
  },
  {
    "title": "A Measurement Framework for Evaluating Emulators for Digital Preservation",
    "doi": "https://doi.org/10.1145/2180868.2180876",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Mark Guttenbrunner; Andreas Rauber",
    "corresponding_authors": "",
    "abstract": "Accessible emulation is often the method of choice for maintaining digital objects, specifically complex ones such as applications, business processes, or electronic art. However, validating the emulator’s ability to faithfully reproduce the original behavior of digital objects is complicated. This article presents an evaluation framework and a set of tests that allow assessment of the degree to which system emulation preserves original characteristics and thus significant properties of digital artifacts. The original system, hardware, and software properties are described. Identical environment is then recreated via emulation. Automated user input is used to eliminate potential confounders. The properties of a rendered form of the object are then extracted automatically or manually either in a target state, a series of states, or as a continuous stream. The concepts described in this article enable preservation planners to evaluate how emulation affects the behavior of digital objects compared to their behavior in the original environment. We also review how these principles can and should be applied to the evaluation of migration and other preservation strategies as a general principle of evaluating the invocation and faithful rendering of digital objects and systems. The article concludes with design requirements for emulators developed for digital preservation tasks.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2054413259",
    "type": "article"
  },
  {
    "title": "Document Score Distribution Models for Query Performance Inference and Prediction",
    "doi": "https://doi.org/10.1145/2559170",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Ronan Cummins",
    "corresponding_authors": "Ronan Cummins",
    "abstract": "Modelling the distribution of document scores returned from an information retrieval (IR) system in response to a query is of both theoretical and practical importance. One of the goals of modelling document scores in this manner is the inference of document relevance. There has been renewed interest of late in modelling document scores using parameterised distributions. Consequently, a number of hypotheses have been proposed to constrain the mixture distribution from which document scores could be drawn. In this article, we show how a standard performance measure (i.e., average precision) can be inferred from a document score distribution using labelled data. We use the accuracy of the inference of average precision as a measure for determining the usefulness of a particular model of document scores. We provide a comprehensive study which shows that certain mixtures of distributions are able to infer average precision more accurately than others. Furthermore, we analyse a number of mixture distributions with regard to the recall-fallout convexity hypothesis and show that the convexity hypothesis is practically useful. Consequently, based on one of the best-performing score-distribution models, we develop some techniques for query-performance prediction (QPP) by automatically estimating the parameters of the document score-distribution model when relevance information is unknown. We present experimental results that outline the benefits of this approach to query-performance prediction.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2064900984",
    "type": "article"
  },
  {
    "title": "Georeferencing Wikipedia Documents Using Data from Social Media Sources",
    "doi": "https://doi.org/10.1145/2629685",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Olivier Van Laere; Steven Schockaert; Vlad Tanasescu; Bart Dhoedt; Christopher B. Jones",
    "corresponding_authors": "",
    "abstract": "Social media sources such as Flickr and Twitter continuously generate large amounts of textual information (tags on Flickr and short messages on Twitter). This textual information is increasingly linked to geographical coordinates, which makes it possible to learn how people refer to places by identifying correlations between the occurrence of terms and the locations of the corresponding social media objects. Recent work has focused on how this potentially rich source of geographic information can be used to estimate geographic coordinates for previously unseen Flickr photos or Twitter messages. In this article, we extend this work by analysing to what extent probabilistic language models trained on Flickr and Twitter can be used to assign coordinates to Wikipedia articles. Our results show that exploiting these language models substantially outperforms both (i) classical gazetteer-based methods (in particular, using Yahoo! Placemaker and Geonames) and (ii) language modelling approaches trained on Wikipedia alone. This supports the hypothesis that social media are important sources of geographic information, which are valuable beyond the scope of individual applications.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2095606380",
    "type": "article"
  },
  {
    "title": "Fast and Flexible Top- <i>k</i> Similarity Search on Large Networks",
    "doi": "https://doi.org/10.1145/3086695",
    "publication_date": "2017-08-21",
    "publication_year": 2017,
    "authors": "Jing Zhang; Jie Tang; Cong Ma; Hanghang Tong; Jing Yu; Juanzi Li; Walter Luyten; Marie‐Francine Moens",
    "corresponding_authors": "",
    "abstract": "Similarity search is a fundamental problem in network analysis and can be applied in many applications, such as collaborator recommendation in coauthor networks, friend recommendation in social networks, and relation prediction in medical information networks. In this article, we propose a sampling-based method using random paths to estimate the similarities based on both common neighbors and structural contexts efficiently in very large homogeneous or heterogeneous information networks. We give a theoretical guarantee that the sampling size depends on the error-bound ε, the confidence level (1-δ), and the path length T of each random walk. We perform an extensive empirical study on a Tencent microblogging network of 1,000,000,000 edges. We show that our algorithm can return top- k similar vertices for any vertex in a network 300× faster than the state-of-the-art methods. We develop a prototype system of recommending similar authors to demonstrate the effectiveness of our method.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2716747561",
    "type": "article"
  },
  {
    "title": "Mining Exploratory Behavior to Improve Mobile App Recommendations",
    "doi": "https://doi.org/10.1145/3072588",
    "publication_date": "2017-08-19",
    "publication_year": 2017,
    "authors": "Jiangning He; Hongyan Liu",
    "corresponding_authors": "",
    "abstract": "With the widespread usage of smart phones, more and more mobile apps are developed every day, playing an increasingly important role in changing our lifestyles and business models. In this trend, it becomes a hot research topic for developing effective mobile app recommender systems in both industry and academia. Compared with existing studies about mobile app recommendations, our research aims to improve the recommendation effectiveness based on analyzing a psychological trait of human beings, exploratory behavior, which refers to a type of variety-seeking behavior in unfamiliar domains. To this end, we propose a novel probabilistic model named Goal-oriented Exploratory Model (GEM), integrating exploratory behavior identification with personalized item recommendation. An algorithm combining collapsed Gibbs sampling and Expectation Maximization is developed for model learning and inference. Through extensive experiments conducted on a real dataset, the proposed model demonstrates superior recommendation performances and good interpretability compared with state-of-art recommendation methods. Moreover, empirical analyses on exploratory behavior find that individuals with a strong exploratory tendency exhibit behavioral patterns of variety seeking, risk taking, and higher involvement. Besides, mobile apps that are less popular or in the long tail possess greater potential of arousing exploratory behavior in individuals.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2750126932",
    "type": "article"
  },
  {
    "title": "Modeling and Mining Domain Shared Knowledge for Sentiment Analysis",
    "doi": "https://doi.org/10.1145/3091995",
    "publication_date": "2017-08-31",
    "publication_year": 2017,
    "authors": "Guangyou Zhou; Jimmy Xiangji Huang",
    "corresponding_authors": "",
    "abstract": "Sentiment classification aims to automatically predict sentiment polarity (e.g., positive or negative) of user generated sentiment data (e.g., reviews, blogs). In real applications, these user-generated sentiment data can span so many different domains that it is difficult to label the training data for all of them. Therefore, we study the problem of sentiment classification adaptation task in this article. That is, a system is trained to label reviews from one source domain but is meant to be used on the target domain. One of the biggest challenges for sentiment classification adaptation task is how to deal with the problem when two data distributions between the source domain and target domain are significantly different from one another. However, our observation is that there might exist some domain shared knowledge among certain input dimensions of different domains. In this article, we present a novel method for modeling and mining the domain shared knowledge from different sentiment review domains via a joint non-negative matrix factorization–based framework. In this proposed framework, we attempt to learn the domain shared knowledge and the domain-specific information from different sentiment review domains with several various regularization constraints. The advantage of the proposed method can promote the correspondence under the topic space between the source domain and the target domain, which can significantly reduce the data distribution gap across two domains. We conduct extensive experiments on two real-world balanced data sets from Amazon product reviews for sentence-level and document-level binary sentiment classification. Experimental results show that our proposed approach significantly outperforms several strong baselines and achieves an accuracy that is competitive with the most well-known methods for sentiment classification adaptation.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2751820697",
    "type": "article"
  },
  {
    "title": "Transfer to Rank for Heterogeneous One-Class Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3243652",
    "publication_date": "2019-01-14",
    "publication_year": 2019,
    "authors": "Weike Pan; Qiang Yang; Wanling Cai; Yaofeng Chen; Qing Zhang; Xiaogang Peng; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "Heterogeneous one-class collaborative filtering is an emerging and important problem in recommender systems, where two different types of one-class feedback, i.e., purchases and browses, are available as input data. The associated challenges include ambiguity of browses, scarcity of purchases, and heterogeneity arising from different feedback. In this article, we propose to model purchases and browses from a new perspective, i.e., users’ roles of mixer, browser and purchaser. Specifically, we design a novel transfer learning solution termed role-based transfer to rank (RoToR), which contains two variants, i.e., integrative RoToR and sequential RoToR. In integrative RoToR, we leverage browses into the preference learning task of purchases, in which we take each user as a sophisticated customer (i.e., mixer ) that is able to take different types of feedback into consideration. In sequential RoToR, we aim to simplify the integrative one by decomposing it into two dependent phases according to a typical shopping process. Furthermore, we instantiate both variants using different preference learning paradigms such as pointwise preference learning and pairwise preference learning. Finally, we conduct extensive empirical studies with various baseline methods on three large public datasets and find that our RoToR can perform significantly more accurate than the state-of-the-art methods.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2908900944",
    "type": "article"
  },
  {
    "title": "A Meta-Framework for Modeling the Human Reading Process in Sentiment Analysis",
    "doi": "https://doi.org/10.1145/2950050",
    "publication_date": "2016-08-11",
    "publication_year": 2016,
    "authors": "Ramy Baly; Roula Hobeica; Hazem Hajj; Wassim El‐Hajj; Khaled Shaban; Ahmad Al-Sallab",
    "corresponding_authors": "",
    "abstract": "This article introduces a sentiment analysis approach that adopts the way humans read, interpret, and extract sentiment from text. Our motivation builds on the assumption that human interpretation should lead to the most accurate assessment of sentiment in text. We call this automated process Human Reading for Sentiment (HRS). Previous research in sentiment analysis has produced many frameworks that can fit one or more of the HRS aspects; however, none of these methods has addressed them all in one approach. HRS provides a meta-framework for developing new sentiment analysis methods or improving existing ones. The proposed framework provides a theoretical lens for zooming in and evaluating aspects of any sentiment analysis method to identify gaps for improvements towards matching the human reading process. Key steps in HRS include the automation of humans low-level and high-level cognitive text processing. This methodology paves the way towards the integration of psychology with computational linguistics and machine learning to employ models of pragmatics and discourse analysis for sentiment analysis. HRS is tested with two state-of-the-art methods; one is based on feature engineering, and the other is based on deep learning. HRS highlighted the gaps in both methods and showed improvements for both.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2515786824",
    "type": "article"
  },
  {
    "title": "Tweet Can Be Fit",
    "doi": "https://doi.org/10.1145/3086676",
    "publication_date": "2017-08-19",
    "publication_year": 2017,
    "authors": "Aleksandr Farseev; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Wellness is a widely popular concept that is commonly applied to fitness and self-help products or services. Inference of personal wellness--related attributes, such as body mass index (BMI) category or disease tendency, as well as understanding of global dependencies between wellness attributes and users’ behavior, is of crucial importance to various applications in personal and public wellness domains. At the same time, the emergence of social media platforms and wearable sensors makes it feasible to perform wellness profiling for users from multiple perspectives. However, research efforts on wellness profiling and integration of social media and sensor data are relatively sparse. This study represents one of the first attempts in this direction. Specifically, we infer personal wellness attributes by utilizing our proposed multisource multitask wellness profile learning framework—WellMTL—which can handle data incompleteness and perform wellness attributes inference from sensor and social media data simultaneously. To gain insights into the data at a global level, we also examine correlations between first-order data representations and personal wellness attributes. Our experimental results show that the integration of sensor data and multiple social media sources can substantially boost the performance of individual wellness profiling.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2750011684",
    "type": "article"
  },
  {
    "title": "Fine-Grained Privacy Detection with Graph-Regularized Hierarchical Attentive Representation Learning",
    "doi": "https://doi.org/10.1145/3406109",
    "publication_date": "2020-09-16",
    "publication_year": 2020,
    "authors": "Xiaolin Chen; Xuemeng Song; Ruiyang Ren; Lei Zhu; Zhiyong Cheng; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "Due to the complex and dynamic environment of social media, user generated contents (UGCs) may inadvertently leak users’ personal aspects, such as the personal attributes, relationships and even the health condition, and thus place users at high privacy risks. Limited research efforts, thus far, have been dedicated to the privacy detection from users’ unstructured data (i.e., UGCs). Moreover, existing efforts mainly focus on applying conventional machine learning techniques directly to traditional hand-crafted privacy-oriented features, ignoring the powerful representing capability of the advanced neural networks. In light of this, in this article, we present a fine-grained privacy detection network (GrHA) equipped with graph-regularized hierarchical attentive representation learning. In particular, the proposed GrHA explores the semantic correlations among personal aspects with graph convolutional networks to enhance the regularization for the UGC representation learning, and, hence, fulfil effective fine-grained privacy detection. Extensive experiments on a real-world dataset demonstrate the superiority of the proposed model over state-of-the-art competitors in terms of eight standard metrics. As a byproduct, we have released the codes and involved parameters to facilitate the research community.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3090325439",
    "type": "article"
  },
  {
    "title": "Hilbert Exclusion",
    "doi": "https://doi.org/10.1145/3001583",
    "publication_date": "2016-12-15",
    "publication_year": 2016,
    "authors": "Richard Connor; Franco Alberto Cardillo; Lucia Vadicamo; Fausto Rabitti",
    "corresponding_authors": "",
    "abstract": "Most research into similarity search in metric spaces relies on the triangle inequality property. This property allows the space to be arranged according to relative distances to avoid searching some subspaces. We show that many common metric spaces, notably including those using Euclidean and Jensen-Shannon distances, also have a stronger property, sometimes called the four-point property: In essence, these spaces allow an isometric embedding of any four points in three-dimensional Euclidean space, as well as any three points in two-dimensional Euclidean space. In fact, we show that any space that is isometrically embeddable in Hilbert space has the stronger property. This property gives stronger geometric guarantees, and one in particular, which we name the Hilbert Exclusion property, allows any indexing mechanism which uses hyperplane partitioning to perform better. One outcome of this observation is that a number of state-of-the-art indexing mechanisms over high-dimensional spaces can be easily refined to give a significant increase in performance; furthermore, the improvement given is greater in higher dimensions. This therefore leads to a significant improvement in the cost of metric search in these spaces.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4297440395",
    "type": "article"
  },
  {
    "title": "Fine-grained Geolocation of Tweets in Temporal Proximity",
    "doi": "https://doi.org/10.1145/3291059",
    "publication_date": "2019-01-11",
    "publication_year": 2019,
    "authors": "Wen-Haw Chong; Ee‐Peng Lim",
    "corresponding_authors": "",
    "abstract": "In fine-grained tweet geolocation, tweets are linked to the specific venues (e.g., restaurants, shops) from which they were posted. This explicitly recovers the venue context that is essential for applications such as location-based advertising or user profiling. For this geolocation task, we focus on geolocating tweets that are contained in tweet sequences. In a tweet sequence, tweets are posted from some latent venue(s) by the same user and within a short time interval. This scenario arises from two observations: (1) It is quite common that users post multiple tweets in a short time and (2) most tweets are not geocoded. To more accurately geolocate a tweet, we propose a model that performs query expansion on the tweet (query) using two novel approaches. The first approach temporal query expansion considers users’ staying behavior around venues. The second approach visitation query expansion leverages on user revisiting the same or similar venues in the past. We combine both query expansion approaches via a novel fusion framework and overlay them on a Hidden Markov Model to account for sequential information. In our comprehensive experiments across multiple datasets and metrics, we show our proposed model to be more robust and accurate than other baselines.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2908939884",
    "type": "article"
  },
  {
    "title": "A Survey on Heterogeneous One-class Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3402521",
    "publication_date": "2020-08-11",
    "publication_year": 2020,
    "authors": "Xiancong Chen; Lin Li; Weike Pan; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "Recommender systems play an important role in providing personalized services for users in the context of information overload. Generally, users’ feedback toward items often contain the most significant information reflecting their preferences, which enables accurate personalized recommendation. In real applications, users’ feedback are usually heterogeneous (rather than homogeneous) such as purchases and examinations in e-commerce, which reflects users’ preferences in different degrees. Effective modeling of such heterogeneous one-class feedback is challenging compared with that of homogeneous feedback of ratings. As a response, heterogeneous one-class collaborative filtering (HOCCF) is proposed, which often converts the heterogeneous feedback into two parts (i.e., target feedback and auxiliary feedback), aiming to care more about the target feedback (e.g., purchases ) with the assistance of the auxiliary feedback (e.g., examinations ). In this survey, we provide an overview of the representative HOCCF methods from the perspective of factorization-based methods, transfer learning-based methods, and deep learning-based methods. First, we review the factorization-based methods according to different strategies. Second, we describe the transfer learning-based methods with different knowledge sharing manners. Third, we discuss the deep learning-based methods according to the neural architectures. Moreover, we include some important example applications, describe the empirical studies, and discuss some promising future directions.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3048405543",
    "type": "article"
  },
  {
    "title": "How the Accuracy and Confidence of Sensitivity Classification Affects Digital Sensitivity Review",
    "doi": "https://doi.org/10.1145/3417334",
    "publication_date": "2020-10-12",
    "publication_year": 2020,
    "authors": "Graham McDonald; Craig Macdonald; Iadh Ounis",
    "corresponding_authors": "",
    "abstract": "Government documents must be manually reviewed to identify any sensitive information, e.g., confidential information, before being publicly archived. However, human-only sensitivity review is not practical for born-digital documents due to, for example, the volume of documents that are to be reviewed. In this work, we conduct a user study to evaluate the effectiveness of sensitivity classification for assisting human sensitivity reviewers. We evaluate how the accuracy and confidence levels of sensitivity classification affects the number of documents that are correctly judged as being sensitive (reviewer accuracy) and the time that it takes to sensitivity review a document (reviewing speed). In our within-subject study, the participants review government documents to identify real sensitivities while being assisted by three sensitivity classification treatments , namely None (no classification predictions), Medium (sensitivity predictions from a simulated classifier with a balanced accuracy (BAC) of 0.7), and Perfect (sensitivity predictions from a classifier with an accuracy of 1.0). Our results show that sensitivity classification leads to significant improvements (ANOVA, p &lt; 0.05) in reviewer accuracy in terms of BAC (+37.9% Medium , +60.0% Perfect ) and also in terms of F 2 (+40.8% Medium , +44.9% Perfect ). Moreover, we show that assisting reviewers with sensitivity classification predictions leads to significantly increased (ANOVA, p &lt; 0.05) mean reviewing speeds (+72.2% Medium , +61.6% Perfect ). We find that reviewers do not agree with the classifier significantly more as the classifier’s confidence increases. However, reviewing speed is significantly increased when the reviewers agree with the classifier (ANOVA, p &lt; 0.05). Our in-depth analysis shows that when the reviewers are not assisted with sensitivity predictions, mean reviewing speeds are 40.5% slower for sensitive judgements compared to not-sensitive judgements. However, when the reviewers are assisted with sensitivity predictions, the difference in reviewing speeds between sensitive and not-sensitive judgements is reduced by ˜10%, from 40.5% to 30.8%. We also find that, for sensitive judgements, sensitivity classification predictions significantly increase mean reviewing speeds by 37.7% when the reviewers agree with the classifier’s predictions ( t -test, p &lt; 0.05). Overall, our findings demonstrate that sensitivity classification is a viable technology for assisting human reviewers with the sensitivity review of digital documents.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3106480498",
    "type": "article"
  },
  {
    "title": "Bilateral Filtering Graph Convolutional Network for Multi-relational Social Recommendation in the Power-law Networks",
    "doi": "https://doi.org/10.1145/3469799",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Minghao Zhao; Qilin Deng; Kai Wang; Runze Wu; Jianrong Tao; Changjie Fan; Liang Chen; Peng Cui",
    "corresponding_authors": "",
    "abstract": "In recent years, advances in Graph Convolutional Networks (GCNs) have given new insights into the development of social recommendation. However, many existing GCN-based social recommendation methods often directly apply GCN to capture user-item and user-user interactions, which probably have two main limitations: (a) Due to the power-law property of the degree distribution, the vanilla GCN with static normalized adjacency matrix has limitations in learning node representations, especially for the long-tail nodes; (b) multi-typed social relationships between users that are ubiquitous in the real world are rarely considered. In this article, we propose a novel Bilateral Filtering Heterogeneous Attention Network (BFHAN), which improves long-tail node representations and leverages multi-typed social relationships between user nodes. First, we propose a novel graph convolutional filter for the user-item bipartite network and extend it to the user-user homogeneous network. Further, we theoretically analyze the correlation between the convergence values of different graph convolutional filters and node degrees after stacking multiple layers. Second, we model multi-relational social interactions between users as the multiplex network and further propose a multiplex attention network to capture distinctive inter-layer influences for user representations. Last but not least, the experimental results demonstrate that our proposed method outperforms several state-of-the-art GCN-based methods for social recommendation tasks.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3203121130",
    "type": "article"
  },
  {
    "title": "On the Study of Transformers for Query Suggestion",
    "doi": "https://doi.org/10.1145/3470562",
    "publication_date": "2021-10-15",
    "publication_year": 2021,
    "authors": "Agnès Mustar; Sylvain Lamprier; Benjamin Piwowarski",
    "corresponding_authors": "",
    "abstract": "When conducting a search task, users may find it difficult to articulate their need, even more so when the task is complex. To help them complete their search, search engine usually provide query suggestions. A good query suggestion system requires to model user behavior during the search session. In this article, we study multiple Transformer architectures applied to the query suggestion task and compare them with recurrent neural network (RNN)-based models. We experiment Transformer models with different tokenizers, with different Encoders (large pretrained models or fully trained ones), and with two kinds of architectures (flat or hierarchic). We study the performance and the behaviors of these various models, and observe that Transformer-based models outperform RNN-based ones. We show that while the hierarchical architectures exhibit very good performances for query suggestion, the flat models are more suitable for complex and long search tasks. Finally, we investigate the flat models behavior and demonstrate that they indeed learn to recover the hierarchy of a search session.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3207707577",
    "type": "article"
  },
  {
    "title": "A Large-scale Analysis of Mixed Initiative in Information-Seeking Dialogues for Conversational Search",
    "doi": "https://doi.org/10.1145/3466796",
    "publication_date": "2021-09-01",
    "publication_year": 2021,
    "authors": "Svitlana Vakulenko; Evangelos Kanoulas; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Conversational search is a relatively young area of research that aims at automating an information-seeking dialogue. In this article, we help to position it with respect to other research areas within conversational artificial intelligence (AI) by analysing the structural properties of an information-seeking dialogue. To this end, we perform a large-scale dialogue analysis of more than 150K transcripts from 16 publicly available dialogue datasets. These datasets were collected to inform different dialogue-based tasks including conversational search. We extract different patterns of mixed initiative from these dialogue transcripts and use them to compare dialogues of different types. Moreover, we contrast the patterns found in information-seeking dialogues that are being used for research purposes with the patterns found in virtual reference interviews that were conducted by professional librarians. The insights we provide (1) establish close relations between conversational search and other conversational AI tasks and (2) uncover limitations of existing conversational datasets to inform future data collection tasks.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3197018105",
    "type": "article"
  },
  {
    "title": "Joint Representation Learning with Relation-Enhanced Topic Models for Intelligent Job Interview Assessment",
    "doi": "https://doi.org/10.1145/3469654",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "D. Z. Shen; Chuan Qin; Hengshu Zhu; Tong Xu; Enhong Chen; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "The job interview is considered as one of the most essential tasks in talent recruitment, which forms a bridge between candidates and employers in fitting the right person for the right job. While substantial efforts have been made on improving the job interview process, it is inevitable to have biased or inconsistent interview assessment due to the subjective nature of the traditional interview process. To this end, in this article, we propose three novel approaches to intelligent job interview by learning the large-scale real-world interview data. Specifically, we first develop a preliminary model, named Joint Learning Model on Interview Assessment (JLMIA), to mine the relationship among job description, candidate resume, and interview assessment. Then, we further design an enhanced model, named Neural-JLMIA, to improve the representative capability by applying neural variance inference. Last, we propose to refine JLMIA with Refined-JLMIA (R-JLMIA) by modeling individual characteristics for each collection, i.e., disentangling the core competences from resume and capturing the evolution of the semantic topics over different interview rounds. As a result, our approaches can effectively learn the representative perspectives of different job interview processes from the successful job interview records in history. In addition, we exploit our approaches for two real-world applications, i.e., person-job fit and skill recommendation for interview assessment. Extensive experiments conducted on real-world data clearly validate the effectiveness of our models, which can lead to substantially less bias in job interviews and provide an interpretable understanding of job interview assessment.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3198193660",
    "type": "article"
  },
  {
    "title": "Unstructured Text Enhanced Open-Domain Dialogue System: A Systematic Survey",
    "doi": "https://doi.org/10.1145/3464377",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Longxuan Ma; Mingda Li; Weinan Zhang; Jiapeng Li; Ting Liu",
    "corresponding_authors": "",
    "abstract": "Incorporating external knowledge into dialogue generation has been proven to benefit the performance of an open-domain Dialogue System (DS), such as generating informative or stylized responses, controlling conversation topics. In this article, we study the open-domain DS that uses unstructured text as external knowledge sources ( U nstructured T ext E nhanced D ialogue S ystem ( UTEDS )). The existence of unstructured text entails distinctions between UTEDS and traditional data-driven DS and we aim at analyzing these differences. We first give the definition of the UTEDS related concepts, then summarize the recently released datasets and models. We categorize UTEDS into Retrieval and Generative models and introduce them from the perspective of model components. The retrieval models consist of Fusion, Matching, and Ranking modules, while the generative models comprise Dialogue and Knowledge Encoding, Knowledge Selection (KS), and Response Generation modules. We further summarize the evaluation methods utilized in UTEDS and analyze the current models’ performance. At last, we discuss the future development trends of UTEDS, hoping to inspire new research in this field.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3198642385",
    "type": "article"
  },
  {
    "title": "An Unsupervised Aspect-Aware Recommendation Model with Explanation Text Generation",
    "doi": "https://doi.org/10.1145/3483611",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Peijie Sun; Le Wu; Kun Zhang; Yu Su; Meng Wang",
    "corresponding_authors": "",
    "abstract": "Review based recommendation utilizes both users’ rating records and the associated reviews for recommendation. Recently, with the rapid demand for explanations of recommendation results, reviews are used to train the encoder–decoder models for explanation text generation. As most of the reviews are general text without detailed evaluation, some researchers leveraged auxiliary information of users or items to enrich the generated explanation text. Nevertheless, the auxiliary data is not available in most scenarios and may suffer from data privacy problems. In this article, we argue that the reviews contain abundant semantic information to express the users’ feelings for various aspects of items, while these information are not fully explored in current explanation text generation task. To this end, we study how to generate more fine-grained explanation text in review based recommendation without any auxiliary data. Though the idea is simple, it is non-trivial since the aspect is hidden and unlabeled. Besides, it is also very challenging to inject aspect information for generating explanation text with noisy review input. To solve these challenges, we first leverage an advanced unsupervised neural aspect extraction model to learn the aspect-aware representation of each review sentence. Thus, users and items can be represented in the aspect space based on their historical associated reviews. After that, we detail how to better predict ratings and generate explanation text with the user and item representations in the aspect space. We further dynamically assign review sentences which contain larger proportion of aspect words with larger weights to control the text generation process, and jointly optimize rating prediction accuracy and explanation text generation quality with a multi-task learning framework. Finally, extensive experimental results on three real-world datasets demonstrate the superiority of our proposed model for both recommendation accuracy and explainability.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W4200626973",
    "type": "article"
  },
  {
    "title": "Users Meet Clarifying Questions: Toward a Better Understanding of User Interactions for Search Clarification",
    "doi": "https://doi.org/10.1145/3524110",
    "publication_date": "2022-04-21",
    "publication_year": 2022,
    "authors": "Jie Zou; Mohammad Aliannejadi; Evangelos Kanoulas; Maria Soledad Pera; Yiqun Liu",
    "corresponding_authors": "",
    "abstract": "The use of clarifying questions (CQs) is a fairly new and useful technique to aid systems in recognizing the intent, context, and preferences behind user queries. Yet, understanding the extent of the effect of CQs on user behavior and the ability to identify relevant information remains relatively unexplored. In this work, we conduct a large user study to understand the interaction of users with CQs in various quality categories, and the effect of CQ quality on user search performance in terms of finding relevant information, search behavior, and user satisfaction. Analysis of implicit interaction data and explicit user feedback demonstrates that high-quality CQs improve user performance and satisfaction. By contrast, low- and mid-quality CQs are harmful, and thus allowing the users to complete their tasks without CQ support may be preferred in this case. We also observe that user engagement, and therefore the need for CQ support, is affected by several factors, such as search result quality or perceived task difficulty. The findings of this study can help researchers and system designers realize why, when, and how users interact with CQs, leading to a better understanding and design of search clarification systems.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4224219410",
    "type": "article"
  },
  {
    "title": "Achieving Human Parity on Visual Question Answering",
    "doi": "https://doi.org/10.1145/3572833",
    "publication_date": "2022-12-20",
    "publication_year": 2022,
    "authors": "Ming Yan; Haiyang Xu; Chenliang Li; Junfeng Tian; Bin Bi; Wei Wang; Xianzhe Xu; Ji Zhang; Songfang Huang; Fei Huang; Luo Si; Rong Jin",
    "corresponding_authors": "",
    "abstract": "The Visual Question Answering (VQA) task utilizes both visual image and language analysis to answer a textual question with respect to an image. It has been a popular research topic with an increasing number of real-world applications in the last decade. This paper introduces a novel hierarchical integration of vision and language AliceMind-MMU (ALIbaba’s Collection of Encoder-decoders from Machine IntelligeNce lab of Damo academy - MultiMedia Understanding) , which leads to similar or even slightly better results than a human being does on VQA. A hierarchical framework is designed to tackle the practical problems of VQA in a cascade manner including: (1) diverse visual semantics learning for comprehensive image content understanding; (2) enhanced multi-modal pre-training with modality adaptive attention; and (3) a knowledge-guided model integration with three specialized expert modules for the complex VQA task. Treating different types of visual questions with corresponding expertise needed plays an important role in boosting the performance of our VQA architecture up to the human level. An extensive set of experiments and analysis are conducted to demonstrate the effectiveness of the new research work.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4312080192",
    "type": "article"
  },
  {
    "title": "Hierarchical Sliding Inference Generator for Question-driven Abstractive Answer Summarization",
    "doi": "https://doi.org/10.1145/3511891",
    "publication_date": "2022-02-14",
    "publication_year": 2022,
    "authors": "Bing Li; Peng Yang; Hanlin Zhao; Penghui Zhang; Zijian Liu",
    "corresponding_authors": "",
    "abstract": "Text summarization on non-factoid question answering (NQA) aims at identifying the core information of redundant answer guidance using questions, which can dramatically improve answer readability and comprehensibility. Most existing approaches focus on extracting query-related sentences to construct a summary, where the logical connection of natural language and the hierarchical interpretable semantic association are often neglected, thus degrading performance. To address these issues, we propose a novel question-driven abstractive answer summarization model, called the H ierarchical S liding I nference G enerator (HSIG), to form inferable and interpretable summaries by explicitly introducing hierarchical information reasoning between questions and corresponding answers. Specifically, we first apply an elaborately designed hierarchical sliding fusion inference model to determine the most relevant question sentence-level representation that provides a deeper interpretable basis for sentence selection in summarization, which further increases computational performance on the premise of following the semantic inheritance structure. Additionally, to improve summary fluency, we construct a double-driven selective generator to integrate various semantic information from two mutual question-and-answer perspectives. Experimental results illustrate that compared with state-of-the-art baselines, our model achieves remarkable improvement on two benchmark datasets and specifically improves the 2.46 ROUGE-1 points on PubMedQA, which demonstrates the superiority of our model on abstractive summarization with hierarchical sequential reasoning.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4213088336",
    "type": "article"
  },
  {
    "title": "Reinforcement Routing on Proximity Graph for Efficient Recommendation",
    "doi": "https://doi.org/10.1145/3512767",
    "publication_date": "2022-02-14",
    "publication_year": 2022,
    "authors": "Chao Feng; Defu Lian; Wang Xiting; Zheng Liu; Xing Xie; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "We focus on Maximum Inner Product Search (MIPS), which is an essential problem in many machine learning communities. Given a query, MIPS finds the most similar items with the maximum inner products. Methods for Nearest Neighbor Search (NNS) which is usually defined on metric space do not exhibit the satisfactory performance for MIPS problem since inner product is a non-metric function. However, inner products exhibit many good properties compared with metric functions, such as avoiding vanishing and exploding gradients. As a result, inner product is widely used in many recommendation systems, which makes efficient Maximum Inner Product Search a key for speeding up many recommendation systems. Graph-based methods for NNS problem show the superiorities compared with other class methods. Each data point of the database is mapped to a node of the proximity graph. Nearest neighbor search in the database can be converted to route on the proximity graph to find the nearest neighbor for the query. This technique can be used to solve MIPS problem. Instead of searching the nearest neighbor for the query, we search the item with a maximum inner product with query on the proximity graph. In this article, we propose a reinforcement model to train an agent to search on the proximity graph automatically for MIPS problem if we lack the ground truths of training queries. If we know the ground truths of some training queries, our model can also utilize these ground truths by imitation learning to improve the agent’s searchability. By experiments, we can see that our proposed mode which combines reinforcement learning with imitation learning shows the superiorities over the state-of-the-art methods.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4213334228",
    "type": "article"
  },
  {
    "title": "Learning to Ask: Conversational Product Search via Representation Learning",
    "doi": "https://doi.org/10.1145/3555371",
    "publication_date": "2022-08-09",
    "publication_year": 2022,
    "authors": "Jie Zou; Jimmy Xiangji Huang; Zhaochun Ren; Evangelos Kanoulas",
    "corresponding_authors": "",
    "abstract": "Online shopping platforms, such as Amazon and AliExpress, are increasingly prevalent in society, helping customers purchase products conveniently. With recent progress in natural language processing, researchers and practitioners shift their focus from traditional product search to conversational product search. Conversational product search enables user-machine conversations and through them collects explicit user feedback that allows to actively clarify the users' product preferences. Therefore, prospective research on an intelligent shopping assistant via conversations is indispensable. Existing publications on conversational product search either model conversations independently from users, queries, and products or lead to a vocabulary mismatch. In this work, we propose a new conversational product search model, ConvPS, to assist users in locating desirable items. The model is first trained to jointly learn the semantic representations of user, query, item, and conversation via a unified generative framework. After learning these representations, they are integrated to retrieve the target items in the latent semantic space. Meanwhile, we propose a set of greedy and explore-exploit strategies to learn to ask the user a sequence of high-performance questions for conversations. Our proposed ConvPS model can naturally integrate the representation learning of the user, query, item, and conversation into a unified generative framework, which provides a promising avenue for constructing accurate and robust conversational product search systems that are flexible and adaptive. Experimental results demonstrate that our ConvPS model significantly outperforms state-of-the-art baselines.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4297816431",
    "type": "article"
  },
  {
    "title": "Toward Best Practices for Training Multilingual Dense Retrieval Models",
    "doi": "https://doi.org/10.1145/3613447",
    "publication_date": "2023-08-12",
    "publication_year": 2023,
    "authors": "Xinyu Zhang; Kelechi Ogueji; Xueguang Ma; Jimmy Lin",
    "corresponding_authors": "",
    "abstract": "Dense retrieval models using a transformer-based bi-encoder architecture have emerged as an active area of research. In this article, we focus on the task of monolingual retrieval in a variety of typologically diverse languages using such an architecture. Although recent work with multilingual transformers demonstrates that they exhibit strong cross-lingual generalization capabilities, there remain many open research questions, which we tackle here. Our study is organized as a “best practices” guide for training multilingual dense retrieval models, broken down into three main scenarios: when a multilingual transformer is available, but training data in the form of relevance judgments are not available in the language and domain of interest (“have model, no data”); when both models and training data are available (“have model and data”); and when training data are available but not models (“have data, no model”). In considering these scenarios, we gain a better understanding of the role of multi-stage fine-tuning, the strength of cross-lingual transfer under various conditions, the usefulness of out-of-language data, and the advantages of multilingual vs. monolingual transformers. Our recommendations offer a guide for practitioners building search applications, particularly for low-resource languages, and while our work leaves open a number of research questions, we provide a solid foundation for future work.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4385780698",
    "type": "article"
  },
  {
    "title": "Multi-aspect Graph Contrastive Learning for Review-enhanced Recommendation",
    "doi": "https://doi.org/10.1145/3618106",
    "publication_date": "2023-09-05",
    "publication_year": 2023,
    "authors": "Ke Wang; Yanmin Zhu; Tianzi Zang; Chunyang Wang; Kuan Liu; Peibo Ma",
    "corresponding_authors": "",
    "abstract": "Review-based recommender systems explore semantic aspects of users’ preferences by incorporating user-generated reviews into rating-based models. Recent works have demonstrated the potential of review information to improve the recommendation capacity. However, most existing studies rely on optimizing review-based representation learning part, thus failing to explicitly capture the fine-grained semantic aspects, and also ignoring the intrinsic correlation between ratings and reviews. To address these problems, we propose a multi-aspect graph contrastive learning framework, named MAGCL, with three distinctive designs: (i) a multi-aspect representation learning module, which projects semantic relations to different subspaces by decoupling review information, and then obtains high-order decoupled representations in each aspect via graph encoder. (ii) the contrastive learning module performs graph contrastive learning to capture the correlation between rating and review patterns, which utilize unlabeled data to generate self-supervised signals and, in turn, relieve the data sparsity problem of supervision signals. (iii) the multi-task learning module conducts joint training to learn high-order structure-aware yet self-discriminative node representations by combining recommendation task and self-supervised task, which helps alleviate the over-smoothing problem. Extensive experiments are conducted on four real-world review datasets and the results show the superiority of the proposed framework MAGCL compared with several state of the arts. We also provide further analysis on multi-aspect representations and graph contrastive learning to verify the advantage of proposed framework.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4386443007",
    "type": "article"
  },
  {
    "title": "An Intent Taxonomy of Legal Case Retrieval",
    "doi": "https://doi.org/10.1145/3626093",
    "publication_date": "2023-09-29",
    "publication_year": 2023,
    "authors": "Yunqiu Shao; Haitao Li; Yueyue Wu; Yiqun Liu; Qingyao Ai; Jiaxin Mao; Yixiao Ma; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Legal case retrieval is a special Information Retrieval (IR) task focusing on legal case documents. Depending on the downstream tasks of the retrieved case documents, users’ information needs in legal case retrieval could be significantly different from those in Web search and traditional ad hoc retrieval tasks. While there are several studies that retrieve legal cases based on text similarity, the underlying search intents of legal retrieval users, as shown in this article, are more complicated than that yet mostly unexplored. To this end, we present a novel hierarchical intent taxonomy of legal case retrieval. It consists of five intent types categorized by three criteria, i.e., search for Particular Case(s) , Characterization , Penalty , Procedure , and Interest . The taxonomy was constructed transparently and evaluated extensively through interviews, editorial user studies, and query log analysis. Through a laboratory user study, we reveal significant differences in user behavior and satisfaction under different search intents in legal case retrieval. Furthermore, we apply the proposed taxonomy to various downstream legal retrieval tasks, e.g., result ranking and satisfaction prediction, and demonstrate its effectiveness. Our work provides important insights into the understanding of user intents in legal case retrieval and potentially leads to better retrieval techniques in the legal domain, such as intent-aware ranking strategies and evaluation methodologies.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4387168261",
    "type": "article"
  },
  {
    "title": "Understanding Feeling-of-Knowing in Information Search: An EEG Study",
    "doi": "https://doi.org/10.1145/3611384",
    "publication_date": "2023-10-30",
    "publication_year": 2023,
    "authors": "Dominika Michalkova; Mario A. Parra; Yashar Moshfeghi",
    "corresponding_authors": "",
    "abstract": "The realisation and the variability of information needs (IN) with respect to a searcher’s gap in knowledge is driven by the perceived Anomalous State of Knowledge (ASK). The concept of Feeling-of-Knowing (FOK), as the introspective feeling of knowledge awareness, shares the characteristics of an ASK state. From an IR perspective, FOK as a premise to trigger IN is unexplored. Motivated by the neuroimaging studies in IR, we investigate the neurophysiological drivers associated with FOK, to provide evidence validating FOK as a distinctive state in IN realisation. We employ Electroencephalography to capture the brain activity of 24 healthy participants performing a textual Question Answering IR scenario. We analyse the evoked neural patterns corresponding to three states of knowledge: i.e., (1)“I know”, (2)“FOK”, (3)“I do not know”. Our findings show the distinct neurophysiological signatures (N1, P2, N400, P6) in response to information segments processed in the context of our three levels. They further reveal that the brain manifestation associated with “FOK” does not significantly differ from the ones associated with “I do not know”, indicating their association with recognition of a gap in knowledge and as such could further inform the IN formation on different levels of knowing.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4388110087",
    "type": "article"
  },
  {
    "title": "Incorporating Structural Information into Legal Case Retrieval",
    "doi": "https://doi.org/10.1145/3609796",
    "publication_date": "2023-07-19",
    "publication_year": 2023,
    "authors": "Yixiao Ma; Yueyue Wu; Qingyao Ai; Yiqun Liu; Yunqiu Shao; Min Zhang; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Legal case retrieval has received increasing attention in recent years. However, compared to ad hoc retrieval tasks, legal case retrieval has its unique challenges. First, case documents are rather lengthy and contain complex legal structures. Therefore, it is difficult for most existing dense retrieval models to encode an entire document and capture its inherent complex structure information. Most existing methods simply truncate part of the document content to meet the input length limit of PLMs, which will lead to information loss. Additionally, the definition of relevance in the legal domain differs from that in the general domain. Previous semantic-based or lexical-based methods fail to provide a comprehensive understanding of the relevance of legal cases. In this article, we propose a Structured Legal case Retrieval (SLR) framework, which incorporates internal and external structural information to address the above two challenges. Specifically, to avoid the truncation of long legal documents, the internal structural information, which is the organization pattern of legal documents, can be utilized to split a case document into segments. By dividing the document-level semantic matching task into segment-level subtasks, SLR can separately process segments using different methods based on the characteristic of each segment. In this way, the key elements of a case document can be highlighted without losing other content information. Second, toward a better understanding of relevance in the legal domain, we investigate the connections between criminal charges appearing in large-scale case corpus to generate a chargewise relation graph. Then, the similarity between criminal charges can be pre-computed as the external structural information to enhance the recognition of relevant cases. Finally, a learning-to-rank algorithm integrates the features collected from internal and external structures to output the final retrieval results. Experimental results on public legal case retrieval benchmarks demonstrate the superior effectiveness of SLR over existing state-of-the-art baselines, including traditional bag-of-words and neural-based methods. Furthermore, we conduct a case study to visualize how the proposed model focuses on key elements and improves retrieval performance.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4384822682",
    "type": "article"
  },
  {
    "title": "H3GNN: Hybrid Hierarchical HyperGraph Neural Network for Personalized Session-based Recommendation",
    "doi": "https://doi.org/10.1145/3630002",
    "publication_date": "2023-10-23",
    "publication_year": 2023,
    "authors": "Zhizhuo Yin; Kai Han; Pengzi Wang; Xi Zhu",
    "corresponding_authors": "",
    "abstract": "Personalized Session-based recommendation (PSBR) is a general and challenging task in the real world, aiming to recommend a session’s next clicked item based on the session’s item transition information and the corresponding user’s historical sessions. A session is defined as a sequence of interacted items during a short period. The PSBR problem has a natural hierarchical architecture in which each session consists of a series of items, and each user owns a series of sessions. However, the existing PSBR methods can merely capture the pairwise relation information within items and users. To effectively capture the hierarchical information, we propose a novel hierarchical hypergraph neural network to model the hierarchical architecture. Moreover, considering that the items in sessions are sequentially ordered, while the hypergraph can only model the set relation, we propose a directed graph aggregator (DGA) to aggregate the sequential information from the directed global item graph. By attentively combining the embeddings of the above two modules, we propose a framework dubbed H3GNN (Hybrid Hierarchical HyperGraph Neural Network). Extensive experiments on three benchmark datasets demonstrate the superiority of our proposed model compared to the state-of-the-art methods, and ablation experiment results validate the effectiveness of all the proposed components.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4387868983",
    "type": "article"
  },
  {
    "title": "Transferring Causal Mechanism over Meta-representations for Target-Unknown Cross-domain Recommendation",
    "doi": "https://doi.org/10.1145/3643807",
    "publication_date": "2024-02-01",
    "publication_year": 2024,
    "authors": "Shengyu Zhang; Qiaowei Miao; Ping Nie; Mengze Li; Zhengyu Chen; Fuli Feng; Kun Kuang; Fei Wu",
    "corresponding_authors": "",
    "abstract": "Tackling the pervasive issue of data sparsity in recommender systems, we present an insightful investigation into the burgeoning area of non-overlapping cross-domain recommendation, a technique that facilitates the transfer of interaction knowledge across domains without necessitating inter-domain user/item correspondence. Existing approaches have predominantly depended on auxiliary information, such as user reviews and item tags, to establish inter-domain connectivity, but these resources may become inaccessible due to privacy and commercial constraints. To address these limitations, our study introduces an in-depth exploration of Target-unknown Cross-domain Recommendation (CDR), which contends with the distinct challenge of lacking target domain information during the training phase in the source domain. We illustrate two critical obstacles inherent to Target-unknown CDR: the lack of an inter-domain bridge due to insufficient user/item correspondence or side information and the potential pitfalls of source-domain training biases when confronting distribution shifts across domains. To surmount these obstacles, we propose the CMCDR framework, a novel approach that leverages causal mechanisms extracted from meta-user/item representations. The CMCDR framework employs a vector-quantized encoder–decoder architecture, enabling the disentanglement of user/item characteristics. We posit that domain-transferable knowledge is more readily discernible from user/item characteristics, i.e., the meta-representations, rather than raw users and items. Capitalizing on these meta-representations, our CMCDR framework adeptly incorporates an attention-driven predictor that approximates the front-door adjustment method grounded in causal theory. This cutting-edge strategy effectively mitigates source-domain training biases and enhances generalization capabilities against distribution shifts. Extensive experiments demonstrate the empirical effectiveness and the rationality of CMCDR for target-unknown cross-domain recommendation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4391448991",
    "type": "article"
  },
  {
    "title": "Improving Semi-Supervised Text Classification with Dual Meta-Learning",
    "doi": "https://doi.org/10.1145/3648612",
    "publication_date": "2024-02-20",
    "publication_year": 2024,
    "authors": "Shujie Li; Guanghu Yuan; Min Yang; Ying Shen; Chengming Li; Ruifeng Xu; Xiaoyan Zhao",
    "corresponding_authors": "",
    "abstract": "The goal of semi-supervised text classification (SSTC) is to train a model by exploring both a small number of labeled data and a large number of unlabeled data, such that the learned semi-supervised classifier performs better than the supervised classifier trained on solely the labeled samples. Pseudo-labeling is one of the most widely used SSTC techniques, which trains a teacher classifier with a small number of labeled examples to predict pseudo labels for the unlabeled data. The generated pseudo-labeled examples are then utilized to train a student classifier, such that the learned student classifier can outperform the teacher classifier. Nevertheless, the predicted pseudo labels may be inaccurate, making the performance of the student classifier degraded. The student classifier may perform even worse than the teacher classifier. To alleviate this issue, in this paper, we introduce a dual meta-learning ( DML ) technique for semi-supervised text classification, which improves the teacher and student classifiers simultaneously in an iterative manner. Specifically, we propose a meta-noise correction method to improve the student classifier by proposing a Noise Transition Matrix (NTM) with meta-learning to rectify the noisy pseudo labels. In addition, we devise a meta pseudo supervision method to improve the teacher classifier. Concretely, we exploit the feedback performance from the student classifier to further guide the teacher classifier to produce more accurate pseudo labels for the unlabeled data. In this way, both teacher and student classifiers can co-evolve in the iterative training process. Extensive experiments on four benchmark datasets highlight the effectiveness of our DML method against existing state-of-the-art methods for semi-supervised text classification. We release our code and data of this paper publicly at https://github.com/GRIT621/DML.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4391970302",
    "type": "article"
  },
  {
    "title": "Towards Unified Representation Learning for Career Mobility Analysis with Trajectory Hypergraph",
    "doi": "https://doi.org/10.1145/3651158",
    "publication_date": "2024-03-06",
    "publication_year": 2024,
    "authors": "Rui Zha; Ying Sun; Chuan Qin; Le Zhang; Tong Xu; Hengshu Zhu; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "Career mobility analysis aims at understanding the occupational movement patterns of talents across distinct labor market entities, which enables a wide range of talent-centered applications, such as job recommendation, labor demand forecasting, and company competitive analysis. Existing studies in this field mainly focus on a single fixed scale, investigating either individual trajectories at the micro-level or crowd flows among market entities at the macro-level. Consequently, the intrinsic cross-scale interactions between talents and the labor market are largely overlooked. To bridge this gap, we propose UniTRep , a novel unified representation learning framework for cross-scale career mobility analysis. Specifically, we first introduce a trajectory hypergraph structure to organize the career mobility patterns in a low-information-loss manner, where market entities and talent trajectories are represented as nodes and hyperedges, respectively. Then, for learning the market-aware talent representations , we attentively propagate the node information to the hyperedges and incorporate the market contextual features into the process of individual trajectory modeling. For learning the trajectory-enhanced market representations , we aggregate the message from hyperedges associated with a specific node to integrate the fine-grained semantics of trajectories into labor market modeling. Moreover, we design two auxiliary tasks to optimize both intra-scale and cross-scale learning with a self-supervised strategy. Extensive experiments on a real-world dataset clearly validate that UniTRep can significantly outperform state-of-the-art baselines for various tasks.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4392518487",
    "type": "article"
  },
  {
    "title": "Toward Bias-Agnostic Recommender Systems: A Universal Generative Framework",
    "doi": "https://doi.org/10.1145/3655617",
    "publication_date": "2024-04-02",
    "publication_year": 2024,
    "authors": "Zhidan Wang; Lixin Zou; Chenliang Li; Shuaiqiang Wang; Xu Chen; Dawei Yin; Weidong Liu",
    "corresponding_authors": "",
    "abstract": "User behavior data, such as ratings and clicks, has been widely used to build personalizing models for recommender systems. However, many unflattering factors (e.g., popularity, ranking position, users’ selection) significantly affect the performance of the learned recommendation model. Most existing work on unbiased recommendation addressed these biases from sample granularity (e.g., sample reweighting, data augmentation) or from the perspective of representation learning (e.g., bias-modeling). However, these methods are usually designed for a specific bias, lacking the universal capability to handle complex situations where multiple biases co-exist. Besides, rare work frees itself from laborious and sophisticated debiasing configurations (e.g., propensity scores, imputed values, or user behavior-generating process). Towards this research gap, in this article, we propose a universal G enerative framework for B ias D isentanglement termed as GBD , constantly generating calibration perturbations for the intermediate representations during training to keep them from being affected by the bias. Specifically, a bias-identifier that tries to retrieve the bias-related information from the representations is first introduced. Subsequently, the calibration perturbations are generated to significantly deteriorate the bias-identifier’s performance, making the bias gradually disentangled from the calibrated representations. Therefore, without relying on notorious debiasing configurations, a bias-agnostic model is obtained under the guidance of the bias identifier. We further present its universality by subsuming the representative biases and their mixture under the proposed framework. Finally, extensive experiments on the real-world, synthetic, and semi-synthetic datasets have demonstrated the superiority of the proposed approach against a wide range of recommendation debiasing methods. The code is available at https://github.com/Zhidan-Wang/GBD .",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4393423726",
    "type": "article"
  },
  {
    "title": "Personality-affected Emotion Generation in Dialog Systems",
    "doi": "https://doi.org/10.1145/3655616",
    "publication_date": "2024-05-13",
    "publication_year": 2024,
    "authors": "Zhiyuan Wen; Jiannong Cao; Jiaxing Shen; Ruosong Yang; Shuaiqi Liu; Maosong Sun",
    "corresponding_authors": "",
    "abstract": "Generating appropriate emotions for responses is essential for dialogue systems to provide human-like interaction in various application scenarios. Most previous dialogue systems tried to achieve this goal by learning empathetic manners from anonymous conversational data. However, emotional responses generated by those methods may be inconsistent, which will decrease user engagement and service quality. Psychological findings suggest that the emotional expressions of humans are rooted in personality traits. Therefore, we propose a new task, Personality-affected Emotion Generation, to generate emotion based on the personality given to the dialogue system and further investigate a solution through the personality-affected mood transition. Specifically, we first construct a daily dialogue dataset, Personality EmotionLines Dataset ( PELD ), with emotion and personality annotations. Subsequently, we analyze the challenges in this task, i.e., (1) heterogeneously integrating personality and emotional factors and (2) extracting multi-granularity emotional information in the dialogue context. Finally, we propose to model the personality as the transition weight by simulating the mood transition process in the dialogue system and solve the challenges above. We conduct extensive experiments on PELD for evaluation. Results suggest that by adopting our method, the emotion generation performance is improved by 13% in macro-F1 and 5% in weighted-F1 from the BERT-base model.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4393871775",
    "type": "article"
  },
  {
    "title": "Soft Contrastive Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3665325",
    "publication_date": "2024-08-19",
    "publication_year": 2024,
    "authors": "Yabin Zhang; Zhenlei Wang; Wenhui Yu; Lantao Hu; Peng Jiang; Kun Gai; Xu Chen",
    "corresponding_authors": "",
    "abstract": "Contrastive learning has recently emerged as an effective strategy for improving the performance of sequential recommendation. However, traditional models commonly construct the contrastive loss by directly optimizing human-designed positive and negative samples, resulting in a model that is overly sensitive to heuristic rules. To address this limitation, we propose a novel soft contrastive framework for sequential recommendation in this article. Our main idea is to extend the point-wise contrast to a region-level comparison, where we aim to identify instances near the initially selected positive/negative samples that exhibit similar contrastive properties. This extension improves the model’s robustness to human heuristics. To achieve this objective, we introduce an adversarial contrastive loss that allows us to explore the sample regions more effectively. Specifically, we begin by considering the user behavior sequence as a holistic entity. We construct adversarial samples by introducing a continuous perturbation vector to the sequence representation. This perturbation vector adds variability to the sequence, enabling more flexible exploration of the sample regions. Moreover, we extend the aforementioned strategy by applying perturbations directly to the items within the sequence. This accounts for the sequential nature of the items. To capture these sequential relationships, we utilize a recurrent neural network to associate the perturbations, which introduces an inductive bias for more efficient exploration of adversarial samples. To demonstrate the effectiveness of our model, we conduct extensive experiments on five real-world datasets.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4396952136",
    "type": "article"
  },
  {
    "title": "Bridging Dense and Sparse Maximum Inner Product Search",
    "doi": "https://doi.org/10.1145/3665324",
    "publication_date": "2024-08-19",
    "publication_year": 2024,
    "authors": "Sebastian Bruch; Franco Maria Nardini; Amir Ingber; Edo Liberty",
    "corresponding_authors": "",
    "abstract": "Maximum inner product search (MIPS) over dense and sparse vectors have progressed independently in a bifurcated literature for decades; the latter is better known as top- \\(k\\) retrieval in Information Retrieval. This duality exists because sparse and dense vectors serve different end goals. That is despite the fact that they are manifestations of the same mathematical problem. In this work, we ask if algorithms for dense vectors could be applied effectively to sparse vectors, particularly those that violate the assumptions underlying top- \\(k\\) retrieval methods. We study clustering-based approximate MIPS where vectors are partitioned into clusters and only a fraction of clusters are searched during retrieval. We conduct a comprehensive analysis of dimensionality reduction for sparse vectors, and examine standard and spherical k -means for partitioning. Our experiments demonstrate that clustering-based retrieval serves as an efficient solution for sparse MIPS. As byproducts, we identify two research opportunities and explore their potential. First, we cast the clustering-based paradigm as dynamic pruning and turn that insight into a novel organization of the inverted index for approximate MIPS over general sparse vectors. Second, we offer a unified regime for MIPS over vectors that have dense and sparse subspaces, that is robust to query distributions.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4397004836",
    "type": "article"
  },
  {
    "title": "ROGER: Ranking-oriented Generative Retrieval",
    "doi": "https://doi.org/10.1145/3603167",
    "publication_date": "2024-06-03",
    "publication_year": 2024,
    "authors": "Yujia Zhou; Jing Yao; Zhicheng Dou; Y. L. Tu; Ledell Wu; Tat‐Seng Chua; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "In recent years, various dense retrieval methods have been developed to improve the performance of search engines with a vectorized index. However, these approaches require a large pre-computed index and have limited capacity to memorize all semantics in a document within a single vector. To address these issues, researchers have explored end-to-end generative retrieval models that use a seq-to-seq generative model to directly return identifiers of relevant documents. Although these models have been effective, they are often trained with the maximum likelihood estimation method. It only encourages the model to assign a high probability to the relevant document identifier, ignoring the relevance comparisons of other documents. This may lead to performance degradation in ranking tasks, where the core is to compare the relevance between documents. To address this issue, we propose a ranking-oriented generative retrieval model that incorporates relevance signals in order to better estimate the relative relevance of different documents in ranking tasks. Based upon the analysis of the optimization objectives of dense retrieval and generative retrieval, we propose utilizing dense retrieval to provide relevance feedback for generative retrieval. Under an alternate training framework, the generative retrieval model gradually acquires higher-quality ranking signals to optimize the model. Experimental results show that our approach increasing Recall@1 by 12.9% with respect to the baselines on MS MARCO dataset.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4399301659",
    "type": "article"
  },
  {
    "title": "<scp>TriMLP</scp> : A Foundational MLP-like Architecture for Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3670995",
    "publication_date": "2024-06-10",
    "publication_year": 2024,
    "authors": "Yiheng Jiang; Yuanbo Xu; Yongjian Yang; Funing Yang; Pengyang Wang; Chaozhuo Li; Fuzhen Zhuang; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "In this work, we present TriMLP as a foundational MLP-like architecture for the sequential recommendation, simultaneously achieving computational efficiency and promising performance. First, we empirically study the incompatibility between existing purely MLP-based models and sequential recommendation, that the inherent fully-connective structure endows historical user–item interactions (referred as tokens) with unrestricted communications and overlooks the essential chronological order in sequences. Then, we propose the MLP-based Triangular Mixer to establish ordered contact among tokens and excavate the primary sequential modeling capability under the standard auto-regressive training fashion. It contains (1) a global mixing layer that drops the lower-triangle neurons in MLP to block the anti-chronological connections from future tokens and (2) a local mixing layer that further disables specific upper-triangle neurons to split the sequence as multiple independent sessions. The mixer serially alternates these two layers to support fine-grained preferences modeling, where the global one focuses on the long-range dependency in the whole sequence, and the local one calls for the short-term patterns in sessions. Experimental results on 12 datasets of different scales from 4 benchmarks elucidate that TriMLP consistently attains favorable accuracy/efficiency tradeoff over all validated datasets, where the average performance boost against several state-of-the-art baselines achieves up to 14.88%, and the maximum reduction of inference time reaches 23.73%. The intriguing properties render TriMLP a strong contender to the well-established RNN-, CNN-, and Transformer-based sequential recommenders. Code is available at https://github.com/jiangyiheng1/TriMLP .",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4399497229",
    "type": "article"
  },
  {
    "title": "Automated Disentangled Sequential Recommendation with Large Language Models",
    "doi": "https://doi.org/10.1145/3675164",
    "publication_date": "2024-06-29",
    "publication_year": 2024,
    "authors": "Xin Wang; Hong Chen; Zirui Pan; Yuwei Zhou; Chaoyu Guan; Lifeng Sun; Wenwu Zhu",
    "corresponding_authors": "",
    "abstract": "Sequential recommendation aims to recommend the next items that a target user may have interest in based on the user’s sequence of past behaviors, which has become a hot research topic in both academia and industry. In the literature, sequential recommendation adopts a Sequence-to-Item or Sequence-to-Sequence training strategy, which supervises a sequential model with a user’s next one or more behaviors as the labels and the sequence of the past behaviors as the input. However, existing powerful sequential recommendation approaches employ more and more complex deep structures such as Transformer in order to accurately capture the sequential patterns, which heavily rely on hand-crafted designs on key attention mechanism to achieve state-of-the-art performance, thus failing to automatically obtain the optimal design of attention representation architectures in various scenarios with different data. Other works on classic automated deep recommender systems only focus on traditional settings, ignoring the problem of sequential scenarios. In this paper, we study the problem of automated sequential recommendation, which faces two main challenges: i) How can we design a proper search space tailored for attention automation in sequential recommendation, and ii) How can we accurately search effective attention representation architectures considering multiple user interests reflected in the sequential behavior. To tackle these challenges, we propose an automated disentangled sequential recommendation (AutoDisenSeq) model. In particular, we employ neural architecture search (NAS) and design a search space tailored for automated attention representation in attentive intention-disentangled sequential recommendation with an expressive and efficient space complexity of \\(O(n^{2})\\) given \\(n\\) as the number of layers. We further propose a context-aware parameter sharing mechanism taking characteristics of each sub-architecture into account to enable accurate architecture performance estimations and great flexibility for disentanglement of latent intention representation. Moreover, we propose AutoDisenSeq-LLM, which utilizes the textual understanding power of large language model (LLM) as a guidance to refine the candidate list for recommendation from AutoDisenSeq. We conduct extensive experiments to show that our proposed AutoDisenSeq model and AutoDisenSeq-LLM model outperform existing baseline methods on four real-world datasets in both overall recommendation and cold-start recommendation scenarios.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4400148150",
    "type": "article"
  },
  {
    "title": "ReCRec: Reasoning the Causes of Implicit Feedback for Debiased Recommendation",
    "doi": "https://doi.org/10.1145/3672275",
    "publication_date": "2024-07-08",
    "publication_year": 2024,
    "authors": "Siyi Lin; Sheng Zhou; Jiawei Chen; Yan Feng; Qihao Shi; Chun Chen; Ying Li; Can Wang",
    "corresponding_authors": "",
    "abstract": "Implicit feedback (e.g., user clicks) is widely used in building recommender systems (RS). However, the inherent notorious exposure bias significantly affects recommendation performance. Exposure bias refers a phenomenon that implicit feedback is influenced by user exposure and does not precisely reflect user preference. Current methods for addressing exposure bias primarily reduce confidence in unclicked data, employ exposure models, or leverage propensity scores. Regrettably, these approaches often lead to biased estimations or elevated model variance, yielding sub-optimal results. To overcome these limitations, we propose a new method ReCRec that Reasons the C auses behind the implicit feedback for debiased R ec ommendation . ReCRec identifies three scenarios behind unclicked data—i.e., unexposed, dislike, or a combination of both. A reasoning module is employed to infer the category to which each instance pertains. Consequently, the model is capable of extracting reliable positive and negative signals from unclicked data, thereby facilitating more accurate learning of user preferences. We also conduct thorough theoretical analyses to demonstrate the debiased nature and low variance of ReCRec. Extensive experiments on both semi-synthetic and real-world datasets validate its superiority over state-of-the-art methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4400413127",
    "type": "article"
  },
  {
    "title": "CETN: Contrast-enhanced Through Network for Click-Through Rate Prediction",
    "doi": "https://doi.org/10.1145/3688571",
    "publication_date": "2024-08-12",
    "publication_year": 2024,
    "authors": "Honghao Li; Lei Sang; Yi Zhang; Xuyun Zhang; Yiwen Zhang",
    "corresponding_authors": "",
    "abstract": "Click-through rate (CTR) prediction is a crucial task in personalized information retrievals, such as industrial recommender systems, online advertising, and web search. Most existing CTR Prediction models utilize explicit feature interactions to overcome the performance bottleneck of implicit feature interactions. Hence, deep CTR models based on parallel structures (e.g., DCN, FinalMLP, xDeepFM) have been proposed to obtain joint information from different semantic spaces. However, these parallel subcomponents lack effective supervision and communication signals, making it challenging to efficiently capture valuable multi-views feature interaction information in different semantic spaces. To address these issues, we propose a simple yet effective novel CTR model: Contrast-enhanced Through Network (CETN). Drawing inspiration from sociology, CETN leverages the complementary nature of diversity and homogeneity to guide the model in acquiring higher-quality feature interaction information. Specifically, CETN employs product-based feature interactions and the augmentation (perturbation) concept from contrastive learning to segment different semantic spaces, each with distinct activation functions. This improves diversity in the feature interaction information captured by the model. Additionally, we introduce self-supervised signals and through connection within each semantic space to ensure the homogeneity of the captured feature interaction information. The experiments conducted on four real datasets demonstrate that our model consistently outperforms twenty baseline models in terms of AUC and Logloss.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4401510630",
    "type": "article"
  },
  {
    "title": "Denoising Alignment with Large Language Model for Recommendation",
    "doi": "https://doi.org/10.1145/3696662",
    "publication_date": "2024-09-24",
    "publication_year": 2024,
    "authors": "Yingtao Peng; Chen Gao; Yu Zhang; Tangpeng Dan; Xiaoyi Du; Hengliang Luo; Yong Li; Xiaofeng Meng",
    "corresponding_authors": "",
    "abstract": "The mainstream approach of GNN-based recommendation aggregates high-order ID information associated with the node in the user-item graph. The aggregation pattern using ID as signal has two disadvantages: lack of textual semantics and the impact of interaction noise. These disadvantages pose a threat to effectively learn user preferences, especially in capturing intricate user-item semantic relationships. Although large language models (LLMs) allow the integration of rich textual information into recommenders and have had groundbreaking applications in recommender systems, current works need to bridge the gap between different representation spaces. This is because LLMs-based methods align the representations of GNN-based models only by using text embedding of LLM, leading to unsatisfactory results. To address this challenge, we propose a D enoising A lignment framework with L LMs for GNN-based R ecommenders (DALR), which aims to align structural representation with textual representation and mitigate the effects of noise. Specifically, We propose a modeling framework that integrates the representation of graph structure with textual information from LLMs to capture intricate user-item interactions. We also suggest an alignment paradigm to enhance representation performance by aligning semantic signals from LLMs and structural features from GNN models. Additionally, we introduce a contrastive learning scheme to relieve the impact of noise and improve model performance. Extensive experiments on public datasets demonstrate that our model consistently outperforms the state-of-the-art methods. DALR achieves improvements ranging from 2.82% to 12.20% in Recall@5 and from 1.04% to 3.48% in NDCG@5 compared to the strongest baseline model, using the Steam dataset as an example.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4402813390",
    "type": "article"
  },
  {
    "title": "Market-aware Long-term Job Skill Recommendation with Explainable Deep Reinforcement Learning",
    "doi": "https://doi.org/10.1145/3704998",
    "publication_date": "2024-11-21",
    "publication_year": 2024,
    "authors": "Ying Sun; Yang Ji; Hengshu Zhu; Fuzhen Zhuang; Qing He; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "Continuously learning new skills is essential for talents to gain a competitive advantage in the labor market. Despite extensive efforts on relevance- or preference-based skill recommendations, little attention has been given to the practical effects of job skills in the market. To bridge this gap, we propose an explainable personalized skill learning recommendation system that considers the long-term learning benefits and costs. Specifically, we model skill learning utilities based on salary and learning cost associated with job positions and propose a multi-objective deep reinforcement learning framework to model and maximize long-term utilities. Furthermore, we propose a S elf- E xplaining S kill R ecommendation D eep Q-N etwork (SeSRDQN) that captures and prototypes prevalent skill sets in the market into representative exemplars for decision-making. SeSRDQN quantitatively decomposes the talent’s long-term learning utility into contributions from each exemplar, offering a comprehensive and multifactorial explanation across various skill learning options. To tackle the combinatorial complexity of the skill space, we develop an MCTS-based optimization-decoding iterative training procedure for explanation fidelity and human understandability. In this way, talents will receive a tailored roadmap of essential skills, complemented by exemplar-based explanations, to effectively plan their careers. Extensive experiments on a real-world dataset validate the effectiveness and explainability of our approach.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4404585594",
    "type": "article"
  },
  {
    "title": "RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation",
    "doi": "https://doi.org/10.1145/3705728",
    "publication_date": "2024-11-29",
    "publication_year": 2024,
    "authors": "Sichun Luo; Bowei He; Haohan Zhao; Wei Shao; Yanlin Qi; Yinya Huang; Aojun Zhou; Yuxuan Yao; Zongpeng Li; Yuanzhang Xiao; Mingjie Zhan; Linqi Song",
    "corresponding_authors": "",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities and have been extensively deployed across various domains, including recommender systems. Prior research has employed specialized prompts to leverage the in-context learning capabilities of LLMs for recommendation purposes. More recent studies have utilized instruction tuning techniques to align LLMs with human preferences, promising more effective recommendations. However, existing methods suffer from several limitations. The full potential of LLMs is not fully elicited due to low-quality tuning data and the overlooked integration of conventional recommender signals. Furthermore, LLMs may generate inconsistent responses for different ranking tasks in the recommendation, potentially leading to unreliable results. In this paper, we introduce RecRanker, tailored for instruction tuning LLMs to serve as the Ranker for top- k Rec ommendations. Specifically, we introduce importance-aware sampling, clustering-based sampling, and penalty for repetitive sampling for sampling high-quality, representative, and diverse training data. To enhance the prompt, we introduce a position shifting strategy to mitigate position bias and augment the prompt with auxiliary information from conventional recommendation models, thereby enriching the contextual understanding of the LLM. Subsequently, we utilize the sampled data to assemble an instruction-tuning dataset with the augmented prompts comprising three distinct ranking tasks: pointwise, pairwise, and listwise rankings. We further propose a hybrid ranking method to enhance the model performance by ensembling these ranking tasks. Our empirical evaluations demonstrate the effectiveness of our proposed RecRanker in both direct and sequential recommendation scenarios. 1",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4404856308",
    "type": "article"
  },
  {
    "title": "Efficient and Adaptive Recommendation Unlearning: A Guided Filtering Framework to Erase Outdated Preferences",
    "doi": "https://doi.org/10.1145/3706633",
    "publication_date": "2024-12-05",
    "publication_year": 2024,
    "authors": "Yizhou Dang; Yuting Liu; Enneng Yang; Guibing Guo; Linying Jiang; Jianzhe Zhao; Xingwei Wang",
    "corresponding_authors": "",
    "abstract": "Recommendation unlearning is an emerging task to erase the influences of user-specified data from a trained recommendation model. Most existing research follows the paradigm of partitioning the original dataset into multi-fold and then retraining corresponding sub-models while those influences are totally removed. Despite the effectiveness, two key problems remain unexplored: i) Existing work becomes inefficient and computationally expensive to retrain all sub-models, especially when facing large amounts of unlearning data. ii) User preferences are dynamically changing. If users express negative opinions on some interacted items they used to prefer, how can we adaptively erase the outdated preferences behind such transformation from the trained model? Although these unlearning data contain outdated information, there is still a lot of helpful knowledge worth preserving. Existing methods ignore this preservation during unlearning and may remove all the knowledge in the interactions, compromising the final performance. In light of these limitations, we propose a novel unlearning framework called GFEraser, which transforms the unlearning into an efficient guided filtering process to avoid time-consuming retraining and retain beneficial knowledge. Specifically, we develop an intra-user negative sampling strategy to learn the outdated preferences that need to be erased. Under the guidance of differential maximization agreement and attention-based fusion module, the original representations are adaptively filtered and aggregated based on the learned preferences. Besides, we leverage contrastive learning to preserve the invariant user preferences, maintaining the final performance. Finally, we devise a new metric called Ranking Decrease Rate to evaluate the unlearning effect. Experimental results demonstrate that GFEraser can maintain reliable recommendation performance while achieving efficient outdated preferences unlearning, up to 37x acceleration.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4405078138",
    "type": "article"
  },
  {
    "title": "FELLAS: Enhancing Federated Sequential Recommendation with LLM as External Services",
    "doi": "https://doi.org/10.1145/3709138",
    "publication_date": "2024-12-20",
    "publication_year": 2024,
    "authors": "Wei Yuan; Chaoqun Yang; Guanhua Ye; Tong Chen; Quoc Viet Hung Nguyen; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "Sequential recommendation has been widely studied in the recommendation domain since it can capture users’ temporal preferences and provide more accurate and timely recommendations. To address user privacy concerns, the combination of federated learning and sequential recommender systems (FedSeqRec) has gained growing attention. Unfortunately, the performance of FedSeqRec is still unsatisfactory because the models used in FedSeqRec have to be lightweight to accommodate communication bandwidth and clients’ on-device computational resource constraints. Recently, large language models (LLMs) have exhibited strong transferable and generalized language understanding abilities and therefore, in the NLP area, many downstream tasks now utilize LLMs as a service to achieve superior performance without constructing complex models. Inspired by this successful practice, we propose a generic FedSeqRec framework, FELLAS, which aims to enhance FedSeqRec by utilizing LLMs as an external service. Specifically, FELLAS employs an LLM server to provide both item-level and sequence-level representation assistance. The item-level representation service is queried by the central server to enrich the original ID-based item embedding with textual information, while the sequence-level representation service is accessed by each client. However, invoking the sequence-level representation service requires clients to send sequences to the external LLM server. To safeguard privacy, we implement \\(d_{\\mathcal{X}}\\) -privacy satisfied sequence perturbation, which protects clients’ sensitive data with guarantees. Additionally, a contrastive learning-based method is designed to transfer knowledge from the noisy sequence representation to clients’ sequential recommendation models. Furthermore, to empirically validate the privacy protection capability of FELLAS, we propose two interacted item inference attacks, considering the threats posed by the LLM server and the central server acting as curious-but-honest adversaries in cooperation. Extensive experiments conducted on three datasets with two widely used sequential recommendation models demonstrate the effectiveness and privacy-preserving capability of FELLAS.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4405674754",
    "type": "article"
  },
  {
    "title": "Efficient content-based indexing of large image databases",
    "doi": "https://doi.org/10.1145/348751.348762",
    "publication_date": "2000-04-01",
    "publication_year": 2000,
    "authors": "Essam A. El-Kwae; Mansur R. Kabuka",
    "corresponding_authors": "",
    "abstract": "Large image databases have emerged in various applications in recent years. A prime requisite of these databases is the means by which their contents can be indexed and retrieved. A multilevel signature file called the Two Signature Multi-level Signature File ( 2SMLSF ) is introduced as an efficient access structure for large image databases. The 2SMLSF encodes image information into binary signatures and creates a tree structures can be efficiently searched to satisfy a user's query. Two types of signatures are generated. Type I signatures are used at all tree levels except the leaf level and are based only on the domain objects included in the image. Type II signatures, on the other hand, are stored at the leaf level and are based on the included domain objects and their spatial relationships. The 2SMLSF was compared analytically to existing signature file techniques. The 2SMLSF significantly reduces the storage requirements; the index structure can answer more queries; and the 2SMLSF performance significantly improves over current techniques. Both storage reduction and performance improvement increase with the number of objects per image and the number of images in the database. For an example large image database, a storage reduction of 78% may be archieved while the performance improvement may reach 98%.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W1968656998",
    "type": "article"
  },
  {
    "title": "On the design of a learning crawler for topical resource discovery",
    "doi": "https://doi.org/10.1145/502115.502119",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Charų C. Aggarwal; Fatima Al-Garawi; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "In recent years, the World Wide Web has shown enormous growth in size. Vast repositories of information are available on practically every possible topic. In such cases, it is valuable to perform topical resource discovery effectively. Consequently, several new ideas have been proposed in recent years; among them a key technique is focused crawling which is able to crawl particular topical portions of the World Wide Web quickly, without having to explore all web pages. In this paper, we propose the novel concept of intelligent crawling which actually learns characteristics of the linkage structure of the World Wide Web while performing the crawling. Specifically, the intelligent crawler uses the inlinking web page content, candidate URL structure, or other behaviors of the inlinking web pages or siblings in order to estimate the probability that a candidate is useful for a given crawl. This is a much more general framework than the focused crawling technique which is based on a pre-defined understanding of the topical structure of the web. The techniques discussed in this paper are applicable for crawling web pages which satisfy arbitrary user-defined predicates such as topical queries, keyword queries, or any combinations of the above. Unlike focused crawling, it is not necessary to provide representative topical examples, since the crawler can learn its way into the appropriate topic. We refer to this technique as intelligent crawling because of its adaptive nature in adjusting to the web page linkage structure. We discuss how to intelligently select features which are most useful for a given crawl. The learning crawler is capable of reusing the knowledge gained in a given crawl in order to provide more efficient crawling for closely related predicates.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2066309116",
    "type": "article"
  },
  {
    "title": "Probabilistic information retrieval as a combination of abstraction, inductive learning, and probabilistic assumptions",
    "doi": "https://doi.org/10.1145/174608.174612",
    "publication_date": "1994-01-02",
    "publication_year": 1994,
    "authors": "Norbert Fuhr; Ulrich Pfeifer",
    "corresponding_authors": "",
    "abstract": "We show that former approaches in probabilistic information retrieval are based on one or two of the three concepts abstraction, inductive learning , and probabilistic assumptions , and we propose a new approach which combines all three concepts. This approach is illustrated for the case of indexing with a controlled vocabulary. For this purpose, we describe a new probabilistic model first, which is then combined with logistic regression, thus yielding a generalization of the original model. Experimental results for the pure theoretical model as well as for heuristic variants are given. Furthermore, linear and logistic regression are compared.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2060704583",
    "type": "article"
  },
  {
    "title": "A hypermedia version control framework",
    "doi": "https://doi.org/10.1145/279339.279341",
    "publication_date": "1998-04-01",
    "publication_year": 1998,
    "authors": "David L. Hicks; John J. Leggett; Peter J. Nürnberg; John L. Schnase",
    "corresponding_authors": "",
    "abstract": "The areas of application of hypermedia technology, combined with the capabilities that hypermedia provides for manipulating structure, create an environment in which version control is very important. A hypermedia version control framework has been designed to specifically address the version control problem in open hypermedia environments. One of the primary distinctions of the framework is the partitioning of hypermedia version control functionality into intrinsic and application-specific categories. The version control has been used as a model for the design of version control services for a hyperbase management system that provides complete version support for both data and structural entities. In addition to serving as a version control model for open hypermedia environments, the framework offers a clarifying and unifying context in which to examine the issues of version control in hypermedia.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2118942077",
    "type": "article"
  },
  {
    "title": "Text categorization for multiple users based on semantic features from a machine-readable dictionary",
    "doi": "https://doi.org/10.1145/183422.183425",
    "publication_date": "1994-07-01",
    "publication_year": 1994,
    "authors": "Elizabeth D. Liddy; Woojin Paik; Edmund S. Yu",
    "corresponding_authors": "",
    "abstract": "The text categorization module described here provides a front-end filtering function for the larger DR-LINK text retrieval system [Liddy and Myaeing 1993]. The model evaluates a large incoming stream of documents to determine which documents are sufficiently similar to a profile at the broad subject level to warrant more refined representation and matching. To accomplish this task, each substantive word in a text is first categorized using a feature set based on the semantic Subject Field Codes (SFCs) assigned to individual word senses in a machine-readable dictionary. When tested on 50 user profiles and 550 megabytes of documents, results indicate that the feature set that is the basis of the text categorization module and the algorithm that establishes the boundary of categories of potentially relevant documents accomplish their tasks with a high level of performance. This means that the category of potentially relevant documents for most profiles would contain at least 80% of all documents later determined to be relevant to the profile. The number of documents in this set would be uniquely determined by the system's category-boundary predictor, and this set is likely to contain less than 5% of the incoming stream of documents.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2003436527",
    "type": "article"
  },
  {
    "title": "When experts agree",
    "doi": "https://doi.org/10.1145/503104.503107",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Krishna Bharat; George A. Mihaila",
    "corresponding_authors": "",
    "abstract": "In response to a query, a search engine returns a ranked list of documents. If the query is about a popular topic (i.e., it matches many documents), then the returned list is usually too long to view fully. Studies show that users usually look at only the top 10 to 20 results. However, we can exploit the fact that the best targets for popular topics are usually linked to by enthusiasts in the same domain. In this paper, we propose a novel ranking scheme for popular topics that places the most authoritative pages on the query topic at the top of the ranking. Our algorithm operates on a special index of \"expert documents.\" These are a subset of the pages on the WWW identified as directories of links to non-affiliated sources on specific topics. Results are ranked based on the match between the query and relevant descriptive text for hyperlinks on expert pages pointing to a given result page. We present a prototype search engine that implements our ranking scheme and discuss its performance. With a relatively small (2.5 million page) expert index, our algorithm was able to perform comparably on popular queries with the best of the mainstream search engines.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2092283802",
    "type": "article"
  },
  {
    "title": "Hyperform",
    "doi": "https://doi.org/10.1145/239041.239043",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Uffe Kock Wiil; John J. Leggett",
    "corresponding_authors": "",
    "abstract": "Development of hypermedia systems is a complex matter. The current trend toward open, extensible, and distributed multiuser hypermedia systems adds additional complexity to the development process. As a means of reducing this complexity, there has been an increasing interest in hyperbase management systems that allow hypermedia system developers to abstract from the intricacies and complexity of the hyperbase layer and fully attend to application and user interface issues. Design, development, and deployment experiences of a dynamic, open, and distributed multiuser hypermedia system development environment called Hyperform is presented. Hyperform is based on the concepts of extensibility, tailorability, and rapid prototyping of hypermedia system services. Open, extensible hyperbase management systems permit hypermedia system developers to tailor hypermedia functionality for specific applications and to serve as a platform for research. The Hyperform development environment is comprised of multiple instances of four component types: (1) a hyperbase management system server, (2) a tool integrator, (3) editors, and (4) participating tools. Hyperform has been deployed in Unix environments, and experiments have shown that Hyperform greatly reduces the effort required to provide customized hyperbase management system support for distributed multiuser hypermedia systems.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W1978674301",
    "type": "article"
  },
  {
    "title": "Analysis of lexical signatures for improving information persistence on the World Wide Web",
    "doi": "https://doi.org/10.1145/1028099.1028101",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "Seung-Taek Park; David M. Pennock; C. Lee Giles; Robert Krovetz",
    "corresponding_authors": "",
    "abstract": "A &lt;i&gt;lexical signature&lt;/i&gt; (LS) consisting of several key words from a Web document is often sufficient information for finding the document later, even if its URL has changed. We conduct a large-scale empirical study of nine methods for generating lexical signatures, including Phelps and Wilensky's original proposal (PW), seven of our own static variations, and one new dynamic method. We examine their performance on the Web over a 10-month period, and on a TREC data set, evaluating their ability to both (1) uniquely identify the original (possibly modified) document, and (2) locate other relevant documents if the original is lost. Lexical signatures chosen to minimize document frequency (DF) are good at unique identification but poor at finding relevant documents. PW works well on the relatively small TREC data set, but acts almost identically to DF on the Web, which contains billions of documents. Term-frequency-based lexical signatures (TF) are very easy to compute and often perform well, but are highly dependent on the ranking system of the search engine used. The term-frequency inverse-document-frequency- (TFIDF-) based method and hybrid methods (which combine DF with TF or TFIDF) seem to be the most promising candidates among static methods for generating effective lexical signatures. We propose a dynamic LS generator called &lt;i&gt;Test &amp; Select&lt;/i&gt; (TS) to mitigate LS conflict. TS outperforms all eight static methods in terms of both extracting the desired document and finding relevant information, over three different search engines. All LS methods show significant performance degradation as documents in the corpus are edited.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2117629987",
    "type": "article"
  },
  {
    "title": "Trustworthy 100-year digital objects",
    "doi": "https://doi.org/10.1145/1010614.1010617",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "H. M. Gladney",
    "corresponding_authors": "H. M. Gladney",
    "abstract": "In ancient times, wax seals impressed with signet rings were affixed to documents as evidence of their authenticity. A digital counterpart is a message authentication code fixed firmly to each important document. If a digital object is sealed together with its own audit trail, each user can examine this evidence to decide whether to trust the content---no matter how distant this user is in time, space, and social affiliation from the document's source.We propose an architecture and design that accomplish this: encapsulation of digital object content with metadata describing its origins, cryptographic sealing, webs of trust for public keys rooted in a forest of respected institutions, and a certain way of managing information identifiers. These means will satisfy emerging needs in civilian and military record management, including medical patient records, regulatory records for aircraft and pharmaceuticals, business records for financial audit, legislative and legal briefs, and scholarly works.This is true for any kind of digital object, independent of its purposes and of most data type and representation details, and provides every kind of user---information authors and editors, librarians and collection managers, and information consumers---with autonomy for implied tasks. Our prototype will conform to applicable standards, will be interoperable over most computing bases, and will be compatible with existing digital library software.The proposed architecture integrates software that is mostly available and widely accepted.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2025082076",
    "type": "article"
  },
  {
    "title": "Object management in distributed information systems",
    "doi": "https://doi.org/10.1145/521.357415",
    "publication_date": "1984-05-24",
    "publication_year": 1984,
    "authors": "Peter Lyngbæk; Dennis McLeod",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Object management in distributed information systems Authors: Peter Lyngbaek Computer Science Dept., University of Southern California, Los Angeles, CA Computer Science Dept., University of Southern California, Los Angeles, CAView Profile , Dennis McLeod Computer Science Dept., University of Southern California, Los Angeles, CA Computer Science Dept., University of Southern California, Los Angeles, CAView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 2pp 96–122https://doi.org/10.1145/521.357415Published:24 May 1984Publication History 27citation766DownloadsMetricsTotal Citations27Total Downloads766Last 12 Months26Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W1980942432",
    "type": "article"
  },
  {
    "title": "38 offices: analyzing needs in individual offices",
    "doi": "https://doi.org/10.1145/1206.1485",
    "publication_date": "1984-08-23",
    "publication_year": 1984,
    "authors": "Raymond R. Panko",
    "corresponding_authors": "Raymond R. Panko",
    "abstract": "article Free Access Share on 38 offices: analyzing needs in individual offices Author: Raymond R. Panko University of Hawaii University of HawaiiView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 3pp 226–234https://doi.org/10.1145/1206.1485Published:23 August 1984Publication History 29citation384DownloadsMetricsTotal Citations29Total Downloads384Last 12 Months14Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2610513229",
    "type": "article"
  },
  {
    "title": "Problems and some solutions in customization of natural language database front ends",
    "doi": "https://doi.org/10.1145/3914.3915",
    "publication_date": "1985-04-01",
    "publication_year": 1985,
    "authors": "Fred J. Damerau",
    "corresponding_authors": "Fred J. Damerau",
    "abstract": "This paper is concerned with some of the issues arising in the development of a domain-independent English interface to IBM SQL-based program products. The TQA system falls into the class of multilayered natural language processing systems. As a result, there is a large number of potential points at which customization to a particular database can be done. Of these, we discuss procedures that affect the reader, the lexicon, the lowest level of grammar rules, the semantic interpreter, and the output formatter. Our tests lead us to believe that the approach we are taking will make it possible for database administrators to generate robust English interfaces to particular databases without help from linguistic experts.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W1971407149",
    "type": "article"
  },
  {
    "title": "A large scale, corpus-based approach for automatically disambiguating biomedical abbreviations",
    "doi": "https://doi.org/10.1145/1165774.1165778",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Hong Yu; Won Kim; Vasileios Hatzivassiloglou; John Wilbur",
    "corresponding_authors": "",
    "abstract": "Abbreviations and acronyms are widely used in the biomedical literature and many of them represent important biomedical concepts. Because many abbreviations are ambiguous (e.g., CAT denotes both chloramphenicol acetyl transferase and computed axial tomography , depending on the context), recognizing the full form associated with each abbreviation is in most cases equivalent to identifying the meaning of the abbreviation. This, in turn, allows us to perform more accurate natural language processing, information extraction, and retrieval. In this study, we have developed supervised approaches to identifying the full forms of ambiguous abbreviations within the context they appear. We first automatically assigned multiple possible full forms for each abbreviation; we then treated the in-context full-form prediction for each specific abbreviation occurrence as a case of word-sense disambiguation. We generated automatically a dictionary of all possible full forms for each abbreviation. We applied supervised machine-learning algorithms for disambiguation. Because some of the links between abbreviations and their corresponding full forms are explicitly given in the text and can be recovered automatically, we can use these explicit links to automatically provide training data for disambiguating the abbreviations that are not linked to a full form within a text. We evaluated our methods on over 150 thousand abstracts and obtain for coverage and precision results of 82% and 92%, respectively, when performed as tenfold cross-validation, and 79% and 80%, respectively, when evaluated against an external set of abstracts in which the abbreviations are not defined.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2146257659",
    "type": "article"
  },
  {
    "title": "CLAIRE",
    "doi": "https://doi.org/10.1145/1165774.1165777",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Chih‐Fong Tsai; Kenneth McGarry; John Tait",
    "corresponding_authors": "",
    "abstract": "Many users of image retrieval systems would prefer to express initial queries using keywords. However, manual keyword indexing is very time-consuming. Therefore, a content-based image retrieval system which can automatically assign keywords to images would be very attractive. Unfortunately, it has proved very challenging to build such systems, except where either the image domain is restricted or the keywords relate only to low-level concepts such as color. This article presents a novel image indexing and classification system, called CLAIRE (CLAssifying Images for REtrieval), composed of one image processing module and three modules of support vector machines for color, texture, and high-level concept classification for keyword assignment. The experimental prototype system described here assigns up to five keywords selected from a controlled vocabulary of 60 terms to each image. The system is trained offline by 1639 examples from the Corel stock photo library. For evaluation, five judges reviewed a sample of 800 unknown images to identify which automatically assigned keywords were actually relevant to the image. The system proved to have an 80% probability to assign at least one relevant keyword to an image.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2088476822",
    "type": "article"
  },
  {
    "title": "Clusters, language models, and ad hoc information retrieval",
    "doi": "https://doi.org/10.1145/1508850.1508851",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "Oren Kurland; Lillian Lee",
    "corresponding_authors": "",
    "abstract": "The language-modeling approach to information retrieval provides an effective statistical framework for tackling various problems and often achieves impressive empirical performance. However, most previous work on language models for information retrieval focused on document-specific characteristics, and therefore did not take into account the structure of the surrounding corpus, a potentially rich source of additional information. We propose a novel algorithmic framework in which information provided by document-based language models is enhanced by the incorporation of information drawn from clusters of similar documents. Using this framework, we develop a suite of new algorithms. Even the simplest typically outperforms the standard language-modeling approach in terms of mean average precision (MAP) and recall, and our new interpolation algorithm posts statistically significant performance improvements for both metrics over all six corpora tested. An important aspect of our work is the way we model corpus structure. In contrast to most previous work on cluster-based retrieval that partitions the corpus, we demonstrate the effectiveness of a simple strategy based on a nearest-neighbors approach that produces overlapping clusters.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2086298942",
    "type": "article"
  },
  {
    "title": "Locality-Based pruning methods for web search",
    "doi": "https://doi.org/10.1145/1344411.1344415",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Edleno Silva de Moura; Celia Francisca dos Santos; Bruno Araujo; Altigran Soares da Silva; Pável Calado; Mário A. Nascimento",
    "corresponding_authors": "",
    "abstract": "This article discusses a novel approach developed for static index pruning that takes into account the locality of occurrences of words in the text. We use this new approach to propose and experiment on simple and effective pruning methods that allow a fast construction of the pruned index. The methods proposed here are especially useful for pruning in environments where the document database changes continuously, such as large-scale web search engines. Extensive experiments are presented showing that the proposed methods can achieve high compression rates while maintaining the quality of results for the most common query types present in modern search engines, namely, conjunctive and phrase queries. In the experiments, our locality-based pruning approach allowed reducing search engine indices to 30% of their original size, with almost no reduction in precision at the top answers. Furthermore, we conclude that even an extremely simple locality-based pruning method can be competitive when compared to complex methods that do not rely on locality information.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2067662418",
    "type": "article"
  },
  {
    "title": "Improving graph-walk-based similarity with reranking",
    "doi": "https://doi.org/10.1145/1877766.1877770",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Einat Minkov; William W. Cohen",
    "corresponding_authors": "",
    "abstract": "Relational or semistructured data is naturally represented by a graph, where nodes denote entities and directed typed edges represent the relations between them. Such graphs are heterogeneous, describing different types of objects and links. We represent personal information as a graph that includes messages , terms , persons , dates , and other object types, and relations like sent-to and has-term . Given the graph, we apply finite random graph walks to induce a measure of entity similarity, which can be viewed as a tool for performing search in the graph. Experiments conducted using personal email collections derived from the Enron corpus and other corpora show how the different tasks of alias finding , threading , and person name disambiguation can be all addressed as search queries in this framework, where the graph-walk-based similarity metric is preferable to alternative approaches, and further improvements are achieved with learning. While researchers have suggested to tune edge weight parameters to optimize the graph walk performance per task, we apply reranking to improve the graph walk results, using features that describe high-level information such as the paths traversed in the walk. High performance, together with practical runtimes, suggest that the described framework is a useful search system in the PIM domain, as well as in other semistructured domains.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2029258770",
    "type": "article"
  },
  {
    "title": "Utilizing inter-passage and inter-document similarities for reranking search results",
    "doi": "https://doi.org/10.1145/1877766.1877769",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Eyal Krikon; Oren Kurland; Michael Bendersky",
    "corresponding_authors": "",
    "abstract": "We present a novel language-model-based approach to reranking search results; that is, reordering the documents in an initially retrieved list so as to improve precision at top ranks. Our model integrates whole-document information with that induced from passages . Specifically, inter-passage, inter-document, and query-based similarities, which constitute a rich source of information, are combined in our model. Empirical evaluation shows that the precision-at-top-ranks performance of our model is substantially better than that of the initial ranking upon which reranking is performed. Furthermore, the performance is substantially better than that of a commonly used passage-based document ranking method that does not exploit inter-item similarities. Our model also generalizes and outperforms a recently proposed reranking method that utilizes inter-document similarities, but which does not exploit passage-based information. Finally, the model's performance is superior to that of a state-of-the-art pseudo-feedback-based retrieval approach.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2058134741",
    "type": "article"
  },
  {
    "title": "Peer-to-Peer Information Retrieval",
    "doi": "https://doi.org/10.1145/2180868.2180871",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Almer S. Tigelaar; Djoerd Hiemstra; Dolf Trieschnigg",
    "corresponding_authors": "",
    "abstract": "Peer-to-peer technology is widely used for file sharing. In the past decade a number of prototype peer-to-peer information retrieval systems have been developed. Unfortunately, none of these has seen widespread real-world adoption and thus, in contrast with file sharing, information retrieval is still dominated by centralized solutions. In this article we provide an overview of the key challenges for peer-to-peer information retrieval and the work done so far. We want to stimulate and inspire further research to overcome these challenges. This will open the door to the development and large-scale deployment of real-world peer-to-peer information retrieval systems that rival existing centralized client-server solutions in terms of scalability, performance, user satisfaction, and freedom.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1993948826",
    "type": "article"
  },
  {
    "title": "Social Link Prediction in Online Social Tagging Systems",
    "doi": "https://doi.org/10.1145/2516891",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Charalampos Chelmis; Viktor K. Prasanna",
    "corresponding_authors": "",
    "abstract": "Social networks have become a popular medium for people to communicate and distribute ideas, content, news, and advertisements. Social content annotation has naturally emerged as a method of categorization and filtering of online information. The unrestricted vocabulary users choose from to annotate content has often lead to an explosion of the size of space in which search is performed. In this article, we propose latent topic models as a principled way of reducing the dimensionality of such data and capturing the dynamics of collaborative annotation process. We propose three generative processes to model latent user tastes with respect to resources they annotate with metadata. We show that latent user interests combined with social clues from the immediate neighborhood of users can significantly improve social link prediction in the online music social media site Last.fm. Most link prediction methods suffer from the high class imbalance problem, resulting in low precision and/or recall. In contrast, our proposed classification schemes for social link recommendation achieve high precision and recall with respect to not only the dominant class (nonexistence of a link), but also with respect to sparse positive instances, which are the most vital in social tie prediction.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2084804965",
    "type": "article"
  },
  {
    "title": "言語-依存および言語-非依存例示照会話し言葉検出法の比較",
    "doi": null,
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Tejedor Javier; Michal Fapšo; Szoeke Igor; Cernocky Jan; František Grézl",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W3173932179",
    "type": "article"
  },
  {
    "title": "Effective and Robust Query-Based Stemming",
    "doi": "https://doi.org/10.1145/2536736.2536738",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Jiaul H. Paik; Swapan K. Parui; Dipasree Pal; Stephen Robertson",
    "corresponding_authors": "",
    "abstract": "Stemming is a widely used technique in information retrieval systems to address the vocabulary mismatch problem arising out of morphological phenomena. The major shortcoming of the commonly used stemmers is that they accept the morphological variants of the query words without considering their thematic coherence with the given query, which leads to poor performance. Moreover, for many queries, such approaches also produce retrieval performance that is poorer than no stemming, thereby degrading the robustness. The main goal of this article is to present corpus-based fully automatic stemming algorithms which address these issues. A set of experiments on six TREC collections and three other non-English collections containing news and web documents shows that the proposed query-based stemming algorithms consistently and significantly outperform four state of the art strong stemmers of completely varying principles. Our experiments also confirm that the robustness of the proposed query-based stemming algorithms are remarkably better than the existing strong baselines.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2011447283",
    "type": "article"
  },
  {
    "title": "The nonverbal structure of patient case discussions in multidisciplinary medical team meetings",
    "doi": "https://doi.org/10.1145/2328967.2328970",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Saturnino Luz",
    "corresponding_authors": "Saturnino Luz",
    "abstract": "Meeting analysis has a long theoretical tradition in social psychology, with established practical ramifications in computer science, especially in computer supported cooperative work. More recently, a good deal of research has focused on the issues of indexing and browsing multimedia records of meetings. Most research in this area, however, is still based on data collected in laboratories, under somewhat artificial conditions. This article presents an analysis of the discourse structure and spontaneous interactions at real-life multidisciplinary medical team meetings held as part of the work routine in a major hospital. It is hypothesized that the conversational structure of these meetings, as indicated by sequencing and duration of vocalizations, enables segmentation into individual patient case discussions. The task of segmenting audio-visual records of multidisciplinary medical team meetings is described as a topic segmentation task, and a method for automatic segmentation is proposed. An empirical evaluation based on hand labelled data is presented, which determines the optimal length of vocalization sequences for segmentation, and establishes the competitiveness of the method with approaches based on more complex knowledge sources. The effectiveness of Bayesian classification as a segmentation method, and its applicability to meeting segmentation in other domains are discussed.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2061911513",
    "type": "article"
  },
  {
    "title": "Improving Text Classification Accuracy by Training Label Cleaning",
    "doi": "https://doi.org/10.1145/2516889",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Andrea Esuli; Fabrizio Sebastiani",
    "corresponding_authors": "",
    "abstract": "In text classification (TC) and other tasks involving supervised learning, labelled data may be scarce or expensive to obtain. Semisupervised learning and active learning are two strategies whose aim is maximizing the effectiveness of the resulting classifiers for a given amount of training effort. Both strategies have been actively investigated for TC in recent years. Much less research has been devoted to a third such strategy, training label cleaning (TLC), which consists in devising ranking functions that sort the original training examples in terms of how likely it is that the human annotator has mislabelled them. This provides a convenient means for the human annotator to revise the training set so as to improve its quality. Working in the context of boosting-based learning methods for multilabel classification we present three different techniques for performing TLC and, on three widely used TC benchmarks, evaluate them by their capability of spotting training documents that, for experimental reasons only, we have purposefully mislabelled. We also evaluate the degradation in classification effectiveness that these mislabelled texts bring about, and to what extent training label cleaning can prevent this degradation.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2068303084",
    "type": "article"
  },
  {
    "title": "Correlation-based retrieval for heavily changed near-duplicate videos",
    "doi": "https://doi.org/10.1145/2037661.2037666",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Jiajun Liu; Zi Huang; Heng Tao Shen; Bin Cui",
    "corresponding_authors": "",
    "abstract": "The unprecedented and ever-growing number of Web videos nowadays leads to the massive existence of near-duplicate videos. Very often, some near-duplicate videos exhibit great content changes, while the user perceives little information change, for example, color features change significantly when transforming a color video with a blue filter. These feature changes contribute to low-level video similarity computations, making conventional similarity-based near-duplicate video retrieval techniques incapable of accurately capturing the implicit relationship between two near-duplicate videos with fairly large content modifications. In this paper, we introduce a new dimension for near-duplicate video retrieval. Different from existing near-duplicate video retrieval approaches which are based on video-content similarity, we explore the correlation between two videos. The intuition is that near-duplicate videos should preserve strong information correlation in spite of intensive content changes. More effective retrieval with stronger tolerance is achieved by replacing video-content similarity measures with information correlation analysis. Theoretical justification and experimental results prove the effectiveness of correlation-based near-duplicate retrieval.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2086542379",
    "type": "article"
  },
  {
    "title": "Trust Prediction via Belief Propagation",
    "doi": "https://doi.org/10.1145/2629530",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Richong Zhang; Yongyi Mao",
    "corresponding_authors": "",
    "abstract": "The prediction of trust relationships in social networks plays an important role in the analytics of the networks. Although various link prediction algorithms for general networks may be adapted for this purpose, the recent notion of “trust propagation” has been shown to effectively capture the trust-formation mechanisms and resulted in an effective prediction algorithm. This article builds on the concept of trust propagation and presents a probabilistic trust propagation model. Our model exploits the modern framework of probabilistic graphical models, more specifically, factor graphs. Under this model, the trust prediction problem can be formulated as a statistical inference problem and we derive the belief propagation algorithm as a solver for trust prediction. The model and algorithm are tested using datasets from Epinions and Ciao, by which performance advantages over the previous algorithms are demonstrated.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2089201173",
    "type": "article"
  },
  {
    "title": "Targeted Advertising in Public Transportation Systems with Quantitative Evaluation",
    "doi": "https://doi.org/10.1145/3003725",
    "publication_date": "2017-01-04",
    "publication_year": 2017,
    "authors": "Dongxiang Zhang; Long Guo; Liqiang Nie; Jie Shao; Sai Wu; Heng Tao Shen",
    "corresponding_authors": "",
    "abstract": "In spite of vast business potential, targeted advertising in public transportation systems is a grossly unexplored research area. For instance, SBS Transit in Singapore can reach 1 billion passengers per year but the annual advertising revenue contributes less than $35 million. To bridge the gap, we propose a probabilistic data model that captures the motion patterns and user interests so as to quantitatively evaluate the impact of an advertisement among the passengers. In particular, we leverage hundreds of millions of bus/train boarding transaction records to quantitatively estimate the probability as well as the extent of a user being influenced by an ad. Based on the influence model, we study a top- k retrieval problem for bus/train ad recommendation, which acts as a primitive operator to support various advanced applications. We solve the retrieval problem efficiently to support real-time decision making. In the experimental study, we use the dataset from SBS Transit as a case study to verify the effectiveness and efficiency of our proposed methodologies.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2568885412",
    "type": "article"
  },
  {
    "title": "Clustered Elias-Fano Indexes",
    "doi": "https://doi.org/10.1145/3052773",
    "publication_date": "2017-04-06",
    "publication_year": 2017,
    "authors": "Giulio Ermanno Pibiri; Rossano Venturini",
    "corresponding_authors": "",
    "abstract": "State-of-the-art encoders for inverted indexes compress each posting list individually . Encoding clusters of posting lists offers the possibility of reducing the redundancy of the lists while maintaining a noticeable query processing speed. In this article, we propose a new index representation based on clustering the collection of posting lists and, for each created cluster, building an ad hoc reference list with respect to which all lists in the cluster are encoded with Elias-Fano . We describe a posting lists clustering algorithm tailored for our encoder and two methods for building the reference list for a cluster. Both approaches are heuristic and differ in the way postings are added to the reference list: according to their frequency in the cluster or according to the number of bits necessary for their representation. The extensive experimental analysis indicates that significant space reductions are indeed possible, beating the best state-of-the-art encoders.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2604113568",
    "type": "article"
  },
  {
    "title": "Improving the Quality of Recommendations for Users and Items in the Tail of Distribution",
    "doi": "https://doi.org/10.1145/3052769",
    "publication_date": "2017-06-06",
    "publication_year": 2017,
    "authors": "Liang Hu; Longbing Cao; Jian Cao; Zhiping Gu; Guandong Xu; Jie Wang",
    "corresponding_authors": "",
    "abstract": "Short-head and long-tail distributed data are widely observed in the real world. The same is true of recommender systems (RSs), where a small number of popular items dominate the choices and feedback data while the rest only account for a small amount of feedback. As a result, most RS methods tend to learn user preferences from popular items since they account for most data. However, recent research in e-commerce and marketing has shown that future businesses will obtain greater profit from long-tail selling. Yet, although the number of long-tail items and users is much larger than that of short-head items and users, in reality, the amount of data associated with long-tail items and users is much less. As a result, user preferences tend to be popularity-biased. Furthermore, insufficient data makes long-tail items and users more vulnerable to shilling attack. To improve the quality of recommendations for items and users in the tail of distribution, we propose a coupled regularization approach that consists of two latent factor models: C-HMF, for enhancing credibility, and S-HMF, for emphasizing specialty on user choices. Specifically, the estimates learned from C-HMF and S-HMF recurrently serve as the empirical priors to regularize one another. Such coupled regularization leads to the comprehensive effects of final estimates, which produce more qualitative predictions for both tail users and tail items. To assess the effectiveness of our model, we conduct empirical evaluations on large real-world datasets with various metrics. The results prove that our approach significantly outperforms the compared methods.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2621989739",
    "type": "article"
  },
  {
    "title": "IDF for Word N-grams",
    "doi": "https://doi.org/10.1145/3052775",
    "publication_date": "2017-06-05",
    "publication_year": 2017,
    "authors": "Masumi Shirakawa; Takahiro Hara; Shojiro Nishio",
    "corresponding_authors": "",
    "abstract": "Inverse Document Frequency (IDF) is widely accepted term weighting scheme whose robustness is supported by many theoretical justifications. However, applying IDF to word N-grams (or simply N-grams) of any length without relying on heuristics has remained a challenging issue. This article describes a theoretical extension of IDF to handle N-grams. First, we elucidate the theoretical relationship between IDF and information distance, a universal metric defined by the Kolmogorov complexity. Based on our understanding of this relationship, we propose N-gram IDF, a new IDF family that gives fair weights to words and phrases of any length. Based only on the magnitude relation of N-gram IDF weights, dominant N-grams among overlapping N-grams can be determined. We also propose an efficient method to compute the N-gram IDF weights of all N-grams by leveraging the enhanced suffix array and wavelet tree. Because the exact computation of N-gram IDF provably requires significant computational cost, we modify it to a fast approximation method that can estimate weight errors analytically and maintain application-level performance. Empirical evaluations with unsupervised/supervised key term extraction and web search query segmentation with various experimental settings demonstrate the robustness and language-independent nature of the proposed N-gram IDF.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2623794988",
    "type": "article"
  },
  {
    "title": "Understanding and Leveraging the Impact of Response Latency on User Behaviour in Web Search",
    "doi": "https://doi.org/10.1145/3106372",
    "publication_date": "2017-08-29",
    "publication_year": 2017,
    "authors": "Xiao Bai; Ioannis Arapakis; B. Barla Cambazoğlu; Ana Freire",
    "corresponding_authors": "",
    "abstract": "The interplay between the response latency of web search systems and users’ search experience has only recently started to attract research attention, despite the important implications of response latency on monetisation of such systems. In this work, we carry out two complementary studies to investigate the impact of response latency on users’ searching behaviour in web search engines. We first conduct a controlled user study to investigate the sensitivity of users to increasing delays in response latency. This study shows that the users of a fast search system are more sensitive to delays than the users of a slow search system. Moreover, the study finds that users are more likely to notice the response latency delays beyond a certain latency threshold, their search experience potentially being affected. We then analyse a large number of search queries obtained from Yahoo Web Search to investigate the impact of response latency on users’ click behaviour. This analysis demonstrates the significant change in click behaviour as the response latency increases. We also find that certain user, context, and query attributes play a role in the way increasing response latency affects the click behaviour. To demonstrate a possible use case for our findings, we devise a machine-learning framework that leverages the latency impact, together with other features, to predict whether a user will issue any clicks on web search results. As a further extension of this use case, we investigate whether this machine-learning framework can be exploited to help search engines reduce their energy consumption during query processing.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2752579606",
    "type": "article"
  },
  {
    "title": "Towards Efficient Framework for Time-Aware Spatial Keyword Queries on Road Networks",
    "doi": "https://doi.org/10.1145/3143802",
    "publication_date": "2017-11-03",
    "publication_year": 2017,
    "authors": "J. Leon Zhao; Yunjun Gao; Gang Chen; Rui‐Pin Chen",
    "corresponding_authors": "",
    "abstract": "The spatial keyword query takes as inputs a query location and a set of query keywords and returns the answer objects by considering both their spatial distances to the query location and textual similarity with the query keywords. However, temporal information plays an important role in the spatial keyword query (where there is, to our knowledge, no prior work considering temporal information of the objects), since objects are not always valid. For instance, visitors may plan their trips according to the opening hours of attractions. Moreover, in real-life applications, objects are located on a predefined road network, and the spatial proximity of two objects is measured by the shortest path distance or travelling time between them. In this article, we study the problem of time-aware spatial keyword (TSK) query , which assumes that objects are located on the road network, and finds the k objects satisfying users’ spatio-temporal description and textual constraint. We first present the pruning strategy and algorithm based on an existing index. Then, we design an efficient index structure called TG index and propose several algorithms using the TG index that can prune the search space with both spatio-temporal and textual information simultaneously. Further, we show that the TG index technique can also be applied to improve the performance of time-travel text search and spatial keyword query. Extensive experiments using both real and synthetic datasets demonstrate the effectiveness and efficiency of the presented index and algorithms.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2765183037",
    "type": "article"
  },
  {
    "title": "Explicit Diversification of Event Aspects for Temporal Summarization",
    "doi": "https://doi.org/10.1145/3158671",
    "publication_date": "2018-02-02",
    "publication_year": 2018,
    "authors": "Richard McCreadie; Rodrygo L. T. Santos; Craig Macdonald; Iadh Ounis",
    "corresponding_authors": "",
    "abstract": "During major events, such as emergencies and disasters, a large volume of information is reported on newswire and social media platforms. Temporal summarization (TS) approaches are used to automatically produce concise overviews of such events by extracting text snippets from related articles over time. Current TS approaches rely on a combination of event relevance and textual novelty for snippet selection. However, for events that span multiple days, textual novelty is often a poor criterion for selecting snippets, since many snippets are textually unique but are semantically redundant or non-informative. In this article, we propose a framework for the diversification of snippets using explicit event aspects, building on recent works in search result diversification. In particular, we first propose two techniques to identify explicit aspects that a user might want to see covered in a summary for different types of event. We then extend a state-of-the-art explicit diversification framework to maximize the coverage of these aspects when selecting summary snippets for unseen events. Through experimentation over the TREC TS 2013, 2014, and 2015 datasets, we show that explicit diversification for temporal summarization significantly outperforms classical novelty-based diversification, as the use of explicit event aspects reduces the amount of redundant and off-topic snippets returned, while also increasing summary timeliness.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2781872642",
    "type": "article"
  },
  {
    "title": "Binary Sketches for Secondary Filtering",
    "doi": "https://doi.org/10.1145/3231936",
    "publication_date": "2018-12-06",
    "publication_year": 2018,
    "authors": "Vladimír Míč; David Novák; Pavel Zezula",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of matching the most similar data objects to a given query object. We adopt a generic model of similarity that involves the domain of objects and metric distance functions only. We examine the case of a large dataset in a complex data space, which makes this problem inherently difficult. Many indexing and searching approaches have been proposed, but they have often failed to efficiently prune complex search spaces and access large portions of the dataset when evaluating queries. We propose an approach to enhancing the existing search techniques to significantly reduce the number of accessed data objects while preserving the quality of the search results. In particular, we extend each data object with its sketch , a short binary string in Hamming space. These sketches approximate the similarity relationships in the original search space, and we use them to filter out non-relevant objects not pruned by the original search technique. We provide a probabilistic model to tune the parameters of the sketch-based filtering separately for each query object. Experiments conducted with different similarity search techniques and real-life datasets demonstrate that the secondary filtering can speed-up similarity search several times.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2904966474",
    "type": "article"
  },
  {
    "title": "Modeling reformulation using query distributions",
    "doi": "https://doi.org/10.1145/2457465.2457466",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Xiaobing Xue; W. Bruce Croft",
    "corresponding_authors": "",
    "abstract": "Query reformulation modifies the original query with the aim of better matching the vocabulary of the relevant documents, and consequently improving ranking effectiveness. Previous models typically generate words and phrases related to the original query, but do not consider how these words and phrases would fit together in actual queries. In this article, a novel framework is proposed that models reformulation as a distribution of actual queries, where each query is a variation of the original query. This approach considers an actual query as the basic unit and thus captures important query-level dependencies between words and phrases. An implementation of this framework that only uses publicly available resources is proposed, which makes fair comparisons with other methods using TREC collections possible. Specifically, this implementation consists of a query generation step that analyzes the passages containing query words to generate reformulated queries and a probability estimation step that learns a distribution for reformulated queries by optimizing the retrieval performance. Experiments on TREC collections show that the proposed model can significantly outperform previous reformulation models.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2047599666",
    "type": "article"
  },
  {
    "title": "Comparing the Archival Rate of Arabic, English, Danish, and Korean Language Web Pages",
    "doi": "https://doi.org/10.1145/3041656",
    "publication_date": "2017-06-05",
    "publication_year": 2017,
    "authors": "Lulwah M. Alkwai; Michael L. Nelson; Michele C. Weigle",
    "corresponding_authors": "",
    "abstract": "It has long been suspected that web archives and search engines favor Western and English language webpages. In this article, we quantitatively explore how well indexed and archived Arabic language webpages are as compared to those from other languages. We began by sampling 15,092 unique URIs from three different website directories: DMOZ (multilingual), Raddadi, and Star28 (the last two primarily Arabic language). Using language identification tools, we eliminated pages not in the Arabic language (e.g., English-language versions of Aljazeera pages) and culled the collection to 7,976 Arabic language webpages. We then used these 7,976 pages and crawled the live web and web archives to produce a collection of 300,646 Arabic language pages. We compared the analysis of Arabic language pages with that of English, Danish, and Korean language pages. First, for each language, we sampled unique URIs from DMOZ; then, using language identification tools, we kept only pages in the desired language. Finally, we crawled the archived and live web to collect a larger sample of pages in English, Danish, or Korean. In total for the four languages, we analyzed over 500,000 webpages. We discovered: (1) English has a higher archiving rate than Arabic, with 72.04% archived. However, Arabic has a higher archiving rate than Danish and Korean, with 53.36% of Arabic URIs archived, followed by Danish and Korean with 35.89% and 32.81% archived, respectively. (2) Most Arabic and English language pages are located in the United States; only 14.84% of the Arabic URIs had an Arabic country code top-level domain (e.g., sa) and only 10.53% had a GeoIP in an Arabic country. Most Danish-language pages were located in Denmark, and most Korean-language pages were located in South Korea. (3) The presence of a webpage in a directory positively impacts indexing and presence in the DMOZ directory, specifically, positively impacts archiving in all four languages. In this work, we show that web archives and search engines favor English pages. However, it is not universally true for all Western-language webpages because, in this work, we show that Arabic webpages have a higher archival rate than Danish language webpages.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2624014132",
    "type": "article"
  },
  {
    "title": "Top-N Recommendation with Multi-Channel Positive Feedback using Factorization Machines",
    "doi": "https://doi.org/10.1145/3291756",
    "publication_date": "2019-02-13",
    "publication_year": 2019,
    "authors": "Babak Loni; Roberto Pagano; Martha Larson; Alan Hanjalić",
    "corresponding_authors": "",
    "abstract": "User interactions can be considered to constitute different feedback channels, for example, view, click, like or follow, that provide implicit information on users’ preferences. Each implicit feedback channel typically carries a unary, positive-only signal that can be exploited by collaborative filtering models to generate lists of personalized recommendations. This article investigates how a learning-to-rank recommender system can best take advantage of implicit feedback signals from multiple channels. We focus on Factorization Machines (FMs) with Bayesian Personalized Ranking (BPR), a pairwise learning-to-rank method, that allows us to experiment with different forms of exploitation. We perform extensive experiments on three datasets with multiple types of feedback to arrive at a series of insights. We compare conventional, direct integration of feedback types with our proposed method, which exploits multiple feedback channels during the sampling process of training. We refer to our method as multi-channel sampling. Our results show that multi-channel sampling outperforms conventional integration, and that sampling with the relative “level” of feedback is always superior to a level-blind sampling approach. We evaluate our method experimentally on three datasets in different domains and observe that with our multi-channel sampler the accuracy of recommendations can be improved considerably compared to the state-of-the-art models. Further experiments reveal that the appropriate sampling method depends on particular properties of datasets such as popularity skewness.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2912057614",
    "type": "article"
  },
  {
    "title": "Theoretical, Qualitative, and Quantitative Analyses of Small-Document Approaches to Resource Selection",
    "doi": "https://doi.org/10.1145/2590975",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Ilya Markov; Fábio Crestani",
    "corresponding_authors": "",
    "abstract": "In a distributed retrieval setup, resource selection is the problem of identifying and ranking relevant sources of information for a given user’s query. For better usage of existing resource-selection techniques, it is desirable to know what the fundamental differences between them are and in what settings one is superior to others. However, little is understood still about the actual behavior of resource-selection methods. In this work, we focus on small-document approaches to resource selection that rank and select sources based on the ranking of their documents. We pose a number of research questions and approach them by three types of analyses. First, we present existing small-document techniques in a unified framework and analyze them theoretically. Second, we propose using a qualitative analysis to study the behavior of different small-document approaches. Third, we present a novel experimental methodology to evaluate small-document techniques and to validate the results of the qualitative analysis. This way, we answer the posed research questions and provide insights about small-document methods in general and about each technique in particular.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1997402015",
    "type": "article"
  },
  {
    "title": "Cache Design of SSD-Based Search Engine Architectures",
    "doi": "https://doi.org/10.1145/2661629",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Jianguo Wang; Eric Lo; Man Lung Yiu; Jiancong Tong; Gang Wang; Xiaoguang Liu",
    "corresponding_authors": "",
    "abstract": "Caching is an important optimization in search engine architectures. Existing caching techniques for search engine optimization are mostly biased towards the reduction of random accesses to disks, because random accesses are known to be much more expensive than sequential accesses in traditional magnetic hard disk drive (HDD). Recently, solid-state drive (SSD) has emerged as a new kind of secondary storage medium, and some search engines like Baidu have already used SSD to completely replace HDD in their infrastructure. One notable property of SSD is that its random access latency is comparable to its sequential access latency. Therefore, the use of SSDs to replace HDDs in a search engine infrastructure may void the cache management of existing search engines. In this article, we carry out a series of empirical experiments to study the impact of SSD on search engine cache management. Based on the results, we give insights to practitioners and researchers on how to adapt the infrastructure and caching policies for SSD-based search engines.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2063002113",
    "type": "article"
  },
  {
    "title": "Risk-Sensitive Learning to Rank with Evolutionary Multi-Objective Feature Selection",
    "doi": "https://doi.org/10.1145/3300196",
    "publication_date": "2019-02-14",
    "publication_year": 2019,
    "authors": "Daniel Xavier de Sousa; Sérgio Canuto; Marcos André Gonçalves; Thierson Couto Rosa; Wellington S. Martins",
    "corresponding_authors": "",
    "abstract": "Learning to Rank (L2R) is one of the main research lines in Information Retrieval. Risk-sensitive L2R is a sub-area of L2R that tries to learn models that are good on average while at the same time reducing the risk of performing poorly in a few but important queries (e.g., medical or legal queries). One way of reducing risk in learned models is by selecting and removing noisy, redundant features, or features that promote some queries to the detriment of others. This is exacerbated by learning methods that usually maximize an average metric (e.g., mean average precision (MAP) or Normalized Discounted Cumulative Gain (NDCG)). However, historically, feature selection (FS) methods have focused only on effectiveness and feature reduction as the main objectives. Accordingly, in this work, we propose to evaluate FS for L2R with an additional objective in mind, namely risk-sensitiveness . We present novel single and multi-objective criteria to optimize feature reduction, effectiveness, and risk-sensitiveness, all at the same time. We also introduce a new methodology to explore the search space, suggesting effective and efficient extensions of a well-known Evolutionary Algorithm (SPEA2) for FS applied to L2R. Our experiments show that explicitly including risk as an objective criterion is crucial to achieving a more effective and risk-sensitive performance. We also provide a thorough analysis of our methodology and experimental results.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2912859456",
    "type": "article"
  },
  {
    "title": "Pairwise Link Prediction Model for Out of Vocabulary Knowledge Base Entities",
    "doi": "https://doi.org/10.1145/3406116",
    "publication_date": "2020-09-02",
    "publication_year": 2020,
    "authors": "Richong Zhang; Samuel Mensah; Fanshuang Kong; Zhiyuan Hu; Yongyi Mao; Xudong Liu",
    "corresponding_authors": "",
    "abstract": "Real-world knowledge bases such as DBPedia, Yago, and Freebase contain sparse linkage connectivity, which poses a severe challenge to link prediction between entities. To cope with such data scarcity issues, recent models have focused on learning interactions between entity pairs by means of relations that exist between them. However promising, some relations are associated with very few tail entities or head entities, resulting in poor estimation of the relation interaction between entities. In this article, we break the sole dependency of modeling relation interactions between entity pairs by associating a triple with pairwise embeddings, i.e., distributed vector representations for pairs of word-based entities and relation of a triple. We capture the interactions that exist between pairwise embeddings by means of a Pairwise Factorization Model that employs a factorization machine with relation attention. This approach allows parameters for related interactions to be estimated efficiently, ensuring that the pairwise embeddings are discriminative, providing strong supervisory signals for the decoding task of link prediction. The Pairwise Factorization Model we propose exploits a neural bag-of-words model as the encoder, which effectively encodes word-based entities into distributed vector representations for the decoder. The proposed model is simple and enjoys efficiency and capability, showing superior link prediction performance over state-of-the-art complex models on benchmark datasets DBPedia50K and FB15K-237.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3081520483",
    "type": "article"
  },
  {
    "title": "A Critical Reassessment of the Saerens-Latinne-Decaestecker Algorithm for Posterior Probability Adjustment",
    "doi": "https://doi.org/10.1145/3433164",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Andrea Esuli; Alessio Molinari; Fabrizio Sebastiani",
    "corresponding_authors": "",
    "abstract": "We critically re-examine the Saerens-Latinne-Decaestecker (SLD) algorithm, a well-known method for estimating class prior probabilities (“priors”) and adjusting posterior probabilities (“posteriors”) in scenarios characterized by distribution shift, i.e., difference in the distribution of the priors between the training and the unlabelled documents. Given a machine learned classifier and a set of unlabelled documents for which the classifier has returned posterior probabilities and estimates of the prior probabilities, SLD updates them both in an iterative, mutually recursive way, with the goal of making both more accurate; this is of key importance in downstream tasks such as single-label multiclass classification and cost-sensitive text classification. Since its publication, SLD has become the standard algorithm for improving the quality of the posteriors in the presence of distribution shift, and SLD is still considered a top contender when we need to estimate the priors (a task that has become known as “quantification”). However, its real effectiveness in improving the quality of the posteriors has been questioned. We here present the results of systematic experiments conducted on a large, publicly available dataset, across multiple amounts of distribution shift and multiple learners. Our experiments show that SLD improves the quality of the posterior probabilities and of the estimates of the prior probabilities, but only when the number of classes in the classification scheme is very small and the classifier is calibrated. As the number of classes grows, or as we use non-calibrated classifiers, SLD converges more slowly (and often does not converge at all), performance degrades rapidly, and the impact of SLD on the quality of the prior estimates and of the posteriors becomes negative rather than positive.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3113985549",
    "type": "article"
  },
  {
    "title": "Retrieval Evaluation Measures that Agree with Users’ SERP Preferences",
    "doi": "https://doi.org/10.1145/3431813",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Tetsuya Sakai; Zhaohao Zeng",
    "corresponding_authors": "",
    "abstract": "We examine the “goodness” of ranked retrieval evaluation measures in terms of how well they align with users’ Search Engine Result Page (SERP) preferences for web search. The SERP preferences cover 1,127 topic-SERP-SERP triplets extracted from the NTCIR-9 INTENT task, reflecting the views of 15 different assessors. Each assessor made two SERP preference judgements for each triplet: one in terms of relevance and the other in terms of diversity. For each evaluation measure, we compute the Agreement Rate (AR) of each triplet: the proportion of assessors that agree with the measure’s SERP preference. We then compare the mean ARs of the measures as well as those of best/median/worst assessors using Tukey HSD tests. Our first experiment compares traditional ranked retrieval measures based on the SERP relevance preferences: we find that normalised Discounted Cumulative Gain (nDCG) and intentwise Rank-biased Utility (iRBU) perform best in that they are the only measures that are statistically indistinguishable from our best assessor; nDCG also statistically significantly outperforms our median assessor. Our second experiment utilises 119,646 document preferences that we collected for a subset of the above topic-SERP-SERP triplets (containing 894 triplets) to compare preference-based evaluation measures as well as traditional ones. Again, we evaluate them based on the SERP relevance preferences. The results suggest that measures such as wpref5 are the most promising among the preference-based measures considered, although they underperform the best traditional measures such as nDCG on average. Our third experiment compares diversified search measures based on the SERP diversity preferences as well as the SERP relevance preferences, and it shows that D♯-measures are clearly the most reliable: in particular, D♯-nDCG and D♯-RBP statistically significantly outperform the median assessor and all intent-aware measures; they also outperform the recently proposed RBU on average. Also, in terms of agreement with SERP diversity preferences, D♯-nDCG statistically significantly outperforms RBU. Hence, if IR researchers want to use evaluation measures that align well with users’ SERP preferences, then we recommend nDCG and iRBU for traditional search, and D♯-measures such as D♯-nDCG for diversified search. As for document preference-based measures that we have examined, we do not have a strong reason to recommended them over traditional measures like nDCG, since they align slightly less well with users’ SERP preferences despite their quadratic assessment cost.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3117895913",
    "type": "article"
  },
  {
    "title": "Cost-Effective Online Trending Topic Detection and Popularity Prediction in Microblogging",
    "doi": "https://doi.org/10.1145/3001833",
    "publication_date": "2016-12-15",
    "publication_year": 2016,
    "authors": "Zhongchen Miao; Kai Chen; Yi Fang; Jianhua He; Yi Zhou; Wenjun Zhang; Hongyuan Zha",
    "corresponding_authors": "",
    "abstract": "Identifying topic trends on microblogging services such as Twitter and estimating those topics’ future popularity have great academic and business value, especially when the operations can be done in real time. For any third party, however, capturing and processing such huge volumes of real-time data in microblogs are almost infeasible tasks, as there always exist API (Application Program Interface) request limits, monitoring and computing budgets, as well as timeliness requirements. To deal with these challenges, we propose a cost-effective system framework with algorithms that can automatically select a subset of representative users in microblogging networks in offline, under given cost constraints. Then the proposed system can online monitor and utilize only these selected users’ real-time microposts to detect the overall trending topics and predict their future popularity among the whole microblogging network. Therefore, our proposed system framework is practical for real-time usage as it avoids the high cost in capturing and processing full real-time data, while not compromising detection and prediction performance under given cost constraints. Experiments with real microblogs dataset show that by tracking only 500 users out of 0.6 million users and processing no more than 30,000 microposts daily, about 92% trending topics could be detected and predicted by the proposed system and, on average, more than 10 hours earlier than they appear in official trends lists.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2566283272",
    "type": "article"
  },
  {
    "title": "Graph-based Regularization on Embedding Layers for Recommendation",
    "doi": "https://doi.org/10.1145/3414067",
    "publication_date": "2020-09-05",
    "publication_year": 2020,
    "authors": "Yuan Zhang; Fei Sun; Xiaoyong Yang; Xu Chen; Wenwu Ou; Yan Zhang",
    "corresponding_authors": "",
    "abstract": "Neural networks have been extensively used in recommender systems. Embedding layers are not only necessary but also crucial for neural models in recommendation as a typical discrete task. In this article, we argue that the widely used l 2 regularization for normal neural layers (e.g., fully connected layers) is not ideal for embedding layers from the perspective of regularization theory in Reproducing Kernel Hilbert Space. More specifically, the l 2 regularization corresponds to the inner product and the distance in the Euclidean space where correlations between discrete objects (e.g., items) are not well captured. Inspired by this observation, we propose a graph-based regularization approach to serve as a counterpart of the l 2 regularization for embedding layers. The proposed regularization incurs almost no extra computational overhead especially when being trained with mini-batches. We also discuss its relationships to other approaches (namely, data augmentation, graph convolution, and joint learning) theoretically. We conducted extensive experiments on five publicly available datasets from various domains with two state-of-the-art recommendation models. Results show that given a kNN (k-nearest neighbor) graph constructed directly from training data without external information, the proposed approach significantly outperforms the l 2 regularization on all the datasets and achieves more notable improvements for long-tail users and items.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3083606581",
    "type": "article"
  },
  {
    "title": "Block-Aware Item Similarity Models for Top- <i>N</i> Recommendation",
    "doi": "https://doi.org/10.1145/3411754",
    "publication_date": "2020-09-10",
    "publication_year": 2020,
    "authors": "Yifan Chen; Yang Wang; Xiang Zhao; Jie Zou; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Top- N recommendations have been studied extensively. Promising results have been achieved by recent item-based collaborative filtering (ICF) methods. The key to ICF lies in the estimation of item similarities. Observing the block-diagonal structure of the item similarities in practice, we propose a block-diagonal regularization (BDR) over item similarities for ICF. The intuitions behind BDR are as follows: (1) with BDR, item clustering is embedded into the learning of ICF methods; (2) BDR induces sparsity of item similarities, which guarantees recommendation efficiency; and (3) BDR captures in-block transitivity to overcome rating sparsity. By regularizing the item similarity matrix of item similarity models with BDR, we obtain a block-aware item similarity model. Our experimental evaluations on a large number of datasets show that the block-diagonal structure is crucial to the performance of top- N recommendation.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3084805822",
    "type": "article"
  },
  {
    "title": "Pretrained Embeddings for Stance Detection with Hierarchical Capsule Network on Social Media",
    "doi": "https://doi.org/10.1145/3412362",
    "publication_date": "2020-09-15",
    "publication_year": 2020,
    "authors": "Guangzhen Zhao; Peng Yang",
    "corresponding_authors": "",
    "abstract": "Stance detection on social media aims to identify the stance of social media users toward a topic or claim, which can provide powerful information for various downstream tasks. Many existing stance detection approaches neglect to model the deep semantic representation information in tweets and do not explore aggregating the hierarchical features among words, thus degrading performance. To address these issues, this article proposes a novel deep learning approach P retrained E mbeddings for Stance Detection with H ierarchical C apsule N etwork (PE-HCN) without complicated preprocessing. Specifically, PE-HCN first adopts a pretrained language model and then uses a related textual entailment task for fine-tuning to obtain the deep textual representations of tweets. The PE-HCN approach extends the dynamic routing scheme to cope with these deep textual representations by utilizing primary capsules for routing the information among words in each tweet and applying secondary capsules to transmit the aggregated features to each category capsule accordingly. Moreover, to improve the confidences of the category capsules, we design an adaptive feedback mechanism to dynamically strengthen the routing signals. Through experiments on three benchmark datasets, compared with the state-of-the-art baselines, the extensive results exhibit that PE-HCN achieves competitive improvements of up to 6.32%, 2.09%, and 1.8%, respectively.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3086641547",
    "type": "article"
  },
  {
    "title": "Theories of Conversation for Conversational IR",
    "doi": "https://doi.org/10.1145/3439869",
    "publication_date": "2021-08-16",
    "publication_year": 2021,
    "authors": "Paul Thomas; Mary Czerwinksi; Daniel McDuff; Nick Craswell",
    "corresponding_authors": "",
    "abstract": "Conversational information retrieval is a relatively new and fast-developing research area, but conversation itself has been well studied for decades. Researchers have analysed linguistic phenomena such as structure and semantics but also paralinguistic features such as tone, body language, and even the physiological states of interlocutors. We tend to treat computers as social agents—especially if they have some humanlike features in their design—and so work from human-to-human conversation is highly relevant to how we think about the design of human-to-computer applications. In this article, we summarise some salient past work, focusing on social norms; structures; and affect, prosody, and style. We examine social communication theories briefly as a review to see what we have learned about how humans interact with each other and how that might pertain to agents and robots. We also discuss some implications for research and design of conversational IR systems.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3006669551",
    "type": "article"
  },
  {
    "title": "Dialogue History Matters! Personalized Response Selection in Multi-Turn Retrieval-Based Chatbots",
    "doi": "https://doi.org/10.1145/3453183",
    "publication_date": "2021-08-17",
    "publication_year": 2021,
    "authors": "Juntao Li; Chang Liu; Chongyang Tao; Zhangming Chan; Dongyan Zhao; Min Zhang; Rui Yan",
    "corresponding_authors": "",
    "abstract": "Existing multi-turn context-response matching methods mainly concentrate on obtaining multi-level and multi-dimension representations and better interactions between context utterances and response. However, in real-place conversation scenarios, whether a response candidate is suitable not only counts on the given dialogue context but also other backgrounds, e.g., wording habits, user-specific dialogue history content. To fill the gap between these up-to-date methods and the real-world applications, we incorporate user-specific dialogue history into the response selection and propose a personalized hybrid matching network (PHMN). Our contributions are two-fold: (1) our model extracts personalized wording behaviors from user-specific dialogue history as extra matching information; (2) we perform hybrid representation learning on context-response utterances and explicitly incorporate a customized attention mechanism to extract vital information from context-response interactions so as to improve the accuracy of matching. We evaluate our model on two large datasets with user identification, i.e., personalized Ubuntu dialogue Corpus (P-Ubuntu) and personalized Weibo dataset (P-Weibo). Experimental results confirm that our method significantly outperforms several strong models by combining personalized attention, wording behaviors, and hybrid representation learning.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3193685260",
    "type": "article"
  },
  {
    "title": "Learning a Hierarchical Intent Model for Next-Item Recommendation",
    "doi": "https://doi.org/10.1145/3473972",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Nengjun Zhu; Jian Cao; Xinjiang Lu; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "A session-based recommender system (SBRS) captures users’ evolving behaviors and recommends the next item by profiling users in terms of items in a session. User intent and user preference are two factors affecting his (her) decisions. Specifically, the former narrows the selection scope to some item types, while the latter helps to compare items of the same type. Most SBRSs assume one arbitrary user intent dominates a session when making a recommendation. However, this oversimplifies the reality that a session may involve multiple types of items conforming to different intents. In current SBRSs, items conforming to different user intents have cross-interference in profiling users for whom only one user intent is considered. Explicitly identifying and differentiating items conforming to various user intents can address this issue and model rich contextual information of a session. To this end, we design a framework modeling user intent and preference explicitly, which empowers the two factors to play their distinctive roles. Accordingly, we propose a key-array memory network (KA-MemNN) with a hierarchical intent tree to model coarse-to-fine user intents. The two-layer weighting unit (TLWU) in KA-MemNN detects user intents and generates intent-specific user profiles. Furthermore, the hierarchical semantic component (HSC) integrates multiple sets of intent-specific user profiles along with different user intent distributions to model a multi-intent user profile. The experimental results on real-world datasets demonstrate the superiority of KA-MemNN over selected state-of-the-art methods.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W3202906516",
    "type": "article"
  },
  {
    "title": "Anytime Ranking on Document-Ordered Indexes",
    "doi": "https://doi.org/10.1145/3467890",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Joel Mackenzie; Matthias Petri; Alistair Moffat",
    "corresponding_authors": "",
    "abstract": "Inverted indexes continue to be a mainstay of text search engines, allowing efficient querying of large document collections. While there are a number of possible organizations, document-ordered indexes are the most common, since they are amenable to various query types, support index updates, and allow for efficient dynamic pruning operations. One disadvantage with document-ordered indexes is that high-scoring documents can be distributed across the document identifier space, meaning that index traversal algorithms that terminate early might put search effectiveness at risk. The alternative is impact-ordered indexes, which primarily support top- <?TeX $k$?> disjunctions but also allow for anytime query processing, where the search can be terminated at any time, with search quality improving as processing latency increases. Anytime query processing can be used to effectively reduce high-percentile tail latency that is essential for operational scenarios in which a service level agreement (SLA) imposes response time requirements. In this work, we show how document-ordered indexes can be organized such that they can be queried in an anytime fashion, enabling strict latency control with effective early termination. Our experiments show that processing document-ordered topical segments selected by a simple score estimator outperforms existing anytime algorithms, and allows query runtimes to be accurately limited to comply with SLA requirements.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3197604682",
    "type": "article"
  },
  {
    "title": "Are Neural Ranking Models Robust?",
    "doi": "https://doi.org/10.1145/3534928",
    "publication_date": "2022-06-21",
    "publication_year": 2022,
    "authors": "Chen Wu; Ruqing Zhang; Jiafeng Guo; Yixing Fan; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "Recently, we have witnessed the bloom of neural ranking models in the information retrieval (IR) field. So far, much effort has been devoted to developing effective neural ranking models that can generalize well on new data. There has been less attention paid to the robustness perspective. Unlike the effectiveness, which is about the average performance of a system under normal purpose, robustness cares more about the system performance in the worst case or under malicious operations instead. When a new technique enters into the real-world application, it is critical to know not only how it works in average, but also how would it behave in abnormal situations. So, we raise the question in this work: Are neural ranking models robust? To answer this question, first, we need to clarify what we refer to when we talk about the robustness of ranking models in IR. We show that robustness is actually a multi-dimensional concept and there are three ways to define it in IR: (1) the performance variance under the independent and identically distributed (I.I.D.) setting; (2) the out-of-distribution (OOD) generalizability ; and (3) the defensive ability against adversarial operations. The latter two definitions can be further specified into two different perspectives, respectively, leading to five robustness tasks in total. Based on this taxonomy, we build corresponding benchmark datasets, design empirical experiments, and systematically analyze the robustness of several representative neural ranking models against traditional probabilistic ranking models and learning-to-rank (LTR) models. The empirical results show that there is no simple answer to our question. While neural ranking models are less robust against other IR models in most cases, some of them can still win two out of five tasks. This is the first comprehensive study on the robustness of neural ranking models. We believe the way we study the robustness as well as our findings would be beneficial to the IR community. We will also release all the data and codes to facilitate the future research in this direction.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3189509741",
    "type": "article"
  },
  {
    "title": "The Power of Selecting Key Blocks with Local Pre-ranking for Long Document Information Retrieval",
    "doi": "https://doi.org/10.1145/3568394",
    "publication_date": "2022-10-17",
    "publication_year": 2022,
    "authors": "Minghan Li; Diana Nicoleta Popa; Johan Chagnon; Yagmur Gizem Cinar; Éric Gaussier",
    "corresponding_authors": "",
    "abstract": "On a wide range of natural language processing and information retrieval tasks, transformer-based models, particularly pre-trained language models like BERT, have demonstrated tremendous effectiveness. Due to the quadratic complexity of the self-attention mechanism, however, such models have difficulties processing long documents. Recent works dealing with this issue include truncating long documents, in which case one loses potential relevant information, segmenting them into several passages, which may lead to miss some information and high computational complexity when the number of passages is large, or modifying the self-attention mechanism to make it sparser as in sparse-attention models, at the risk again of missing some information. We follow here a slightly different approach in which one first selects key blocks of a long document by local query-block pre-ranking, and then few blocks are aggregated to form a short document that can be processed by a model such as BERT. Experiments conducted on standard Information Retrieval datasets demonstrate the effectiveness of the proposed approach.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3214374241",
    "type": "article"
  },
  {
    "title": "Follow the Timeline! Generating an Abstractive and Extractive Timeline Summary in Chronological Order",
    "doi": "https://doi.org/10.1145/3517221",
    "publication_date": "2022-03-05",
    "publication_year": 2022,
    "authors": "Xiuying Chen; Mingzhe Li; Shen Gao; Zhangming Chan; Dongyan Zhao; Xin Gao; Xiangliang Zhang; Rui Yan",
    "corresponding_authors": "",
    "abstract": "Today, timestamped web documents related to a general news query flood the Internet, and timeline summarization targets this concisely by summarizing the evolution trajectory of events along the timeline. Unlike traditional document summarization, timeline summarization needs to model the time series information of the input events and summarize important events in chronological order. To tackle this challenge, in this article we propose our Unified Timeline Summarizer, which can generate abstractive and extractive timeline summaries in time order. Concretely, in the encoder part, we propose a graph-based event encoder that relates multiple events according to their content dependency and learns a global representation of each event. In the decoder part, to ensure the chronological order of the abstractive summary, we propose to extract the feature of event-level attention in its generation process with sequential information retained and use it to simulate the evolutionary attention of the ground truth summary. The event-level attention can also be used to assist in extracting a summary, where the extracted summary also comes in time sequence. We augment the previous Chinese large-scale timeline summarization dataset and collect a new English timeline dataset. Extensive experiments conducted on these datasets and on the out-of-domain Timeline 17 dataset show that our Unified Timeline Summarizer achieves state-of-the-art performance in terms of both automatic and human evaluations. 1",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4221060168",
    "type": "article"
  },
  {
    "title": "Personal or General? A Hybrid Strategy with Multi-factors for News Recommendation",
    "doi": "https://doi.org/10.1145/3555373",
    "publication_date": "2022-08-12",
    "publication_year": 2022,
    "authors": "Zhenya Huang; Binbin Jin; Hongke Zhao; Qi Liu; Defu Lian; Bao Tengfei; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "News recommender systems have become an effective manner to help users make decisions by suggesting the potential news that users may click and read, which has shown the proliferation nowadays. Many representative algorithms made great efforts to discover users’ preferences from the histories for triggering news recommendations. However, there exist some limitations due to the following two main issues. First, they mainly rely on the sufficient user data, which cannot well capture users’ temporal interests with very limited records. Second, always perceiving users’ histories for recommendation may ignore some important news (e.g., breaking news). In this article, we propose a novel Multi-factors Fusion model for news recommendation by integrating both user-dependent preference effect and user-independent timeliness effect together. First, to track the preference of a certain user, we decompose her reading history into two user-related factors, including the long-term habit and the short-term interest. Specifically, we extract her persistent habit by exploring the category effect of news that she focuses on from her whole records. Then, we characterize her temporary interests by proposing a recurrent neural network of analyzing the homogeneous relations between her latest clicked news and the candidate ones. Second, to describe the user-independent news timeliness effect, we propose a novel survival analysis model to estimate the instantaneous click probability of a certain news as the occurring probability of an event, where much sensational news tends to be picked out. Last, we fuse all effects to determine the probability of a user clicking on a certain news under the independent event assumption. We conduct extensive experiments on two real-world datasets. Experimental results demonstrate that our model can generate better news recommendations on both general scenario and cold-start scenario.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4291144017",
    "type": "article"
  },
  {
    "title": "Examining User Heterogeneity in Digital Experiments",
    "doi": "https://doi.org/10.1145/3578931",
    "publication_date": "2023-01-12",
    "publication_year": 2023,
    "authors": "Sriram Somanchi; Ahmed Abbasi; Ken Kelley; David G. Dobolyi; Ted Tao Yuan",
    "corresponding_authors": "",
    "abstract": "Digital experiments are routinely used to test the value of a treatment relative to a status quo control setting — for instance, a new search relevance algorithm for a website or a new results layout for a mobile app. As digital experiments have become increasingly pervasive in organizations and a wide variety of research areas, their growth has prompted a new set of challenges for experimentation platforms. One challenge is that experiments often focus on the average treatment effect (ATE) without explicitly considering differences across major sub-groups — heterogeneous treatment effect (HTE). This is especially problematic because ATEs have decreased in many organizations as the more obvious benefits have already been realized. However, questions abound regarding the pervasiveness of user HTEs and how best to detect them. We propose a framework for detecting and analyzing user HTEs in digital experiments. Our framework combines an array of user characteristics with double machine learning. Analysis of 27 real-world experiments spanning 1.76 billion sessions and simulated data demonstrates the effectiveness of our detection method relative to existing techniques. We also find that transaction, demographic, engagement, satisfaction, and lifecycle characteristics exhibit statistically significant HTEs in 10% to 20% of our real-world experiments, underscoring the importance of considering user heterogeneity when analyzing experiment results, otherwise personalized features and experiences cannot happen, thus reducing effectiveness. In terms of the number of experiments and user sessions, we are not aware of any study that has examined user HTEs at this scale. Our findings have important implications for information retrieval, user modeling, platforms, and digital experience contexts, in which online experiments are often used to evaluate the effectiveness of design artifacts.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4315705277",
    "type": "article"
  },
  {
    "title": "A Dense Representation Framework for Lexical and Semantic Matching",
    "doi": "https://doi.org/10.1145/3582426",
    "publication_date": "2023-01-31",
    "publication_year": 2023,
    "authors": "Sheng-Chieh Lin; Jimmy Lin",
    "corresponding_authors": "",
    "abstract": "Lexical and semantic matching capture different successful approaches to text retrieval and the fusion of their results has proven to be more effective and robust than either alone. Prior work performs hybrid retrieval by conducting lexical and semantic matching using different systems (e.g., Lucene and Faiss, respectively) and then fusing their model outputs. In contrast, our work integrates lexical representations with dense semantic representations by densifying high-dimensional lexical representations into what we call low-dimensional dense lexical representations (DLRs). Our experiments show that DLRs can effectively approximate the original lexical representations, preserving effectiveness while improving query latency. Furthermore, we can combine dense lexical and semantic representations to generate dense hybrid representations (DHRs) that are more flexible and yield faster retrieval compared to existing hybrid techniques. In addition, we explore jointly training lexical and semantic representations in a single model and empirically show that the resulting DHRs are able to combine the advantages of the individual components. Our best DHR model is competitive with state-of-the-art single-vector and multi-vector dense retrievers in both in-domain and zero-shot evaluation settings. Furthermore, our model is both faster and requires smaller indexes, making our dense representation framework an attractive approach to text retrieval. Our code is available at https://github.com/castorini/dhr .",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4318617465",
    "type": "article"
  },
  {
    "title": "FASTER: A Dynamic Fairness-assurance Strategy for Session-based Recommender Systems",
    "doi": "https://doi.org/10.1145/3586993",
    "publication_date": "2023-03-14",
    "publication_year": 2023,
    "authors": "Yao Wu; Jian Cao; Guandong Xu",
    "corresponding_authors": "",
    "abstract": "When only users’ preferences and interests are considered by a recommendation algorithm, it will lead to the severe long-tail problem over items. Therefore, the unfair exposure phenomenon of recommended items caused by this problem has attracted widespread attention in recent years. For the first time, we reveal the fact that there is a more serious unfair exposure problem in session-based recommender systems (SRSs), which learn the short-term and dynamic preferences of users from anonymous sessions. Considering the fact that in SRSs, recommendations are provided multiple times and item exposures are accumulated over interactions in a session, we define new metrics both for the fairness of item exposure and recommendation quality among sessions. Moreover, we design a dynamic F airness- A ssurance ST rategy for s E ssion-based R ecommender systems ( FASTER ). FASTER is a post-processing strategy that tries to keep a balance between item exposure fairness and recommendation quality. It can also maintain the fairness of recommendation quality among sessions. The effectiveness of FASTER is verified on three real-world datasets and five original algorithms. The experiment results show that FASTER can generally reduce the unfair exposure of different session-based recommendation algorithms while still ensuring a high level of recommendation quality.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4324157320",
    "type": "article"
  },
  {
    "title": "Invariant Node Representation Learning under Distribution Shifts with Multiple Latent Environments",
    "doi": "https://doi.org/10.1145/3604427",
    "publication_date": "2023-06-14",
    "publication_year": 2023,
    "authors": "Haoyang Li; Ziwei Zhang; Xin Wang; Wenwu Zhu",
    "corresponding_authors": "",
    "abstract": "Node representation learning methods, such as graph neural networks, show promising results when testing and training graph data come from the same distribution. However, the existing approaches fail to generalize under distribution shifts when the nodes reside in multiple latent environments. How to learn invariant node representations to handle distribution shifts with multiple latent environments remains unexplored. In this article, we propose a novel I nvariant N ode representation L earning (INL) approach capable of generating invariant node representations based on the invariant patterns under distribution shifts with multiple latent environments by leveraging the invariance principle. Specifically, we define invariant and variant patterns as ego-subgraphs of each node and identify the invariant ego-subgraphs through jointly accounting for node features and graph structures. To infer the latent environments of nodes, we propose a contrastive modularity-based graph clustering method based on the variant patterns. We further propose an invariant learning module to learn node representations that can generalize to distribution shifts. We theoretically show that our proposed method can achieve guaranteed performance under distribution shifts. Extensive experiments on both synthetic and real-world node classification benchmarks demonstrate that our method greatly outperforms state-of-the-art baselines under distribution shifts.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4380433640",
    "type": "article"
  },
  {
    "title": "An Approximate Algorithm for Maximum Inner Product Search over Streaming Sparse Vectors",
    "doi": "https://doi.org/10.1145/3609797",
    "publication_date": "2023-07-17",
    "publication_year": 2023,
    "authors": "Sebastian Bruch; Franco Maria Nardini; Amir Ingber; Edo Liberty",
    "corresponding_authors": "",
    "abstract": "Maximum Inner Product Search or top- k retrieval on sparse vectors is well understood in information retrieval, with a number of mature algorithms that solve it exactly. However, all existing algorithms are tailored to text and frequency-based similarity measures. To achieve optimal memory footprint and query latency, they rely on the near stationarity of documents and on laws governing natural languages. We consider, instead, a setup in which collections are streaming—necessitating dynamic indexing—and where indexing and retrieval must work with arbitrarily distributed real-valued vectors. As we show, existing algorithms are no longer competitive in this setup, even against naïve solutions. We investigate this gap and present a novel approximate solution, called Sinnamon , that can efficiently retrieve the top- k results for sparse real valued vectors drawn from arbitrary distributions. Notably, Sinnamon offers levers to trade off memory consumption, latency, and accuracy, making the algorithm suitable for constrained applications and systems. We give theoretical results on the error introduced by the approximate nature of the algorithm and present an empirical evaluation of its performance on two hardware platforms and synthetic and real-valued datasets. We conclude by laying out concrete directions for future research on this general top- k retrieval problem over sparse vectors.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4384523577",
    "type": "article"
  },
  {
    "title": "Training Robust Deep Collaborative Filtering Models via Adversarial Noise Propagation",
    "doi": "https://doi.org/10.1145/3589000",
    "publication_date": "2023-08-18",
    "publication_year": 2023,
    "authors": "Hai Chen; Fulan Qian; Chang Liu; Yanping Zhang; Hang Su; Shu Zhao",
    "corresponding_authors": "",
    "abstract": "The recommendation performance of deep collaborative filtering models drops sharply under imperceptible adversarial perturbations. Some methods promote the robustness of recommendation systems by adversarial training. However, these methods only study shallow models and lack the exploration of deep models. Furthermore, the way these methods add adversarial noise to the weight parameters of users and items is not fully applicable to deep collaborative filtering models, because the adversarial noise is not sufficient to fully affect its network structure with multiple hidden layers. In this article, we propose a novel adversarial training framework, Random Layer-wise Adversarial Training (RAT), which trains a robust deep collaborative filtering model via adversarial noise propagation. Specifically, we inject adversarial noise into the output of the hidden layer in a random layer-wise manner. The adversarial noise propagates forward from the injected position to obtain more flexible model parameters during the adversarial training process. We validate the effectiveness of RAT on multilayer perceptron (MLP) and implement RAT on MLP-based and convolutional neural networks-based deep collaborative filtering models. Experiments on three publicly available datasets show that the deep collaborative filtering model trained by RAT not only defends against adversarial noise but also guarantees recommendation performance.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4385979104",
    "type": "article"
  },
  {
    "title": "Electronic mail as a coalition-building information technology",
    "doi": "https://doi.org/10.1145/267954.267958",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "Celia T. Romm; Nava Pliskin",
    "corresponding_authors": "",
    "abstract": "One of the most intriguing lines of research within the literature on diffusion of information technologies (IT) is the study of the power and politics of this process. The major objective of this article is to build on the work of Kling and Markus on power and IT, by extending their perspective to email. To demonstrate how email can be used for political purposes within an organizational context, a case study is presented. The case study describes a series of events which took place in a university. In the case, email was used by a group of employees to stage a rebellion against the university president. The discussion demonstrates that email features make it amenable to a range of political uses. The article is concluded with a discussion of the implications from this case to email research and practice.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W1982535335",
    "type": "article"
  },
  {
    "title": "A visual retrieval environment for hypermedia information systems",
    "doi": "https://doi.org/10.1145/214174.214175",
    "publication_date": "1996-01-11",
    "publication_year": 1996,
    "authors": "Dario Lucarella; Antonella Zanzi",
    "corresponding_authors": "",
    "abstract": "We present a graph-based object model that may be used as a uniform framework for direct manipulation of multimedia information. After an introduction motivating the need for abstraction and structuring mechanisms in hypermedia systems, we introduce the data model and the notion of perspective, a form of data abstraction that acts as a user interface to the system, providing control over the visibility of the objects and their properties. A perspective is defined to include an intension and an extension. The intension is defined in terms of a pattern, a subgraph of the schema graph, and the extension is the set of pattern-matching instances. Perspectives, as well as database schema and instances, are graph structures that can be manipulated in various ways. The resulting uniform approach is well suited to a visual interface. A visual interface for complex information systems provides high semantic power, thus exploiting the semantic expressibility of the underlying data model, while maintaining ease of interaction with the system. In this way, we reach the goal of decreasing cognitive load on the user, with the additional advantage of always maintaining the same interaction style. We present a visual retrieval environment that effectively combines filtering, browsing, and navigation to provide an integrated view of the retrieval problem. Design and implementation issues are outlined for MORE (Multimedia Object Retrieval Environment), a prototype system relying on the proposed model. The focus is on the main user interface functionalities, and actual interaction sessions are presented including schema creation, information loading, and information retrieval.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W1968071216",
    "type": "article"
  },
  {
    "title": "Customizing information capture and access",
    "doi": "https://doi.org/10.1145/239041.239048",
    "publication_date": "1997-01-01",
    "publication_year": 1997,
    "authors": "Daniela Rus; Devika Subramanian",
    "corresponding_authors": "",
    "abstract": "This article presents a customizable architecture for software agents that capture and access information in large, heterogeneous, distributed electronic repositories. The key idea is to exploit underlying structure at various levels of granularity to build high-level indices with task-specific interpretations. Information agents construct such indices and are configured as a network of reusable modules called structure detectors and segmenters. We illustrate our architecture with the design and implementation of smart information filters in two contexts: retrieving stock market data from Internet newsgroups and retrieving technical reports from Internet FTP sites.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2055136145",
    "type": "article"
  },
  {
    "title": "Access control for large collections",
    "doi": "https://doi.org/10.1145/248625.248652",
    "publication_date": "1997-04-01",
    "publication_year": 1997,
    "authors": "H. M. Gladney",
    "corresponding_authors": "H. M. Gladney",
    "abstract": "Efforts to place vast information resources at the fingertips of each individual in large user populations must be balanced by commensurate attention to information protection. For distributed systems with less-structured tasks, more-diversified information, and a heterogeneous user set, the computing system must administer enterprise-chosen access control policies. One kind of resource is a digital library that emulates massive collections of paper and other physical media for clerical, engineering, and cultural applications. This article considers the security requirements for such libraries and proposes an access control method that mimics organizational practice by combining a subject tree with ad hoc role granting that controls privileges for many operations independently, that treats (all but one) privileged roles (e.g., auditor, security officer) like every other individual authorization, and that binds access control information to objects indirectly for scaling, flexibility, and reflexive protection. We sketch a realization and show that it will perform well, generalizes many deployed proposed access control policies, and permits individual data centers to implement other models economically and without disruption.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W1969965528",
    "type": "article"
  },
  {
    "title": "A highly scalable and effective method for metasearch",
    "doi": "https://doi.org/10.1145/502115.502120",
    "publication_date": "2001-07-01",
    "publication_year": 2001,
    "authors": "Weiyi Meng; Zonghuan Wu; Clement Yu; Zhuogang Li",
    "corresponding_authors": "",
    "abstract": "A metasearch engine is a system that supports unified access to multiple local search engines. Database selection is one of the main challenges in building a large-scale metasearch engine. The problem is to efficiently and accurately determine a small number of potentially useful local search engines to invoke for each user query. In order to enable accurate selection, metadata that reflect the contents of each search engine need to be collected and used. This article proposes a highly scalable and accurate database selection method. This method has several novel features. First, the metadata for representing the contents of all search engines are organized into a single integrated representative. Such a representative yields both computational efficiency and storage efficiency. Second, the new selection method is based on a theory for ranking search engines optimally. Experimental results indicate that this new method is very effective. An operational prototype system has been built based on the proposed approach.",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2129974412",
    "type": "article"
  },
  {
    "title": "The impact on retrieval effectiveness of skewed frequency distributions",
    "doi": "https://doi.org/10.1145/326440.326447",
    "publication_date": "1999-10-01",
    "publication_year": 1999,
    "authors": "Mark Sanderson; C. J. van Rijsbergen",
    "corresponding_authors": "",
    "abstract": "We present an analysis of word senses that provides a fresh insight into the impact of word ambiguity on retrieval effectiveness with potential broader implications for other processes of information retrieval. Using a methodology of forming artifically ambiguous words, known as pseudowords, and through reference to other researchers' work, the analysis illustrates that the distribution of the frequency of occurrance of the senses of a word plays a strong role in ambiguity's impact of effectiveness. Further investigation shows that this analysis may also be applicable to other processes of retrieval, such as Cross Language Information Retrieval, query expansion, retrieval of OCR'ed texts, and stemming. The analysis appears to provide a means of explaining, at least in part, reasons for the processes' impact (or lack of it) on effectiveness.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W1983179002",
    "type": "article"
  },
  {
    "title": "Information system behavior specification by high level Petri nets",
    "doi": "https://doi.org/10.1145/237496.237498",
    "publication_date": "1996-10-01",
    "publication_year": 1996,
    "authors": "Andreas Oberweis; Peter Sander",
    "corresponding_authors": "",
    "abstract": "The specification of an information system should include a description of structural system aspects as well as a description of the system behavior. In this article, we show how this can be achieved by high-level Petri nets—namely, the so-called NR/T-nets (Nested-Relation/Transition Nets). In NR/T-nets, the structural part is modeled by nested relations, and the behavioral part is modeled by a novel Petri net formalism. Each place of a net represents a nested relation scheme, and the marking of each place is given as a nested relation of the respective type. Insert and delete operations in a nested relational database (NF2-database) are expressed by transitions in a net. These operations may operate not only on whole tuples of a given relation, but also on “subtuples” of existing tuples. The arcs of a net are inscribed with so-called Filter Tables, which allow (together with an optional logical expression as transition inscription) conditions to be formulated on the specified (sub-) tuples. The occurrence rule for NR/T-net transitions is defined by the operations union, intersection, and “negative” in lattices of nested relations. The structure of an NR/T-net, together with the occurrence rule, defines classes of possible information system procedures, i.e., sequences of (possibly concurrent) operations in an information system.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2092663181",
    "type": "article"
  },
  {
    "title": "Preference-based decision making for cooperative knowledge-based systems",
    "doi": "https://doi.org/10.1145/185462.185484",
    "publication_date": "1994-10-01",
    "publication_year": 1994,
    "authors": "Stephen T.C. Wong",
    "corresponding_authors": "Stephen T.C. Wong",
    "abstract": "Recent advances in cooperative knowledge-based systems (CKBS) offer significant promise for intelligent interaction between multiple AI systems for solving larger, more complex problems. In this paper, we propose a logical, qualitative problem-solving scheme for CKBS that uses social choice theory as a formal basis for making joint decisions and promoting conflict resolution. This scheme consists of three steps: (1) the selection of decision criteria and competing alternatives, (2) the formation of preference profiles and collective choices, and (3) the negotiation among agents as conflicts arise in group decision making. In this paper, we focus on the computational mechanisms developed to support steps (2) and (3) of the scheme. In addition, the practicality of the scheme is illustrated with examples taken from a working prototype dealing with collaborative structural design of buildings.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W1983257030",
    "type": "article"
  },
  {
    "title": "A general explanation component for conceptual modeling in CASE environments",
    "doi": "https://doi.org/10.1145/230538.230560",
    "publication_date": "1996-07-01",
    "publication_year": 1996,
    "authors": "Jon Atle Gulla",
    "corresponding_authors": "Jon Atle Gulla",
    "abstract": "In information systems engineering, conceptual models are constructed to assess existing information systems and work out requirements for new ones. As these models serve as a means for communication between customers and developers, it is paramount that both parties understand the models, as well as that the models form a proper basis for the subsequent design and implementation of the systems. New CASE environments are now experimenting with formal modeling languages and various techniques for validating conceptual models, though it seems difficult to come up with a technique that handles the linguistic barriers between the parties involved in a satisfactory manner. In this article, we discuss the theoretical basis of an explanation component implemented for the PPP CASE environment. This component integrates other validation techniques and provides a very flexible natural-language interface to complex model information. It describes properties of the modeling language and the conceptual models in terms familiar to users, and the explanations can be combined with graphical model views. When models are executed, it can justify requested inputs and explain computed outputs by relating trace information to properties of the models.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2023527059",
    "type": "article"
  },
  {
    "title": "The model-assisted global query system for multiple databases in distributed enterprises",
    "doi": "https://doi.org/10.1145/237496.237499",
    "publication_date": "1996-10-01",
    "publication_year": 1996,
    "authors": "Waiman Cheung; Cheng Hsu",
    "corresponding_authors": "",
    "abstract": "Today's enterprises typically employ multiple information systems, which are independently developed, locally administered, and different in logical or physical designs. Therefore, a fundamental challenge in enterprise information management is the sharing of information for enterprise users across organizational boundaries; this requires a global query system capable of providing on-line intelligent assistance to users. Conventional technologies, such as schema-based query languages and hard-coded schema integration, are not sufficient to solve this problem. This article develops a new approach, a “model-assisted global query system,” that utilizes an on-line repository of enterprise metadata—the Metadatabase—to facilitate global query formulation and processing with certain desirable properties such as adaptiveness and open-systems architecture. A definitional model characterizing the various classes and roles of the required metadata as knowledge for the system is presented. The significance of possessing this knowledge (via a Metadatabase) toward improving the global query capabilities available previously is analyzed. On this basis, a direct method using model traversal and a query language using global model constructs are developed along with other new methods required for this approach. It is then tested through a prototype system in a computer-integrated manufacturing (CIM) setting.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2109396805",
    "type": "article"
  },
  {
    "title": "Document architecture and text formatting",
    "doi": "https://doi.org/10.1145/4656.4657",
    "publication_date": "1985-10-01",
    "publication_year": 1985,
    "authors": "A.J.H.M. Peels; Norbert J. M. Janssen; Wop Nawijn",
    "corresponding_authors": "",
    "abstract": "The formalization of the architecture of documents and text formatting are the central issues of this paper. Besides a fundamental and theoretical approach toward these topics, an overview is presented of the COBATEF system. The COBATEF system is a context-based text formatting system, for which a software, as well as a hardware, implementation is available. A unique feature of the system is its automatic text-element recognition mechanism, which is context based and consequently takes advantage of the implicit structure of text. A predefined layout for each type of text element then opens the way for a fully automatic text-processing system in which user control information can be reduced to an absolute minimum.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W1989399140",
    "type": "article"
  },
  {
    "title": "Augmenting thesauri for information systems",
    "doi": "https://doi.org/10.1145/42196.42246",
    "publication_date": "1987-10-01",
    "publication_year": 1987,
    "authors": "Roy Rada; Brian K. Martin",
    "corresponding_authors": "",
    "abstract": "A thesaurus can be a critical component of an office information system. Access to various sets of documents can be facilitated by thesauri and by the connections that are made among thesauri. In the projects described in this paper, the thesauri are stored and manipulated through a relational database management system. The system detects inheritance properties in a thesaurus and uses them to guide a human expert in decisions about how to augment the thesaurus. New strategies will extend our ability to augment existing thesauri.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2063032168",
    "type": "article"
  },
  {
    "title": "Details of command-language keystrokes",
    "doi": "https://doi.org/10.1145/357431.357434",
    "publication_date": "1983-04-01",
    "publication_year": 1983,
    "authors": "Robert B. Allen; Marge Scerbo",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Details of command-language keystrokes Authors: Robert B. Allen 3D-443, Bell Laboratories, Murray Hill, NJ 3D-443, Bell Laboratories, Murray Hill, NJView Profile , M. W. Scerbo Department of Psychology, University of Cincinnati, Cincinnati, OH Department of Psychology, University of Cincinnati, Cincinnati, OHView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 2pp 159–178https://doi.org/10.1145/357431.357434Published:01 April 1983Publication History 20citation471DownloadsMetricsTotal Citations20Total Downloads471Last 12 Months15Last 6 weeks7 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W1965552771",
    "type": "article"
  },
  {
    "title": "Trustworthy 100-year digital objects",
    "doi": "https://doi.org/10.1145/1080343.1080346",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "H. M. Gladney; Raymond A. Lorie",
    "corresponding_authors": "",
    "abstract": "How can an author store digital information so that it will be reliably intelligible, even years later when he or she is no longer available to answer questions? Methods that might work are not good enough; what is preserved today should be reliably intelligible whenever someone wants it. Prior proposals fail because they generally confound saved data with irrelevant details of today's information technology---details that are difficult to define, extract, and save completely and accurately.We use a virtual machine to represent and eventually to render any data whatsoever. We focus on a case of intermediate difficulty---an executable procedure---and identify a variant for every other data type.This solution might be more elaborate than needed to render some text, image, audio, or video data. Simple data can be preserved as representations using well-known standards. We sketch practical methods for files ranging from simple structures to those containing computer programs, treating simple cases here and deferring complex cases for future work. Enough of the complete solution is known to enable practical aggressive preservation programs today.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W1989438115",
    "type": "article"
  },
  {
    "title": "A knowledge-based message management system",
    "doi": "https://doi.org/10.1145/27641.27642",
    "publication_date": "1987-07-01",
    "publication_year": 1987,
    "authors": "S. K. Chang; Linda Leung",
    "corresponding_authors": "",
    "abstract": "The design approach of a knowledge-based message management system is described. A linguistic message filter is used to filter out junk messages. Relevant messages are then processed by an expert system, driven by user-defined alerter rules. An alerter rule base for a secretarial office is illustrated. Further research topics in knowledge-base design, evaluation, and learning are also discussed.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2058858157",
    "type": "article"
  },
  {
    "title": "Understanding the office: A social-analytic perspective",
    "doi": "https://doi.org/10.1145/9760.9763",
    "publication_date": "1986-12-01",
    "publication_year": 1986,
    "authors": "Rudy Hirschheim",
    "corresponding_authors": "Rudy Hirschheim",
    "abstract": "In order to apply office automation in a meaningful fashion, it is apparent that some understanding of the office is necessary. Most descriptive studies of the office have placed great emphasis on manifest office actions, suggesting that offices are the embodiment of these actions. The meanings of these actions or tasks, however, have been given scant attention. There exist a number of office activity or task taxonomies, but they do little more than provide a simple and limited structure through which to conceive of an office. From a social-analytic perspective this appears to be overly simplistic and misses the richness of social action in an office. Focusing on the overt and manifest aspects of the office may very well lead to its misrepresentation. This paper takes a critical look at the way offices are conceived in the office automation literature and suggests alternatives that may provide a better understanding of the real functions of an office.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2067852415",
    "type": "article"
  },
  {
    "title": "Usage patterns in an integrated voice and data communications system",
    "doi": "https://doi.org/10.1145/4229.4231",
    "publication_date": "1985-07-01",
    "publication_year": 1985,
    "authors": "Robert T. Nicholson",
    "corresponding_authors": "Robert T. Nicholson",
    "abstract": "Recently, office communication systems have begun to integrate voice recordings into their mail and data communications facilities. The study of usage patterns on one such system shows that voice is used for informal, person-to-person communications, as opposed to the formal content of typed messages. Voice messages are generally sent to fewer recipients (often only one), and sometimes replace face-to-face meetings.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2076986034",
    "type": "article"
  },
  {
    "title": "Logical routing specification in office information systems",
    "doi": "https://doi.org/10.1145/2275.2278",
    "publication_date": "1984-10-01",
    "publication_year": 1984,
    "authors": "Murray S. Mazer; Frederick H. Lochovsky",
    "corresponding_authors": "",
    "abstract": "article Free AccessLogical routing specification in office information systems Authors: Murray S. Mazer Univ. of Toronto, Toronto, Ont., Canada Univ. of Toronto, Toronto, Ont., CanadaView Profile , Frederick H. Lochovsky Univ. of Toronto, Toronto, Ont., Canada Univ. of Toronto, Toronto, Ont., CanadaView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 4pp 303–330https://doi.org/10.1145/2275.2278Published:01 October 1984Publication History 27citation397DownloadsMetricsTotal Citations27Total Downloads397Last 12 Months20Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2102871293",
    "type": "article"
  },
  {
    "title": "Probabilistic models for answer-ranking in multilingual question-answering",
    "doi": "https://doi.org/10.1145/1777432.1777439",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Jeongwoo Ko; Luo Si; Eric Nyberg; Teruko Mitamura",
    "corresponding_authors": "",
    "abstract": "This article presents two probabilistic models for answering ranking in the multilingual question-answering (QA) task, which finds exact answers to a natural language question written in different languages. Although some probabilistic methods have been utilized in traditional monolingual answer-ranking, limited prior research has been conducted for answer-ranking in multilingual question-answering with formal methods. This article first describes a probabilistic model that predicts the probabilities of correctness for individual answers in an independent way. It then proposes a novel probabilistic method to jointly predict the correctness of answers by considering both the correctness of individual answers as well as their correlations. As far as we know, this is the first probabilistic framework that proposes to model the correctness and correlation of answer candidates in multilingual question-answering and provide a novel approach to design a flexible and extensible system architecture for answer selection in multilingual QA. An extensive set of experiments were conducted to show the effectiveness of the proposed probabilistic methods in English-to-Chinese and English-to-Japanese cross-lingual QA, as well as English, Chinese, and Japanese monolingual QA using TREC and NTCIR questions.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2152367169",
    "type": "article"
  },
  {
    "title": "STEvent",
    "doi": "https://doi.org/10.1145/1777432.1777438",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Hady W. Lauw; Ee‐Peng Lim; HweeHwa Pang; Teck-Tim Tan",
    "corresponding_authors": "",
    "abstract": "Spatio-temporal data concerning the movement of individuals over space and time contains latent information on the associations among these individuals. Sources of spatio-temporal data include usage logs of mobile and Internet technologies. This article defines a spatio-temporal event by the co-occurrences among individuals that indicate potential associations among them. Each spatio-temporal event is assigned a weight based on the precision and uniqueness of the event. By aggregating the weights of events relating two individuals, we can determine the strength of association between them. We conduct extensive experimentation to investigate both the efficacy of the proposed model as well as the computational complexity of the proposed algorithms. Experimental results on three real-life spatio-temporal datasets cross-validate each other, lending greater confidence on the reliability of our proposed model.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1982303424",
    "type": "article"
  },
  {
    "title": "Learning with click graph for query intent classification",
    "doi": "https://doi.org/10.1145/1777432.1777435",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Xiao Li; Ye‐Yi Wang; Dou Shen; Alex Acero",
    "corresponding_authors": "",
    "abstract": "Topical query classification, as one step toward understanding users' search intent, is gaining increasing attention in information retrieval. Previous works on this subject primarily focused on enrichment of query features, for example, by augmenting queries with search engine results. In this work, we investigate a completely orthogonal approach—instead of improving feature representation, we aim at drastically increasing the amount of training data. To this end, we propose two semisupervised learning methods that exploit user click-through data. In one approach, we infer class memberships of unlabeled queries from those of labeled ones according to their proximities in a click graph; and then use these automatically labeled queries to train classifiers using query terms as features. In a second approach, click graph learning and query classifier training are conducted jointly with an integrated objective. Our methods are evaluated in two applications, product intent and job intent classification. In both cases, we expand the training data by over two orders of magnitude, leading to significant improvements in classification performance. An additional finding is that with a large amount of training data obtained in this fashion, a classifier based on simple query term features can outperform those using state-of-the-art, augmented features.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2084261737",
    "type": "article"
  },
  {
    "title": "A Probabilistic Model to Combine Tags and Acoustic Similarity for Music Retrieval",
    "doi": "https://doi.org/10.1145/2180868.2180870",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "Riccardo Miotto; Nicola Orio",
    "corresponding_authors": "",
    "abstract": "The rise of the Internet has led the music industry to a transition from physical media to online products and services. As a consequence, current online music collections store millions of songs and are constantly being enriched with new content. This has created a need for music technologies that allow users to interact with these extensive collections efficiently and effectively. Music search and discovery may be carried out using tags, matching user interests and exploiting content-based acoustic similarity. One major issue in music information retrieval is how to combine such noisy and heterogeneous information sources in order to improve retrieval effectiveness. With this aim in mind, the article explores a novel music retrieval framework based on combining tags and acoustic similarity through a probabilistic graph-based representation of a collection of songs. The retrieval function highlights the path across the graph that most likely observes a user query and is used to improve state-of-the-art music search and discovery engines by delivering more relevant ranking lists. Indeed, by means of an empirical evaluation, we show how the proposed approach leads to better performances than retrieval strategies which rank songs according to individual information sources alone or which use a combination of them.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2115551677",
    "type": "article"
  },
  {
    "title": "Aggregation Methods for Proximity-Based Opinion Retrieval",
    "doi": "https://doi.org/10.1145/2382438.2382445",
    "publication_date": "2012-11-01",
    "publication_year": 2012,
    "authors": "Shima Gerani; Mark Carman; Fábio Crestani",
    "corresponding_authors": "",
    "abstract": "The enormous amount of user-generated data available on the Web provides a great opportunity to understand, analyze, and exploit people’s opinions on different topics. Traditional Information Retrieval methods consider the relevance of documents to a topic but are unable to differentiate between subjective and objective documents. Opinion retrieval is a retrieval task in which not only the relevance of a document to the topic is important but also the amount of opinion expressed in the document about the topic. In this article, we address the blog post opinion retrieval task and propose methods that rank blog posts according to their relevance and opinionatedness toward a topic. We propose estimating the opinion density at each position in a document using a general opinion lexicon and kernel density functions. We propose and investigate different models for aggregating the opinion density at query terms positions to estimate the opinion score of every document. We then combine the opinion score with the relevance score based on a probabilistic justification. Experimental results on the BLOG06 dataset show that the proposed method provides significant improvement over the standard TREC baselines. The proposed models also achieve much higher performance compared to all state of the art methods.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2050877003",
    "type": "article"
  },
  {
    "title": "Sibyl, a factoid question-answering system for spoken documents",
    "doi": "https://doi.org/10.1145/2328967.2328972",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Pere R. Comas; Jordi Turmo; Lluı́s Màrquez",
    "corresponding_authors": "",
    "abstract": "In this article, we present a factoid question-answering system, Sibyl, specifically tailored for question answering (QA) on spoken-word documents. This work explores, for the first time, which techniques can be robustly adapted from the usual QA on written documents to the more difficult spoken document scenario. More specifically, we study new information retrieval (IR) techniques designed or speech, and utilize several levels of linguistic information for the speech-based QA task. These include named-entity detection with phonetic information, syntactic parsing applied to speech transcripts, and the use of coreference resolution. Sibyl is largely based on supervised machine-learning techniques, with special focus on the answer extraction step, and makes little use of handcrafted knowledge. Consequently, it should be easily adaptable to other domains and languages. Sibyl and all its modules are extensively evaluated on the European Parliament Plenary Sessions English corpus, comparing manual with automatic transcripts obtained by three different automatic speech recognition (ASR) systems that exhibit significantly different word error rates. This data belongs to the CLEF 2009 track for QA on speech transcripts. The main results confirm that syntactic information is very useful for learning to rank question candidates, improving results on both manual and automatic transcripts, unless the ASR quality is very low. At the same time, our experiments on coreference resolution reveal that the state-of-the-art technology is not mature enough to be effectively exploited for QA with spoken documents. Overall, the performance of Sibyl is comparable or better than the state-of-the-art on this corpus, confirming the validity of our approach.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2060951214",
    "type": "article"
  },
  {
    "title": "An Online Learning Framework for Refining Recency Search Results with User Click Feedback",
    "doi": "https://doi.org/10.1145/2382438.2382439",
    "publication_date": "2012-11-01",
    "publication_year": 2012,
    "authors": "Taesup Moon; Wei Chu; Lihong Li; Zhaohui Zheng; Yi Chang",
    "corresponding_authors": "",
    "abstract": "Traditional machine-learned ranking systems for Web search are often trained to capture stationary relevance of documents to queries, which have limited ability to track nonstationary user intention in a timely manner. In recency search, for instance, the relevance of documents to a query on breaking news often changes significantly over time, requiring effective adaptation to user intention. In this article, we focus on recency search and study a number of algorithms to improve ranking results by leveraging user click feedback. Our contributions are threefold. First, we use commercial search engine sessions collected in a random exploration bucket for reliable offline evaluation of these algorithms, which provides an unbiased comparison across algorithms without online bucket tests. Second, we propose an online learning approach that reranks and improves the search results for recency queries near real-time based on user clicks. This approach is very general and can be combined with sophisticated click models. Third, our empirical comparison of a dozen algorithms on real-world search data suggests importance of a few algorithmic choices in these applications, including generalization across different query-document pairs, specialization to popular queries, and near real-time adaptation of user clicks for reranking.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2107170340",
    "type": "article"
  },
  {
    "title": "Search Result Diversification in Short Text Streams",
    "doi": "https://doi.org/10.1145/3057282",
    "publication_date": "2017-07-17",
    "publication_year": 2017,
    "authors": "Shangsong Liang; Emine Yılmaz; Hong Shen; Maarten de Rijke; W. Bruce Croft",
    "corresponding_authors": "",
    "abstract": "We consider the problem of search result diversification for streams of short texts. Diversifying search results in short text streams is more challenging than in the case of long documents, as it is difficult to capture the latent topics of short documents. To capture the changes of topics and the probabilities of documents for a given query at a specific time in a short text stream, we propose a dynamic Dirichlet multinomial mixture topic model, called D2M3, as well as a Gibbs sampling algorithm for the inference. We also propose a streaming diversification algorithm, SDA, that integrates the information captured by D2M3 with our proposed modified version of the PM-2 (Proportionality-based diversification Method -- second version) diversification algorithm. We conduct experiments on a Twitter dataset and find that SDA statistically significantly outperforms state-of-the-art non-streaming retrieval methods, plain streaming retrieval methods, as well as streaming diversification methods that use other dynamic topic models.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2735716999",
    "type": "article"
  },
  {
    "title": "Exploiting User and Venue Characteristics for Fine-Grained Tweet Geolocation",
    "doi": "https://doi.org/10.1145/3156667",
    "publication_date": "2018-02-02",
    "publication_year": 2018,
    "authors": "Wen-Haw Chong; Ee‐Peng Lim",
    "corresponding_authors": "",
    "abstract": "Which venue is a tweet posted from? We call this a fine-grained geolocation problem. Given an observed tweet, the task is to infer its discrete posting venue, e.g., a specific restaurant. This recovers the venue context and differs from prior work, which geolocats tweets to location coordinates or cities/neighborhoods. First, we conduct empirical analysis to uncover venue and user characteristics for improving geolocation. For venues, we observe spatial homophily , in which venues near each other have more similar tweet content (i.e., text representations) compared to venues further apart. For users, we observe that they are spatially focused and more likely to visit venues near their previous visits. We also find that a substantial proportion of users post one or more geocoded tweet(s), thus providing their location history data. We then propose geolocation models that exploit spatial homophily and spatial focus characteristics plus posting time information. Our models rank candidate venues of test tweets such that the actual posting venue is ranked high. To better tune model parameters, we introduce a learning-to-rank framework. Our best model significantly outperforms state-of-the-art baselines. Furthermore, we show that tweets without any location-indicative words can be geolocated meaningfully as well.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2792929363",
    "type": "article"
  },
  {
    "title": "From Question to Text",
    "doi": "https://doi.org/10.1145/3233771",
    "publication_date": "2018-10-30",
    "publication_year": 2018,
    "authors": "Heyan Huang; Xiaochi Wei; Liqiang Nie; Xian-Ling Mao; Xin-Shun Xu",
    "corresponding_authors": "",
    "abstract": "Understanding unstructured texts is an essential skill for human beings as it enables knowledge acquisition. Although understanding unstructured texts is easy for we human beings with good education, it is a great challenge for machines. Recently, with the rapid development of artificial intelligence techniques, researchers put efforts to teach machines to understand texts and justify the educated machines by letting them solve the questions upon the given unstructured texts, inspired by the reading comprehension test as we humans do. However, feature effectiveness with respect to different questions significantly hinders the performance of answer selection, because different questions may focus on various aspects of the given text and answer candidates. To solve this problem, we propose a question-oriented feature attention (QFA) mechanism, which learns to weight different engineering features according to the given question, so that important features with respect to the specific question is emphasized accordingly. Experiments on MCTest dataset have well-validated the effectiveness of the proposed method. Additionally, the proposed QFA is applicable to various IR tasks, such as question answering and answer selection. We have verified the applicability on a crawled community-based question-answering dataset.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2899008850",
    "type": "article"
  },
  {
    "title": "KNET",
    "doi": "https://doi.org/10.1145/2797137",
    "publication_date": "2015-08-24",
    "publication_year": 2015,
    "authors": "Qing Cui; Bin Gao; Jiang Bian; Siyu Qiu; Hanjun Dai; Tie‐Yan Liu",
    "corresponding_authors": "",
    "abstract": "Neural network techniques are widely applied to obtain high-quality distributed representations of words (i.e., word embeddings) to address text mining, information retrieval, and natural language processing tasks. Most recent efforts have proposed several efficient methods to learn word embeddings from context such that they can encode both semantic and syntactic relationships between words. However, it is quite challenging to handle unseen or rare words with insufficient context. Inspired by the study on the word recognition process in cognitive psychology, in this article, we propose to take advantage of seemingly less obvious but essentially important morphological knowledge to address these challenges. In particular, we introduce a novel neural network architecture called KNET that leverages both words’ contextual information and morphological knowledge to learn word embeddings. Meanwhile, this new learning architecture is also able to benefit from noisy knowledge and balance between contextual information and morphological knowledge. Experiments on an analogical reasoning task and a word similarity task both demonstrate that the proposed KNET framework can greatly enhance the effectiveness of word embeddings.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2042232391",
    "type": "article"
  },
  {
    "title": "Stochastic Query Covering for Fast Approximate Document Retrieval",
    "doi": "https://doi.org/10.1145/2699671",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Aris Anagnostopoulos; Luca Becchetti; Ilaria Bordino; Stefano Leonardi; Ida Mele; Piotr Sankowski",
    "corresponding_authors": "",
    "abstract": "We design algorithms that, given a collection of documents and a distribution over user queries, return a small subset of the document collection in such a way that we can efficiently provide high-quality answers to user queries using only the selected subset. This approach has applications when space is a constraint or when the query-processing time increases significantly with the size of the collection. We study our algorithms through the lens of stochastic analysis and prove that even though they use only a small fraction of the entire collection, they can provide answers to most user queries, achieving a performance close to the optimal. To complement our theoretical findings, we experimentally show the versatility of our approach by considering two important cases in the context of Web search. In the first case, we favor the retrieval of documents that are relevant to the query, whereas in the second case we aim for document diversification. Both the theoretical and the experimental analysis provide strong evidence of the potential value of query covering in diverse application scenarios.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2062296170",
    "type": "article"
  },
  {
    "title": "The Effects of Task Complexity on the Use of Different Types of Information in a Search Assistance Tool",
    "doi": "https://doi.org/10.1145/3371707",
    "publication_date": "2019-12-20",
    "publication_year": 2019,
    "authors": "Bogeum Choi; Austin R. Ward; Yuan Li; Jaime Arguello; R. Capra",
    "corresponding_authors": "",
    "abstract": "In interactive information retrieval, an important research question is: How do task characteristics influence users’ needs and behaviors? We report on a laboratory study ( N =32) that investigated the effects of task complexity on the types of information used by participants while searching. Participants completed tasks of four complexity levels and had access to four different types of information provided through a search-assistance tool referred to as the InfoBoxes (IB). The IB tool presented the following types of task-related information ( info-types ) on different tabs: (1) facts, (2) concepts, (3) opinions, and (4) insights. Facts (and opinions) were defined as objective (and subjective) statements relevant to the task. Concepts were defined as important ideas, principles, or entities related to the task. Insights were defined as tips or advice about the task. The study investigated six research questions that considered the effects of task complexity on: (RQ1) participants’ pre-/post-task perceptions about useful info-types; (RQ2) use of different info-types during the task; (RQ3) motivations for engaging with the IB; (RQ4) gains from using it; (RQ5) the search stage participants were in while engaging with the IB; and (RQ6) motivations for sometimes avoiding the IB. Our results suggest that task complexity influenced all six types of outcomes. We discuss implications of our results for designing search assistance tools and systems that favor certain types of content based on task characteristics.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2994848904",
    "type": "article"
  },
  {
    "title": "Overview of the Special Issue on Contextual Search and Recommendation",
    "doi": "https://doi.org/10.1145/2691351",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Paul N. Bennett; Kevyn Collins‐Thompson; Diane Kelly; Ryen W. White; Yi Zhang",
    "corresponding_authors": "",
    "abstract": "editorial Free AccessOverview of the Special Issue on Contextual Search and Recommendation Editors: Paul N. Bennett View Profile , Kevyn Collins-Thompson View Profile , Diane Kelly View Profile , Ryen W. White View Profile , Yi Zhang View Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 33Issue 1March 2015 Article No.: 1epp 1–7https://doi.org/10.1145/2691351Published:17 March 2015Publication History 12citation543DownloadsMetricsTotal Citations12Total Downloads543Last 12 Months32Last 6 weeks10 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2111182641",
    "type": "article"
  },
  {
    "title": "Geographic Diversification of Recommended POIs in Frequently Visited Areas",
    "doi": "https://doi.org/10.1145/3362505",
    "publication_date": "2019-10-17",
    "publication_year": 2019,
    "authors": "Jung‐Kyu Han; Hayato Yamana",
    "corresponding_authors": "",
    "abstract": "In the personalized Point-Of-Interest (POI) (or venue) recommendation, the diversity of recommended POIs is an important aspect. Diversity is especially important when POIs are recommended in the target users’ frequently visited areas, because users are likely to revisit such areas. In addition to the (POI) category diversity that is a popular diversification objective in recommendation domains, diversification of recommended POI locations is an interesting subject itself. Despite its importance, existing POI recommender studies generally focus on and evaluate prediction accuracy. In this article, geographical diversification ( geo-diversification ), a novel diversification concept that aims to increase recommendation coverage for a target users’ geographic areas of interest, is introduced, from which a method that improves geo-diversity as an addition to existing state-of-the-art POI recommenders is proposed. In experiments with the datasets from two real Location Based Social Networks (LSBNs), we first analyze the performance of four state-of-the-art POI recommenders from various evaluation perspectives including category diversity and geo-diversity that have not been examined previously. The proposed method consistently improves geo-diversity (CPR(geo)@20) by 5 to 12% when combined with four state-of-the-art POI recommenders with negligible prediction accuracy (Recall@20) loss and provides 6 to 18% geo-diversity improvement with tolerable prediction accuracy loss (up to 2.4%).",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2980849092",
    "type": "article"
  },
  {
    "title": "Investigating Searchers’ Mental Models to Inform Search Explanations",
    "doi": "https://doi.org/10.1145/3371390",
    "publication_date": "2019-12-20",
    "publication_year": 2019,
    "authors": "Paul Thomas; Bodo Billerbeck; Nick Craswell; Ryen W. White",
    "corresponding_authors": "",
    "abstract": "Modern web search engines use many signals to select and rank results in response to queries. However, searchers’ mental models of search are relatively unsophisticated, hindering their ability to use search engines efficiently and effectively. Annotating results with more in-depth explanations could help, but search engine providers need to know what to explain. To this end, we report on a study of searchers’ mental models of web selection and ranking, with more than 400 respondents to an online survey and 11 face-to-face interviews. Participants volunteered a range of factors and showed good understanding of important concepts such as popularity, wording, and personalization. However, they showed little understanding of recency or diversity and incorrect ideas of payment for ranking. Where there are already explanatory annotations on the results page—such as “ad” markers and keyword highlighting—participants were familiar with ranking concepts. This suggests that further explanatory annotations may be useful.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2996188425",
    "type": "article"
  },
  {
    "title": "Spoken Conversational Context Improves Query Auto-completion in Web Search",
    "doi": "https://doi.org/10.1145/3447875",
    "publication_date": "2021-05-05",
    "publication_year": 2021,
    "authors": "Tung Vuong; Salvatore Andolina; Giulio Jacucci; Tuukka Ruotsalo",
    "corresponding_authors": "",
    "abstract": "Web searches often originate from conversations in which people engage before they perform a search. Therefore, conversations can be a valuable source of context with which to support the search process. We investigate whether spoken input from conversations can be used as a context to improve query auto-completion. We model the temporal dynamics of the spoken conversational context preceding queries and use these models to re-rank the query auto-completion suggestions. Data were collected from a controlled experiment and comprised conversations among 12 participant pairs conversing about movies or traveling. Search query logs during the conversations were recorded and temporally associated with the conversations. We compared the effects of spoken conversational input in four conditions: a control condition without contextualization; an experimental condition with the model using search query logs; an experimental condition with the model using spoken conversational input; and an experimental condition with the model using both search query logs and spoken conversational input. We show the advantage of combining the spoken conversational context with the Web-search context for improved retrieval performance. Our results suggest that spoken conversations provide a rich context for supporting information searches beyond current user-modeling approaches.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3158941343",
    "type": "article"
  },
  {
    "title": "Target-guided Emotion-aware Chat Machine",
    "doi": "https://doi.org/10.1145/3456414",
    "publication_date": "2021-08-17",
    "publication_year": 2021,
    "authors": "Wei Wei; Jiayi Liu; Xian-Ling Mao; Guibing Guo; Feida Zhu; Pan Zhou; Yuchong Hu; Shanshan Feng",
    "corresponding_authors": "",
    "abstract": "The consistency of a response to a given post at the semantic level and emotional level is essential for a dialogue system to deliver humanlike interactions. However, this challenge is not well addressed in the literature, since most of the approaches neglect the emotional information conveyed by a post while generating responses. This article addresses this problem and proposes a unified end-to-end neural architecture, which is capable of simultaneously encoding the semantics and the emotions in a post and leveraging target information to generate more intelligent responses with appropriately expressed emotions. Extensive experiments on real-world data demonstrate that the proposed method outperforms the state-of-the-art methods in terms of both content coherence and emotion appropriateness.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3195638179",
    "type": "article"
  },
  {
    "title": "Efficient Multi-modal Hashing with Online Query Adaption for Multimedia Retrieval",
    "doi": "https://doi.org/10.1145/3477180",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Lei Zhu; C. Zheng; Xu Lu; Zhiyong Cheng; Liqiang Nie; Huaxiang Zhang",
    "corresponding_authors": "",
    "abstract": "Multi-modal hashing supports efficient multimedia retrieval well. However, existing methods still suffer from two problems: (1) Fixed multi-modal fusion. They collaborate the multi-modal features with fixed weights for hash learning, which cannot adaptively capture the variations of online streaming multimedia contents. (2) Binary optimization challenge. To generate binary hash codes, existing methods adopt either two-step relaxed optimization that causes significant quantization errors or direct discrete optimization that consumes considerable computation and storage cost. To address these problems, we first propose a Supervised Multi-modal Hashing with Online Query-adaption method. A self-weighted fusion strategy is designed to adaptively preserve the multi-modal features into hash codes by exploiting their complementarity. Besides, the hash codes are efficiently learned with the supervision of pair-wise semantic labels to enhance their discriminative capability while avoiding the challenging symmetric similarity matrix factorization. Further, we propose an efficient Unsupervised Multi-modal Hashing with Online Query-adaption method with an adaptive multi-modal quantization strategy. The hash codes are directly learned without the reliance on the specific objective formulations. Finally, in both methods, we design a parameter-free online hashing module to adaptively capture query variations at the online retrieval stage. Experiments validate the superiority of our proposed methods.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3201835075",
    "type": "article"
  },
  {
    "title": "Simulating and Modeling the Risk of Conversational Search",
    "doi": "https://doi.org/10.1145/3507357",
    "publication_date": "2022-02-01",
    "publication_year": 2022,
    "authors": "Zhenduo Wang; Qingyao Ai",
    "corresponding_authors": "",
    "abstract": "In conversational search, agents can interact with users by asking clarifying questions to increase their chance of finding better results. Many recent works and shared tasks in both natural language processing and information retrieval communities have focused on identifying the need to ask clarifying questions and methodologies of generating them. These works assume that asking a clarifying question is a safe alternative to retrieving results. As existing conversational search models are far from perfect, it is possible and common that they could retrieve/generate bad clarifying questions. Asking too many clarifying questions can also drain a user’s patience when the user prefers searching efficiency over correctness. Hence, these models can backfire and harm a user’s search experience due to these risks from asking clarifying questions. In this work, we propose a simulation framework to simulate the risk of asking questions in conversational search and further revise a risk-aware conversational search model to control the risk. We show the model’s robustness and effectiveness through extensive experiments on three conversational datasets — MSDialog, Ubuntu Dialog Corpus, and Opendialkg — in which we compare it with multiple baselines. We show that the risk-control module can work with two different re-ranker models and outperform all of the baselines in most of our experiments.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4221017794",
    "type": "article"
  },
  {
    "title": "GDESA: Greedy Diversity Encoder with Self-attention for Search Results Diversification",
    "doi": "https://doi.org/10.1145/3544103",
    "publication_date": "2022-06-13",
    "publication_year": 2022,
    "authors": "Xubo Qin; Zhicheng Dou; Yutao Zhu; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Search result diversification aims to generate diversified search results so as to meet the various information needs of users. Most of those existing diversification methods greedily select the optimal documents one-by-one comparing with the selected document sequences. Due to the fact that the information utilities of the candidate documents are not independent, a model based on greedy document selection may not produce the global optimal ranking results. To address this issue, some work proposes to model global document interactions regardless of whether a document is selected, which is inconsistent with actual user behavior. In this article, we propose a new supervised diversification framework as an ensemble of global interaction and document selection. Based on a self-attention encoder-decoder structure and an RNN-based document selection component, the model can simultaneously leverage both the global interactions among all the documents and the interactions between the selected sequence and each unselected document. This framework is called Greedy Diversity Encoder with Self-Attention (GDESA). Experimental results show that GDESA outperforms previous methods that rely just on global interactions, and our further analysis demonstrates that using both global interactions and document selection is necessary and beneficial.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4282569005",
    "type": "article"
  },
  {
    "title": "A Static and Dynamic Attention Framework for Multi Turn Dialogue Generation",
    "doi": "https://doi.org/10.1145/3522763",
    "publication_date": "2022-06-30",
    "publication_year": 2022,
    "authors": "Weinan Zhang; Yiming Cui; Kaiyan Zhang; Yifa Wang; Qingfu Zhu; Lingzhi Li; Ting Liu",
    "corresponding_authors": "",
    "abstract": "Recently, research on open domain dialogue systems have attracted extensive interests of academic and industrial researchers. The goal of an open domain dialogue system is to imitate humans in conversations. Previous works on single turn conversation generation have greatly promoted the research of open domain dialogue systems. However, understanding multiple single turn conversations is not equal to the understanding of multi turn dialogue due to the coherent and context dependent properties of human dialogue. Therefore, in open domain multi turn dialogue generation, it is essential to modeling the contextual semantics of the dialogue history, rather than only according to the last utterance. Previous research had verified the effectiveness of the hierarchical recurrent encoder-decoder framework on open domain multi turn dialogue generation. However, using RNN-based model to hierarchically encoding the utterances to obtain the representation of dialogue history still face the problem of a vanishing gradient. To address this issue, in this paper, we proposed a static and dynamic attention-based approach to model the dialogue history and then generate open domain multi turn dialogue responses. Experimental results on Ubuntu and Opensubtitles datasets verify the effectiveness of the proposed static and dynamic attention-based approach on automatic and human evaluation metrics in various experimental settings. Meanwhile, we also empirically verify the performance of combining the static and dynamic attentions on open domain multi turn dialogue generation.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4283728202",
    "type": "article"
  },
  {
    "title": "Extractive Explanations for Interpretable Text Ranking",
    "doi": "https://doi.org/10.1145/3576924",
    "publication_date": "2022-12-16",
    "publication_year": 2022,
    "authors": "Jurek Leonhardt; Koustav Rudra; Avishek Anand",
    "corresponding_authors": "",
    "abstract": "Neural document ranking models perform impressively well due to superior language understanding gained from pre-training tasks. However, due to their complexity and large number of parameters these (typically transformer-based) models are often non-interpretable in that ranking decisions can not be clearly attributed to specific parts of the input documents. In this article, we propose ranking models that are inherently interpretable by generating explanations as a by-product of the prediction decision. We introduce the Select-And-Rank paradigm for document ranking, where we first output an explanation as a selected subset of sentences in a document. Thereafter, we solely use the explanation or selection to make the prediction, making explanations first-class citizens in the ranking process. Technically, we treat sentence selection as a latent variable trained jointly with the ranker from the final output. To that end, we propose an end-to-end training technique for Select-And-Rank models utilizing reparameterizable subset sampling using the Gumbel-max trick . We conduct extensive experiments to demonstrate that our approach is competitive to state-of-the-art methods. Our approach is broadly applicable to numerous ranking tasks and furthers the goal of building models that are interpretable by design . Finally, we present real-world applications that benefit from our sentence selection method.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4313476629",
    "type": "article"
  },
  {
    "title": "TME: Tree-guided Multi-task Embedding Learning towards Semantic Venue Annotation",
    "doi": "https://doi.org/10.1145/3582553",
    "publication_date": "2023-02-01",
    "publication_year": 2023,
    "authors": "Ronghui Xu; Meng Chen; Yongshun Gong; Yang Liu; Xiaohui Yu; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "The prevalence of location-based services has generated a deluge of check-ins, enabling the task of human mobility understanding. Among the various types of information associated with the check-in venues, categories (e.g., Bar and Museum ) are vital to the task, as they often serve as excellent semantic characterization of the venues. Despite its significance and importance, a large portion of venues in the check-in services do not have even a single category label, such as up to 30% of venues in the Foursquare system lacking category labels. We, therefore, address the problem of semantic venue annotation, i.e., labeling the venue with a semantic category. Existing methods either fail to fully exploit the contextual information in the check-in sequences, or do not consider the semantic correlations across related categories. As such, we devise a Tree-guided Multi-task Embedding model (TME for short) to learn effective representations of venues and categories for the semantic annotation. TME jointly learns a common feature space by modeling multi-contexts of check-ins and utilizes the predefined category hierarchy to regularize the relatedness among categories. We evaluate TME over the task of semantic venue annotation on two check-in datasets. Experimental results show the superiority of TME over several state-of-the-art baselines.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4318775883",
    "type": "article"
  },
  {
    "title": "Recognize News Transition from Collective Behavior for News Recommendation",
    "doi": "https://doi.org/10.1145/3578362",
    "publication_date": "2023-02-02",
    "publication_year": 2023,
    "authors": "Qing Meng; Hui Yan; Bo Liu; Xiangguo Sun; Mingrui Hu; Jiuxin Cao",
    "corresponding_authors": "",
    "abstract": "In the news recommendation, users are overwhelmed by thousands of news daily, which makes the users’ behavior data have high sparsity. Therefore, only considering a single user’s personalized preferences cannot support the news recommendation. How to improve the relatedness of news and users and reduce data sparsity has become a hot issue. Recent studies have attempted to use graph models to enrich the relationship between users and news, but they are still limited to modeling the historical behaviors of a single user. To fill the gap, we integrate user-news relationships and the overall user historical clicked news sequences to construct a global heterogeneous transition graph. And a refinement approach is proposed to recognize the news transition patterns in the graph. Based on the global heterogeneous transition graph, we propose a heterogeneous transition graph attention network to capture the common behavior patterns of most users to enhance the representation of user interest. Fusing the users’ personalized and common interest, we propose the GAINRec model to recommend news effectively. Extensive experiments are conducted on two public news recommendation datasets, and the results show the superiority of the proposed GAINRec model compared with the state-of-the-art news recommendation models. The implementation of our model is available at https://github.com/newsrec/GAINRec .",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4319034470",
    "type": "article"
  },
  {
    "title": "Meta-CRS: A Dynamic Meta-Learning Approach for Effective Conversational Recommender System",
    "doi": "https://doi.org/10.1145/3604804",
    "publication_date": "2023-06-17",
    "publication_year": 2023,
    "authors": "Yuxin Ni; Yunwen Xia; Hui Fang; Chong Long; Xinyu Kong; Daqian Li; Dong Yang; Jie Zhang",
    "corresponding_authors": "",
    "abstract": "Conversational recommender system (CRS) enhances the recommender system by acquiring the latest user preference through dialogues, where an agent needs to decide “whether to ask or recommend”, “which attributes to ask”, and “which items to recommend” in each round. To explore these questions, reinforcement learning is adopted in most CRS frameworks. However, existing studies somewhat ignore to consider the connection between the previous rounds and the current round of the conversation, which might lead to the lack of prior knowledge and inaccurate decisions. In this view, we propose to facilitate the connections between different rounds of conversations in a dialogue session through deep transformer-based multi-channel meta-reinforcement learning, so that the CRS agent can decide each action/decision based on previous states, actions, and their rewards. Besides, to better utilize a user’s historical preferences, we propose a more dynamic and personalized graph structure to support the conversation module and the recommendation module. Experiment results on five real-world datasets and an online evaluation with real users in an industrial environment validate the improvement of our method over the state-of-the-art approaches and the effectiveness of our designs.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4381054202",
    "type": "article"
  },
  {
    "title": "Document-level Relation Extraction via Separate Relation Representation and Logical Reasoning",
    "doi": "https://doi.org/10.1145/3597610",
    "publication_date": "2023-07-14",
    "publication_year": 2023,
    "authors": "Heyan Huang; Changsen Yuan; Qian Liu; Yixin Cao",
    "corresponding_authors": "",
    "abstract": "Document-level relation extraction (RE) extends the identification of entity/mentions’ relation from the single sentence to the long document. It is more realistic and poses new challenges to relation representation and reasoning skills. In this article, we propose a novel model, SRLR , using S eparate Relation R epresentation and L ogical R easoning considering the indirect relation representation and complex reasoning of evidence sentence problems. Specifically, we first expand the judgment of relational facts from the entity-level to the mention-level, highlighting fine-grained information to capture the relation representation for the entity pair. Second, we propose a logical reasoning module to identify evidence sentences and conduct relational reasoning. Extensive experiments on two publicly available benchmark datasets demonstrate the effectiveness of our proposed SRLR as compared to 19 baseline models. Further ablation study also verifies the effects of the key components.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4384300984",
    "type": "article"
  },
  {
    "title": "SLED: Structure Learning based Denoising for Recommendation",
    "doi": "https://doi.org/10.1145/3611385",
    "publication_date": "2023-08-05",
    "publication_year": 2023,
    "authors": "Shengyu Zhang; Tan Jiang; Kun Kuang; Fuli Feng; Jin Yu; Jianxin Ma; Zhou Zhao; Jianke Zhu; Hongxia Yang; Tat‐Seng Chua; Fei Wu",
    "corresponding_authors": "",
    "abstract": "In recommender systems, click behaviors play a fundamental role in mining users’ interests and training models (clicked items as positive samples). Such signals are implicit feedback and are arguably less representative of users’ inherent interests. Most existing works denoise implicit feedback by introducing external signals, such as gaze, dwell time, and “like” behaviors. However, such explicit feedback is not always routinely available, or might be problematic to collect on a large scale. In this paper, we identify that an interaction’s related structural patterns in its neighborhood graph are potentially correlated with some outcome of implicit feedback (i.e., users’ ratings after consuming items), analogous to findings in other domains such as social networks. Inspired by this finding, we propose a novel Structure LEarning based Denoising (SLED) framework for denoising recommendation without explicit signals, which consists of two phases: center-aware graph structure learning and denoised recommendation . Phase 1 pre-trains a structural encoder in a self-supervised manner and learns to capture an interaction’s related structural patterns in its neighborhood graph. Phase 2 transfers the structure encoder to downstream recommendation datasets, which helps to down-weight the effect of noisy interactions on user interest modeling and loss calculation. We collect a relatively noisy industrial dataset across several days during a period of product promotion festival. Extensive experiments on this dataset and multiple public datasets demonstrate that the proposed SLED framework can significantly improve the recommendation quality over various base recommendation models.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4385606922",
    "type": "article"
  },
  {
    "title": "Community Preserving Social Recommendation with Cyclic Transfer Learning",
    "doi": "https://doi.org/10.1145/3631115",
    "publication_date": "2023-10-28",
    "publication_year": 2023,
    "authors": "Xuelian Ni; Fei Xiong; Shirui Pan; Jia Wu; Liang Wang; Hongshu Chen",
    "corresponding_authors": "",
    "abstract": "Transfer learning-based recommendation mitigates the sparsity of user-item interactions by introducing auxiliary domains. Social influence extracted from direct connections between users typically serves as an auxiliary domain to improve prediction performance. However, direct social connections also face severe data sparsity problems that limit model performance. In contrast, users’ dependency on communities is another valuable social information that has not yet received sufficient attention. Although studies have incorporated community information into recommendation by aggregating users’ preferences within the same community, they seldom capture the structural discrepancies among communities and the influence of structural discrepancies on users’ preferences. To address these challenges, we propose a community-preserving recommendation framework with cyclic transfer learning, incorporating heterogeneous community influence into the rating domain. We analyze the characteristics of the community domain and its inter-influence on the rating domain, and construct link constraints and preference constraints in the community domain. The shared vectors that bridge the rating domain and the community domain are allowed to be more consistent with the characteristics of both domains. Extensive experiments are conducted on four real-world datasets. The results manifest the excellent performance of our approach in capturing real users’ preferences compared with other state-of-the-art methods.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4387999338",
    "type": "article"
  },
  {
    "title": "Stopping Methods for Technology-assisted Reviews Based on Point Processes",
    "doi": "https://doi.org/10.1145/3631990",
    "publication_date": "2023-11-11",
    "publication_year": 2023,
    "authors": "Mark Stevenson; Reem Bin-Hezam",
    "corresponding_authors": "",
    "abstract": "Technology Assisted Review (TAR), which aims to reduce the effort required to screen collections of documents for relevance, is used to develop systematic reviews of medical evidence and identify documents that must be disclosed in response to legal proceedings. Stopping methods are algorithms which determine when to stop screening documents during the TAR process, helping to ensure that workload is minimised while still achieving a high level of recall. This paper proposes a novel stopping method based on point processes, which are statistical models that can be used to represent the occurrence of random events. The approach uses rate functions to model the occurrence of relevant documents in the ranking and compares four candidates, including one that has not previously been used for this purpose (hyperbolic). Evaluation is carried out using standard datasets (CLEF e-Health, TREC Total Recall, TREC Legal), and this work is the first to explore stopping method robustness by reporting performance on a range of rankings of varying effectiveness. Results show that the proposed method achieves the desired level of recall without requiring an excessive number of documents to be examined in the majority of cases and also compares well against multiple alternative approaches.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4388594564",
    "type": "article"
  },
  {
    "title": "Towards Effective and Efficient Sparse Neural Information Retrieval",
    "doi": "https://doi.org/10.1145/3634912",
    "publication_date": "2023-12-02",
    "publication_year": 2023,
    "authors": "Thibault Formal; Carlos Lassance; Benjamin Piwowarski; Stéphane Clinchant",
    "corresponding_authors": "",
    "abstract": "Sparse representation learning based on Pre-trained Language Models has seen a growing interest in Information Retrieval. Such approaches can take advantage of the proven efficiency of inverted indexes and inherit desirable IR priors such as explicit lexical matching or some degree of interpretability. In this work, we thoroughly develop the framework of sparse representation learning in IR, which unifies term weighting and expansion in a supervised setting. We then build on SPLADE—a sparse expansion-based retriever—and show to which extent it is able to benefit from the same training improvements as dense bi-encoders by studying the effect of distillation, hard negative mining, as well as the Pre-trained Language Model’s initialization on its effectiveness , leading to state-of-the-art results in both in- and out-of-domain evaluation settings (SPLADE++). We furthermore propose efficiency improvements, allowing us to reach latency requirements on par with traditional keyword-based approaches (Efficient-SPLADE).",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4389269373",
    "type": "article"
  },
  {
    "title": "Diversifying Sequential Recommendation with Retrospective and Prospective Transformers",
    "doi": "https://doi.org/10.1145/3653016",
    "publication_date": "2024-03-17",
    "publication_year": 2024,
    "authors": "Chaoyu Shi; Pengjie Ren; Dongjie Fu; Xin Xin; Shansong Yang; Fei Cai; Zhaochun Ren; Zhumin Chen",
    "corresponding_authors": "",
    "abstract": "Previous studies on sequential recommendation (SR) have predominantly concentrated on optimizing recommendation accuracy. However, there remains a significant gap in enhancing recommendation diversity, particularly for short interaction sequences. The limited availability of interaction information in short sequences hampers the recommender’s ability to comprehensively model users’ intents, consequently affecting both the diversity and accuracy of recommendation. In light of the above challenge, we propose reTrospective and pRospective Transformers for dIversified sEquential Recommendation (TRIER) . The TRIER addresses the issue of insufficient information in short interaction sequences by first retrospectively learning to predict users’ potential historical interactions, thereby introducing additional information and expanding short interaction sequences, and then capturing users’ potential intents from multiple augmented sequences. Finally, the TRIER learns to generate diverse recommendation lists by covering as many potential intents as possible. To evaluate the effectiveness of TRIER, we conduct extensive experiments on three benchmark datasets. The experimental results demonstrate that TRIER significantly outperforms state-of-the-art methods, exhibiting diversity improvement of up to 11.36% in terms of intra-list distance (ILD@5) on the Steam dataset, 3.43% ILD@5 on the Yelp dataset and 3.77% in terms of category coverage (CC@5) on the Beauty dataset. As for accuracy, on the Yelp dataset, we observe notable improvement of 7.62% and 8.63% in HR@5 and NDCG@5, respectively. Moreover, we found that TRIER reveals more significant accuracy and diversity improvement for short interaction sequences.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4392895351",
    "type": "article"
  },
  {
    "title": "LLM-enhanced Composed Image Retrieval: An Intent Uncertainty-aware Linguistic-Visual Dual Channel Matching Model",
    "doi": "https://doi.org/10.1145/3699715",
    "publication_date": "2024-10-09",
    "publication_year": 2024,
    "authors": "Hongfei Ge; Yuanchun Jiang; Jianshan Sun; Kun Yuan; Yezheng Liu",
    "corresponding_authors": "",
    "abstract": "Composed image retrieval (CoIR) involves a multi-modal query of the reference image and modification text describing the desired changes, allowing users to express image retrieval intents flexibly and effectively. The key of CoIR lies in how to properly reason the search intent from the multi-modal query. Existing work either aligns the composite embedding of the multi-modal query and the target image embedding in the visual domain through late-fusion or converts all images into text descriptions and leverage large language models (LLM) for text semantic reasoning. However, this single-modality reasoning approach fails to comprehensively and interpretably capture the users’ ambiguous and uncertain intents in the multi-modal queries, incurring the inconsistency between retrieved results and ground truth. Besides, the expensive manually-annotated datasets limit the further performance improvement of CoIR. To this end, this paper proposes an LLM-enhanced Intent Uncertainty-aware Linguistic-Visual Dual Channel Matching Model (IUDC), which combines the strengths of multi-modal late-fusion and LLMs for composed image retrieval. We first construct an LLM-based triplet augmentation strategy to generate more synthetic training triplets. Based on this, the core of IUDC consists of two matching channels: the semantic matching channel is responsible for intent reasoning on the aspect-level attributes extracted by an LLM, and the visual matching channel accounts for the fine-grained visual matching between multi-modal fusion embedding and target images. Considering the intent uncertainty presented in the multi-modal queries, we introduce Probability Distribution Encoder (PDE) to project the intents as probabilistic distributions in the two matching channels. Consequently, a mutually enhanced module is designed to share knowledge between the visual and semantic representations for better representation learning. Finally, the matching scores of two channels are added to retrieve the target image. Extensive experiments conducted on two real datasets demonstrate the effectiveness and superiority of our model. Notably, with the help of the proposed LLM-based triplet augmentation strategy, our model achieves a new record of state-of-the-art performance among all datasets.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4403246017",
    "type": "article"
  },
  {
    "title": "From text to hypertext by indexing",
    "doi": "https://doi.org/10.1145/195705.195717",
    "publication_date": "1995-01-02",
    "publication_year": 1995,
    "authors": "Airi Salminen; Jean Tague‐Sutcliffe; Charles McClellan",
    "corresponding_authors": "",
    "abstract": "A model is presented for converting a collection of documents to hypertext by means of indexing. The documents are assumed to be semistructured, i.e., their text is a hierarchy of parts, and some of the parts consist of natural language. The model is intended as a framework for specifying hypertextual reading capabilities for specific application areas and for developing new automated tools for the conversion of semistructured text to hypertext. In the model, two well-known paradigms—formal grammars and document indexing—are combined. The structure of the source text is defined by a schema that is a constrained context-free grammar. The hierarchic structure of the source may thus be modeled by a parse tree for the grammar. The effect of indexing is described by grammar transformations. The new grammar, called an indexing schema, is associated with a new parse tree where some text parts are index elements. The indexing schema may hide some parts of the original documents or the structure of some parts. For information retrieval, parts of the indexed text are considered to be nodes of a hypergraph. In the hypergraph-based information access, the navigation capabilities of the hypertext systems are combined with the querying capabilities of information retrieval systems.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2067697363",
    "type": "article"
  },
  {
    "title": "Data structures for efficient broker implementation",
    "doi": "https://doi.org/10.1145/256163.256165",
    "publication_date": "1997-07-01",
    "publication_year": 1997,
    "authors": "Anthony Tomasic; Luis Gravano; Calvin Lue; Peter Schwarz; Laura M. Haas",
    "corresponding_authors": "",
    "abstract": "With the profusion of text databases on the Internet, it is becoming increasingly hard to find the most useful databases for a given query. To attack this problem, several existing and proposed systems employ brokers to direct user queries, using a local database of summary information about the available databases. This summary information must effectively distinguish relevant databases and must be compact while allowing efficient access. We offer evidence that one broker, GlOSS , can be effective at locating databases of interest even in a system of hundreds of databased and can examine the performance of accessing the GlOSS summeries for two promising storage methods: the grid file and partitioned hashing. We show that both methods can be tuned to provide good performance for a particular workload (within a broad range of workloads), and we discuss the tradeoffs between the two data structures. As a side effect of our work, we show that grid files are more broadly applicable than previously thought; inparticular, we show that by varying the policies used to construct the grid file we can provide good performance for a wide range of workloads even when storing highly skewed data.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2037607644",
    "type": "article"
  },
  {
    "title": "Rich and lean representations of information for knowledge work",
    "doi": "https://doi.org/10.1145/196734.196746",
    "publication_date": "1994-04-01",
    "publication_year": 1994,
    "authors": "Karen Ruhleder",
    "corresponding_authors": "Karen Ruhleder",
    "abstract": "Applying information systems to complex intellectual tasks requires the representation and codification of ambiguous and fragmentary forms of data. This application effects changes not only in representation of this data, but in the relationships between users and tools, techniques, or systems for data interpretation. It also affects the complex infrastructures that support this process. This article uses a package metaphor to examine the impact on one domain of knowledge work, classical scholarship, of the “computerization” of a key data source, the textual edition. The construction of one on-line textual databank, the Thesaurus Linguae Graecae (TLG), has altered the traditional relationships between text “owners” and “users” has changed the role of the text as a conduit for social and historical information, and has disrupted traditional patterns of transmitting domain expertise. A rich information resource has become lean in its electronic form. The TLG has standardized the corpus of Greek literature and eased access to a broad range of works, including rare and out-of-print materials. At the same time, its construction has decoupled often-contested textual sources from their accompanying critical notes and supplemental materials. The use of the TLG has also shifted notions of objectivity, accuracy, and requisite expertise within the community. The transmission of domain knowledge must now be coupled with the transmission of technical knowledge, a process for which no infrastructure is currently in place. These experiences parallel those of other knowledge workers. “Mechanistic” paradigms of information and knowledge cannot accommodate important components of computing packages, including the transmission of expertise and infrastructures for tool development and evaluation. Recent developments in information storage and dissemination, including gophers and ftp sites may indicate that despite technical advances that could be used to support rich representations (such as hypermedia and multimedia), leaner forms of data may prevail.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2085740750",
    "type": "article"
  },
  {
    "title": "Knowledge-based document retrieval in office environments",
    "doi": "https://doi.org/10.1145/203052.203056",
    "publication_date": "1995-07-01",
    "publication_year": 1995,
    "authors": "Augusto Celentano; Mariagrazia Fugini; S. Pozzi",
    "corresponding_authors": "",
    "abstract": "In the office environment, the retrieval of documents is performed using the concepts contained in the documents, information about the procedural context where the documents are used, and information about the regulations and laws that discipline the life of documents within a given application domain. To fulfill the requirements of such a sophisticated retrieval, we propose a document retrieval model and system based on the representation of knowledge describing the semantic contents of documents, the way in which the documents are managed by procedures and by people in the office, and the application domain where the office operates. The article describes the knowledge representation issues needed for the document retrieval system and presents a document retrieval model that captures these issues. The effectiveness of the approach is illustrated by describing a system, named Kabiria , built on top of such model. The article describes the querying and browsing environments, and the architecture of the system.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2120898974",
    "type": "article"
  },
  {
    "title": "Transportable natural language processing through simplicity—the PRE system",
    "doi": "https://doi.org/10.1145/3914.3985",
    "publication_date": "1985-04-01",
    "publication_year": 1985,
    "authors": "Samuel S. Epstein",
    "corresponding_authors": "Samuel S. Epstein",
    "abstract": "PRE (Purposefully Restricted English) is a restricted English database query language whose implementation has addressed engineering goals, namely, habitability, interapplication transportability, performance, and use with a reliable database management system that supports large numbers of concurrent users and large databases. Habitability has not been demonstrated, but initial indications are encouraging. The other goals have clearly been achieved. The existence of the PRE system demonstrates that an explicitly “minimalist” approach to natural language processing can facilitate achievement of transportability.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2035985774",
    "type": "article"
  },
  {
    "title": "Whiteboards: a graphical database tool",
    "doi": "https://doi.org/10.1145/5401.5403",
    "publication_date": "1986-01-01",
    "publication_year": 1986,
    "authors": "James Donahue; Jennifer Widom",
    "corresponding_authors": "",
    "abstract": "The “Whiteboards” system is intended to be an electronic equivalent of the whiteboards and corkboards that we have in our offices. A Whiteboard database has similar qualities of storing disparate collections of data and saving their spatial location in a window to help with organization. A Whiteboard database can contain references to arbitrary entities: text files, notes, programs, tools, pictures, etc. Whiteboards runs as an application in the Cedar programming environment developed at the Xerox Palo Alto Research Center.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2080860173",
    "type": "article"
  },
  {
    "title": "Evolution of an organizational interface: the new business department at a largeinsurance firm",
    "doi": "https://doi.org/10.1145/42196.42266",
    "publication_date": "1987-10-01",
    "publication_year": 1987,
    "authors": "Andrew Clement; C. C. Gotlieb",
    "corresponding_authors": "",
    "abstract": "This paper describes how the work organization and computer system of the New Business Department at a large life insurance firm have interacted and evolved over time. The dynamics of interaction are explained largely in terms of the economic incentive to reduce the length of transaction-processing chains and the more political goal of extending managerial control. It is argued that examining the interaction of organizations and computer systems can contribute to a better theoretical understanding of the development of large computer systems and offer guidance to designers of user-computer interfaces. A graphical technique for depicting organizational interfaces is presented.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W1971108699",
    "type": "article"
  },
  {
    "title": "A space-partitioning-based indexing method for multidimensional non-ordered discrete data spaces",
    "doi": "https://doi.org/10.1145/1125857.1125860",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Gang Qian; Qiang Zhu; Qiang Xue; Sakti Pramanik",
    "corresponding_authors": "",
    "abstract": "There is an increasing demand for similarity searches in a multidimensional non-ordered discrete data space (NDDS) from application areas such as bioinformatics and data mining. The non-ordered and discrete nature of an NDDS raises new challenges for developing efficient indexing methods for similarity searches. In this article, we propose a new indexing technique, called the NSP-tree , to support efficient similarity searches in an NDDS. As we know, overlap causes a performance degradation for indexing methods (e.g., the R-tree) for a continuous data space. In an NDDS, this problem is even worse due to the limited number of elements available on each dimension of an NDDS. The key idea of the NSP-tree is to use a novel discrete space-partitioning (SP) scheme to ensure no overlap at each level in the tree. A number of heuristics and strategies are incorporated into the tree construction algorithms to deal with the challenges for developing an SP-based index tree for an NDDS. Our experiments demonstrate that the NSP-tree is quite promising in supporting efficient similarity searches in NDDSs. We have compared the NSP-tree with the ND-tree, a data-partitioning-based indexing technique for NDDSs that was proposed recently, and the linear scan using different NDDSs. It was found that the search performance of the NSP-tree was better than those of both methods.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2135631159",
    "type": "article"
  },
  {
    "title": "An adaptive threshold framework for event detection using HMM-based life profiles",
    "doi": "https://doi.org/10.1145/1462198.1462201",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Chien Chin Chen; Meng Chang Chen; Ming-Syan Chen⋆",
    "corresponding_authors": "",
    "abstract": "When an event occurs, it attracts attention of information sources to publish related documents along its lifespan. The task of event detection is to automatically identify events and their related documents from a document stream, which is a set of chronologically ordered documents collected from various information sources. Generally, each event has a distinct activeness development so that its status changes continuously during its lifespan. When an event is active, there are a lot of related documents from various information sources. In contrast when it is inactive, there are very few documents, but they are focused. Previous works on event detection did not consider the characteristics of the event's activeness, and used rigid thresholds for event detection. We propose a concept called life profile, modeled by a hidden Markov model, to model the activeness trends of events. In addition, a general event detection framework, LIPED, which utilizes the learned life profiles and the burst-and-diverse characteristic to adjust the event detection thresholds adaptively, can be incorporated into existing event detection methods. Based on the official TDT corpus and contest rules, the evaluation results show that existing detection methods that incorporate LIPED achieve better performance in the cost and F1 metrics, than without.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W1999550513",
    "type": "article"
  },
  {
    "title": "An analysis of latent semantic term self-correlation",
    "doi": "https://doi.org/10.1145/1462198.1462200",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "Laurence A. F. Park; Kotagiri Ramamohanarao",
    "corresponding_authors": "",
    "abstract": "Latent semantic analysis (LSA) is a generalized vector space method that uses dimension reduction to generate term correlations for use during the information retrieval process. We hypothesized that even though the dimension reduction establishes correlations between terms, the dimension reduction is causing a degradation in the correlation of a term to itself (self-correlation). In this article, we have proven that there is a direct relationship to the size of the LSA dimension reduction and the LSA self-correlation. We have also shown that by altering the LSA term self-correlations we gain a substantial increase in precision, while also reducing the computation required during the information retrieval process.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2003862930",
    "type": "article"
  },
  {
    "title": "Effects of position and number of relevant documents retrieved on users' evaluations of system performance",
    "doi": "https://doi.org/10.1145/1740592.1740597",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Diane Kelly; Xin Fu; Chirag Shah",
    "corresponding_authors": "",
    "abstract": "Information retrieval research has demonstrated that system performance does not always correlate positively with user performance, and that users often assign positive evaluation scores to search systems even when they are unable to complete tasks successfully. This research investigated the relationship between objective measures of system performance and users' perceptions of that performance. In this study, subjects evaluated the performance of four search systems whose search results were manipulated systematically to produce different orderings and numbers of relevant documents. Three laboratory studies were conducted with a total of eighty-one subjects. The first two studies investigated the effect of the order of five relevant and five nonrelevant documents in a search results list containing ten results on subjects' evaluations. The third study investigated the effect of varying the number of relevant documents in a search results list containing ten results on subjects' evaluations. Results demonstrate linear relationships between subjects' evaluations and the position of relevant documents in a search results list and the total number of relevant documents retrieved. Of the two, number of relevant documents retrieved was a stronger predictor of subjects' evaluation ratings and resulted in subjects using a greater range of evaluation scores.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2092307146",
    "type": "article"
  },
  {
    "title": "Detecting and Tracking Topics and Events from Web Search Logs",
    "doi": "https://doi.org/10.1145/2382438.2382440",
    "publication_date": "2012-11-01",
    "publication_year": 2012,
    "authors": "Hongyan Liu; Jun He; Yingqin Gu; Hui Xiong; Xiaoyong Du",
    "corresponding_authors": "",
    "abstract": "Recent years have witnessed increased efforts on detecting topics and events from Web search logs, since this kind of data not only capture web content but also reflect the users’ activities. However, the majority of existing work is focused on exploiting clustering techniques for topic and event detection. Due to the huge size and the evolving nature of Web data, existing clustering approaches are limited to meet the real-time demand. To that end, in this article, we propose a method called LETD to detect evolving topics in a timely manner. Also, we design the techniques to extract events from topics and to infer the evolving relationship among the events. For topic detection, we first provide a measurement to select the important URLs, which are most likely to describe a real-life topic. Then, starting from these selected URLs, we exploit the local expansion method to find other topic-related URLs. Moreover, in the LETD framework, we design algorithms based on Random Walk and Markov Random Fields (MRF), respectively. Because the LETD method exploits a divide-and-conquer strategy to process the data, it is more efficient than existing methods based on clustering techniques. To better illustrate the LETD framework, we develop a demo system StoryTeller which can discover hot topics and events, infer the evolving relationships among events, and visualize information in a storytelling way. This demo system can provide a global view of the topic development and help users target the interesting events more conveniently. Finally, experimental results on real-world Microsoft click-through data have shown that StoryTeller can find real-life hot topics and meaningful evolving relationships among events, and has also demonstrated the efficiency and effectiveness of the LETD method.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2050291832",
    "type": "article"
  },
  {
    "title": "Understanding Intrinsic Diversity in Web Search",
    "doi": "https://doi.org/10.1145/2629553",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Karthik Raman; Paul N. Bennett; Kevyn Collins‐Thompson",
    "corresponding_authors": "",
    "abstract": "Current research on Web search has focused on optimizing and evaluating single queries. However, a significant fraction of user queries are part of more complex tasks [Jones and Klinkner 2008] which span multiple queries across one or more search sessions [Liu and Belkin 2010; Kotov et al. 2011]. An ideal search engine would not only retrieve relevant results for a user's particular query but also be able to identify when the user is engaged in a more complex task and aid the user in completing that task [Morris et al. 2008; Agichtein et al. 2012]. Toward optimizing whole-session or task relevance, we characterize and address the problem of intrinsic diversity (ID) in retrieval [Radlinski et al. 2009], a type of complex task that requires multiple interactions with current search engines. Unlike existing work on extrinsic diversity [Carbonell and Goldstein 1998; Zhai et al. 2003; Chen and Karger 2006] that deals with ambiguity in intent across multiple users, ID queries often have little ambiguity in intent but seek content covering a variety of aspects on a shared theme. In such scenarios, the underlying needs are typically exploratory, comparative, or breadth-oriented in nature. We identify and address three key problems for ID retrieval: identifying authentic examples of ID tasks from post-hoc analysis of behavioral signals in search logs; learning to identify initiator queries that mark the start of an ID search task; and given an initiator query, predicting which content to prefetch and rank.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2074367844",
    "type": "article"
  },
  {
    "title": "Location-aware Influence Maximization over Dynamic Social Streams",
    "doi": "https://doi.org/10.1145/3230871",
    "publication_date": "2018-07-27",
    "publication_year": 2018,
    "authors": "Yanhao Wang; Yuchen Li; Ju Fan; Kian‐Lee Tan",
    "corresponding_authors": "",
    "abstract": "Influence maximization (IM), which selects a set of k seed users (a.k.a., a seed set ) to maximize the influence spread over a social network, is a fundamental problem in a wide range of applications. However, most existing IM algorithms are static and location-unaware. They fail to provide high-quality seed sets efficiently when the social network evolves rapidly and IM queries are location-aware. In this article, we first define two IM queries, namely Stream Influence Maximization (SIM) and Location-aware SIM (LSIM), to track influential users over social streams. Technically, SIM adopts the sliding window model and maintains a seed set with the maximum influence value collectively over the most recent social actions. LSIM further considers social actions are associated with geo-tags and identifies a seed set that maximizes the influence value in a query region over a location-aware social stream. Then, we propose the Sparse Influential Checkpoints (SIC) framework for efficient SIM query processing. SIC maintains a sequence of influential checkpoints over the sliding window and each checkpoint maintains a partial solution for SIM in an append-only substream of social actions. Theoretically, SIC keeps a logarithmic number of checkpoints w.r.t. the size of the sliding window and always returns an approximate solution from one of the checkpoint for the SIM query at any time. Furthermore, we propose the Location-based SIC (LSIC) framework and its improved version LSIC + , both of which process LSIM queries by integrating the SIC framework with a Quadtree spatial index. LSIC can provide approximate solutions for both ad hoc and continuous LSIM queries in real time, while LSIC + further improves the solution quality of LSIC. Experimental results on real-world datasets demonstrate the effectiveness and efficiency of the proposed frameworks against the state-of-the-art IM algorithms.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2883729465",
    "type": "article"
  },
  {
    "title": "Next-Item Recommendation via Collaborative Filtering with Bidirectional Item Similarity",
    "doi": "https://doi.org/10.1145/3366172",
    "publication_date": "2019-12-20",
    "publication_year": 2019,
    "authors": "Zijie Zeng; Jing Lin; Lin Li; Weike Pan; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "Exploiting temporal effect has empirically been recognized as a promising way to improve recommendation performance in recent years. In real-world applications, one-class data in the form of (user, item, timestamp) are usually more accessible and abundant than numerical ratings. In this article, we focus on exploiting such one-class data in order to provide personalized next-item recommendation services. Specifically, we base our work on the framework of time-aware item-based collaborative filtering and propose a simple yet effective similarity measurement called bidirectional item similarity (BIS) that is able to capture sequential patterns even from noisy data. Furthermore, we extend BIS via some factorization techniques and obtain an adaptive version, i.e., adaptive BIS (ABIS), in order to better fit the behavioral data. We also design a compound weighting function that leverages the complementarity between two well-known time-aware weighting functions. With the proposed similarity measurements and weighting function, we obtain two novel collaborative filtering methods that are able to achieve significantly better performance than the state-of-the-art methods, showcasing their effectiveness for next-item recommendation.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2996661047",
    "type": "article"
  },
  {
    "title": "Topic Modeling for Wikipedia Link Disambiguation",
    "doi": "https://doi.org/10.1145/2633044",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Bradley Skaggs; Lise Getoor",
    "corresponding_authors": "",
    "abstract": "Many articles in the online encyclopedia Wikipedia have hyperlinks to ambiguous article titles; these ambiguous links should be replaced with links to unambiguous articles, a process known as disambiguation. We propose a novel statistical topic model based on link text, which we refer to as the Link Text Topic Model (LTTM), that we use to suggest new link targets for ambiguous links. To evaluate our model, we describe a method for extracting ground truth for this link disambiguation task from edits made to Wikipedia in a specific time period. We use this ground truth to demonstrate the superiority of LTTM over other existing link- and content-based approaches to disambiguating links in Wikipedia. Finally, we build a web service that uses LTTM to make suggestions to human editors wanting to fix ambiguous links in Wikipedia.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2004647285",
    "type": "article"
  },
  {
    "title": "Accounting for Language Changes Over Time in Document Similarity Search",
    "doi": "https://doi.org/10.1145/2934671",
    "publication_date": "2016-09-03",
    "publication_year": 2016,
    "authors": "Sara Morsy; George Karypis",
    "corresponding_authors": "",
    "abstract": "Given a query document, ranking the documents in a collection based on how similar they are to the query is an essential task with extensive applications. For collections that contain documents whose creation dates span several decades, this task is further complicated by the fact that the language changes over time. For example, many terms add or lose one or more senses to meet people’s evolving needs. To address this problem, we present methods that take advantage of two types of information to account for the language change. The first is the citation network that often exists within the collection, which can be used to link related documents with significantly different creation dates (and hence different language use). The second is the changes in the usage frequency of terms that occur over time, which can indicate changes in their senses and uses. These methods utilize the preceding information while estimating the representation of both documents and terms within the context of nonprobabilistic static and dynamic topic models. Our experiments on two real-world datasets that span more than 40 years show that our proposed methods improve the retrieval performance of existing models and that these improvements are statistically significant.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2513500384",
    "type": "article"
  },
  {
    "title": "QuoteRec",
    "doi": "https://doi.org/10.1145/3183370",
    "publication_date": "2018-03-23",
    "publication_year": 2018,
    "authors": "Jiwei Tan; Xiaojun Wan; Hui Liu; Jianguo Xiao",
    "corresponding_authors": "",
    "abstract": "Quote is a language phenomenon of transcribing the statement of someone else, such as a proverb and a famous saying. An appropriate usage of quote usually equips the expression with more elegance and credibility. However, there are times when we are eager to stress our idea by citing a quote, while nothing relevant comes to mind. Therefore, it is exciting to have a recommender system which provides quote recommendations while we are writing. This article extends previous study of quote recommendation, the task that recommends the appropriate quote according to the context (i.e., the content occurring before and after the quote). In this article, a quote recommender system called QuoteRec is presented to tackle the task. We investigate two models to learn the vector representations of quotes and contexts, and then rank the candidate quotes based on the representations. The first model learns the quote representation according to the contexts of a quote. The second model is an extension of the neural network model in previous study, which learns the representation of a quote by concerning both its content and contexts. Experimental results demonstrate the effectiveness of the two models in learning the semantic representations of quotes, and the neural network model achieves state-of-the-art results on the quote recommendation task.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2793652880",
    "type": "article"
  },
  {
    "title": "Learning from Multi-annotator Data",
    "doi": "https://doi.org/10.1145/3309543",
    "publication_date": "2019-02-21",
    "publication_year": 2019,
    "authors": "Xueying Zhan; Yaowei Wang; Yanghui Rao; Qing Li",
    "corresponding_authors": "",
    "abstract": "In the field of sentiment analysis and emotion detection in social media, or other tasks such as text classification involving supervised learning, researchers rely more heavily on large and accurate labelled training datasets. However, obtaining large-scale labelled datasets is time-consuming and high-quality labelled datasets are expensive and scarce. To deal with these problems, online crowdsourcing systems provide us an efficient way to accelerate the process of collecting training data via distributing the enormous tasks to various annotators to help create large amounts of labelled data at an affordable cost. Nowadays, these crowdsourcing platforms are heavily needed in dealing with social media text, since the social network platforms (e.g., Twitter) generate huge amounts of data in textual form everyday. However, people from different social and knowledge backgrounds have different views on various texts, which may lead to noisy labels. The existing noisy label aggregation/refinement algorithms mostly focus on aggregating labels from noisy annotations, which would not guarantee their effectiveness on the subsequent classification/ranking tasks. In this article, we propose a noise-aware classification framework that integrates the steps of noisy label aggregation and classification. The aggregated noisy crowd labels are fed into a classifier for training, while the predicted labels are employed as feedback for adjusting the parameters at the label aggregating stage. The classification framework is suitable for directly running on crowdsourcing datasets and applies to various kinds of classification algorithms. The feedback strategy makes it possible for us to find optimal parameters instead of using known data for parameter selection. Simulation experiments demonstrate that our method provide significant label aggregation performance for both binary and multiple classification tasks under various noisy environments. Experimenting on real-world data validates the feasibility of our framework in real noise data and helps us verify the reasonableness of the simulated experiment settings.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2917725866",
    "type": "article"
  },
  {
    "title": "Safe Exploration for Optimizing Contextual Bandits",
    "doi": "https://doi.org/10.1145/3385670",
    "publication_date": "2020-04-21",
    "publication_year": 2020,
    "authors": "Rolf Jagerman; Ilya Markov; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Contextual bandit problems are a natural fit for many information retrieval tasks, such as learning to rank, text classification, recommendation, and so on. However, existing learning methods for contextual bandit problems have one of two drawbacks: They either do not explore the space of all possible document rankings (i.e., actions) and, thus, may miss the optimal ranking, or they present suboptimal rankings to a user and, thus, may harm the user experience. We introduce a new learning method for contextual bandit problems, Safe Exploration Algorithm (SEA), which overcomes the above drawbacks. SEA starts by using a baseline (or production) ranking system (i.e., policy), which does not harm the user experience and, thus, is safe to execute but has suboptimal performance and, thus, needs to be improved. Then SEA uses counterfactual learning to learn a new policy based on the behavior of the baseline policy. SEA also uses high-confidence off-policy evaluation to estimate the performance of the newly learned policy. Once the performance of the newly learned policy is at least as good as the performance of the baseline policy, SEA starts using the new policy to execute new actions, allowing it to actively explore favorable regions of the action space. This way, SEA never performs worse than the baseline policy and, thus, does not harm the user experience, while still exploring the action space and, thus, being able to find an optimal policy. Our experiments using text classification and document retrieval confirm the above by comparing SEA (and a boundless variant called BSEA) to online and offline learning methods for contextual bandit problems.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3022971154",
    "type": "article"
  },
  {
    "title": "Profile-Based Summarisation for Web Site Navigation",
    "doi": "https://doi.org/10.1145/2699661",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Ahmad Alhindi; Udo Kruschwitz; Chris Fox; M‐Dyaa Albakour",
    "corresponding_authors": "",
    "abstract": "Information systems that utilise contextual information have the potential of helping a user identify relevant information more quickly and more accurately than systems that work the same for all users and contexts. Contextual information comes in a variety of types, often derived from records of past interactions between a user and the information system. It can be individual or group based. We are focusing on the latter, harnessing the search behaviour of cohorts of users, turning it into a domain model that can then be used to assist other users of the same cohort. More specifically, we aim to explore how such a domain model is best utilised for profile-biased summarisation of documents in a navigation scenario in which such summaries can be displayed as hover text as a user moves the mouse over a link. The main motivation is to help a user find relevant documents more quickly. Given the fact that the Web in general has been studied extensively already, we focus our attention on Web sites and similar document collections. Such collections can be notoriously difficult to search or explore. The process of acquiring the domain model is not a research interest here; we simply adopt a biologically inspired method that resembles the idea of ant colony optimisation. This has been shown to work well in a variety of application areas. The model can be built in a continuous learning cycle that exploits search patterns as recorded in typical query log files. Our research explores different summarisation techniques, some of which use the domain model and some that do not. We perform task-based evaluations of these different techniques—thus of the impact of the domain model and profile-biased summarisation—in the context of Web site navigation.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2171815785",
    "type": "article"
  },
  {
    "title": "Keeping the Data Lake in Form",
    "doi": "https://doi.org/10.1145/3388870",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Ayman Alserafi; Alberto Abelló; Oscar Romero; Toon Calders",
    "corresponding_authors": "",
    "abstract": "Data lakes (DLs) are large repositories of raw datasets from disparate sources. As more datasets are ingested into a DL, there is an increasing need for efficient techniques to profile them and to detect the relationships among their schemata, commonly known as holistic schema matching . Schema matching detects similarity between the information stored in the datasets to support information discovery and retrieval. Currently, this is computationally expensive with the volume of state-of-the-art DLs. To handle this challenge, we propose a novel early-pruning approach to improve efficiency, where we collect different types of content metadata and schema metadata about the datasets, and then use this metadata in early-pruning steps to pre-filter the schema matching comparisons. This involves computing proximities between datasets based on their metadata, discovering their relationships based on overall proximities and proposing similar dataset pairs for schema matching. We improve the effectiveness of this task by introducing a supervised mining approach for effectively detecting similar datasets that are proposed for further schema matching. We conduct extensive experiments on a real-world DL that proves the success of our approach in effectively detecting similar datasets for schema matching, with recall rates of more than 85% and efficiency improvements above 70%. We empirically show the computational cost saving in space and time by applying our approach in comparison to instance-based schema matching techniques.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3026486734",
    "type": "article"
  },
  {
    "title": "Enhancing Employer Brand Evaluation with Collaborative Topic Regression Models",
    "doi": "https://doi.org/10.1145/3392734",
    "publication_date": "2020-05-23",
    "publication_year": 2020,
    "authors": "Hao Lin; Hengshu Zhu; Junjie Wu; Yuan Zuo; Chen Zhu; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "Employer Brand Evaluation (EBE) is to understand an employer’s unique characteristics to identify competitive edges. Traditional approaches rely heavily on employers’ financial information, including financial reports and filings submitted to the Securities and Exchange Commission (SEC), which may not be readily available for private companies. Fortunately, online recruitment services provide a variety of employers’ information from their employees’ online ratings and comments, which enables EBE from an employee’s perspective. To this end, in this article, we propose a method named Company Profiling–based Collaborative Topic Regression (CPCTR) to collaboratively model both textual (i.e., reviews) and numerical information (i.e., salaries and ratings) for learning latent structural patterns of employer brands. With identified patterns, we can effectively conduct both qualitative opinion analysis and quantitative salary benchmarking. Moreover, a Gaussian processes--based extension, GPCTR, is proposed to capture the complex correlation among heterogeneous information. Extensive experiments are conducted on three real-world datasets to validate the effectiveness and generalizability of our methods in real-life applications. The results clearly show that our methods outperform state-of-the-art baselines and enable a comprehensive understanding of EBE.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3034873720",
    "type": "article"
  },
  {
    "title": "Toward Comprehensive User and Item Representations via Three-tier Attention Network",
    "doi": "https://doi.org/10.1145/3446341",
    "publication_date": "2021-02-23",
    "publication_year": 2021,
    "authors": "Hongtao Liu; Wenjun Wang; Qiyao Peng; Nannan Wu; Fangzhao Wu; Pengfei Jiao",
    "corresponding_authors": "",
    "abstract": "Product reviews can provide rich information about the opinions users have of products. However, it is nontrivial to effectively infer user preference and item characteristics from reviews due to the complicated semantic understanding. Existing methods usually learn features for users and items from reviews in single static fashions and cannot fully capture user preference and item features. In this article, we propose a neural review-based recommendation approach that aims to learn comprehensive representations of users/items under a three-tier attention framework. We design a review encoder to learn review features from words via a word-level attention, an aspect encoder to learn aspect features via a review-level attention, and a user/item encoder to learn the final representations of users/items via an aspect-level attention. In word- and review-level attentions, we adopt the context-aware mechanism to indicate importance of words and reviews dynamically instead of static attention weights. In addition, the attentions in the word and review levels are of multiple paradigms to learn multiple features effectively, which could indicate the diversity of user/item features. Furthermore, we propose a personalized aspect-level attention module in user/item encoder to learn the final comprehensive features. Extensive experiments are conducted and the results in rating prediction validate the effectiveness of our method.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3130347695",
    "type": "article"
  },
  {
    "title": "Interactive Sequential Basket Recommendation by Learning Basket Couplings and Positive/Negative Feedback",
    "doi": "https://doi.org/10.1145/3444368",
    "publication_date": "2021-02-23",
    "publication_year": 2021,
    "authors": "Wei Wang; Longbing Cao",
    "corresponding_authors": "",
    "abstract": "Sequential recommendation , such as next-basket recommender systems (NBRS), which model users’ sequential behaviors and the relevant context/session, has recently attracted much attention from the research community. Existing session-based NBRS involve session representation and inter-basket relations but ignore their hybrid couplings with the intra-basket items, often producing irrelevant or similar items in the next basket. In addition, they do not predict next-baskets (more than one next basket recommended). Interactive recommendation further involves user feedback on the recommended basket. The existing work on next-item recommendation involves positive feedback on selected items but ignores negative feedback on unselected ones. Here, we introduce a new setting— interactive sequential basket recommendation , which iteratively predicts next baskets by learning the intra-/inter-basket couplings between items and both positive and negative user feedback on recommended baskets. A hierarchical attentive encoder-decoder model (HAEM) continuously recommends next baskets one after another during sequential interactions with users after analyzing the item relations both within a basket and between adjacent sequential baskets (i.e., intra-/inter-basket couplings) and incorporating the user selection and unselection (i.e., positive/negative) feedback on the recommended baskets to refine NBRS. HAEM comprises a basket encoder and a sequence decoder to model intra-/inter-basket couplings and a prediction decoder to sequentially predict next-baskets by interactive feedback-based refinement. Empirical analysis shows that HAEM significantly outperforms the state-of-the-art baselines for NBRS and session-based recommenders for accurate and novel recommendation. We also show the effect of continuously refining sequential basket recommendation by including unselection feedback during interactive recommendation.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3132580718",
    "type": "article"
  },
  {
    "title": "SPEX: A Generic Framework for Enhancing Neural Social Recommendation",
    "doi": "https://doi.org/10.1145/3473338",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Hui Li; Lianyun Li; Guipeng Xv; Chen Lin; Ke Li; Bingchuan Jiang",
    "corresponding_authors": "",
    "abstract": "Social Recommender Systems (SRS) have attracted considerable attention since its accompanying service, social networks, helps increase user satisfaction and provides auxiliary information to improve recommendations. However, most existing SRS focus on social influence and ignore another essential social phenomenon, i.e., social homophily. Social homophily, which is the premise of social influence, indicates that people tend to build social relations with similar people and form influence propagation paths. In this article, we propose a generic framework Social PathExplorer (SPEX) to enhance neural SRS. SPEX treats the neural recommendation model as a black box and improves the quality of recommendations by modeling the social recommendation task, the formation of social homophily, and their mutual effect in the manner of multi-task learning. We design a Graph Neural Network based component for influence propagation path prediction to help SPEX capture the rich information conveyed by the formation of social homophily. We further propose an uncertainty based task balancing method to set appropriate task weights for the recommendation task and the path prediction task during the joint optimization. Extensive experiments have validated that SPEX can be easily plugged into various state-of-the-art neural recommendation models and help improve their performance. The source code of our work is available at: https://github.com/XMUDM/SPEX.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W3204736135",
    "type": "article"
  },
  {
    "title": "Dynamic Structural Role Node Embedding for User Modeling in Evolving Networks",
    "doi": "https://doi.org/10.1145/3472955",
    "publication_date": "2021-11-22",
    "publication_year": 2021,
    "authors": "Lili Wang; Cheng‐Han Huang; Ying Lü; Weicheng Ma; Ruibo Liu; Soroush Vosoughi",
    "corresponding_authors": "",
    "abstract": "Complex user behavior, especially in settings such as social media, can be organized as time-evolving networks. Through network embedding, we can extract general-purpose vector representations of these dynamic networks which allow us to analyze them without extensive feature engineering. Prior work has shown how to generate network embeddings while preserving the structural role proximity of nodes. These methods, however, cannot capture the temporal evolution of the structural identity of the nodes in dynamic networks. Other works, on the other hand, have focused on learning microscopic dynamic embeddings. Though these methods can learn node representations over dynamic networks, these representations capture the local context of nodes and do not learn the structural roles of nodes. In this article, we propose a novel method for learning structural node embeddings in discrete-time dynamic networks. Our method, called HR2vec , tracks historical topology information in dynamic networks to learn dynamic structural role embeddings. Through experiments on synthetic and real-world temporal datasets, we show that our method outperforms other well-known methods in tasks where structural equivalence and historical information both play important roles. HR2vec can be used to model dynamic user behavior in any networked setting where users can be represented as nodes. Additionally, we propose a novel method (called network fingerprinting) that uses HR2vec embeddings for modeling whole (or partial) time-evolving networks. We showcase our network fingerprinting method on synthetic and real-world networks. Specifically, we demonstrate how our method can be used for detecting foreign-backed information operations on Twitter.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3216418890",
    "type": "article"
  },
  {
    "title": "Profiling Users for Question Answering Communities via Flow-Based Constrained Co-Embedding Model",
    "doi": "https://doi.org/10.1145/3470565",
    "publication_date": "2021-11-24",
    "publication_year": 2021,
    "authors": "Shangsong Liang; Yupeng Luo; Zaiqiao Meng",
    "corresponding_authors": "",
    "abstract": "In this article, we study the task of user profiling in question answering communities (QACs). Previous user profiling algorithms suffer from a number of defects: they regard users and words as atomic units, leading to the mismatch between them; they are designed for other applications but not for QACs; and some semantic profiling algorithms do not co-embed users and words, leading to making the affinity measurement between them difficult. To improve the profiling performance, we propose a neural Flow-based Constrained Co-embedding Model, abbreviated as FCCM. FCCM jointly co-embeds the vector representations of both users and words in QACs such that the affinities between them can be semantically measured. Specifically, FCCM extends the standard variational auto-encoder model to enforce the inferred embeddings of users and words subject to the voting constraint, i.e., given a question and the users who answer this question in the community, representations of the users whose answers receive more votes are closer to the representations of the words associated with these answers, compared with representations of whose receiving fewer votes. In addition, FCCM integrates normalizing flow into the variational auto-encoder framework to avoid the assumption that the distributions of the embeddings are Gaussian, making the inferred embeddings fit the real distributions of the data better. Experimental results on a Chinese Zhihu question answering dataset demonstrate the effectiveness of our proposed FCCM model for the task of user profiling in QACs.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3216761404",
    "type": "article"
  },
  {
    "title": "Are Topics Interesting or Not? An LDA-based Topic-graph Probabilistic Model for Web Search Personalization",
    "doi": "https://doi.org/10.1145/3476106",
    "publication_date": "2021-12-30",
    "publication_year": 2021,
    "authors": "Jiashu Zhao; Jimmy Xiangji Huang; Hongbo Deng; Yi Chang; Xia Long",
    "corresponding_authors": "",
    "abstract": "In this article, we propose a Latent Dirichlet Allocation– (LDA) based topic-graph probabilistic personalization model for Web search. This model represents a user graph in a latent topic graph and simultaneously estimates the probabilities that the user is interested in the topics, as well as the probabilities that the user is not interested in the topics. For a given query issued by the user, the webpages that have higher relevancy to the interested topics are promoted, and the webpages more relevant to the non-interesting topics are penalized. In particular, we simulate a user’s search intent by building two profiles: A positive user profile for the probabilities of the user is interested in the topics and a corresponding negative user profile for the probabilities of being not interested in the the topics. The profiles are estimated based on the user’s search logs. A clicked webpage is assumed to include interesting topics. A skipped (viewed but not clicked) webpage is assumed to cover some non-interesting topics to the user. Such estimations are performed in the latent topic space generated by LDA. Moreover, a new approach is proposed to estimate the correlation between a given query and the user’s search history so as to determine how much personalization should be considered for the query. We compare our proposed models with several strong baselines including state-of-the-art personalization approaches. Experiments conducted on a large-scale real user search log collection illustrate the effectiveness of the proposed models.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W4200199191",
    "type": "article"
  },
  {
    "title": "Understanding the “Pathway” Towards a Searcher’s Learning Objective",
    "doi": "https://doi.org/10.1145/3495222",
    "publication_date": "2022-01-11",
    "publication_year": 2022,
    "authors": "Kelsey Urgo; Jaime Arguello",
    "corresponding_authors": "",
    "abstract": "Search systems are often used to support learning-oriented goals. This trend has given rise to the “search-as-learning” movement, which proposes that search systems should be designed to support learning. To this end, an important research question is: How does a searcher’s type of learning objective (LO) influence their trajectory (or pathway ) toward that objective? We report on a lab study (N = 36) in which participants gathered information to meet a specific type of LO. To characterize LOs and pathways , we leveraged Anderson and Krathwohl’s (A&amp;K’s) taxonomy [ 3 ]. A&amp;K’s taxonomy situates LOs at the intersection of two orthogonal dimensions: (1) cognitive process (CP) (remember, understand, apply, analyze, evaluate, and create) and (2) knowledge type (factual, conceptual, procedural, and metacognitive knowledge). Participants completed learning-oriented search tasks that varied along three CPs (apply, evaluate, and create) and three knowledge types (factual, conceptual, and procedural knowledge). A pathway is defined as a sequence of learning instances (e.g., subgoals) that were also each classified into cells from A&amp;K’s taxonomy. Our study used a think-aloud protocol, and pathways were generated through a qualitative analysis of participants’ think-aloud comments and recorded screen activities. We investigate three research questions. First, in RQ1, we study the impact of the LO on pathway characteristics (e.g., pathway length). Second, in RQ2, we study the impact of the LO on the types of A&amp;K cells traversed along the pathway. Third, in RQ3, we study common and uncommon transitions between A&amp;K cells along pathways conditioned on the knowledge type of the objective. We discuss implications of our results for designing search systems to support learning.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4206807987",
    "type": "article"
  },
  {
    "title": "Complex-valued Neural Network-based Quantum Language Models",
    "doi": "https://doi.org/10.1145/3505138",
    "publication_date": "2022-03-09",
    "publication_year": 2022,
    "authors": "Peng Zhang; Wenjie Hui; Benyou Wang; Donghao Zhao; Dawei Song; Christina Lioma; Jakob Grue Simonsen",
    "corresponding_authors": "",
    "abstract": "Language modeling is essential in Natural Language Processing and Information Retrieval related tasks. After the statistical language models, Quantum Language Model (QLM) has been proposed to unify both single words and compound terms in the same probability space without extending term space exponentially. Although QLM achieved good performance in ad hoc retrieval, it still has two major limitations: (1) QLM cannot make use of supervised information, mainly due to the iterative and non-differentiable estimation of the density matrix, which represents both queries and documents in QLM. (2) QLM assumes the exchangeability of words or word dependencies, neglecting the order or position information of words.This article aims to generalize QLM and make it applicable to more complicated matching tasks (e.g., Question Answering) beyond ad hoc retrieval. We propose a complex-valued neural network-based QLM solution called C-NNQLM to employ an end-to-end approach to build and train density matrices in a light-weight and differentiable manner, and it can therefore make use of external well-trained word vectors and supervised labels. Furthermore, C-NNQLM adopts complex-valued word vectors whose phase vectors can directly encode the order (or position) information of words. Note that complex numbers are also essential in the quantum theory. We show that the real-valued NNQLM (R-NNQLM) is a special case of C-NNQLM.The experimental results on the QA task show that both R-NNQLM and C-NNQLM achieve much better performance than the vanilla QLM, and C-NNQLM's performance is on par with state-of-the-art neural network models. We also evaluate the proposed C-NNQLM on text classification and document retrieval tasks. The results on most datasets show that the C-NNQLM can outperform R-NNQLM, which demonstrates the usefulness of the complex representation for words and sentences in C-NNQLM.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4220961088",
    "type": "article"
  },
  {
    "title": "Integrating Representation and Interaction for Context-Aware Document Ranking",
    "doi": "https://doi.org/10.1145/3529955",
    "publication_date": "2022-04-14",
    "publication_year": 2022,
    "authors": "Haonan Chen; Zhicheng Dou; Qiannan Zhu; Xiaochen Zuo; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Recent studies show that historical behaviors (such as queries and their clicks) contained in a search session can benefit the ranking performance of subsequent queries in the session. Existing neural context-aware ranking models usually rank documents based on either latent representations of user search behaviors or the word-level interactions between the candidate document and each historical behavior in the search session. However, these two kinds of models both have their own drawbacks. Representation-based models neglect fine-grained information on word-level interactions, whereas interaction-based models suffer from the length restriction of session sequence because of the large cost of word-level interactions. To complement the limitations of these two kinds of models, we propose a unified context-aware document ranking model that takes full advantage of both representation and interaction. Specifically, instead of matching a candidate document with every single historical query in a session, we encode the session history into a latent representation and use this representation to enhance the current query and the candidate document. We then just match the enhanced query and candidate document with several matching components to capture the fine-grained information of word-level interactions. Rich experiments on two public query logs prove the effectiveness and efficiency of our model for leveraging representation and interaction.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4223931259",
    "type": "article"
  },
  {
    "title": "Sequence-aware Knowledge Distillation for a Lightweight Event Representation",
    "doi": "https://doi.org/10.1145/3545798",
    "publication_date": "2022-06-27",
    "publication_year": 2022,
    "authors": "Jianming Zheng; Fei Cai; Yanxiang Ling; Honghui Chen",
    "corresponding_authors": "",
    "abstract": "Event representation targets to model the event-reasoning process as a machine-readable format. Previous studies on event representation mostly concentrate on a sole modeling perspective and have not well investigated the scenario-level knowledge, which can cause information loss. To cope with this dilemma, we propose a unified fine-tuning architecture-based approach ( UniFA-S ) that integrates all levels of trainings, including the scenario-level knowledge. However, another challenge for existing models is the ever-increasing computation overheads, restricting the deployment ability on limited resources devices. Hence, in this article, we aim to compress the cumbersome model UniFA-S into a lighter and easy-to-deploy one without much performance damage. To this end, we propose a sequence-aware knowledge distillation model (SaKD) that employs a dynamic self-distillation on the decouple-compress-couple framework for compressing UniFA-S , which cannot only realize the model compression, but also retain the integrity of individual components. We also design two fitting strategies to address the less-supervised issue at the distillation stage. Comprehensive experiments on representation-and-inference ability-based tasks validate the effectiveness of SaKD. Compared to UniFA-S , SaKD realizes a more portable event representation model at the cost of only 1.0% performance drop in terms of accuracy or Spearman’s correlation, which is far less than other knowledge distillation models.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4283591063",
    "type": "article"
  },
  {
    "title": "Metaphorical User Simulators for Evaluating Task-oriented Dialogue Systems",
    "doi": "https://doi.org/10.1145/3596510",
    "publication_date": "2023-05-22",
    "publication_year": 2023,
    "authors": "Weiwei Sun; Shuyu Guo; Shuo Zhang; Pengjie Ren; Zhumin Chen; Maarten de Rijke; Zhaochun Ren",
    "corresponding_authors": "",
    "abstract": "Task-oriented dialogue systems (TDSs) are assessed mainly in an offline setting or through human evaluation. The evaluation is often limited to single-turn or is very time-intensive. As an alternative, user simulators that mimic user behavior allow us to consider a broad set of user goals to generate human-like conversations for simulated evaluation. Employing existing user simulators to evaluate TDSs is challenging as user simulators are primarily designed to optimize dialogue policies for TDSs and have limited evaluation capabilities. Moreover, the evaluation of user simulators is an open challenge. In this work, we propose a metaphorical user simulator for end-to-end TDS evaluation, where we define a simulator to be metaphorical if it simulates a user’s analogical thinking in interactions with systems. We also propose a tester-based evaluation framework to generate variants, i.e., dialogue systems with different capabilities. Our user simulator constructs a metaphorical user model that assists the simulator in reasoning by referring to prior knowledge when encountering new items. We estimate the quality of simulators by checking the simulated interactions between simulators and variants. Our experiments are conducted using three TDS datasets. The proposed user simulator demonstrates better consistency with manual evaluation than an agenda-based simulator and a seq2seq model on three datasets; our tester framework demonstrates efficiency and has been tested on multiple tasks, such as conversational recommendation and e-commerce dialogues.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4377238805",
    "type": "article"
  },
  {
    "title": "A Versatile Framework for Evaluating Ranked Lists in Terms of Group Fairness and Relevance",
    "doi": "https://doi.org/10.1145/3589763",
    "publication_date": "2023-05-31",
    "publication_year": 2023,
    "authors": "Tetsuya Sakai; Jin Young Kim; In-Ho Kang",
    "corresponding_authors": "",
    "abstract": "We present a simple and versatile framework for evaluating ranked lists in terms of Group Fairness and Relevance, in which the groups (i.e., possible attribute values) can be either nominal or ordinal in nature. First, we demonstrate that when our framework is applied to a binary hard group membership setting, our Group Fairness and Relevance (GFR) measures can easily quantify the overall polarity of each ranked list. Second, by utilising an existing diversified search test collection and treating each intent as an attribute value, we demonstrate that our framework can also handle soft group membership and that the GFR measures are highly correlated with a diversified information retrieval (IR) measure in this context as well. Third, using real data from a Japanese local search service, we demonstrate how our framework enables researchers to study intersectional group fairness based on multiple attribute sets. We also show that the similarity function for comparing the achieved and target distributions over the attribute values should be chosen carefully when the attribute values are ordinal. For such situations, our recommendation is to use multiple similarity functions with our framework: for example, one based on Jensen-Shannon Divergence (which disregards the ordinal nature of the groups) and another based on Root Normalised Order-aware Divergence (which has been designed specifically for handling ordinal groups). In addition, we highlight the fundamental differences between our framework and Attention-Weighted Rank Fairness (AWRF), a group fairness measure used at the TREC Fair Ranking Track.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4378835047",
    "type": "article"
  },
  {
    "title": "Stylized Data-to-text Generation: A Case Study in the E-Commerce Domain",
    "doi": "https://doi.org/10.1145/3603374",
    "publication_date": "2023-06-07",
    "publication_year": 2023,
    "authors": "Liqiang Jing; Xuemeng Song; Xuming Lin; Zhongzhou Zhao; Wei Zhou; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "Existing data-to-text generation efforts mainly focus on generating a coherent text from non-linguistic input data, such as tables and attribute–value pairs, but overlook that different application scenarios may require texts of different styles. Inspired by this, we define a new task, namely stylized data-to-text generation, whose aim is to generate coherent text for the given non-linguistic data according to a specific style. This task is non-trivial, due to three challenges: the logic of the generated text, unstructured style reference and biased training samples. To address these challenges, we propose a novel stylized data-to-text generation model, named StyleD2T, comprising three components: logic planning-enhanced data embedding, mask-based style embedding, and unbiased stylized text generation. In the first component, we introduce a graph-guided logic planner for attribute organization to ensure the logic of generated text. In the second component, we devise feature-level mask-based style embedding to extract the essential style signal from the given unstructured style reference. In the last one, pseudo triplet augmentation is utilized to achieve unbiased text generation, and a multi-condition based confidence assignment function is designed to ensure the quality of pseudo samples. Extensive experiments on a newly collected dataset from Taobao 1 have been conducted, and the results show the superiority of our model over existing methods.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4379792729",
    "type": "article"
  },
  {
    "title": "MAN: Memory-augmented Attentive Networks for Deep Learning-based Knowledge Tracing",
    "doi": "https://doi.org/10.1145/3589340",
    "publication_date": "2023-08-18",
    "publication_year": 2023,
    "authors": "Liangliang He; Xiao Li; Pancheng Wang; Jintao Tang; Ting Wang",
    "corresponding_authors": "",
    "abstract": "Knowledge Tracing (KT) is the task of modeling a learner’s knowledge state to predict future performance in e-learning systems based on past performance. Deep learning-based methods, such as recurrent neural networks, memory-augmented neural networks, and attention-based neural networks, have recently been used in KT. Such methods have demonstrated excellent performance in capturing the latent dependencies of a learner’s knowledge state on recent exercises. However, these methods have limitations when it comes to dealing with the so-called Skill Switching Phenomenon (SSP), i.e., when learners respond to exercises in an e-learning system, the latent skills in the exercises typically switch irregularly. SSP will deteriorate the performance of deep learning-based approaches for simulating the learner’s knowledge state during skill switching, particularly when the association between the switching skills and the previously learned skills is weak. To address this problem, we propose the Memory-augmented Attentive Network (MAN), which combines the advantages of memory-augmented neural networks and attention-based neural networks. Specifically, in MAN, memory-augmented neural networks are used to model learners’ longer term memory knowledge, while attention-based neural networks are used to model learners’ recent term knowledge. In addition, we design a context-aware attention mechanism that automatically weighs the tradeoff between these two types of knowledge. With extensive experiments on several e-learning datasets, we show that MAN effectively improve predictive accuracies of existing state-of-the-art DLKT methods.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4385979163",
    "type": "article"
  },
  {
    "title": "Efficient Neural Ranking Using Forward Indexes and Lightweight Encoders",
    "doi": "https://doi.org/10.1145/3631939",
    "publication_date": "2023-11-08",
    "publication_year": 2023,
    "authors": "Jurek Leonhardt; Henrik Høeg Müller; Koustav Rudra; Megha Khosla; Abhijit Anand; Avishek Anand",
    "corresponding_authors": "",
    "abstract": "Dual-encoder-based dense retrieval models have become the standard in IR. They employ large Transformer-based language models, which are notoriously inefficient in terms of resources and latency. We propose Fast-Forward indexes—vector forward indexes which exploit the semantic matching capabilities of dual-encoder models for efficient and effective re-ranking. Our framework enables re-ranking at very high retrieval depths and combines the merits of both lexical and semantic matching via score interpolation. Furthermore, in order to mitigate the limitations of dual-encoders, we tackle two main challenges: Firstly, we improve computational efficiency by either pre-computing representations, avoiding unnecessary computations altogether, or reducing the complexity of encoders. This allows us to considerably improve ranking efficiency and latency. Secondly, we optimize the memory footprint and maintenance cost of indexes; we propose two complementary techniques to reduce the index size and show that, by dynamically dropping irrelevant document tokens, the index maintenance efficiency can be improved substantially. We perform an evaluation to show the effectiveness and efficiency of Fast-Forward indexes—our method has low latency and achieves competitive results without the need for hardware acceleration, such as GPUs.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4388493308",
    "type": "article"
  },
  {
    "title": "Cross-domain Recommendation via Dual Adversarial Adaptation",
    "doi": "https://doi.org/10.1145/3632524",
    "publication_date": "2023-11-11",
    "publication_year": 2023,
    "authors": "Hongzu Su; Jingjing Li; Zhekai Du; Lei Zhu; Ke Lü; Hengtao Shen",
    "corresponding_authors": "",
    "abstract": "Data scarcity is a perpetual challenge of recommendation systems, and researchers have proposed a variety of cross-domain recommendation methods to alleviate the problem of data scarcity in target domains. However, in many real-world cross-domain recommendation systems, the source domain and the target domain are sampled from different data distributions, which obstructs the cross-domain knowledge transfer. In this article, we propose to specifically align the data distributions between the source domain and the target domain to alleviate imbalanced sample distribution and thus challenge the data scarcity issue in the target domain. Technically, our proposed approach builds a dual adversarial adaptation (DAA) framework to adversarially train the target model together with a pre-trained source model. Two domain discriminators play the two-player minmax game with the target model and guide the target model to learn reliable domain-invariant features that can be transferred across domains. At the same time, the target model is calibrated to learn domain-specific information of the target domain. In addition, we formulate our approach as a plug-and-play module to boost existing recommendation systems. We apply the proposed method to address the issues of insufficient data and imbalanced sample distribution in real-world Click-through Rate/Conversion Rate predictions on two large-scale industrial datasets. We evaluate the proposed method in scenarios with and without overlapping users/items, and extensive experiments verify that the proposed method is able to significantly improve the prediction performance on the target domain. For instance, our method can boost PLE with a performance improvement of 15.4% in terms of Area Under Curve compared with single-domain PLE on our private game dataset. In addition, our method is able to surpass single-domain MMoE by 6.85% on the public datasets. Code: https://github.com/TL-UESTC/DAA .",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4388601341",
    "type": "article"
  },
  {
    "title": "Using Neural and Graph Neural Recommender Systems to Overcome Choice Overload: Evidence From a Music Education Platform",
    "doi": "https://doi.org/10.1145/3637873",
    "publication_date": "2023-12-20",
    "publication_year": 2023,
    "authors": "Hédi Razgallah; Michail Vlachos; Ahmad Ajalloeian; Ninghao Liu; Johannes Schneider; Alexis Steinmann",
    "corresponding_authors": "",
    "abstract": "The application of recommendation technologies has been crucial in the promotion of physical and digital content across numerous global platforms such as Amazon, Apple, and Netflix. Our study aims to investigate the advantages of employing recommendation technologies on educational platforms, with a particular focus on an educational platform for learning and practicing music. Our research is based on data from Tomplay, a music platform that offers sheet music with professional audio recordings, enabling users to discover and practice music content at varying levels of difficulty. Through our analysis, we emphasize the distinct interaction patterns on educational platforms like Tomplay, which we compare with other commonly used recommendation datasets. We find that interactions are comparatively sparse on educational platforms, with users often focusing on specific content as they learn, rather than interacting with a broader range of material. Therefore, our primary goal is to address the issue of data sparsity. We achieve this through entity resolution principles and propose a neural network (NN)-based recommendation model. Further, we improve this model by utilizing graph neural networks (GNNs), which provide superior predictive accuracy compared to NNs. Notably, our study demonstrates that GNNs are highly effective even for users with little or no historical preferences (cold-start problem). Our cold-start experiments also provide valuable insights into an independent issue, namely, the number of historical interactions needed by a recommendation model to gain a comprehensive understanding of a user. Our findings demonstrate that a platform acquires a solid knowledge of a user’s general preferences and characteristics with 50 past interactions. Overall, our study makes significant contributions to information systems research on business analytics and prescriptive analytics. Moreover, our framework and evaluation results offer implications for various stakeholders, including online educational institutions, education policymakers, and learning platform users.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4390030271",
    "type": "article"
  },
  {
    "title": "An Analysis on Matching Mechanisms and Token Pruning for Late-interaction Models",
    "doi": "https://doi.org/10.1145/3639818",
    "publication_date": "2024-01-31",
    "publication_year": 2024,
    "authors": "Qi Liu; Gang Guo; Jiaxin Mao; Zhicheng Dou; Ji-Rong Wen; Hao Jiang; Xinyu Zhang; Zhao Cao",
    "corresponding_authors": "",
    "abstract": "With the development of pre-trained language models, the dense retrieval models have become promising alternatives to the traditional retrieval models that rely on exact match and sparse bag-of-words representations. Different from most dense retrieval models using a bi-encoder to encode each query or document into a dense vector, the recently proposed late-interaction multi-vector models (i.e., ColBERT and COIL) achieve state-of-the-art retrieval effectiveness by using all token embeddings to represent documents and queries and modeling their relevance with a sum-of-max operation. However, these fine-grained representations may cause unacceptable storage overhead for practical search systems. In this study, we systematically analyze the matching mechanism of these late-interaction models and show that the sum-of-max operation heavily relies on the co-occurrence signals and some important words in the document. Based on these findings, we then propose several simple document pruning methods to reduce the storage overhead and compare the effectiveness of different pruning methods on different late-interaction models. We also leverage query pruning methods to further reduce the retrieval latency. We conduct extensive experiments on both in-domain and out-domain datasets and show that some of the used pruning methods can significantly improve the efficiency of these late-interaction models without substantially hurting their retrieval effectiveness.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4391402460",
    "type": "article"
  },
  {
    "title": "Token-Event-Role Structure-Based Multi-Channel Document-Level Event Extraction",
    "doi": "https://doi.org/10.1145/3643885",
    "publication_date": "2024-02-07",
    "publication_year": 2024,
    "authors": "Qizhi Wan; Changxuan Wan; Keli Xiao; Hui Xiong; Dexi Liu; Xiping Liu; Rong Hu",
    "corresponding_authors": "",
    "abstract": "Document-level event extraction is a long-standing challenging information retrieval problem involving a sequence of sub-tasks: entity extraction, event type judgment, and event type-specific multi-event extraction. However, addressing the problem as multiple learning tasks leads to increased model complexity. Also, existing methods insufficiently utilize the correlation of entities crossing different events, resulting in limited event extraction performance. This article introduces a novel framework for document-level event extraction, incorporating a new data structure called token-event-role and a multi-channel argument role prediction module. The proposed data structure enables our model to uncover the primary role of tokens in multiple events, facilitating a more comprehensive understanding of event relationships. By leveraging the multi-channel prediction module, we transform entity and multi-event extraction into a single task of predicting token–event pairs, thereby reducing the overall parameter size and enhancing model efficiency. The results demonstrate that our approach outperforms the state-of-the-art method by 9.5 percentage points in terms of the F 1 score, highlighting its superior performance in event extraction. Furthermore, an ablation study confirms the significant value of the proposed data structure in improving event extraction tasks, further validating its importance in enhancing the overall performance of the framework.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4391614230",
    "type": "article"
  },
  {
    "title": "Target-constrained Bidirectional Planning for Generation of Target-oriented Proactive Dialogue",
    "doi": "https://doi.org/10.1145/3652598",
    "publication_date": "2024-03-13",
    "publication_year": 2024,
    "authors": "Jian Wang; Dongding Lin; Wenjie Li",
    "corresponding_authors": "",
    "abstract": "Target-oriented proactive dialogue systems aim at leading conversations from a dialogue context toward a pre-determined target, such as making recommendations on designated items or introducing new specific topics. To this end, it is critical for such dialogue systems to plan reasonable actions to drive the conversation proactively, and meanwhile, to plan appropriate topics to move the conversation forward to the target topic smoothly. In this work, we mainly focus on effective dialogue planning for target-oriented dialogue generation. Inspired by decision-making theories in cognitive science, we propose a novel target-constrained bidirectional planning (TRIP) approach, which plans an appropriate dialogue path by looking ahead and looking back. By formulating the planning as a generation task, our TRIP bidirectionally generates a dialogue path consisting of a sequence of &lt;action, topic&gt; pairs using two Transformer decoders. They are expected to supervise each other and converge on consistent actions and topics by minimizing the decision gap and contrastive generation of targets. Moreover, we propose a target-constrained decoding algorithm with a bidirectional agreement to better control the planning process. Subsequently, we adopt the planned dialogue paths to guide dialogue generation in a pipeline manner, where we explore two variants: prompt-based generation and plan-controlled generation. Extensive experiments are conducted on two challenging dialogue datasets, which are re-purposed for exploring target-oriented dialogue. Our automatic and human evaluations demonstrate that the proposed methods significantly outperform various baseline models.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4392750069",
    "type": "article"
  },
  {
    "title": "Multi-grained Document Modeling for Search Result Diversification",
    "doi": "https://doi.org/10.1145/3652852",
    "publication_date": "2024-03-15",
    "publication_year": 2024,
    "authors": "Zhirui Deng; Zhicheng Dou; Zhan Su; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Search result diversification plays a crucial role in improving users’ search experience by providing users with documents covering more subtopics. Previous studies have made great progress in leveraging inter-document interactions to measure the similarity among documents. However, different parts of the document may embody different subtopics and existing models ignore the subtle similarities and differences of content within each document. In this article, we propose a hierarchical attention framework to combine intra-document interactions with inter-document interactions in a complementary manner in order to conduct multi-grained document modeling. Specifically, we separate the document into passages to model the document content from multi-grained perspectives. Then, we design stacked interaction blocks to conduct inter-document and intra-document interactions. Moreover, to measure the subtopic coverage of each document more accurately, we propose a passage-aware document-subtopic interaction to perform fine-grained document-subtopic interaction. Experimental results demonstrate that our model achieves state-of-the-art performance compared with existing methods.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4392849580",
    "type": "article"
  },
  {
    "title": "Beyond Relevance: Factor-level Causal Explanation for User Travel Decisions with Counterfactual Data Augmentation",
    "doi": "https://doi.org/10.1145/3653673",
    "publication_date": "2024-03-22",
    "publication_year": 2024,
    "authors": "Hanzhe Li; Jingjing Gu; Xinjiang Lu; D. Z. Shen; Yuting Liu; YaNan Deng; Guoliang Shi; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "Point-of-Interest (POI) recommendation, an important research hotspot in the field of urban computing, plays a crucial role in urban construction. While understanding the process of users’ travel decisions and exploring the causality of POI choosing is not easy due to the complex and diverse influencing factors in urban travel scenarios. Moreover, the spurious explanations caused by severe data sparsity, i.e., misrepresenting universal relevance as causality, may also hinder us from understanding users’ travel decisions. To this end, in this article, we propose a factor-level causal explanation generation framework based on counterfactual data augmentation for user travel decisions, named Factor-level Causal Explanation for User Travel Decisions (FCE-UTD), which can distinguish between true and false causal factors and generate true causal explanations. Specifically, we first assume that a user decision is composed of a set of several different factors. Then, by preserving the user decision structure with a joint counterfactual contrastive learning paradigm, we learn the representation of factors and detect the relevant factors. Next, we further identify true causal factors by constructing counterfactual decisions with a counterfactual representation generator, in particular, it can not only augment the dataset and mitigate the sparsity but also contribute to clarifying the causal factors from other false causal factors that may cause spurious explanations. Besides, a causal dependency learner is proposed to identify causal factors for each decision by learning causal dependency scores. Extensive experiments conducted on three real-world datasets demonstrate the superiority of our approach in terms of check-in rate, fidelity, and downstream tasks under different behavior scenarios. The extra case studies also demonstrate the ability of FCE-UTD to generate causal explanations in POI choosing.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4393085086",
    "type": "article"
  },
  {
    "title": "Unsupervised Social Bot Detection via Structural Information Theory",
    "doi": "https://doi.org/10.1145/3660522",
    "publication_date": "2024-04-25",
    "publication_year": 2024,
    "authors": "Hao Peng; Jingyun Zhang; Xiang Huang; Zhifeng Hao; Angsheng Li; Zhengtao Yu; Philip S. Yu",
    "corresponding_authors": "",
    "abstract": "Research on social bot detection plays a crucial role in maintaining the order and reliability of information dissemination while increasing trust in social interactions. The current mainstream social bot detection models rely on black-box neural network technology, for example, Graph Neural Network, Transformer, and so on, which lacks interpretability. In this work, we present UnDBot, a novel unsupervised, interpretable, yet effective, and practical framework for detecting social bots. This framework is built upon structural information theory. We begin by designing three social relationship metrics that capture various aspects of social bot behaviors: posting type distribution , posting influence , and follow-to-follower ratio . Three new relationships are utilized to construct a new, unified, and weighted social multi-relational graph, aiming to model the relevance of social user behaviors and discover long-distance correlations between users. Second, we introduce a novel method for optimizing heterogeneous structural entropy. This method involves the personalized aggregation of edge information from the social multi-relational graph to generate a two-dimensional encoding tree. The heterogeneous structural entropy facilitates decoding of the substantial structure of the social bots network and enables hierarchical clustering of social bots. Third, a new community labeling method is presented to distinguish social bot communities by computing the user’s stationary distribution, measuring user contributions to network structure, and counting the intensity of user aggregation within the community. Compared with 10 representative social bot detection approaches, comprehensive experiments demonstrate the advantages of effectiveness and interpretability of UnDBot on 4 real social network datasets.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4395448893",
    "type": "article"
  },
  {
    "title": "Breaking Through the Noisy Correspondence: A Robust Model for Image-Text Matching",
    "doi": "https://doi.org/10.1145/3662732",
    "publication_date": "2024-04-29",
    "publication_year": 2024,
    "authors": "Hangkun Shi; Meng Liu; X. Mu; Xuemeng Song; Yupeng Hu; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "Unleashing the power of image-text matching in real-world applications is hampered by noisy correspondence. Manually curating high-quality datasets is expensive and time-consuming, and datasets generated using diffusion models are not adequately well-aligned. The most promising way is to collect image-text pairs from the Internet, but it will inevitably introduce noisy correspondence. To reduce the negative impact of noisy correspondence, we propose a novel model that first transforms the noisy correspondence filtering problem into a similarity distribution modeling problem by exploiting the powerful capabilities of pre-trained models. Specifically, we use the Gaussian Mixture model to model the similarity obtained by CLIP as clean distribution and noisy distribution, to filter out most of the noisy correspondence in the dataset. Afterward, we used relatively clean data to fine-tune the model. To further reduce the negative impact of unfiltered noisy correspondence, i.e., a minimal part where two distributions intersect during the fine-tuning process, we propose a distribution-sensitive dynamic margin ranking loss, further increasing the distance between the two distributions. Through continuous iteration, the noisy correspondence gradually decreases and the model performance gradually improves. Our extensive experiments demonstrate the effectiveness and robustness of our model even under high noise rates.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4396216126",
    "type": "article"
  },
  {
    "title": "RevGNN: Negative Sampling Enhanced Contrastive Graph Learning for Academic Reviewer Recommendation",
    "doi": "https://doi.org/10.1145/3679200",
    "publication_date": "2024-07-22",
    "publication_year": 2024,
    "authors": "Weibin Liao; Yifan Zhu; Yanyan Li; Qi Zhang; Zhonghong Ou; Xuesong Li",
    "corresponding_authors": "",
    "abstract": "Acquiring reviewers for academic submissions is a challenging recommendation scenario. Recent graph learning-driven models have made remarkable progress in the field of recommendation, but their performance in the academic reviewer recommendation task may suffer from a significant false negative issue. This arises from the assumption that unobserved edges represent negative samples. In fact, the mechanism of anonymous review results in inadequate exposure of interactions between reviewers and submissions, leading to a higher number of unobserved interactions compared to those caused by reviewers declining to participate. Therefore, investigating how to better comprehend the negative labeling of unobserved interactions in academic reviewer recommendations is a significant challenge. This study aims to tackle the ambiguous nature of unobserved interactions in academic reviewer recommendations. Specifically, we propose an unsupervised Pseudo Neg-Label strategy to enhance graph contrastive learning (GCL) for recommending reviewers for academic submissions, which we call RevGNN. RevGNN utilizes a two-stage encoder structure that encodes both scientific knowledge and behavior using Pseudo Neg-Label to approximate review preference. Extensive experiments on three real-world datasets demonstrate that RevGNN outperforms all baselines across four metrics. Additionally, detailed further analyses confirm the effectiveness of each component in RevGNN.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4400880042",
    "type": "article"
  },
  {
    "title": "TCGC: Temporal Collaboration-Aware Graph Co-Evolution Learning for Dynamic Recommendation",
    "doi": "https://doi.org/10.1145/3687470",
    "publication_date": "2024-08-27",
    "publication_year": 2024,
    "authors": "Haoran Tang; Shiqing Wu; Xueyao Sun; Jun Zeng; Guandong Xu; Qing Li",
    "corresponding_authors": "",
    "abstract": "Dynamic recommendation systems, where users interact with items continuously over time, have been widely deployed in real-world online streaming applications. The burst of interaction stream causes a rapid evolution of both users and items. To update representations dynamically, existing studies have investigated event-level and history-level dynamics by modeling the newly arrived interactions and aggregating historical interactions, respectively. However, most of them directly learn the representation evolution as new interactions occur, without exploring the collaboration between the newly arrived and historical interactions, thus failing to scrutinize whether those new interactions would benefit the evolution learning process when generating dynamic representations. Moreover, most of them model the two levels of dynamics independently, explicitly ignoring the inherent co-evolving correlation between them. In this work, we propose the Temporal Collaboration-Aware Graph Co-Evolution Learning (TCGC) for the dynamic recommendation scenario. First, we explore the effectiveness of collaborative information and devise the collaboration-aware indicator to guide the evolution learning process. Second, we design a temporal co-evolving graph network, enabling our framework to capture the correlation between event and history dynamics. Third, we leverage the evolution task and recommendation task together for joint training. Extensive experiments on four public datasets demonstrate the superiority and effectiveness of our proposed TCGC.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4401906128",
    "type": "article"
  },
  {
    "title": "A Multifocal Graph-based Neural Network Scheme for Topic Event Extraction",
    "doi": "https://doi.org/10.1145/3696353",
    "publication_date": "2024-09-19",
    "publication_year": 2024,
    "authors": "Qizhi Wan; Changxuan Wan; Keli Xiao; Rong Hu; Dexi Liu; Guoqiong Liao; Xiping Liu; Yuxin Shuai",
    "corresponding_authors": "",
    "abstract": "Event extraction is a long-standing and challenging task in natural language processing, and existing studies mainly focus on extracting events within sentences. However, a significant problem that has not been carefully investigated is whether an “event topic” can be identified to represent the main aspects of extracted events. This paper formulates the “topic event” extraction problem, aiming to identify a representative event from extracted ones. Specifically, after defining the topic event, we develop a multifocal graph-based framework to handle the extraction task. To enrich the associations of events and their tokens, we construct four event graphs, including the event subgraph and three event-associated graphs (i.e., event dependency parsing graph, event organization graph, and event share token graph), that reflect the internal and external structures of events, respectively. Subsequently, we design a multi-attention event-graph neural network to capture these event graph structures and improve event subgraph embedding. Finally, the output embeddings in the last layer of each channel are concatenated and fed into a fully connected network for topic event recognition. Extensive experiments validate the effectiveness of our method, and the results confirm its superiority over state-of-the-art baselines. In-depth analyses explore the essential factors (e.g., graph structures, attentions, feature generation method, etc.) determining the extraction performance.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4402622753",
    "type": "article"
  },
  {
    "title": "Building A Coding Assistant via the Retrieval-Augmented Language Model",
    "doi": "https://doi.org/10.1145/3695868",
    "publication_date": "2024-09-16",
    "publication_year": 2024,
    "authors": "Xinze Li; Hanbin Wang; Zhenghao Liu; Shi Yu; Shuo Wang; Yukun Yan; Yukai Fu; Yu Gu; Ge Yu",
    "corresponding_authors": "",
    "abstract": "Pretrained language models have shown strong effectiveness in code-related tasks, such as code retrieval, code generation, code summarization, and code completion tasks. In this paper, we propose CO de assista N t vi A retrieval-augme N ted language model (CONAN), which aims to build a code assistant by mimicking the knowledge-seeking behaviors of humans during coding. Specifically, it consists of a code structure aware retriever (CONAN-R) and a dual-view code representation-based retrieval-augmented generation model (CONAN-G). CONAN-R pretrains CodeT5 using Code-Documentation Alignment and Masked Entity Prediction tasks to make language models code structure-aware and learn effective representations for code snippets and documentation. Then CONAN-G designs a dual-view code representation mechanism for implementing a retrieval-augmented code generation model. CONAN-G regards the code documentation descriptions as prompts, which help language models better understand the code semantics. Our experiments show that CONAN achieves convincing performance on different code generation tasks and significantly outperforms previous retrieval augmented code generation models. Our further analyses show that CONAN learns tailored representations for both code snippets and documentation by aligning code-documentation data pairs and capturing structural semantics by masking and predicting entities in the code data. Additionally, the retrieved code snippets and documentation provide necessary information from both program language and natural language to assist the code generation process. CONAN can also be used as an assistant for Large Language Models (LLMs), providing LLMs with external knowledge in shorter code document lengths to improve their effectiveness on various code tasks. It shows the ability of CONAN to extract necessary information and help filter out the noise from retrieved code documents.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4402817791",
    "type": "article"
  },
  {
    "title": "Revisiting Conversation Discourse for Dialogue Disentanglement",
    "doi": "https://doi.org/10.1145/3698191",
    "publication_date": "2024-10-01",
    "publication_year": 2024,
    "authors": "Bobo Li; Hao Fei; Fei Li; Shengqiong Wu; Lizi Liao; Yinwei Wei; Tat‐Seng Chua; Donghong Ji",
    "corresponding_authors": "",
    "abstract": "Dialogue disentanglement aims to detach the chronologically ordered utterances into several independent sessions. Conversation utterances are essentially organized and described by the underlying discourse, and thus dialogue disentanglement requires the full understanding and harnessing of the intrinsic discourse attribute. In this paper, we propose enhancing dialogue disentanglement by taking full advantage of the dialogue discourse characteristics. First of all, in feature encoding stage , we construct the heterogeneous graph representations to model the various dialogue-specific discourse structural features, including the static speaker-role structures (i.e., speaker-utterance and speaker-mentioning structure) and the dynamic contextual structures (i.e., the utterance-distance and partial-replying structure). We then develop a structure-aware framework to integrate the rich structural features for better modeling the conversational semantic context. Second, in model learning stage , we perform optimization with a hierarchical ranking loss mechanism, which groups dialogue utterances into different discourse levels and carries training covering pair-wise and session-wise levels hierarchically. Third, in inference stage , we devise an easy-first decoding algorithm, which performs utterance pairing under the easy-to-hard manner with a global context, breaking the constraint of traditional sequential decoding order. On two benchmark datasets, our overall system achieves new state-of-the-art performances on all evaluations. In-depth analyses further demonstrate the efficacy of each proposed idea and also reveal how our methods help advance the task. Our work has great potential to facilitate broader multi-party multi-thread dialogue applications.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4403029276",
    "type": "article"
  },
  {
    "title": "Enhancing ID-based Recommendation with Large Language Models",
    "doi": "https://doi.org/10.1145/3704263",
    "publication_date": "2024-11-13",
    "publication_year": 2024,
    "authors": "Lei Chen; Chen Gao; Xiaoyi Du; Hengliang Luo; Depeng Jin; Yong Li; Meng Wang",
    "corresponding_authors": "",
    "abstract": "Large Language Models (LLMs) have recently garnered significant attention in various domains, including recommendation systems. Recent research leverages the capabilities of LLMs to improve the performance and user modeling aspects of recommender systems. These studies primarily focus on utilizing LLMs to interpret textual data in recommendation tasks. However, it's worth noting that in ID-based recommendations, textual data is absent, and only ID data is available. The untapped potential of LLMs for ID data within the ID-based recommendation paradigm remains relatively unexplored. To this end, we introduce a pioneering approach called “LLM for ID-based Recommendation” (LLM4IDRec). This innovative approach integrates the capabilities of LLMs while exclusively relying on ID data, thus diverging from the previous reliance on textual data. The basic idea of LLM4IDRec is that by employing LLM to augment ID data, if augmented ID data can improve recommendation performance, it demonstrates the ability of LLM to interpret ID data effectively, exploring an innovative way for the integration of LLM in ID-based recommendation. Specifically, we first define a prompt template to enhance LLM's ability to comprehend ID data and the ID-based recommendation task. Next, during the process of generating training data using this prompt template, we develop two efficient methods to capture both the local and global structure of ID data. We feed this generated training data into the LLM and employ LoRA for fine-tuning LLM. Following the fine-tuning phase, we utilize the fine-tuned LLM to generate ID data that aligns with users’ preferences. We design two filtering strategies to eliminate invalid generated data. Thirdly, we can merge the original ID data with the generated ID data, creating augmented data. Finally, we input this augmented data into the existing ID-based recommendation models without any modifications to the recommendation model itself. We evaluate the effectiveness of our LLM4IDRec approach using three widely-used datasets. Our results demonstrate a notable improvement in recommendation performance, with our approach consistently outperforming existing methods in ID-based recommendation by solely augmenting input data.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4404304342",
    "type": "article"
  },
  {
    "title": "One Model for All: Large Language Models are Domain-Agnostic Recommendation Systems",
    "doi": "https://doi.org/10.1145/3705727",
    "publication_date": "2024-11-26",
    "publication_year": 2024,
    "authors": "Zuoli Tang; Zhaoxin Huan; Zihao Li; Xiaolu Zhang; Jun Hu; Chilin Fu; Jun Zhou; Lixin Zou; Chenliang Li",
    "corresponding_authors": "",
    "abstract": "Sequential recommendation systems aim to predict users’ next likely interaction based on their history. However, these systems face data sparsity and cold-start problems. Utilizing data from other domains, known as multi-domain methods, is useful for alleviating these problems. However, traditional multi-domain methods rely on meaningless ID-based item representation, which makes it difficult to align items with similar meanings from different domains, yielding sup-optimal knowledge transfer. This paper introduces LLM-Rec , a framework that utilizes pre-trained large language models (LLMs) for domain-agnostic recommendation. Specifically, we mix user's behaviors from multiple domains and concatenate item titles into a sentence, then use LLMs for generating user and item representations. By mixing behaviors across different domains, we can exploit the knowledge encoded in LLMs to bridge the semantic across over multi-domain behaviors, thus obtaining semantically rich representations and improving performance in all domains. Furthermore, we explore the underlying reasons why LLMs are effective and investigate whether LLMs can understand the semantic correlations as the recommendation model, and if advanced techniques like scaling laws in NLP also work in recommendations. We conduct extensive experiments with LLMs ranging from 40M to 6.7B to answer the above questions and to verify the effectiveness of LLM-Rec in multi-domain recommendation \\({}^{\\ddagger}\\) .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4404742642",
    "type": "article"
  },
  {
    "title": "Certified Unlearning for Federated Recommendation",
    "doi": "https://doi.org/10.1145/3706419",
    "publication_date": "2024-12-02",
    "publication_year": 2024,
    "authors": "Thanh Trung Huynh; Trong Bang Nguyen; Thanh Nguyen; Phi Le Nguyen; Hongzhi Yin; Quoc Viet Hung Nguyen; Thành Tâm Nguyên",
    "corresponding_authors": "",
    "abstract": "Recommendation systems play a crucial role in providing web-based suggestion utilities by leveraging user behavior, preferences, and interests. In the context of privacy concerns and the proliferation of handheld devices, federated recommender systems have emerged as a promising solution. These systems allow each client to train a local model and exchange only the model updates with a central server, thus preserving data privacy. However, certain use cases necessitate the deduction of contributions from specific clients, a process known as “unlearning”. Existing machine unlearning methods are designed for centralized settings and do not cater to the collaborative nature of recommendation systems, thereby overlooking their unique characteristics. This paper proposes CFRU, a novel federated recommendation unlearning model that enables efficient and certified removal of target clients from the global model. Instead of retraining the model, our approach rolls back and eliminates the historical updates associated with the target client. To efficiently store the learning process's historical updates, we propose sampling strategies that reduce the number of historical updates, retaining only the most significant ones. Furthermore, we analyze the potential bias introduced by the removal of target clients’ updates at each training round and establish an estimation using the Lipschitz condition. Leveraging this estimation, we propose an efficient iterative scheme to accumulate the bias across all rounds, compensating for the removed updates from the global model and recovering its utility without requiring post-training steps. Extensive experiments conducted on two real-world datasets, incorporating two poison attack scenarios, have shown that our unlearning technique can achieve a model quality that is 99.3% equivalent to retraining the model from scratch while performing up to 1000 times faster.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4404927184",
    "type": "article"
  },
  {
    "title": "Self Data Augmentation for Open Domain Question Answering",
    "doi": "https://doi.org/10.1145/3707449",
    "publication_date": "2024-12-10",
    "publication_year": 2024,
    "authors": "Qin Zhang; Mengqi Zheng; Shangsi Chen; Han Liu; Meng Fang",
    "corresponding_authors": "",
    "abstract": "Information Retrieval (IR) constitutes a vital facet of Open-Domain Question Answering (ODQA) systems, focusing on the exploration of pertinent information within extensive collections of passages, such as Wikipedia, to facilitate subsequent reader processing. Historically, information retrieval relied on textual overlaps for relevant context retrieval, employing methods like BM25 and TF-IDF, which, however, lacked natural language understanding. The advent of deep learning ushered in a new era, leading to the introduction of Dense Passage Retrievers (DPR), shows superiority over traditional sparse retrievers. These dense retrievers leverage Pre-trained Language Models (PLMs) to initialize context encoders, enabling the extraction of natural language representations. They utilize the distance between latent vectors of contexts as a metric for assessing similarity. However, DPR methods are heavily reliant on large volumes of meticulously labeled data, such as Natural Questions. The process of data labeling is both costly and time-intensive. In this paper, we propose a novel data augmentation methodology SDA (Self Data Augmentation) that employs DPR models to automatically annotate unanswered questions. Specifically, we initiate the process by retrieving relevant pseudo passages for these unlabeled questions. We subsequently introduce three distinct passage selection methods to annotate these pseudo passages. Ultimately, we amalgamate the pseudo-labeled passages with the unanswered questions to create augmented data. Our experimental evaluations conducted on two extensive datasets (Natural Questions and TriviaQA), alongside a reletively small dataset (WebQuestions), utilizing three diverse base models, illustrate the significant enhancement achieved through the incorporation of freshly augmented data. Moreover, our proposed data augmentation method exhibits remarkable flexibility, which is readily adaptable to various dense retrievers. Additionally, we have conducted a comprehensive human study on the augmented data, which further supports our conclusions.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4405247832",
    "type": "article"
  },
  {
    "title": "The maximum entropy approach and probabilistic IR models",
    "doi": "https://doi.org/10.1145/352595.352597",
    "publication_date": "2000-07-01",
    "publication_year": 2000,
    "authors": "Warren R. Greiff; Jay Ponte",
    "corresponding_authors": "",
    "abstract": "This paper takes a fresh look at modeling approaches to information retrieval that have been the basis of much of the probabilistically motivated IR research over the last 20 years. We shall adopt a subjectivist Bayesian view of probabilities and argue that classical work on probabilistic retrieval is best understood from this perspective. The main focus of the paper will be the ranking formulas corresponding to the Binary Independence Model (BIM), presented originally by Roberston and Sparck Jones [1977] and the Combination Match Model (CMM), developed shortly thereafter by Croft and Harper [1979]. We will show how these same ranking formulas can result from a probabilistic methodology commonly known as Maximum Entropy (MAXENT).",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2019286881",
    "type": "article"
  },
  {
    "title": "C-TODOS: an automatic tool for office system conceptual design",
    "doi": "https://doi.org/10.1145/76158.76893",
    "publication_date": "1989-10-01",
    "publication_year": 1989,
    "authors": "Barbara Pernici; Federico Barbic; Roberto Maiocchi; Mariagrazia Fugini; J. R. Rames; Colette Rolland",
    "corresponding_authors": "",
    "abstract": "Designers of office information systems, which share various features with information systems and software development, need to carefully consider special issues such as document and communication flows, user roles, user interfaces, and available technology. The ESPRIT Project, Automatic TOols for Designing Office Information Systems (TODOS), proposes an integrated environment for office design with tools for requirements collection and analysis, conceptual design, rapid prototyping, and architecture selection. Conceptual design is a central phase of office system design: It provides correct and complete functional requirements from which the office prototype will be developed and the final architecture chosen. C-TODOS, the conceptual design support tool developed within TODOS, is presented in this paper. The purpose of C-TODOS is to give the designer tools for supporting conceptual modeling activities with the goal of obtaining correct, consistent, and good quality office-functional specifications. This paper presents C-TODOS within the TODOS development environment and describes the basic features of the tool: the TODOS Conceptual Model, the Specification Database, and the Modeling, Query and Consistency Checking Modules. The use of C-TODOS, through illustration of the development of a test case, and possible future research are discussed.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2002107844",
    "type": "article"
  },
  {
    "title": "Design implications of a task-driven approach to unstructured cognitive tasks in office work",
    "doi": "https://doi.org/10.1145/4229.4230",
    "publication_date": "1985-07-01",
    "publication_year": 1985,
    "authors": "Sidney E. Harris; Harvey J. Brightman",
    "corresponding_authors": "",
    "abstract": "Previous research in modeling office activities has been primarily oriented toward office work that is structured and organized. In this paper we report on efforts to develop a new methodology for needs assessment evaluation. We use the Critical Task Method to identify the “bottleneck cognitive tasks” of principals with an unstructured work profile. Data were collected on the computer-support needs of faculty researchers, and the findings indicate that a “knowledge-based” design offers the most promise for delivering effective support. In addition, the systems design suggests the integration of text, data, voice, and images.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1976505058",
    "type": "article"
  },
  {
    "title": "Query optimization on local area networks",
    "doi": "https://doi.org/10.1145/3864.3866",
    "publication_date": "1985-01-02",
    "publication_year": 1985,
    "authors": "Alan R. Hevner; Owen Q. Wu; S. Bing Yao",
    "corresponding_authors": "",
    "abstract": "Local area networks are becoming widely used as the database communication framework for sophisticated information systems. Databases can be distributed among stations on a network to achieve the advantages of performance, reliability, availability, and modularity. Efficient distributed query optimization algorithms are presented here for two types of local area networks: address ring networks and broadcast networks . Optimal algorithms are designed for simple queries . Optimization principles from these algorithms guide the development of effective heuristic algorithms for general queries on both types of networks. Several examples illustrate distributed query processing on local area networks.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1987812171",
    "type": "article"
  },
  {
    "title": "Distributed form management",
    "doi": "https://doi.org/10.1145/78915.78918",
    "publication_date": "1990-01-03",
    "publication_year": 1990,
    "authors": "Heikki Hämmäinen; Eero Eloranta; Jari Alasuvanto",
    "corresponding_authors": "",
    "abstract": "An open architecture for distributed form management is described. The model employs object-orientation in describing organizational units as well as individual users as entities with uniform external interfaces. Each entity is represented by an autonomous user agent which operates on local and migrating forms . The form concept encapsulates data, layout, and rules into a unified object which is the basic unit of presentation, processing, storage, and communication. All functionality of the system appears in rules of form classes and all data in instances of these form classes. This approach applies the techniques of computer supported cooperative work to provide a flexible mechanism for interpersonal, intraoffice, and interoffice procedures. The main challenge is to organize the collaboration without affecting the autonomy of individual user agents. In this respect, the contribution of the model is the mechanism for form migration. The dynamic integration of forms into different agents is solved with the coordinated interchange of form classes. A specific inheritance scheme provides the desired flexibility by separating the interrelated private and public form operations within each agent. The paper first describes the architecture by starting from a single agent and moving progressively towards a set of cooperating agents. Then an agent implementation called PAGES is described, experiences reported, and the open issues discussed. A typical distributed ordering procedure is used as an example throughout the text.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1989323565",
    "type": "article"
  },
  {
    "title": "Compression, information theory, and grammars: a unified approach",
    "doi": "https://doi.org/10.1145/78915.78917",
    "publication_date": "1990-01-03",
    "publication_year": 1990,
    "authors": "Abraham Bookstein; Shmuel T. Klein",
    "corresponding_authors": "",
    "abstract": "Text compression is of considerable theoretical and practical interest. It is, for example, becoming increasingly important for satisfying the requirements of fitting a large database onto a single CD-ROM. Many of the compression techniques discussed in the literature are model based. We here propose the notion of a formal grammar as a flexible model of text generation that encompasses most of the models offered before as well as, in principle, extending the possibility of compression to a much more general class of languages. Assuming a general model of text generation, a derivation is given of the well known Shannon entropy formula, making possible a theory of information based upon text representation rather than on communication. The ideas are shown to apply to a number of commonly used text models. Finally, we focus on a Markov model of text generation, suggest an information theoretic measure of similarity between two probability distributions, and develop a clustering algorithm based on this measure. This algorithm allows us to cluster Markov states, and thereby base our compression algorithm on a smaller number of probability distributions than would otherwise have been required. A number of theoretical consequences of this approach to compression are explored, and a detailed example is given.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2090685444",
    "type": "article"
  },
  {
    "title": "Portability of syntax and semantics in DATALOG",
    "doi": "https://doi.org/10.1145/3914.3982",
    "publication_date": "1985-04-01",
    "publication_year": 1985,
    "authors": "Carole D. Hafner; Kurt Godden",
    "corresponding_authors": "",
    "abstract": "This paper presents a discussion of the techniques developed and problems encountered during the design, implementation, and experimental use of a portable natural language processor. Datalog (for “database dialogue\") is an experimental natural language query system, which was designed to achieve a maximum degree of portability and extendibility. Datalog uses a three-level architecture to provide both portability of syntax to new and extended tasks and portability of semantics to new database applications. The implementation of each of the three levels, the structures and conventions that control the interactions among them, and the way in which different aspects of the design contribute to portability are described. Finally, two specific, implemented examples are presented, showing how it was possible to transport or extend Datalog by changing only one “layer” of the system's knowledge and achieve correct processing of the extended input by the entire system.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1997257732",
    "type": "article"
  },
  {
    "title": "Extraction of coherent relevant passages using hidden Markov models",
    "doi": "https://doi.org/10.1145/1165774.1165775",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Jing Jiang; ChengXiang Zhai",
    "corresponding_authors": "",
    "abstract": "In information retrieval, retrieving relevant passages, as opposed to whole documents, not only directly benefits the end user by filtering out the irrelevant information within a long relevant document, but also improves retrieval accuracy in general. A critical problem in passage retrieval is to extract coherent relevant passages accurately from a document, which we refer to as passage extraction . While much work has been done on passage retrieval, the passage extraction problem has not been seriously studied. Most existing work tends to rely on presegmenting documents into fixed-length passages which are unlikely optimal because the length of a relevant passage is presumably highly sensitive to both the query and document.In this article, we present a new method for accurately detecting coherent relevant passages of variable lengths using hidden Markov models (HMMs). The HMM-based method naturally captures the topical boundaries between passages relevant and nonrelevant to the query. Pseudo-feedback mechanisms can be naturally incorporated into such an HMM-based framework to improve parameter estimation. We show that with appropriate parameter estimation, the HMM method outperforms a number of strong baseline methods on two datasets. We further show how the HMM method can be applied on top of any basic passage extraction method to improve passage boundaries.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2038587496",
    "type": "article"
  },
  {
    "title": "Reducing human interactions in Web directory searches",
    "doi": "https://doi.org/10.1145/1281485.1281491",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "Ori Gerstel; Shay Kutten; Eduardo Sany Laber; Rachel Matichin; David Peleg; Artur Alves Pessoa; Críston Pereira de Souza",
    "corresponding_authors": "",
    "abstract": "Consider a website containing a collection of webpages with data such as in Yahoo or the Open Directory project. Each page is associated with a weight representing the frequency with which that page is accessed by users. In the tree hierarchy representation, accessing each page requires the user to travel along the path leading to it from the root. By enhancing the index tree with additional edges (hotlinks) one may reduce the access cost of the system. In other words, the hotlinks reduce the expected number of steps needed to reach a leaf page from the tree root, assuming that the user knows which hotlinks to take. The hotlink enhancement problem involves finding a set of hotlinks minimizing this cost. This article proposes the first exact algorithm for the hotlink enhancement problem. This algorithm runs in polynomial time for trees with logarithmic depth. Experiments conducted with real data show that significant improvement in the expected number of accesses per search can be achieved in websites using this algorithm. These experiments also suggest that the simple and much faster heuristic proposed previously by Czyzowicz et al. [2003] creates hotlinks that are nearly optimal in the time savings they provide to the user. The version of the hotlink enhancement problem in which the weight distribution on the leaves is unknown is discussed as well. We present a polynomial-time algorithm that is optimal for any tree for any depth.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2161378143",
    "type": "article"
  },
  {
    "title": "An empirical investigation of user term feedback in text-based targeted image search",
    "doi": "https://doi.org/10.1145/1198296.1198299",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Joyce Chai; Chen Zhang; Rong Jin",
    "corresponding_authors": "",
    "abstract": "Text queries are natural and intuitive for users to describe their information needs. However, text-based image retrieval faces many challenges. Traditional text retrieval techniques on image descriptions have not been very successful. This is mainly due to the inconsistent textual descriptions and the discrepancies between user queries and terms in the descriptions. To investigate strategies to alleviate this vocabulary problem, this article examines the role of user term feedback in targeted image search that is based on text-based image retrieval. Term feedback refers to the feedback from a user on specific terms regarding their relevance to a target image. Previous studies have indicated the effectiveness of term feedback in interactive text retrieval. However, in our experiments on text-based image retrieval, the term feedback has not been shown to be effective. Our results indicate that, although term feedback has a positive effect by allowing users to identify more relevant terms, it also has a strong negative effect by providing more opportunities for users to specify irrelevant terms. To understand these different effects and their implications, this article further analyzes important factors that contribute to the utility of term feedback and discusses the outlook of term feedback in interactive text-based image retrieval.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2037050119",
    "type": "article"
  },
  {
    "title": "Classification-aware hidden-web text database selection",
    "doi": "https://doi.org/10.1145/1344411.1344412",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Panagiotis G. Ipeirotis; Luis Gravano",
    "corresponding_authors": "",
    "abstract": "Many valuable text databases on the web have noncrawlable contents that are “hidden” behind search interfaces. Metasearchers are helpful tools for searching over multiple such “hidden-web” text databases at once through a unified query interface. An important step in the metasearching process is database selection, or determining which databases are the most relevant for a given user query. The state-of-the-art database selection techniques rely on statistical summaries of the database contents, generally including the database vocabulary and associated word frequencies. Unfortunately, hidden-web text databases typically do not export such summaries, so previous research has developed algorithms for constructing approximate content summaries from document samples extracted from the databases via querying. We present a novel “focused-probing” sampling algorithm that detects the topics covered in a database and adaptively extracts documents that are representative of the topic coverage of the database. Our algorithm is the first to construct content summaries that include the frequencies of the words in the database. Unfortunately, Zipf's law practically guarantees that for any relatively large database, content summaries built from moderately sized document samples will fail to cover many low-frequency words; in turn, incomplete content summaries might negatively affect the database selection process, especially for short queries with infrequent words. To enhance the sparse document samples and improve the database selection decisions, we exploit the fact that topically similar databases tend to have similar vocabularies, so samples extracted from databases with a similar topical focus can complement each other. We have developed two database selection algorithms that exploit this observation. The first algorithm proceeds hierarchically and selects the best categories for a query, and then sends the query to the appropriate databases in the chosen categories. The second algorithm uses “shrinkage,” a statistical technique for improving parameter estimation in the face of sparse data, to enhance the database content summaries with category-specific words. We describe how to modify existing database selection algorithms to adaptively decide (at runtime) whether shrinkage is beneficial for a query. A thorough evaluation over a variety of databases, including 315 real web databases as well as TREC data, suggests that the proposed sampling methods generate high-quality content summaries and that the database selection algorithms produce significantly more relevant database selection decisions and overall search results than existing algorithms.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2125121047",
    "type": "article"
  },
  {
    "title": "Identifying, Indexing, and Ranking Chemical Formulae and Chemical Names in Digital Documents",
    "doi": "https://doi.org/10.1145/1961209.1961215",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "Bingjun Sun; Prasenjit Mitra; C. Lee Giles; Karl T. Mueller",
    "corresponding_authors": "",
    "abstract": "End-users utilize chemical search engines to search for chemical formulae and chemical names. Chemical search engines identify and index chemical formulae and chemical names appearing in text documents to support efficient search and retrieval in the future. Identifying chemical formulae and chemical names in text automatically has been a hard problem that has met with varying degrees of success in the past. We propose algorithms for chemical formula and chemical name tagging using Conditional Random Fields (CRFs) and Support Vector Machines (SVMs) that achieve higher accuracy than existing (published) methods. After chemical entities have been identified in text documents, they must be indexed. In order to support user-provided search queries that require a partial match between the chemical name segment used as a keyword or a partial chemical formula, all possible (or a significant number of) subformulae of formulae that appear in any document and all possible subterms (e.g., “methyl”) of chemical names (e.g., “methylethyl ketone”) must be indexed. Indexing all possible subformulae and subterms results in an exponential increase in the storage and memory requirements as well as the time taken to process the indices. We propose techniques to prune the indices significantly without reducing the quality of the returned results significantly. Finally, we propose multiple query semantics to allow users to pose different types of partial search queries for chemical entities. We demonstrate empirically that our search engines improve the relevance of the returned results for search queries involving chemical entities.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2009556891",
    "type": "article"
  },
  {
    "title": "An information-theoretic framework for semantic-multimedia retrieval",
    "doi": "https://doi.org/10.1145/1852102.1852105",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "João Magalhães; Stefan Rüger",
    "corresponding_authors": "",
    "abstract": "This article is set in the context of searching text and image repositories by keyword. We develop a unified probabilistic framework for text, image, and combined text and image retrieval that is based on the detection of keywords (concepts) using automated image annotation technology. Our framework is deeply rooted in information theory and lends itself to use with other media types. We estimate a statistical model in a multimodal feature space for each possible query keyword. The key element of our framework is to identify feature space transformations that make them comparable in complexity and density. We select the optimal multimodal feature space with a minimum description length criterion from a set of candidate feature spaces that are computed with the average-mutual-information criterion for the text part and hierarchical expectation maximization for the visual part of the data. We evaluate our approach in three retrieval experiments (only text retrieval, only image retrieval, and text combined with image retrieval), verify the framework's low computational complexity, and compare with existing state-of-the-art ad-hoc models.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2078116075",
    "type": "article"
  },
  {
    "title": "High-performance processing of text queries with tunable pruned term and term pair indexes",
    "doi": "https://doi.org/10.1145/2094072.2094077",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "Andreas Broschart; Ralf Schenkel",
    "corresponding_authors": "",
    "abstract": "Term proximity scoring is an established means in information retrieval for improving result quality of full-text queries. Integrating such proximity scores into efficient query processing, however, has not been equally well studied. Existing methods make use of precomputed lists of documents where tuples of terms, usually pairs, occur together, usually incurring a huge index size compared to term-only indexes. This article introduces a joint framework for trading off index size and result quality, and provides optimization techniques for tuning precomputed indexes towards either maximal result quality or maximal query processing performance under controlled result quality, given an upper bound for the index size. The framework allows to selectively materialize lists for pairs based on a query log to further reduce index size. Extensive experiments with two large text collections demonstrate runtime improvements of more than one order of magnitude over existing text-based processing techniques with reasonable index sizes.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2046874737",
    "type": "article"
  },
  {
    "title": "Approximate Recall Confidence Intervals",
    "doi": "https://doi.org/10.1145/2414782.2414784",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "William Webber",
    "corresponding_authors": "William Webber",
    "abstract": "Recall, the proportion of relevant documents retrieved, is an important measure of effectiveness in information retrieval, particularly in the legal, patent, and medical domains. Where document sets are too large for exhaustive relevance assessment, recall can be estimated by assessing a random sample of documents, but an indication of the reliability of this estimate is also required. In this article, we examine several methods for estimating two-tailed recall confidence intervals. We find that the normal approximation in current use provides poor coverage in many circumstances, even when adjusted to correct its inappropriate symmetry. Analytic and Bayesian methods based on the ratio of binomials are generally more accurate but are inaccurate on small populations. The method we recommend derives beta-binomial posteriors on retrieved and unretrieved yield, with fixed hyperparameters, and a Monte Carlo estimate of the posterior distribution of recall. We demonstrate that this method gives mean coverage at or near the nominal level, across several scenarios, while being balanced and stable. We offer advice on sampling design, including the allocation of assessments to the retrieved and unretrieved segments, and compare the proposed beta-binomial with the officially reported normal intervals for recent TREC Legal Track iterations.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2066289596",
    "type": "article"
  },
  {
    "title": "Factors Influencing Users’ Information Requests",
    "doi": "https://doi.org/10.1145/3209624",
    "publication_date": "2018-07-12",
    "publication_year": 2018,
    "authors": "Jaime Arguello; Bogeum Choi; R. Capra",
    "corresponding_authors": "",
    "abstract": "We report on a crowdsourced study that investigated how two factors influence the way people formulate information requests. Our first factor, medium , considers whether the request is produced using text or voice. Our second factor, target , considers whether the request is intended for a search engine or a human intermediary (i.e., someone who will search on the user’s behalf). In particular, we study how these two factors influence the way people formulate requests in situations where the information need has a specific type of extra-topical dimension (i.e., a type of constraint that is independent from the information need’s topic). We focus on six extra-topical dimensions: (1) domain knowledge, (2) viewpoint, (3) experiential, (4) venue location, (5) source location, and (6) temporal. The extra-topical dimension was manipulated by giving participants carefully constructed search tasks. We analyzed a large number of information requests produced by study participants, and address three research questions. We study the effects of our two factors (medium and target) on (RQ1) participants’ perceptions about their own information requests, (RQ2) the different characteristics of their information requests (e.g., natural language structure, retrieval performance), and (RQ3) participants’ strategies for requesting information when the search task has a specific type of extra-topical dimension. Our results found that both factors influenced participants’ perceptions about their own information requests, the characteristics of participants’ requests, and the strategies adopted by participants to request information matching the extra-topical dimension. Our results have implications for future research on methods that can harness (rather than ignore) extra-topical query terms to retrieve relevant information.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2822550322",
    "type": "article"
  },
  {
    "title": "Two-Stage Document Length Normalization for Information Retrieval",
    "doi": "https://doi.org/10.1145/2699669",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Seung‐Hoon Na",
    "corresponding_authors": "Seung‐Hoon Na",
    "abstract": "The standard approach for term frequency normalization is based only on the document length. However, it does not distinguish the verbosity from the scope, these being the two main factors determining the document length. Because the verbosity and scope have largely different effects on the increase in term frequency, the standard approach can easily suffer from insufficient or excessive penalization depending on the specific type of long document. To overcome these problems, this article proposes two-stage normalization by performing verbosity and scope normalization separately, and by employing different penalization functions. In verbosity normalization, each document is prenormalized by dividing the term frequency by the verbosity of the document. In scope normalization, an existing retrieval model is applied in a straightforward manner to the prenormalized document, finally leading us to formulate our proposed verbosity normalized (VN) retrieval model. Experimental results carried out on standard TREC collections demonstrate that the VN model leads to marginal but statistically significant improvements over standard retrieval models.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1967193210",
    "type": "article"
  },
  {
    "title": "Patent Query Formulation by Synthesizing Multiple Sources of Relevance Evidence",
    "doi": "https://doi.org/10.1145/2651363",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Parvaz Mahdabi; Fábio Crestani",
    "corresponding_authors": "",
    "abstract": "Patent prior art search is a task in patent retrieval with the goal of finding documents which describe prior art work related to a query patent. A query patent is a full patent application composed of hundreds of terms which does not represent a single focused information need. Fortunately, other relevance evidence sources (i.e., classification tags and bibliographical data) provide additional details about the underlying information need. In this article, we propose a unified framework that integrates multiple relevance evidence components for query formulation. We first build a query model from the textual fields of a query patent. To overcome the term mismatch, we expand this initial query model with the term distribution of documents in the citation graph, modeling old and recent domain terminology. We build an IPC lexicon and perform query expansion using this lexicon incorporating proximity information. We performed an empirical evaluation on two patent datasets. Our results show that employing the temporal features of documents has a precision enhancing effect, while query expansion using IPC lexicon improves the recall of the final rank list.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2061341076",
    "type": "article"
  },
  {
    "title": "Indexing Word Sequences for Ranked Retrieval",
    "doi": "https://doi.org/10.1145/2559168",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Samuel Huston; J. Shane Culpepper; W. Bruce Croft",
    "corresponding_authors": "",
    "abstract": "Formulating and processing phrases and other term dependencies to improve query effectiveness is an important problem in information retrieval. However, accessing word-sequence statistics using inverted indexes requires unreasonable processing time or substantial space overhead. Establishing a balance between these competing space and time trade-offs can dramatically improve system performance. In this article, we present and analyze a new index structure designed to improve query efficiency in dependency retrieval models. By adapting a class of ( ε, δ )-approximation algorithms originally proposed for sketch summarization in networking applications, we show how to accurately estimate statistics important in term-dependency models with low, probabilistically bounded error rates. The space requirements for the vocabulary of the index is only logarithmically linked to the size of the vocabulary. Empirically, we show that the sketch index can reduce the space requirements of the vocabulary component of an index of n -grams consisting of between 1 and 4 words extracted from the GOV2 collection to less than 0.01% of the space requirements of the vocabulary of a full index. We also show that larger n -gram queries can be processed considerably more efficiently than in current alternatives, such as positional and next-word indexes.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2100399044",
    "type": "article"
  },
  {
    "title": "Compact Indexing and Judicious Searching for Billion-Scale Microblog Retrieval",
    "doi": "https://doi.org/10.1145/3052771",
    "publication_date": "2017-05-12",
    "publication_year": 2017,
    "authors": "Dongxiang Zhang; Liqiang Nie; Huanbo Luan; Kian‐Lee Tan; Tat‐Seng Chua; Heng Tao Shen",
    "corresponding_authors": "",
    "abstract": "In this article, we study the problem of efficient top- k disjunctive query processing in a huge microblog dataset. In terms of compact indexing, we categorize the keywords into rare terms and common terms based on inverse document frequency (idf) and propose tailored block-oriented organization to save memory consumption. In terms of fast searching, we classify the queries into three types based on term category and judiciously design an efficient search algorithm for each type. We conducted extensive experiments on a billion-scale Twitter dataset and examined the performance with both simple and more advanced ranking functions. The results showed that with much smaller index size, our search algorithm achieves a factor of 2--3 times faster speedup over state-of-the-art solutions in both ranking scenarios.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2616258542",
    "type": "article"
  },
  {
    "title": "A Price-per-attention Auction Scheme Using Mouse Cursor Information",
    "doi": "https://doi.org/10.1145/3374210",
    "publication_date": "2020-01-27",
    "publication_year": 2020,
    "authors": "Ioannis Arapakis; Antonio Penta; Hideo Joho; Luis A. Leiva",
    "corresponding_authors": "",
    "abstract": "Payments in online ad auctions are typically derived from click-through rates, so that advertisers do not pay for ineffective ads. But advertisers often care about more than just clicks. That is, for example, if they aim to raise brand awareness or visibility. There is thus an opportunity to devise a more effective ad pricing paradigm, in which ads are paid only if they are actually noticed. This article contributes a novel auction format based on a pay-per-attention (PPA) scheme. We show that the PPA auction inherits the desirable properties (strategy-proofness and efficiency) as its pay-per-impression and pay-per-click counterparts, and that it also compares favourably in terms of revenues. To make the PPA format feasible, we also contribute a scalable diagnostic technology to predict user attention to ads in sponsored search using raw mouse cursor coordinates only, regardless of the page content and structure. We use the user attention predictions in numerical simulations to evaluate the PPA auction scheme. Our results show that, in relevant economic settings, the PPA revenues would be strictly higher than the existing auction payment schemes.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3122570191",
    "type": "article"
  },
  {
    "title": "Cross-Lingual Topic Discovery From Multilingual Search Engine Query Log",
    "doi": "https://doi.org/10.1145/2956235",
    "publication_date": "2016-09-21",
    "publication_year": 2016,
    "authors": "Di Jiang; Yongxin Tong; Yuanfeng Song",
    "corresponding_authors": "",
    "abstract": "Today, major commercial search engines are operating in a multinational fashion to provide web search services for millions of users who compose search queries by different languages. Hence, the search engine query log, which serves as the backbone of many search engine applications, records millions of users’ search history in a wide spectrum of human languages and demonstrates a strong multilingual phenomenon. However, with its salience, the multilingual nature of a search engine query log is usually ignored by existing works, which usually consider query log entries of different languages as being orthogonal and independent. This kind of oversimplified assumption heavily distorts the underlying structure of web search data. In this article, we pioneer in recognition of the multilingual nature of a query log and make the first attempt to cross the language barrier in query logs. We propose a novel model named Cross-Lingual Query Log Topic Model (CL-QLTM) to analyze query logs from a cross-lingual perspective and derive the latent topics of web search data. The CL-QLTM comprehensively integrates web search data in different languages by collectively utilizing cross-lingual dictionaries, as well as the co-occurrence relations in the query log. In order to relieve the efficiency bottleneck of applying the CL-QLTM on voluminous query logs, we propose an efficient parameter inference algorithm based on the MapReduce computing paradigm. Both qualitative and quantitative experimental results show that the CL-QLTM is able to effectively derive cross-lingual topics from multilingual query logs and spawn a wide spectrum of new search engine applications.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2522589322",
    "type": "article"
  },
  {
    "title": "Modeling Multiple Coexisting Category-Level Intentions for Next Item Recommendation",
    "doi": "https://doi.org/10.1145/3441642",
    "publication_date": "2021-05-05",
    "publication_year": 2021,
    "authors": "Yanan Xu; Yanmin Zhu; Jiadi Yu",
    "corresponding_authors": "",
    "abstract": "Purchase intentions have a great impact on future purchases and thus can be exploited for making recommendations. However, purchase intentions are typically complex and may change from time to time. Through empirical study with two e-commerce datasets, we observe that behaviors of multiple types can indicate user intentions and a user may have multiple coexisting category-level intentions that evolve over time. In this article, we propose a novel Intention-Aware Recommender System (IARS) which consists of four components for mining such complex intentions from user behaviors of multiple types. In the first component, we utilize several Recurrent Neural Networks (RNNs) and an attention layer to model diverse user intentions simultaneously and design two kinds of Multi-behavior GRU (MGRU) cells to deal with heterogeneous behaviors. To reveal user intentions, we carefully design three tasks that share representations from MGRUs. The next-item recommendation is the main task and leverages attention to select user intentions according to candidate items. The remaining two (item prediction and sequence comparison) are auxiliary tasks and can reveal user intentions. Extensive experiments on the two real-world datasets demonstrate the effectiveness of our models compared with several state-of-the-art recommendation methods in terms of hit ratio and NDCG.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3157278747",
    "type": "article"
  },
  {
    "title": "CoSam: An Efficient Collaborative Adaptive Sampler for Recommendation",
    "doi": "https://doi.org/10.1145/3450289",
    "publication_date": "2021-05-25",
    "publication_year": 2021,
    "authors": "Jiawei Chen; Chengquan Jiang; Can Wang; Sheng Zhou; Feng Yan; Chun Chen; Martin Ester; Xiangnan He",
    "corresponding_authors": "",
    "abstract": "Sampling strategies have been widely applied in many recommendation systems to accelerate model learning from implicit feedback data. A typical strategy is to draw negative instances with uniform distribution, which, however, will severely affect a model’s convergence, stability, and even recommendation accuracy. A promising solution for this problem is to over-sample the “difficult” (a.k.a. informative) instances that contribute more on training. But this will increase the risk of biasing the model and leading to non-optimal results. Moreover, existing samplers are either heuristic, which require domain knowledge and often fail to capture real “difficult” instances, or rely on a sampler model that suffers from low efficiency. To deal with these problems, we propose CoSam, an efficient and effective collaborative sampling method that consists of (1) a collaborative sampler model that explicitly leverages user-item interaction information in sampling probability and exhibits good properties of normalization, adaption, interaction information awareness, and sampling efficiency, and (2) an integrated sampler-recommender framework, leveraging the sampler model in prediction to offset the bias caused by uneven sampling. Correspondingly, we derive a fast reinforced training algorithm of our framework to boost the sampler performance and sampler-recommender collaboration. Extensive experiments on four real-world datasets demonstrate the superiority of the proposed collaborative sampler model and integrated sampler-recommender framework.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3164333934",
    "type": "article"
  },
  {
    "title": "CATS: Customizable Abstractive Topic-based Summarization",
    "doi": "https://doi.org/10.1145/3464299",
    "publication_date": "2021-10-25",
    "publication_year": 2021,
    "authors": "Seyed Ali Bahrainian; George Zerveas; Fábio Crestani; Carsten Eickhoff",
    "corresponding_authors": "",
    "abstract": "Neural sequence-to-sequence models are the state-of-the-art approach used in abstractive summarization of textual documents, useful for producing condensed versions of source text narratives without being restricted to using only words from the original text. Despite the advances in abstractive summarization, custom generation of summaries (e.g., towards a user’s preference) remains unexplored. In this article, we present CATS, an abstractive neural summarization model that summarizes content in a sequence-to-sequence fashion while also introducing a new mechanism to control the underlying latent topic distribution of the produced summaries. We empirically illustrate the efficacy of our model in producing customized summaries and present findings that facilitate the design of such systems. We use the well-known CNN/DailyMail dataset to evaluate our model. Furthermore, we present a transfer-learning method and demonstrate the effectiveness of our approach in a low resource setting, i.e., abstractive summarization of meetings minutes, where combining the main available meetings’ transcripts datasets, AMI and International Computer Science Institute(ICSI) , results in merely a few hundred training documents.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3209028787",
    "type": "article"
  },
  {
    "title": "Social Context-aware Person Search in Videos via Multi-modal Cues",
    "doi": "https://doi.org/10.1145/3480967",
    "publication_date": "2021-11-22",
    "publication_year": 2021,
    "authors": "Wei‐Xue Li; Tong Xu; Peilun Zhou; Weidong He; Yanbin Hao; Yi Zheng; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "Person search has long been treated as a crucial and challenging task to support deeper insight in personalized summarization and personality discovery. Traditional methods, e.g., person re-identification and face recognition techniques, which profile video characters based on visual information, are often limited by relatively fixed poses or small variation of viewpoints and suffer from more realistic scenes with high motion complexity (e.g., movies). At the same time, long videos such as movies often have logical story lines and are composed of continuously developmental plots. In this situation, different persons usually meet on a specific occasion, in which informative social cues are performed. We notice that these social cues could semantically profile their personality and benefit person search task in two aspects. First, persons with certain relationships usually co-occur in short intervals; in case one of them is easier to be identified, the social relation cues extracted from their co-occurrences could further benefit the identification for the harder ones. Second, social relations could reveal the association between certain scenes and characters (e.g., classmate relationship may only exist among students), which could narrow down candidates into certain persons with a specific relationship. In this way, high-level social relation cues could improve the effectiveness of person search. Along this line, in this article, we propose a social context-aware framework, which fuses visual and social contexts to profile persons in more semantic perspectives and better deal with person search task in complex scenarios. Specifically, we first segment videos into several independent scene units and abstract out social contexts within these scene units. Then, we construct inner-personal links through a graph formulation operation for each scene unit, in which both visual cues and relation cues are considered. Finally, we perform a relation-aware label propagation to identify characters’ occurrences, combining low-level semantic cues (i.e., visual cues) and high-level semantic cues (i.e., relation cues) to further enhance the accuracy. Experiments on real-world datasets validate that our solution outperforms several competitive baselines.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3217620713",
    "type": "article"
  },
  {
    "title": "Explainable Hyperbolic Temporal Point Process for User-Item Interaction Sequence Generation",
    "doi": "https://doi.org/10.1145/3570501",
    "publication_date": "2022-11-04",
    "publication_year": 2022,
    "authors": "Yuchen Zhou; Yanan Cao; Yanmin Shang; Chuan Zhou; Shirui Pan; Zheng Lin; Qian Li",
    "corresponding_authors": "",
    "abstract": "Recommender systems which captures dynamic user interest based on time-ordered user-item interactions plays a critical role in the real-world. Although existing deep learning-based recommendation systems show good performances, these methods have two main drawbacks. Firstly, user interest is the consequence of the coaction of many factors. However, existing methods do not fully explore potential influence factors and ignore the user-item interaction formation process. The coarse-grained modeling patterns cannot accurately reflect complex user interest and leads to suboptimal recommendation results. Furthermore, these methods are implicit and largely operate in a black-box fashion. It is difficult to interpret their modeling processes and recommendation results. Secondly, recommendation datasets usually exhibit scale-free distributions and some existing recommender systems take advantage of hyperbolic space to match the data distribution. But they ignore that the operations in hyperbolic space are more complex than that in Euclidean space which further increases the difficulty of model interpretation. To tackle the above shortcomings, we propose an E xplainable H yperbolic T emporal P oint P rocess for User-Item Interaction Sequence Generation (EHTPP) . Specifically, EHTPP regards each user-item interaction as an event in hyperbolic space and employs a temporal point process framework to model the probability of event occurrence. Considering that the complexity of user interest and the interpretability of the model,EHTPP explores four potential influence factors related to user interest and uses them to explicitly guide the probability calculation in the temporal point process. In order to validate the effectiveness of EHTPP, we carry out a comprehensive evaluation of EHTPP on three datasets compared with a few competitive baselines. Experimental results demonstrate the state-of-the-art performances of EHTPP.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4308206072",
    "type": "article"
  },
  {
    "title": "Pre-trained Models for Search and Recommendation: Introduction to the Special Issue - Part 1",
    "doi": "https://doi.org/10.1145/3709134",
    "publication_date": "2025-01-13",
    "publication_year": 2025,
    "authors": "Wenjie Wang; Zheng Liu; Fuli Feng; Zhicheng Dou; Qingyao Ai; Grace Hui Yang; Defu Lian; Lu Hou; Nick Craswell; Aixin Sun; Hamed Zamani; Donald Metzler; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Foundation Models such as Large Language Models (LLMs) have significantly advanced many research areas. In particular, LLMs offer significant advantages for recommender systems, making them valuable tools for personalized recommendations. For example, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406334257",
    "type": "article"
  },
  {
    "title": "KG4RecEval: Does Knowledge Graph Really Matter for Recommender Systems?",
    "doi": "https://doi.org/10.1145/3713071",
    "publication_date": "2025-01-21",
    "publication_year": 2025,
    "authors": "Haonan Zhang; Dongxia Wang; Zhu Sun; Yanhui Li; Youcheng Sun; Huizhi Liang; Wenhai Wang",
    "corresponding_authors": "",
    "abstract": "Recommender systems (RSs) are designed to provide personalized recommendations to users. Recently, knowledge graphs (KGs) have been widely introduced in RSs to improve recommendation accuracy. In this study, however, we demonstrate that RSs do not necessarily perform worse even if the KG is downgraded to the user-item interaction graph only (or removed). We propose an evaluation framework KG4RecEval to systematically evaluate how much a KG contributes to the recommendation accuracy of a KG-based RS, using our defined metric KGER ( KG utilization efficiency in recommendation ). We consider the scenarios where knowledge in a KG gets completely removed, randomly distorted and decreased, and also where recommendations are for cold-start users. Our extensive experiments on four commonly used datasets and a number of state-of-the-art KG-based RSs reveal that: to remove, randomly distort or decrease knowledge does not necessarily decrease recommendation accuracy, even for cold-start users. These findings inspire us to rethink how to better utilize knowledge from existing KGs, whereby we discuss and provide insights into what characteristics of datasets and KG-based RSs may help improve KG utilization efficiency. The code and supplementary material of this paper are available at: https://github.com/HotBento/KG4RecEval .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406679435",
    "type": "article"
  },
  {
    "title": "MVideoRec: Micro Video Recommendations Through Modality Decomposition and Contrastive Learning",
    "doi": "https://doi.org/10.1145/3711855",
    "publication_date": "2025-01-24",
    "publication_year": 2025,
    "authors": "Li Yu; Jianyong Hu; Qihan Du; Xi Niu",
    "corresponding_authors": "",
    "abstract": "Personalized micro video recommendation aims to recommend the micro videos tailored to user preference based on the user’s interaction history with the micro videos, which has drawn increasing attention from both the academic and industrial communities. Existing solutions primarily concentrate on video-level interactions between users and micro videos to model their preferences, and cannot distinguish the finer-grained users’ interactions with various modalities. Ignoring modality-level interactions prevents the full understanding of the user’s true and subtle preferences on micro videos. To this end, in this paper, we propose a Contrastive Multimodal Interaction Graph Learning ( MVideoRec ) model to automatically and explicitly learn the modality-level interaction between users and micro videos for recommendations. Specifically, we designed a graph structure learning module with a sparsification strategy to infer modality-level interaction graph, which will be dynamically and iteratively updated based on the node representations obtained from the node representation learning module. Furthermore, to address the lack of ground truth labels, we propose to generate teacher view from video-level interaction graph and student view from modality-level interaction graph, as well as construct intra-modality and inter-modality contrastive pairwise instances to provide self-supervised signals. Extensive experiments on three real-world micro video datasets validate the effectiveness of MVideoRec.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406799884",
    "type": "article"
  },
  {
    "title": "Enabling Harmonious Human-Machine Interaction with Visual-Context Augmented Dialogue System: A Review",
    "doi": "https://doi.org/10.1145/3715098",
    "publication_date": "2025-01-28",
    "publication_year": 2025,
    "authors": "Hao Wang; Bin Guo; Yating Zeng; M. Chen; Yasan Ding; Ying Zhang; Lina Yao; Zhiwen Yu",
    "corresponding_authors": "",
    "abstract": "The intelligent dialogue system, aiming at communicating with humans harmoniously with natural language, is brilliant for promoting the advancement of human-machine interaction in the era of artificial intelligence. With the gradually complex human-computer interaction requirements, it is difficult for traditional text-based dialogue system to meet the demands for more vivid and convenient interaction. Consequently, Visual-Context Augmented Dialogue System (VAD), which has the potential to communicate with humans by perceiving and understanding multimodal information (i.e., visual context in images or videos, textual dialogue history), has become a predominant research paradigm. Benefiting from the consistency and complementarity between visual and textual context, VAD possesses the potential to generate engaging and context-aware responses. To depict the development of VAD, we first characterize the concept model of VAD and then present its generic system architecture to illustrate the system workflow, followed by a summary of multimodal fusion techniques. Subsequently, several research challenges and representative works are investigated, followed by the summary of authoritative benchmarks and real-world application of VAD. We conclude this paper by putting forward some open issues and promising research trends for VAD, e.g., the cognitive mechanisms of human-machine dialogue under cross-modal dialogue context, mobile and lightweight deployment of VAD.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406920151",
    "type": "review"
  },
  {
    "title": "Rebalancing Discriminative Responses for Knowledge Tracing",
    "doi": "https://doi.org/10.1145/3716821",
    "publication_date": "2025-02-12",
    "publication_year": 2025,
    "authors": "Jiajun Cui; Hong Qian; Chanjin Zheng; Lu Wang; Mo Yu; Wei Zhang",
    "corresponding_authors": "",
    "abstract": "Knowledge tracing (KT) is a crucial task in computer-aided education and intelligent tutoring systems, predicting students’ performance on new questions from their responses to prior ones. An accurate KT model can capture a student’s mastery level of different knowledge topics, as reflected in their predicted performance on different questions. This helps improve the learning efficiency by suggesting appropriate new questions that complement students’ knowledge states. However, current KT models have significant drawbacks that they neglect the imbalanced discrimination of historical responses. A significant proportion of question responses provide limited information for discerning students’ knowledge mastery, such as those that demonstrate uniform performance across different students. Optimizing the prediction of these cases may increase overall KT accuracy, but also negatively impact the model’s ability to trace personalized knowledge states, especially causing a deceptive surge of performance. Towards this end, we propose a framework to reweight the contribution of different responses based on their discrimination in training. Additionally, we introduce an adaptive predictive score fusion technique to maintain accuracy on less discriminative responses, achieving proper balance between student knowledge mastery and question difficulty. Experimental results demonstrate that our framework enhances the performance of three mainstream KT methods on three widely-used datasets.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407406709",
    "type": "article"
  },
  {
    "title": "Review-Enhanced Universal Sequence Representation Learning for Recommender Systems",
    "doi": "https://doi.org/10.1145/3717832",
    "publication_date": "2025-02-14",
    "publication_year": 2025,
    "authors": "Junjie Zhang; Wenqi Sun; Yupeng Hou; Wayne Xin Zhao; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "With the widespread deployment of recommender systems on various online platforms, researchers are striving to develop transferable recommendation algorithms that can effectively adapt to new task scenarios without requiring the re-training of new recommenders. However, there have been challenges in dealing with explicit ID modeling in this context. Recently, researchers have drawn inspiration from the achievements of pre-trained language models (PLMs), making it possible to acquire ID-agnostic representations by utilizing the corresponding texts of items. These representations have shown to be transferable across diverse domains. However, while these methods demonstrate generalization, they are less proficient in making personalized recommendations as they learn universal representation. In light of this issue, we present a review-enhanced universal sequence representation learning approach named RUNSRec . Our goal is to not only comprehend universal user behavioral patterns across different domains but also capture their inherent preferences to make recommendations. Our approach makes three technical advancements toward this objective. Firstly, we introduce a lightweight item encoding architecture based on parametric whitening and mixture-of-experts enhanced adapter. It learns discriminative item textual representations by encoding their corresponding identity text and review text, with a discriminative keyword extraction method to enhance the representation identifiability. Secondly, we propose a universal sequence representation learning method that enables the training of transferable recommenders across diverse domains, based on two novel contrastive learning tasks. Furthermore, we introduce a personalized adapter tuning mechanism that enables the universal recommender to capture user personal preferences in a parameter-efficient way. By incorporating universal behavioral patterns learned during the pre-training stage and personalized user tastes captured through adapter tuning, our approach achieves a better balance between generalization and personalization in transferable recommender systems. Extensive experiments conducted on five real-world datasets have demonstrated the effectiveness of our proposed approach.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407564270",
    "type": "article"
  },
  {
    "title": "Independent or Social Driven Decision? A Counterfactual Refinement Strategy for Graph-Based Social Recommendation",
    "doi": "https://doi.org/10.1145/3717830",
    "publication_date": "2025-02-14",
    "publication_year": 2025,
    "authors": "Dongyang Li; Jianshan Sun; Chongming Gao; Fuli Feng; Kun Yuan",
    "corresponding_authors": "",
    "abstract": "Social recommendation models have traditionally relied on social homophily to enhance user preference prediction by incorporating information from socially connected friends. However, this approach neglects the diverse nature of social relationships. Some individuals with independent personalities often prioritize their own interests over friends’ advice when making purchase decisions. Conversely, those who seek advice from others are more susceptible to social influence. Moreover, existing methods tend to overlook redundant and noisy social relationships within the network, hindering their ability to achieve accurate recommendations. In response, this paper proposes a novel counterfactual method to understand the causal factors driving purchase behaviors, thereby identifying the influence of users’ friends on their purchase decisions. By answering counterfactual questions about the influence of a friend's purchase behavior on the user's choices, we develop a causal model to represent social influence in the network. Our proposed refinement strategy, grounded in causal inference, generates counterfactual purchase behavior and guides the refinement of the social graph. Moreover, we present tailored graph refinement methods at various levels, ensuring fine-grained improvements. Experimental results on benchmark data demonstrate that the application of our strategy to different social recommendation models significantly enhances their predictive performance. The source code has been made available on https://github.com/LDY911/CFRSSR-Code .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407564388",
    "type": "article"
  },
  {
    "title": "Lightweight yet Efficient: An External Attentive Graph Convolutional Network with Positional Prompts for Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3719343",
    "publication_date": "2025-02-27",
    "publication_year": 2025,
    "authors": "Jinyu Zhang; Chao Li; Zhongying Zhao",
    "corresponding_authors": "",
    "abstract": "Graph-based Sequential Recommender systems (GSRs) have gained significant research attention due to their ability to simultaneously handle user-item interactions and sequential relationships between items. Current GSRs often utilize composite or in-depth structures for graph encoding (e.g., the Graph Transformer). Nevertheless, they have high computational complexity, hindering the deployment on resource-constrained edge devices. Moreover, the relative position encoding in Graph Transformer has difficulty in considering the complicated positional dependencies within sequence. To this end, we propose an External Attentive Graph convolutional network with Positional prompts for Sequential recommendation, namely EA-GPS. Specifically, we first introduce an external attentive graph convolutional network that linearly measures the global associations among nodes via two external memory units. Then, we present a positional prompt-based decoder that explicitly treats the absolute item positions as external prompts. By introducing length-adaptive sequential masking and a soft attention network, such a decoder facilitates the model to capture the long-term positional dependencies and contextual relationships within sequences. Extensive experimental results on five real-world datasets demonstrate that the proposed EA-GPS outperforms the state-of-the-art methods. Remarkably, it achieves the superior performance while maintaining a smaller parameter size and lower training overhead. The implementation of this work is publicly available at https://github.com/ZZY-GraphMiningLab/EA-GPS.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408024519",
    "type": "article"
  },
  {
    "title": "Symmetric Graph Contrastive Learning against Noisy Views for Recommendation",
    "doi": "https://doi.org/10.1145/3722103",
    "publication_date": "2025-03-11",
    "publication_year": 2025,
    "authors": "Chu Zhao; Enneng Yang; Yuliang Liang; Jianzhe Zhao; Guibing Guo; X. Wang",
    "corresponding_authors": "",
    "abstract": "Graph Contrastive Learning (GCL) leverages data augmentation techniques to produce contrasting views, enhancing the accuracy of recommendation systems through learning the consistency between contrastive views. However, existing augmentation methods, such as directly perturbing interaction graph (e.g., node/edge dropout), may interfere with the original connections and generate poor contrasting views, resulting in sub-optimal performance. In this paper, we define the views that share only a small amount of information with the original graph due to poor data augmentation as noisy views (i.e., the last 20% of the views with a cosine similarity value less than 0.1 to the original view). We demonstrate through detailed experiments that noisy views will significantly degrade recommendation performance. Further, we propose a model-agnostic Symmetric Graph Contrastive Learning (SGCL) method with theoretical guarantees to address this issue. Specifically, we introduce symmetry theory into graph contrastive learning, based on which we propose a symmetric form and contrast loss resistant to noisy interference. We provide theoretical proof that our proposed SGCL method has a high tolerance to noisy views. Further demonstration is given by conducting extensive experiments on three real-world datasets. The experimental results demonstrate that our approach substantially increases recommendation accuracy, with relative improvements reaching as high as 12.25% over nine other competing models. These results highlight the efficacy of our method. The code is available at https://github.com/user683/SGCL .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408326996",
    "type": "article"
  },
  {
    "title": "Uniform Graph Pre-training and Prompting for Transferable Recommendation",
    "doi": "https://doi.org/10.1145/3724392",
    "publication_date": "2025-03-18",
    "publication_year": 2025,
    "authors": "Qìng Yu; Lixin Zou; Xiangyang Luo; Xiangyu Zhao; Chenliang Li",
    "corresponding_authors": "",
    "abstract": "Recently, the paradigm of pre-training and fine-tuning has achieved impressive performance owing to their ability to transfer general knowledge from pre-trained domain to target domain. Meanwhile, Graph Neural Networks (GNNs) have gained prominence in recommender systems. However, there is a lack of unified pre-training and fine-tuning paradigms in graph-based recommendation systems. Applying pre-training and fine-tuning in graph-based recommendation is challenging due to the unique characteristics of recommendation data, including the non-uniform representation, negative transfer effects, and skewed data distributions. To overcome these challenges, we introduce ProRec ( P re-training and p ro mpting Rec ommendation), a novel model that synergizes uniform graph pre-training with prompt-tuning for recommendation systems. Specifically, to address the challenge of inconsistent features across different recommendation datasets, ProRec constructs unified input features at the subgraph level and uses a Graph Auto-Encoder for pre-training, laying the foundation for uniform knowledge transfer from the pre-trained domain to the downstream domain. Additionally, ProRec employs prompt-tuning during the fine-tuning phase, which, in a parameter-efficient manner, enhancing the generalization of pre-trained knowledge to downstream tasks and thereby reducing negative transfer effects. Furthermore, a cross-layer contrastive learning strategy is adopted to eliminate uneven data distribution, promoting more evenly distributed and informative representations. Finally, extensive benchmark comparisons have demonstrated that ProRec outperforms the latest state-of-the-art methods. The source code necessary for replication is available at https://github.com/Code2Q/ProRec .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408564233",
    "type": "article"
  },
  {
    "title": "CPWS: Confident Programmatic Weak Supervision for High-Quality Data Labeling",
    "doi": "https://doi.org/10.1145/3725730",
    "publication_date": "2025-03-25",
    "publication_year": 2025,
    "authors": "Shulan Ruan; Huijie Liu; Zhao Chen; Bin Feng; Kun Zhang; Caleb Chen Cao; Enhong Chen; Lei Chen",
    "corresponding_authors": "",
    "abstract": "Programmatic Weak Supervision (PWS) is a recent data labeling paradigm, which employs several Labeling Functions (LFs) to provide weak labels and involves a Label Model (LM) for label aggregation. Despite the significant progress, there still remain some inherent challenges in PWS. From the view of labeling, LFs may wrongly label some data points. From the view of data, some data points themselves may be low-quality ( e.g. , ambiguous texts or blurred images). These largely stem from the lack of an explicit evaluation mechanism for LFs or data points. To this end, inspired by confident learning focusing on label quality, we propose a Confident PWS (CPWS) approach for high-quality data labeling. Specifically, several LFs are firstly utilized to provide weak labels for unlabeled data. Then, we develop an explicit Dual Evaluation Mechanism (DEM) to evaluate the quality of both LFs and data points, which not only employs data to evaluate trained models, but also leverages trained models to evaluate data. Along this line, we further design a Distribution-guided Pruning Strategy (DPS) to prune low-quality data and aggregate weak labels under the guidance of label class distribution. Extensive experiments on various benchmark datasets demonstrate the effectiveness and generalization ability of our proposed approach.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408813337",
    "type": "article"
  },
  {
    "title": "Enhancing Sequential Personalized Product Search with External Out-of-sequence Knowledge",
    "doi": "https://doi.org/10.1145/3726864",
    "publication_date": "2025-03-28",
    "publication_year": 2025,
    "authors": "Jiongnan Liu; Zhicheng Dou; Jian‐Yun Nie; Zhen-Lin Chen; Guoyu Tang; Sulong Xu; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "A key challenge in personalized product search is to capture user’s preferences. Recent work attempted to model sequences of user historical behaviors, i.e., product purchase histories, to build user profiles and to personalize results accordingly. Although these approaches have demonstrated promising retrieval performances, we notice that most of them focus solely on the intra-sequence interactions between items. However, as there is usually a small amount of historical behavior data, the user profiles learned by these approaches could be very sensitive to the noise included in it. To tackle this problem, we propose incorporating out-of-sequence external information to enhance user modeling. More specifically, we inject the external item-item relations (e.g., belonging to the same brand), and query-query relations (e.g., the semantic similarities between them), into the intra-sequence interaction to learn better user profiles. In addition, we devise two auxiliary decoders, with the historical item sequence reconstruction task and the global item similarity prediction task, to further improve the reliability of user modeling. Experimental results on two datasets from simulated and real user search logs respectively show that the proposed personalized product search method outperforms existing approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408930227",
    "type": "article"
  },
  {
    "title": "Multi-view Intent Learning and Alignment with Large Langue Models for Session-based Recommendation",
    "doi": "https://doi.org/10.1145/3719344",
    "publication_date": "2025-04-08",
    "publication_year": 2025,
    "authors": "Shutong Qiao; Wei Zhou; Junhao Wen; Chen Gao; Qun Luo; Peixuan Chen; Yong Li",
    "corresponding_authors": "",
    "abstract": "Session-based recommendation (SBR) methods often rely on user behavior data, which can struggle with the sparsity of session data, limiting performance. Researchers have identified that beyond behavioral signals, rich semantic information in item descriptions is crucial for capturing hidden user intent. While large language models (LLMs) offer new ways to leverage this semantic data, the challenges of session anonymity, short-sequence nature, and high LLM training costs have hindered the development of a lightweight, efficient LLM framework for SBR. To address the above challenges, we propose an LLM-enhanced SBR framework that integrates semantic and behavioral signals from multiple views. This two-stage framework leverages the strengths of both LLMs and traditional SBR models while minimizing training costs. In the first stage, we use multi-view prompts to infer latent user intentions at the session semantic level, supported by an intent localization module to alleviate LLM hallucinations. In the second stage, we align and unify these semantic inferences with behavioral representations, effectively merging insights from both large and small models. Extensive experiments on two real datasets demonstrate that the LLM4SBR framework can effectively improve model performance. We release our codes along with the baselines at https://github.com/tsinghua-fib-lab/LLM4SBR .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409309502",
    "type": "article"
  },
  {
    "title": "Federated Semantic Learning for Privacy-preserving Cross-domain Recommendation",
    "doi": "https://doi.org/10.1145/3728359",
    "publication_date": "2025-04-08",
    "publication_year": 2025,
    "authors": "Ziang Lu; Lei Guo; Xu Yu; Zhiyong Cheng; Xiaohui Han; Lei Zhu",
    "corresponding_authors": "",
    "abstract": "In the evolving landscape of recommender systems, the challenge of effectively conducting privacy-preserving Cross-Domain Recommendation (CDR), especially under strict non-overlapping constraints, has emerged as a key focus. Despite extensive research has made significant progress, several limitations still exist: 1) Previous semantic-based methods fail to deeply exploit rich textual information, since they quantize the text into codes, losing its original rich semantics. 2) The current solution solely relies on the text-modality, while the synergistic effects with the ID-modality are ignored. 3) Existing studies do not consider the impact of irrelevant semantic features, leading to inaccurate semantic representation. To address these challenges, we introduce federated semantic learning and devise FFMSR as our solution. For Limitation 1, we locally learn items’ semantic encodings from their original texts by a multi-layer semantic encoder, and then cluster them on the server to facilitate the transfer of semantic knowledge between domains. To tackle Limitation 2, we integrate both ID and Text modalities on the clients, and utilize them to learn different aspects of items. To handle Limitation 3, a Fast Fourier Transform (FFT)-based filter and a gating mechanism are developed to alleviate the impact of irrelevant semantic information in the local model. We conduct extensive experiments on two real-world datasets, and the results demonstrate the superiority of our FFMSR method over other SOTA methods. Our source codes are publicly available at: https://github.com/Sapphire-star/FFMSR .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409309596",
    "type": "article"
  },
  {
    "title": "End-to-End Explainable Fake News Detection Via Evidence-Claim Variational Causal Inference",
    "doi": "https://doi.org/10.1145/3728462",
    "publication_date": "2025-04-08",
    "publication_year": 2025,
    "authors": "Jinguang Wang; Shengsheng Qian; Jun Hu; Wenxiang Dong; Xudong Huang; Richang Hong",
    "corresponding_authors": "",
    "abstract": "Explainable Fake News Detection (EFND) is a new challenge that aims to verify news authenticity and provide clear explanations for its decisions. Traditional EFND methods often treat the tasks of classification and explanation as separate, ignoring the fact that explanation content can assist in enhancing fake news detection. To overcome this gap, we present a new solution: the End-to-end Explainable Fake News Detection Network ( \\(EExpFND\\) ). Our model includes an evidence-claim variational causal inference component, which not only utilizes explanation content to improve fake news detection but also employs a variational approach to address the distributional bias between the ground truth explanation in the training set and the prediction explanation in the test set. Additionally, we incorporate a masked attention network to detail the nuanced relationships between evidence and claims. Our comprehensive tests across two public datasets show that \\(EExpFND\\) sets a new benchmark in performance. The code is available at https://anonymous.4open.science/r/EExpFND-F5C6.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409309599",
    "type": "article"
  },
  {
    "title": "Geometric-Augmented Self-Distillation for Graph-Based Recommendation",
    "doi": "https://doi.org/10.1145/3729223",
    "publication_date": "2025-04-10",
    "publication_year": 2025,
    "authors": "Meng Jian; Tuo Wang; Z.D. Xia; Ge Shi; Richang Hong; Lifang Wu",
    "corresponding_authors": "",
    "abstract": "The prevalent recommendation techniques explore the graph structure of interactions to alleviate the interaction sparsity issue for inferring users’ interests. These graph models focus on extracting local structural signals to model users’ interests, introducing grid-like distortion and ignoring the hierarchical tree-like structure when learning from the interaction graph. The learned interests lack significant hierarchical signals, resulting in suboptimal recommendation performance. In this paper, we investigate geometric-augmented graph learning with hyperbolic and Euclidean geometries to delve into local structural and hierarchical knowledge from the interaction graph. A self-teaching network called geometric-augmented self-distillation (GASD) is proposed to transfer hierarchical knowledge from hyperbolic to Euclidean space. The transfer learning enables shrinking of the network into a primary student to implement effective and efficient inference in Euclidean space, preventing computational burden in hyperbolic space. Experiments on publicly available datasets demonstrate that the proposed GASD outperforms the state-of-the-art models, verifying the effectiveness and efficiency of knowledge transfer by self-distillation to aggregate knowledge adaptively for personalized recommendation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409330178",
    "type": "article"
  },
  {
    "title": "The LambdaGap Framework for Precision-Oriented Ranking",
    "doi": "https://doi.org/10.1145/3733235",
    "publication_date": "2025-04-29",
    "publication_year": 2025,
    "authors": "Ramon Adàlia; Gemma Calbo Sanjuan; Tomás Margalef; Ismael Zamora",
    "corresponding_authors": "",
    "abstract": "LambdaRank has proven effective for optimizing information retrieval metrics such as Normalized Discounted Cumulative Gain (NDCG). However, its application to Precision at document k (P@k) poses significant challenges because of the metric’s unique definition, which heavily restricts the number of effective training document pairs. This limitation diminishes the learning signal for relevant documents beyond the top k, potentially resulting in suboptimal performance. To overcome this, we propose LambdaGap, a ranking algorithm inspired by LambdaRank specifically tailored for optimizing P@k. LambdaGap replaces the pairwise weighting scheme in LambdaRank by one where pairs of documents within k positions in the ranking are masked out. We establish a theoretical link between LambdaGap and P@k by identifying the implicit metric optimized by the model. Furthermore, we introduce a new metric, Average Relevance Position beyond document k, which can be used in conjunction with LambdaRank to indirectly optimize for P@k. Our extensive experiments on publicly available datasets demonstrate the effectiveness of the proposed methods, yielding statistically significant improvements in P@k performance and highlighting their potential for more efficient training.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409918480",
    "type": "article"
  },
  {
    "title": "Explainable, Effective, and Efficient Learning-to-Rank Models Using ILMART",
    "doi": "https://doi.org/10.1145/3733232",
    "publication_date": "2025-04-30",
    "publication_year": 2025,
    "authors": "Claudio Lucchese; Franco Maria Nardini; Salvatore Orlando; Raffaele Perego; Alberto Veneri",
    "corresponding_authors": "",
    "abstract": "Learning ranking models that are both explainable and effective is an emerging topic within the research area of explainable AI. Several Learning-to-Rank (LtR) algorithms have been recently proposed that build models that are simple to explain and, at the same time, almost as effective as their state-of-the-art, black-box counterparts. In this work, we propose ILMART (Interpretable LambdaMART), a novel framework with different strategies to constrain the state-of-the-art LtR LambdaMART algorithm to generate interpretable models, i.e., ensembles whose trees can use either single features (main effects) or a limited number of interacting features (interaction effects). ILMART facilitates a straightforward trade-off between model explainability and effectiveness by precisely tuning the quantity of main and interaction effects during the learning phase. We show that slightly increasing their number allows ILMART models to reach ranking performances at par with full-complexity LambdaMART ones. Furthermore, reproducible experiments conducted on publicly available LtR datasets demonstrate that ILMART can improve nDCG@10 by up to 10% compared to state-of-the-art competitors while preserving an explainable structure. Finally, we explore the relationship between model explainability and inference efficiency by introducing a novel and easy-to-implement scoring algorithm for ILMART ranking models, achieving up to a \\(100\\times\\) speedup compared to the baseline.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409983501",
    "type": "article"
  },
  {
    "title": "New Paradigm for Evaluating Scholar Summaries: A Facet-aware Metric and A Meta-evaluation Benchmark",
    "doi": "https://doi.org/10.1145/3733597",
    "publication_date": "2025-05-06",
    "publication_year": 2025,
    "authors": "Tairan Wang; Xiuying Chen; Qingqing Zhu; Taicheng Guo; Shen Gao; Zhiyong Lu; Xin Gao; Xiangliang Zhang",
    "corresponding_authors": "",
    "abstract": "Evaluation of summary quality is particularly crucial within the scientific domain, because it facilitates efficient knowledge dissemination and automated scientific information retrieval. This paper presents conceptual and experimental analyses of scientific summarization, highlighting the inadequacies of traditional evaluation methods. These methods, including \\(n\\) -gram overlap calculations, embedding comparisons, verification, and QA-based approaches, often fall short in providing explanations, grasping scientific concepts, or identifying key content. Correspondingly, we introduce the Facet-aware Metric (FM), employing LLMs for advanced semantic matching to evaluate summaries based on different facets. The facet granularity is tailored to the structure of scientific abstracts, offering an integrated evaluation approach that is not fragmented, while also providing fine-grained interpretability. Recognizing the absence of an evaluation benchmark in the scientific domain, we curate a Scientific abstract summary evaluation Dataset (ScholarSum) with facet-level annotations. Our findings confirm that FM offers a more logical approach to evaluating scientific summaries. In addition, fine-tuned smaller models can compete with LLMs in scientific contexts, while LLMs have limitations in learning from in-context information in scientific domains. We hope our benchmark inspires better evaluation metrics and future enhancements to LLMs: https://github.com/iriscxy/ScholarSum .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410119193",
    "type": "article"
  },
  {
    "title": "Generating Clarifying Questions for Conversational Legal Case Retrieval without External Knowledge",
    "doi": "https://doi.org/10.1145/3736161",
    "publication_date": "2025-05-16",
    "publication_year": 2025,
    "authors": "Bulou Liu; Yiran Hu; Qingyao Ai; Yiqun Liu; Yueyue Wu; Chenliang Li; Weixing Shen",
    "corresponding_authors": "",
    "abstract": "In legal case retrieval, existing work has shown that human-mediated conversational search can improve users’ search experience. One of the key problems for a practical conversational search system is how to ask high-quality clarifying questions to initiate conversations with users and understand their search intents. Previous works demonstrated that human-annotated external domain knowledge (such as event schemas) can improve the legal utility of clarifying questions generated by large language models. However, these methods are restricted to specific law systems or languages and cannot be generalized to others. To this end, we propose to generate context and domain-specific questions with LLMs without external annotations or knowledge by extracting information from top-retrieved documents given the current conversation context. Specifically, we construct a conversational legal case retrieval system CARQ that iteratively selects neighbor candidate case documents from the retrieved list at each conversation step to ask clarifying questions. We pretrain CARQ to capture the differences between legal cases and employ the reward augmented maximum likelihood to optimize the system directly for retrieval metrics. Extensive automated and human evaluations on three widely adopted legal case retrieval datasets demonstrate the superior effectiveness of our approach as compared with the state-of-the-art baselines.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410429768",
    "type": "article"
  },
  {
    "title": "ID-centric pre-training for recommendation",
    "doi": "https://doi.org/10.1145/3735128",
    "publication_date": "2025-05-19",
    "publication_year": 2025,
    "authors": "Yiqing Wu; Ruobing Xie; Zhao Zhang; Xu Zhang; Fuzhen Zhuang; Leyu Lin; Zhanhui Kang; Zhulin An; Yongjun Xu",
    "corresponding_authors": "",
    "abstract": "Classical sequential recommendation models generally adopt ID embeddings to store knowledge learned from user historical behaviors and represent items. However, these unique IDs are challenging to be transferred to new domains. With the thriving of pre-trained language model (PLM), some pioneer works adopt PLM for pre-trained recommendation, where modality information is considered universal across domains via PLM. Unfortunately, the behavioral information in ID embeddings is verified to currently dominate in recommendation compared to modality information and thus limits these models’ performance. In this work, we propose a novel ID-centric recommendation pre-training paradigm (IDP), which directly transfers informative ID embeddings learned in pre-training domains to item representations in new domains. Specifically, in pre-training stage, besides the ID-based sequential recommendation model, we also build a Cross-domain ID-matcher (CDIM) learned by both behavioral and modality information. In the tuning stage, modality information of new domain items is regarded as a cross-domain bridge built by CDIM. They first adopted to retrieve behaviorally and semantically similar items from pre-training domains using CDIM. Next, these retrieved items’ pre-trained ID embeddings are directly adopted to generate downstream new items’ embeddings. Through extensive experiments on real-world datasets, we demonstrate that our proposed model significantly outperforms all baselines.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410502410",
    "type": "article"
  },
  {
    "title": "Incorporating Cognitive Abilities into Web Search Re-ranking",
    "doi": "https://doi.org/10.1145/3736401",
    "publication_date": "2025-05-19",
    "publication_year": 2025,
    "authors": "Tung Vuong; Pritom Kumar Das; Tuukka Ruotsalo",
    "corresponding_authors": "",
    "abstract": "Web search ranking models learn from human interactions to improve retrieval performance, but they are presently limited by their use of behavioral factors, such as click-through data or dwell time, that do not account for differences in their users’ cognition. However, it is well understood that users’ behavior varies according to their abilities in processing information, making inferences, and interacting with computing systems. As a result, researchers may miss opportunities to design ranking models that are optimized for their users’ cognitive abilities. To address this, we report an approach for search result re-ranking that incorporates cognitive ability information in the ranking model. We report extensive empirical in-the-wild experiments with data from simulated tasks and real-world tasks of 20 participants to measure, predict, and use these data to train search result re-ranking models. Our results demonstrate that cognitive ability data significantly improve the effectiveness of re-ranking models in simulated-task and real-world conditions, and that cognitive abilities can be predicted from regular user interactions without requiring separate cognitive testing for each user. In particular, the models show improved performance in predicting the position of the documents the users select during search sessions. Our findings show that search engines have significant potential to improve their ranking performance by accounting for users’ cognitive ability.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410502591",
    "type": "article"
  },
  {
    "title": "User Invariant Preference Learning for Multi-Behavior Recommendation",
    "doi": "https://doi.org/10.1145/3728465",
    "publication_date": "2025-05-23",
    "publication_year": 2025,
    "authors": "Mingshi Yan; Zhiyong Cheng; Fan Liu; Yingda Lyu; Yahong Han",
    "corresponding_authors": "",
    "abstract": "In multi-behavior recommendation scenarios, analyzing users’ diverse behaviors, such as click , purchase , and rating , enables a more comprehensive understanding of their interests, facilitating personalized and accurate recommendations. A fundamental assumption of multi-behavior recommendation methods is the existence of shared user preferences across behaviors, representing users’ intrinsic interests. Based on this assumption, existing approaches aim to integrate information from various behaviors to enrich user representations. However, they often overlook the presence of both commonalities and individualities in users’ multi-behavior preferences. These individualities reflect distinct aspects of preferences captured by different behaviors, where certain auxiliary behaviors may introduce noise, hindering the prediction of the target behavior. To address this issue, we propose a user invariant preference learning (UIPL) for multi-behavior recommendation, aiming to capture users’ intrinsic interests (referred to as invariant preferences) from multi-behavior interactions to mitigate the introduction of noise. Specifically, UIPL leverages the paradigm of invariant risk minimization to learn invariant preferences. To implement this, we employ a variational autoencoder (VAE) to extract users’ invariant preferences, replacing the standard reconstruction loss with an invariant risk minimization constraint. Additionally, we construct distinct environments by combining multi-behavior data to enhance robustness in learning these preferences. Finally, the learned invariant preferences are used to provide recommendations for the target behavior. Extensive experiments on four real-world datasets demonstrate that UIPL significantly outperforms current state-of-the-art methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410642065",
    "type": "article"
  },
  {
    "title": "Causal Deconfounding via Confounder Disentanglement for Dual-Target Cross-Domain Recommendation",
    "doi": "https://doi.org/10.1145/3737457",
    "publication_date": "2025-05-27",
    "publication_year": 2025,
    "authors": "Jia-Jie Zhu; Yan Wang; Feng Zhu; Zhu Sun",
    "corresponding_authors": "",
    "abstract": "In recent years, dual-target Cross-Domain Recommendation (CDR) has been proposed to capture comprehensive user preferences in order to ultimately enhance the recommendation accuracy in both data-richer and data-sparser domains simultaneously. However, in addition to users’ true preferences, the user–item interactions might also be affected by confounders (e.g., free shipping, sales promotion). As a result, dual-target CDR has to meet two challenges: (1) how to effectively decouple observed confounders, including single-domain confounders and cross-domain confounders, and (2) how to preserve the positive effects of observed confounders on predicted interactions, while eliminating their negative effects on capturing comprehensive user preferences. To address the above two challenges, we propose a Causal Deconfounding Framework via Confounder Disentanglement for Dual-Target Cross-Domain Recommendation (CD2CDR) . In CD2CDR, we first propose a confounder disentanglement module to effectively decouple observed single-domain and cross-domain confounders. We then propose a causal deconfounding module to preserve the positive effects of such observed confounders and eliminate their negative effects via backdoor adjustment, thereby enhancing the recommendation accuracy in each domain. Extensive experiments conducted on seven real-world datasets demonstrate that CD2CDR significantly outperforms the state-of-the-art methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410771457",
    "type": "article"
  },
  {
    "title": "Pre-Trained Models for Search and Recommendation: Introduction to the Special Issue - Part 2",
    "doi": "https://doi.org/10.1145/3736540",
    "publication_date": "2025-05-27",
    "publication_year": 2025,
    "authors": "Wenjie Wang; Zheng Liu; Fuli Feng; Zhicheng Dou; Qingyao Ai; Grace Hui Yang; Defu Lian; Lu Hou; Aixin Sun; Hamed Zamani; Donald Metzler; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410772601",
    "type": "article"
  },
  {
    "title": "Lightweight Embeddings with Graph Rewiring for Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3742424",
    "publication_date": "2025-06-02",
    "publication_year": 2025,
    "authors": "Xurong Liang; Tong Chen; Wei Yuan; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "GNN-based recommender systems have become increasingly popular in academia and industry due to their ability to capture high-order information from user-item interaction graphs. However, as recommendation services scale rapidly and their deployment now commonly involves resource-constrained edge devices, GNN-based models face significant challenges, including high embedding storage costs and run-time latency from graph propagations. Our previous work, LEGCF, effectively reduced embedding storage costs but struggled to maintain recommendation performance under stricter storage limits. Additionally, LEGCF did not address the extensive run-time computation costs associated with graph propagation, which involves heavy multiplication and accumulation operations (MACs). These challenges consequently hinder effective training and inference on resource-constrained edge devices. To address these limitations, we propose Lightweight Embeddings with Rewired Graph (LERG) for Graph Collaborative Filtering, an improved extension of LEGCF. LERG retains LEGCF’s compositional codebook structure but introduces quantization techniques to reduce the storage cost of embedding weights, enabling the inclusion of more meta-embeddings within the same storage constraints for improved model expressiveness. To optimize graph propagation for edge devices, we pretrain the quantized compositional embedding table using the full interaction graph on resource-rich servers, after which a fine-tuning stage is engaged to identify and prune low-contribution entities via a gradient-free binary integer programming approach, constructing a rewired graph that excludes these entities (i.e., user/item nodes) from propagating signals. The quantized compositional embedding table with selective embedding participation and sparse rewired graph is transferred to edge devices which significantly reduce computation memory and inference time. Experiments on three public benchmark datasets, including an industry-scale dataset, demonstrate that LERG achieves superior recommendation performance while dramatically reducing storage and computation costs for graph-based recommendation services.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410953896",
    "type": "article"
  },
  {
    "title": "Pre-training for Legal Case Retrieval Based on Inter-Case Distinctions",
    "doi": "https://doi.org/10.1145/3735127",
    "publication_date": "2025-06-04",
    "publication_year": 2025,
    "authors": "Weihang Su; Qingyao Ai; Yueyue Wu; Anzhe Xie; Changyue Wang; Yixiao Ma; Haitao Li; Zhijing Wu; Yiqun Liu; Min Zhang",
    "corresponding_authors": "",
    "abstract": "Legal case retrieval aims to help legal workers find relevant cases related to their cases at hand, which is important for the guarantee of fairness and justice in legal judgments. While recent advances in neural retrieval methods have significantly improved the performance of open-domain retrieval tasks (e.g., Web search), their advantages haven’t been observed in legal case retrieval due to their thirst for annotated data. As annotating large-scale training data in legal domains is prohibitive due to the need for domain expertise, traditional search techniques based on lexical matching such as TF-IDF, BM25, and Query Likelihood are still prevalent in legal case retrieval systems. While previous studies have designed several pre-training methods for IR models in open-domain tasks, these methods are usually suboptimal in legal case retrieval because they cannot understand and capture the key knowledge and data structures in the legal corpus. To this end, we propose a novel pre-training framework named Caseformer that enables the pre-trained models to learn legal knowledge and domain-specific relevance-matching patterns in legal case retrieval without any human-labeled data. This framework is designed to support both dense retrieval models and neural re-ranking models. Through three unsupervised learning tasks, Caseformer is able to capture the special language, document structure, and relevance-matching patterns of legal case documents, making it a strong backbone for downstream legal case retrieval tasks. Experimental results show that our model has achieved state-of-the-art performance in both zero-shot and fine-tuning settings. Also, experiments on both Chinese and English legal datasets demonstrate that the effectiveness of Caseformer is language-independent in legal case retrieval.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411024450",
    "type": "article"
  },
  {
    "title": "Coherence-guided Preference Disentanglement for Cross-domain Recommendations",
    "doi": "https://doi.org/10.1145/3742855",
    "publication_date": "2025-06-05",
    "publication_year": 2025,
    "authors": "Zhaozhen Xiang; Yan Zhang; Lixin Duan; Hongzhi Yin; Ivor W. Tsang",
    "corresponding_authors": "",
    "abstract": "Discovering user preferences across different domains is pivotal in cross-domain recommendation systems, particularly when platforms lack comprehensive user-item interactive data. The limited presence of shared users often hampers the effective modeling of common preferences. While leveraging shared items’ attributes, such as category and popularity, can enhance cross-domain recommendation performance, the scarcity of shared items between domains has limited research in this area. To address this, we propose a Coherence-guided Preference Disentanglement (CoPD) method aimed at improving cross-domain recommendation by (i) explicitly extracting shared item attributes to guide the learning of shared user preferences and (ii) disentangling these preferences to identify specific user interests transferred between domains. CoPD introduces coherence constraints on item embeddings of shared and specific domains, aiding in extracting shared attributes. Moreover, it utilizes these attributes to guide the disentanglement of user preferences into separate embeddings for interest and conformity through a popularity-weighted loss. Experiments conducted on real-world datasets demonstrate the superior performance of our proposed CoPD over existing competitive baselines, highlighting its effectiveness in enhancing cross-domain recommendation performance. The code is available at https://github.com/XiangZongyi/CoPD .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411063521",
    "type": "article"
  },
  {
    "title": "Light Dynamic Graph Learning on Temporal Networks",
    "doi": "https://doi.org/10.1145/3745024",
    "publication_date": "2025-06-24",
    "publication_year": 2025,
    "authors": "Zhiqiang Pan; Chen Gao; Fei Cai; Honghui Chen; Yong Li",
    "corresponding_authors": "",
    "abstract": "Dynamic graph learning on temporal networks aims to understand the continuous evolution pattern of networks, with an important application on forecasting the future temporal network. Existing methods mainly focus on modeling the structural and temporal features, with recent research interest shifting towards considering the structural correlations between nodes through their neighbor co-occurrences. Though satisfactory performance has been achieved, there still remain several limitations: (1) the deviation of investigated scenarios from real-world applications, since most previous researches concentrate on special cases of multigraphs with abundant repeat edges; (2) the insufficient computational efficiency of modeling the structural features, since the existing neighbor co-occurrence scheme fails to consider explicit structural correlations between nodes and suffers from a time-consuming pair-wise encoding strategy; (3) the unsatisfying prediction accuracy due to inadequate modeling of temporal features, since each neighbor’s historical temporal features and the temporal domain shifting with network evolving are both neglected. To solve these issues, we first focus on the general scenarios of temporal networks without abundant repeat edges for approaching the actual applications, and propose an efficient and effective dynamic graph learning method named LightDyG. Specifically, (1) on the one hand, to increase the computational efficiency, LightDyG decouples the structural correlations between nodes and their individual substructures for fast convergence based on the analysis of existing co-occurrence mechanism, and further designs an incremental strategy for efficient structural encoding; (2) on the other hand, to improve the prediction accuracy, the temporal characteristics are considered by including both the interaction and appearance timestamps of neighbors, and a time-invariant temporal encoding strategy is designed to eliminate the temporal bias introduced by the network evolution. Extensive experiments conducted on four public temporal networks demonstrate that LightDyG outperforms the best baselines by 4.54%~11.39% and 6.06%~16.24% in terms of AP and AUC on the temporal link prediction tasks, respectively. In addition, LightDyG reduces the time cost for training and test up to 45.91% and 63.94%, respectively, and also achieves a fast convergence speed during training. The implementation of our approach is available in https://github.com/nudtzpan/LightDyG .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411605865",
    "type": "article"
  },
  {
    "title": "Unified Heterogeneous Hypergraph Construction for Incomplete Multimedia Recommendation",
    "doi": "https://doi.org/10.1145/3745020",
    "publication_date": "2025-06-24",
    "publication_year": 2025,
    "authors": "Zhenghong Lin; Yanchao Tan; Jiamin Chen; Hengyu Zhang; Chaochao Chen; Shiping Wang; Carl Yang",
    "corresponding_authors": "",
    "abstract": "In the dynamic environment of multimedia-sharing platforms like Twitter and TikTok, multimedia recommendation systems have been widely used to help users discover items of interest. However, traditional approaches often fall short, when the item modalities are incomplete, a common issue in real-world scenarios. To this end, we introduce the unified heterogeneous Hypergraph construction for Incomplete multimedia REcommendation ( HIRE ), a novel framework designed to jointly learn a heterogeneous hypergraph and perform accurate recommendations under incomplete scenarios. HIRE first initializes the unified heterogeneous hypergraph for modality completion and employs self-supervised learning aligned with the contrastive text-centered view for multimedia recommendation. Such integration effectively handles the challenges posed by incomplete modalities, leading to improved recommendation accuracy. Furthermore, we find that the hypergraph directly learned from the HIRE is a dense structure which can be inaccurate and coarse. Therefore, we devise the HIRE framework with Sparse constraint named HIRES , which uniquely integrates optimal transport and a \\(\\ell_{2,1}\\) -norm to refine the hypergraph structure. Our extensive experiments across various datasets demonstrate the superiority of HIRES in addressing incomplete modalities, establishing it as a powerful tool for personalized multimedia recommendations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411606019",
    "type": "article"
  },
  {
    "title": "Neural Recommendation Reasoning with Logic Rules",
    "doi": "https://doi.org/10.1145/3742856",
    "publication_date": "2025-06-25",
    "publication_year": 2025,
    "authors": "Jing Yao; Xiting Wang; Jianxun Lian; Xiaoyuan Yi; Xing Xie",
    "corresponding_authors": "",
    "abstract": "Explainability is critical for recommender systems to ensure good user experience and facilitate designers to debug. However, generating explanations in recommender systems usually requires large efforts due to the dependency on additional data and case-by-case model design. One possible solution to these challenges is reasoning with logic rules, whose validity or confidence can automatically indicate high-quality explanations and formats are general. However, pioneer methods can be hardly applied in recommendation due to the high sparsity of interaction data, which raises the difficulty in accurately computing the rule validity, and the specific ranking-oriented task. To bridge this gap, we propose a general framework for Reco mmendation with lo gic r ule reasoning ( Recolor ) that satisfies three desirable properties. First, we explicitly estimate the rule validity to ensure well-grounded decisions, where a fuzzy logic validity module is designed for accurate estimation on highly sparse recommendation data. Second, we ensure the generality for both the types of input data and model architectures by designing a neural logic generation module, which decouples the user-item representation learning from the rule construction. Third, we integrate the two above-mentioned modules with a ranking-oriented BPR loss and achieve a unified optimization of explainability and accuracy. For any given neural recommendation model, our proposed logic rule reasoning framework can upgrade it to a self-explainable version. Numerical experiments and user studies on four public recommendation datasets with different levels of sparsity demonstrate that our framework shows high-validity rule explanations, generality in architecture and data, and high recommendation accuracy.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411644190",
    "type": "article"
  },
  {
    "title": "HGDNet: De-noised Review-based Rating Prediction using Hierarchical Gating and Discriminative Networks",
    "doi": "https://doi.org/10.1145/3746282",
    "publication_date": "2025-06-26",
    "publication_year": 2025,
    "authors": "Jingwei Ma; Jiahui Wen; Lei Zhu; Mingyang Zhong; Yang Xu; Lei Guo; Hongzhi Yin",
    "corresponding_authors": "",
    "abstract": "The expressiveness of historical reviews in capturing user preferences has garnered significant attention in recommender systems. However, this technology still has certain limitations. Firstly, irrelevant reviews can introduce noise that may adversely affect the performance of the model. Secondly, existing approaches often assume a flat structure for review features, thus failing to capture the intricate and hierarchical nature of user-item interactions. Thirdly, it is challenging for review-based recommendation models to effectively assess the usefulness of reviews due to sparse supervision signals. To address these challenges, we propose a novel Hierarchical Gating and Discriminative model for rating prediction. Specifically, we introduce a local gating module that utilizes personalized end-to-end differential thresholds to select reviews in a relatively “hard” manner, thereby minimizing the impact of noisy reviews while facilitating model training. Additionally, we incorporate a global gating module to assess the overall usefulness of review signals by estimating the uncertainties inherent in historical reviews. Moreover, we propose a hierarchical discriminative network to develop self-supervision signals at both global and local levels to guide the learning of the hierarchical gating network. Extensive experiments on public datasets have demonstrated the effectiveness of the proposed model, and further investigations provide deep insight into its superiority.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411673838",
    "type": "article"
  },
  {
    "title": "Cold-start User Recommendation via Heterogeneous Domain Adaptation",
    "doi": "https://doi.org/10.1145/3746637",
    "publication_date": "2025-07-01",
    "publication_year": 2025,
    "authors": "Hanrui Wu; Yanxin Wu; Nuosi Li; Jia Zhang; Yonghui Xu; Michael K. Ng; Jinyi Long",
    "corresponding_authors": "",
    "abstract": "In recommendation systems, cold-start user recommendation is a challenging problem, where precise recommendations are required for users who have not appeared before. Several existing cold-start user recommendation models adopt domain adaptation to extract information from auxiliary source domains to assist the recommendations on the target domain. In this paper, we propose that the cold-start user recommendation problem can be formulated by the heterogeneous domain adaption approach. We determine a transformation of user features, e.g., user social relations and historical interactions between warm users and their interested items, into a latent space so that the loss function is set by user feature reconstruction and by feature and distribution matching in the heterogeneous domains. The resulting optimization problem can be solved by matrix eigendecomposition, and the cold-start users’ preferences can thus be obtained. We also extend the proposed model using neural networks. We perform extensive experiments on several real-world datasets, and the results in terms of Precision, Recall, NDCG, and Hit Rate verify the effectiveness of the proposed model.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411870761",
    "type": "article"
  },
  {
    "title": "Dual-Adaptive Update Strategies Enhanced Meta-Optimization for User Cold-Start Recommendation",
    "doi": "https://doi.org/10.1145/3746634",
    "publication_date": "2025-07-09",
    "publication_year": 2025,
    "authors": "Xuhao Zhao; Yanmin Zhu; Chunyang Wang; Mengyuan Jing; Wenze Ma; Jiadi Yu; Feilong Tang",
    "corresponding_authors": "",
    "abstract": "User cold-start recommendation presents a significant challenge for recommender systems, affecting their overall effectiveness. Meta-learning-based methods have been introduced to address this issue. These methods treat the user cold-start recommendation problem as a few-shot learning task, where each user represents a unique task. The objective is to acquire shared initialization parameters that can be effectively applied across all cold-start users. Subsequently, these shared parameters are fine-tuned into personalized parameters using individual interaction data. Recent studies argue that shared parameters are unsuitable for all users with an implicit grouping distribution of user preference. Therefore, they propose adaptive-initialization-based methods, which first differentiate tasks based on user preferences and then generate task-adaptive initialization parameters using task representations. However, both the meta-learning and adaptive-initialization-based manners ignore discovering the adaptive capability of update strategies in the process of transferring initialization parameters to personalized parameters. Instead, they rely on task-shared optimization strategies, leading the model to fall into an overfitting or underfitting situation. In response to this, we propose a dual-adaptive update strategies enhanced meta-optimization framework (DAUS) for user cold-start recommendation. 1 First, we integrate dual-adaptive update strategies to enhance the adaptive capability of transferring initialization parameters. This involves incorporating both task-adaptive optimization hyperparameters and objectives. Second, we design a multifaceted task encoder , which can provide diverse task information to differentiate between tasks, including explicit task features (task relevance, training signals, etc.) and other implicit task information. Extensive experiments based on three real-world datasets demonstrate that our DAUS outperforms the state-of-the-art methods. The source code is available at https://github.com/XuHao-bit/DAUS .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412119963",
    "type": "article"
  },
  {
    "title": "A Novel Benford’s Law-Driven Approach for Detecting Machine-Generated Text",
    "doi": "https://doi.org/10.1145/3748305",
    "publication_date": "2025-07-14",
    "publication_year": 2025,
    "authors": "Zhenhua Wang; Chen Zhang; Ming Ren",
    "corresponding_authors": "",
    "abstract": "Detecting Machine-Generated Text (MGT) is critical for the sustainable development of information systems. Existing studies often overlook the generation inconsistency between AI and human, limiting the effectiveness of detection. This article introduces a novel detection approach, BENADV, and the motivation stems from our recognition that, unlike MGT (probabilistic token prediction), Human-Written Text (HWT) is influenced by individual factors (e.g., personal experience), which constitutes a form of “manipulation” at the textual level. Specifically, BENADV is built on our new discovery that MGT adheres more closely to Benford’s law compared to HWT. We leverage the adherence patterns as detection mechanisms, and further enhance detection performance through adversarial perturbations controlled by stochastic differential equations. Extensive experiments on general-domain datasets demonstrate that BENADV is SOTA. For instance, on the HC3 dataset, BENADV achieves 99.13% accuracy and 99.18% F1, outperforming existing methods by 1.16–7.82% and 1.37–8.30%. Moreover, BENADV exhibits remarkable scalability, with its performance consistently exceeding 96% on vertical domain datasets as AI advances (from GPT-3.5 to GPT-4), far surpassing the 50–60% performance of existing methods. Notably, BENADV excels in the more challenging short MGT detection. Also, we provide practical insights and discuss implications.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412393837",
    "type": "article"
  },
  {
    "title": "Deep Hashing with Semantic Hash Centers for Image Retrieval",
    "doi": "https://doi.org/10.1145/3749983",
    "publication_date": "2025-07-23",
    "publication_year": 2025,
    "authors": "Li Chen; Rui Liu; Yuxiang Zhou; Xudong Ma; Yong Chen; Dell Zhang",
    "corresponding_authors": "",
    "abstract": "Deep hashing presents an effective strategy for large-scale image retrieval. Current hashing methods are generally categorized by their supervision types: point-wise, pair-wise, and list-wise. Recent advancements in point-wise methods (e.g., CSQ, MDS) have significantly enhanced retrieval performance across diverse datasets by pre-assigning a hash center to each class, thereby improving the discriminability of the resultant hash codes. However, these methods employ purely data-independent algorithms for generating hash centers, overlooking the semantic connections between different classes, which, we argue, could degrade retrieval performance. To tackle this problem, this paper expands on the newly emerged concept of “hash centers” to introduce “ semantic hash centers”, which posits that hash centers of semantically related classes should exhibit closer Hamming distances, while those of unrelated classes should be more distant. Based on this hypothesis, we propose a three-stage framework, termed SHC, to produce hash codes that preserve semantics. First, we build a classification network to detect semantic similarities between classes, and utilize a data-dependent approach to similarity calculation that can adapt to varied data distributions. Next, we develop a new optimization algorithm to generate semantic hash centers. This algorithm not only maintains semantic relatedness among hash centers but also integrates a constraint to ensure a minimum distance between them, addressing the issue of excessively proximate hash centers potentially impairing retrieval performance. Finally, we train a deep hashing network with the above generated semantic hash centers to convert each image into a binary hash code. Experiments on large-scale image retrieval across several public datasets demonstrate that SHC generates more discriminative hash codes, markedly enhancing retrieval performance. Specifically, in terms of the MAP@100, MAP@1000, and MAP@ALL metrics, SHC records average improvements of +6.24%, +6.68%, and +10.39% , respectively, over the most competitive existing methods. The code of our SHC project is available at https://github.com/cc752424640/Deep-Hashing-with-Semantic-Hash-Centers-for-Image-Retrieval .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412603522",
    "type": "article"
  },
  {
    "title": "Bottlenecked Heterogeneous Graph Contrastive Learning for Robust Recommendation",
    "doi": "https://doi.org/10.1145/3750725",
    "publication_date": "2025-07-24",
    "publication_year": 2025,
    "authors": "Lei Sang; Minxing Huang; Yu Wang; Yiwen Zhang; Xindong Wu",
    "corresponding_authors": "",
    "abstract": "In recommender systems, heterogeneous graph neural networks (HGNNs) have demonstrated remarkable efficacy due to their capacity to harness rich auxiliary information within heterogeneous information networks (HINs). However, existing HGNN-based recommendation face severe noise cascading challenge. The presence of substantial data noise can adversely affect robustness of recommender, as the graph structures are susceptible to noise and even unnoticed malicious perturbations. Moreover, these noise can propagate and accumulate through connected nodes, potentially exerting a profound impact on target nodes within the graph structure. To tackle the noise challenges, we present a B ottlenecked H eterogeneous G raph C ontrastive L earning (BHGCL), aiming to enhance the robustness of recommendation systems. BHGCL can first effectively separate fine-grained latent factors from complex self-supervision signals with a disentangled-based encoder, leveraging diverse semantic information across various meta-paths. Then, by employing the information bottleneck (IB) principle, BHGCL adaptively learns to reduce noise in augmented graphs. IB can capture the minimum sufficient information from the data features, which significantly improving system performance in environments with noisy data. Experimental findings from multiple real-world datasets reveal that our approach surpasses the latest advanced recommendation systems, verifying its effectiveness and robustness. To reproduce our work, we have open-sourced our code at https://github.com/DuellingSword/BHGCL .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412627774",
    "type": "article"
  },
  {
    "title": "Compressing integer lists with Contextual Arithmetic Trits",
    "doi": "https://doi.org/10.1145/3749098",
    "publication_date": "2025-07-28",
    "publication_year": 2025,
    "authors": "Yann Barsamian; André Chailloux",
    "corresponding_authors": "",
    "abstract": "Inverted indexes allow to query large databases without needing to search in the database at each query. An important line of research is to construct inverted indexes that require a rather small space usage while still allowing low timings for compression, decompression, and queries. In this article, we show how to use trit encoding, combined with contextual methods for computing inverted indexes. We perform an extensive study of different variants of these methods and show that our method consistently outperforms the Binary Interpolative Method — which is one of the golden standards in this topic — with respect to compression size. We apply our methods to a variety of datasets and make available the source code that produced the results, together with all our datasets.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412700563",
    "type": "article"
  },
  {
    "title": "Causal Inference for Multi-Criteria Rating Recommender Systems",
    "doi": "https://doi.org/10.1145/3757737",
    "publication_date": "2025-08-01",
    "publication_year": 2025,
    "authors": "Zhihao Guo; Peng Song; Chenjiao Feng; Kaixuan Yao; Jiye Liang",
    "corresponding_authors": "",
    "abstract": "Recommender systems are designed to assist users in discovering interesting items and bringing profits to online platforms. The existing works primarily explore the correlation between historical feedback and model predictions through the data-driven paradigm based on a single user-item rating matrix (i.e., overall rating). However, this single-criterion methods ignore the users’ multi-criteria (MC) behavioral characteristics. For example, a hotel system allows users to rate from multiple dimensions, such as environment and location (i.e., MC ratings). Moreover, selection bias is pervasive in user behavior data. Traditional data-driven methods may induce spurious association and amplified biases. To address the above challenges, we propose a debiasing framework called Multi-Criteria Causal Recommendation (MCCR), which encapsulates users’ diverse MC preferences and employs causal inference to construct novel training and inference strategies. Specifically, we first represent the causal relationships among variables in MC scenarios through the structural causal model. Then, we mitigate the negative impact of selection bias through the back-door adjustment. Next, a graph representation learning framework suitable for MC ratings is developed, which is used to extract higher-order information and infer the heterogeneity of users’ preferences with different criteria. Experimental results on six real datasets demonstrate that the MCCR significantly outperforms the existing baselines.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412827303",
    "type": "article"
  },
  {
    "title": "DuAda: Adaptive Targeted Model Poisoning Attack Framework via Dummy User Simulation on Federated Recommendation",
    "doi": "https://doi.org/10.1145/3757059",
    "publication_date": "2025-07-29",
    "publication_year": 2025,
    "authors": "Jiajie Su; Chaochao Chen; Yihao Wang; Weiming Liu; Yuyuan Li; Tao Wang; Zhigang Li; Xiaolin Zheng; Jianwei Yin",
    "corresponding_authors": "",
    "abstract": "Federated Recommendation (FedRec) has been widely applied recently for realizing privacy preservation in recommender systems. However, due to direct uploads of model gradients from all clients, FedRec is vulnerable to potential poisoning attacks. In this paper, we focus on the targeted model poisoning attacks in FedRec, which aims to raise the exposure ratio of specific target items by generating poisoned gradients to influence global training. Challenges emerge when implementing this kind of attack. On the one hand, simulating authentic users on the malicious clients for downstream poisoning is hard when access to prior knowledge is limited. On the other hand, distinguished item attributes and personalized user preferences require the attack to be adaptive to complex distributions. To this end, we propose a novel attack DuAda with two modules, i.e., dummy user simulator and adaptive distribution attacker . The dummy user simulator is designed to generate malicious users with characteristics similar to real users, which exploits authentic user representations and preference labels simultaneously through two-stage inversion optimization. The attacker first extracts heterogeneous distributions by a special multi-prototype clustering method, and then conducts adaptive attacks from both explicit and implicit promotion perspectives. The explicit promotion raises the prediction scores of target items based on the inherent characteristics, while the implicit promotion imbues them with the features of popular items. Targeted at our proposed attack method, we also design a merged adaptive defense mechanism to fight against DuAda and conduct defensive experiments. Empirical studies on four real-world datasets demonstrate the effectiveness and interpretability of DuAda.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412898685",
    "type": "article"
  },
  {
    "title": "Explainable Recommendation with Simulated Human Feedback",
    "doi": "https://doi.org/10.1145/3758091",
    "publication_date": "2025-08-05",
    "publication_year": 2025,
    "authors": "Jiakai Tang; Jingsen Zhang; Zihang Tian; X. N. Feng; Lei Wang; Xu Chen",
    "corresponding_authors": "",
    "abstract": "Recent advancements in explainable recommendation have greatly bolstered user experience by elucidating the decision-making rationale. However, the existing methods actually fail to provide effective feedback signals for potentially better or worse generated explanations due to their reliance on traditional supervised learning paradigms in sparse interaction data. To address these issues, we propose a novel human-like feedback-driven optimization framework. This framework employs a dynamic interactive optimization mechanism for achieving human-centered explainable requirements without incurring high labor costs. Specifically, we propose to utilize large language models (LLMs) as human simulators to predict human-like feedback for guiding the learning process. To enable the LLMs to deeply understand the task essence and meet user’s diverse personalized requirements, we introduce a human-induced customized reward scoring method, which helps stimulate the language understanding and logical reasoning capabilities of LLMs. Furthermore, considering the potential conflicts between different perspectives of explanation quality, we introduce a principled Pareto optimization that transforms the multi-perspective quality enhancement task into a multi-objective optimization problem for improving explanation performance. At last, to achieve efficient model training, we design an off-policy optimization pipeline. By incorporating a replay buffer and addressing the data distribution biases, we can effectively improve data utilization and enhance model generality. Extensive experiments on four datasets demonstrate the superiority of our approach.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412991558",
    "type": "article"
  },
  {
    "title": "Position-aware Graph Transformer for Recommendation",
    "doi": "https://doi.org/10.1145/3757736",
    "publication_date": "2025-08-05",
    "publication_year": 2025,
    "authors": "Jiajia Chen; Jiancan Wu; Jiawei Chen; Chongming Gao; Yong Li; Xiang Wang",
    "corresponding_authors": "",
    "abstract": "Collaborative recommendation fundamentally involves learning high-quality user and item representations from interaction data. Recently, graph convolution networks (GCNs) have advanced the field by utilizing high-order connectivity patterns in interaction graphs, as evidenced by state-of-the-art methods like PinSage and LightGCN. However, one key limitation has not been well addressed in existing solutions: capturing long-range collaborative filtering signals, which are crucial for modeling user preference. In this work, we propose a new graph transformer (GT) framework— Position-aware Graph Transformer for Recommendation (PGTR), which combines the global modeling capability of Transformer blocks with the local neighborhood feature extraction of GCNs. The key insight is to explicitly incorporate node position and structure information from the user-item interaction graph into GT architecture via several purpose-designed positional encodings. The long-range collaborative signals from the Transformer block are then combined linearly with the local neighborhood features from the GCN backbone to enhance node embeddings for final recommendations. Empirical studies demonstrate the effectiveness of the proposed PGTR method when implemented on various GCN-based backbones across four real-world datasets and the robustness against interaction sparsity as well as noise. Our implementations are available in GitHub: https://github.com/MEICRS/PGTR .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412991572",
    "type": "article"
  },
  {
    "title": "Uncovering Recommendation Serendipity with Objective Data-driven Factor Investigation",
    "doi": "https://doi.org/10.1145/3758092",
    "publication_date": "2025-08-05",
    "publication_year": 2025,
    "authors": "Wenjun Jiang; Song Li; Xueqi Li; Kenli Li; Jie Wu",
    "corresponding_authors": "",
    "abstract": "The serendipity recommendation tries to burst the filter bubble while still meeting user interests. However, serendipity itself has not been well understood in the recommendation system. Thus, factor investigation in recommendation serendipity has attracted much attention, for which two challenges hinder follow-up research: (1) Ambiguity of factors . Different works exploit different factors, and the meanings of factors are inconsistent in various works. (2) Lack of complete impact validation . The importance of these factors in different domains is not yet fully understood. The common approach of user surveys costs much, but the results are usually less objective and limited in quantity. To this end, we strive to comprehensively identify and clarify serendipity factors and explore objective data-driven approaches to validate factor impacts in large-scale cross-domain scenarios. We first conduct a comprehensive literature review to identify all possible factors, from which we find that some factors are being used indistinguishably. To address this issue, we propose two principles of meaning coverage and factor independence to clarify and disentangle serendipity factors. Next, we propose a general experimental framework to explore the impacts of factors. Then, we implement one such framework and run experiments on nine representative datasets to study factor importance on serendipity. We also propose a quantitative method to measure the degree of disentanglement of factors and to test the effects of factor combinations. We gain several useful findings: (1) relevance , diversity , and random are critical factors affecting serendipity; (2) domain features affect factor importance and can guide serendipity recommendation; (3) the disentanglement quantification method benefits the understanding of serendipity and the combination of factors. To our knowledge, this is the first work to comprehensively investigate serendipity factors and experimentally compare their impacts in an objective data-driven approach.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412991667",
    "type": "article"
  },
  {
    "title": "Agent4Ranking: Semantic Robust Ranking via Personalized Query Rewriting Using Multi-agent LLMs",
    "doi": "https://doi.org/10.1145/3749099",
    "publication_date": "2025-07-17",
    "publication_year": 2025,
    "authors": "Xiaopeng Li; Lixin Su; Pengyue Jia; Suqi Cheng; Junfeng Wang; Dawei Yin; Xiangyu Zhao",
    "corresponding_authors": "",
    "abstract": "Search engines are crucial as they provide an efficient and easy way to access vast amounts of information on the internet for diverse information needs. User queries, even with a specific need, can differ significantly. Prior research has explored the resilience of ranking models against typical query variations like paraphrasing, misspellings, and order changes. Yet, these works overlook how diverse demographics uniquely formulate identical queries. For instance, older individuals tend to construct queries more naturally and in varied order compared to other groups. This demographic diversity necessitates enhancing the adaptability of ranking models to diverse query formulations. To this end, in this paper, we propose a framework that integrates a novel rewriting pipeline that rewrites queries from various demographic perspectives and a novel framework to enhance ranking robustness. To be specific, we use Chain of Thought (CoT) technology to utilize Large Language Models (LLMs) as agents to emulate various demographic profiles, then use them for efficient query rewriting, and we innovate a Robust Multi-gate Mixture of Experts (R-MMoE) architecture coupled with a hybrid loss function, collectively strengthening the ranking models’ robustness. Our extensive experiments on both public and industrial datasets assesses the efficacy of our query rewriting approach and the enhanced accuracy and robustness of the ranking model. The findings highlight the sophistication and effectiveness of our proposed model. We release our code implementation publicly 1 .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413067177",
    "type": "article"
  },
  {
    "title": "SparseFraudNet: A Graph-based Approach for Cold-start Fraud Detection with Information Aggregation",
    "doi": "https://doi.org/10.1145/3748719",
    "publication_date": "2025-08-22",
    "publication_year": 2025,
    "authors": "Wen Zhang; Rui Li; Quan Bai; Song Wang",
    "corresponding_authors": "",
    "abstract": "Online reviews play a critical role in influencing consumer’s purchasing decision on e-commerce, making them a prime target for manipulation through fraudulent reviews. Although various Fraud Detection (FD) techniques have been presented, a crucial problem still remains unaddressed, i.e., the cold-start problem in FD, which refers to the difficulty in identifying fraudulent reviews due to limited historical data for new users and new products. Existing graph-based detection methods, while effective for well-connected nodes, are suffering Sparse Graph (SG) connections in cold-start FD. In this paper, we propose a novel approach called SparseFraudNet to address the problem of cold-start FD with information aggregation. Specifically, the local information aggregation is proposed to dynamically optimize neighbor selection using Reinforcement Learning (RL) with Bernoulli Multi-Armed Bandit (BMAB), with the goal to capture the five key types of relations among reviews. The global information aggregation is proposed to leverage Graph Coarsening (GC) with manifold learning and spectral clustering to mitigate adjacency matrix sparsity for new users under new products using Sparse Spectral Clustering (SSC). Experiments on the YelpZip-Cold and YelpNYC-Cold datasets demonstrate that the proposed SparseFraudNet approach significantly outperforms state-of-the-art methods in FD in terms of accuracy, precision, recall, F1 measure and AUC to identify fraudulent reviews of new users under new products.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413418666",
    "type": "article"
  },
  {
    "title": "CorpusBrain++: A Continual Generative Pre-Training Framework for Knowledge-Intensive Language Tasks",
    "doi": "https://doi.org/10.1145/3763233",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Jiafeng Guo; Changjiang Zhou; Ruqing Zhang; Jiangui Chen; Maarten de Rijke; Yixing Fan; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "Knowledge-intensive language tasks (KILTs) typically require retrieving relevant documents from trustworthy corpora, e.g., Wikipedia, to produce specific answers. Very recently, a pre-trained generative retrieval model for KILTs, named CorpusBrain, was proposed and reached new state-of-the-art retrieval performance. However, most research on KILTs, including CorpusBrain, has predominantly focused on a static document collection, overlooking the dynamic nature of real-world scenarios, where new documents are continuously being incorporated into the source corpus. To address this gap, it is crucial to explore the capability of retrieval models to effectively handle the dynamic retrieval scenario inherent in KILTs. In this work, we first introduce the continual document learning (CDL) task for KILTs and build a novel benchmark dataset named KILT++ based on the original KILT dataset for evaluation. Then, we conduct a comprehensive study of the use of pre-trained CorpusBrain on KILT++. Unlike the promising results in the stationary scenario, CorpusBrain is prone to catastrophic forgetting in the dynamic scenario, hence hampering retrieval performance. To alleviate this issue, we propose CorpusBrain++, a continual generative pre-training framework that enhances the original model along two key dimensions: (i) We employ a backbone-adapter architecture: the dynamic adapter is learned for each downstream KILT task via task-specific pre-training objectives; the backbone parameters that are task-shared are kept unchanged to offer foundational retrieval capacity. (ii) We use an experience replay strategy based on exemplar documents that are similar to new documents, to prevent catastrophic forgetting of old documents. Empirical results demonstrate the effectiveness and efficiency of CorpusBrain++ in comparison to both traditional and generative information retrieval methods.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413591155",
    "type": "article"
  },
  {
    "title": "LLM4DSR: Leveraging Large Language Model for Denoising Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3762182",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Bohao Wang; Feng Liu; Changwang Zhang; Jiawei Chen; Yudi Wu; Sheng Zhou; Xingyu Lou; Jun Wang; Yan Feng; Chun Chen; Can Wang",
    "corresponding_authors": "",
    "abstract": "Sequential recommenders generate recommendations based on users’ historical interaction sequences. However, in practice, these sequences are often contaminated by noisy interactions, which can arise from various factors such as clickbait, the influence of prominently positioned items, or accidental interactions. Such noise can significantly degrade recommendation performance. Accurately identifying such noisy interactions without additional information is particularly challenging due to the absence of explicit supervisory signals indicating noise. Large Language Models (LLMs), equipped with extensive open knowledge and semantic reasoning abilities, offer a promising avenue to bridge this information gap. However, employing LLMs for denoising in sequential recommendation presents notable challenges: 1) Direct application of pretrained LLMs may not be competent for the denoising task, frequently generating nonsensical responses; 2) Fine-tuning on the denoising task can partially mitigate the issue of generating nonsensical outputs. However, even after fine-tuning, the reliability of LLM outputs remains questionable, especially given the complexity of the denoising task and the inherent hallucination issue of LLMs. To tackle these challenges, we propose LLM4DSR, a tailored approach for denoising sequential recommendation using LLMs. We constructed a self-supervised fine-tuning task to activate LLMs’ capabilities to identify noisy items and suggest replacements. Furthermore, we developed an uncertainty estimation module that ensures only high-confidence responses are utilized for sequence corrections. Remarkably, LLM4DSR is model-agnostic, allowing corrected sequences to be flexibly applied across various recommendation models. To the best of our knowledge, this is the first work that employs LLMs for sequential recommendation denoising while addressing the unique challenges of adapting LLMs to this task. Extensive experiments conducted on three real-world datasets across two noise settings validate the effectiveness of LLM4DSR, demonstrating an average improvement of 12.9% in NDCG@20. The code is available at https://github.com/WANGBohaO-jpg/LLM4DSR .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413591191",
    "type": "article"
  },
  {
    "title": "Self-Monitoring Large Language Models for Click-Through Rate Prediction",
    "doi": "https://doi.org/10.1145/3763789",
    "publication_date": "2025-08-26",
    "publication_year": 2025,
    "authors": "Huachi Zhou; Kravtsova Viktoria Yu.; Qinggang Zhang; Hao Chen; Daochen Zha; Wenqi Pei; Anthony Kong; Xiao Huang",
    "corresponding_authors": "",
    "abstract": "Click-through rate prediction tasks estimate interaction probabilities using user-item features (i.e., the combined set of user and item features). LLMs have emerged as a promising approach by organizing these features into prompts and fine-tuning LLMs to predict the interaction label. However, our feature-wise and interaction-wise analysis reveals two critical limitations, leading to incomplete relationship modeling between user-item features and interaction labels: (i) LLMs tend to utilize only a subset of available features, neglecting others, and (ii) they struggle with predictions for tail items that appear less frequently in the training samples. To bridge this gap, we propose F eature- I nstructed L arge language model for M onitoring ( FILM ), which introduces a self-monitoring temperature mechanism that dynamically guides LLMs to focus on informative features, and an auxiliary compaction loss that facilitates better feature-interaction relationship learning for tail items. By integrating these two designs, FILM not only improves feature utilization in LLMs but also enhances predictions for tail items. Furthermore, we demonstrate that FILM -generated interaction embeddings can be transferred to lightweight models, enabling efficient deployment. Extensive experiments demonstrate that FILM achieves significant performance improvements over state-of-the-art baselines by learning better relationships between user-item features and interaction labels and generalizes under different LLM backbones.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413655245",
    "type": "article"
  },
  {
    "title": "A Model-agnostic Pre-training Framework for Search Result Diversification",
    "doi": "https://doi.org/10.1145/3764662",
    "publication_date": "2025-08-26",
    "publication_year": 2025,
    "authors": "Zhirui Deng; Zhicheng Dou; Yutao Zhu; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Search result diversification focuses on providing relevant and diverse documents covering different users’ intents. Intuitively, training an effective and stable search result diversification model needs a large amount of training data. Unfortunately, annotating such data that encompasses real users’ search intents is expensive and time-consuming, and most existing models are trained with limited training data, which might lead to unsatisfactory ranking results. Given that Wikipedia contains massive amounts of rigorous editorial and well-structured data, in this paper, we propose a pre-training framework leveraging the large-scale Wikipedia data to build weak-supervised signals. Specifically, we introduce four strategies to extract paired supervised signals reflecting the subtopic coverage information from Wikipedia. We also propose a subtopic-disentangled negative sampling strategy to sample hard negative samples and enhance the model's ability to identify subtle subtopic differences. Four auxiliary tasks are devised to pre-train the Transformer model, which is further adopted as the representation generation model in the downstream diversified ranking. Experimental results demonstrate that our pre-trained model can significantly improve the performance of several existing models, which confirms the effectiveness and scalability of pre-training for search result diversification.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413683006",
    "type": "article"
  },
  {
    "title": "Getting off the DIME: Dimension Pruning via Dimension Importance Estimation for Dense Information Retrieval",
    "doi": "https://doi.org/10.1145/3765619",
    "publication_date": "2025-09-02",
    "publication_year": 2025,
    "authors": "Guglielmo Faggioli; Nicola Ferro; Raffaele Perego; Nicola Tonellotto",
    "corresponding_authors": "",
    "abstract": "Dense Information Retrieval (IR) systems rely on neural networks to embed documents and queries within a latent low-dimensional space. Among the Dense IR approaches, bi-encoders are particularly popular, as they achieve state-of-the-art performance and allow for efficient encoding of documents and queries. Nevertheless, using this class of systems, by construction, all the documents and queries are represented using the same set of dimensions. In this paper, we introduce the Manifold Clustering (MC) hypothesis which states that, for each query, there exists a query-dependent manifold of the original embedding space where the query and documents relevant to it cluster more effectively. We empirically validate the MC hypothesis showing that it is possible to find a query-dependent linear subspace of the original embedding space where high retrieval effectiveness is achieved. To find such subspaces, we propose the Dimension IMportance Estimators (DIMEs), a class of models that associate an importance score with each dimension of an embedding and can be used to project the dense representations only on the most important dimensions. We first demonstrate the effectiveness of the DIMEs by proposing an oracle DIME which employs annotated documents and induces performance improvements as big as +184% in terms of AP. To demonstrate the practical applicability of the DIMEs beyond the oracle, we also propose a set of DIMEs based on pseudo-relevance and active feedback that induce improvement as big as +49.6% in terms of AP and +55.9% in terms of nDCG@10. The effectiveness of such DIMEs not only empirically supports the MC hypothesis, but illustrates an actual strategy to outperform the state-of-the-art that does not require any form of retraining, fine-tuning or re-indexing and can be efficiently implemented at retrieval time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413928702",
    "type": "article"
  },
  {
    "title": "Projection-Displacement based Query Performance Prediction for Embedded Space of Dense Retrievers",
    "doi": "https://doi.org/10.1145/3765617",
    "publication_date": "2025-09-02",
    "publication_year": 2025,
    "authors": "Suchana Datta; Guglielmo Faggioli; Nicola Ferro; Debasis Ganguly; Cristina Ioana Muntean; Raffaele Perego; Nicola Tonellotto",
    "corresponding_authors": "",
    "abstract": "Recent advances in representation learning have enabled neural Information Retrieval (IR) systems to use learned dense representations for queries and documents to effectively handle semantics, language nuances, and vocabulary mismatch problems. In contrast to traditional IR systems that rely on word matching, dense IR models exploit query/document similarity in dense latent spaces to account for semantics. This requires substantial training data and comes with increased computational demands. Thus, it would be beneficial to predict how a system will perform for a given query to decide whether a dense IR model is the best option or alternatives should be used. Traditional Query Performance Predictors (QPP) are designed for lexical IR approaches and perform sub-optimally when applied to dense neural IR systems. Therefore, there has been a renewed interest in QPP methods to improve their effectiveness for dense neural IR models. While the results of the new QPP methods are generally encouraging, there is ample room for improvement in absolute performance and stability. We argue that by using features more aligned with the underlying rationale of dense IR models, we can enhance the performance of QPP. In this respect, we propose the Projection-Displacement based QPP (PDQPP), which exploits the geometric properties of dense IR models, projects queries and retrieved documents onto subspaces defined by pseudo-relevant documents, and considers changes in retrieval scores within them as a proxy for retrieval coherence. Minor score changes suggest robust and coherent retrieval, while significant alterations indicate semantic divergence and potentially poor performance. Results over a wide range of experimental settings on both traditional (TREC Robust) and neural-oriented (TREC Deep Learning) test collections show that PDQPP mostly outperforms the state-of-the-art QPP baselines.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413929082",
    "type": "article"
  },
  {
    "title": "Decentralized Next Point-of-Interest Recommendation Guided by Willingness to Share",
    "doi": "https://doi.org/10.1145/3766066",
    "publication_date": "2025-09-05",
    "publication_year": 2025,
    "authors": "Ziqing Wu; Zhu Sun; Dongxia Wang; Lu Zhang; Jie Zhang; Yew-Soon Ong",
    "corresponding_authors": "",
    "abstract": "Decentralized learning (DL) has proven to be effective for privacy-preserving next Point-of-Interest (POI) recommendation by sharing check-in information among users and collaboratively training on-device models. Existing works, however, simply assume that users tend to share check-ins with neighbors of short geographical distance or similar preferences yet ignore users’ actual willingness to share the information (WSI), causing potential privacy concerns. As such, we present a W SI-guided H ierarchical DL framework for next POI Rec ommendation (WHDL-Rec) to seek enhanced privacy protection with recommendation accuracy assured. In particular, WHDL-Rec first performs hierarchical data segregation to partition the private and public user data. It then accords to the server-client architecture, where the server exploits the public data to automatically learn users’ WSI w.r.t. check-ins and capture global user behavior patterns for recommendation accuracy maintenance; and the clients fuse the learned global patterns with the local private data for personalized on-device next POI recommendation, whereby WSI-guided collaborative learning is conducted with more secure check-in sharing. Extensive experiments on three real-world datasets demonstrate the efficacy of WHDL-Rec in delivering more accurate and privacy-preserved recommendations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414014524",
    "type": "article"
  },
  {
    "title": "User Immersion-aware Short Video Recommendation",
    "doi": "https://doi.org/10.1145/3748303",
    "publication_date": "2025-09-05",
    "publication_year": 2025,
    "authors": "Zhiyu He; Shaorun Zhang; Weizhi Ma; Jiayu Li; Peijie Sun; Qingyao Ai; Yiqun Liu; Min Zhang",
    "corresponding_authors": "",
    "abstract": "Short videos have gained immense popularity, necessitating effective recommender systems that cater to individual preferences. The platforms use advanced algorithms to analyze user engagement and provide videos that satisfy users. A critical factor in user satisfaction is immersion , defined as the feeling of being deeply engaged in an activity. However, existing recommendation algorithms in the short video scenario have largely disregarded user immersion. Our study integrates user immersion into recommendation systems, aiming to predict immersion from user interactions and recommend items to enhance the overall viewing experience. Based on the user study of collecting and analyzing user immersion, we integrate immersion into the recommendations for both lab and large-scale scenarios. We adapt user-annotated immersion to large-scale real-world datasets without immersion labels. Specifically, we propose ImmersRec , an immersion-aware recommendation framework with immersion prediction fine-tuning, immersion knowledge alignment, and immersion-enhanced recommendation. Extensive experiments on two short video platforms indicate that our approach achieves significant enhancements among various context-aware recommender backbones. We investigate the predicted immersion and find it impacts not only short-term utility but also long-term user engagement. This research pioneers the incorporation of user immersion in short video recommendation algorithms, emphasizing its potential for improving recommendations with minimal data. The code can be available at https://github.com/hezy18/ImmersRec.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414014630",
    "type": "article"
  },
  {
    "title": "Predicting Document Relevance from Brain Recordings",
    "doi": "https://doi.org/10.1145/3766067",
    "publication_date": "2025-09-08",
    "publication_year": 2025,
    "authors": "Vadym Gryshchuk; Maria Maistro; Christina Lioma; Tuukka Ruotsalo",
    "corresponding_authors": "",
    "abstract": "Recent neuroimaging studies have revealed the association between relevance and brain responses. However, fundamental questions about how the human brain responds to a human relevance judgement of an entire text document and how such responses could be used in predicting document relevance remain unexplored. Here, we present the first work to utilise electroencephalography (EEG) data for predicting document relevance with respect to the topic selected by a human whose brain responses are recorded during document reading. Our approach jointly learns to predict document relevance from EEG and word embeddings computed for the document under a bimodal architecture. The EEG representations in our bimodal architecture account for a human’s attention towards words, and word embeddings are used as a representation of word semantics. Experiments with several EEG decoding models and word embedding models show that document relevance can be predicted from EEG data and that our bimodal approach yields higher prediction performance ( \\(\\text{AUROC}=0.68\\) ) than models with only word embeddings ( \\(\\text{AUROC}=0.62\\) ) or only EEG data ( \\(\\text{AUROC}=0.63\\) ). Our findings create new opportunities for modelling document relevance through implicit physiological signals, emphasising the combined importance of human brain signals and language models in capturing personalised document relevance beyond traditional behavioural signals.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414053533",
    "type": "article"
  },
  {
    "title": "ITCoHD-MRec: An Independent Topological Preference Aware and Cooperative Hypergraph Diffusion based Multimodal Recommender Model",
    "doi": "https://doi.org/10.1145/3767337",
    "publication_date": "2025-09-11",
    "publication_year": 2025,
    "authors": "Xiulan Hao; Xinwei Li; Hua Wang; Zhonglong Zheng; Yunliang Jiang; Yanchun Zhang",
    "corresponding_authors": "",
    "abstract": "Multimodal recommendation provides richer and more accurate personalized recommendations by jointly modeling user’s historical behaviors and different modality of items, such as text, image, audio and video in online platforms. Most existing work of multimodal recommendation focuses on leveraging modal features and modal correlation graph structures to learn user preferences. Due to insufficient exploration of user collaborative preferences and the noise during high-order multimodal data connections, valuable information may be lost, leading to deviations in understanding user preferences. Therefore, an I ndependent T opological preference aware and Co operative H ypergraph D iffusion based M ultimodal Rec ommender Model (ITCoHD-MRec) is necessary for online platforms. This paper aims to develop an ITCoHD-MRec that incorporates topological perception as well as generative diffusion models in multimodal hypergraph recommendation to make the model more adaptive and robust in complex environments. Firstly, leveraging a Graph Convolutional Network (GCN), the model independently captures user preference representations for both collaborative relevance and modal relevance from the user-item interaction graph, which contains ID embeddings and modal features. This enables the extraction of deeper associations between users and items. Secondly, leveraging topological pruning techniques, the model learns differentiated features in different modal blocks to prevent node representations from becoming homogenized. This helps further identify user preferred connectivity patterns and removes redundant noisy connections. Finally, by employing the diffusion model, information regarding the higher-order interaction patterns between attributes and items within the hypergraph structure is propagated. This effectively captures the potential global dependencies between attributes and items, thereby providing deeper associations enriched with more substantial semantic information for subsequent recommendation tasks. The model autonomously learns different features and higher-order connectivity of nodes, which enables the model to obtain a wider and more accurate perception of user preferences in complex interaction environments. Experimental comparisons with fifteen models on four real datasets - Baby, Sports, Clothing and Electronics show that the model improves the recall by 0.85% to 3.57% and the normalized discounted cumulative gain by 2.31% to 3.43%, which validates the effectiveness of ITCoHD-MRec.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414153418",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on Causality Representation Learning in LLMs-Driven Recommender Systems",
    "doi": "https://doi.org/10.1145/3747838",
    "publication_date": "2025-07-08",
    "publication_year": 2025,
    "authors": "Lina Yao; Julian McAuley; Yongfeng Zhang; Kun Zhang",
    "corresponding_authors": "",
    "abstract": "This editorial introduces the Special Issue on Trustworthy Recommender Systems, hosted by the ACM Transactions on Recommender Systems in 2024. We provide an overview on the multifaceted aspects of trustworthiness and point to recent regulations that ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414164649",
    "type": "article"
  },
  {
    "title": "Robust Neural Information Retrieval: An Adversarial and Out-of-Distribution Perspective",
    "doi": "https://doi.org/10.1145/3768153",
    "publication_date": "2025-09-16",
    "publication_year": 2025,
    "authors": "Yu-An Liu; Ruqing Zhang; Jiafeng Guo; Maarten de Rijke; Yixing Fan; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "Recent advances in neural information retrieval models have significantly enhanced these models’ effectiveness across information retrieval tasks. The robustness of these models, which is essential for ensuring their reliability in practice, has also garnered significant attention. With a wide array of research on robust information retrieval being published, we believe it is the opportune moment to consolidate the current status, glean insights from existing methodologies, and lay the groundwork for future development. Robustness of information retrieval is a multifaceted concept and we emphasize the importance of robustness against performance variance, out-of-distribution scenarios, and adversarial attacks. With a focus on out-of-distribution and adversarial robustness, we dissect robustness solutions for dense retrieval models and neural ranking models, respectively, recognizing them as pivotal components of the neural information retrieval pipeline. We provide an in-depth discussion of methods, datasets, and evaluation metrics, shedding light on challenges and future directions in the era of large language models. To accompany this survey, we release three additional resources: (1) a curated list of publications related to robust information retrieval, 1 (2) a tutorial based on this survey, 2 and (3) a heterogeneous benchmark for robust information retrieval, BestIR, that collects all known datasets for evaluating information retrieval systems for robustness. 3 We hope that this study provides useful clues for future research on the robustness of information retrieval models and helps to develop trustworthy IR systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414241558",
    "type": "article"
  },
  {
    "title": "Large Language Models in Document Intelligence: A Comprehensive Survey, Recent Advances, Challenges and Future Trends",
    "doi": "https://doi.org/10.1145/3768156",
    "publication_date": "2025-09-16",
    "publication_year": 2025,
    "authors": "Wenjun Ke; Yifan Zheng; Yining Li; Hengyuan Xu; Dong Nie; Peng Wang; Yao He",
    "corresponding_authors": "",
    "abstract": "The rapid proliferation of documents has made document intelligence increasingly critical across various industries. In recent years, large language models (LLMs) have dramatically transformed the field of document intelligence, allowing for more advanced and accurate document processing solutions. Despite these advancements, most existing surveys have failed to focus on these breakthroughs, instead concentrating on traditional methods and earlier machine learning techniques. This survey seeks to fill that gap by offering an in-depth analysis of approximately 300 papers published between 2021 and mid-2025, thus providing a comprehensive overview of the impact of LLMs in document intelligence. The key topics explored include retrieval-augmented generation (RAG), long context processing, and fine-tuning LLMs for document comprehension. Furthermore, the survey highlights essential datasets, practical applications, current challenges, and future research directions, offering critical insights for both researchers and industry practitioners looking to advance the field.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414241920",
    "type": "article"
  },
  {
    "title": "A Comprehensive Survey on Composed Image Retrieval",
    "doi": "https://doi.org/10.1145/3767328",
    "publication_date": "2025-09-16",
    "publication_year": 2025,
    "authors": "Xuemeng Song; Haoqiang Lin; Haokun Wen; Bohan Hou; Mingzhu Xu; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "Composed Image Retrieval (CIR) is an emerging yet challenging task that allows users to search for target images using a multimodal query, comprising a reference image and a modification text specifying the user’s desired changes to the reference image. Given its significant academic and practical value, CIR has become a rapidly growing area of interest in the computer vision and machine learning communities, particularly with the advances in deep learning. To the best of our knowledge, there is currently no comprehensive review of CIR to provide a timely overview of this field. Therefore, we synthesize insights from over 150 publications in top conferences and journals, including ACM TOIS, SIGIR, and CVPR. In particular, we systematically categorize existing supervised CIR and zero-shot CIR models using a fine-grained taxonomy. For a comprehensive review, we also briefly discuss approaches for tasks closely related to CIR, such as attribute-based CIR and dialog-based CIR. Additionally, we summarize benchmark datasets for evaluation and analyze existing supervised and zero-shot CIR methods by comparing experimental results across multiple datasets. Furthermore, we present promising future directions in this field, offering practical insights for researchers interested in further exploration.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414243647",
    "type": "article"
  },
  {
    "title": "Multi-Channel Hypergraph Contrastive Learning for Matrix Completion",
    "doi": "https://doi.org/10.1145/3768319",
    "publication_date": "2025-09-17",
    "publication_year": 2025,
    "authors": "Xiang Li; Changsheng Shui; Zhongying Zhao; Junyu Dong; Yanwei Yu",
    "corresponding_authors": "",
    "abstract": "Rating is a typical user’s explicit feedback that visually reflects how much a user likes a related item. The (rating) matrix completion is essentially a rating prediction process, which is also a significant problem in recommender systems. Recently, graph neural networks (GNNs) have been widely used in matrix completion, which captures users’ preferences over items by formulating a rating matrix as a bipartite graph. However, existing methods are susceptible due to data sparsity and long-tail distribution in real-world scenarios. Moreover, the messaging mechanism of GNNs makes it difficult to capture high-order correlations and constraints between nodes, which are essentially useful in recommendation tasks. To tackle these challenges, we propose a M ulti-Channel H ypergraph C ontrastive L earning framework for matrix completion, named MHCL. Specifically, MHCL adaptively learns hypergraph structures to capture high-order correlations between nodes and jointly captures local and global collaborative relationships through attention-based cross-view aggregation. Additionally, to consider the magnitude and order information of ratings, we treat different rating subgraphs as different channels, encourage alignment between adjacent ratings, and further achieve the mutual enhancement between different ratings through multi-channel cross-rating contrastive learning. Extensive experiments on eight publicly available real-world datasets demonstrate that our proposed method significantly outperforms the current state-of-the-art approaches. The source code of our model is available at https://github.com/lx970414/MHCL.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414277007",
    "type": "article"
  },
  {
    "title": "Knowledge Graph Pruning for Recommendation",
    "doi": "https://doi.org/10.1145/3769107",
    "publication_date": "2025-09-23",
    "publication_year": 2025,
    "authors": "Fake Lin; Xi Zhu; Ziwei Zhao; Deqiang Huang; Yu Yu; Xueying Li; Zhi Zheng; Tong Xu; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "Recent years have witnessed the prosperity of knowledge graph based recommendation system (KGRS), which enriches the representation of users, items, and entities by structural knowledge with striking improvement. Nevertheless, its unaffordable computational cost still limits researchers from exploring more sophisticated models. We observe that the bottleneck for training efficiency arises from the knowledge graph, which is plagued by the well-known issue of knowledge explosion. Recently, some works have attempted to slim the inflated KG via summarization techniques, which summarize multiple real nodes into the single virtual one. However, these summarized virtual nodes may ignore collaborative signals and thus fail to figure out the redundant nodes related to recommendation task. To this end, in this paper, we propose a novel approach called KGTrimmer for knowledge graph pruning tailored for recommendation, to remove the unessential nodes while minimizing performance degradation. Specifically, we design an importance evaluator from a dual-view perspective. For the collective view, we embrace the idea of collective intelligence by extracting community consensus based on abundant collaborative signals, i.e., nodes are considered important if they attract attention of numerous users. For the holistic view, we learn a global mask to identify the valueless nodes from their inherent properties or overall popularity. With the collective and holistic importance scores, we build an end-to-end importance-aware graph neural network, which injects filtered knowledge to enhance the distillation of valuable user-item collaborative signals. Ultimately, we generate a pruned knowledge graph with lightweight, stable, and robust properties to facilitate the following-up recommendation task. Extensive experiments are conducted on three publicly available datasets to prove the effectiveness and generalizability of KGTrimmer, where it can reduce the number of triplets in KG by up to 90% without compromising performance.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414436789",
    "type": "article"
  },
  {
    "title": "Periodic Graph Neural Networks for Click-Through Rate Prediction in Online Advertising",
    "doi": "https://doi.org/10.1145/3769103",
    "publication_date": "2025-09-23",
    "publication_year": 2025,
    "authors": "Panyu Zhai; Yanwu Yang; Chunjie Zhang",
    "corresponding_authors": "",
    "abstract": "CTR prediction serves as a valuable function to provide indications about the effectiveness of advertising campaigns. Numerous models have been developed to learn dynamic representations and sophisticated feature interactions for CTR prediction. We observe that users’ behavioral sequences have periodic patterns, which is a crucial factor for capturing the temporal dependency in highly dynamic environments such as online advertising. Unfortunately, existing work ignores periodic patterns in CTR prediction, and thus incurs the low model performance. This paper proposes a periodic CTR prediction model in the GNNs modeling framework (PGNN), that combines periodic graph representations and feature graph representations. The former learns periodic graph representations of users’ and ads’ sequences with multi-scale periodic patterns and the high-order collaborative information across sequences on a dynamic graph of user-ad interactions, and the latter is designed to learn sophisticated feature interactions by incorporating the principle of field-aware feature interaction into an interpolable graph convolutional attention mechanism on a feature graph. Experiments conducted on three public datasets (i.e., Movielens-1M, Criteo-attribution and Alimama) demonstrate the superiority of PGNN. PGNN outperforms the strongest baseline by 0.01~0.02 in terms of AUC and Logloss. Meanwhile, the effectiveness of periodic graph representation learning is also verified in this research.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414449234",
    "type": "article"
  },
  {
    "title": "GANPrompt: Improving LLM-Based Recommendations with GAN-Enhanced Diversity Prompts",
    "doi": "https://doi.org/10.1145/3769428",
    "publication_date": "2025-09-26",
    "publication_year": 2025,
    "authors": "Xinyu Li; Chuang Zhao; Hongke Zhao; Likang Wu; Ming He; Jianping Fan",
    "corresponding_authors": "",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in understanding and generating natural language, with an increasing presence in the field of recommendation systems. However, LLMs still encounter a significant issue known as prompt sensitivity, where the model's output is susceptible to minor changes in the input prompt. This challenge is particularly problematic in recommendation systems, which rely on stable and consistent outputs. Fine-tuning LLMs with diverse prompts can reduce prompt sensitivity, but also lead to a decline in recommendation performance. Therefore, choosing an effective fine-tuning method is important to achieve enhanced robustness without sacrificing performance. To address prompt sensitivity while maintaining recommendation performance, we propose G enerative A dversarial N etwork-based p rompt enhancement (GANPrompt), a framework for improving LLM-based recommendation systems using adversarial game theory. In this framework, the generator and discriminator compete to produce diverse prompts, which are then used to fine-tune LLM-based recommendation systems, enhancing both robustness and accuracy. Specifically, to generate diverse prompts for fine-tuning and enhance the robustness of LLMs, we develop a GAN-based generator for diverse prompts, with an attribute generation module providing the foundational data support. Further, we introduce a diversity constraint to ensure that the generated prompts maintain high diversity while preserving semantic consistency. To maintain accuracy during the fine-tuning process, we introduce an explicit guidance knowledge token integration method. This method reduces noise and information loss in the face of diverse prompts by enhancing the use of traditional collaborative signals. Through extensive experiments on four publicly available datasets and one real-world industrial dataset, we demonstrate the effectiveness of the proposed framework. Our source code is available at https://github.com/LxytIUON/GANPrompt .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414555619",
    "type": "article"
  },
  {
    "title": "A Hybrid Adaptive Sampling Strategy for Fair and Accurate Meta-learned User Modeling",
    "doi": "https://doi.org/10.1145/3769296",
    "publication_date": "2025-09-30",
    "publication_year": 2025,
    "authors": "Zheng Zhang; Qi Liu; Zirui Hu; Yi Zhan; Zhenya Huang; Weibo Gao; Qingyang Mao; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "User modeling serves as a crucial foundation for researchers to capture useful potential characteristics, playing a pivotal role in various applications such as recommender systems. One common challenge in user modeling is the cold-start problem, where interactions are notably limited for new users. To tackle this issue, the paradigm of meta-learning has been introduced to user modeling, yielding promising results. Similar to a guidebook for a new traveler, meta-learning significantly influences decision-making for new users in critical scenarios, such as career recommendations. Consequently, the issue of fairness in meta-learning has become paramount. Several methods have been proposed to mitigate unfairness in meta-learning and have shown promising results. However, a fundamental question remains unexplored: What is the critical factor leading to unfairness in meta-learned user modeling? Through theoretical analysis that integrates the meta-learning paradigm with group fairness metrics, we identify group proportion imbalance as a critical factor. Subsequently, another question arises: How can we mitigate the influence of this factor to enhance fairness while ensuring accuracy? To this end, we introduce a novel F airness-aware A daptive S ampling framework for me T a-learning, abbreviated as FAST. Its core concept involves adaptively adjusting the sampling distribution for different user groups during the interleaved training process of meta-learning. Moreover, we provide theoretical guarantees demonstrating the convergence of FAST, showcasing its potential to effectively eliminate unfairness. Furthermore, to ensure model accuracy, we enhance FAST with FAST+ by introducing a hybrid sampling strategy at an individual level. This strategy prioritizes fairness and thoroughly explores important users during the sampling process, allowing for a better accuracy-fairness trade-off. Finally, we conduct extensive experiments on real-world datasets, which demonstrate the effectiveness of both FAST and FAST+ frameworks.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414654670",
    "type": "article"
  },
  {
    "title": "RECOSIM: A Universal, Accurate, and Scalable Simulation Framework for Online Community Recommendations",
    "doi": "https://doi.org/10.1145/3768342",
    "publication_date": "2025-10-03",
    "publication_year": 2025,
    "authors": "Guangping Zhang; Dongsheng Li; Hansu Gu; Peng Zhang; Tun Lu; Li Shang; Ning Gu",
    "corresponding_authors": "",
    "abstract": "As recommender systems become increasingly important components in online communities, studying their impact on these communities becomes ever more crucial. Facing the high costs and ethical risks of real-world social experiments, researchers construct recommendation simulators to study the interactions between recommender systems and users. However, existing simulators face challenges in providing universal, accurate, and scalable interaction modeling for various types of online communities involving millions of contents and users with diverse action types. To address these challenges, we propose RECOSIM, a simulation framework capable of offering efficient recommendation interaction simulations across a wide range of scenarios. RECOSIM decomposes the user agent into five fundamental modules: Encode Model, Decode Model, Activity Model, Scoring Model, and Generation Model, allowing for accurate and extensible modeling of user behavior and interaction dynamics. The recommender system agent adheres to established industry architectures, implementing three stages and four fundamental strategies, thereby improving generalizability across various platforms and the computational efficiency of simulation. Utilizing two real-world datasets (Weibo and Zhihu), we validate the accuracy and stability of each component and the overall framework of RECOSIM, demonstrating the reliability of RECOSIM as a simulation environment. Subsequently, we delve into analyzing the impact of the four fundamental recommendation strategies on online communities, providing design inspirations for enhancing user engagement and community growth.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414799610",
    "type": "article"
  },
  {
    "title": "Knowledge-Driven Reasoning for Compatible and Interpretable API Recommendation via Teacher LLM Distillation",
    "doi": "https://doi.org/10.1145/3771772",
    "publication_date": "2025-10-14",
    "publication_year": 2025,
    "authors": "Lianyong Qi; Jinyun Xie; Chunhua Hu; Xiaolong Xu; Hong-Ya Xiang; Haipeng Dai; Rong Gu; Xuyun Zhang; Wanchun Dou",
    "corresponding_authors": "",
    "abstract": "Application Programming Interface (API) recommendation is a crucial task in code intelligence, aiming to suggest suitable APIs for programming queries. Recent efforts have integrated Large Language Models (LLMs) into this task. However, these methods overlook the compatibility between recommended APIs and fail to fully utilize the factual knowledge of APIs. Moreover, these prompting-only methods are limited by the insufficient domain-specific knowledge of LLMs. In this paper, we propose a novel fine-tuning method, KDRAR, designed to leverage knowledge-driven reasoning with LLMs for compatible and interpretable API recommendation. To fully utilize the factual knowledge, we introduce a dual matching strategy that leverages both function descriptions and keyword matching to retrieve candidate APIs. To handle compatibility, we translate compatibility information into descriptive knowledge [73], which is integrated into the recommendation process. Furthermore, we adopt a distilled fine-tuning strategy: a student LLM is trained via distillation from a teacher LLM to perform step-by-step reasoning for enhanced recommendation and explanation. By considering both function matching and compatibility information, the knowledge-driven reasoning not only improves API recommendation accuracy but also provides reasonable explanations for the recommendations. Experimental results show that our method significantly outperforms baseline methods on API recommendation tasks across multiple API domains.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415157126",
    "type": "article"
  },
  {
    "title": "A Comprehensive Survey on Retrieval Methods in Recommender Systems",
    "doi": "https://doi.org/10.1145/3771925",
    "publication_date": "2025-10-16",
    "publication_year": 2025,
    "authors": "Junjie Huang; Jizheng Chen; Jianghao Lin; Jiarui Qin; Ziming Feng; Weinan Zhang; Yong Yu",
    "corresponding_authors": "",
    "abstract": "In an era dominated by information overload, effective recommender systems are essential for managing the deluge of data across digital platforms. Multi-stage cascade ranking systems are widely used in the industry, with retrieval and ranking being two typical stages. Retrieval methods sift through vast candidates to filter out irrelevant items, while ranking methods prioritize these candidates to present the most relevant items to users. Unlike studies focusing on the ranking stage, this survey explores the critical yet often overlooked retrieval stage of recommender systems. To achieve precise and efficient personalized retrieval, we summarize existing work in three key areas: improving similarity computation between user and item, enhancing indexing mechanisms for efficient retrieval, and optimizing training methods of retrieval. We also provide a comprehensive set of benchmarking experiments on three public datasets. Furthermore, we highlight current industrial applications through a case study on retrieval practices at a specific company, covering the entire retrieval process and online serving, along with practical implications and challenges. By detailing the retrieval stage, which is fundamental for effective recommendation, this survey aims to bridge the existing knowledge gap and serve as a cornerstone for researchers interested in optimizing this critical component of cascade recommender systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415249087",
    "type": "article"
  },
  {
    "title": "Beyond Texts: Incorporating Co-occurrences into the Review-based Conversation Recommendation Systems.",
    "doi": "https://doi.org/10.1145/3771276",
    "publication_date": "2025-10-16",
    "publication_year": 2025,
    "authors": "Haoyao Zhang; Zhida Qin; Xinjian Liang; Jing Guo; Shuang Li; Tianyu Huang; John C. S. Lui",
    "corresponding_authors": "",
    "abstract": "Conversational recommender systems (CRSs) interact with users through natural language to provide recommendations and generate responses. Due to limited information in conversation, existing works utilize KGs or reviews to improve CRS. Despite achievements, they overlook co-occurrence relations which have shown effectiveness in collaborative filtering systems. In this work, we first propose a novel framework named CoCRS , aiming to incorporate Co -occurrences into the review-based C onversation R ecommendation S ystems. In CoCRS, we mine co-occurrences from two aspects: (1) item and entity , (2) user and item . For the first one, we extract entities from redundant review texts by KG and construct a relation-aware item-entity heterogeneous graph. In the second aspect, we analyze review sentiments and construct a sentiment-aware user-item bipartite graph. We encode two graphs to obtain user and entity embeddings. Since users in CRS are anonymous, we generate a virtual similar user representation to match reviews with users. Besides, we capture time-aware preference representation from two time dimensions. Finally, we generate word-level user representation with word-oriented KG and model user preference by integrating the above representations. Extensive experiments demonstrate that CoCRS outperforms baselines and the cold-start experiment highlights its robustness. The LLM experiment illustrates the significant role of co-occurrence relationships in LLM-based CRS. Our code are available at https://github.com/Qin-lab-code/CoCRS.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415260839",
    "type": "article"
  },
  {
    "title": "Feedback techniques for continuity and synchronization in multimedia information retrieval",
    "doi": "https://doi.org/10.1145/201040.201044",
    "publication_date": "1995-04-01",
    "publication_year": 1995,
    "authors": "P. Venkat Rangan; S. Ramanathan; Srihari Sampath-Kumar",
    "corresponding_authors": "",
    "abstract": "Future advances in storage and networking technologies will make it feasible to build multimedia on-demand information servers capable of providing services similar to those of a neighborhood videotape rental store over metropolitan area networks. Such multimedia information servers must not only support retrieval of continuous media units (such as video frames and audio samples), but also preserve synchrony among playback of the different media components constituting a multimedia object. We develop techniques for supporting continuous and synchronous retrieval from multimedia servers. We present feedback techniques by which, during retrieval of multimedia objects from a multimedia server to mediaphones, the multimedia server uses lightweight messages called feedback units transmitted periodically back to it (by mediaphones) to detect impending discontinuities as well as asynchronies at mediaphones. The multimedia server then preventively readjusts media transmission so as to avoid either anomaly, and steers the mediaphones back to synchrony. Given the available buffer sizes at mediaphones and the maximum tolerable asynchrony, we present methods to determine the minimum rate at which feedback units must be transmitted so as to maintain both continuity and synchronization. These feedback techniques remain robust even in the presence of playback rate mismatches and network delay jitter, and their initial simulation for video-audio playback yields a feedback rate of one per 1,000 media units to keep the asynchrony within 250ms, showing that the overhead due to feedback transmission is very small. The constant rate feedback techniques developed in this article form the basis of a prototype on-demand information server being developed at the UCSD Multimedia Laboratory.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2070397412",
    "type": "article"
  },
  {
    "title": "A study of probability kinematics in information retrieval",
    "doi": "https://doi.org/10.1145/290159.290161",
    "publication_date": "1998-07-01",
    "publication_year": 1998,
    "authors": "Fábio Crestani; C. J. van Rijsbergen",
    "corresponding_authors": "",
    "abstract": "We analyze the kinematics of probabilistic term weights at retrieval time for different Information Retrieval models. We present four models based on different notions of probabilistic retrieval. Two of these models are based on classical probability theory and can be considered as prototypes of models long in use in Information Retrieval, like the Vector Space Model and the Probabilistic Model. The two other models are based on a logical technique of evaluating the probability of a conditional called imaging; one is a generalization of the other. We analyze the transfer of probabilities occurring in the term space at retrieval time for these four models, compare their retrieval performance using classical test collections, and discuss the results. We believe that our results provide useful suggestions on how to improve existing probabilistic models of Information Retrieval by taking into consideration term-term similarity.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W1999713929",
    "type": "article"
  },
  {
    "title": "An extension of Ukkonen's enhanced dynamic programming ASM algorithm",
    "doi": "https://doi.org/10.1145/214174.214183",
    "publication_date": "1996-01-11",
    "publication_year": 1996,
    "authors": "Hal Berghel; David Roach",
    "corresponding_authors": "",
    "abstract": "We describe an improvement on Ukkonen's Enhanced Dynamic Programming (EHD) approximate string-matching algorithm for unit-penalty four-edit comparisons. The new algorithm has an asymptotic complexity similar to that of Ukkonen's but is significantly faster due to a decrease in the number of array cell calculations. A 42% speedup was achieved in an application involving name comparisons. Even greater improvements are possible when comparing longer and more dissimilar strings. Although the speed of the algorithm under consideration is comparable to other fast ASM algorithms, it has greater effectiveness in text-processing applications because it supports all four basic Damerau-type editing operations.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2050711351",
    "type": "article"
  },
  {
    "title": "A general framework for bidirectional translation between abstract and pictorial data",
    "doi": "https://doi.org/10.1145/146486.146557",
    "publication_date": "1992-10-01",
    "publication_year": 1992,
    "authors": "Satoshi Matsuoka; Shin Takahashi; Tomihisa Kamada; Akinori Yonezawa",
    "corresponding_authors": "",
    "abstract": "The merits of direct manipulation are now widely recognized. However, direct manipulation interfaces incur high cost in their creation. To cope with this problem, we present a model of bidirectional translation between pictures and abstract application data, and a prototype system, TRIP2, based on this model. Using this model, general mapping from abstract data to pictures and from pictures to abstract data is realized merely by giving declarative mapping rules, allowing fast and easy creation of direct manipulation interfaces. We apply the prototype system to the generation of the interfaces for kinship diagrams, Graph Editors, E-R diagrams, and an Othello game.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W3088085860",
    "type": "article"
  },
  {
    "title": "Collaborative conceptual schema design",
    "doi": "https://doi.org/10.1145/291128.291130",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "Sudha Ram; V. Ramesh",
    "corresponding_authors": "",
    "abstract": "Recent years have seen an increased interest in providing support for collaborative activities among groups of users participating in various information systems design tasks such as, requirements determination and process modeling. However, little attention has been paid to the collaborative conceptual database design process. In this article, we develop a model of the collaborative conceptual schema development process and describe the design and implementation of a graphical multiuser conceptual schema design tool that is based on the model. The system we describe allows a group of users to work collaboratively on the creation of database schemas in synchronous (same-time) mode (either in a face-to-face or distributed setting). Extensive modeling support is provided to assist users in creating semantically correct conceptual schemas. The system also provides users with several graphical facilities such as, a large drawing workspace with the ability to scroll or “jump” to any portion of this workspace, zooming capabilities, and the ability to move object(s) to any portion of the workspace. The unique component of the system, however, is its built-in support for collaborative schema design. The system supports a relaxed WYSIWIS environment, i.e., each user can control the graphical layout of the same set of schema objects. The system ensures that changes/additions made by any user are consistent. Any conflicts that may compromise to the integrity of the shared schema are flagged and resolved by the system. The results from a preliminary experiment suggest that the use of our system in a collaborative mode improved information sharing among users, minimized conflicts, and led to a more comprehensive schema definition.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2074903028",
    "type": "article"
  },
  {
    "title": "MEGA---the maximizing expected generalization algorithm for learning complex query concepts",
    "doi": "https://doi.org/10.1145/944012.944014",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "Edward Yi Chang; Beitao Li",
    "corresponding_authors": "",
    "abstract": "Specifying exact query concepts has become increasingly challenging to end-users. This is because many query concepts (e.g., those for looking up a multimedia object) can be hard to articulate, and articulation can be subjective. In this study, we propose a query-concept learner that learns query criteria through an intelligent sampling process. Our concept learner aims to fulfill two primary design objectives: (1) it has to be expressive in order to model most practical query concepts and (2) it must learn a concept quickly and with a small number of labeled data since online users tend to be too impatient to provide much feedback. To fulfill the first goal, we model query concepts in k -CNF, which can express almost all practical query concepts. To fulfill the second design goal, we propose our maximizing expected generalization algorithm (MEGA), which converges to target concepts quickly by its two complementary steps: sample selection and concept refinement. We also propose a divide-and-conquer method that divides the concept-learning task into G subtasks to achieve speedup. We notice that a task must be divided carefully, or search accuracy may suffer. Through analysis and mining results, we observe that organizing image features in a multiresolution manner, and minimizing intragroup feature correlation, can speed up query-concept learning substantially while maintaining high search accuracy. Through examples, analysis, experiments, and a prototype implementation, we show that MEGA converges to query concepts significantly faster than traditional methods.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2022743991",
    "type": "article"
  },
  {
    "title": "Application of aboutness to functional benchmarking in information retrieval",
    "doi": "https://doi.org/10.1145/502795.502796",
    "publication_date": "2001-10-01",
    "publication_year": 2001,
    "authors": "Kam‐Fai Wong; Dawei Song; Peter Bruza; Chun Hung Cheng",
    "corresponding_authors": "",
    "abstract": "Experimental approaches are widely employed to benchmark the performance of an information retrieval (IR) system. Measurements in terms of recall and precision are computed as performance indicators. Although they are good at assessing the retrieval effectiveness of an IR system, they fail to explore deeper aspects such as its underlying functionality and explain why the system shows such performance. Recently, inductive (i.e., theoretical) evaluation of IR systems has been proposed to circumvent the controversies of the experimental methods. Several studies have adopted the inductive approach, but they mostly focus on theoretical modeling of IR properties by using some metalogic. In this article, we propose to use inductive evaluation for functional benchmarking of IR models as a complement of the traditional experiment-based performance benchmarking. We define a functional benchmark suite in two stages: the evaluation criteria based on the notion of \"aboutness,\" and the formal evaluation methodology using the criteria. The proposed benchmark has been successfully applied to evaluate various well-known classical and logic-based IR models. The functional benchmarking results allow us to compare and analyze the functionality of the different IR models.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2109212752",
    "type": "article"
  },
  {
    "title": "A general-purpose compression scheme for large collections",
    "doi": "https://doi.org/10.1145/568727.568730",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Adam Cannane; Hugh Williams",
    "corresponding_authors": "",
    "abstract": "Compression of large collections can lead to improvements in retrieval times by offsetting the CPU decompression costs with the cost of seeking and retrieving data from disk. We propose a semistatic phrase-based approach called xray that builds a model offline using sample training data extracted from a collection, and then compresses the entire collection online in a single pass. The particular benefits of xray are that it can be used in applications where individual records or documents must be decompressed, and that decompression is fast. The xray scheme also allows new data to be added to a collection without modifying the semistatic model. Moreover, xray can be used to compress general-purpose data such as genomic, scientific, image, and geographic collections without prior knowledge of the structure of the data. We show that xray is effective on both text and general-purpose collections. In general, xray is more effective than the popular gzip and compress schemes, while being marginally less effective than bzip2. We also show that xray is efficient: of the popular schemes we tested, it is typically only slower than gzip in decompression. Moreover, the query evaluation costs of retrieval of documents from a large collection with our search engine is improved by more than 30% when xray is incorporated compared to an uncompressed approach. We use simple techniques for obtaining the training data from the collection to be compressed and show that with just over 4% of data the entire collection can be effectively compressed. We also propose four schemes for phrase-match selection during the single pass compression of the collection. We conclude that with these novel approaches xray is a fast and effective scheme for compression and decompression of large general-purpose collections.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2028347876",
    "type": "article"
  },
  {
    "title": "Qualitative decision making in adaptive presentation of structured information",
    "doi": "https://doi.org/10.1145/1028099.1028100",
    "publication_date": "2004-10-01",
    "publication_year": 2004,
    "authors": "Ronen I. Brafman; Carmel Domshlak; Solomon Eyal Shimony",
    "corresponding_authors": "",
    "abstract": "We present a new approach for adaptive presentation of structured information, based on preference-based constrained optimization techniques rooted in qualitative decision-theory. In this approach, document presentation is viewed as a configuration problem whose goal is to determine the optimal presentation of a document, while taking into account the preferences of the content provider, viewer interaction with the browser, and, possibly, some layout constraints. The preferences of the content provider are represented by a CP-net, a graphical, qualitative preference model developed in Boutilier et al. [1999]. The layout constraints are represented as geometric constraints, integrated within the optimization process. We discuss the theoretical basis of our approach, as well as implemented prototype systems for Web pages and for general media-rich document presentation.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2042694482",
    "type": "article"
  },
  {
    "title": "Named entity translation matching and learning",
    "doi": "https://doi.org/10.1145/1198296.1198298",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Wai Lam; Shing-Kit Chan; Ruizhang Huang",
    "corresponding_authors": "",
    "abstract": "This article introduces a named entity matching model that makes use of both semantic and phonetic evidence. The matching of semantic and phonetic information is captured by a unified framework via a bipartite graph model. By considering various technical challenges of the problem, including order insensitivity and partial matching, this approach is less rigid than existing approaches and highly robust. One major component is a phonetic matching model which exploits similarity at the phoneme level. Two learning algorithms for learning the similarity information of basic phonemic matching units based on training examples are investigated. By applying the proposed named entity matching model, a mining system is developed for discovering new named entity translations from daily Web news. The system is able to discover new name translations that cannot be found in the existing bilingual dictionary.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2054160115",
    "type": "article"
  },
  {
    "title": "On setting the hyper-parameters of term frequency normalization for information retrieval",
    "doi": "https://doi.org/10.1145/1247715.1247719",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "Ben He; Iadh Ounis",
    "corresponding_authors": "",
    "abstract": "The setting of the term frequency normalization hyper-parameter suffers from the query dependence and collection dependence problems, which remarkably hurt the robustness of the retrieval performance. Our study in this article investigates three term frequency normalization methods, namely normalization 2, BM25's normalization and the Dirichlet Priors normalization. We tackle the query dependence problem by modifying the query term weight using a Divergence From Randomness term weighting model, and tackle the collection dependence problem by measuring the correlation of the normalized term frequency with the document length. Our research hypotheses for the two problems, as well as an automatic hyper-parameter setting methodology, are extensively validated and evaluated on four Text REtrieval Conference (TREC) collections.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2106258822",
    "type": "article"
  },
  {
    "title": "Learning to Align Comments to News Topics",
    "doi": "https://doi.org/10.1145/3072591",
    "publication_date": "2017-07-17",
    "publication_year": 2017,
    "authors": "Lei Hou; Juanzi Li; Xiaoli Li; Jie Tang; Xiaofei Guo",
    "corresponding_authors": "",
    "abstract": "With the rapid proliferation of social media, increasingly more people express their opinions and reviews (user-generated content (UGC)) on recent news articles through various online services, such as news portals, forums, discussion groups, and microblogs. Clearly, identifying hot topics that users greatly care about can improve readers’ news browsing experience and facilitate research into interaction analysis between news and UGC. Furthermore, it is of great benefit to public opinion monitoring and management for both industry and government agencies. However, it is extremely time consuming, if not impossible, to manually examine the large amount of available social content. In this article, we formally define the news comment alignment problem and propose a novel framework that: (1) automatically extracts topics from a given news article and its associated comments, (2) identifies and extends positive examples with different degrees of confidence using three methods (i.e., hypersphere, density, and cluster chain), and (3) completes the alignment between news sentences and comments through a weighted-SVM classifier. Extensive experiments show that our proposed framework significantly outperforms state-of-the-art methods.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2735748713",
    "type": "article"
  },
  {
    "title": "Handling Massive <i>N</i> -Gram Datasets Efficiently",
    "doi": "https://doi.org/10.1145/3302913",
    "publication_date": "2019-02-11",
    "publication_year": 2019,
    "authors": "Giulio Ermanno Pibiri; Rossano Venturini",
    "corresponding_authors": "",
    "abstract": "Two fundamental problems concern the handling of large n -gram language models: indexing , that is, compressing the n -grams and associated satellite values without compromising their retrieval speed, and estimation , that is, computing the probability distribution of the n -grams extracted from a large textual source. Performing these two tasks efficiently is vital for several applications in the fields of Information Retrieval, Natural Language Processing, and Machine Learning, such as auto-completion in search engines and machine translation. Regarding the problem of indexing, we describe compressed, exact, and lossless data structures that simultaneously achieve high space reductions and no time degradation with respect to the state-of-the-art solutions and related software packages. In particular, we present a compressed trie data structure in which each word of an n -gram following a context of fixed length k , that is, its preceding k words, is encoded as an integer whose value is proportional to the number of words that follow such context. Since the number of words following a given context is typically very small in natural languages, we lower the space of representation to compression levels that were never achieved before, allowing the indexing of billions of strings. Despite the significant savings in space, our technique introduces a negligible penalty at query time. Specifically, the most space-efficient competitors in the literature, which are both quantized and lossy, do not take less than our trie data structure and are up to 5 times slower. Conversely, our trie is as fast as the fastest competitor but also retains an advantage of up to 65% in absolute space. Regarding the problem of estimation, we present a novel algorithm for estimating modified Kneser-Ney language models that have emerged as the de-facto choice for language modeling in both academia and industry thanks to their relatively low perplexity performance. Estimating such models from large textual sources poses the challenge of devising algorithms that make a parsimonious use of the disk. The state-of-the-art algorithm uses three sorting steps in external memory: we show an improved construction that requires only one sorting step by exploiting the properties of the extracted n -gram strings. With an extensive experimental analysis performed on billions of n -grams, we show an average improvement of 4.5 times on the total runtime of the previous approach.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2810834465",
    "type": "article"
  },
  {
    "title": "A Multi-View–Based Collective Entity Linking Method",
    "doi": "https://doi.org/10.1145/3300197",
    "publication_date": "2019-02-06",
    "publication_year": 2019,
    "authors": "Ming Liu; Gong Gu; Bing Qin; Ting Liu",
    "corresponding_authors": "",
    "abstract": "Facing lots of name mentions appearing on the web, entity linking is essential for many information processing applications. To improve linking accuracy, the relations between entities are usually considered in the linking process. This kind of method is called collective entity linking and can obtain high-quality results. There are two kinds of information helpful to reveal the relations between entities, i.e., contextual information and structural information of entities. Most traditional collective entity linking methods consider them separately. In fact, these two kinds of information represent entities from specific and diverse views and can enhance each other, respectively. Besides, if we look into each view closely, it can be separated into sub-views that are more meaningful. For this reason, this article proposes a multi-view–based collective entity linking algorithm, which combines several views of entities into an objective function for entity linking. The importance of each view can be valued and the linking results can be obtained along with resolving this objective function. Experimental results demonstrate that our linking algorithm can acquire higher accuracy than many state-of-the-art entity linking methods. Besides, since we simplify the entity's structure and change the entity linking to a sub-matrix searching problem, our algorithm also obtains high efficiency.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2914412196",
    "type": "article"
  },
  {
    "title": "Does Diversity Affect User Satisfaction in Image Search",
    "doi": "https://doi.org/10.1145/3320118",
    "publication_date": "2019-05-08",
    "publication_year": 2019,
    "authors": "Zhijing Wu; Ke Zhou; Yiqun Liu; Min Zhang; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Diversity has been taken into consideration by existing Web image search engines in ranking search results. However, there is no thorough investigation of how diversity affects user satisfaction in image search. In this article, we address the following questions: (1) How do different factors, such as content and visual presentations, affect users’ perception of diversity? (2) How does search result diversity affect user satisfaction with different search intents? To answer those questions, we conduct a set of laboratory user studies to collect users’ perceived diversity annotations and search satisfaction. We find that the existence of nearly duplicated image results has the largest impact on users’ perceived diversity, followed by the similarity in content and visual presentations. Besides these findings, we also investigate the relationship between diversity and satisfaction in image search. Specifically, we find that users’ preference for diversity varies across different search intents. When users want to collect information or save images for further usage (the Locate search tasks), more diversified result lists lead to higher satisfaction levels. The insights may help commercial image search engines to design better result ranking strategies and evaluation metrics.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2944762291",
    "type": "article"
  },
  {
    "title": "Question Answering in Knowledge Bases",
    "doi": "https://doi.org/10.1145/3345557",
    "publication_date": "2019-09-20",
    "publication_year": 2019,
    "authors": "Richong Zhang; Yue Wang; Yongyi Mao; Jinpeng Huai",
    "corresponding_authors": "",
    "abstract": "Question answering over knowledge bases aims to take full advantage of the information in knowledge bases with the ultimate purpose of returning answers to questions. To access the substantial knowledge within the KB, many model architectures are hindered by the bottleneck of accurately predicting relations that connect subject entities in questions to object entities in the knowledge base. To break the bottleneck, this article presents a novel model architecture, APVA, which includes a verification mechanism to check the correctness of predicted relations. Specifically, APVA takes advantage of KB-based information to improve relation prediction but verifies the correctness of the predicted relation by means of simple negative sampling in a logistic regression framework. The APVA architecture offers a natural way to integrate an iterative training procedure, which we call turbo training. Accordingly, we introduce APVA-TURBO to perform question answering over knowledge bases. We demonstrate extensive experiments to show that APVA-TURBO outperforms existing approaches on question answering.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2973947483",
    "type": "article"
  },
  {
    "title": "Constructing Click Model for Mobile Search with Viewport Time",
    "doi": "https://doi.org/10.1145/3360486",
    "publication_date": "2019-09-26",
    "publication_year": 2019,
    "authors": "Yukun Zheng; Jiaxin Mao; Yiqun Liu; Cheng Luo; Min Zhang; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "A series of click models has been proposed to extract accurate and unbiased relevance feedback from valuable yet noisy click-through data in search logs. Previous works have shown that users search behavior in mobile and desktop scenarios are rather different in many aspects, therefore, the click models designed for desktop search may not be effective in the mobile context. To address this problem, we propose two novel click models for mobile search: (1) Mobile Click Model (MCM), which models click necessity bias and examination satisfaction bias; (2) Viewport Time Click Model (VTCM), which further extends MCM by utilizing the viewport time. Extensive experiments on large-scale real mobile search logs show that: (1) MCM and VTCM outperform existing models in predicting users’ clicks and estimating result relevance; (2) MCM and VTCM can extract richer information, such as the click necessity of search results and the probability of user satisfaction, from mobile click logs; (3) By modeling the viewport time distributions of heterogeneous results, VTCM can bring a significant improvement over MCM in click prediction and relevance estimation tasks. Our proposed click models can help better understand user behavior patterns in mobile search and improve the ranking performance of mobile search engines.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2976307459",
    "type": "article"
  },
  {
    "title": "Explaining Text Matching on Neural Natural Language Inference",
    "doi": "https://doi.org/10.1145/3418052",
    "publication_date": "2020-09-16",
    "publication_year": 2020,
    "authors": "Youngwoo Kim; Myungha Jang; James Allan",
    "corresponding_authors": "",
    "abstract": "Natural language inference (NLI) is the task of detecting the existence of entailment or contradiction in a given sentence pair. Although NLI techniques could help numerous information retrieval tasks, most solutions for NLI are neural approaches whose lack of interpretability prohibits both straightforward integration and diagnosis for further improvement. We target the task of generating token-level explanations for NLI from a neural model. Many existing approaches for token-level explanation are either computationally costly or require additional annotations for training. In this article, we first introduce a novel method for training an explanation generator that does not require additional human labels. Instead, the explanation generator is trained with the objective of predicting how the model’s classification output will change when parts of the inputs are modified. Second, we propose to build an explanation generator in a multi-task learning setting along with the original NLI task so the explanation generator can utilize the model’s internal behavior. The experiment results suggest that the proposed explanation generator outperforms numerous strong baselines. In addition, our method does not require excessive additional computation at prediction time, which renders it an order of magnitude faster than the best-performing baseline.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3090640022",
    "type": "article"
  },
  {
    "title": "OutdoorSent",
    "doi": "https://doi.org/10.1145/3385186",
    "publication_date": "2020-04-21",
    "publication_year": 2020,
    "authors": "Wyverson Bonasoli de Oliveira; Leyza Baldo Dorini; Rodrigo Minetto; Thiago H. Silva",
    "corresponding_authors": "",
    "abstract": "Opinion mining in outdoor images posted by users during different activities can provide valuable information to better understand urban areas. In this regard, we propose a framework to classify the sentiment of outdoor images shared by users on social networks. We compare the performance of state-of-the-art ConvNet architectures and one specifically designed for sentiment analysis. We also evaluate how the merging of deep features and semantic information derived from the scene attributes can improve classification and cross-dataset generalization performance. The evaluation explores a novel dataset—namely, OutdoorSent—and other publicly available datasets. We observe that the incorporation of knowledge about semantic attributes improves the accuracy of all ConvNet architectures studied. Besides, we found that exploring only images related to the context of the study—outdoor, in our case—is recommended, i.e., indoor images were not significantly helpful. Furthermore, we demonstrated the applicability of our results in the United States city of Chicago, Illinois, showing that they can help to improve the knowledge of subjective characteristics of different areas of the city. For instance, particular areas of the city tend to concentrate more images of a specific class of sentiment, which are also correlated with median income, opening up opportunities in different fields.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W4288080293",
    "type": "article"
  },
  {
    "title": "The Effect of Social and Physical Detachment on Information Need",
    "doi": "https://doi.org/10.1145/2414782.2414786",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "Elad Yom‐Tov; Fernando Díaz",
    "corresponding_authors": "",
    "abstract": "The information need of users and the documents which answer this need are frequently contingent on the different characteristics of users. This is especially evident during natural disasters, such as earthquakes and violent weather incidents, which create a strong transient information need. In this article, we investigate how the information need of users, as expressed by their queries, is affected by their physical detachment, as estimated by their physical location in relation to that of the event, and by their social detachment, as quantified by the number of their acquaintances who may be affected by the event. Drawing on large-scale data from ten major events, we show that social and physical detachment levels of users are a major influence on their search engine queries. We demonstrate how knowing social and physical detachment levels can assist in improving retrieval for two applications: identifying search queries related to events and ranking results in response to event-related queries. We find that the average precision in identifying relevant search queries improves by approximately 18%, and that the average precision of ranking that uses detachment information improves by 10%. Using both types of detachment achieved a larger gain in performance than each of them separately.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2043353275",
    "type": "article"
  },
  {
    "title": "Browse-to-Search",
    "doi": "https://doi.org/10.1145/2630420",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Shiyang Lu; Tao Mei; Jingdong Wang; Jian Zhang; Zhiyong Wang; Shipeng Li",
    "corresponding_authors": "",
    "abstract": "With the development of image search technology, users are no longer satisfied with searching for images using just metadata and textual descriptions. Instead, more search demands are focused on retrieving images based on similarities in their contents (textures, colors, shapes etc.). Nevertheless, one image may deliver rich or complex content and multiple interests. Sometimes users do not sufficiently define or describe their seeking demands for images even when general search interests appear, owing to a lack of specific knowledge to express their intents. A new form of information seeking activity, referred to as exploratory search, is emerging in the research community, which generally combines browsing and searching content together to help users gain additional knowledge and form accurate queries, thereby assisting the users with their seeking and investigation activities. However, there have been few attempts at addressing integrated exploratory search solutions when image browsing is incorporated into the exploring loop. In this work, we investigate the challenges of understanding users' search interests from the images being browsed and infer their actual search intentions. We develop a novel system to explore an effective and efficient way for allowing users to seamlessly switch between browse and search processes, and naturally complete visual-based exploratory search tasks. The system, called Browse-to-Search enables users to specify their visual search interests by circling any visual objects in the webpages being browsed, and then the system automatically forms the visual entities to represent users' underlying intent. One visual entity is not limited by the original image content, but also encapsulated by the textual-based browsing context and the associated heterogeneous attributes. We use large-scale image search technology to find the associated textual attributes from the repository. Users can then utilize the encapsulated visual entities to complete search tasks. The Browse-to-Search system is one of the first attempts to integrate browse and search activities for a visual-based exploratory search, which is characterized by four unique properties: (1) in session—searching is performed during browsing session and search results naturally accompany with browsing content; (2) in context—the pages being browsed provide text-based contextual cues for searching; (3) in focus—users can focus on the visual content of interest without worrying about the difficulties of query formulation, and visual entities will be automatically formed; and (4) intuitiveness—a touch and visual search-based user interface provides a natural user experience. We deploy the Browse-to-Search system on tablet devices and evaluate the system performance using millions of images. We demonstrate that it is effective and efficient in facilitating the user's exploratory search compared to the conventional image search methods and, more importantly, provides users with more robust results to satisfy their exploring experience.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2083297468",
    "type": "article"
  },
  {
    "title": "Deep Dependency Substructure-Based Learning for Multidocument Summarization",
    "doi": "https://doi.org/10.1145/2766447",
    "publication_date": "2015-07-14",
    "publication_year": 2015,
    "authors": "Yan Su; Xiaojun Wan",
    "corresponding_authors": "",
    "abstract": "Most extractive style topic-focused multidocument summarization systems generate a summary by ranking textual units in multiple documents and extracting a proper subset of sentences biased to the given topic. Usually, the textual units are simply represented as sentences or n-grams, which do not carry deep syntactic and semantic information. This article presents a novel extractive topic-focused multidocument summarization framework. The framework proposes a new kind of more meaningful and informative units named frequent Deep Dependency Sub-Structure (DDSS) and a topic-sensitive Multi-Task Learning (MTL) model for frequent DDSS ranking. Given a document set, first, we parse all the sentences into deep dependency structures with a Head-driven Phrase Structure Grammar (HPSG) parser and mine the frequent DDSSs after semantic normalization. Then we employ a topic-sensitive MTL model to learn the importance of these frequent DDSSs. Finally, we exploit an Integer Linear Programming (ILP) formulation and use the frequent DDSSs as the essentials for summary extraction. Experimental results on two DUC datasets demonstrate that our proposed approach can achieve state-of-the-art performance. Both the DDSS information and the topic-sensitive MTL model are validated to be very helpful for topic-focused multidocument summarization.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2115530263",
    "type": "article"
  },
  {
    "title": "End-to-End Neural Matching for Semantic Location Prediction of Tweets",
    "doi": "https://doi.org/10.1145/3415149",
    "publication_date": "2020-09-05",
    "publication_year": 2020,
    "authors": "Paul Mousset; Yoann Pitarch; Lynda Tamine",
    "corresponding_authors": "",
    "abstract": "The impressive increasing availability of social media posts has given rise to considerable research challenges. This article is concerned with the problem of semantic location prediction of geotagged tweets. The underlying task is to associate to a social media post, the focal spatial object, if any (e.g., Place Of Interest POI), it topically focuses on. Although relevant for a number of applications such as POI recommendation, this problem has not so far received the attention it deserves. In previous work, the problem has mainly been tackled by means of language models that rely on costly probability estimation of word relevance across spatial regions. We propose the Spatially-aware Geotext Matching (SGM) model, which relies on a neural network learning framework. The model combines exact word-word-local interaction matching signals with semantic global tweet-POI interaction matching signals. The local interactions are built over kernel spatial word distributions that allow revealing spatially driven word pair similarity patterns. The global interactions consider the strength of the interaction between the tweet and the POI from both the spatial and semantic perspectives. Experimental results on two real-world datasets demonstrate the effectiveness of our proposed SGM model compared to state-of-the-art baselines including language models and traditional neural interaction-based models.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3083054174",
    "type": "article"
  },
  {
    "title": "Browse-to-Search:視覚エンティティによる対話型探索的検索",
    "doi": null,
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Shiyang Lu; Tao Mei; Wang Jingdong; Jian Zhang; Zhiyong Wang; LI Shi-peng",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3109366935",
    "type": "article"
  },
  {
    "title": "A Hybrid Framework for Session Context Modeling",
    "doi": "https://doi.org/10.1145/3448127",
    "publication_date": "2021-05-05",
    "publication_year": 2021,
    "authors": "Jia Chen; Jiaxin Mao; Yiqun Liu; Ziyi Ye; Weizhi Ma; Chao Wang; Min Zhang; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Understanding user intent is essential for various retrieval tasks. By leveraging contextual information within sessions, e.g., query history and user click behaviors, search systems can capture user intent more accurately and thus perform better. However, most existing systems only consider intra-session contexts and may suffer from the problem of lacking contextual information, because short search sessions account for a large proportion in practical scenarios. We believe that in these scenarios, considering more contexts, e.g., cross-session dependencies, may help alleviate the problem and contribute to better performance. Therefore, we propose a novel Hybrid framework for Session Context Modeling (HSCM), which realizes session-level multi-task learning based on the self-attention mechanism. To alleviate the problem of lacking contextual information within current sessions, HSCM exploits the cross-session contexts by sampling user interactions under similar search intents in the historical sessions and further aggregating them into the local contexts. Besides, application of the self-attention mechanism rather than RNN-based frameworks in modeling session-level sequences also helps (1) better capture interactions within sessions, (2) represent the session contexts in parallelization. Experimental results on two practical search datasets show that HSCM not only outperforms strong baseline solutions such as HiNT, CARS, and BERTserini in document ranking, but also performs significantly better than most existing query suggestion methods. According to the results in an additional experiment, we have also found that HSCM is superior to most ranking models in click prediction.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3159809086",
    "type": "article"
  },
  {
    "title": "Meta-Information in Conversational Search",
    "doi": "https://doi.org/10.1145/3468868",
    "publication_date": "2021-08-16",
    "publication_year": 2021,
    "authors": "Johannes Kiesel; Lars Meyer; Martin Potthast; Benno Stein",
    "corresponding_authors": "",
    "abstract": "The exchange of meta-information has always formed part of information behavior. In this article, we show that this rule also extends to conversational search. Information about the user’s information need, their preferences, and the quality of search results are only some of the most salient examples of meta-information that are exchanged as a matter of course in a search conversation. To understand the importance of meta-information for conversational search, we revisit its definition and survey how meta-information has been taken into account in the past in information retrieval. Meta-information has gone by many names, about which a concise overview is provided. An in-depth analysis of the role of meta-information in search and conversation theories reveals that they provide significant support for the importance of meta-information in conversational search. We further identify conversational search datasets are suitable for a deeper inspection with regard to meta-information, namely, Spoken Conversational Search and Microsoft Information-Seeking Conversations. A quantitative data analysis demonstrates the practical significance of meta-information in information-seeking conversations, whereas a qualitative analysis shows the effects of exchanging different types. Finally, we discuss practical applications and challenges of meta-information in conversational search, including a case study of VERSE, an existing search system for the visually impaired.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3195417707",
    "type": "article"
  },
  {
    "title": "BotSpot++: A Hierarchical Deep Ensemble Model for Bots Install Fraud Detection in Mobile Advertising",
    "doi": "https://doi.org/10.1145/3476107",
    "publication_date": "2021-11-17",
    "publication_year": 2021,
    "authors": "Yadong Zhu; Xiliang Wang; Qing Li; Tianjun Yao; Shangsong Liang",
    "corresponding_authors": "",
    "abstract": "Mobile advertising has undoubtedly become one of the fastest-growing industries in the world. The influx of capital attracts increasing fraudsters to defraud money from advertisers. Fraudsters can leverage many techniques, where bots install fraud is the most difficult to detect due to its ability to emulate normal users by implementing sophisticated behavioral patterns to evade from detection rules defined by human experts. Therefore, we proposed BotSpot 1 for bots install fraud detection previously. However, there are some drawbacks in BotSpot, such as the sparsity of the devices’ neighbors, weak interactive information of leaf nodes, and noisy labels. In this work, we propose BotSpot++ to improve these drawbacks: (1) for the sparsity of the devices’ neighbors, we propose to construct a super device node to enrich the graph structure and information flow utilizing domain knowledge and a clustering algorithm; (2) for the weak interactive information, we propose to incorporate a self-attention mechanism to enhance the interaction of various leaf nodes; and (3) for the noisy labels, we apply a label smoothing mechanism to alleviate it. Comprehensive experimental results show that BotSpot++ yields the best performance compared with six state-of-the-art baselines. Furthermore, we deploy our model to the advertising platform of Mobvista, 2 a leading global mobile advertising company. The online experiments also demonstrate the effectiveness of our proposed method.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3211476206",
    "type": "article"
  },
  {
    "title": "MiDTD: A Simple and Effective Distillation Framework for Distantly Supervised Relation Extraction",
    "doi": "https://doi.org/10.1145/3503917",
    "publication_date": "2022-01-11",
    "publication_year": 2022,
    "authors": "Rui Li; Cheng Yang; Tingwei Li; Sen Su",
    "corresponding_authors": "",
    "abstract": "Relation extraction (RE), an important information extraction task, faced the great challenge brought by limited annotation data. To this end, distant supervision was proposed to automatically label RE data, and thus largely increased the number of annotated instances. Unfortunately, lots of noise relation annotations brought by automatic labeling become a new obstacle. Some recent studies have shown that the teacher-student framework of knowledge distillation can alleviate the interference of noise relation annotations via label softening. Nevertheless, we find that they still suffer from two problems: propagation of inaccurate dark knowledge and constraint of a unified distillation temperature . In this article, we propose a simple and effective Multi-instance Dynamic Temperature Distillation (MiDTD) framework, which is model-agnostic and mainly involves two modules: multi-instance target fusion (MiTF) and dynamic temperature regulation (DTR). MiTF combines the teacher’s predictions for multiple sentences with the same entity pair to amend the inaccurate dark knowledge in each student’s target. DTR allocates alterable distillation temperatures to different training instances to enable the softness of most student’s targets to be regulated to a moderate range. In experiments, we construct three concrete MiDTD instantiations with BERT, PCNN, and BiLSTM-based RE models, and the distilled students significantly outperform their teachers and the state-of-the-art (SOTA) methods.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4205312114",
    "type": "article"
  },
  {
    "title": "Enhancing Multi-View Smoothness for Sequential Recommendation Models",
    "doi": "https://doi.org/10.1145/3582495",
    "publication_date": "2023-01-31",
    "publication_year": 2023,
    "authors": "Kun Zhou; Hui Wang; Ji-Rong Wen; Wayne Xin Zhao",
    "corresponding_authors": "",
    "abstract": "Sequential recommendation models aim to predict the interested items to a user based on his historical behaviors. To train sequential recommenders, implicit feedback data is widely adopted since it is easier to obtain than explicit feedback data. In the setting of implicit feedback, a user’s historical behaviors can be characterized as a chronologically ordered sequence of interacted items. From a perspective of machine learning, the historical interaction sequence and the recommended items can be considered as context and label , respectively, which are usually in one-hot representations in the recommendation models. However, due to the discrete nature, one-hot representations are hard to sufficiently reflect the underlying user preference, and might also contain noise from implicit feedback that will mislead the model training. To solve these issues, we propose a general optimization framework, Multi-View Smoothness (MVS), to enhance the smoothness of sequential recommendation models in both data representations and model learning. Specifically, with the help of a complementary model, we smooth and enrich the one-hot representations of contexts and labels to better depict the underlying user preference (i.e., context smoothness and label smoothness), and devise a model regularization strategy to enforce the neighborhood smoothness of the model itself (i.e., model smoothness). Based on these strategies, we design three regularizers to constrain and improve the training of sequential recommendation models. Extensive experiments on five datasets show that our approach is able to improve the performance of various base models consistently and outperform other regularization training methods.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4318617464",
    "type": "article"
  },
  {
    "title": "A Systematic Review of Cost, Effort, and Load Research in Information Search and Retrieval, 1972–2020",
    "doi": "https://doi.org/10.1145/3583069",
    "publication_date": "2023-02-09",
    "publication_year": 2023,
    "authors": "Molly McGregor; Leif Azzopardi; Martin Halvey",
    "corresponding_authors": "",
    "abstract": "During the information search and retrieval (ISR) process, user-system interactions such as submitting queries, examining results, and engaging with information impose some degree of demand on the user’s resources. Within ISR, these demands are well recognised, and numerous studies have demonstrated that the cost, effort, and load (CEL) experienced during the search process are affected by a variety of factors. Despite this recognition, there is no universally accepted definition of the constructs of CEL within the field of ISR. Ultimately, this has led to problems with how these constructs have been interpreted and subsequently measured. This systematic review contributes a synthesis of literature, summarising key findings relating to how researchers have been defining and measuring CEL within ISR over the past 50 years. After manually screening 1,109 articles, we detailed and analysed 91 articles which examine CEL within ISR. The discussion focuses on comparing the similarities and differences between CEL definitions and measures before identifying the limitations of the current state of the nomenclature. Opportunities for future research are also identified. Going forward, we propose a CEL taxonomy that integrates the relationships between CEL and their related constructs, which will help focus and disambiguate future research in this important area.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4319736113",
    "type": "review"
  },
  {
    "title": "A Dual-branch Learning Model with Gradient-balanced Loss for Long-tailed Multi-label Text Classification",
    "doi": "https://doi.org/10.1145/3597416",
    "publication_date": "2023-08-04",
    "publication_year": 2023,
    "authors": "Yitong Yao; Jing Zhang; Peng Zhang; Yueheng Sun",
    "corresponding_authors": "",
    "abstract": "Multi-label text classification has a wide range of applications in the real world. However, the data distribution in the real world is often imbalanced, which leads to serious long-tailed problems. For multi-label classification, due to the vast scale of datasets and existence of label co-occurrence, how to effectively improve the prediction accuracy of tail labels without degrading the overall precision becomes an important challenge. To address this issue, we propose A Dual-Branch Learning Model with Gradient-Balanced Loss (DBGB) based on the paradigm of existing pre-trained multi-label classification SOTA models. Our model consists of two main long-tailed module improvements. First, with the shared text representation, the dual-classifier is leveraged to process two kinds of label distributions; one is the original data distribution and the other is the under-sampling distribution for head labels to strengthen the prediction for tail labels. Second, the proposed gradient-balanced loss can adaptively suppress the negative gradient accumulation problem related to labels, especially tail labels. We perform extensive experiments on three multi-label text classification datasets. The results show that the proposed method achieves competitive performance on overall prediction results compared to the state-of-the-art methods in solving the multi-label classification, with significant improvement on tail-label accuracy.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4385580697",
    "type": "article"
  },
  {
    "title": "Heterogeneous Evolution Network Embedding with Temporal Extension for Intelligent Tutoring Systems",
    "doi": "https://doi.org/10.1145/3617828",
    "publication_date": "2023-08-29",
    "publication_year": 2023,
    "authors": "Sannyuya Liu; Shengyingjie Liu; Zongkai Yang; Jianwen Sun; Xiaoxuan Shen; Qing Li; Rui Zou; Shangheng Du",
    "corresponding_authors": "",
    "abstract": "Graph embedding (GE) aims to acquire low-dimensional node representations while maintaining the graph’s structural and semantic attributes. Intelligent tutoring systems (ITS) signify a noteworthy achievement in the fusion of AI and education. Utilizing GE to model ITS can elevate their performance in predictive and annotation tasks. Current GE techniques, whether applied to heterogeneous or dynamic graphs, struggle to efficiently model ITS data. The GEs within ITS should retain their semidynamic, independent, and smooth characteristics. This article introduces a heterogeneous evolution network (HEN) for illustrating entities and relations within an ITS. Additionally, we introduce a temporal extension graph neural network (TEGNN) to model both evolving and static nodes within the HEN. In the TEGNN framework, dynamic nodes are initially improved over time through temporal extension (TE), providing an accurate depiction of each learner’s implicit state at each time step. Subsequently, we propose a stochastic temporal pooling (STP) strategy to estimate the embedding sets of all evolving nodes. This effectively enhances model efficiency and usability. Following this, a heterogeneous aggregation network is devised to proficiently extract heterogeneous features from the HEN. This network employs both node-level and relation-level attention mechanisms to craft aggregated node features. To emphasize the superiority of TEGNN, we perform experiments on several real ITS datasets and show that our method significantly outperforms the state-of-the-art approaches. The experiments validate that TE serves as an efficient framework for modeling temporal information in GE, and STP not only accelerates the training process but also enhances the resultant accuracy.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386254497",
    "type": "article"
  },
  {
    "title": "Semantic Collaborative Learning for Cross-Modal Moment Localization",
    "doi": "https://doi.org/10.1145/3620669",
    "publication_date": "2023-09-07",
    "publication_year": 2023,
    "authors": "Yupeng Hu; Kun Wang; Meng Liu; Haoyu Tang; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "Localizing a desired moment within an untrimmed video via a given natural language query, i.e., cross-modal moment localization, has attracted widespread research attention recently. However, it is a challenging task because it requires not only accurately understanding intra-modal semantic information, but also explicitly capturing inter-modal semantic correlations (consistency and complementarity). Existing efforts mainly focus on intra-modal semantic understanding and inter-modal semantic alignment, while ignoring necessary semantic supplement. Consequently, we present a cross-modal semantic perception network for more effective intra-modal semantic understanding and inter-modal semantic collaboration. Concretely, we design a dual-path representation network for intra-modal semantic modeling. Meanwhile, we develop a semantic collaborative network to achieve multi-granularity semantic alignment and hierarchical semantic supplement. Thereby, effective moment localization can be achieved based on sufficient semantic collaborative learning. Extensive comparison experiments demonstrate the promising performance of our model compared with existing state-of-the-art competitors.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4386527955",
    "type": "article"
  },
  {
    "title": "CAFE+: Towards Compact, Adaptive, and Fast Embedding for Large-scale Online Recommendation Models",
    "doi": "https://doi.org/10.1145/3713072",
    "publication_date": "2025-01-21",
    "publication_year": 2025,
    "authors": "Zirui Liu; Hailin Zhang; Boxuan Chen; Zihan Jiang; Yikai Zhao; Yangyu Tao; Tong Yang; Bin Cui",
    "corresponding_authors": "",
    "abstract": "The growing memory demands of embedding tables in Deep Learning Recommendation Models (DLRMs) pose great challenges for model training and deployment. Existing embedding compression solutions cannot simultaneously achieve memory efficiency, low latency, and adaptability to dynamic data distribution. This paper presents CAFE+, a Compact, Adaptive, and Fast Embedding compression framework that meets the above requirements. The design philosophy of CAFE+ is to dynamically allocate more memory to important features, and less to unimportant ones. We assign unique embedding to important feature and allow multiple unimportant features sharing one embedding. We propose a fast and lightweight feature monitor, to real-time capture feature importance and report important features. We theoretically analyze the accuracy of our feature monitor, and prove the superiority of CAFE+ from the aspect of model convergence. Extensive experiments show CAFE+ outperforms existing embedding compression methods, yielding \\(3.94\\%\\) and \\(3.94\\%\\) superior testing AUC on Criteo Kaggle dataset and CriteoTB dataset at a compression ratio of \\(10000\\times\\) . Building on our conference version [114], this journal version introduces several novel designs (Implicit Importance Attenuation, Adaptive Threshold Adjustment, and ColdSifter) that enable CAFE+ to more effectively adapt to long-term online learning and achieve better model quality. All codes are available at GitHub [112].",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406679564",
    "type": "article"
  },
  {
    "title": "Ownership Verification for Federated Recommendation",
    "doi": "https://doi.org/10.1145/3715320",
    "publication_date": "2025-01-27",
    "publication_year": 2025,
    "authors": "Enyue Yang; Weike Pan; Lixin Fan; Hanlin Gu; Zhitao Li; Qiang Yang; Zhong Ming",
    "corresponding_authors": "",
    "abstract": "Most federated learning-based recommender systems allow clients to access a well-trained high-quality model locally, which provides adversaries with the opportunity to infringe the legitimate copyright of the model. In response, we study an emerging and important problem, i.e., copyright protection of a federated recommendation model, which has not yet been addressed in the community of federated learning or recommender systems. We propose the first backdoor-based ownership verification scheme for federated recommendation called OVFR, which enables the server to claim its ownership for a given suspicious recommendation model. Firstly, we propose to generate a trigger set tailored to recommendation scenarios. In particular, we generate some fake users and items, and then construct a set of fake users with fake interaction records as a trigger set. Moreover, we ensure that the distribution of the popularity of the fake items follows a long-tailed distribution for the effectiveness of the incorporated watermarking. To provide robustness assurance, we propose two different hybrid strategies to make the embeddings of the fake items similar to those of the real items. Secondly, we focus on effectively learning from a trigger set for recommendation scenarios. In particular, we design a mean square error (MSE) loss function and a contrastive loss function for incorporating the backdoor-based watermarking into the item embeddings, since the item embeddings are often more valuable and easier to be accessed than other parameters of a federated recommendation model. We then design a contrastive loss function to reduce the risk of the fake items being detected. Extensive experiments on three public datasets show the effectiveness of our OVFR in terms of ownership verification, model performance, and robustness.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406845995",
    "type": "article"
  },
  {
    "title": "MKCRec: Meta-relation guided Knowledge Coupling for Paper Recommendation",
    "doi": "https://doi.org/10.1145/3715101",
    "publication_date": "2025-02-11",
    "publication_year": 2025,
    "authors": "Chengde Zhang; Zihan Zhang; Jiaying Huang; Yan Liu; Dawei Jin; Xia Xiao; Zuwu Shen",
    "corresponding_authors": "",
    "abstract": "With the surge of academic papers, it has become a common practice to recommend papers based on authors’ research interests. Existing methods focus on leveraging author-paper research interactions to mine authors’ research interests with coauthorship networks. However, sparse research interactions would pose a huge challenge to distinguish research interests of authors. Fortunately, inter-dependent knowledge across papers provides rich potential heterogeneous connections for author-paper interactions, offering much insights for learning authors’ research interests. Therefore, we propose a meta-relation guided knowledge coupling approach for paper recommendation. Specifically, we construct a meta-relation-guided heterogeneous graph architecture to depict the numerous inter-dependencies among authors and papers, thereby exploring complex author-paper interactions. First, a meta-relation-aware heterogeneous graph encoder is developed to extract relational structure which maintains the relation-specific representation of authors’ research interest and papers’ research relatedness. Then, a cross-meta-path attention network is designed to aggregate the characteristics of different meta-relations and obtain research features of authors and papers. Finally, a self-supervised data augmentation architecture is constructed to mine and preserve local and global graph structure information, acquiring papers with high relevance to author’s research interests through training loss. Numerous experiments are conducted on two real academic datasets, effectively demonstrating the superiority of our proposed model and validating its effectiveness in paper recommendation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4407371612",
    "type": "article"
  },
  {
    "title": "HORAE: Temporal Multi-Interest Pre-training for Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3727645",
    "publication_date": "2025-04-01",
    "publication_year": 2025,
    "authors": "Shirui Hu; Weichang Wu; Zuoli Tang; Zhaoxin Huan; Lin Wang; Xiaolu Zhang; Jun Zhou; Lixin Zou; Chenliang Li",
    "corresponding_authors": "",
    "abstract": "The data sparsity problem has been a long-standing obstacle towards achieving better recommendation performance since it is miserable to estimate the user’s interests from limited historical behaviors. The pre-training paradigm, i.e., learning universal knowledge across a wide spectrum of domains, has increasingly become a new de-facto practice in many fields, especially for adaption to new domains. The merit of this superior generalizability renders it a natural choice to tackle the data sparsity problem for various recommendation scenarios. Hence, several efforts mainly follow masked language modeling or simple data augmentation via contrastive learning to build a pre-trained recommendation model. Our recent work (namely Miracle ) suggests that the common treatment utilizing the masked language modeling is not sufficient for pre-training a recommender system, since a user’s intent could be more complex than predicting the next word or item. The encouraging results demonstrate that the multi-interest modeling could significantly push the frontier of recommender system pre-training. Nevertheless, how to accommodate the temporal dynamics of the user interests seems to be underexplored under both single vector representation and multi-interest schemes. In this paper, we aim to incorporate sophisticated temporal information modeling with the current advance in this line. More specifically, we extend Miracle by further considering relative position information and two kinds of relative time interval information jointly when performing multi-interest learning. Then, a sequential process for interest refinement is proposed to learn the subtle nuances of how interests change and shift along the timeline, leading to a more precise representation of user interests. Our extensive experiments on multiple real-world datasets validate the effectiveness of the proposed solution, demonstrating a significant improvement over current state-of-the-art models on these benchmarks. The code is available at https://github.com/WHUIR/Horae .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409045761",
    "type": "article"
  },
  {
    "title": "Personality dialogue agent based on personality description and conversation history",
    "doi": "https://doi.org/10.1145/3731679",
    "publication_date": "2025-04-24",
    "publication_year": 2025,
    "authors": "Yuxing Chu; Mingxu Sun; Ke Huang; Haokun Geng; Yanyu Zhang; Lili Zhang; Menghua Zhang",
    "corresponding_authors": "",
    "abstract": "In the study of dialogue system, personalized dialogue mainly focuses on the semantic matching degree between response and role. However, various factors, such as semantic style, dialogue noise, and sparse personality information, can affect the performance of the model. For this purpose, we construct a novel personalized dialogue model. Based on the personality description information and conversation history, it uses the information enhancement algorithm to cluster the personality description text into a number of fine sparse categories, and uses the feature classifier to precisely select the features highly relevant to the current dialogue situation according to the input query content. At the same time, the history information selector will fine-filter the conversation history, retaining the parts that are valuable for generating replies. We combine the processed personality description text with the filtered historical context information, and send it to the decoder through the feature cue learning strategy for deep processing to generate personalized responses. Our model integrates the proposed algorithms, classifiers, selectors and feature cue learning strategies to build a complete dialogue system. Experiments on two datasets show that our model is superior to other models in terms of consistency and coherence.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409735488",
    "type": "article"
  },
  {
    "title": "Including Co-Relation via Concatenate Operator for Static and Temporal Knowledge Graph Embedding",
    "doi": "https://doi.org/10.1145/3733231",
    "publication_date": "2025-04-29",
    "publication_year": 2025,
    "authors": "Likang Xiao; Richong Zhang; Junfan Chen; Lei Zhang",
    "corresponding_authors": "",
    "abstract": "Knowledge Graph Completion (KGC) aims to complete KGs by predicting missing entities. A common solution for KGC is Knowledge Graph Embedding (KGE), which assumes that semantical similar entities or relationships should possess similar representations in high-dimensional space. In KGE, a heuristic score function of the head entity and its relation with different operators is required. A typical technique is regularization for tensor factorization, such as the Nuclear-p norm and the Frobenius norm of the query/entity embedding, which significantly improve the KGE model performance on the KGC task. However, the Co-Relation s, including the association between tail entities ( Co-Query Relation ) and the association between queries ( Co-Entity Relation ), desirable for KGC are not fully considered in existing embedding regularization techniques. In this article, we theoretically interpret the role of Co-Relation in KGE and propose a novel ConR regularization approach to learn embedding that takes Co-Relations into account. Extensive experiments show that our model improves static and temporal KGC tasks over decomposition-based models, ComplEx and TuckER. Further analysis of the score cumulative distribution function and embedding visualization demonstrates the effectiveness of ConR .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409918358",
    "type": "article"
  },
  {
    "title": "Preference Logical Reasoning with Preference Operators for Explainable Recommendations",
    "doi": "https://doi.org/10.1145/3733596",
    "publication_date": "2025-05-01",
    "publication_year": 2025,
    "authors": "Fei Li; Enneng Yang; Guibing Guo; Linying Jiang; Jianzhe Zhao; Xingwei Wang",
    "corresponding_authors": "",
    "abstract": "Preference logical reasoning utilizes user-item interactions (e.g., ratings and reviews) to infer user preferences and discover user decision paths from the knowledge graph to enhance the explainability of item recommendations. However, existing algorithms assume that the ratings and reviews of any item are always consistent, ignoring situations where items with high ratings have negative reviews or items with low ratings but positive reviews. This leads to inaccurate learning of user preferences. In fact, through experimental analysis of two real datasets, we found that on average, about 10% of the interactive data exhibited this inconsistency, that is, items with high ratings but negative reviews appear in the recommendation list. To address this issue, we propose a general preference logical reasoning method based on preference operators. Specifically, we capture the semantic information of users towards the item (its corresponding attributes) in reviews and define two preference operators ( like and dislike ) for the item to correct ambiguous neutral ratings or false ratings that do not reflect true preferences. In the process of preference path reasoning, the like preference operator increases the occurrence probability of liked items, while the dislike preference operator reduces the occurrence probability of disliked items. By fusing the preference operators in the preference path, we obtain consistent user preferences and enhance the explainability of item recommendations. The experimental results on four real datasets demonstrate that our method can effectively improve the performance of all comparison baselines in terms of recommendation accuracy and user decision explainability.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410044258",
    "type": "article"
  },
  {
    "title": "Debiased Cognition Representation Learning for Knowledge Tracing",
    "doi": "https://doi.org/10.1145/3736576",
    "publication_date": "2025-05-23",
    "publication_year": 2025,
    "authors": "Xiangwei Lv; Guifeng Wang; Jingyuan Chen; Hejian Su; Zhiang Dong; Yumeng Zhu; Beishui Liao; Fei Wu",
    "corresponding_authors": "",
    "abstract": "Knowledge tracing (KT) is a fundamental task in intelligent education aimed at tracking students’ knowledge status and predicting their performance on new questions. The primary challenge in KT is accurately inferring a high-quality representation of students’ knowledge state that effectively captures their understanding of questions. However, existing methods are typically developed under the assumption that students’ behaviors directly reflect their knowledge state, which may not hold true especially in online learning scenarios. Abnormal behaviors exhibited by students, such as guessing and plagiarism, can introduce biases into the data, making it difficult to accurately assess students’ true knowledge state. To address this limitation, we propose a novel DebiAsed Cognition rEpresentation (DACE) modeling approach. This approach introduces a novel adversarial training strategy based on information bottleneck theory to obtain a debiased knowledge state representation that retains only the most reliable information for accurately predicting students’ performance on new questions. Moreover, we design a novel contrastive learning module through embedding-based augmentation to further enhance the robustness and generalizability of the learned knowledge state representation. We conduct extensive experiments on three public KT datasets and the newly released dataset BaiPy to demonstrate the superiority of our model over strong baselines, particularly when confronted with biased data. Our code and datasets are available at https://github.com/lvXiangwei/DACE.git .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410642342",
    "type": "article"
  },
  {
    "title": "Semantic-enhanced Co-attention Prompt Learning for Non-overlapping Cross-Domain Recommendation",
    "doi": "https://doi.org/10.1145/3742422",
    "publication_date": "2025-06-09",
    "publication_year": 2025,
    "authors": "Lei Guo; Choong Eue Song; Feng Guo; Xiaohui Han; Xiaojun Chang; Lei Zhu",
    "corresponding_authors": "",
    "abstract": "Non-overlapping Cross-domain Sequential Recommendation (NCSR) is the task that focuses on domain knowledge transfer without overlapping entities. Compared with traditional Cross-domain Sequential Recommendation (CSR), NCSR poses several challenges: 1) NCSR methods often rely on explicit item IDs, overlooking semantic information among entities. 2) Existing CSR mainly relies on domain alignment for knowledge transfer, risking semantic loss during alignment. 3) Most previous studies do not consider the many-to-one characteristic, which is challenging because of the utilization of multiple source domains. Given the above challenges, we introduce the prompt learning technique for Many-to-one Non-overlapping Cross-domain Sequential Recommendation (MNCSR) and propose a Text-enhanced Co-attention Prompt Learning Paradigm (TCPLP). Specifically, we capture semantic meanings by representing items through text rather than IDs, leveraging natural language universality to facilitate cross-domain knowledge transfer. Unlike prior works that need to conduct domain alignment, we directly learn transferable domain information, where two types of prompts, i.e., domain-shared and domain-specific prompts, are devised, with a co-attention-based network for prompt encoding. Then, we develop a two-stage learning strategy, i.e., pre-train &amp; prompt-tuning paradigm, for domain knowledge pre-learning and transferring, respectively. We conduct extensive experiments on three datasets and the experimental results demonstrate the superiority of our TCPLP. Our source codes have been publicly released 1 .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411134767",
    "type": "article"
  },
  {
    "title": "Learning Binarized Representations with Pseudo-positive Sample Enhancement for Efficient Graph Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3744239",
    "publication_date": "2025-06-10",
    "publication_year": 2025,
    "authors": "Yankai Chen; Y. K. Que; Xinni Zhang; Chen Ma; Irwin King",
    "corresponding_authors": "",
    "abstract": "Learning vectorized embeddings is fundamental to many recommender systems for user-item matching. To enable efficient online inference, representation binarization , which embeds latent features into compact binary sequences, has recently shown significant promise in optimizing both memory usage and computational overhead. However, existing approaches primarily focus on numerical quantization , neglecting the associated information loss , which often results in noticeable performance degradation. To address these issues, we study the problem of graph representation binarization for efficient collaborative filtering. Our findings indicate that explicitly mitigating information loss at various stages of embedding binarization has a significant positive impact on performance. Building on these insights, we propose an enhanced framework, BiGeaR++, which specifically leverages supervisory signals from pseudo-positive samples , incorporating both real item data and latent embedding samples. Compared to its predecessor BiGeaR, BiGeaR++ introduces a fine-grained inference distillation mechanism and an effective embedding sample synthesis approach. Empirical evaluations across five real-world datasets demonstrate that the new designs in BiGeaR++ work seamlessly well with other modules, delivering substantial improvements of around 1% \\(\\sim\\) 10% over BiGeaR and thus achieving state-of-the-art performance compared to the competing methods. Our implementation is available at https://github.com/QueYork/BiGeaR-SS .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411183745",
    "type": "article"
  },
  {
    "title": "Adaptive Sampling-based Dynamic Graph Learning for Information Diffusion Prediction",
    "doi": "https://doi.org/10.1145/3744643",
    "publication_date": "2025-06-17",
    "publication_year": 2025,
    "authors": "Xiaodong Lü; Mingzhe Liu; Tongyu Zhu; Leilei Sun; Jibin Wang; Weifeng Lv; Yikun Ban; Deqing Wang",
    "corresponding_authors": "",
    "abstract": "Information diffusion prediction, aimed at estimating future interacting users for a given content, is crucial for various applications on online social platforms. Recently, methods based on dynamic graph learning have achieved superior performance. However, these methods often face scalability issues due to their full-neighbor aggregation, which requires loading the whole diffusion graph, making them impractical for large graphs. While improving model scalability through sampling is an immediate approach, it is challenging on the diffusion graph due to various user dependencies (i.e., the temporal and structural correlations of user-item interactions). To address this problem, we propose a new model named ASDIP, which performs adaptive sampling on the diffusion graph. Specifically, ASDIP employs multiple sampling strategies to extract walks from the diffusion graph, each identifying a representative user dependency by sampling walks that satisfy a specific temporal constraint. Next, the walks sampled by different strategies are first mapped into distinct strategy-specific user representations and then merged into a unified user representation, adaptively fusing the information obtained from different strategies. Finally, a cascade representation learning module is proposed to generate cascade representations based on user representations and interaction timestamps. Experimental results validate the effectiveness and scalability of ASDIP.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411374069",
    "type": "article"
  },
  {
    "title": "Interaction Privacy Vulnerability in Federated Recommendation and Lossless Countermeasure",
    "doi": "https://doi.org/10.1145/3745025",
    "publication_date": "2025-06-19",
    "publication_year": 2025,
    "authors": "Xiaoqiang Gui; Guoxian Yu; Jun Wang; Shuguang Han; Qingzhong Li; Zhang Yong-qing; Wei Wang",
    "corresponding_authors": "",
    "abstract": "Federated Recommendation (FedRec) systems are recognized as privacy-preserving solutions for collaboratively training recommender models without sharing users’ private data. However, recent studies have revealed that FedRec systems are vulnerable to interaction-level membership inference attacks. In such attacks, a semi-honest server can employ crafted methods to infer users’ interacted items. In this paper, we identify that user preference information is predominantly stored in the user-uploaded parameters rather than in the local parameters after local training. Leveraging this insight, we expose a new interaction vulnerability and introduce the PubPara attack. Our experiments show that PubPara improves the inference performance by at least 40% over existing attacks, while requiring the minimal inference time and remaining robust against current defense methods. To safeguard user privacy without compromising recommender performance, we propose MultiVerse, a novel countermeasure. MultiVerse utilizes untrained items outside the user’s local training data to obfuscate the server’s inference of interacted items. It includes a four-step strategy (training, optimization, refinement, and denoising) to achieve robust defense. Extensive experiments on three representative FedRec models (F-NCF, F-LightGCN, and FedRAP) across three real-world datasets validate that MultiVerse significantly degrades the attack’s inference performance to near the level of random guess while maintaining lossless recommender performance.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411448935",
    "type": "article"
  },
  {
    "title": "AgentTOD: A Task-Oriented Dialogue Agent with a Flexible and Adaptive API Calling Paradigm",
    "doi": "https://doi.org/10.1145/3745021",
    "publication_date": "2025-06-20",
    "publication_year": 2025,
    "authors": "Heng-Da Xu; Xian-Ling Mao; Fanshu Sun; Tian-Yi Che; Chun Xu; Heyan Huang",
    "corresponding_authors": "",
    "abstract": "Task-oriented dialogue (TOD) systems play a vital role in numerous assistance and service scenarios, significantly improving people’s daily lives. Conventionally, a TOD system adheres to a fixed paradigm, where it must first extract user goals and query external databases before it can generate the final response. However, this fixed extract-and-query paradigm is not always optimal for all dialogue turns, which is redundant for the simple turns that do not need external information, and is inadequate for the complex turns that need to interact with the external world multiple times. To address the limitations, in this paper, we propose AgentTOD, a novel TOD framework that uses a large language model (LLM) as the intelligent agent to achieve a flexible dialogue paradigm. AgentTOD deprecates the traditional modular architecture (including dialogue state tracking and dialogue policy) by utilizing an LLM as the controller brain to determine when and how to call the provided APIs to obtain external information. It can choose to call APIs any number of times with various parameters until it’s enough to reply to the user. Besides, to train AgentTOD, we construct a large and comprehensive TOD dataset, called TrajsTOD (Trajectories of TODs), which consists of 66k+ user-agent dialogue trajectories converted from 8 popular TOD datasets covering 60 domains. TrajsTOD is constructed with minimal dialogue annotations where only the API calling logs are needed, and can empower AgentTOD with the general ability to call APIs and generate responses according to the task definition. Extensive experimental results on the MultiWOZ-series and SGD datasets demonstrate AgentTOD has superior performance on task-oriented dialogues as well as a superior adaptability to new task scenarios.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411489243",
    "type": "article"
  },
  {
    "title": "Breaking The Loop: Causal Learning To Mitigate Echo Chambers In Social Networks",
    "doi": "https://doi.org/10.1145/3757738",
    "publication_date": "2025-08-01",
    "publication_year": 2025,
    "authors": "Dianer Yu; Qian Li; Huan Huo; Guandong Xu",
    "corresponding_authors": "",
    "abstract": "In social networks, echo chambers form when users primarily encounter information that reinforces their existing views with limited exposure to different perspectives. This self-reinforcing isolation worsens societal issues such as division and declining public discourse. Traditional approaches attempt to mitigate echo chambers by analyzing observable interaction patterns to identify their formative mechanisms. However, they overlook unobserved implicit factors, called hidden confounders in causal inference, that significantly influence content exposure and user behaviors despite not being directly captured in the data. To address this, we propose Causal Echo Diffusion Attenuator (CEDA) , a novel framework that integrates causal learning with sequential recommendations to detect and adjust for hidden confounders in social networks. Generally, CEDA comprises four key components: (1) User Dual Modelling builds comprehensive user embeddings by combining users’ attributes and structural information to fully capture behavior patterns. (2) Causal Transformer then estimates residual embeddings that account for hidden confounders, incorporating them into the Transformer as causal adjustments for unbiased user embeddings. (3) Social Diffusion Predictor uses unbiased user embeddings to jointly optimize diffusion prediction accuracy and information diversity. (4) Targeted Interventions strategically reshapes information flows to disrupt echo chambers based on the generated prediction and diversity insights. Extensive experiments demonstrate CEDA’s superior performance in both predicting information diffusion patterns and mitigating echo chambers.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412827327",
    "type": "article"
  },
  {
    "title": "Towards Goal-oriented Intelligent Tutoring Systems in Online Education",
    "doi": "https://doi.org/10.1145/3760401",
    "publication_date": "2025-08-12",
    "publication_year": 2025,
    "authors": "Yang Deng; Zifeng Ren; An Zhang; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Interactive Intelligent Tutoring Systems (ITSs) enhance the learning experience in online education by fostering effective learning through interactive problem-solving. However, many current ITS models do not fully incorporate proactive engagement strategies that optimize educational resources through thoughtful planning and assessment. In this work, we propose a novel and practical task of Goal-oriented Intelligent Tutoring Systems (GITS), designed to help students achieve proficiency in specific concepts through a tailored sequence of exercises and evaluations. We introduce a novel graph-based reinforcement learning framework, named Planning-Assessment-Interaction ( PAI ), to tackle the challenges of goal-oriented policy learning within GITS. This framework utilizes cognitive structure information to refine state representation and guide the selection of subsequent actions, whether that involves presenting an exercise or conducting an assessment. Additionally, PAI employs a cognitive diagnosis model that dynamically updates to predict student reactions to exercises and assessments. We construct three benchmark datasets covering different subjects to facilitate offline GITS research. Experimental results validate PAI 's effectiveness and efficiency, and we present comprehensive analyses of its performance with different student types, highlighting the unique challenges presented by this task.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413105373",
    "type": "article"
  },
  {
    "title": "A Survey of Conversational Search",
    "doi": "https://doi.org/10.1145/3759453",
    "publication_date": "2025-08-08",
    "publication_year": 2025,
    "authors": "Fengran Mo; Kelong Mao; Ziliang Zhao; Hongjin Qian; Haonan Chen; Yiruo Cheng; Xiaoxi Li; Yutao Zhu; Zhicheng Dou; Jian‐Yun Nie",
    "corresponding_authors": "",
    "abstract": "As a cornerstone of modern information access, search engines have become indispensable in everyday life. With the rapid advancements in AI and natural language processing (NLP) technologies, particularly large language models (LLMs), search engines have evolved to support more intuitive and intelligent interactions between users and systems. Conversational search, an emerging paradigm for next-generation search engines, leverages natural language dialogue to facilitate complex and precise information retrieval, thus attracting significant attention. Unlike traditional keyword-based search engines, conversational search systems enhance user experience by supporting intricate queries, maintaining context over multi-turn interactions, and providing robust information integration and processing capabilities. Key components such as query reformulation, search clarification, conversational retrieval, and response generation work in unison to enable these sophisticated interactions. In this survey, we explore the recent advancements and potential future directions in conversational search, examining the critical modules that constitute a conversational search system. We highlight the integration of LLMs in enhancing these systems and discuss the challenges and opportunities that lie ahead in this dynamic field. Additionally, we provide insights into real-world applications and robust evaluations of current conversational search systems, aiming to guide future research and development in conversational search.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413243547",
    "type": "article"
  },
  {
    "title": "Social Cognitive Theory Enhanced Diversified Recommendation",
    "doi": "https://doi.org/10.1145/3767324",
    "publication_date": "2025-09-11",
    "publication_year": 2025,
    "authors": "Zhirui Deng; Zhicheng Dou; Yutao Zhu; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "The diversified recommendation aims to satisfy a user's different preferences and hence alleviates the information cocoon problem. Previous methods focus on increasing the sample probability of interacted items in the long-tail category. However, these methods are limited by the scope of the historical interactions of a single user and confront the challenge of inadequate diversity of past interactions and unpredictable potential diverse preferences. Drawing from social cognitive theory, observational learning ability allows humans to imitate others’ behaviors when their experience is insufficient. Inspired by it, in this paper, we apply the idea of observational learning to the diversified recommendation and introduce a social Cog nitive theory enhanced D iversified R ecommendation model ( Cog4DR ). Specifically, we design a three-step observational learning pipeline, including attention, purification, and retention, corresponding to the three essential stages of observational learning. The pipeline enables the current user to observe other users who have similar tastes but also engage with unique categories, therefore exploring potential diverse preferences and achieving dual improvements in accuracy and diversity. Experimental results indicate that Cog4DR outperforms all previous approaches, demonstrating the effectiveness of imitating other users’ behaviors for diversified recommendations.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414153441",
    "type": "article"
  },
  {
    "title": "Learn to Rank Risky Investors: A Case Study of Predicting Retail Traders’ Behaviour and Profitability",
    "doi": "https://doi.org/10.1145/3768623",
    "publication_date": "2025-09-19",
    "publication_year": 2025,
    "authors": "Weixian Waylon Li; Tiejun Ma",
    "corresponding_authors": "",
    "abstract": "Identifying risky traders with high profits in financial markets is crucial for market makers, such as trading exchanges, to ensure effective risk management through real-time decisions on regulation compliance and hedging. However, capturing the complex and dynamic behaviours of individual traders poses significant challenges. Traditional classification and anomaly detection methods often establish a fixed risk boundary, failing to account for this complexity and dynamism. To tackle this issue, we propose a profit-aware risk ranker (PA-RiskRanker) that reframes the problem of identifying risky traders as a ranking task using Learning-to-Rank (LETOR) algorithms. Our approach features a Profit-Aware binary cross entropy (PA-BCE) loss function and a transformer-based ranker enhanced with a self-cross-trader attention pipeline. These components effectively integrate profit and loss (P&amp;L) considerations into the training process while capturing intra- and inter-trader relationships. Our research critically examines the limitations of existing deep learning-based LETOR algorithms in trading risk management, which often overlook the importance of P&amp;L in financial scenarios. By prioritising P&amp;L, our method improves risky trader identification, achieving an 8.4% increase in F1 score compared to state-of-the-art (SOTA) ranking models like Rankformer. Additionally, it demonstrates a 10%-17% increase in average profit compared to all benchmark models.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414363252",
    "type": "article"
  },
  {
    "title": "Exploring Heterogeneous Data Lake based on Canonical Graphs",
    "doi": "https://doi.org/10.1145/3772001",
    "publication_date": "2025-10-21",
    "publication_year": 2025,
    "authors": "Yuan Qin; Ye Yuan; Zhenyu Wen; Guoren Wang",
    "corresponding_authors": "",
    "abstract": "A data lake maintains a large amounts of heterogeneous data with different data schemas and query interfaces. Efficiently querying and analyzing the heterogeneous data enables users to gain more complete insights. In this paper, we study a novel problem of distributed keyword search across heterogeneous data sources. Traditional distributed search algorithms generally require the predefined crossing edges connecting relevant data instances for communication between different sources, which is unpractical for the data lake due to the schema heterogeneity. To effectively perform keyword search over the data lake, we first introduce canonical graphs and then develop a best-first search algorithm called UnifySea, which explores the answers across different sources based on the unified identification of related instances. To further improve the query efficiency, we propose a novel incremental keyword search algorithm called DistSea, which just need to identify the promising relevant data between different sources. DistSea incrementally calculates the optimal answers based on locally partial evaluation. Equipped with several efficient pruning rules, DistSea reduces unpromising tree calculation across different sources. Experimental evaluations on six real-world benchmarks demonstrate the effectiveness, efficiency and scalability of the proposed algorithms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415382717",
    "type": "article"
  },
  {
    "title": "Reproducibility and Artifact Consistency of the SIGIR 2022 Recommender Systems Papers Based on Message Passing",
    "doi": "https://doi.org/10.1145/3772275",
    "publication_date": "2025-10-22",
    "publication_year": 2025,
    "authors": "Maurizio Ferrari Dacrema; Michael Benigni; Nicola Ferro",
    "corresponding_authors": "",
    "abstract": "Graph-based techniques relying on neural networks and embeddings have gained attention as a way to develop Recommender Systems (RS) with several papers on the topic presented at SIGIR 2022 and 2023. Given the importance of ensuring that published research is methodologically sound and reproducible, in this paper we analyze 10 graph-based RS papers, most of which were published at SIGIR 2022, and assess their impact on subsequent work published in SIGIR 2023. Our analysis reveals several critical points that require attention: (i) the prevalence of bad practices, such as erroneous data splits or information leakage between training and testing data, which call into question the validity of the results; (ii) frequent inconsistencies between the provided artifacts (source code and data) and their descriptions in the paper, causing uncertainty about what is actually being evaluated; and (iii) the preference for new or complex baselines that are weaker compared to simpler ones, creating the impression of continuous improvement even when, particularly for the Amazon-Book dataset, the state-of-the-art has significantly worsened. Due to these issues, we are unable to confirm the claims made in most of the papers that we examined and attempted to reproduce.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4415435767",
    "type": "article"
  },
  {
    "title": "The equalizing impact of a group support system on status differentials",
    "doi": "https://doi.org/10.1145/297117.297126",
    "publication_date": "1999-01-01",
    "publication_year": 1999,
    "authors": "Bernard C. Y. Tan; Kwok‐Kee Wei; Richard T. Watson",
    "corresponding_authors": "",
    "abstract": "This study investigates the impact of the electronic communication capability of a group support system (GSS) on status differentials in small groups. A laboratory experiment was used to answer the research questions. Three support levels were studied: manual, face-to-face GSS, and dispersed GSS. Two task types were examined: intellective and preference. Five dependent variables reflecting different aspects of status differentials were measured: status influence, sustained influence, residual disagreement, perceived influence, and decision confidence. The results show that manual groups had higher status influence, sustained influence, and decision confidence, but lower residual disagreement than face-to-face GSS and dispersed GSS groups. Preference task groups also produced higher status influence and sustained influence, but lower residual disagreement compared to intellective task groups. In addition, manual groups working on the preference task reported higher perceived influence than face-to-face GSS and dispersed GSS groups working on the same task. These findings suggest that when groups are engaged in activities for which status differentials are undesirable, a GSS can be used in both face-to-face and dispersed settings to dampen status differentials. Moreover, when a task amplifies status differentials, the use of a GSS tends to produce corresponding stronger dampening effects.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2036109093",
    "type": "article"
  },
  {
    "title": "An investigation of content representation using text grammars",
    "doi": "https://doi.org/10.1145/151480.151490",
    "publication_date": "1993-01-02",
    "publication_year": 1993,
    "authors": "Dasaratha V. Rama; Padmini Srinivasan",
    "corresponding_authors": "",
    "abstract": "We extend prior work on a model for natural language text representation and retrieval using a linguistic device called text grammar. We demonstrate the value of this approach in accessing relevant items from a collection of empirical abstracts in a medical domain. The advantage, when compared to traditional keyword retrieval, is that this approach is a significant move towards knowledge representation and retrieval. Text representation in this model includes keywords and their conceptual roles in the text. In particular, it involves extracting TOPIC predicates representing the research issue addressed and DESIGN predicates representing important methodological features of the empirical study. Preliminary experimentation shows that keywords exhibit a variety of text-grammar roles in a text database. Second, as intuitively expected, retrieval using TOPIC predicates identifies a smaller subset of texts than Boolean retrieval does. These empirical results along with the theoretical work indicate that the representation and retrieval strategies proposed have a significant potential. Finally, EMPIRICIST, a prototype system is described. In it the text representation predicates are implemented as a network while retrieval is through constrained-spreading activation strategies.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2012137968",
    "type": "article"
  },
  {
    "title": "Making a digital library",
    "doi": "https://doi.org/10.1145/248625.248627",
    "publication_date": "1997-04-01",
    "publication_year": 1997,
    "authors": "Richard Entlich; Jan Olsen; Lorrin R. Garson; Michael Lesk; Lorraine Normore; Stuart Weibel",
    "corresponding_authors": "",
    "abstract": "The CORE (Chemical Online Retrieval Experiment) project is a library of primary journal articles in chemistry. Any library has an inside and an outside; in this article we describe the inside of the library and the methods for building the system and accumulating the database. A later article will describe the outside (user experiences). Among electronic-library projects, the CORE project is unusual in that it has both ASCII derived from typesetting and image data for all its pages, and among experimental electronic-library projects, it is unusually large. We describe here (a) the processes of scanning and analyzing about 400,000 pages of primary journal material, (b) the conversion of a similar amount of textual database material, (c) the linking of these two data sources, and (d) the indexing of the text material.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2061858109",
    "type": "article"
  },
  {
    "title": "Complete answer aggregates for treelike databases",
    "doi": "https://doi.org/10.1145/382979.383042",
    "publication_date": "2001-04-01",
    "publication_year": 2001,
    "authors": "Holger Meuss; Klaus U. Schulz",
    "corresponding_authors": "",
    "abstract": "The use of markup languages like SGML, HTML or XML for encoding the strucutre of documents or linguistic data has lead to many databases where entries are adequately described as trees. In this context querying formalisms are interesting that offer the possiblity to refer both to textual content and logical structure. We consider models where the strucutre specified in a query is not only used as a filter, but also for selecting and presenting different parts of the data. If answers are formalized as mapping from query nodes to the database, a simple enumeration of all mappings in the answer set will often suffer from the effect that many answers have common subparts. From a theoretical point of view this may lead to an exponential time complexity of the computation and presentation of all answers. Concentration on the language of so called tree queries—a variant and extension of Kilpeläinen's Tree Matching formalism—we introduce the notion of a “complete answer aggregate” for a given query. This new data strucutre offers a compact view of the set of all answer and supports active exploration of the ansewer space. Since complete answer aggregates use a powerful structure-sharing mechanism their maximal size is of order 𝒪( d•h•q ) where d and q respectively denote the size of the database and the query, and h is the maximal depth of a path of the database. An algorithm is given that computes a complete answer aggregate for a given treee query in time 𝒪( d •log( d)•h• ). For the sublanguage of so-called rigid tree queries, as well as for so-called “nonrecursive” databases, an improved bound of 𝒪( d •log( d)•q ) is obtained. The algorithm is based on a specific index structure that supports practical efficiency.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1968934723",
    "type": "article"
  },
  {
    "title": "Approximate spatio-temporal retrieval",
    "doi": "https://doi.org/10.1145/366836.366874",
    "publication_date": "2001-01-01",
    "publication_year": 2001,
    "authors": "Dimitris Papadias; Nikos Mamoulis; Vasilis Delis",
    "corresponding_authors": "",
    "abstract": "This paper proposes a framework for the handling of spatio-temporal queries with inexact matches, using the concept of relation similarity. We initially describe a binary string encoding for 1D relations that permits the automatic derivation of similarity measures. We then extend this model to various granularity levels and many dimensions, and show that reasoning on spatio-temporal structure is significantly facilitated in the new framework. Finally, we provide algorithms and optimization methods for four types of queries: (i) object retrieval based on some spatio-temporal relations with respect to a reference object, (ii) spatial joins, i.e., retrieval of object pairs that satisfy some input relation, (iii) structural queries, which retrieve configurations matching a particular spatio-temporal structure, and (iv) special cases of motion queries. Considering the current large availability of multidimensional data and the increasing need for flexible query-answering mechanisms, our techniques can be used as the core of spatio-temporal query processors.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2029781953",
    "type": "article"
  },
  {
    "title": "Designing with the user",
    "doi": "https://doi.org/10.1145/45941.383895",
    "publication_date": "1988-04-01",
    "publication_year": 1988,
    "authors": "Lucy Suchman",
    "corresponding_authors": "Lucy Suchman",
    "abstract": "article Free Access Share on Designing with the user: book review of Computers and democracy: a Scandinavian challenge, G. Bjerknes, P. Ehn, and M. Kyng, Eds. Gower Press, Brookfield, VT, 1987 Author: Lucy Suchman Xerox Palo Alto Research Center, Palo Alto, CA Xerox Palo Alto Research Center, Palo Alto, CAView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 6Issue 2April 1988 pp 173–183https://doi.org/10.1145/45941.383895Online:01 April 1988Publication History 17citation798DownloadsMetricsTotal Citations17Total Downloads798Last 12 Months47Last 6 weeks9 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2065016469",
    "type": "article"
  },
  {
    "title": "Knowledge encapsulation for focused search from pervasive devices",
    "doi": "https://doi.org/10.1145/503104.503106",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Yariv Aridor; David Carmel; Yoelle Maarek; Aya Soffer; Ronny Lempel",
    "corresponding_authors": "",
    "abstract": "Mobile knowledge seekers often need access to information on the Web during a meeting or on the road, while away from their desktop. A common practice today is to use pervasive devices such as Personal Digital Assistants or mobile phones. However, these devices have inherent constraints (e.g., slow communication, form factor) which often make information discovery tasks impractical.In this paper, we present a new focused-search approach specifically oriented for the mode of work and the constraints dictated by pervasive devices. It combines focused search within specific topics with encapsulation of topic-specific information in a persistent repository. One key characteristic of these persistent repositories is that their footprint is small enough to fit on local devices, and yet they are rich enough to support many information discovery tasks in disconnected mode. More specifically, we suggest a representation for topic-specific information based on \"knowledge-agent bases\" that comprise all the information necessary to access information about a topic (under the form of key concepts and key Web pages) and assist in the full search process from query formulation assistance to result scanning on the device itself. The key contribution of our work is the coupling of focused search with encapsulated knowledge representation making information discovery from pervasive devices practical as well as efficient. We describe our model in detail and demonstrate its aspects through sample scenarios.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W1970990216",
    "type": "article"
  },
  {
    "title": "A prototype system for the electronic storage and retrieval of document images",
    "doi": "https://doi.org/10.1145/4229.4232",
    "publication_date": "1985-07-01",
    "publication_year": 1985,
    "authors": "Grid Thoma; Surachai Suthasinekul; Frank L. Walker; John P. Cookson; M. Rashidian",
    "corresponding_authors": "",
    "abstract": "A prototype system has been implemented for electronic scanning, digitization, storage, retrieval, and display of images of biomedical documents. Paper documents are scanned and digitized at a scan density of 200 picture elements (pels) per inch by either a high-speed loose-leaf scanner with an automatic document transport or a book scanner with a manual book holder. Each scanner employs a high-resolution charge-coupled device (CCD) linear array operating at a sampling rate close to 10 MHz. The analog output signal of the CCD array is digitized into 1 bit per pixel two-tone images by means of dynamic thresholding. The digitized images are stored on magnetic disks to be processed and will eventually be transferred onto optical disks for archival storage. Existing on-line bibliographic databases developed by the National Library of Medicine are used as directories for the retrieval of document images. These images are displayed at a resolution of 200 pels/inch in both soft-copy (raster-refreshed CRT) and hard-copy forms. This prototype system, developed as part of a research and development program, offers the opportunity to investigate the areas of document image enhancement, image compression, and omnifont text recognition and to conduct experiments designed to answer key questions on the role of electronic document storage and retrieval technology in library information processing and the preservation of library documents.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2025653668",
    "type": "article"
  },
  {
    "title": "A visual interface for a database with version management",
    "doi": "https://doi.org/10.1145/214427.214430",
    "publication_date": "1986-07-01",
    "publication_year": 1986,
    "authors": "Jay W. Davison; Stanley B. Zdonik",
    "corresponding_authors": "",
    "abstract": "This paper describes a graphical interface to an experimental database system which incorporates a built-in version control mechanism that maintains a history of the database development and changes. The system is an extension of ISIS [6], Interface for a Semantic Information System, a workstation-based, graphical database programming tool developed at Brown University. ISIS supports a graphical interface to a modified subset of the Semantic Data Model (SDM) [7]. The ISIS extension introduces a transaction mechanism that interacts with the version control facilities. A series of version control support tools have been added to ISIS to provide a notion of history to user-created databases. The user can form new versions of three types of ISIS objects: a class definition object (a type), the set of instances of a class (the content), and an entity. A version-viewing mechanism is provided to allow for the comparison of various object versions. Database operations are grouped together in atomic units to form transactions, which are stored as entities in the database. A sample session demonstrates the capabilities of version and transaction control during the creation and manipulation of database objects.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2029041049",
    "type": "article"
  },
  {
    "title": "An OIS model for internal accounting control evaluation",
    "doi": "https://doi.org/10.1145/357423.357426",
    "publication_date": "1983-01-01",
    "publication_year": 1983,
    "authors": "Andrew D. Bailey; James H. Gerlach; R. Preston McAfee; Andrew B. Whinston",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on An OIS model for internal accounting control evaluation Authors: Andrew D. Bailey Department of Accounting, School of Management, University of Minnesota, 271 19th Ave. South, Minneapolis, MN Department of Accounting, School of Management, University of Minnesota, 271 19th Ave. South, Minneapolis, MNView Profile , James H. Gerlach Faculty of Commerce and Business Administration, 2053 Main Hall, University Campus, Vancouver, B.C., Canada V6T 1Y8 Faculty of Commerce and Business Administration, 2053 Main Hall, University Campus, Vancouver, B.C., Canada V6T 1Y8View Profile , R. Preston McAfee Department of Economics, University of Western Ontario, London, Ont., Canada N6A 5C2 Department of Economics, University of Western Ontario, London, Ont., Canada N6A 5C2View Profile , Andrew B. Whinston Department of Management, Economics, and Computer Science, Purdue University, West Lafayette, IN Department of Management, Economics, and Computer Science, Purdue University, West Lafayette, INView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 1pp 25–44https://doi.org/10.1145/357423.357426Published:01 January 1983Publication History 14citation824DownloadsMetricsTotal Citations14Total Downloads824Last 12 Months32Last 6 weeks3 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2051324681",
    "type": "article"
  },
  {
    "title": "Dynamic element retrieval in a structured environment",
    "doi": "https://doi.org/10.1145/1185877.1185880",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Carolyn J. Crouch",
    "corresponding_authors": "Carolyn J. Crouch",
    "abstract": "This research examines the feasibility of dynamic element retrieval in a structured environment. Structured documents and queries are represented in extended vector form, based on a modification of the basic vector space model suggested by Fox [1983]. A method for the dynamic retrieval of XML elements, which requires only a single indexing of the documents at the level of the basic indexing node, is presented. This method, which we refer to as flexible retrieval , produces a rank ordered list of retrieved elements that is equivalent to the result produced by the same retrieval against an all-element index of the collection. Flexible retrieval obviates the need for storing either an all-element index or multiple indices of the collection.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2011518216",
    "type": "article"
  },
  {
    "title": "A novel XML music information retrieval method using graph invariants",
    "doi": "https://doi.org/10.1145/1281485.1281490",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "Alberto A. Pinto; Goffredo Haus",
    "corresponding_authors": "",
    "abstract": "The increasing diffusion of XML languages for the encoding of domain-specific multimedia information raises the need for new information retrieval models that can fully exploit structural information. An XML language specifically designed for music like MX allows queries to be made directly on the thematic material. The main advantage of such a system is that it can handle symbolic, notational, and audio objects at the same time through a multilayered structure. On the model side, common music information retrieval methods do not take into account the inner structure of melodic themes and the metric relationships between notes. In this article we deal with two main topics: a novel architecture based on a new XML language for music and a new model of melodic themes based on graph theory. This model takes advantage of particular graph invariants that can be linked to melodic themes as metadata in order to characterize all their possible modifications through specific transformations and that can be exploited in filtering algorithms. We provide a similarity function and show through an evaluation stage how it improves existing methods, particularly in the case of same-structured themes.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2007675602",
    "type": "article"
  },
  {
    "title": "Processing Long Queries Against Short Text",
    "doi": "https://doi.org/10.1145/3052772",
    "publication_date": "2017-05-12",
    "publication_year": 2017,
    "authors": "Dongxiang Zhang; Yuchen Li; Ju Fan; Lianli Gao; Fumin Shen; Heng Tao Shen",
    "corresponding_authors": "",
    "abstract": "Many real applications in real-time news stream advertising call for efficient processing of long queries against short text. In such applications, dynamic news feeds are regarded as queries to match against an advertisement (ad) database for retrieving the k most relevant ads. The existing approaches to keyword retrieval cannot work well in this search scenario when queries are triggered at a very high frequency. To address the problem, we introduce new techniques to significantly improve search performance. First, we devise a two-level partitioning for tight upper bound estimation and a lazy evaluation scheme to delay full evaluation of unpromising candidates, which can bring three to four times performance boosting in a database with 7 million ads. Second, we propose a novel rank-aware block-oriented inverted index to further improve performance. In this index scheme, each entry in an inverted list is assigned a rank according to its importance in the ad. Then, we introduce a block-at-a-time search strategy based on the index scheme to support a much tighter upper bound estimation and a very early termination. We have conducted experiments with real datasets, and the results show that the rank-aware method can further improve performance by an order of magnitude.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2615162663",
    "type": "article"
  },
  {
    "title": "Parallelization of Massive Textstream Compression Based on Compressed Sensing",
    "doi": "https://doi.org/10.1145/3086702",
    "publication_date": "2017-08-21",
    "publication_year": 2017,
    "authors": "Min Peng; Wang Gao; Hua Wang; Yanchun Zhang; Jiajia Huang; Qianqian Xie; Gang Hu; Gang Tian",
    "corresponding_authors": "",
    "abstract": "Compressing textstreams generated by social networks can both reduce storage consumption and improve efficiency such as fast searching. However, the compression process is a challenge due to the large scale of textstreams. In this article, we propose a textstream compression framework based on compressed sensing theory and design a series of matching parallel procedures. The new approach uses a linear projection technique in the textstream compression process, achieving fast compression speed and low compression ratio. Two processes are executed by designing elaborated parallel procedures for efficient compressing and decompressing of large-scale textstreams. The decompression process is implemented for approximate solutions of underdetermined linear systems. Experimental results show that the new method can efficiently achieve the compression and decompression tasks on a large amount of text generated by social networks.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2749358103",
    "type": "article"
  },
  {
    "title": "DBpedia-Based Entity Linking via Greedy Search and Adjusted Monte Carlo Random Walk",
    "doi": "https://doi.org/10.1145/3086703",
    "publication_date": "2017-08-31",
    "publication_year": 2017,
    "authors": "Ming Liu; Lei Chen; Bingquan Liu; Guidong Zheng; Xiaoming Zhang",
    "corresponding_authors": "",
    "abstract": "Facing a large amount of entities appearing on the web, entity linking has recently become useful. It assigns an entity from a resource to one name mention to help users grasp the meaning of this name mention. Unfortunately, many possible entities can be assigned to one name mention. Apparently, the usually co-occurring name mentions are related and can be considered together to determine their best assignments. This approach is called collective entity linking and is often conducted based on entity graph. However, traditional collective entity linking methods either consume much time due to the large scale of entity graph or obtain low accuracy due to simplifying graph. To improve both accuracy and efficiency, this article proposes a novel collective entity linking algorithm. It first constructs an entity graph by connecting any two related entities, and then a probability-based objective function is proposed on this graph to ensure the high accuracy of the linking result. Via this function, we convert entity linking to the process of finding the nodes with the highest PageRank Values. Greedy search and an adjusted Monte Carlo random walk are proposed to fulfill this work. Experimental results demonstrate that our algorithm performs much better than traditional linking methods.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2752310529",
    "type": "article"
  },
  {
    "title": "Selective Cluster Presentation on the Search Results Page",
    "doi": "https://doi.org/10.1145/3158672",
    "publication_date": "2018-02-28",
    "publication_year": 2018,
    "authors": "Or Levi; Ido Guy; Fiana Raiber; Oren Kurland",
    "corresponding_authors": "",
    "abstract": "Web search engines present, for some queries, a cluster of results from the same specialized domain (“vertical”) on the search results page (SERP). We introduce a comprehensive analysis of the presentation of such clusters from seven different verticals based on the logs of a commercial Web search engine. This analysis reveals several unique characteristics—such as size, rank, and clicks—of result clusters from community question-and-answer websites. The study of properties of this result cluster—specifically as part of the SERP—has received little attention in previous work. Our analysis also motivates the pursuit of a long-standing challenge in ad hoc retrieval, namely, selective cluster retrieval . In our setting, the specific challenge is to select for presentation the documents most highly ranked either by a cluster-based approach (those in the top-retrieved cluster) or by a document-based approach. We address this classification task by representing queries with features based on those utilized for ranking the clusters, query-performance predictors, and properties of the document-clustering structure. Empirical evaluation performed with TREC data shows that our approach outperforms a recently proposed state-of-the-art cluster-based document-retrieval method as well as state-of-the-art document-retrieval methods that do not account for inter-document similarities.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2788052342",
    "type": "article"
  },
  {
    "title": "BoRe",
    "doi": "https://doi.org/10.1145/3361217",
    "publication_date": "2019-10-17",
    "publication_year": 2019,
    "authors": "Pengtao Lv; Xiangwu Meng; Yujie Zhang",
    "corresponding_authors": "",
    "abstract": "News recommendation has become an essential way to help readers discover interesting stories. While a growing line of research has focused on modeling reading preferences for news recommendation, they neglect the instability of reader consumption behaviors, i.e., consumption behaviors of readers may be influenced by other factors in addition to user interests, which degrades the recommendation effectiveness of existing methods. In this article, we propose a probabilistic generative model, BoRe, where user interests and crowd effects are used to adapt to the instability of reader consumption behaviors, and reading sequences are utilized to adapt user interests evolving over time. Further, the extreme sparsity problem in the domain of news severely hinders accurately modeling user interests and reading sequences, which discounts BoRe’s ability to adapt to the instability. Accordingly, we leverage domain-specific features to model user interests in the situation of extreme sparsity. Meanwhile, we consider groups of users instead of individuals to capture reading sequences. Besides, we study how to reduce the computation to allow online application. Extensive experiments have been conducted to evaluate the effectiveness and efficiency of BoRe on real-world datasets. The experimental results show the superiority of BoRe, compared with the state-of-the-art competing methods.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2981038821",
    "type": "article"
  },
  {
    "title": "Effects of Usage-Based Feedback on Video Retrieval",
    "doi": "https://doi.org/10.1145/1961209.1961214",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "David Vallet; Frank Hopfgartner; Joemon M. Jose; Pablo Castells",
    "corresponding_authors": "",
    "abstract": "We present a model for exploiting community-based usage information for video retrieval, where implicit usage information from past users is exploited in order to provide enhanced assistance in video retrieval tasks, and alleviate the effects of the semantic gap problem. We propose a graph-based model for all types of implicit and explicit feedback, in which the relevant usage information is represented. Our model is designed to capture the complex interactions of a user with an interactive video retrieval system, including the representation of sequences of user-system interaction during a search session. Building upon this model, four recommendation strategies are defined and evaluated. An evaluation strategy is proposed based on simulated user actions, which enables the evaluation of our recommendation strategies over a usage information pool obtained from 24 users performing four different TRECVid tasks. Furthermore, the proposed simulation approach is used to simulate usage information pools with different characteristics, with which the recommendation approaches are further evaluated on a larger set of tasks, and their performance is studied with respect to the scalability and quality of the available implicit information.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2001543498",
    "type": "article"
  },
  {
    "title": "Efficient Index-Based Snippet Generation",
    "doi": "https://doi.org/10.1145/2590972",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "Hannah Bast; Marjan Celikik",
    "corresponding_authors": "",
    "abstract": "Ranked result lists with query-dependent snippets have become state of the art in text search. They are typically implemented by searching, at query time, for occurrences of the query words in the top-ranked documents. This document-based approach has three inherent problems: (i) when a document is indexed by terms which it does not contain literally (e.g., related words or spelling variants), localization of the corresponding snippets becomes problematic; (ii) each query operator (e.g., phrase or proximity search) has to be implemented twice, on the index side in order to compute the correct result set, and on the snippet-generation side to generate the appropriate snippets; and (iii) in a worst case, the whole document needs to be scanned for occurrences of the query words, which could be problematic for very long documents. We present a new index-based method that localizes snippets by information solely computed from the index and that overcomes all three problems. Unlike previous index-based methods, we show how to achieve this at essentially no extra cost in query processing time, by a technique we call operator inversion . We also show how our index-based method allows the caching of individual segments instead of complete documents, which enables a significantly larger cache hit-ratio as compared to the document-based approach. We have fully integrated our implementation with the CompleteSearch engine.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2008527192",
    "type": "article"
  },
  {
    "title": "What Does Affect the Correlation Among Evaluation Measures?",
    "doi": "https://doi.org/10.1145/3106371",
    "publication_date": "2017-08-29",
    "publication_year": 2017,
    "authors": "Nicola Ferro",
    "corresponding_authors": "Nicola Ferro",
    "abstract": "Information Retrieval (IR) is well-known for the great number of adopted evaluation measures, with new ones popping up more and more frequently. In this context, correlation analysis is the tool used to study the evaluation measures and to let us understand if two measures rank systems similarly, if they grasp different aspects of system performances or actually reflect different user models, if a new measure is well motivated or not. To this end, the two most commonly used correlation coefficients are the Kendall’s τ correlation and the AP correlation τ AP . The goal of the article is to investigate the properties of the tool, that is, correlation analysis, we use to study evaluation measures. In particular, we investigate three research questions about these two correlation coefficients: (i) what is the effect of the number of systems and topics? (ii) what is the effect of removing low-performing systems? (iii) what is the effect of the experimental collections? To answer these research questions, we propose a methodology based on General Linear Mixed Model (GLMM) and ANalysis Of VAriance (ANOVA) to isolate the effects of the number of topics, number of systems, and experimental collections and to let us observe expected correlation values, net from these effects, which are stable and reliable. We learned that the effect of the number of topics is more prominent than the effect of the number of systems. Even if it produces different absolute values, the effect of removing low-performing systems does not seem to provide information substantially different from not removing them, especially when comparing a whole set of evaluation measures. Finally, we found out that both document corpora and topic sets affect the correlation among evaluation measures, the effect of the latter being more prominent. Moreover, there is a substantial interaction between evaluation measures, corpora and topic sets, meaning that the correlation between different evaluation measures can be substantially increased or decreased depending on the different corpora and topics at hand.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2752377997",
    "type": "article"
  },
  {
    "title": "DGeye: Probabilistic Risk Perception and Prediction for Urban Dangerous Goods Management",
    "doi": "https://doi.org/10.1145/3448256",
    "publication_date": "2021-05-05",
    "publication_year": 2021,
    "authors": "Jingyuan Wang; Xin Lin; Yuan Zuo; Junjie Wu",
    "corresponding_authors": "",
    "abstract": "Recent years have witnessed the emergence of worldwide megalopolises and the accompanying public safety events, making urban safety a top priority in modern urban management. Among various threats, dangerous goods such as gas and hazardous chemicals transported through cities have bred repeated tragedies and become the deadly “bomb” we sleep with every day. While tremendous research efforts have been devoted to dealing with dangerous goods transportation (DGT) issues, further study is still in great need to quantify this problem and explore its intrinsic dynamics from a big data perspective. In this article, we present a novel system called DGeye , to feature a fusion between DGT trajectory data and residential population data for dangers perception and prediction. Specifically, DGeye first develops a probabilistic graphical model-based approach to mine spatio-temporally adjacent risk patterns from population-aware risk trajectories. Then, DGeye builds the novel causality network among risk patterns for risk pain-point identification, risk source attribution, and online risky state prediction. Experiments on both Beijing and Tianjin cities demonstrate the effectiveness of DGeye in real-life DGT risk management. As a case in point, our report powered by DGeye successfully drove the government to lay down gas pipelines for the famous Guijie food street in Beijing.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3157597645",
    "type": "article"
  },
  {
    "title": "RLPS: A Reinforcement Learning–Based Framework for Personalized Search",
    "doi": "https://doi.org/10.1145/3446617",
    "publication_date": "2021-05-05",
    "publication_year": 2021,
    "authors": "Jing Yao; Zhicheng Dou; Jun Xu; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Personalized search is a promising way to improve search qualities by taking user interests into consideration. Recently, machine learning and deep learning techniques have been successfully applied to search result personalization. Most existing models simply regard the personal search history as a static set of user behaviors and learn fixed ranking strategies based on all the recorded data. Though improvements have been achieved, the essence that the search process is a sequence of interactions between the search engine and user is ignored. The user’s interests may dynamically change during the search process, therefore, it would be more helpful if a personalized search model could track the whole interaction process and adjust its ranking strategy continuously. In this article, we adapt reinforcement learning to personalized search and propose a framework, referred to as RLPS. It utilizes a Markov Decision Process ( MDP ) to track sequential interactions between the user and search engine, and continuously update the underlying personalized ranking model with the user’s real-time feedback to learn the user’s dynamic interests. Within this framework, we implement two models: the listwise RLPS-L and the hierarchical RLPS-H. RLPS-L interacts with users and trains the ranking model with document lists, while RLPS-H improves model training by designing a layered structure and introducing document pairs. In addition, we also design a feedback-aware personalized ranking component to capture the user’s feedback, which impacts the user interest profile for the next query. Significant improvements over existing personalized search models are observed in the experiments on the public AOL search log and a commercial log.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3159789144",
    "type": "article"
  },
  {
    "title": "Modeling Global and Local Interactions for Online Conversation Recommendation",
    "doi": "https://doi.org/10.1145/3473970",
    "publication_date": "2021-11-17",
    "publication_year": 2021,
    "authors": "Xingshan Zeng; Jing Li; Lingzhi Wang; Kam‐Fai Wong",
    "corresponding_authors": "",
    "abstract": "The popularity of social media platforms results in a huge volume of online conversations produced every day. To help users better engage in online conversations, this article presents a novel framework to automatically recommend conversations to users based on what they said and how they behaved in their chatting histories. While prior work mostly focuses on post-level recommendation, we aim to explore conversation context and model the interaction patterns therein. Furthermore, to characterize personal interests from interleaving user interactions, we learn (1) global interactions , represented by topic and discourse word clusters to reflect users’ content and pragmatic preferences, and (2) local interactions , encoding replying relations and chronological order of conversation turns to characterize users’ prior behavior. Built on collaborative filtering, our model captures global interactions via discovering word distributions to represent users’ topical interests and discourse behaviors, while local interactions are explored with graph-structured networks exploiting both reply structure and temporal features. Extensive experiments on three datasets from Twitter and Reddit show that our model coupling global and local interactions significantly outperforms the state-of-the-art model. Further analyses show that our model is able to capture meaningful features from global and local interactions, which results in its superior performance in conversation recommendation.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4200108907",
    "type": "article"
  },
  {
    "title": "LkeRec: Toward Lightweight End-to-End Joint Representation Learning for Building Accurate and Effective Recommendation",
    "doi": "https://doi.org/10.1145/3486673",
    "publication_date": "2021-12-14",
    "publication_year": 2021,
    "authors": "Surong Yan; Kwei-Jay Lin; Xiaolin Zheng; Haosen Wang",
    "corresponding_authors": "",
    "abstract": "Explicit and implicit knowledge about users and items have been used to describe complex and heterogeneous side information for recommender systems (RSs). Many existing methods use knowledge graph embedding (KGE) to learn the representation of a user-item knowledge graph (KG) in low-dimensional space. In this article, we propose a lightweight end-to-end joint learning framework for fusing the tasks of KGE and RSs at the model level. Our method proposes a lightweight KG embedding method by using bidirectional bijection relation-type modeling to enable scalability for large graphs while using self-adaptive negative sampling to optimize negative sample generating. Our method further generates the integrated views for users and items based on relation-types to explicitly model users’ preferences and items’ features, respectively. Finally, we add virtual “recommendation” relations between the integrated views of users and items to model the preferences of users on items, seamlessly integrating RS with user-item KG over a unified graph. Experimental results on multiple datasets and benchmarks show that our method can achieve a better accuracy of recommendation compared with existing state-of-the-art methods. Complexity and runtime analysis suggests that our method can gain a lower time and space complexity than most of existing methods and improve scalability.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4200212775",
    "type": "article"
  },
  {
    "title": "Metrics and Algorithms for Routing Questions to User Communities",
    "doi": "https://doi.org/10.1145/2724706",
    "publication_date": "2015-03-09",
    "publication_year": 2015,
    "authors": "Aditya Pal",
    "corresponding_authors": "Aditya Pal",
    "abstract": "An online community consists of a group of users who share a common interest, background, or experience, and their collective goal is to contribute toward the welfare of the community members. Several websites allow their users to create and manage niche communities, such as Yahoo! Groups, Facebook Groups, Google+ Circles, and WebMD Forums. These community services also exist within enterprises, such as IBM Connections. Question answering within these communities enables their members to exchange knowledge and information with other community members. However, the onus of finding the right community for question asking lies with an individual user. The overwhelming number of communities necessitates the need for a good question routing strategy so that new questions get routed to an appropriately focused community and thus get resolved in a reasonable time frame. In this article, we consider the novel problem of routing a question to the right community and propose a framework for selecting and ranking the relevant communities for a question. We propose several novel features for modeling the three main entities of the system: questions, users, and communities. We propose features such as language attributes, inclination to respond, user familiarity, and difficulty of a question; based on these features, we propose similarity metrics between the routed question and the system entities. We introduce a Cutoff-Aggregation ( CA ) algorithm that aggregates the entity similarity within a community to compute that community's relevance. We introduce two k -nearest-neighbor ( knn ) algorithms that are a natural instantiation of the CA algorithm, which are computationally efficient and evaluate several ranking algorithms over the aggregate similarity scores computed by the two knn algorithms. We propose clustering techniques to speed up our recommendation framework and show how pipelining can improve the model performance. We demonstrate the effectiveness of our framework on two large real-world datasets.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2074143256",
    "type": "article"
  },
  {
    "title": "Answering Arabic Why-Questions",
    "doi": "https://doi.org/10.1145/2950049",
    "publication_date": "2016-09-07",
    "publication_year": 2016,
    "authors": "Aqil M. Azmi; Nouf AlShenaifi",
    "corresponding_authors": "",
    "abstract": "A Question Answering (QA) system is concerned with building a system that automatically answer questions posed by humans in a natural language. Compared to other languages, little effort was directed towards QA systems for Arabic. Due to the difficulty of handling why -questions, most Arabic QA systems tend to ignore it. In this article, we specifically address the why -question for Arabic using two different approaches and compare their performance and the quality of their answer. The first is the baseline approach, a generic method that is used to answer all types of questions, including factoid; and for the second approach, we use Rhetorical Structure Theory (RST). We evaluate both schemes using a corpus of 700 textual documents in different genres collected from Open Source Arabic Corpora (OSAC), and a set of 100 question-answer pairs. Overall, the performance measures of recall, precision, and c@1 was 68% (all three measures) for the baseline approach, and 71%, 78%, and 77.4%, respectively, for the RST-based approach. The recently introduced extension of the accuracy, the c@1 measure, rewards unanswered questions over those wrongly answered.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2515224663",
    "type": "article"
  },
  {
    "title": "Intent-Oriented Dynamic Interest Modeling for Personalized Web Search",
    "doi": "https://doi.org/10.1145/3639817",
    "publication_date": "2024-01-08",
    "publication_year": 2024,
    "authors": "Yutong Bai; Yujia Zhou; Zhicheng Dou; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Given a user, a personalized search model relies on her historical behaviors, such as issued queries and their clicked documents, to generate an interest profile and personalize search results accordingly. In interest profiling, most existing personalized search approaches use “static” document representations as the inputs, which do not change with the current search. However, a document is usually long and contains multiple pieces of information, a static fix-length document vector is usually insufficient to represent the important information related to the original query or the current query, and makes the profile noisy and ambiguous. To tackle this problem, we propose building dynamic and intent-oriented document representations which highlight important parts of a document rather than simply encode the entire text. Specifically, we divide each document into multiple passages, and then separately use the original query and the current query to interact with the passages. Thereafter we generate two “dynamic” document representations containing the key information around the historical and the current user intent, respectively. We then profile interest by capturing the interactions between these document representations, the historical queries, and the current query. Experimental results on a real-world search log dataset demonstrate that our model significantly outperforms state-of-the-art personalization methods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4390658770",
    "type": "article"
  },
  {
    "title": "Can Perturbations Help Reduce Investment Risks? Risk-aware Stock Recommendation via Split Variational Adversarial Training",
    "doi": "https://doi.org/10.1145/3643131",
    "publication_date": "2024-01-25",
    "publication_year": 2024,
    "authors": "Jiezhu Cheng; Kaizhu Huang; Zibin Zheng",
    "corresponding_authors": "",
    "abstract": "In the stock market, a successful investment requires a good balance between profits and risks. Based on the learning to rank paradigm, stock recommendation has been widely studied in quantitative finance to recommend stocks with higher return ratios for investors. Despite the efforts to make profits, many existing recommendation approaches still have some limitations in risk control, which may lead to intolerable paper losses in practical stock investing. To effectively reduce risks, we draw inspiration from adversarial learning and propose a novel Split Variational Adversarial Training (SVAT) method for risk-aware stock recommendation. Essentially, SVAT encourages the stock model to be sensitive to adversarial perturbations of risky stock examples and enhances the model’s risk awareness by learning from perturbations. To generate representative adversarial examples as risk indicators, we devise a variational perturbation generator to model diverse risk factors. Particularly, the variational architecture enables our method to provide a rough risk quantification for investors, showing an additional advantage of interpretability. Experiments on several real-world stock market datasets demonstrate the superiority of our SVAT method. By lowering the volatility of the stock-recommendation model, SVAT effectively reduces investment risks and outperforms state-of-the-art baselines by more than 30% in terms of risk-adjusted profits. All the experimental data and source code are available at https://drive.google.com/drive/folders/14AdM7WENEvIp5x5bV3zV_i4Aev21C9g6?usp=sharing .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4391222213",
    "type": "article"
  },
  {
    "title": "Revisiting Bag of Words Document Representations for Efficient Ranking with Transformers",
    "doi": "https://doi.org/10.1145/3640460",
    "publication_date": "2024-02-09",
    "publication_year": 2024,
    "authors": "David Rau; Mostafa Dehghani; Jaap Kamps",
    "corresponding_authors": "",
    "abstract": "Modern transformer-based information retrieval models achieve state-of-the-art performance across various benchmarks. The self-attention of the transformer models is a powerful mechanism to contextualize terms over the whole input but quickly becomes prohibitively expensive for long input as required in document retrieval. Instead of focusing on the model itself to improve efficiency, this paper explores different bag of words document representations that encode full documents by only a fraction of their characteristic terms, allowing us to control and reduce the input length. We experiment with various models for document retrieval on MS MARCO data, as well as zero-shot document retrieval on Robust04, and show large gains in efficiency while retaining reasonable effectiveness. Inference time efficiency gains are both lowering the time and memory complexity in a controllable way, allowing for further trading off memory footprint and query latency. More generally, this line of research connects traditional IR models with neural “NLP” models and offers novel ways to explore the space between (efficient, but less effective) traditional rankers and (effective, but less efficient) neural rankers elegantly.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4391680357",
    "type": "article"
  },
  {
    "title": "Filter-based Stance Network for Rumor Verification",
    "doi": "https://doi.org/10.1145/3649462",
    "publication_date": "2024-02-26",
    "publication_year": 2024,
    "authors": "Jun Li; Yi Bin; Yunshan Ma; Yang Yang; Zi Huang; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Rumor verification on social media aims to identify the truth value of a rumor, which is important to decrease the detrimental public effects. A rumor might arouse heated discussions and replies, conveying different stances of users that could be helpful in identifying the rumor. Thus, several works have been proposed to verify a rumor by modelling its entire stance sequence in the time domain. However, these works ignore that such a stance sequence could be decomposed into controversies with different intensities, which could be used to cluster the stance sequences with the same consensus. In addition, the existing stance extractors fail to consider both the impact of all previously posted tweets and the reply chain on obtaining the stance of a new reply. To address the above problems, in this article, we propose a novel stance-based network to aggregate the controversies of the stance sequence for rumor verification, termed Filter-based Stance Network (FSNet). As controversies with different intensities are reflected as the different changes of stances, it is convenient to represent different controversies in the frequency domain, but it is hard in the time domain. Our proposed FSNet decomposes the stance sequence into multiple controversies in the frequency domain and obtains the weighted aggregation of them. Specifically, FSNet consists of two modules: the stance extractor and the filter block. To obtain better stance features toward the source, the stance extractor contains two stages. In the first stage, the tweet representation of each reply is obtained by aggregating information from all previously posted tweets in a conversation. Then, the features of stance toward the source, i.e., rumor-aware stance, are extracted with the reply chains in the second stage. In the filter block module, a rumor-aware stance sequence is constructed by sorting all the tweets of a conversation in chronological order. Fourier Transform thereafter is employed to convert the stance sequence into the frequency domain, where different frequency components reflect controversies of different intensities. Finally, a frequency filter is applied to explore the different contributions of controversies. We supervise our FSNet with both stance labels and rumor labels to strengthen the relations between rumor veracity and crowd stances. Extensive experiments on two benchmark datasets demonstrate that our model substantially outperforms all the baselines.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4392163092",
    "type": "article"
  },
  {
    "title": "Cross-Model Comparative Loss for Enhancing Neuronal Utility in Language Understanding",
    "doi": "https://doi.org/10.1145/3652599",
    "publication_date": "2024-03-15",
    "publication_year": 2024,
    "authors": "Yunchang Zhu; Liang Pang; Kangxi Wu; Yanyan Lan; Huawei Shen; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "Current natural language understanding (NLU) models have been continuously scaling up, both in terms of model size and input context, introducing more hidden and input neurons. While this generally improves performance on average, the extra neurons do not yield a consistent improvement for all instances. This is because some hidden neurons are redundant, and the noise mixed in input neurons tends to distract the model. Previous work mainly focuses on extrinsically reducing low-utility neurons by additional post- or pre-processing, such as network pruning and context selection, to avoid this problem. Beyond that, can we make the model reduce redundant parameters and suppress input noise by intrinsically enhancing the utility of each neuron? If a model can efficiently utilize neurons, no matter which neurons are ablated (disabled), the ablated submodel should perform no better than the original full model. Based on such a comparison principle between models, we propose a cross-model comparative loss for a broad range of tasks. Comparative loss is essentially a ranking loss on top of the task-specific losses of the full and ablated models, with the expectation that the task-specific loss of the full model is minimal. We demonstrate the universal effectiveness of comparative loss through extensive experiments on 14 datasets from three distinct NLU tasks based on five widely used pre-trained language models and find it particularly superior for models with few parameters or long input.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4392849927",
    "type": "article"
  },
  {
    "title": "SPContrastNet: A Self-Paced Contrastive Learning Model for Few-Shot Text Classification",
    "doi": "https://doi.org/10.1145/3652600",
    "publication_date": "2024-03-20",
    "publication_year": 2024,
    "authors": "Junfan Chen; Richong Zhang; Xiaohan Jiang; Chunming Hu",
    "corresponding_authors": "",
    "abstract": "Meta-learning has recently promoted few-shot text classification, which identifies target classes based on information transferred from source classes through a series of small tasks or episodes. Existing works constructing their meta-learner on Prototypical Networks need improvement in learning discriminative text representations between similar classes that may lead to conflicts in label prediction. The overfitting problems caused by a few training instances need to be adequately addressed. In addition, efficient episode sampling procedures that could enhance few-shot training should be utilized. To address the problems mentioned above, we first present a contrastive learning framework that simultaneously learns discriminative text representations via supervised contrastive learning while mitigating the overfitting problem via unsupervised contrastive regularization, and then we build an efficient self-paced episode sampling approach on top of it to include more difficult episodes as training progresses. Empirical results on eight few-shot text classification datasets show that our model outperforms the current state-of-the-art models. The extensive experimental analysis demonstrates that our supervised contrastive representation learning and unsupervised contrastive regularization techniques improve the performance of few-shot text classification. The episode-sampling analysis reveals that our self-paced sampling strategy improves training efficiency.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4393002364",
    "type": "article"
  },
  {
    "title": "Passage-aware Search Result Diversification",
    "doi": "https://doi.org/10.1145/3653672",
    "publication_date": "2024-03-21",
    "publication_year": 2024,
    "authors": "Zhan Su; Zhicheng Dou; Yutao Zhu; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Research on search result diversification strives to enhance the variety of subtopics within the list of search results. Existing studies usually treat a document as a whole and represent it with one fixed-length vector. However, considering that a long document could cover different aspects of a query, using a single vector to represent the document is usually insufficient. To tackle this problem, we propose to exploit multiple passages to better represent documents in search result diversification. Different passages of each document may reflect different subtopics of the query and comparison among the passages can improve result diversity. Specifically, we segment the entire document into multiple passages and train a classifier to filter out the irrelevant ones. Then the document diversity is measured based on several passages that can offer the information needs of the query. Thereafter, we devise a passage-aware search result diversification framework that takes into account the topic information contained in the selected document sequence and candidate documents. The candidate documents’ novelty is evaluated based on their passages while considering the dynamically selected document sequence. We conducted experiments on a commonly utilized dataset, and the results indicate that our proposed method performs better than the most leading methods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4393041431",
    "type": "article"
  },
  {
    "title": "Graph Augmentation Empowered Contrastive Learning for Recommendation",
    "doi": "https://doi.org/10.1145/3677377",
    "publication_date": "2024-07-12",
    "publication_year": 2024,
    "authors": "Lixiang Xu; Yusheng Liu; Tong Xu; Enhong Chen; Yuanyan Tang",
    "corresponding_authors": "",
    "abstract": "The application of contrastive learning (CL) to collaborative filtering (CF) in recommender systems has achieved remarkable success. CL-based recommendation models mainly focus on creating multiple augmented views by employing different graph augmentation methods and utilizing these views for self-supervised learning. However, current CL methods for recommender systems usually struggle to fully address the problem of noisy data. To address this problem, we propose the G raph A ugmentation E mpowered C ontrastive L earning (GAECL) for recommendation framework, which uses graph augmentation based on topological and semantic dual adaptation and global co-modeling via structural optimization to co-create contrasting views for better augmentation of the CF paradigm. Specifically, we strictly filter out unimportant topologies by reconstructing the adjacency matrix and mask unimportant attributes in nodes according to the PageRank centrality principle to generate an augmented view that filters out noisy data. Additionally, GAECL achieves global collaborative modeling through structural optimization and generates another augmented view based on the PageRank centrality principle. This helps to filter the noisy data while preserving the original semantics of the data for more effective data augmentation. Extensive experiments are conducted on five datasets to demonstrate the superior performance of our model over various recommendation models.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4400581069",
    "type": "article"
  },
  {
    "title": "A Knowledge Graph Embedding Model for Answering Factoid Entity Questions",
    "doi": "https://doi.org/10.1145/3678003",
    "publication_date": "2024-07-15",
    "publication_year": 2024,
    "authors": "Parastoo Jafarzadeh; Faezeh Ensan; Mahdiyar Ali Akbar Alavi; Fattane Zarrinkalam",
    "corresponding_authors": "",
    "abstract": "Factoid entity questions (FEQ), which seek answers in the form of a single entity from knowledge sources such as DBpedia and Wikidata, constitute a substantial portion of user queries in search engines. This paper introduces the Knowledge Graph Embedding model for Factoid Entity Question answering (KGE-FEQ). Leveraging a textual knowledge graph derived from extensive text collections, KGE-FEQ encodes textual relationships between entities. The model employs a two-step process: (1) Triple Retrieval, where relevant triples are retrieved from the textual knowledge graph based on semantic similarities to the question, and (2) Answer Selection, where a knowledge graph embedding approach is utilized for answering the question. This involves positioning the embedding for the answer entity close to the embedding of the question entity, incorporating a vector representing the question and textual relations between entities. Extensive experiments evaluate the performance of the proposed approach, comparing KGE-FEQ to state-of-the-art baselines in factoid entity question answering and the most advanced open-domain question answering techniques applied to FEQs. The results show that KGE-FEQ outperforms existing methods across different datasets. Ablation studies highlights the effectiveness of KGE-FEQ when both the question and textual relations between entities are considered for answering questions.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4400650325",
    "type": "article"
  },
  {
    "title": "CAME: Competitively Learning a Mixture-of-Experts Model for First-stage Retrieval",
    "doi": "https://doi.org/10.1145/3678880",
    "publication_date": "2024-07-22",
    "publication_year": 2024,
    "authors": "Jiafeng Guo; Yinqiong Cai; Keping Bi; Yixing Fan; Wei Chen; Ruqing Zhang; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "The first-stage retrieval aims to retrieve a subset of candidate documents from a huge collection both effectively and efficiently. Since various matching patterns can exist between queries and relevant documents, previous work tries to combine multiple retrieval models to find as many relevant results as possible. The constructed ensembles, whether learned independently or jointly, do not care which component model is more suitable to an instance during training. Thus, they cannot fully exploit the capabilities of different types of retrieval models in identifying diverse relevance patterns. Motivated by this observation, in this paper, we propose a Mixture-of-Experts (MoE) model consisting of representative matching experts and a novel competitive learning mechanism to let the experts develop and enhance their expertise during training. Specifically, our MoE model shares the bottom layers to learn common semantic representations and uses differently structured upper layers to represent various types of retrieval experts. Our competitive learning mechanism has two stages: (1) a standardized learning stage to train the experts equally to develop their capabilities to conduct relevance matching; (2) a specialized learning stage where the experts compete with each other on every training instance and get rewards and updates according to their performance to enhance their expertise on certain types of samples. Experimental results on retrieval benchmark datasets show that our method significantly outperforms the state-of-the-art baselines in the in-domain and out-of-domain settings.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4400879993",
    "type": "article"
  },
  {
    "title": "SECON: Maintaining Semantic Consistency in Data Augmentation for Code Search",
    "doi": "https://doi.org/10.1145/3686151",
    "publication_date": "2024-08-01",
    "publication_year": 2024,
    "authors": "Xu Zhang; Z.-P. Lin; Xiaoyu Hu; J.Q. Wang; Wenpeng Lü; Deyu Zhou",
    "corresponding_authors": "",
    "abstract": "Efficient code search techniques are crucial in accelerating software development by aiding developers in locating specific code snippets and understanding code functionalities. This study investigates code search methodologies, focusing on the emerging significance of semantic consistency in data augmentation techniques. While existing approaches predominantly enhance raw data, often requiring additional preprocessing and incurring higher training costs, this research introduces a pioneering method operating at the code and query representation levels. By bypassing the need for extensive data processing, this novel approach fosters an interactive alignment between code and query, augmenting the semantic coherence crucial for effective code search. An extensive empirical evaluation of a diverse dataset across multiple programming languages substantiates the efficacy of this approach in significantly enhancing code search model performance compared to traditional methodologies. The implementation is publicly available on GitHub 1 , offering an accessible resource for further exploration and application.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4401214385",
    "type": "article"
  },
  {
    "title": "PEPT: Expert Finding Meets Personalized Pre-training",
    "doi": "https://doi.org/10.1145/3690380",
    "publication_date": "2024-08-28",
    "publication_year": 2024,
    "authors": "Qiyao Peng; Hongyan Xu; Yinghui Wang; Hongtao Liu; Cuiying Huo; Wenjun Wang",
    "corresponding_authors": "",
    "abstract": "Finding experts is essential in Community Question Answering (CQA) platforms as it enables the effective routing of questions to potential users who can provide relevant answers. The key is to personalized learning expert representations based on their historical answered questions, and accurately matching them with target questions. Recently, the applications of Pre-Trained Language Models (PLMs) have gained significant attraction due to their impressive capability to comprehend textual data, and are widespread used across various domains. There have been some preliminary works exploring the usability of PLMs in expert finding, such as pre-training expert or question representations. However, these models usually learn pure text representations of experts from histories, disregarding personalized and fine-grained expert modeling. For alleviating this, we present a personalized pre-training and fine-tuning paradigm, which could effectively learn expert interest and expertise simultaneously. Specifically, in our pre-training framework, we integrate historical answered questions of one expert with one target question, and regard it as a candidate-aware expert-level input unit. Then, we fuse expert IDs into the pre-training for guiding the model to model personalized expert representations, which can help capture the unique characteristics and expertise of each individual expert. Additionally, in our pre-training task, we design (1) a question-level masked language model task to learn the relatedness between histories, enabling the modeling of question-level expert interest; (2) a vote-oriented task to capture question-level expert expertise by predicting the vote score the expert would receive. Through our pre-training framework and tasks, our approach could holistically learn expert representations including interests and expertise. Our method has been extensively evaluated on six real-world CQA datasets, and the experimental results consistently demonstrate the superiority of our approach over competitive baseline methods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4401952267",
    "type": "article"
  },
  {
    "title": "Unsupervised Video Moment Retrieval with Knowledge-based Pseudo Supervision Construction",
    "doi": "https://doi.org/10.1145/3701229",
    "publication_date": "2024-10-19",
    "publication_year": 2024,
    "authors": "Guolong Wang; Xun Wu; Xun Tu; Zhaoyuan Liu; Junchi Yan",
    "corresponding_authors": "",
    "abstract": "Video moment retrieval locates a specified moment by a sentence query. Recent approaches have made remarkable advancements with large-scale video-sentence annotations. These annotations require extensive human labor and expertise, leading to the need for unsupervised fashion. Generating pseudo-supervision from videos is an effective strategy. With the power of the large-scale pre-trained model, we introduce knowledge into constructing pseudo-supervision. The main technical challenge is improving pseudo-supervision diversity and alleviating noise brought by external knowledge. To address these problems, we propose two Knowledge-based Pseudo Supervision Construction (KPSC) strategies: KPSC-P and KPSC-F. They all follow two steps: generating diverse samples and alleviating knowledge chaos. The main difference is that the former first learns a representation space with prompt tuning, while the latter directly utilizes data information. KPSC-P has two modules: 1) Proposal Prompt (PP): Generate temporal proposals; 2) Verb Prompt (VP): Generate pseudo-queries with noun-verb patterns. KPSC-F also has two modules: 1) Captioner: Generating candidate queries; 2) Filter: Alleviating knowledge chaos. Thus, our KPSC involves two attempts to extract knowledge from pre-trained models. Extensive experiments show that our attempts outperform the existing unsupervised methods on two public datasets (Charades-STA and ActivityNet-Captions) and perform on par with several methods using stronger supervision.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4403560362",
    "type": "article"
  },
  {
    "title": "MF-GSLAE: A Multi-Factor User Representation Pre-training Framework for Dual-Target Cross-Domain Recommendation",
    "doi": "https://doi.org/10.1145/3690382",
    "publication_date": "2024-10-24",
    "publication_year": 2024,
    "authors": "Hao Wang; Mingjia Yin; Luankang Zhang; Sirui Zhao; Enhong Chen",
    "corresponding_authors": "",
    "abstract": "Recently, the dual-target cross-domain recommendation has been an emerging research problem, which aims to improve the performances of both source and target domains by transferring the preferences of overlapping users. Most of the existing work adopted a coarse-grained manner to detach general users’ preferences and associate them with domain-specific information for enhancing user representation learning, which fails to depict the differences in users’ diverse preferences and aggregate relevant preferences with improper propagation. To this end, in this paper, we propose a multi-factor user representation pretraining framework, dubbed MF-GSLAE, with a focus on fine-grained preference learning and transferring. Specifically, we first propose a fine-grained factor representation pre-training paradigm. It projects the behavior records of both domains into several subspaces and introduces a compactness regularization to generate multiple fine-grained preference factors. Furthermore, we propose a multi-factor graph structure learning method within linear complexity to efficiently construct preference connections on different scales of users, which could aggregate the intrinsic relationship of user preferences in immediate embedding spaces to capture high-order information. Following the pre-training, we subsequently design a factor selection module with the bootstrapping mechanism to adaptively choose the corresponding domain-related preferences and transfer domain-shared information through partial overlapping factors for addressing the negative transfer problem. Finally, the optimization objectives of both domains are formalized in a multi-task learning framework and derive the learned user representation in an end-to-end training manner. Extensive experimental results on several publicly available datasets have not only demonstrated the effectiveness of the learned user representations with the comparison of state-of-the-art baselines but also indicated the interpretability and robustness. The code of our work is publicly available at https://github.com/USTC-StarTeam/MF-GSLAE .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4403735307",
    "type": "article"
  },
  {
    "title": "TCKT: Tree-Based Cross-domain Knowledge Transfer for Next POI Cold-Start Recommendation",
    "doi": "https://doi.org/10.1145/3709137",
    "publication_date": "2024-12-24",
    "publication_year": 2024,
    "authors": "Xi He; Yilin Liu; Weikang He; Xin Xing; Xingyu Lu; Yanbing Liu",
    "corresponding_authors": "",
    "abstract": "The next point of interest (POI) recommendation task recommends POIs to users that they may be interested in next time based on their historical trajectories. This task holds value for both users and businesses. However, it has consistently faced the issue of cold-start caused by sparse user check-in data. Existing research mainly focuses on knowledge transfer among cities within the same data source, but these data are very rare. The abundance of available third-party data presents opportunities to improve cold-start performance, but it is not easy. This third-party data contains numerous entities, such as POIs and users, which have different representations and distributions across different data domains, making knowledge transfer difficult. To address these challenges, we propose the Tree-Based Cross-domain Knowledge Transfer (TCKT) model. First, we construct a multi-granularity Geographical Frequency Tree (GF-Tree), transforming the POI recommendation problem into a path generation problem. Second, we design a pre-training model to mine general user behavior patterns and spatio-temporal features among POIs from large-scale third-party data. Finally, we propose a dual-channel domain adaptation model to facilitate cross-domain knowledge transfer and improve cold-start performance. Experimental results on three public datasets demonstrate that our method outperforms state-of-the-art (SOTA) baseline methods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4405735954",
    "type": "article"
  },
  {
    "title": "On the expressive power of query languages",
    "doi": "https://doi.org/10.1145/174608.174611",
    "publication_date": "1994-01-02",
    "publication_year": 1994,
    "authors": "Peter Scháuble; Beat Wüthrich",
    "corresponding_authors": "",
    "abstract": "Two main topics are addressed. First, an algebraic approach is presented to define a general notion of expressive power. Heterogeneous algebras represent information systems and morphisms represent the correspondences between the instances of databases, the correspondences between answers, and the correspondences between queries. An important feature of this new notion of expressive power is that query languages of different types can be compared with respect to their expressive power. In the case of relational query languages, the new notion of expressive power is shown to be equivalent to the notion used by Chandra and Harel. In the case of nonrelational query languages, the versatility of the new notion of expressive power is demonstrated by comparing the fixpoint query languages with an object-oriented query language called FQL. The expressive power of the Functional Query Language FQL is the second main topic of this paper. The specifications of FQL functions can be recursive or even mutually recursive, FQL has a fixpoint semantics based on a complete lattice consisting of bag functions. The query language FQL is shown to be more expressive than the fixpoint query languages. This result implies that FQL is also more expressive than Datalog with stratified negation. Examples of recursive FQL functions are given that determine the ancestors of persons and the bill of materials.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2038650947",
    "type": "article"
  },
  {
    "title": "Consistency, standards, and formal approaches to interface development and evaluation",
    "doi": "https://doi.org/10.1145/128756.128760",
    "publication_date": "1992-01-02",
    "publication_year": 1992,
    "authors": "Jonathan Grudin",
    "corresponding_authors": "Jonathan Grudin",
    "abstract": "article Free AccessConsistency, standards, and formal approaches to interface development and evaluation: a note on Wiecha, Bennett, Boies, Gould, and Greene Author: Jonathan Grudin University of California, Irvine University of California, IrvineView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 10Issue 1Jan. 1992 pp 103–111https://doi.org/10.1145/128756.128760Published:02 January 1992Publication History 15citation644DownloadsMetricsTotal Citations15Total Downloads644Last 12 Months60Last 6 weeks8 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2134750061",
    "type": "article"
  },
  {
    "title": "Document ranking on weight-partitioned signature files",
    "doi": "https://doi.org/10.1145/226163.226164",
    "publication_date": "1996-04-01",
    "publication_year": 1996,
    "authors": "Dik Lun Lee; Liming Ren",
    "corresponding_authors": "",
    "abstract": "A signature file organization, called the weight-partitioned signature file, for supporting document ranking is proposed. It employs multiple signature files, each of which corresponds to one term frequency, to represent terms with different term frequencies. Words with the same term frequency in a document are grouped together and hashed into the signature file corresponding to that term frequency. This eliminates the need to record the term frequency explicitly for each word. We investigate the effect of false drops on retrieval effectiveness if they are not eliminated in the search process. We have shown that false drops introduce insignificant degradation on precision and recall when the false-drop probability is below a certain threshold. This is an important result since false-drop elimination could become the bottleneck in systems using fast signature file search techniques. We perform an analytical study on the performance of the weight-partitioned signature file under different search strategies and configurations. An optimal formula is obtained to determine for a fixed total storage overhead the storage to be allocated to each partition in order to minimize the effect of false drops on document ranks. Experiments were performed using a document collection to support the analytical results.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2064614244",
    "type": "article"
  },
  {
    "title": "Modeling word occurrences for the compression of concordances",
    "doi": "https://doi.org/10.1145/256163.256166",
    "publication_date": "1997-07-01",
    "publication_year": 1997,
    "authors": "Abraham Bookstein; Shmuel T. Klein; T. Raita",
    "corresponding_authors": "",
    "abstract": "An earlier paper developed a procedure for compressing concordances, assuming that all alements occurred independently. The models introduced in that paper are extended here to take the possiblity of clustering into account. The concordance is conceptualized as a set of bitmaps, in which the bit locations reporesent documents, and the one-bits represent the occurrence of given terms. Hidden Markov Models (HMM's) are used to describe the clustering of the one-bits. However, for computational reasons, the HMM is approximated by traditional Markov models. A set of criteria is developed to constrain the allowable set of n -state models, and a full inventory is given for n ≤ 4. Graph-theoretic reduction and complementation operations are defined among the various models and are used to provide a structure relating the models studied. Finally, the new methods were tested on the concordances of the English Bible and of two of the world's largest full-text retrieval systems: the Tre´sor de la Langue Franc¸aise and the Responsa Project.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2086348764",
    "type": "article"
  },
  {
    "title": "An intelligent approach to handling imperfect information in concept-based natural language queries",
    "doi": "https://doi.org/10.1145/568727.568729",
    "publication_date": "2002-07-01",
    "publication_year": 2002,
    "authors": "Vesper Owei",
    "corresponding_authors": "Vesper Owei",
    "abstract": "Missing information, imprecision, inconsistency, vagueness, uncertainty, and ignorance abound in information systems. Such imperfection is a fact of life in database systems. Although these problems are widely studied in relational database systems, this is not the case in conceptual query systems. And yet, concept-based query languages have been proposed and some are already commercial products. It is therefore imperative to study these problems in concept-based query languages, with a view to prescribing formal approaches to dealing with the problems. In this article, we have done just that for a concept-based natural language query system that we developed. A methodology for handling and resolving each type of imperfection is developed. The proposed approaches are automated as much as possible, with the user mainly serving an assistive function.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1992871598",
    "type": "article"
  },
  {
    "title": "A Butler process for resource sharing on Spice machines",
    "doi": "https://doi.org/10.1145/4229.4234",
    "publication_date": "1985-07-01",
    "publication_year": 1985,
    "authors": "Roger B. Dannenberg; Peter Hibbard",
    "corresponding_authors": "",
    "abstract": "A network of personal computers may contain a large amount of distributed computing resources. For a number of reasons it is desirable to share these resources, but sharing is complicated by issues of security and autonomy. A process known as the Butler addresses these problems and provides support for resource sharing. The Butler relies upon a capability-based accounting system called the Banker to monitor the use of local resources.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W1968055044",
    "type": "article"
  },
  {
    "title": "A critical appraisal of task taxonomies as a tool for studying office activities",
    "doi": "https://doi.org/10.1145/2275.2279",
    "publication_date": "1984-10-01",
    "publication_year": 1984,
    "authors": "Christopher A. Higgins; Frank Safayeni",
    "corresponding_authors": "",
    "abstract": "article Free AccessA critical appraisal of task taxonomies as a tool for studying office activities Authors: Christopher A. Higgins Univ. of Western Ontario, London, Ont., Canada Univ. of Western Ontario, London, Ont., CanadaView Profile , Frank R. Safayeni Univ. of Waterloo, Waterloo, Ont., Canada Univ. of Waterloo, Waterloo, Ont., CanadaView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 4Oct. 1984 pp 331–339https://doi.org/10.1145/2275.2279Published:01 October 1984Publication History 10citation473DownloadsMetricsTotal Citations10Total Downloads473Last 12 Months13Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W1996091178",
    "type": "article"
  },
  {
    "title": "A methodology for analyzing SAGE libraries for cancer profiling",
    "doi": "https://doi.org/10.1145/1055709.1055712",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Jörg Sander; Raymond T. Ng; Monica C. Sleumer; Man Saint Yuen; Steven J.M. Jones",
    "corresponding_authors": "",
    "abstract": "Serial Analysis of Gene Expression (SAGE) has proven to be an important alternative to microarray techniques for global profiling of mRNA populations. We have developed preprocessing methodologies to address problems in analyzing SAGE data due to noise caused by sequencing error, normalization methodologies to account for libraries sampled at different depths, and missing tag imputation methodologies to aid in the analysis of poorly sampled SAGE libraries. We have also used subspace selection using the Wilcoxon rank sum test to exclude tags that have similar expression levels regardless of source. Using these methodologies we have clustered, using the OPTICS algorithm, 88 SAGE libraries derived from cancerous and normal tissues as well as cell line material. Our results produced eight dense clusters representing ovarian cancer cell line, brain cancer cell line, brain cancer bulk tissue, prostate tissue, pancreatic cancer, breast cancer cell line, normal brain, and normal breast bulk tissue. The ovarian cancer and brain cancer cell lines clustered closely together, leading to a further investigation on possible associations between these two cancer types. We also investigated the utility of gene expression data in the classification between normal and cancerous tissues. Our results indicate that brain and breast cancer libraries have strong identities allowing robust discrimination from their normal counterparts. However, the SAGE expression data provide poor predictive accuracy in discriminating between prostate and ovarian cancers and their respective normal tissues.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1969806156",
    "type": "article"
  },
  {
    "title": "An Integrated Signature-Based Framework for Efficient Visual Similarity Detection and Measurement in Video Shots",
    "doi": "https://doi.org/10.1145/3190784",
    "publication_date": "2018-05-27",
    "publication_year": 2018,
    "authors": "Saddam Bekhet; Amr Ahmed",
    "corresponding_authors": "",
    "abstract": "This article presents a framework for speedy video matching and retrieval through detection and measurement of visual similarity. The framework’s efficiency stems from its power to encode a given shot content into a compact fixed-length signature that helps in robust real-time matching. Separate scene and motion signatures are developed and fused together to fully represent and match respective video shots. Scene information is captured through the Statistical Dominant Color Profile (SDCP), while motion information is captured through a graph-based signature called the Dominant Color Graph Profile (DCGP). The SDCP is a fixed-length compact signature that statistically encodes the colors’ spatiotemporal patterns across video frames. The DCGP is a fixed-length signature that records and tracks the gray levels across subsampled video frames, where the graph structural properties are used to extract the signature values. Finally, the overall video signature is generated by fusing the individual scene and motion signatures. The signature-based aspect of the proposed framework is the key to its high matching speed (&gt; 2000 fps) compared to current techniques that rely on exhaustive processing. To maximize the benefit of the framework, compressed-domain videos are utilized as a case study following their wide availability. However, the framework avoids full video decompression and operates on tiny frames rather than full-size decompressed frames. Experiments on various standard and challenging dataset groups show the framework’s robust performance in terms of both retrieval and computational performance.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2806681694",
    "type": "article"
  },
  {
    "title": "Shallow and Deep Syntactic/Semantic Structures for Passage Reranking in Question-Answering Systems",
    "doi": "https://doi.org/10.1145/3233772",
    "publication_date": "2018-11-19",
    "publication_year": 2018,
    "authors": "Kateryna Tymoshenko; Alessandro Moschitti",
    "corresponding_authors": "",
    "abstract": "In this article, we extensively study the use of syntactic and semantic structures obtained with shallow and full syntactic parsers for answer passage reranking. We propose several dependency and constituent-based structures, also enriched with Linked Open Data (LD) knowledge to represent pairs of questions and answer passages. We encode such tree structures in learning-to-rank (L2R) algorithms using tree kernels, which can project them in tree substructure spaces, where each dimension represents a powerful syntactic/semantic feature. Additionally, since we define links between question and passage structures, our tree kernel spaces also include relational structural features. We carried out an extensive comparative experimentation of our models for automatic answer selection benchmarks on different TREC QA corpora as well as the newer Wikipedia-based dataset, namely WikiQA, which has been widely used to test sentence rerankers. The results consistently demonstrate that our structural semantic models achieve the state of the art in passage reranking. In particular, we derived the following important findings: (i) relational syntactic structures are essential to achieve superior results; (ii) models trained with dependency trees can outperform those trained with shallow trees, e.g., in case of sentence reranking; (iii) external knowledge automatically generated with focus and question classifiers is very effective; and (iv) the semantic information derived by LD and incorporated in syntactic structures can be used to replace the knowledge provided by the above-mentioned classifiers. This is a remarkable advantage as it enables our models to increase coverage and portability over new domains.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2901681178",
    "type": "article"
  },
  {
    "title": "Direct posterior confidence for out-of-vocabulary spoken term detection",
    "doi": "https://doi.org/10.1145/2328967.2328969",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Dong Wang; Simon King; Joe Frankel; Ravichander Vipperla; Nicholas Evans; Raphaël Troncy",
    "corresponding_authors": "",
    "abstract": "Spoken term detection (STD) is a key technology for spoken information retrieval. As compared to the conventional speech transcription and keyword spotting, STD is an open-vocabulary task and has to address out-of-vocabulary (OOV) terms. Approaches based on subword units, for example phones, are widely used to solve the OOV issue; however, performance on OOV terms is still substantially inferior to that of in-vocabulary (INV) terms. The performance degradation on OOV terms can be attributed to a multitude of factors. One particular factor we address in this article is the unreliable confidence estimation caused by weak acoustic and language modeling due to the absence of OOV terms in the training corpora. We propose a direct posterior confidence derived from a discriminative model, such as multilayer perceptron (MLP). The new confidence considers a wide-range acoustic context which is usually important for speech recognition and retrieval; moreover, it localizes on detected speech segments and therefore avoids the impact of long-span word context which is usually unreliable for OOV term detection. In this article, we first develop an extensive discussion about the modeling weakness problem associated with OOV terms, and then propose our approach to address this problem based on direct poster confidence. Our experiments carried out on spontaneous and conversational multiparty meeting speech, demonstrate that the proposed technique provides a significant improvement in STD performance as compared to conventional lattice-based confidence, in particular for OOV terms. Furthermore, the new confidence estimation approach is fused with other advanced techniques for OOV treatment, such as stochastic pronunciation modeling and discriminative confidence normalization. This leads to an integrated solution for OOV term detection that results in a large performance improvement.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1980321112",
    "type": "article"
  },
  {
    "title": "Efficient fuzzy search in large text collections",
    "doi": "https://doi.org/10.1145/2457465.2457470",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Hannah Bast; Marjan Celikik",
    "corresponding_authors": "",
    "abstract": "We consider the problem of fuzzy full-text search in large text collections, that is, full-text search which is robust against errors both on the side of the query as well as on the side of the documents. Standard inverted-index techniques work extremely well for ordinary full-text search but fail to achieve interactive query times (below 100 milliseconds) for fuzzy full-text search even on moderately-sized text collections (above 10 GBs of text). We present new preprocessing techniques that achieve interactive query times on large text collections (100 GB of text, served by a single machine). We consider two similarity measures, one where the query terms match similar terms in the collection (e.g., algorithm matches algoritm or vice versa) and one where the query terms match terms with a similar prefix in the collection (e.g., alori matches algorithm). The latter is important when we want to display results instantly after each keystroke (search as you type). All algorithms have been fully integrated into the CompleteSearch engine.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2011971739",
    "type": "article"
  },
  {
    "title": "On Annotation Methodologies for Image Search Evaluation",
    "doi": "https://doi.org/10.1145/3309994",
    "publication_date": "2019-03-27",
    "publication_year": 2019,
    "authors": "Yunqiu Shao; Yiqun Liu; Fan Zhang; Min Zhang; Shaoping Ma",
    "corresponding_authors": "",
    "abstract": "Image search engines differ significantly from general web search engines in the way of presenting search results. The difference leads to different interaction and examination behavior patterns, and therefore requires changes in evaluation methodologies. However, evaluation of image search still utilizes the methods for general web search. In particular, offline metrics are calculated based on coarse-fine topical relevance judgments with the assumption that users examine results in a sequential manner. In this article, we investigate annotation methods via crowdsourcing for image search evaluation based on a lab-based user study. Using user satisfaction as the golden standard, we make several interesting findings. First, instead of item-based annotation, annotating relevance in a row-based way is more efficient without hurting performance. Second, besides topical relevance, image quality plays a crucial role when evaluating the image search results, and the importance of image quality changes with search intent. Third, compared to traditional four-level scales, the fine-grain annotation method outperforms significantly. To our best knowledge, our work is the first to systematically study how diverse factors in data annotation impact image search evaluation. Our results suggest different strategies for exploiting the crowdsourcing to get data annotated under different conditions.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2931686991",
    "type": "article"
  },
  {
    "title": "Understanding Assimilation-contrast Effects in Online Rating Systems",
    "doi": "https://doi.org/10.1145/3362651",
    "publication_date": "2019-10-17",
    "publication_year": 2019,
    "authors": "Xiaoying Zhang; Hong Xie; Junzhou Zhao; John C. S. Lui",
    "corresponding_authors": "",
    "abstract": "“Unbiasedness,” which is an important property to ensure that users’ ratings indeed reflect their true evaluations of products, is vital both in shaping consumer purchase decisions and providing reliable recommendations in online rating systems. Recent experimental studies showed that distortions from historical ratings would ruin the unbiasedness of subsequent ratings. How to “discover” historical distortions in each single rating (or at the micro-level), and perform the “debiasing operations” are our main objective. Using 42M real customer ratings, we first show that users either “assimilate” or “contrast” to historical ratings under different scenarios, which can be further explained by a well-known psychological argument: the “Assimilate-Contrast” theory. This motivates us to propose the Historical Influence Aware Latent Factor Model (HIALF), the “first” model for real rating systems to capture and mitigate historical distortions in each single rating. HIALF allows us to study the influence patterns of historical ratings from a modelling perspective, which perfectly matches the assimilation and contrast effects observed in experiments. Moreover, HIALF achieves significant improvements in predicting subsequent ratings and characterizing relationships in ratings. It also contributes to better recommendations, wiser consumer purchase decisions, and deeper understanding of historical distortions in both honest rating and misbehaving rating settings.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2981055564",
    "type": "article"
  },
  {
    "title": "Large-Alphabet Semi-Static Entropy Coding Via Asymmetric Numeral Systems",
    "doi": "https://doi.org/10.1145/3397175",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Alistair Moffat; Matthias Petri",
    "corresponding_authors": "",
    "abstract": "An entropy coder takes as input a sequence of symbol identifiers over some specified alphabet and represents that sequence as a bitstring using as few bits as possible, typically assuming that the elements of the sequence are independent of each other. Previous entropy coding methods include the well-known Huffman and arithmetic approaches. Here we examine the newer asymmetric numeral systems (ANS) technique for entropy coding and develop mechanisms that allow it to be efficiently used when the size of the source alphabet is large—thousands or millions of symbols. In particular, we examine different ways in which probability distributions over large alphabets can be approximated and in doing so infer techniques that allow the ANS mechanism to be extended to support large-alphabet entropy coding. As well as providing a full description of ANS, we also present detailed experiments using several different types of input, including data streams arising as typical output from the modeling stages of text compression software, and compare theproposed ANS variants with Huffman and arithmetic coding baselines, measuring both compression effectiveness and also encoding and decoding throughput. We demonstrate that in applications in which semi-static compression is appropriate, ANS-based coders can provide an excellent balance between compression effectiveness and speed, even when the alphabet is large.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3041245763",
    "type": "article"
  },
  {
    "title": "An Attention-based Deep Relevance Model for Few-shot Document Filtering",
    "doi": "https://doi.org/10.1145/3419972",
    "publication_date": "2020-10-06",
    "publication_year": 2020,
    "authors": "Bulou Liu; Chenliang Li; Wei Zhou; Feng Ji; Yu Duan; Haiqing Chen",
    "corresponding_authors": "",
    "abstract": "With the large quantity of textual information produced on the Internet, a critical necessity is to filter out the irrelevant information and organize the rest into categories of interest (e.g., an emerging event). However, supervised-learning document filtering methods heavily rely on a large number of labeled documents for model training. Manually identifying plenty of positive examples for each category is expensive and time-consuming. Also, it is unrealistic to cover all the categories from an evolving text source that covers diverse kinds of events, user opinions, and daily life activities. In this article, we propose a novel attention-based deep relevance model for few-shot document filtering (named ADRM), inspired by the relevance feedback methodology proposed for ad hoc retrieval. ADRM calculates the relevance score between a document and a category by taking a set of seed words and a few seed documents relevant to the category. It constructs the category-specific conceptual representation of the document based on the corresponding seed words and seed documents. Specifically, to filter irrelevant yet noisy information in the seed documents, ADRM employs two types of attention mechanisms (namely whole-match attention and max-match attention ) and generates category-specific representations for them. Then ADRM is devised to extract the relevance signals by modeling the hidden feature interactions in the word embedding space. The relevance signals are extracted through a gated convolutional process, a self-attention layer, and a relevance aggregation layer. Extensive experiments on three real-world datasets show that ADRM consistently outperforms the existing technical alternatives, including the conventional classification and retrieval baselines, and the state-of-the-art deep relevance ranking models for few-shot document filtering. We also perform an ablation study to demonstrate that each component in ADRM is effective for enhancing filtering performance. Further analysis shows that ADRM is robust under varying parameter settings.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3092303407",
    "type": "article"
  },
  {
    "title": "<scp>MyrrorBot</scp> : A Digital Assistant Based on Holistic User Models for Personalized Access to Online Services",
    "doi": "https://doi.org/10.1145/3447679",
    "publication_date": "2021-08-16",
    "publication_year": 2021,
    "authors": "Cataldo Musto; Fedelucio Narducci; Marco Polignano; Marco de Gemmis; Pasquale Lops; Giovanni Semeraro",
    "corresponding_authors": "",
    "abstract": "In this article, we present MyrrorBot , a personal digital assistant implementing a natural language interface that allows the users to: (i) access online services, such as music, video, news, and food recommendation s, in a personalized way, by exploiting a strategy for implicit user modeling called holistic user profiling ; (ii) query their own user models, to inspect the features encoded in their profiles and to increase their awareness of the personalization process. Basically, the system allows the users to formulate natural language requests related to their information needs. Such needs are roughly classified in two groups: quantified self-related needs (e.g., Did I sleep enough? Am I extrovert? ) and personalized access to online services (e.g., Play a song I like ). The intent recognition strategy implemented in the platform automatically identifies the intent expressed by the user and forwards the request to specific services and modules that generate an appropriate answer that fulfills the query. In the experimental evaluation, we evaluated both qualitative (users’ acceptance of the system, usability) as well as quantitative (time required to complete basic tasks, effectiveness of the personalization strategy) aspects of the system, and the results showed that MyrrorBot can improve the way people access online services and applications. This leads to a more effective interaction and paves the way for further development of our system.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3193570035",
    "type": "article"
  },
  {
    "title": "Conversational Search and Recommendation: Introduction to the Special Issue",
    "doi": "https://doi.org/10.1145/3465272",
    "publication_date": "2021-09-01",
    "publication_year": 2021,
    "authors": "Claudia Hauff; Julia Kiseleva; Mark Sanderson; Hamed Zamani; Yongfeng Zhang",
    "corresponding_authors": "",
    "abstract": "introduction Share on Conversational Search and Recommendation: Introduction to the Special Issue Authors: Claudia Hauff Delft University of Technology, Van Mourik Broekmanweg, XE Delft, The Netherlands Delft University of Technology, Van Mourik Broekmanweg, XE Delft, The NetherlandsSearch about this author , Julia Kiseleva Microsoft, One Microsoft Way, Redmond, WA, United States Microsoft, One Microsoft Way, Redmond, WA, United StatesSearch about this author , Mark Sanderson RMIT University, Melbourne, Victoria, Australia RMIT University, Melbourne, Victoria, AustraliaSearch about this author , Hamed Zamani University of Massachusetts Amherst, Amherst, MA, United States University of Massachusetts Amherst, Amherst, MA, United StatesSearch about this author , Yongfeng Zhang Rutgers University, Piscataway, NJ, United States Rutgers University, Piscataway, NJ, United StatesSearch about this author Authors Info & Claims ACM Transactions on Information SystemsVolume 39Issue 4October 2021 Article No.: 38pp 1–6https://doi.org/10.1145/3465272Online:01 September 2021Publication History 0citation263DownloadsMetricsTotal Citations0Total Downloads263Last 12 Months263Last 6 weeks11 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3196635871",
    "type": "article"
  },
  {
    "title": "Collaborative Reflection-Augmented Autoencoder Network for Recommender Systems",
    "doi": "https://doi.org/10.1145/3467023",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Lianghao Xia; Chao Huang; Yong Xu; Huance Xu; Xiang Li; Weiguo Zhang",
    "corresponding_authors": "",
    "abstract": "As the deep learning techniques have expanded to real-world recommendation tasks, many deep neural network based Collaborative Filtering (CF) models have been developed to project user-item interactions into latent feature space, based on various neural architectures, such as multi-layer perceptron, auto-encoder and graph neural networks. However, the majority of existing collaborative filtering systems are not well designed to handle missing data. Particularly, in order to inject the negative signals in the training phase, these solutions largely rely on negative sampling from unobserved user-item interactions and simply treating them as negative instances, which brings the recommendation performance degradation. To address the issues, we develop a Collaborative Reflection-Augmented Autoencoder Network (CRANet), that is capable of exploring transferable knowledge from observed and unobserved user-item interactions. The network architecture of CRANet is formed of an integrative structure with a reflective receptor network and an information fusion autoencoder module, which endows our recommendation framework with the ability of encoding implicit user's pairwise preference on both interacted and non-interacted items. Additionally, a parametric regularization-based tied-weight scheme is designed to perform robust joint training of the two-stage CRANet model. We finally experimentally validate CRANet on four diverse benchmark datasets corresponding to two recommendation tasks, to show that debiasing the negative signals of user-item interactions improves the performance as compared to various state-of-the-art recommendation techniques. Our source code is available at https://github.com/akaxlh/CRANet.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3198350630",
    "type": "article"
  },
  {
    "title": "Does More Context Help? Effects of Context Window and Application Source on Retrieval Performance",
    "doi": "https://doi.org/10.1145/3474055",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Tung Vuong; Salvatore Andolina; Giulio Jacucci; Tuukka Ruotsalo",
    "corresponding_authors": "",
    "abstract": "We study the effect of contextual information obtained from a user's digital trace on Web search performance. Contextual information is modeled using Dirichlet-Hawkes processes (DHP) and used in augmenting Web search queries. The context is captured by monitoring all naturally occurring user behavior using continuous 24/7 recordings of the screen and associating the context with the queries issued by the users. We report a field study in which 13 participants installed a screen recording and digital activity monitoring system on their laptops for 14 days, resulting in data on all Web search queries and the associated context data. A query augmentation (QAug) model was built to expand the original query with semantically related terms. The effects of context window and source were determined by training context models with temporally varying context windows and varying application sources. The context models were then utilized to re-rank the QAug model. We evaluate the context models by using the Web document rankings of the original query as a control condition compared against various experimental conditions: (1) a search context condition in which the context was sourced from search history; (2) a non-search context condition in which the context was sourced from all interactions excluding search history; (3) a comprehensive context condition in which the context was sourced from both search and non-search histories; and (4) an application-specific condition in which the context was sourced from interaction histories captured on a specific application type. Our results indicated that incorporating more contextual information significantly improved Web search rankings as measured by the positions of the documents on which users clicked in the search result pages. The effects and importance of different context windows and application sources, along with different query types are analyzed, and their impact on Web search performance is discussed.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3203811892",
    "type": "article"
  },
  {
    "title": "Embedding Hierarchical Structures for Venue Category Representation",
    "doi": "https://doi.org/10.1145/3478285",
    "publication_date": "2021-11-22",
    "publication_year": 2021,
    "authors": "Meng Chen; Lei Zhu; Ronghui Xu; Yang Liu; Xiaohui Yu; Yilong Yin",
    "corresponding_authors": "",
    "abstract": "Venue categories used in location-based social networks often exhibit a hierarchical structure, together with the category sequences derived from users’ check-ins. The two data modalities provide a wealth of information for us to capture the semantic relationships between those categories. To understand the venue semantics, existing methods usually embed venue categories into low-dimensional spaces by modeling the linear context (i.e., the positional neighbors of the given category) in check-in sequences. However, the hierarchical structure of venue categories, which inherently encodes the relationships between categories, is largely untapped. In this article, we propose a venue C ategory E mbedding M odel named Hier-CEM , which generates a latent representation for each venue category by embedding the Hier archical structure of categories and utilizing multiple types of context. Specifically, we investigate two kinds of hierarchical context based on any given venue category hierarchy and show how to model them together with the linear context collaboratively. We apply Hier-CEM to three tasks on two real check-in datasets collected from Foursquare. Experimental results show that Hier-CEM is better at capturing both semantic and sequential information inherent in venues than state-of-the-art embedding methods.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3215411791",
    "type": "article"
  },
  {
    "title": "Personalized, Sequential, Attentive, Metric-Aware Product Search",
    "doi": "https://doi.org/10.1145/3473337",
    "publication_date": "2021-11-24",
    "publication_year": 2021,
    "authors": "Yaoxin Pan; Shangsong Liang; Jiaxin Ren; Zaiqiao Meng; Qiang Zhang",
    "corresponding_authors": "",
    "abstract": "The task of personalized product search aims at retrieving a ranked list of products given a user’s input query and his/her purchase history. To address this task, we propose the PSAM model, a Personalized, Sequential, Attentive and Metric-aware (PSAM) model, that learns the semantic representations of three different categories of entities, i.e., users, queries, and products, based on user sequential purchase historical data and the corresponding sequential queries. Specifically, a query-based attentive LSTM (QA-LSTM) model and an attention mechanism are designed to infer users dynamic embeddings, which is able to capture their short-term and long-term preferences. To obtain more fine-grained embeddings of the three categories of entities, a metric-aware objective is deployed in our model to force the inferred embeddings subject to the triangle inequality, which is a more realistic distance measurement for product search. Experiments conducted on four benchmark datasets show that our PSAM model significantly outperforms the state-of-the-art product search baselines in terms of effectiveness by up to 50.9% improvement under NDCG@20. Our visualization experiments further illustrate that the learned product embeddings are able to distinguish different types of products.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4200293063",
    "type": "article"
  },
  {
    "title": "Exploiting Representations from Statistical Machine Translation for Cross-Language Information Retrieval",
    "doi": "https://doi.org/10.1145/2644807",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Ferhan Türe; Jimmy Lin",
    "corresponding_authors": "",
    "abstract": "This work explores how internal representations of modern statistical machine translation systems can be exploited for cross-language information retrieval. We tackle two core issues that are central to query translation: how to exploit context to generate more accurate translations and how to preserve ambiguity that may be present in the original query, thereby retaining a diverse set of translation alternatives. These two considerations are often in tension since ambiguity in natural language is typically resolved by exploiting context, but effective retrieval requires striking the right balance. We propose two novel query translation approaches: the grammar-based approach extracts translation probabilities from translation grammars, while the decoder-based approach takes advantage of n -best translation hypotheses. Both are context-sensitive , in contrast to a baseline context-insensitive approach that uses bilingual dictionaries for word-by-word translation. Experimental results show that by “opening up” modern statistical machine translation systems, we can access intermediate representations that yield high retrieval effectiveness. By combining evidence from multiple sources, we demonstrate significant improvements over competitive baselines on standard cross-language information retrieval test collections. In addition to effectiveness, the efficiency of our techniques are explored as well.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2020833137",
    "type": "article"
  },
  {
    "title": "Subspace Frequency Analysis--Based Field Indices Extraction for Electricity Customer Classification",
    "doi": "https://doi.org/10.1145/2858657",
    "publication_date": "2016-02-08",
    "publication_year": 2016,
    "authors": "Minghao Piao; Keun Ho Ryu",
    "corresponding_authors": "",
    "abstract": "In electricity customer classification, the most important task is to avoid the curse of dimensionality problem, as the consumption diagrams have a large number of dimensions. To avoid the curse of dimensionality problem, field indices (load shape factor) are often used instead of consumption diagrams. Field indices are directly extracted from consumption diagrams according to a predefined formula. Previous studies show that the most important thing for defining such a formula is to find meaningful time intervals from consumption diagrams. However, the inconvenient thing is that there are still a lack of details to explain how to define such time intervals. In our study, we propose a data mining--based method named SFATIE to support the extraction of field indices. The performance of the proposed method is evaluated by comparing it with other dimensionality reduction methods during the classification. For the classification, most often we have used classification methods like C5.0, SVM, Neural Net, Bayes Net, and Logistic. The experimental results show that our method is better or close to other dimensionality reduction methods. In addition, the experimental results show that our proposed method can produce the good quality of field indices and that these indices can improve the performance of electricity customer classification.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2258689554",
    "type": "article"
  },
  {
    "title": "Measuring the Semantic Uncertainty of News Events for Evolution Potential Estimation",
    "doi": "https://doi.org/10.1145/2903719",
    "publication_date": "2016-06-09",
    "publication_year": 2016,
    "authors": "Xiangfeng Luo; Junyu Xuan; Jie Lü; Guangquan Zhang",
    "corresponding_authors": "",
    "abstract": "The evolution potential estimation of news events can support the decision making of both corporations and governments. For example, a corporation could manage its public relations crisis in a timely manner if a negative news event about this corporation is known with large evolution potential in advance. However, existing state-of-the-art methods are mainly based on time series historical data, which are not suitable for the news events with limited historical data and bursty properties. In this article, we propose a purely content-based method to estimate the evolution potential of the news events. The proposed method considers a news event at a given time point as a system composed of different keywords, and the uncertainty of this system is defined and measured as the Semantic Uncertainty of this news event. At the same time, an uncertainty space is constructed with two extreme states: the most uncertain state and the most certain state. We believe that the Semantic Uncertainty has correlation with the content evolution of the news events, so it can be used to estimate the evolution potential of the news events. In order to verify the proposed method, we present detailed experimental setups and results measuring the correlation of the Semantic Uncertainty with the Content Change of news events using collected news events data. The results show that the correlation does exist and is stronger than the correlation of value from the time-series-based method with the Content Change. Therefore, we can use the Semantic Uncertainty to estimate the evolution potential of news events.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2412361335",
    "type": "article"
  },
  {
    "title": "Causal Relationship Detection in Archival Collections of Product Reviews for Understanding Technology Evolution",
    "doi": "https://doi.org/10.1145/2937752",
    "publication_date": "2016-08-11",
    "publication_year": 2016,
    "authors": "Yating Zhang; Adam Jatowt; Katsumi Tanaka",
    "corresponding_authors": "",
    "abstract": "Technology progress is one of the key reasons behind today's rapid changes in lifestyles. Knowing how products and objects evolve can not only help with understanding the evolutionary patterns in our society but can also provide clues on effective product design and can offer support for predicting the future. We propose a general framework for analyzing technology's impact on our lives through detecting cause--effect relationships, where causes represent changes in technology while effects are changes in social life, such as new activities or new ways of using products. We address the challenge of viewing technology evolution through the “social impact lens” by mining causal relationships from the long-term collections of product reviews. In particular, we first propose dividing vocabulary into two groups: terms describing product features (called physical terms ) and terms representing product usage (called conceptual terms ). We then search for two kinds of changes related to the appearance of terms: frequency-based and context-based changes. The former indicate periods when a word was significantly more frequently used, whereas the latter indicate periods of high change in the word's context. Based on the detected changes, we then search for causal term pairs such that the change in the physical term triggers the change in the conceptual term. We next extend our approach to finding causal relationships between word groups such as a group of words representing the same technology and causing a given conceptual change or group of words representing two different technologies that simultaneously “co-cause” a conceptual change. We conduct experiments on different product types using the Amazon Product Review Dataset, which spans 1995 to 2013, and we demonstrate that our approaches outperform state-of-the-art baselines.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2518244067",
    "type": "article"
  },
  {
    "title": "A Re-classification of Information Seeking Tasks and Their Computational Solutions",
    "doi": "https://doi.org/10.1145/3497875",
    "publication_date": "2022-03-09",
    "publication_year": 2022,
    "authors": "Zhiwen Tang; Grace Hui Yang",
    "corresponding_authors": "",
    "abstract": "This article presents a re-classification of information seeking (IS) tasks, concepts, and algorithms. The proposed taxonomy provides new dimensions to look into information seeking tasks and methods. The new dimensions include the number of search iterations, search goal types, and procedures to reach these goals. Differences along these dimensions for the information seeking tasks call for suitable computational solutions. The article then reviews machine learning solutions that match each new category. The paper ends with a review of evaluation campaigns for IS systems.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3212285817",
    "type": "article"
  },
  {
    "title": "Generating Relevant and Informative Questions for Open-Domain Conversations",
    "doi": "https://doi.org/10.1145/3510612",
    "publication_date": "2022-02-14",
    "publication_year": 2022,
    "authors": "Yanxiang Ling; Fei Cai; Jun Liu; Honghui Chen; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Recent research has highlighted the importance of mixed-initiative interactions in conversational search. To enable mixed-initiative interactions, information retrieval systems should be able to ask diverse questions, such as information-seeking, clarification, and open-ended ones. question generation (QG) of open-domain conversational systems aims at enhancing the interactiveness and persistence of human-machine interactions. The task is challenging because of the sparsity of question generation (QG)-specific data in conversations. Current work is limited to single-turn interaction scenarios. We propose a context-enhanced neural question generation (CNQG) model that leverages the conversational context to predict question content and pattern, then perform question decoding. A hierarchical encoder framework is employed to obtain the discourse-level context representation. Based on this, we propose Review and Transit mechanisms to respectively select contextual keywords and predict new topic words to further construct the question content. Conversational context and the predicted question content are used to produce the question pattern, which in turn guides the question decoding process implemented by a recurrent decoder with a joint attention mechanism. To fully utilize the limited QG-specific data to train our question generator, we perform multi-task learning with three auxiliary training objectives, i.e., question pattern prediction, Review , and Transit mechanisms. The required additional labeled data is obtained in a self-supervised way. We also design a weight decaying strategy to adjust the influences of various auxiliary learning tasks. To the best of our acknowledge, we are the first to extend the application of QG to the multi-turn open-domain conversational scenario. Extensive experimental results demonstrate the effectiveness of our proposal and its main components on generating relevant and informative questions, with robust performance for contexts with various lengths.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4212822326",
    "type": "article"
  },
  {
    "title": "Learning Implicit and Explicit Multi-task Interactions for Information Extraction",
    "doi": "https://doi.org/10.1145/3533020",
    "publication_date": "2022-06-11",
    "publication_year": 2022,
    "authors": "Kai Sun; Richong Zhang; Samuel Mensah; Yongyi Mao; Xudong Liu",
    "corresponding_authors": "",
    "abstract": "Information extraction aims at extracting entities, relations, and so on, in text to support information retrieval systems. To extract information, researchers have considered multitask learning (ML) approaches. The conventional ML approach learns shared features across tasks, with the assumption that these features capture sufficient task interactions to learn expressive shared representations for task classification. However, such an assumption is flawed in different perspectives. First, the shared representation may contain noise introduced by another task; tasks coupled for multitask learning may have different complexities but this approach treats all tasks equally; the conventional approach has a flat structure that hinders the learning of explicit interactions. This approach, however, learns implicit interactions across tasks and often has a generalization ability that has benefited the learning of multitasks. In this article, we take advantage of implicit interactions learned by conventional approaches while alleviating the issues mentioned above by developing a Recurrent Interaction Network with an effective Early Prediction Integration (RIN-EPI) for multitask learning. Specifically, RIN-EPI learns implicit and explicit interactions across two different but related tasks. To effectively learn explicit interactions across tasks, we consider the correlations among the outputs of related tasks. It is, however, obvious that task outputs are unobservable during training, so we leverage the predictions at intermediate layers (referred to as early predictions) as proxies as well as shared features across tasks to learn explicit interactions through attention mechanisms and sequence learning models. By recurrently learning explicit interactions, we gradually improve predictions for the individual tasks in the multitask learning. We demonstrate the effectiveness of RIN-EPI on the learning of two mainstream multitasks for information extraction: (1) entity recognition and relation classification and (2) aspect and opinion term co-extraction. Extensive experiments demonstrate the effectiveness of the RIN-EPI architecture, where we achieve state-of-the-art results on several benchmark datasets.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4293083978",
    "type": "article"
  },
  {
    "title": "Learning Dual-view User Representations for Enhanced Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3572028",
    "publication_date": "2022-11-22",
    "publication_year": 2022,
    "authors": "Lyuxin Xue; Deqing Yang; Shuoyao Zhai; Yuxin Li; Yanghua Xiao",
    "corresponding_authors": "",
    "abstract": "Sequential recommendation (SR) aims to predict a user’s next interacted item given his/her historical interactions. Most existing sequential recommendation systems model user preferences only with item-level representations, where a user’s interaction sequence are often modeled with sequential or graph-based method to infer the user’s sequential interaction pattern. However, since a user’s preference factors may vary over time, the user modeling on item-level could hardly represent the user’s preference precisely and sufficiently, resulting in suboptimal recommendation performance. In addition, the recommendation results based on the item-level user representations lack the interpretability of preference factors. To address these problems, we propose a novel SR model with dual-view user representations in this paper, namely DUVRec, where a user’s preference is learned based on the representations of two distinct views, i.e., item view and factor view . Specifically, the item-view user representation is learned as the previous SR models to encode the user preference of item level, while the factor-view user representation is learned by an coarse-grained graph embedding method to explicitly represent the user in terms of preference factors. As a result, such dual-view user representations are more comprehensive than that in the previous SR models, leading to enhanced SR performance. Furthermore, we design a contrastive learning strategy to achieve mutual complementation between these two views. Our extensive experiments upon three benchmark datasets justify DUVRec’s superior performance over the state-of-the-art SR models, including the advantage of the dual-view contrastive learning. In addition, DUVRec’s capability of providing explanations on recommendation results is also demonstrated through some specific case studies.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4309698070",
    "type": "article"
  },
  {
    "title": "Conditional Cross-Platform User Engagement Prediction",
    "doi": "https://doi.org/10.1145/3589226",
    "publication_date": "2023-03-24",
    "publication_year": 2023,
    "authors": "Xinhang Li; Zhaopeng Qiu; Jiacheng Jiang; Yong Zhang; Chunxiao Xing; Xian Wu",
    "corresponding_authors": "",
    "abstract": "The bursting of media sharing platforms like TikTok, YouTube, and Kwai enables normal users to create and share content with worldwide audiences. The most popular YouTuber can attract up to 100 million followers. Since there are multiple popular platforms, it’s quite common that a YouTuber publishes the same media to multiple platforms, or replicates all media from one platform to another. However, the users of different platforms have different tastes. The media that is popular on one platform may not be a great vogue on other platforms. Observing such cross-platform variance, we propose a new task: estimating the user engagement score of a media on one platform given its popularity on other platforms. This task can benefit both the YouTubers and the platform. On one hand, YouTubers can use the predicted engagement to guide the media reworking; on the other hand, the platform can use the predicted engagement to establish promotion and advertising plans. Therefore, this task is of great practical value. To tackle this task, we propose a disentangled neural network that can separate the general media adorability from platform inclinations. In this manner, by substituting the inclination from the source platform to the target platform, we are able to predict the user engagement in the target platform. To validate the proposed model, we manage to build a dataset of micro-videos which are published on four platforms TikTok, Kwai, Bilibili, and WESEE. The experimental results prove the effectiveness of the proposed model.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4360851801",
    "type": "article"
  },
  {
    "title": "A Review Selection Method Based on Consumer Decision Phases in E-commerce",
    "doi": "https://doi.org/10.1145/3587265",
    "publication_date": "2023-03-30",
    "publication_year": 2023,
    "authors": "Jin Zhang; Xinrui Li; Liye Wang",
    "corresponding_authors": "",
    "abstract": "A valuable small subset strategically selected from massive online reviews is beneficial to improve consumers’ decision-making efficiency in e-commerce. Existing review selection methods primarily concentrate on the informativeness of reviews and aim to find a subset of reviews that can reflect the informational properties of the original review set. However, changes in consumers’ review diets during the two-phase decision process are not fully considered. In this study, we propose a novel review selection problem of finding a diet-matched review subset with high diversity and representativeness, which can better adapt to consumers’ review-diet conversion from attribute-oriented to experience-oriented reviews between two decision phases. A novel decision-phase-based review selection method named DPRS is further proposed, which involves two steps: review classification and review selection. In the review classification step, the probability of a review being attribute-oriented or experience-oriented is estimated by prior knowledge-aware attentive neural network. In the second step, a novel heuristic algorithm, namely, stepwise non-dominated selection with superiority strategy, is introduced to seek the solution to the review selection problem. Extensive experiments on a real-world dataset demonstrate that DPRS outperforms state-of-the-art methods in terms of both review classification and review selection.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4361279380",
    "type": "review"
  },
  {
    "title": "How Many Crowd Workers Do I Need? On Statistical Power when Crowdsourcing Relevance Judgments",
    "doi": "https://doi.org/10.1145/3597201",
    "publication_date": "2023-05-22",
    "publication_year": 2023,
    "authors": "Kevin Roitero; David La Barbera; Michael Soprano; Gianluca Demartini; Stefano Mizzaro; Tetsuya Sakai",
    "corresponding_authors": "",
    "abstract": "To scale the size of Information Retrieval collections, crowdsourcing has become a common way to collect relevance judgments at scale. Crowdsourcing experiments usually employ 100–10,000 workers, but such a number is often decided in a heuristic way. The downside is that the resulting dataset does not have any guarantee of meeting predefined statistical requirements as, for example, have enough statistical power to be able to distinguish in a statistically significant way between the relevance of two documents. We propose a methodology adapted from literature on sound topic set size design, based on t-test and ANOVA, which aims at guaranteeing the resulting dataset to meet a predefined set of statistical requirements. We validate our approach on several public datasets. Our results show that we can reliably estimate the recommended number of workers needed to achieve statistical power, and that such estimation is dependent on the topic, while the effect of the relevance scale is limited. Furthermore, we found that such estimation is dependent on worker features such as agreement. Finally, we describe a set of practical estimation strategies that can be used to estimate the worker set size, and we also provide results on the estimation of document set sizes.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4377238720",
    "type": "article"
  },
  {
    "title": "Selective Query Processing: A Risk-Sensitive Selection of Search Configurations",
    "doi": "https://doi.org/10.1145/3608474",
    "publication_date": "2023-07-13",
    "publication_year": 2023,
    "authors": "Josiane Mothe; Md Zia Ullah",
    "corresponding_authors": "",
    "abstract": "In information retrieval systems, search parameters are optimized to ensure high effectiveness based on a set of past searches, and these optimized parameters are then used as the search configuration for all subsequent queries. A better approach, however, would be to adapt the parameters to fit the query at hand. Selective query expansion is one such an approach, in which the system decides automatically whether or not to expand the query, resulting in two possible search configurations. This approach was extended recently to include many other parameters, leading to many possible search configurations where the system automatically selects the best configuration on a per-query basis. One problem with this approach is the system training, which requires evaluation of each training query with every possible configuration. In real-world systems, so many parameters and possible values must be evaluated that this approach is impractical, especially when the system must be updated frequently, as is the case for commercial search engines. In general, the more configurations, the greater the effectiveness when configuration selection is appropriate but also the greater the risk of decreasing effectiveness in the case of an inappropriate configuration selection. To determine the ideal configurations to be used for each query in real-world systems, we have developed a method in which a limited number of possible configurations are pre-selected, then used in a meta-search engine that decides the best search configuration for each query. We define a risk-sensitive approach for configuration pre-selection that considers the risk-reward tradeoff between the number of configurations kept and system effectiveness. We define two alternative risk functions to apply to different goals. For final configuration selection, the decision is based on query feature similarities. We compare two alternative risk functions on two query types (ad hoc and diversity) and compare these to more sophisticated machine learning based methods. We find that a relatively small number of configurations (20) selected by our risk-sensitive model is sufficient to obtain results close to the best achievable results for each query. Effectiveness is increased by about 15% according to the P@10 and nDCG@10 evaluation metrics when compared to traditional grid search using a single configuration and by about 20% when compared to learning to rank documents. Our risk-sensitive approach works for both diversity- and ad hoc oriented searches. Moreover, the similarity-based selection method outperforms the more sophisticated approaches. Thus, we demonstrate the feasibility of developing per-query information retrieval systems, which will guide future research in this direction.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4384204114",
    "type": "article"
  },
  {
    "title": "NIR-Prompt: A Multi-task Generalized Neural Information Retrieval Training Framework",
    "doi": "https://doi.org/10.1145/3626092",
    "publication_date": "2023-10-02",
    "publication_year": 2023,
    "authors": "Shicheng Xu; Liang Pang; Huawei Shen; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "Information retrieval aims to find information that meets users’ needs from the corpus. Different needs correspond to different IR tasks such as document retrieval, open-domain question answering, retrieval-based dialogue, and so on, while they share the same schema to estimate the relationship between texts. It indicates that a good IR model can generalize to different tasks and domains. However, previous studies indicate that state-of-the-art neural information retrieval (NIR) models, e.g., pre-trained language models (PLMs) are hard to generalize. It is mainly because the end-to-end fine-tuning paradigm makes the model overemphasize task-specific signals and domain biases but loses the ability to capture generalized essential signals. To address this problem, we propose a novel NIR training framework named NIR-Prompt for retrieval and reranking stages based on the idea of decoupling signal capturing and combination. NIR-Prompt exploits Essential Matching Module (EMM) to capture the essential matching signals and gets the description of tasks by Matching Description Module (MDM). The description is used as task-adaptation information to combine the essential matching signals to adapt to different tasks. Experiments under in-domain multi-task, out-of-domain multi-task, and new task adaptation settings show that NIR-Prompt can improve the generalization of PLMs in NIR for both retrieval and reranking stages compared with baselines.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4387259549",
    "type": "article"
  },
  {
    "title": "Triple Dual Learning for Opinion-based Explainable Recommendation",
    "doi": "https://doi.org/10.1145/3631521",
    "publication_date": "2023-11-02",
    "publication_year": 2023,
    "authors": "Yuting Zhang; Ying Sun; Fuzhen Zhuang; Yongchun Zhu; Zhulin An; Yongjun Xu",
    "corresponding_authors": "",
    "abstract": "Recently, with the aim of enhancing the trustworthiness of recommender systems, explainable recommendation has attracted much attention from the research community. Intuitively, users’ opinions toward different aspects of an item determine their ratings (i.e., users’ preferences) for the item. Therefore, rating prediction from the perspective of opinions can realize personalized explanations at the level of item aspects and user preferences. However, there are several challenges in developing an opinion-based explainable recommendation: (1) The complicated relationship between users’ opinions and ratings. (2) The difficulty of predicting the potential (i.e., unseen) user-item opinions because of the sparsity of opinion information. To tackle these challenges, we propose an overall preference-aware opinion-based explainable rating prediction model by jointly modeling the multiple observations of user-item interaction (i.e., review, opinion, rating). To alleviate the sparsity problem and raise the effectiveness of opinion prediction, we further propose a triple dual learning-based framework with a novelly designed triple dual constraint . Finally, experiments on three popular datasets show the effectiveness and great explanation performance of our framework.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4388210299",
    "type": "article"
  },
  {
    "title": "Improving First-stage Retrieval of Point-of-interest Search by Pre-training Models",
    "doi": "https://doi.org/10.1145/3631937",
    "publication_date": "2023-11-07",
    "publication_year": 2023,
    "authors": "Lang Mei; Jiaxin Mao; Juan Hu; Naiqiang Tan; Hua Chai; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Point-of-interest (POI) search is important for location-based services, such as navigation and online ride-hailing service. The goal of POI search is to find the most relevant destinations from a large-scale POI database given a text query. To improve the effectiveness and efficiency of POI search, most existing approaches are based on a multi-stage pipeline that consists of an efficiency-oriented retrieval stage and one or more effectiveness-oriented re-rank stages. In this article, we focus on the first efficiency-oriented retrieval stage of the POI search. We first identify the limitations of existing first-stage POI retrieval models in capturing the semantic-geography relationship and modeling the fine-grained geographical context information. Then, we propose a Geo-Enhanced Dense Retrieval framework for POI search to alleviate the above problems. Specifically, the proposed framework leverages the capacity of pre-trained language models (e.g., BERT) and designs a pre-training approach to better model the semantic match between the query prefix and POIs. With the POI collection, we first perform a token-level pre-training task based on a geographical-sensitive masked language prediction and design two retrieval-oriented pre-training tasks that link the address of each POI to its name and geo-location. With the user behavior logs collected from an online POI search system, we design two additional pre-training tasks based on users’ query reformulation behavior and the transitions between POIs. We also utilize a late-interaction network structure to model the fine-grained interactions between the text and geographical context information within an acceptable query latency. Extensive experiments on the real-world datasets collected from the Didichuxing application demonstrate that the proposed framework can achieve superior retrieval performance over existing first-stage POI retrieval methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4388455852",
    "type": "article"
  },
  {
    "title": "Less is More: Removing Redundancy of Graph Convolutional Networks for Recommendation",
    "doi": "https://doi.org/10.1145/3632751",
    "publication_date": "2023-11-20",
    "publication_year": 2023,
    "authors": "Shaowen Peng; Kazunari Sugiyama; Tsunenori Mine",
    "corresponding_authors": "",
    "abstract": "While Graph Convolutional Networks (GCNs) have shown great potential in recommender systems and collaborative filtering (CF), they suffer from expensive computational complexity and poor scalability. On top of that, recent works mostly combine GCNs with other advanced algorithms which further sacrifice model efficiency and scalability. In this work, we unveil the redundancy of existing GCN-based methods in three aspects: (1) Feature redundancy . By reviewing GCNs from a spectral perspective, we show that most spectral graph features are noisy for recommendation, while stacking graph convolution layers can suppress but cannot completely remove the noisy features, which we mostly summarize from our previous work; (2) Structure redundancy . By providing a deep insight into how user/item representations are generated, we show that what makes them distinctive lies in the spectral graph features, while the core idea of GCNs (i.e., neighborhood aggregation) is not the reason making GCNs effective; and (3) Distribution redundancy . Following observations from (1), we further show that the number of required spectral features is closely related to the spectral distribution, where important information tends to be concentrated in more (fewer) spectral features on a flatter (sharper) distribution. To make important information be concentrated in as few features as possible, we sharpen the spectral distribution by increasing the node similarity without changing the original data, thereby reducing the computational cost. To remove these three kinds of redundancies, we propose a Simplified Graph Denoising Encoder (SGDE) only exploiting the top- K singular vectors without explicitly aggregating neighborhood, which significantly reduces the complexity of GCN-based methods. We further propose a scalable contrastive learning framework to alleviate data sparsity and to boost model robustness and generalization, leading to significant improvement. Extensive experiments on three real-world datasets show that our proposed SGDE not only achieves state-of-the-art but also shows higher scalability and efficiency than our previously proposed GDE as well as traditional and GCN-based CF methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4388827060",
    "type": "article"
  },
  {
    "title": "Data Augmentation for Sample Efficient and Robust Document Ranking",
    "doi": "https://doi.org/10.1145/3634911",
    "publication_date": "2023-11-29",
    "publication_year": 2023,
    "authors": "Abhijit Anand; Jurek Leonhardt; Jaspreet Singh; Koustav Rudra; Avishek Anand",
    "corresponding_authors": "",
    "abstract": "Contextual ranking models have delivered impressive performance improvements over classical models in the document ranking task. However, these highly over-parameterized models tend to be data-hungry and require large amounts of data even for fine-tuning. In this article, we propose data-augmentation methods for effective and robust ranking performance. One of the key benefits of using data augmentation is in achieving sample efficiency or learning effectively when we have only a small amount of training data. We propose supervised and unsupervised data augmentation schemes by creating training data using parts of the relevant documents in the query-document pairs. We then adapt a family of contrastive losses for the document ranking task that can exploit the augmented data to learn an effective ranking model. Our extensive experiments on subsets of the MS MARCO and TREC-DL test sets show that data augmentation, along with the ranking-adapted contrastive losses, results in performance improvements under most dataset sizes. Apart from sample efficiency, we conclusively show that data augmentation results in robust models when transferred to out-of-domain benchmarks. Our performance improvements in in-domain and more prominently in out-of-domain benchmarks show that augmentation regularizes the ranking model and improves its robustness and generalization capability.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4389140526",
    "type": "article"
  },
  {
    "title": "Privacy-Preserving Individual-Level COVID-19 Infection Prediction via Federated Graph Learning",
    "doi": "https://doi.org/10.1145/3633202",
    "publication_date": "2023-12-07",
    "publication_year": 2023,
    "authors": "Wenjie Fu; Huandong Wang; Chen Gao; Guanghua Liu; Yong Li; Tao Jiang",
    "corresponding_authors": "",
    "abstract": "Accurately predicting individual-level infection state is of great value since its essential role in reducing the damage of the epidemic. However, there exists an inescapable risk of privacy leakage in the fine-grained user mobility trajectories required by individual-level infection prediction. In this article, we focus on developing a framework of privacy-preserving individual-level infection prediction based on federated learning (FL) and graph neural networks (GNN). We propose Falcon , a F ederated gr A ph L earning method for privacy-preserving individual-level infe C tion predicti ON . It utilizes a novel hypergraph structure with spatio-temporal hyperedges to describe the complex interactions between individuals and locations in the contagion process. By organically combining the FL framework with hypergraph neural networks, the information propagation process of the graph machine learning is able to be divided into two stages distributed on the server and the clients, respectively, so as to effectively protect user privacy while transmitting high-level information. Furthermore, it elaborately designs a differential privacy perturbation mechanism as well as a plausible pseudo location generation approach to preserve user privacy in the graph structure. Besides, it introduces a cooperative coupling mechanism between the individual-level prediction model and an additional region-level model to mitigate the detrimental impacts caused by the injected obfuscation mechanisms. Extensive experimental results show that our methodology outperforms state-of-the-art algorithms and is able to protect user privacy against actual privacy attacks. Our code and datasets are available at the link: https://github.com/wjfu99/FL-epidemic .",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4389438901",
    "type": "article"
  },
  {
    "title": "Guest Editorial - Special Issue on Text Categorization.",
    "doi": null,
    "publication_date": "1994-01-01",
    "publication_year": 1994,
    "authors": "David Lewis; Philip J. Hayes",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W104970664",
    "type": "editorial"
  },
  {
    "title": "DIRECT: a query facility for multiple databases",
    "doi": "https://doi.org/10.1145/185462.185472",
    "publication_date": "1994-10-01",
    "publication_year": 1994,
    "authors": "Ulla Merz; Roger King",
    "corresponding_authors": "",
    "abstract": "The subject of this research project is the architecture and design of a multidatabase query facility. These databases contain structured data, typical for business applications. Problems addressed are: presenting a uniform interface for retrieving data from multiple databases, providing autonomy for the component databases, and defining an architecture for semantic services. DIRECT is a query facility for heterogeneous databases. The databases and their definitions can differ in their data models, names, types, and encoded values. Instead of creating a global schema, descriptions of different databases are allowed to coexist. A multidatabase query language provides a uniform interface for retrieving data from different databases. DIRECT has been exercised with operational databases that are part of an automated business system.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2064782132",
    "type": "article"
  },
  {
    "title": "Integrating geometrical and linguistic analysis for email signature block parsing",
    "doi": "https://doi.org/10.1145/326440.326442",
    "publication_date": "1999-10-01",
    "publication_year": 1999,
    "authors": "Hao Chen; Jianying Hu; Richard Sproat",
    "corresponding_authors": "",
    "abstract": "The signature block is a common structured component found in email messages. Accurate identification and analysis of signature blocks is important in many multimedia messaging and information retrieval applications such as email text-to-speech rendering, automatic construction of personal address databases, and interactive message retrieval. It is also a very challenging task, because signature blocks often appear in complex two-dimensional layouts which are guided only by loose conventions. Traditional text analysis methods designed to deal with sequential text cannot handle two-dimensional structures, while the highly unconstrained nature of signature blocks makes the application of two-dimensional grammars very difficult. In this article, we describe an algorithm for signature block analysis which combines two-dimensional structural segmentation with one-dimensional grammatical constraints. The information obtained from both layout and linguistic analysis is integrated in the form of weighted finite-state transducers. The algorithm is currently implemented as a component in a preprocessing system for email text-to-speech rendering.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2089777159",
    "type": "article"
  },
  {
    "title": "The knowledge in multiple human relevance judgments",
    "doi": "https://doi.org/10.1145/279339.279340",
    "publication_date": "1998-04-01",
    "publication_year": 1998,
    "authors": "W. John Wilber",
    "corresponding_authors": "W. John Wilber",
    "abstract": "We show first that the pooling of multiple human judgments of relevance provides predictor of relevance that is superior to that obtained from a single human's relevance judgemts. A learning algorithm applied to a set of relevance judgments obtained from a single human would be expected to perform on new material at a level somewhat below that human. However, we examine two learning methods which when trained on the superior source of pooled human relevance judgments are able to perform at the level of a single human on new material. All performance comparisons are based on an independent human judge. Both algorithms function by producing term weights—one by a log odds calculation and the other by producing a least-squares fit to human relevance ratings. Some characteristics of the algorithms are examined.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2129172100",
    "type": "article"
  },
  {
    "title": "Optimal placement of high-probability randomly retrieved blocks on CLV optical discs",
    "doi": "https://doi.org/10.1145/103731.103732",
    "publication_date": "1991-01-03",
    "publication_year": 1991,
    "authors": "Daniel Alexander Ford; Stavros Christodoulakis",
    "corresponding_authors": "",
    "abstract": "Optimal data placement on a CLV (Constant Linear Velocity) format optical discs has an objective the minimization of the expected access cost of data retrievals from the disc when the probabilities of access of data items may be different. The problem of optimal data placement for optical discs is both important and more difficult than the corresponding problem on magnetic discs. A good data placement on optical discs is more important because data sets on optical discs such as WORM and CD ROM cannot be modified or moved once they are placed on disc. Currently, even rewritable optical discs are best suited for applications that are archival in nature. The problem of optimal data placement on CLV format optical discs is more difficult, mainly because the useful storage space is not uniformly distributed across the disc surface (along the radius). This leads to a complicated positional performance trade-off not present for magnetic disks. We present a model that encompasses all the important aspects of the placement problem on CLV format optical discs. The model takes into account the nonuniform distribution of useful storage, the dependency of the rotational delay on disc position, a parameterized seek cost function for optical discs, and the varying access probabilities of data items. We show that the optimal placement of high-probability blocks satisfies a unimodality property. Based on this observation, we solve the optimal placement problem. We then study the impact of the relative weights of the problem parameters and show that the optimal data placement may be very different from the optimal data placement on magnetic disks. We also validate our model and analysis and give an algorithm for computing the placement of disc sectors.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2070055870",
    "type": "article"
  },
  {
    "title": "Conceptual learning in database design",
    "doi": "https://doi.org/10.1145/146760.146779",
    "publication_date": "1992-07-01",
    "publication_year": 1992,
    "authors": "Yannis E. Ionnidis; Tomas Saulys; Andrew J. Whitsitt",
    "corresponding_authors": "",
    "abstract": "This paper examines the idea of incorporating machine learning algorithms into a database system for monitoring its stream of incoming queries and generating hierarchies with the most important concepts expressed in those queries. The goal is for these hierarchies to provide valuable input to the database administrator for dynamically modifying the physical and external schemas of a database for improved system performance and user productivity. The criteria for choosing the appropriate learning algorithms are analyzed, and based on them, two such algorithms, UNIMEM and COBWEB, are selected as the most suitable ones for the task. Standard UNIMEM and COBWEB implementations have been modified to support queries as input. Based on the results of experiments with these modified implementations, the whole approach appears to be quite promising, expecially if the concept hierarchy from which the learning algorithms start their processing is initialized with some of the most obvious concepts captured in the database.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2078031499",
    "type": "article"
  },
  {
    "title": "PicASHOW: pictorial authority search by hyperlinks on the web.",
    "doi": null,
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "Ronny Lempel; Aya Soffer",
    "corresponding_authors": "",
    "abstract": "We describe PicASHOW, a fully automated WWW image retrieval system that is based on several link-structure analyzing algorithms. Our basic premise is that a page p displays (or links to) an image when the author of p considers the image to be of value to the viewers of the page. We thus extend some well known link-based WWW page retrieval schemes to the context of image retrieval. PicASHOW’s analysis of the link structure enables it to retrieve relevant images even when those are stored in files with meaningless names. The same analysis also allows it to identify image containers and image hubs. We define these as Web pages that are rich in relevant images, or from which many images are readily accessible. PicASHOW requires no image analysis whatsoever and no creation of taxonomies for preclassification of the Web’s images. It can be implemented by standard WWW search engines with reasonable overhead, in terms of both computations and storage, and with no change to user query formats. It can thus be used to easily add image retrieving capabilities to standard search engines. Our results demonstrate that PicASHOW, while relying almost exclusively on link analysis, compares well with dedicated WWW image retrieval systems. We conclude that link analysis, a proven effective technique for Web page search, can improve the performance of Web image retrieval, as well as extend its definition to include the retrieval of image hubs and containers.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2055225264",
    "type": "article"
  },
  {
    "title": "A society model for office information systems",
    "doi": "https://doi.org/10.1145/6168.6170",
    "publication_date": "1986-04-01",
    "publication_year": 1986,
    "authors": "Cheng-Seen Ho; Yang-Chang Hong; Te‐Son Kuo",
    "corresponding_authors": "",
    "abstract": "A society model, which characterizes the behavior and procedure of offices, is proposed. It is our belief that an office system capable of dealing with all real office problems only through the modeling of the internal behavior of an office can be developed. In this society model, office entities are viewed as agents . An agent is modeled as a microsociety of interacting knowledge sources. Within the microsociety, there exists a microknowledge exchange system , which provides a set of microknowledge exchange protocols as a coordination system among those knowledge sources during their cooperative reasoning process. An office is then modeled as a society of various interacting agents using their knowledge to complete the office goals cooperatively. It is this unified view that allows offices to be modeled in a flexible and general way.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2023515166",
    "type": "article"
  },
  {
    "title": "Introduction to the special issue on XML retrieval",
    "doi": "https://doi.org/10.1145/1185877.1185878",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Ricardo Baeza‐Yates; Norbert Fuhr; Yoelle Maarek",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2026961849",
    "type": "article"
  },
  {
    "title": "Frequency-based identification of correct translation equivalents (FITE) obtained through transformation rules",
    "doi": "https://doi.org/10.1145/1292591.1292593",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Ari Pirkola; Jarmo Toivonen; Heikki Keskustalo; Kalervo Järvelin",
    "corresponding_authors": "",
    "abstract": "We devised a novel statistical technique for the identification of the translation equivalents of source words obtained by transformation rule based translation (TRT). The effectiveness of the technique called frequency-based identification of translation equivalents ( FITE ) was tested using biological and medical cross-lingual spelling variants and out-of-vocabulary (OOV) words in Spanish-English and Finnish-English TRT. The results showed that, depending on the source language and frequency corpus, FITE-TRT (the identification of translation equivalents from TRT's translation set by means of the FITE technique) may achieve high translation recall. In the case of the Web as the frequency corpus, translation recall was 89.2%--91.0% for Spanish-English FITE-TRT. For both language pairs FITE-TRT achieved high translation precision: 95.0%--98.8%. The technique also reliably identified native source language words: source words that cannot be correctly translated by TRT. Dictionary-based CLIR augmented with FITE-TRT performed substantially better than basic dictionary-based CLIR where OOV keys were kept intact. FITE-TRT with Web document frequencies was the best technique among several fuzzy translation/matching approaches tested in cross-language retrieval experiments. We also discuss the application of FITE-TRT in the automatic construction of multilingual dictionaries.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2009700724",
    "type": "article"
  },
  {
    "title": "Error correction vs. query garbling for Arabic OCR document retrieval",
    "doi": "https://doi.org/10.1145/1292591.1292596",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Kareem Darwish; Walid Magdy",
    "corresponding_authors": "",
    "abstract": "Due to the existence of large numbers of legacy documents (such as old books and newspapers), improving retrieval effectiveness for OCR'ed documents continues to be an important problem. This article compares the effect of OCR error correction with and without language modeling and the effect of query garbling with weighted structured queries on the retrieval of OCR degraded Arabic documents. The results suggest that moderate error correction does not yield statistically significant improvement in retrieval effectiveness when indexing and searching using n-grams. Also, reversing error correction models to perform query garbling in conjunction with weighted structured queries yields improved retrieval effectiveness. Lastly, using very good error correction that utilizes language modeling yields the best improvement in retrieval effectiveness.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2075294717",
    "type": "article"
  },
  {
    "title": "SEA",
    "doi": "https://doi.org/10.1145/1508850.1508853",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "K. Selçuk Candan; Mehmet E. Dönderler; Terri Hedgpeth; Jong Wook Kim; Qing Li; Maria Luisa Sapino",
    "corresponding_authors": "",
    "abstract": "While navigation within complex information spaces is a problem for all users, the problem is most evident with individuals who are blind who cannot simply locate, point, and click on a link in hypertext documents with a mouse. Users who are blind have to listen searching for the link in the document using only the keyboard and a screen reader program, which may be particularly inefficient in large documents with many links or deep hierarchies that are hard to navigate. Consequently, they are especially penalized when the information being searched is hidden under multiple layers of indirections. In this article, we introduce a segment-enrich-annotate (SEA) paradigm for adapting digital content with deep structures for improved accessibility. In particular, we instantiate and evaluate this paradigm through the iCare-Assistant, an assistive system for helping students who are blind in accessing Web and electronic course materials. Our evaluations, involving the participation of students who are blind, showed that the iCare-Assistant system, built based on the SEA paradigm, reduces the navigational overhead significantly and enables user who are blind access complex online course servers effectively.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1976961370",
    "type": "article"
  },
  {
    "title": "Combining relations for information extraction from free text",
    "doi": "https://doi.org/10.1145/1777432.1777437",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Mstislav Maslennikov; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Relations between entities of the same semantic type tend to be sparse in free texts. Therefore, combining relations is the key to effective information extraction (IE) on free text datasets with a small set of training samples. Previous approaches to bootstrapping for IE used different types of relations, such as dependency or co-occurrence, and faced the problems of paraphrasing and misalignment of instances. To cope with these problems, we propose a framework that integrates several types of relations. After extracting candidate entities, our framework evaluates relations between them at the phrasal, dependency, semantic frame, and discourse levels. For each of these levels, we build a classifier that outputs a score for relation instances. In order to integrate these scores, we propose three strategies: (1) integrate evaluation scores from each relation classifier; (2) incorporate the elimination of negatively labeled instances in a previous strategy; and (3) add cascading of extracted relations into strategy (2). Our framework improves the state-of-art results for supervised systems by 8%, 15%, 3%, and 5% on MUC4 (terrorism); MUC6 (management succession); ACE RDC 2003 (news, general types); and ACE RDC 2003 (news, specific types) domains respectively.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2035121996",
    "type": "article"
  },
  {
    "title": "Efficient Entity Translation Mining",
    "doi": "https://doi.org/10.1145/2382438.2382444",
    "publication_date": "2012-11-01",
    "publication_year": 2012,
    "authors": "Gae-won You; Seung-won Hwang; Young-In Song; Long Jiang; Zaiqing Nie",
    "corresponding_authors": "",
    "abstract": "This article studies the problem of mining entity translation, specifically, mining English and Chinese name pairs. Existing efforts can be categorized into (a) transliteration-based approaches that leverage phonetic similarity and (b) corpus-based approaches that exploit bilingual cooccurrences. These approaches suffer from inaccuracy and scarcity, respectively. In clear contrast, we use under-leveraged resources of monolingual entity cooccurrences crawled from entity search engines, which are represented as two entity-relationship graphs extracted from two language corpora, respectively. Our problem is then abstracted as finding correct mappings across two graphs. To achieve this goal, we propose a holistic approach to exploiting both transliteration similarity and monolingual cooccurrences. This approach, which builds upon monolingual corpora, complements existing corpus-based work requiring scarce resources of parallel or comparable corpus while significantly boosting the accuracy of transliteration-based work. In addition, by parallelizing the mapping process on multicore architectures, we speed up the computation by more than 10 times per unit accuracy. We validated the effectiveness and efficiency of our proposed approach using real-life datasets.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2075718039",
    "type": "article"
  },
  {
    "title": "Search Result Prefetching on Desktop and Mobile",
    "doi": "https://doi.org/10.1145/3015466",
    "publication_date": "2017-05-12",
    "publication_year": 2017,
    "authors": "Ryen W. White; Fernando Díaz; Qi Guo",
    "corresponding_authors": "",
    "abstract": "Search result examination is an important part of searching. High page load latency for landing pages (clicked search results) can reduce the efficiency of the search process. Proactively prefetching landing pages in advance of clickthrough can save searchers valuable time. However, prefetching consumes resources (primarily bandwidth and battery) that are wasted unless the prefetched results are requested by searchers. Balancing the costs in prefetching particular results against the benefits in reduced latency to searchers represents the search result prefetching challenge. In this article, we introduce this challenge and present methods to address it in both desktop and mobile settings. Our methods leverage searchers’ cursor movements (on desktop) and viewport-based viewing behavior (on mobile) on search engine result pages (SERPs) in real time to dynamically estimate the result that searchers will request next. We demonstrate through large-scale log analysis that our approach significantly outperforms three strong baselines that prefetch results based on (i) the search engine result ranking (prefetch top-ranked results), (ii) past SERP clicks from all searchers for the query (prefetch popular results), or (iii) past SERP clicks from the current searcher for the query (prefetch results that the searcher prefers). Our promising findings have implications for the design of search support in desktop and mobile settings that makes the search process more efficient.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2590277053",
    "type": "article"
  },
  {
    "title": "Search, Mining, and Their Applications on Mobile Devices",
    "doi": "https://doi.org/10.1145/3086665",
    "publication_date": "2017-08-24",
    "publication_year": 2017,
    "authors": "Hongning Wang; Rui Li; Milad Shokouhi; Hang Li; Yi Chang",
    "corresponding_authors": "",
    "abstract": "In recent years, mobile devices have become the most popular interface for users to retrieve and access information: recent reports show that users spend significantly more time and issue more search queries on mobile devices than on desktops in the United States. 1 The accelerated growth of mobile usage brings unique opportunities to the information retrieval and data mining research communities. Mobile devices capture rich contextual and personal signals that can be leveraged to accurately predict users’ intent for serving more relevant content and can even proactively provide novel zero-query recommendations. Apple Siri, Google Now, and Microsoft Cortana are recent examples of such emerging systems. Furthermore, mobile devices constantly generate a huge amount of sensor footprints (e.g., GPS, motion sensors) and user activity data (e.g., used apps) that are often missing from their desktop counterparts. These new sources of implicit and explicit user feedback are valuable for discovering actionable knowledge, and designing better systems that serve each individual the right content at the right time and location. In addition, by aggregating mobile interactions across individuals, one can infer interesting conclusions beyond search and recommendation. Generating real-time traffic estimates is one example of such applications. This special issue focuses on research problems of search, mining, and their applications in mobile devices. Topics of interest in this special issue include but are not limited to mobile data mining and management, mobile search, personalization and recommendation, mobile user interfaces and human-computer interaction, and new applications in the mobile environment. The aim of this special issue is to bring together top experts across multiple disciplines, including information retrieval, data mining, mobile computing, and cyberphysical systems, such that academic and industrial researchers can exchange ideas and share the latest developments on the state of the art and practice of mobile search and mobile data mining.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2746562412",
    "type": "article"
  },
  {
    "title": "Social Influence Spectrum at Scale",
    "doi": "https://doi.org/10.1145/3086700",
    "publication_date": "2017-08-21",
    "publication_year": 2017,
    "authors": "Hung T. Nguyen; Preetam Ghosh; Michael L. Mayo; Thang N. Dinh",
    "corresponding_authors": "",
    "abstract": "Given a social network, the Influence Maximization (InfMax) problem seeks a seed set of k people that maximizes the expected influence for a viral marketing campaign. However, a solution for a particular seed size k is often not enough to make an informed choice regarding budget and cost-effectiveness. In this article, we propose the computation of Influence Spectrum (InfSpec), the maximum influence at each possible seed set size k within a given range [ k lower , k upper ], thus providing optimal decision making for any availability of budget or influence requirements. As none of the existing methods for InfMax are efficient enough for the task in large networks, we propose LISA (sub-Linear Influence Spectrum Approximation), an efficient approximation algorithm for InfSpec (and also InfMax) with the best-known worst-case guarantees for billion-scale networks. LISA returns an (1-1/e -ϵ)-approximate influence spectrum with high probability (1-δ), where ϵ, δ are precision parameters provided by users. Using statistical decision theory, LISA has an asymptotic optimal running time (in addition to optimal approximation guarantee). In practice, LISA surpasses the state-of-the-art InfMax methods, taking less than 15 minutes to process a network of 41.7 million nodes and 1.5 billions edges.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2748305665",
    "type": "article"
  },
  {
    "title": "CO <sup>2</sup>",
    "doi": "https://doi.org/10.1145/3182164",
    "publication_date": "2018-03-13",
    "publication_year": 2018,
    "authors": "Long Guo; Dongxiang Zhang; Wang Yuan; Huayu Wu; Bin Cui; Kian‐Lee Tan",
    "corresponding_authors": "",
    "abstract": "User-generated trajectories (UGTs), such as travel records from bus companies, capture rich information of human mobility in the offline world. However, some interesting applications of these raw footprints have not been exploited well due to the lack of textual information to infer the subject’s personal interests. Although there is rich semantic information contained in the spatial- and temporal-aware user-generated contents (STUGC) published in the online world, such as Twitter, less effort has been made to utilize this information to facilitate the interest discovery process. In this article, we design an effective probabilistic framework named CO 2 to &lt;underline&gt;c&lt;/underline&gt;onnect the &lt;underline&gt;o&lt;/underline&gt;ffline world with the &lt;underline&gt;o&lt;/underline&gt;nline world in order to discover users’ interests directly from their raw footprints in UGT. CO 2 first infers trip intentions by utilizing the semantic information in STUGC and then discovers user interests by aggregating the intentions. To evaluate the effectiveness of CO 2 , we use two large-scale real-world datasets as a case study and further conduct a questionnaire survey to show the superior performance of CO 2 .",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2791307671",
    "type": "article"
  },
  {
    "title": "Swipe and Tell",
    "doi": "https://doi.org/10.1145/3185153",
    "publication_date": "2018-06-13",
    "publication_year": 2018,
    "authors": "Klaas Nelissen; Monique Snoeck; Seppe vanden Broucke; Bart Baesens",
    "corresponding_authors": "",
    "abstract": "When content consumers explicitly judge content positively, we consider them to be engaged. Unfortunately, explicit user evaluations are difficult to collect, as they require user effort. Therefore, we propose to use device interactions as implicit feedback to detect engagement. We assess the usefulness of swipe interactions on tablets for predicting engagement and make the comparison with using traditional features based on time spent. We gathered two unique datasets of more than 250,000 swipes, 100,000 unique article visits, and over 35,000 explicitly judged news articles by modifying two commonly used tablet apps of two newspapers. We tracked all device interactions of 407 experiment participants during one month of habitual news reading. We employed a behavioral metric as a proxy for engagement, because our analysis needed to be scalable to many users, and scanning behavior required us to allow users to indicate engagement quickly. We point out the importance of taking into account content ordering, report the most predictive features, zoom in on briefly read content and on the most frequently read articles. Our findings demonstrate that fine-grained tablet interactions are useful indicators of engagement for newsreaders on tablets. The best features successfully combine both time-based aspects and swipe interactions.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2808544295",
    "type": "article"
  },
  {
    "title": "SMAPH",
    "doi": "https://doi.org/10.1145/3284102",
    "publication_date": "2018-12-06",
    "publication_year": 2018,
    "authors": "Marco Cornolti; Paolo Ferragina; Massimiliano Ciaramita; Stefan Rüd; Hinrich Schütze",
    "corresponding_authors": "",
    "abstract": "We study the problem of linking the terms of a web-search query to a semantic representation given by the set of entities (a.k.a. concepts) mentioned in it. We introduce SMAPH, a system that performs this task using the information coming from a web search engine, an approach we call “piggybacking.” We employ search engines to alleviate the noise and irregularities that characterize the language of queries. Snippets returned as search results also provide a context for the query that makes it easier to disambiguate the meaning of the query. From the search results, SMAPH builds a set of candidate entities with high coverage. This set is filtered by linking back the candidate entities to the terms occurring in the input query, ensuring high precision. A greedy disambiguation algorithm performs this filtering; it maximizes the coherence of the solution by iteratively discovering the pertinent entities mentioned in the query. We propose three versions of SMAPH that outperform state-of-the-art solutions on the known benchmarks and on the GERDAQ dataset, a novel dataset that we have built specifically for this problem via crowd-sourcing and that we make publicly available.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2905300009",
    "type": "article"
  },
  {
    "title": "Emotional Conversation Generation Based on a Bayesian Deep Neural Network",
    "doi": "https://doi.org/10.1145/3368960",
    "publication_date": "2019-12-07",
    "publication_year": 2019,
    "authors": "Xiao Sun; Jia Li; Xing Wei; Changliang Li; Jianhua Tao",
    "corresponding_authors": "",
    "abstract": "The field of conversation generation using neural networks has attracted increasing attention from researchers for several years. However, traditional neural language models tend to generate a generic reply with poor semantic logic and no emotion. This article proposes an emotional conversation generation model based on a Bayesian deep neural network that can generate replies with rich emotions, clear themes, and diverse sentences. The topic and emotional keywords of the replies are pregenerated by introducing commonsense knowledge in the model. The reply is divided into multiple clauses, and then a multidimensional generator based on the transformer mechanism proposed in this article is used to iteratively generate clauses from two dimensions: sentence granularity and sentence structure. Subjective and objective experiments prove that compared with existing models, the proposed model effectively improves the semantic logic and emotional accuracy of replies. This model also significantly enhances the diversity of replies, largely overcoming the shortcomings of traditional models that generate safe replies.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2995833361",
    "type": "article"
  },
  {
    "title": "Offline versus Online Representation Learning of Documents Using External Knowledge",
    "doi": "https://doi.org/10.1145/3349527",
    "publication_date": "2019-09-19",
    "publication_year": 2019,
    "authors": "Lynda Tamine; Laure Soulier; Gia-Hung Nguyen; Nathalie Souf",
    "corresponding_authors": "",
    "abstract": "An intensive recent research work investigated the combined use of hand-curated knowledge resources and corpus-driven resources to learn effective text representations. The overall learning process could be run by online revising the learning objective or by offline refining an original learned representation. The differentiated impact of each of the learning approaches on the quality of the learned representations has not been studied so far in the literature. This article focuses on the design of comparable offline vs. online knowledge-enhanced document representation learning models and the comparison of their effectiveness using a set of standard IR and NLP downstream tasks. The results of quantitative and qualitative analyses show that (1) offline vs. online learning approaches have dissimilar result trends regarding the task as well as the dataset distribution counts with regard to domain application; (2) while considering external knowledge resources is undoubtedly beneficial, the way used to express relational constraints could affect semantic inference effectiveness. The findings of this work present opportunities for the design of future representation learning models, but also for providing insights about the evaluation of such models.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3004047605",
    "type": "article"
  },
  {
    "title": "Using an Inverted Index Synopsis for Query Latency and Performance Prediction",
    "doi": "https://doi.org/10.1145/3389795",
    "publication_date": "2020-05-18",
    "publication_year": 2020,
    "authors": "Nicola Tonellotto; Craig Macdonald",
    "corresponding_authors": "",
    "abstract": "Predicting the query latency by a search engine has important benefits, for instance, in allowing the search engine to adjust its configuration to address long-running queries without unnecessarily sacrificing its effectiveness. However, for the dynamic pruning techniques that underlie many commercial search engines, achieving accurate predictions of query latencies is difficult. We propose the use of index synopses—which are stochastic samples of the full index—for attaining accurate timing predictions. Indeed, we experiment using the TREC ClueWeb09 collection, and a large set of real user queries, and find that using small index synopses it is possible to very accurately estimate properties of the larger index, including sizes of posting list unions and intersections. Thereafter, we demonstrate that index synopses facilitate two key use cases: first, for query efficiency prediction, we show that predicting the query latencies on the full index and classifying long-running queries can be accurately achieved using index synopses; second, for query performance prediction, we show that the effectiveness of queries can be estimated more accurately using a synopsis index post-retrieval predictor than a pre-retrieval predictor. Overall, our experiments demonstrate the value of such a stochastic sample of a larger index at predicting the properties of the larger index.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3013057774",
    "type": "article"
  },
  {
    "title": "Learning to Respond with Your Favorite Stickers",
    "doi": "https://doi.org/10.1145/3429980",
    "publication_date": "2021-02-17",
    "publication_year": 2021,
    "authors": "Shen Gao; Xiuying Chen; Li Liu; Dongyan Zhao; Rui Yan",
    "corresponding_authors": "",
    "abstract": "Stickers with vivid and engaging expressions are becoming increasingly popular in online messaging apps, and some works are dedicated to automatically select sticker response by matching the stickers image with previous utterances. However, existing methods usually focus on measuring the matching degree between the dialog context and sticker image, which ignores the user preference of using stickers. Hence, in this article, we propose to recommend an appropriate sticker to user based on multi-turn dialog context and sticker using history of user. Two main challenges are confronted in this task. One is to model the sticker preference of user based on the previous sticker selection history. Another challenge is to jointly fuse the user preference and the matching between dialog context and candidate sticker into final prediction making. To tackle these challenges, we propose a Preference Enhanced Sticker Response Selector (PESRS) model. Specifically, PESRS first employs a convolutional-based sticker image encoder and a self-attention-based multi-turn dialog encoder to obtain the representation of stickers and utterances. Next, deep interaction network is proposed to conduct deep matching between the sticker and each utterance. Then, we model the user preference by using the recently selected stickers as input and use a key-value memory network to store the preference representation. PESRS then learns the short-term and long-term dependency between all interaction results by a fusion network and dynamically fuses the user preference representation into the final sticker selection prediction. Extensive experiments conducted on a large-scale real-world dialog dataset show that our model achieves the state-of-the-art performance for all commonly used metrics. Experiments also verify the effectiveness of each component of PESRS.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3129872977",
    "type": "article"
  },
  {
    "title": "Response Ranking with Multi-types of Deep Interactive Representations in Retrieval-based Dialogues",
    "doi": "https://doi.org/10.1145/3462207",
    "publication_date": "2021-08-17",
    "publication_year": 2021,
    "authors": "Ruijian Xu; Chongyang Tao; Jiazhan Feng; Wei Wu; Rui Yan; Dongyan Zhao",
    "corresponding_authors": "",
    "abstract": "Building an intelligent dialogue system with the ability to select a proper response according to a multi-turn context is challenging in three aspects: (1) the meaning of a context–response pair is built upon language units from multiple granularities (e.g., words, phrases, and sub-sentences, etc.); (2) local (e.g., a small window around a word) and long-range (e.g., words across the context and the response) dependencies may exist in dialogue data; and (3) the relationship between the context and the response candidate lies in multiple relevant semantic clues or relatively implicit semantic clues in some real cases. However, existing approaches usually encode the dialogue with mono-type representation and the interaction processes between the context and the response candidate are executed in a rather shallow manner, which may lead to an inadequate understanding of dialogue content and hinder the recognition of the semantic relevance between the context and response. To tackle these challenges, we propose a representation [ K ] -interaction [ L ] -matching framework that explores multiple types of deep interactive representations to build context-response matching models for response selection. Particularly, we construct different types of representations for utterance–response pairs and deepen them via alternate encoding and interaction. By this means, the model can handle the relation of neighboring elements, phrasal pattern, and long-range dependencies during the representation and make a more accurate prediction through multiple layers of interactions between the context–response pair. Experiment results on three public benchmarks indicate that the proposed model significantly outperforms previous conventional context-response matching models and achieve slightly better results than the BERT model for multi-turn response selection in retrieval-based dialogue systems.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3193603894",
    "type": "article"
  },
  {
    "title": "A Graph Theoretic Approach for Multi-Objective Budget Constrained Capsule Wardrobe Recommendation",
    "doi": "https://doi.org/10.1145/3457182",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Shubham Patil; Debopriyo Banerjee; Shamik Sural",
    "corresponding_authors": "",
    "abstract": "Traditionally, capsule wardrobes are manually designed by expert fashionistas through their creativity and technical prowess. The goal is to curate minimal fashion items that can be assembled into several compatible and versatile outfits. It is usually a cost and time intensive process, and hence lacks scalability. Although there are a few approaches that attempt to automate the process, they tend to ignore the price of items or shopping budget. In this article, we formulate this task as a multi-objective budget constrained capsule wardrobe recommendation ( MOBCCWR ) problem. It is modeled as a bipartite graph having two disjoint vertex sets corresponding to top-wear and bottom-wear items, respectively. An edge represents compatibility between the corresponding item pairs. The objective is to find a 1-neighbor subset of fashion items as a capsule wardrobe that jointly maximize compatibility and versatility scores by considering corresponding user-specified preference weight coefficients and an overall shopping budget as a means of achieving personalization. We study the complexity class of MOBCCWR , show that it is NP-Complete, and propose a greedy algorithm for finding a near-optimal solution in real time. We also analyze the time complexity and approximation bound for our algorithm. Experimental results show the effectiveness of the proposed approach on both real and synthetic datasets.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3198615823",
    "type": "article"
  },
  {
    "title": "Direction-Aware User Recommendation Based on Asymmetric Network Embedding",
    "doi": "https://doi.org/10.1145/3466754",
    "publication_date": "2021-11-16",
    "publication_year": 2021,
    "authors": "Sheng Zhou; Xin Wang; Martin Ester; Bolang Li; Chen Ye; Zhen Zhang; Can Wang; Jiajun Bu",
    "corresponding_authors": "",
    "abstract": "User recommendation aims at recommending users with potential interests in the social network. Previous works have mainly focused on the undirected social networks with symmetric relationship such as friendship, whereas recent advances have been made on the asymmetric relationship such as the following and followed by relationship. Among the few existing direction-aware user recommendation methods, the random walk strategy has been widely adopted to extract the asymmetric proximity between users. However, according to our analysis on real-world directed social networks, we argue that the asymmetric proximity captured by existing random walk based methods are insufficient due to the inbalance in-degree and out-degree of nodes. To tackle this challenge, we propose InfoWalk, a novel informative walk strategy to efficiently capture the asymmetric proximity solely based on random walks. By transferring the direction information into the weights of each step, InfoWalk is able to overcome the limitation of edges while simultaneously maintain both the direction and proximity. Based on the asymmetric proximity captured by InfoWalk, we further propose the qualitative (DNE-L) and quantitative (DNE-T) directed network embedding methods, capable of preserving the two properties in the embedding space. Extensive experiments conducted on six real-world benchmark datasets demonstrate the superiority of the proposed DNE model over several state-of-the-art approaches in various tasks.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3214350751",
    "type": "article"
  },
  {
    "title": "Boosting Recommendation in Unexplored Categories by User Price Preference",
    "doi": "https://doi.org/10.1145/2978579",
    "publication_date": "2016-10-10",
    "publication_year": 2016,
    "authors": "Jia Chen; Qin Jin; Shiwan Zhao; Shenghua Bao; Li Zhang; Zhong Su; Yong Yu",
    "corresponding_authors": "",
    "abstract": "State-of-the-art methods for product recommendation encounter a significant performance drop in categories where a user has no purchase history. This problem needs to be addressed since current online retailers are moving beyond single category and attempting to be diversified. In this article, we investigate the challenging problem of product recommendation in unexplored categories and discover that the price, a factor comparable across categories, can improve the recommendation performance significantly. We introduce the price utility concept to characterize users’ sense of price and propose three different utility functions. We show that user price preference in a category is a distribution and we mine typical user price preference patterns based on three different types of distance between distributions. We fuse user price preference through regularization and joint factorization to boost recommendation performance in both browsing and buying shopping orientations. Experimental results show that fusing user price preference improves performance in a series of recommendation tasks: unexplored category recommendation, product recommendation under a given unexplored category, and product recommendation under generic unexplored categories.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2531811925",
    "type": "article"
  },
  {
    "title": "Learning Relation Ties with a Force-Directed Graph in Distant Supervised Relation Extraction",
    "doi": "https://doi.org/10.1145/3520082",
    "publication_date": "2022-03-09",
    "publication_year": 2022,
    "authors": "Yu-Ming Shang; Heyan Huang; Xin Sun; Wei Wei; Xian-Ling Mao",
    "corresponding_authors": "",
    "abstract": "Relation ties, defined as the correlation and mutual exclusion between different relations, are critical for distant supervised relation extraction. Previous studies usually obtain this property by greedily learning the local connections between relations. However, they are essentially limited because of failing to capture the global topology structure of relation ties and may easily fall into a locally optimal solution. To address this issue, we propose a novel force-directed graph to comprehensively learn relation ties. Specifically, we first construct a graph according to the global co-occurrence of all relations. Then, we borrow the idea of Coulomb’s law from physics and introduce the concept of attractive force and repulsive force into this graph to learn correlation and mutual exclusion between relations. Finally, the obtained relation representations are applied as an inter-dependent relation classifier. Extensive experimental results demonstrate that our method is capable of modeling global correlation and mutual exclusion between relations, and outperforms the state-of-the-art baselines. In addition, the proposed force-directed graph can be used as a module to augment existing relation extraction systems and improve their performance.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3017797966",
    "type": "article"
  },
  {
    "title": "GraphHINGE: Learning Interaction Models of Structured Neighborhood on Heterogeneous Information Network",
    "doi": "https://doi.org/10.1145/3472956",
    "publication_date": "2022-03-24",
    "publication_year": 2022,
    "authors": "Jiarui Jin; Kounianhua Du; Weinan Zhang; Jiarui Qin; Yuchen Fang; Yong Yu; Zheng Zhang; Alexander J. Smola",
    "corresponding_authors": "",
    "abstract": "Heterogeneous information network (HIN) has been widely used to characterize entities of various types and their complex relations. Recent attempts either rely on explicit path reachability to leverage path-based semantic relatedness or graph neighborhood to learn heterogeneous network representations before predictions. These weakly coupled manners overlook the rich interactions among neighbor nodes, which introduces an early summarization issue. In this article, we propose GraphHINGE ( H eterogeneous IN teract and aggre G at E ), which captures and aggregates the interactive patterns between each pair of nodes through their structured neighborhoods. Specifically, we first introduce Neighborhood-based Interaction (NI) module to model the interactive patterns under the same metapaths, and then extend it to Cross Neighborhood-based Interaction (CNI) module to deal with different metapaths. Next, in order to address the complexity issue on large-scale networks, we formulate the interaction modules via a convolutional framework and learn the parameters efficiently with fast Fourier transform. Furthermore, we design a novel neighborhood-based selection (NS) mechanism, a sampling strategy, to filter high-order neighborhood information based on their low-order performance. The extensive experiments on six different types of heterogeneous graphs demonstrate the performance gains by comparing with state-of-the-arts in both click-through rate prediction and top-N recommendation tasks.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3175976391",
    "type": "article"
  },
  {
    "title": "Multimodal Web Page Segmentation Using Self-organized Multi-objective Clustering",
    "doi": "https://doi.org/10.1145/3480966",
    "publication_date": "2022-03-07",
    "publication_year": 2022,
    "authors": "S. Jayashree; Gaël Dias; Judith Jeyafreeda Andrew; Sriparna Saha; Fabrice Maurel; Stéphane Ferrari",
    "corresponding_authors": "",
    "abstract": "Web page segmentation (WPS) aims to break a web page into different segments with coherent intra- and inter-semantics. By evidencing the morpho-dispositional semantics of a web page, WPS has traditionally been used to demarcate informative from non-informative content, but it has also evidenced its key role within the context of non-linear access to web information for visually impaired people. For that purpose, a great deal of ad hoc solutions have been proposed that rely on visual, logical, and/or text cues. However, such methodologies highly depend on manually tuned heuristics and are parameter-dependent. To overcome these drawbacks, principled frameworks have been proposed that provide the theoretical bases to achieve optimal solutions. However, existing methodologies only combine few discriminant features and do not define strategies to automatically select the optimal number of segments. In this article, we present a multi-objective clustering technique called MCS that relies on \\( K \\) -means, in which (1) visual, logical, and text cues are all combined in a early fusion manner and (2) an evolutionary process automatically discovers the optimal number of clusters (segments) as well as the correct positioning of seeds. As such, our proposal is parameter-free, combines many different modalities, does not depend on manually tuned heuristics, and can be run on any web page without any constraint. An exhaustive evaluation over two different tasks, where (1) the number of segments must be discovered or (2) the number of clusters is fixed with respect to the task at hand, shows that MCS drastically improves over most competitive and up-to-date algorithms for a wide variety of external and internal validation indices. In particular, results clearly evidence the impact of the visual and logical modalities towards segmentation performance.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4206845400",
    "type": "article"
  },
  {
    "title": "Leveraging Narrative to Generate Movie Script",
    "doi": "https://doi.org/10.1145/3507356",
    "publication_date": "2022-02-01",
    "publication_year": 2022,
    "authors": "Yutao Zhu; Ruihua Song; Jian‐Yun Nie; Pan Du; Zhicheng Dou; Jin Zhou",
    "corresponding_authors": "",
    "abstract": "Generating a text based on a predefined guideline is an interesting but challenging problem. A series of studies have been carried out in recent years. In dialogue systems, researchers have explored driving a dialogue based on a plan, while in story generation, a storyline has also been proved to be useful. In this article, we address a new task—generating movie scripts based on a predefined narrative. As an early exploration, we study this problem in a “retrieval-based” setting. We propose a model (ScriptWriter-CPre) to select the best response (i.e., next script line) among the candidates that fit the context (i.e., previous script lines) as well as the given narrative. Our model can keep track of what in the narrative has been said and what is to be said. Besides, it can also predict which part of the narrative should be paid more attention to when selecting the next line of script. In our study, we find the narrative plays a different role than the context. Therefore, different mechanisms are designed for deal with them. Due to the unavailability of data for this new application, we construct a new large-scale data collection GraphMovie from a movie website where end-users can upload their narratives freely when watching a movie. This new dataset is made available publicly to facilitate other studies in text generation under the guideline. Experimental results on the dataset show that our proposed approach based on narratives significantly outperforms the baselines that simply use the narrative as a kind of context.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4220896903",
    "type": "article"
  },
  {
    "title": "RESUS: Warm-up Cold Users via Meta-learning Residual User Preferences in CTR Prediction",
    "doi": "https://doi.org/10.1145/3564283",
    "publication_date": "2022-09-19",
    "publication_year": 2022,
    "authors": "Yanyan Shen; Lifan Zhao; Weiyu Cheng; Zibin Zhang; Wenwen Zhou; Kangyi Lin",
    "corresponding_authors": "",
    "abstract": "Click-Through Rate (CTR) prediction on cold users is a challenging task in recommender systems. Recent researches have resorted to meta-learning to tackle the cold-user challenge, which either perform few-shot user representation learning or adopt optimization-based meta-learning. However, existing methods suffer from information loss or inefficient optimization process, and they fail to explicitly model global user preference knowledge which is crucial to complement the sparse and insufficient preference information of cold users. In this paper, we propose a novel and efficient approach named RESUS, which decouples the learning of global preference knowledge contributed by collective users from the learning of residual preferences for individual users. Specifically, we employ a shared predictor to infer basis user preferences, which acquires global preference knowledge from the interactions of different users. Meanwhile, we develop two efficient algorithms based on the nearest neighbor and ridge regression predictors, which infer residual user preferences via learning quickly from a few user-specific interactions. Extensive experiments on three public datasets demonstrate that our RESUS approach is efficient and effective in improving CTR prediction accuracy on cold users, compared with various state-of-the-art methods.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4296371110",
    "type": "article"
  },
  {
    "title": "Studying the Impact of Data Disclosure Mechanism in Recommender Systems via Simulation",
    "doi": "https://doi.org/10.1145/3569452",
    "publication_date": "2022-10-25",
    "publication_year": 2022,
    "authors": "Ziqian Chen; Fei Sun; Yifan Tang; Haokun Chen; Jinyang Gao; Bolin Ding",
    "corresponding_authors": "",
    "abstract": "Recently, privacy issues in web services that rely on users’ personal data have raised great attention. Despite that recent regulations force companies to offer choices for each user to opt-in or opt-out of data disclosure, real-world applications usually only provide an “all or nothing” binary option for users to either disclose all their data or preserve all data with the cost of no personalized service. In this article, we argue that such a binary mechanism is not optimal for both consumers and platforms. To study how different privacy mechanisms affect users’ decisions on information disclosure and how users’ decisions affect the platform’s revenue, we propose a privacy-aware recommendation framework that gives users fine control over their data. In this new framework, users can proactively control which data to disclose based on the tradeoff between anticipated privacy risks and potential utilities. Then we study the impact of different data disclosure mechanisms via simulation with reinforcement learning due to the high cost of real-world experiments. The results show that the platform mechanisms with finer split granularity and more unrestrained disclosure strategy can bring better results for both consumers and platforms than the “all or nothing” mechanism adopted by most real-world applications.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4307203489",
    "type": "article"
  },
  {
    "title": "Shortening the <i>OED</i>",
    "doi": "https://doi.org/10.1145/146760.146764",
    "publication_date": "1992-07-01",
    "publication_year": 1992,
    "authors": "G. Elizabeth Blake; Tim Bray; Frank Wm. Tompa",
    "corresponding_authors": "",
    "abstract": "Textual databases with highly variable structure can be usefully described by a grammar-defined model. One example of such a text is the Oxford English Dictionary . This paper describes a first attempt to apply technology based on this model to a real problem. A language called GOEDEL, which is a partial implementation of a set of grammar-defined database operators, was used to extract and alter a subset of the OED in order to assist the editors in their production of The Shorter Oxford English Dictionary . The implementation of the pstring data structure to describe a piece of text and the functions that operate on this pstring are illustrated with some detailed examples. The project was judged a success and the resulting program used in production by the Oxford University Press.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2092292397",
    "type": "article"
  },
  {
    "title": "The envoy framework",
    "doi": "https://doi.org/10.1145/146760.146770",
    "publication_date": "1992-07-01",
    "publication_year": 1992,
    "authors": "Murugappan Palaniappan; Nicole Yankelovich; George Fitzmaurice; Anne Loomis; Bernard J. Haan; James H. Coombs; Norman Meyrowitz",
    "corresponding_authors": "",
    "abstract": "The Envoy Framework addresses a need for computer-based assistants or agents that operate in conjunction with users' existing applications, helping them perform tedious, repetitive, or time-consuming tasks more easily and efficiently. Envoys carry out missions for users by invoking envoy-aware applications called operatives and inform users of mission results via envoy-aware applications called informers. The distributed, open architecture developed for Envoys is derived from an analysis of the best characteristics of existing agent systems. This architecture has been designed as a model for how agent technology can be seamlessly integrated into the electronic desktop. It defines a set of application programmer's interfaces so that developers may convert their software to envoy-aware applications. A subset of the architecture described in this paper has been implemented in an Envoy Framework prototype.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2161976736",
    "type": "article"
  },
  {
    "title": "Transporting the linguistic string project system from a medical to a Navy domain",
    "doi": "https://doi.org/10.1145/3914.3984",
    "publication_date": "1985-04-01",
    "publication_year": 1985,
    "authors": "Elaine Marsh; Carol Friedman",
    "corresponding_authors": "",
    "abstract": "The Linguistic String Project (LSP) natural language processing system has been developed as a domain-independent natural language processing system. Initially utilized for processing sets of medical messages and other texts in the medical domain, it has been used at the Naval Research Laboratory for processing Navy messages about shipboard equipment failures. This paper describes the structure of the LSP system and the features that make it transportable from one domain to another. The processing procedures encourage the isolation of domain-specific information, yet take advantage of the syntactic and semantic similarities between the medical and Navy domains. From our experience in transporting the LSP system, we identify the features that are required for transportable natural language systems.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2069767820",
    "type": "article"
  },
  {
    "title": "PicASHOW",
    "doi": "https://doi.org/10.1145/503104.503105",
    "publication_date": "2002-01-01",
    "publication_year": 2002,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We describe PicASHOW, a fully automated WWW image retrieval system that is based on several link-structure analyzing algorithms. Our basic premise is that a page p displays (or links to) an image when the author of p considers the image to be of value to the viewers of the page. We thus extend some well known link-based WWW page retrieval schemes to the context of image retrieval.PicASHOW's analysis of the link structure enables it to retrieve relevant images even when those are stored in files with meaningless names. The same analysis also allows it to identify image containers and image hubs . We define these as Web pages that are rich in relevant images, or from which many images are readily accessible.PicASHOW requires no image analysis whatsoever and no creation of taxonomies for preclassification of the Web's images. It can be implemented by standard WWW search engines with reasonable overhead, in terms of both computations and storage, and with no change to user query formats. It can thus be used to easily add image retrieving capabilities to standard search engines.Our results demonstrate that PicASHOW, while relying almost exclusively on link analysis, compares well with dedicated WWW image retrieval systems. We conclude that link analysis, a proven effective technique for Web page search, can improve the performance of Web image retrieval, as well as extend its definition to include the retrieval of image hubs and containers.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4234450598",
    "type": "article"
  },
  {
    "title": "Message addressing schemes",
    "doi": "https://doi.org/10.1145/357417.357422",
    "publication_date": "1984-01-01",
    "publication_year": 1984,
    "authors": "D. Tsichritzis",
    "corresponding_authors": "D. Tsichritzis",
    "abstract": "article Free Access Share on Message addressing schemes Author: D. Tsichritzis Computer Systems Research Group, University of Toronto, Toronto, Ont., Canada M5S 1A4 Computer Systems Research Group, University of Toronto, Toronto, Ont., Canada M5S 1A4View Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 101 January 1984pp 58–77https://doi.org/10.1145/357417.357422Published:01 January 1984Publication History 9citation358DownloadsMetricsTotal Citations9Total Downloads358Last 12 Months17Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2072686104",
    "type": "article"
  },
  {
    "title": "Introduction to keeping, refinding and sharing personal information",
    "doi": "https://doi.org/10.1145/1402256.1402257",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Deborah Barreau; R. Capra; Susan Dumais; William Jones; Manuel A. Pérez-Quiñones",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to keeping, refinding and sharing personal information Authors: Deborah Barreau University of North Carolina at Chapel Hill University of North Carolina at Chapel HillView Profile , Robert Capra University of North Carolina at Chapel Hill University of North Carolina at Chapel HillView Profile , Susan Dumais Microsoft Corporation Microsoft CorporationView Profile , William Jones University of Washington University of WashingtonView Profile , Manuel Pérez-Quiñones Virginia Polytechnic Institute and State University Virginia Polytechnic Institute and State UniversityView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 26Issue 4Article No.: 18pp 1–3https://doi.org/10.1145/1402256.1402257Published:07 October 2008Publication History 3citation0DownloadsMetricsTotal Citations3Total Downloads0Last 12 Months0Last 6 weeks0 Get Citation Alerts Save to binder temporarily unavailable - maintenance in progressSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2057802142",
    "type": "article"
  },
  {
    "title": "Efficient k-nearest neighbor searching in nonordered discrete data spaces",
    "doi": "https://doi.org/10.1145/1740592.1740595",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "Dashiell Kolbe; Qiang Zhu; Sakti Pramanik",
    "corresponding_authors": "",
    "abstract": "Numerous techniques have been proposed in the past for supporting efficient k -nearest neighbor ( k -NN) queries in continuous data spaces. Limited work has been reported in the literature for k -NN queries in a nonordered discrete data space (NDDS). Performing k -NN queries in an NDDS raises new challenges. The Hamming distance is usually used to measure the distance between two vectors (objects) in an NDDS. Due to the coarse granularity of the Hamming distance, a k -NN query in an NDDS may lead to a high degree of nondeterminism for the query result. We propose a new distance measure, called Granularity-Enhanced Hamming (GEH) distance, which effectively reduces the number of candidate solutions for a query. We have also implemented k -NN queries using multidimensional database indexing in NDDSs. Further, we use the properties of our multidimensional NDDS index to derive the probability of encountering valid neighbors within specific regions of the index. This probability is used to develop a new search ordering heuristic. Our experiments on synthetic and genomic data sets demonstrate that our index-based k -NN algorithm is efficient in finding k -NNs in both uniform and nonuniform data sets in NDDSs and that our heuristics are effective in improving the performance of such queries.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1992267648",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/1402256.1402264",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Gary Marchionini",
    "corresponding_authors": "Gary Marchionini",
    "abstract": "Peer review is an important resource of scholarly communities and must be managed and nurtured carefully. Electronic manuscript management systems have begun to improve some aspects of workflow for conferences and journals but also raise issues related to reviewer roles and reputations and the control of reviews over time. Professional societies should make their policies related to reviews and reviewer histories clear to authors and reviewers, develop strategies and tools to facilitate good and timely reviews, and facilitate the training of new reviewers.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2090634054",
    "type": "editorial"
  },
  {
    "title": "Ranking function adaptation with boosting trees",
    "doi": "https://doi.org/10.1145/2037661.2037663",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "Keke Chen; Jing Bai; Zhaohui Zheng",
    "corresponding_authors": "",
    "abstract": "Machine-learned ranking functions have shown successes in Web search engines. With the increasing demands on developing effective ranking functions for different search domains, we have seen a big bottleneck, that is, the problem of insufficient labeled training data, which has significantly slowed the development and deployment of machine-learned ranking functions for different domains. There are two possible approaches to address this problem: (1) combining labeled training data from similar domains with the small target-domain labeled data for training or (2) using pairwise preference data extracted from user clickthrough log for the target domain for training. In this article, we propose a new approach called tree-based ranking function adaptation (Trada) to effectively utilize these data sources for training cross-domain ranking functions. Tree adaptation assumes that ranking functions are trained with the Stochastic Gradient Boosting Trees method—a gradient boosting method on regression trees. It takes such a ranking function from one domain and tunes its tree-based structure with a small amount of training data from the target domain. The unique features include (1) automatic identification of the part of the model that needs adjustment for the new domain and (2) appropriate weighing of training examples considering both local and global distributions. Based on a novel pairwise loss function that we developed for pairwise learning, the basic tree adaptation algorithm is also extended (Pairwise Trada) to utilize the pairwise preference data from the target domain to further improve the effectiveness of adaptation. Experiments are performed on real datasets to show that tree adaptation can provide better-quality ranking functions for a new domain than other methods.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2129231817",
    "type": "article"
  },
  {
    "title": "Dual-factor Generation Model for Conversation",
    "doi": "https://doi.org/10.1145/3394052",
    "publication_date": "2020-06-05",
    "publication_year": 2020,
    "authors": "Ruqing Zhang; Jiafeng Guo; Yixing Fan; Yanyan Lan; Xueqi Cheng",
    "corresponding_authors": "",
    "abstract": "The conversation task is usually formulated as a conditional generation problem, i.e., to generate a natural and meaningful response given the input utterance. Generally speaking, this formulation is apparently based on an oversimplified assumption that the response is solely dependent on the input utterance. It ignores the subjective factor of the responder, e.g., his/her emotion or knowledge state, which is a major factor that affects the response in practice. Without explicitly differentiating such subjective factor behind the response, existing generation models can only learn the general shape of conversations, leading to the blandness problem of the response. Moreover, there is no intervention mechanism within the existing generation process, since the response is fully decided by the input utterance. In this work, we propose to view the conversation task as a dual-factor generation problem, including an objective factor denoting the input utterance and a subjective factor denoting the responder state. We extend the existing neural sequence-to-sequence (Seq2Seq) model to accommodate the responder state modeling. We introduce two types of responder state, i.e., discrete and continuous state, to model emotion state and topic preference state, respectively. We show that with our dual-factor generation model, we can not only better fit the conversation data, but also actively control the generation of the response with respect to sentiment or topic specificity.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3033557797",
    "type": "article"
  },
  {
    "title": "Fast Forward Index Methods for Pseudo-Relevance Feedback Retrieval",
    "doi": "https://doi.org/10.1145/2744199",
    "publication_date": "2015-05-13",
    "publication_year": 2015,
    "authors": "Edward Kai Fung Dang; Robert W. P. Luk; James Allan",
    "corresponding_authors": "",
    "abstract": "The inverted index is the dominant indexing method in information retrieval systems. It enables fast return of the list of all documents containing a given query term. However, for retrieval schemes involving query expansion, as in pseudo-relevance feedback (PRF), the retrieval time based on an inverted index increases linearly with the number of expansion terms. In this regard, we have examined the use of a forward index , which consists of the mapping of each document to its constituent terms. We propose a novel forward index-based reranking scheme to shorten the PRF retrieval time. In our method, a first retrieval of the original query is performed using an inverted index, and then a forward index is employed for the PRF part. We have studied several new forward indexes, including using a novel spstring data structure and the weighted variable bit-block compression (wvbc) signature. With modern hardware such as solid-state drives (SSDs) and sufficiently large main memory, forward index methods are particularly promising. We find that with the whole index stored in main memory, PRF retrieval using a spstring or wvbc forward index excels in time efficiency over an inverted index, being able to obtain the same levels of performance measures at shorter times.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2246718308",
    "type": "article"
  },
  {
    "title": "The Effects of Aggregated Search Coherence on Search Behavior",
    "doi": "https://doi.org/10.1145/2935747",
    "publication_date": "2016-09-22",
    "publication_year": 2016,
    "authors": "Jaime Arguello; R. Capra",
    "corresponding_authors": "",
    "abstract": "Aggregated search is the task of combining results from multiple independent search systems in a single Search Engine Results Page (SERP). Aggregated search coherence refers to the extent to which different sources on the SERP focus on similar senses of an ambiguous or underspecified query. In previous studies, we found that the query senses in a set of vertical results can influence user engagement with the web results (the so-called “spillover” effect). In this work, we investigate five research questions (RQ1--RQ5) that extend our prior work. First, we investigate the extent to which results from different sources focus on different senses of an ambiguous query (RQ1). Second, we investigate how the vertical-to-web spillover effect varies across different verticals (RQ2). Then, we examine whether the level of spillover depends on the vertical position (RQ3) and on whether the vertical results are displayed with a border and different-colored background to distinguish them from the web results (RQ4). Finally, we propose a new method for displaying results from a particular vertical that are more consistent with the query senses in the web results (RQ5). We evaluate this new method based on how it influences users to make more correct decisions with respect to the web results—to engage with the web results when at least one of them is relevant and to avoid engaging with the web results otherwise. Our results show the following trends. In terms of RQ1, our analysis suggests that the top results from the web search engine are more diversified than the top results from our four different verticals considered (images, news, shopping, and video). In terms of RQ2, we found a stronger spillover effect for the images vertical than the news, shopping, and video verticals. In terms of RQ3, we found a stronger level of spillover when the vertical was positioned at the top of the SERP versus to the right side of the web results. In terms of RQ4, we found an interesting additive effect between the vertical’s position and displaying the vertical results enclosed in a border and with a different-colored background—the image vertical had no spillover when presented to the right side of the web results and with a border and background. Finally, in terms of RQ5, we found that our proposed vertical results selection approach can influence users to make more correct predictions about their level of engagement with the web results.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2521475904",
    "type": "article"
  },
  {
    "title": "Context Trees",
    "doi": "https://doi.org/10.1145/2978578",
    "publication_date": "2016-10-10",
    "publication_year": 2016,
    "authors": "Alasdair Thomason; Nathan Griffiths; Víctor F. Vásquez Sánchez",
    "corresponding_authors": "",
    "abstract": "Exposing latent knowledge in geospatial trajectories has the potential to provide a better understanding of the movements of individuals and groups. Motivated by such a desire, this work presents the context tree , a new hierarchical data structure that summarises the context behind user actions in a single model. We propose a method for context tree construction that augments geospatial trajectories with land usage data to identify such contexts. Through evaluation of the construction method and analysis of the properties of generated context trees, we demonstrate the foundation for understanding and modelling behaviour afforded. Summarising user contexts into a single data structure gives easy access to information that would otherwise remain latent, providing the basis for better understanding and predicting the actions and behaviours of individuals and groups. Finally, we also present a method for pruning context trees for use in applications where it is desirable to reduce the size of the tree while retaining useful information.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4300578593",
    "type": "article"
  },
  {
    "title": "Better Understanding Procedural Search Tasks: Perceptions, Behaviors, and Challenges",
    "doi": "https://doi.org/10.1145/3630004",
    "publication_date": "2023-10-23",
    "publication_year": 2023,
    "authors": "Bogeum Choi; Sarah Casteel; Jaime Arguello; R. Capra",
    "corresponding_authors": "",
    "abstract": "People often search for information to acquire procedural knowledge–“how to” knowledge about step-by-step procedures, methods, algorithms, techniques, heuristics, and skills. A procedural search task might involve implementing a solution to a problem, evaluating different approaches to a problem, and brainstorming on the types of problems that can be solved with a specific resource. We report on a study ( N =36) that aimed to better understand how people search for procedural knowledge. Much research has investigated how search task characteristics impact people’s perceptions and behaviors. Along these lines, we manipulated procedural search tasks along two orthogonal dimensions: product and goal. The product dimension relates to the main outcome of the task and the goal dimension relates to task’s success criteria. We manipulated tasks across three product categories and two goal categories. The study investigated four research questions. First, we examined the effects of the product and goal on participants’ (RQ1) pre-task perceptions, (RQ2) post-task perceptions, and (RQ3) search behaviors. Second, regardless of the task product and goal, by analyzing participants’ think-aloud comments and screen activities we closely examined how people search for procedural knowledge. Specifically, we report on (RQ4) important relevance criteria, types of information sought, and challenges.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4387868987",
    "type": "article"
  },
  {
    "title": "On deductive databases with incomplete information",
    "doi": "https://doi.org/10.1145/203052.203074",
    "publication_date": "1995-07-01",
    "publication_year": 1995,
    "authors": "Q. Kong; Greg G.Chen",
    "corresponding_authors": "",
    "abstract": "In order to extend the ability to handle incomplete information in a definite deductive database, a Horn clause-based system representing incomplete information as incomplete constants is proposed. By using the notion of incomplete constants the deductive database system handles incomplete information in the form of sets of possible values, thereby giving more information than null values. The resulting system extends Horn logic to express a restricted form of indefiniteness. Although a deductive database with this kind of incomplete information is, in fact, a subset of an indefinite deductive database system, it represents indefiniteness in terms of value incompleteness, and therefore it can make use of the existing Horn logic computation rules. The inference rules for such a system are presented, its model theory discussed, and a model theory of indefiniteness proposed. The theory is consistent with minimal model theory and extends its expressive power.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2022924061",
    "type": "article"
  },
  {
    "title": "Estimating accesses in partitioned signature file organizations",
    "doi": "https://doi.org/10.1145/130226.145014",
    "publication_date": "1993-04-01",
    "publication_year": 1993,
    "authors": "Paolo Ciaccia; Pavel Zezula",
    "corresponding_authors": "",
    "abstract": "We show that performance of some basic methods for the partitioning of signature files, namely Quick Filter and Fixed Prefix, can be easily evaluated by means of a closed formula. The approximation is based on well-known results from probability theory, and, as shown by simulations, introduces no appreciable errors when compared with the exact, cumbersome formulas used so far. Furthermore, we prove that the exact formulas for the two methods coincide. Although this does not imply that the two methods behave in the same way, it sheds light on the way they could be compared.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2007748621",
    "type": "article"
  },
  {
    "title": "Phone-based CSCW",
    "doi": "https://doi.org/10.1145/159764.159760",
    "publication_date": "1993-10-01",
    "publication_year": 1993,
    "authors": "Paul Resnick",
    "corresponding_authors": "Paul Resnick",
    "abstract": "Telephones are the most ubiquitous, best-networked, and simplest computer terminals available today. They have been used for voice mail but largely overlooked as a platform for asynchronous cooperative-work applications such as event calendars, issue discussions, and question-and-answer gathering. HyperVoice is a software toolkit for constructing such applications. Its building blocks are high-level presentation formats for collections of structured voice messages. The presentation formats can themselves be presented and manipulated, enabling significant customization of applications by phone. Results of two field trials suggest social-context factors that will influence the success or failure of phone-based cooperative work applications in particular settings.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2042010493",
    "type": "article"
  },
  {
    "title": "Designing database interfaces with DBface",
    "doi": "https://doi.org/10.1145/130226.134481",
    "publication_date": "1993-04-01",
    "publication_year": 1993,
    "authors": "Roger King; Michael Novak",
    "corresponding_authors": "",
    "abstract": "DBface is a toolkit for designing interfaces to object-oriented databases. It provides users with a set of tools for building custom interfaces with minimal programming. This is accomplished by combining techniques from User Interface Management Systems (UIMS) with a built-in knowledge about the specific kinds of techniques used by object-oriented databases. DBface allows users to create graphical constructs and interactive techniques by taking advantage of an object-oriented database environment and tools. Not only can database tools be used for creating an interface, but information about the interface being built is stored within a database schema and is syntactically consistent with all other schema information. Thus, an interface can deal with data and schema information, including information about another interface. This allows for easy reusability of graphical constructs such as data representations.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2048827668",
    "type": "article"
  },
  {
    "title": "Exploiting parallelism in pattern matching",
    "doi": "https://doi.org/10.1145/103731.103734",
    "publication_date": "1991-01-03",
    "publication_year": 1991,
    "authors": "Victor Mak; Kuo Chu Lee; Ophir Frieder",
    "corresponding_authors": "",
    "abstract": "We propose a document-searching architecture based on high-speed hardware pattern matching to increase the throughput of an information retrieval system. We also propose a new parallel VLSI pattern-matching algorithm called the Data Parallel Pattern Matching (DPPM) algorithm, which serially broadcasts and compares the pattern to a block of data in parallel. The DPPM algorithm utilizes the high degree of integration of VLSI technology to attain very high-speed processing through parallelism. Performance of the DPPM has been evaluated both analytically and by simulation. Based on the simulation statistics and timing analysis on the hardware design, a search rate of multiple gigabytes per second is achievable using 2-μm CMOS technology. The potential performance of the proposed document-searching architecture is also analyzed using the simulation statistics of the DPPM algorithm.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2004978723",
    "type": "article"
  },
  {
    "title": "Cursor movement during text editing",
    "doi": "https://doi.org/10.1145/3864.3867",
    "publication_date": "1985-01-02",
    "publication_year": 1985,
    "authors": "John D. Gould; Clayton Lewis; Vincent Barnes",
    "corresponding_authors": "",
    "abstract": "Nine participants used a full-screen computer text editor (XEDIT) with an IBM 3277 terminal to edit marked-up documents at each of three cursor speeds (3.3, 4.7, and 11.0 cm/s). These speeds occur when a user continuously holds down an arrow key to move the cursor more than one character position (i.e., in repeat or typamatic mode). Results show that cursor speed did not seem to act as a pacing device for the entire editing task. Since cursor speed is a form of system response, this finding is in contrast with the generally found positive relation between system-response time and user-response time. Participants preferred the Fast cursor speed, however. Overall, more than one-third of all keystrokes were used to move the cursor. We estimate that 9-14 percent of editing time was spent controlling and moving the cursor, regardless of cursor speed.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2032731307",
    "type": "article"
  },
  {
    "title": "Early user---system interaction for database selection in massive domain-specific online environments",
    "doi": "https://doi.org/10.1145/635484.635488",
    "publication_date": "2003-01-01",
    "publication_year": 2003,
    "authors": "Jack G. Conrad; Joanne R. S. Claussen",
    "corresponding_authors": "",
    "abstract": "The continued growth of very large data environments such as Westlaw and Dialog, in addition to the World Wide Web, increases the importance of effective and efficient database selection and searching. Current research focuses largely on completely autonomous and automatic selection, searching, and results merging in distributed environments. This fully automatic approach has significant deficiencies, including reliance upon thresholds below which databases with relevant documents are not searched (compromised recall). It also merges documents, often from disparate data sources that users may have discarded before their source selection task proceeded (diluted precision). We examine the impact that early user interaction can have on the process of database selection. After analyzing thousands of real user queries, we show that precision can be significantly increased when queries are categorized by the users themselves, then handled effectively by the system. Such query categorization strategies may eliminate limitations of fully automated query processing approaches. Our system harnesses the WIN search engine, a sibling to INQUERY, run against one or more authority sources when search is required. We compare our approach to one that does not recognize or utilize distinct features associated with user queries. We show that by avoiding a one-size-fits-all approach that restricts the role users can play in information discovery, database selection effectiveness can be appreciably improved.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2078165184",
    "type": "article"
  },
  {
    "title": "Extended probabilistic HAL with close temporal association for psychiatric query document retrieval",
    "doi": "https://doi.org/10.1145/1416950.1416954",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Jui‐Feng Yeh; Chung‐Hsien Wu; Liang-Chih Yu; Yu‐Sheng Lai",
    "corresponding_authors": "",
    "abstract": "Psychiatric query document retrieval can assist individuals to locate query documents relevant to their depression-related problems efficiently and effectively. By referring to relevant documents, individuals can understand how to alleviate their depression-related symptoms according to recommendations from health professionals. This work presents an extended probabilistic Hyperspace Analog to Language ( epHAL ) model to achieve this aim. The epHAL incorporates the close temporal associations between words in query documents to represent word cooccurrence relationships in a high-dimensional context space. The information flow mechanism further combines the query words in the epHAL space to infer related words for effective information retrieval. The language model perplexity is considered as the criterion for model optimization. Finally, the epHAL is adopted for psychiatric query document retrieval, and indicates its superiority in information retrieval over traditional approaches.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1985330912",
    "type": "article"
  },
  {
    "title": "Effects of Personalized and Aggregate Top-N Recommendation Lists on User Preference Ratings",
    "doi": "https://doi.org/10.1145/3430028",
    "publication_date": "2021-01-14",
    "publication_year": 2021,
    "authors": "Gediminas Adomavičius; Jesse Bockstedt; Shawn P. Curley; Jingjing Zhang",
    "corresponding_authors": "",
    "abstract": "Prior research has shown a robust effect of personalized product recommendations on user preference judgments for items. Specifically, the display of system-predicted preference ratings as item recommendations has been shown in multiple studies to bias users’ preference ratings after item consumption in the direction of the predicted rating. Top-N lists represent another common approach for presenting item recommendations in recommender systems. Through three controlled laboratory experiments, we show that top-N lists do not induce a discernible bias in user preference judgments. This result is robust, holding for both lists of personalized item recommendations and lists of items that are top-rated based on averages of aggregate user ratings. Adding numerical ratings to the list items does generate a bias, consistent with earlier studies. Thus, in contexts where preference biases are of concern to an online retailer or platform, top-N lists, without numerical predicted ratings, would be a promising format for displaying item recommendations.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3118374343",
    "type": "article"
  },
  {
    "title": "Microtask Detection",
    "doi": "https://doi.org/10.1145/3432290",
    "publication_date": "2021-01-08",
    "publication_year": 2021,
    "authors": "Ryen W. White; Elnaz Nouri; James Woffinden-Luey; Mark J. Encarnación; Sunil Kumar Jauhar",
    "corresponding_authors": "",
    "abstract": "Information systems, such as task management applications and digital assistants, can help people keep track of tasks of different types and different time durations, ranging from a few minutes to days or weeks. Helping people better manage their tasks and their time are core capabilities of assistive technologies, situated within a broader context of supporting more effective information access and use. Throughout the course of a day, there are typically many short time periods of downtime (e.g., five minutes or less) available to individuals. Microtasks are simple tasks that can be tackled in such short amounts of time. Identifying microtasks in task lists could help people utilize these periods of low activity to make progress on their task backlog. We define actionable tasks as self-contained tasks that need to be completed or acted on. However, not all to-do tasks are actionable. Many task lists are collections of miscellaneous items that can be completed at any time (e.g., books to read, movies to watch), notes (e.g., names, addresses), or the individual items are constituents in a list that is itself a task (e.g., a grocery list). In this article, we introduce the novel challenge of microtask detection, and we present machine-learned models for automatically determining which tasks are actionable and which of these actionable tasks are microtasks. Experiments show that our models can accurately identify actionable tasks, accurately detect actionable microtasks, and that we can combine these models to generate a solution that scales microtask detection to all tasks. We discuss our findings in detail, along with their limitations. These findings have implications for the design of systems to help people make the most of their time.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3128051602",
    "type": "article"
  },
  {
    "title": "Question Tagging via Graph-guided Ranking",
    "doi": "https://doi.org/10.1145/3468270",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Xiao Zhang; Meng Liu; Jianhua Yin; Zhaochun Ren; Liqiang Nie",
    "corresponding_authors": "",
    "abstract": "With the increasing prevalence of portable devices and the popularity of community Question Answering (cQA) sites, users can seamlessly post and answer many questions. To effectively organize the information for precise recommendation and easy searching, these platforms require users to select topics for their raised questions. However, due to the limited experience, certain users fail to select appropriate topics for their questions. Thereby, automatic question tagging becomes an urgent and vital problem for the cQA sites, yet it is non-trivial due to the following challenges. On the one hand, vast and meaningful topics are available yet not utilized in the cQA sites; how to model and tag them to relevant questions is a highly challenging problem. On the other hand, related topics in the cQA sites may be organized into a directed acyclic graph. In light of this, how to exploit relations among topics to enhance their representations is critical. To settle these challenges, we devise a graph-guided topic ranking model to tag questions in the cQA sites appropriately. In particular, we first design a topic information fusion module to learn the topic representation by jointly considering the name and description of the topic. Afterwards, regarding the special structure of topics, we propose an information propagation module to enhance the topic representation. As the comprehension of questions plays a vital role in question tagging, we design a multi-level context-modeling-based question encoder to obtain the enhanced question representation. Moreover, we introduce an interaction module to extract topic-aware question information and capture the interactive information between questions and topics. Finally, we utilize the interactive information to estimate the ranking scores for topics. Extensive experiments on three Chinese cQA datasets have demonstrated that our proposed model outperforms several state-of-the-art competitors.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3197781857",
    "type": "article"
  },
  {
    "title": "I Know What You Need: Investigating Document Retrieval Effectiveness with Partial Session Contexts",
    "doi": "https://doi.org/10.1145/3488667",
    "publication_date": "2021-11-17",
    "publication_year": 2021,
    "authors": "Procheta Sen; Debasis Ganguly; Gareth J. F. Jones",
    "corresponding_authors": "",
    "abstract": "Reducing user effort in finding relevant information is one of the key objectives of search systems. Existing approaches have been shown to effectively exploit the context from the current search session of users for automatically suggesting queries to reduce their search efforts. However, these approaches do not accomplish the end goal of a search system—that of retrieving a set of potentially relevant documents for the evolving information need during a search session. This article takes the problem of query prediction one step further by investigating the problem of contextual recommendation within a search session. More specifically, given the partial context information of a session in the form of a small number of queries, we investigate how a search system can effectively predict the documents that a user would have been presented with had he continued the search session by submitting subsequent queries. To address the problem, we propose a model of contextual recommendation that seeks to capture the underlying semantics of information need transitions of a current user’s search context. This model leverages information from a number of past interactions of other users with similar interactions from an existing search log. To identify similar interactions, as a novel contribution, we propose an embedding approach that jointly learns representations of both individual query terms and also those of queries (in their entirety) from a search log data by leveraging session-level containment relationships. Our experiments conducted on a large query log, namely the AOL, demonstrate that using a joint embedding of queries and their terms within our proposed framework of document retrieval outperforms a number of text-only and sequence modeling based baselines.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3216155842",
    "type": "article"
  },
  {
    "title": "Hyperspherical Variational Co-embedding for Attributed Networks",
    "doi": "https://doi.org/10.1145/3478284",
    "publication_date": "2021-12-08",
    "publication_year": 2021,
    "authors": "Jinyuan Fang; Shangsong Liang; Zaiqiao Meng; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Network-based information has been widely explored and exploited in the information retrieval literature. Attributed networks, consisting of nodes, edges as well as attributes describing properties of nodes, are a basic type of network-based data, and are especially useful for many applications. Examples include user profiling in social networks and item recommendation in user-item purchase networks. Learning useful and expressive representations of entities in attributed networks can provide more effective building blocks to down-stream network-based tasks such as link prediction and attribute inference. Practically, input features of attributed networks are normalized as unit directional vectors. However, most network embedding techniques ignore the spherical nature of inputs and focus on learning representations in a Gaussian or Euclidean space, which, we hypothesize, might lead to less effective representations. To obtain more effective representations of attributed networks, we investigate the problem of mapping an attributed network with unit normalized directional features into a non-Gaussian and non-Euclidean space. Specifically, we propose a hyperspherical variational co-embedding for attributed networks (HCAN), which is based on generalized variational auto-encoders for heterogeneous data with multiple types of entities. HCAN jointly learns latent embeddings for both nodes and attributes in a unified hyperspherical space such that the affinities between nodes and attributes can be captured effectively. We argue that this is a crucial feature in many real-world applications of attributed networks. Previous Gaussian network embedding algorithms break the assumption of uninformative prior, which leads to unstable results and poor performance. In contrast, HCAN embeds nodes and attributes as von Mises-Fisher distributions, and allows one to capture the uncertainty of the inferred representations. Experimental results on eight datasets show that HCAN yields better performance in a number of applications compared with nine state-of-the-art baselines.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4200261358",
    "type": "article"
  },
  {
    "title": "Extraction, characterization and utility of prototypical communication groups in the blogosphere",
    "doi": "https://doi.org/10.1145/1877766.1877772",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Munmun De Choudhury; Hari Sundaram; Ajita John; Dorée Duncan Seligmann",
    "corresponding_authors": "",
    "abstract": "This article analyzes communication within a set of individuals to extract the representative prototypical groups and provides a novel framework to establish the utility of such groups. Corporations may want to identify representative groups (which are indicative of the overall communication set) because it is easier to track the prototypical groups rather than the entire set. This can be useful for advertising, identifying “hot” spots of resource consumption as well as in mining representative moods or temperature of a community. Our framework has three parts: extraction, characterization, and utility of prototypical groups. First, we extract groups by developing features representing communication dynamics of the individuals. Second, to characterize the overall communication set, we identify a subset of groups within the community as the prototypical groups. Third, we justify the utility of these prototypical groups by using them as predictors of related external phenomena; specifically, stock market movement of technology companies and political polls of Presidential candidates in the 2008 U.S. elections. We have conducted extensive experiments on two popular blogs, Engadget and Huffington Post. We observe that the prototypical groups can predict stock market movement/political polls satisfactorily with mean error rate of 20.32%. Further, our method outperforms baseline methods based on alternative group extraction and prototypical group identification methods. We evaluate the quality of the extracted groups based on their conductance and coverage measures and develop metrics: predictivity and resilience to evaluate their ability to predict a related external time-series variable (stock market movement/political polls). This implies that communication dynamics of individuals are essential in extracting groups in a community, and the prototypical groups extracted by our method are meaningful in characterizing the overall communication sets.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2015139765",
    "type": "article"
  },
  {
    "title": "SWIM",
    "doi": "https://doi.org/10.1145/3072652",
    "publication_date": "2017-08-19",
    "publication_year": 2017,
    "authors": "Ali Vardasbi; Heshaam Faili; Masoud Asadpour",
    "corresponding_authors": "",
    "abstract": "A considerable amount of research has been devoted to the proposition of scalable algorithms for influence maximization. A number of such scalable algorithms exploit the community structure of the network. Besides the community structure, real-world social networks possess a different property, known as the layer structure. In this article, we propose a method based on the layer structure to maximize the influence in huge networks. Conducting experiments on a number of real-world networks, we will show that our method outperforms the state-of-the-art algorithms by its time complexity while having similar or slightly better final influence spread. Furthermore, unlike its predecessors, our method is able to show a high entanglement between structure and dynamics by giving insight on the reason why different networks have two contrasting behaviors in their saturation. By “saturation,” we mean a state during the seed selection process after which adjoining new nodes to the initial set will have a negligible effect on increasing the influence spread. We will demonstrate that how our method can predict the saturation dynamics in the networks. This prediction can be used to identify the network structures that are more vulnerable to the fast spread of the rumors.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2749644361",
    "type": "article"
  },
  {
    "title": "Browsing Hierarchy Construction by Minimum Evolution",
    "doi": "https://doi.org/10.1145/2714574",
    "publication_date": "2015-03-23",
    "publication_year": 2015,
    "authors": "Grace Hui Yang",
    "corresponding_authors": "Grace Hui Yang",
    "abstract": "Hierarchies serve as browsing tools to access information in document collections. This article explores techniques to derive browsing hierarchies that can be used as an information map for task-based search. It proposes a novel minimum-evolution hierarchy construction framework that directly learns semantic distances from training data and from users to construct hierarchies. The aim is to produce globally optimized hierarchical structures by incorporating user-generated task specifications into the general learning framework. Both an automatic version of the framework and an interactive version are presented. A comparison with state-of-the-art systems and a user study jointly demonstrate that the proposed framework is highly effective.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2005488407",
    "type": "article"
  },
  {
    "title": "Scaling High-Quality Pairwise Link-Based Similarity Retrieval on Billion-Edge Graphs",
    "doi": "https://doi.org/10.1145/3495209",
    "publication_date": "2022-01-11",
    "publication_year": 2022,
    "authors": "Weiren Yu; Julie A. McCann; Chengyuan Zhang; Hakan Ferhatosmanoğlu",
    "corresponding_authors": "",
    "abstract": "SimRank is an attractive link-based similarity measure used in fertile fields of Web search and sociometry. However, the existing deterministic method by Kusumoto et al. [ 24 ] for retrieving SimRank does not always produce high-quality similarity results, as it fails to accurately obtain diagonal correction matrix D . Moreover, SimRank has a “connectivity trait” problem: increasing the number of paths between a pair of nodes would decrease its similarity score. The best-known remedy, SimRank++ [ 1 ], cannot completely fix this problem, since its score would still be zero if there are no common in-neighbors between two nodes. In this article, we study fast high-quality link-based similarity search on billion-scale graphs. (1) We first devise a “varied- D ” method to accurately compute SimRank in linear memory. We also aggregate duplicate computations, which reduces the time of [ 24 ] from quadratic to linear in the number of iterations. (2) We propose a novel “cosine-based” SimRank model to circumvent the “connectivity trait” problem. (3) To substantially speed up the partial-pairs “cosine-based” SimRank search on large graphs, we devise an efficient dimensionality reduction algorithm, PSR # , with guaranteed accuracy. (4) We give mathematical insights to the semantic difference between SimRank and its variant, and correct an argument in [ 24 ] that “if D is replaced by a scaled identity matrix (1-Ɣ)I, their top-K rankings will not be affected much”. (5) We propose a novel method that can accurately convert from Li et al. SimRank ~{S} to Jeh and Widom’s SimRank S . (6) We propose GSR # , a generalisation of our “cosine-based” SimRank model, to quantify pairwise similarities across two distinct graphs, unlike SimRank that would assess nodes across two graphs as completely dissimilar. Extensive experiments on various datasets demonstrate the superiority of our proposed approaches in terms of high search quality, computational efficiency, accuracy, and scalability on billion-edge graphs.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4205911334",
    "type": "article"
  },
  {
    "title": "User Behavior Simulation for Search Result Re-ranking",
    "doi": "https://doi.org/10.1145/3511469",
    "publication_date": "2022-02-14",
    "publication_year": 2022,
    "authors": "Junqi Zhang; Yiqun Liu; Jiaxin Mao; Weizhi Ma; Jiazheng Xu; Shaoping Ma; Qi Tian",
    "corresponding_authors": "",
    "abstract": "Result ranking is one of the major concerns for Web search technologies. Most existing methodologies rank search results in descending order of relevance. To model the interactions among search results, reinforcement learning (RL algorithms have been widely adopted for ranking tasks. However, the online training of RL methods is time and resource consuming at scale. As an alternative, learning ranking policies in the simulation environment is much more feasible and efficient. In this article, we propose two different simulation environments for the offline training of the RL ranking agent: the Context-aware Click Simulator (CCS) and the Fine-grained User Behavior Simulator with GAN (UserGAN). Based on the simulation environment, we also design a User Behavior Simulation for Reinforcement Learning (UBS4RL) re-ranking framework, which consists of three modules: a feature extractor for heterogeneous search results, a user simulator for collecting simulated user feedback, and a ranking agent for generation of optimized result lists. Extensive experiments on both simulated and practical Web search datasets show that (1) the proposed user simulators can capture and simulate fine-grained user behavior patterns by training on large-scale search logs, (2) the temporal information of user searching process is a strong signal for ranking evaluation, and (3) learning ranking policies from the simulation environment can effectively improve the search ranking performance.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4212801880",
    "type": "article"
  },
  {
    "title": "A Data-Driven Analysis of Behaviors in Data Curation Processes",
    "doi": "https://doi.org/10.1145/3567419",
    "publication_date": "2022-10-07",
    "publication_year": 2022,
    "authors": "Lei Han; Tianwa Chen; Gianluca Demartini; Marta Indulska; Shazia Sadiq",
    "corresponding_authors": "",
    "abstract": "Understanding how data workers interact with data, and various pieces of information related to data preparation, is key to designing systems that can better support them in exploring datasets. To date, however, there is a paucity of research studying the strategies adopted by data workers as they carry out data preparation activities. In this work, we investigate a specific data preparation activity, namely data quality discovery , and aim to (i) understand the behaviors of data workers in discovering data quality issues, (ii) explore what factors (e.g., prior experience) can affect their behaviors, as well as (iii) understand how these behavioral observations relate to their performance. To this end, we collect a multi-modal dataset through a data-driven experiment that relies on the use of eye-tracking technology with a purpose-designed platform built on top of iPython Notebook. The experiment results reveal that: (i) ‘copy–paste–modify’ is a typical strategy for writing code to complete tasks; (ii) proficiency in writing code has a significant impact on the quality of task performance, while perceived difficulty and efficacy can influence task completion patterns; and (iii) searching in external resources is a prevalent action that can be leveraged to achieve better performance. Furthermore, our experiment indicates that providing sample code within the system can help data workers get started with their task, and surfacing underlying data is an effective way to support exploration. By investigating data worker behaviors prior to each search action, we also find that the most common reasons that trigger external search actions are the need to seek assistance in writing or debugging code and to search for relevant code to reuse. Based on our experiment results, we showcase a systematic approach to select from the top best code snippets created by data workers and assemble them to achieve better performance than the best individual performer in the dataset. By doing so, our findings not only provide insights into patterns of interactions with various system components and information resources when performing data curation tasks, but also build effective and efficient data curation processes through data workers’ collective intelligence.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4303427073",
    "type": "article"
  },
  {
    "title": "Evaluating the Robustness of Click Models to Policy Distributional Shift",
    "doi": "https://doi.org/10.1145/3569086",
    "publication_date": "2022-10-29",
    "publication_year": 2022,
    "authors": "Romain Deffayet; Jean-Michel Renders; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Many click models have been proposed to interpret logs of natural interactions with search engines and extract unbiased information for evaluation or learning. The experimental set-up used to evaluate them typically involves measuring two metrics, namely the test perplexity for click prediction and nDCG for relevance estimation. In both cases, the data used for training and testing is assumed to be collected using the same ranking policy. We question this assumption. Important downstream tasks based on click models involve evaluating a different policy than the training policy, i.e., click models need to operate under policy distributional shift . We show that click models are sensitive to it. This can severely hinder their performance on the targeted task: conventional evaluation metrics cannot guarantee that a click model will perform equally well under distributional shift. In order to more reliably predict click model performance under policy distributional shift, we propose a new evaluation protocol. It allows us to compare the relative robustness of six types of click models under various shifts, training configurations and downstream tasks. We obtain insights into the factors that worsen the sensitivity to policy distributional shift, and formulate guidelines to mitigate the risks of deploying policies based on click models.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4307811153",
    "type": "article"
  },
  {
    "title": "An Efficient and Robust Semantic Hashing Framework for Similar Text Search",
    "doi": "https://doi.org/10.1145/3570725",
    "publication_date": "2023-01-30",
    "publication_year": 2023,
    "authors": "Liyang He; Zhenya Huang; Enhong Chen; Qi Liu; Shiwei Tong; Hao Wang; Defu Lian; Shijin Wang",
    "corresponding_authors": "",
    "abstract": "Similar text search aims to find texts relevant to a given query from a database, which is fundamental in many information retrieval applications, such as question search and exercise search. Since millions of texts always exist behind practical search engine systems, a well-developed text search system usually consists of recall and ranking stages. Specifically, the recall stage serves as the basis in the system, where the main purpose is to find a small set of relevant candidates accurately and efficiently. Towards this goal, deep semantic hashing, which projects original texts into compact hash codes, can support good search performance. However, learning desired textual hash codes is extremely difficult due to the following problems. First, compact hash codes (with short length) can improve retrieval efficiency, but the demand for learning compact hash codes cannot guarantee accuracy due to severe information loss. Second, existing methods always learn the unevenly distributed codes in the space from a local perspective, leading to unsatisfactory code-balance results. Third, a large fraction of textual data contains various types of noise in real-world applications, which causes the deviation of semantics in hash codes. To this end, in this paper, we first propose a general unsupervised encoder-decoder semantic hashing framework, namely MASH (short for Memory-bAsed Semantic Hashing), to learn the balanced and compact hash codes for similar text search. Specifically, with a target of retaining semantic information as much as possible, the encoder introduces a novel relevance constraint among informative high-dimensional representations to guide the compact hash code learning. Then, we design an external memory where the hashing learning can be optimized in the global space to ensure the code balance of the learning results, which can promote search efficiency. Besides, to alleviate the performance degradation problem of the model caused by text noise, we propose an improved SMASH (short for denoiSing Memory-bAsed Semantic Hashing) model by incorporating a noise-aware encoder-decoder framework. This framework considers the noise degree for each text from the semantic deviation aspect, ensuring the robustness of hash codes. Finally, we conduct extensive experiments in three real-world datasets. The experimental results clearly demonstrate the effectiveness and efficiency of MASH and SMASH in generating balanced and compact hash codes, as well as the superior denoising ability of SMASH.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4318477599",
    "type": "article"
  },
  {
    "title": "Person-action Instance Search in Story Videos: An Experimental Study",
    "doi": "https://doi.org/10.1145/3617892",
    "publication_date": "2023-08-29",
    "publication_year": 2023,
    "authors": "Yanrui Niu; Chao Liang; Ankang Lu; Baojin Huang; Zhongyuan Wang; Jiahao Guo",
    "corresponding_authors": "",
    "abstract": "Person-Action instance search (P-A INS) aims to retrieve the instances of a specific person doing a specific action, which appears in the 2019–2021 INS tasks of the world-famous TREC Video Retrieval Evaluation (TRECVID). Most of the top-ranking solutions can be summarized with a Division-Fusion-Optimization (DFO) framework, in which person and action recognition scores are obtained separately, then fused, and, optionally, further optimized to generate the final ranking. However, TRECVID only evaluates the final ranking results, ignoring the effects of intermediate steps and their implementation methods. We argue that conducting the fine-grained evaluations of intermediate steps of DFO framework will (1) provide a quantitative analysis of the different methods’ performance in intermediate steps; (2) find out better design choices that contribute to improving retrieval performance; and (3) inspire new ideas for future research from the limitation analysis of current techniques. Particularly, we propose an indirect evaluation method motivated by the leave-one-out strategy, which finds an optimal solution surpassing the champion teams in 2020–2021 INS tasks. Moreover, to validate the generalizability and robustness of the proposed solution under various scenarios, we specifically construct a new large-scale P-A INS dataset and conduct comparative experiments with both the leading NIST TRECVID INS solution and the state-of-the-art P-A INS method. Finally, we discuss the limitations of our evaluation work and suggest future research directions.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386255022",
    "type": "article"
  },
  {
    "title": "Personalized Query Expansion with Contextual Word Embeddings",
    "doi": "https://doi.org/10.1145/3624988",
    "publication_date": "2023-09-20",
    "publication_year": 2023,
    "authors": "Elias Bassani; Nicola Tonellotto; Gabriella Pasi",
    "corresponding_authors": "",
    "abstract": "Personalized Query Expansion, the task of expanding queries with additional terms extracted from the user-related vocabulary, is a well-known solution to improve the retrieval performance of a system w.r.t. short queries. Recent approaches rely on word embeddings to select expansion terms from user-related texts. Although promising results have been delivered with former word embedding techniques, we argue that these methods are not suited for contextual word embeddings, which produce a unique vector representation for each term occurrence. In this article, we propose a Personalized Query Expansion method designed to solve the issues arising from the use of contextual word embeddings with the current Personalized Query Expansion approaches based on word embeddings. Specifically, we employ a clustering-based procedure to identify the terms that better represent the user interests and to improve the diversity of those selected for expansion, achieving improvements of up to 4% w.r.t. the best-performing baseline in terms of MAP@100. Moreover, our approach outperforms previous ones in terms of efficiency, allowing us to achieve sub-millisecond expansion times even in data-rich scenarios. Finally, we introduce a novel metric to evaluate the expansion terms’ diversity and empirically show the unsuitability of previous approaches based on word embeddings when employed along with contextual word embeddings, which cause the selection of semantically overlapping expansion terms.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4386890097",
    "type": "article"
  },
  {
    "title": "Relevance models to help estimate document and query parameters",
    "doi": "https://doi.org/10.1145/1010614.1010615",
    "publication_date": "2004-07-01",
    "publication_year": 2004,
    "authors": "David Bodoff",
    "corresponding_authors": "David Bodoff",
    "abstract": "A central idea of Language Models is that documents (and perhaps queries) are random variables, generated by data-generating functions that are characterized by document (query) parameters. The key new idea of this paper is to model that a relevance judgment is also generated stochastically, and that its data generating function is also governed by those same document and query parameters. The result of this addition is that any available relevance judgments are easily incorporated as additional evidence about the true document and query model parameters. An additional aspect of this approach is that it also resolves the long-standing problem of document-oriented versus query-oriented probabilities. The general approach can be used with a wide variety of hypothesized distributions for documents, queries, and relevance. We test the approach on Reuters Corpus Volume 1, using one set of possible distributions. Experimental results show that the approach does succeed in incorporating relevance data to improve estimates of both document and query parameters, but on this data and for the specific distributions we hypothesized, performance was no better than two separate one-sided models. We conclude that the model's theoretical contribution is its integration of relevance models, document models, and query models, and that the potential for additional performance improvement over one-sided methods requires refinements.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2040415854",
    "type": "article"
  },
  {
    "title": "Preparing heterogeneous XML for full-text search",
    "doi": "https://doi.org/10.1145/1185877.1185881",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Miro Lehtonen",
    "corresponding_authors": "Miro Lehtonen",
    "abstract": "XML retrieval is facing new challenges when applied to heterogeneous XML documents, where next to nothing about the document structure can be taken for granted. We have developed solutions where some of the heterogeneity issues are addressed. Our fragment selection algorithm selectively divides a heterogeneous document collection into equi-sized fragments with full-text content. If the content is considered too data-oriented, it is not accepted. The algorithm needs no information about element names. In addition, three techniques for fragment expansion are presented, all of which yield a 13--17% average improvement in average precision. These techniques and algorithms are among the first steps in developing document-type-independent indexing methods for the full text in heterogeneous XML collections.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2031340710",
    "type": "article"
  },
  {
    "title": "Adaptive hypermedia through contextualized open hypermedia structures",
    "doi": "https://doi.org/10.1145/1281485.1281487",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "Christopher Bailey; Wendy Hall; David E. Millard; Mark Weal",
    "corresponding_authors": "",
    "abstract": "The aim of this article is to produce an alternative view of the adaptive hypermedia (AH) domain from a contextually-aware open hypermedia (OH) perspective. We believe that a wide range of AH techniques can be supported with a small number of OH structures, which can be combined together to create more complex effects, possibly simplifying the development of new AH systems. In this work we reexamine Brusilovsky's taxonomy of AH techniques from a structural OH perspective. We also show that it is possible to identify and model common structures across the taxonomy of adaptive techniques. An agent-based adaptive hypermedia system called HA 3 L is presented, which uses these OH structures to provide a straightforward implementation of a variety of adaptive hypermedia techniques. This enables us to reflect on the structural equivalence of many of the techniques, demonstrates the advantages of the OH approach, and can inform the design of future adaptive hypermedia systems.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2028338749",
    "type": "article"
  },
  {
    "title": "Toward automatic facet analysis and need negotiation",
    "doi": "https://doi.org/10.1145/1416950.1416956",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "Jimmy Lin; Philip Fei Wu; Eileen G. Abels",
    "corresponding_authors": "",
    "abstract": "This work explores the hypothesis that interactions between a trained human search intermediary and an information seeker can inform the design of interactive IR systems. We discuss results from a controlled Wizard-of-Oz case study, set in the context of the TREC 2005 HARD track evaluation, in which a trained intermediary executed an integrated search and interaction strategy based on conceptual facet analysis and informed by need negotiation techniques common in reference interviews. Having a human “in the loop” yielded large improvements over fully automated systems as measured by standard ranked-retrieval metrics, demonstrating the value of mediated search. We present a detailed analysis of the intermediary's actions to gain a deeper understanding of what worked and why. One contribution is a taxonomy of clarification types informed both by empirical results and existing theories in library and information science. We discuss how these findings can guide the development of future systems. Overall, this work illustrates how studying human information-seeking processes can lead to better information retrieval applications.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2007839039",
    "type": "article"
  },
  {
    "title": "Faceted Search with Object Ranking and Answer Size Constraints",
    "doi": "https://doi.org/10.1145/3425603",
    "publication_date": "2020-11-16",
    "publication_year": 2020,
    "authors": "Kostas Manioudakis; Yannis Tzitzikas",
    "corresponding_authors": "",
    "abstract": "Faceted Search is a widely used interaction scheme in digital libraries, e-commerce, and recently also in Linked Data. Surprisingly, object ranking in the context of Faceted Search is not well studied in the literature. In this article, we propose an extension of the model with two parameters that enable specifying the desired answer size and the granularity of the sought object ranking. These parameters allow tackling the problem of too big or too small answers and can specify how refined the sought ranking should be. Then, we provide an algorithm that takes as input these parameters and by considering the hard-constraints (filters), the soft-constraints (preferences), as well as the statistical properties of the dataset (through various frequency-based ranking schemes), produces an object ranking that satisfies these parameters, in a transparent way for the user. Then, we present extensive simulation-based evaluation results that provide evidence that the proposed model also improves the answers and reduces the user’s cost. Finally, we propose GUI extensions that are required and present an implementation of the model.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3107241923",
    "type": "article"
  },
  {
    "title": "VM-NSP",
    "doi": "https://doi.org/10.1145/3440874",
    "publication_date": "2021-02-17",
    "publication_year": 2021,
    "authors": "Wei Wang; Longbing Cao",
    "corresponding_authors": "",
    "abstract": "Negative sequential patterns (NSPs) capture more informative and actionable knowledge than classic positive sequential patterns (PSPs) due to the involvement of both occurring and nonoccurring behaviors and events, which can contribute to many relevant applications. However, NSP mining is nontrivial, as it involves fundamental challenges requiring distinct theoretical foundations and is not directly addressable by PSP mining. In the very limited research reported on NSP mining, a negative element constraint (NEC) is incorporated to only consider the NSPs composed of specific forms of elements (containing either positive or negative items), which results in many valuable NSPs being missed. Here, we loosen the NEC (called loose negative element constraint (LNEC)) to include partial negative elements containing both positive and negative items, which enables the discovery of more flexible patterns but incorporates significant new learning challenges, such as representing and mining complete NSPs. Accordingly, we formalize the LNEC-based NSP mining problem and propose a novel vertical NSP mining framework , VM-NSP, to efficiently mine the complete set of NSPs by a vertical representation (VR) of each sequence. An efficient bitmap-based vertical NSP mining algorithm , bM-NSP, introduces a bitmap hash table--based VR and a prefix-based negative sequential candidate generation strategy to optimize the discovery performance. VM-NSP and its implementation bM-NSP form the first VR-based approach for complete NSP mining with LNEC. Theoretical analyses and experiments confirm the performance superiority of bM-NSP on synthetic and real-life datasets w.r.t. diverse data factors, which substantially expands existing NSP mining methods toward flexible NSP discovery.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3132245688",
    "type": "article"
  },
  {
    "title": "Clarifying Ambiguous Keywords with Personal Word Embeddings for Personalized Search",
    "doi": "https://doi.org/10.1145/3470564",
    "publication_date": "2021-11-22",
    "publication_year": 2021,
    "authors": "Jing Yao; Zhicheng Dou; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Personalized search tailors document ranking lists for each individual user based on her interests and query intent to better satisfy the user’s information need. Many personalized search models have been proposed. They first build a user interest profile from the user’s search history, and then re-rank the documents based on the personalized matching scores between the created profile and candidate documents. In this article, we attempt to solve the personalized search problem from an alternative perspective of clarifying the user’s intention of the current query. We know that there are many ambiguous words in natural language such as “Apple.” People with different knowledge backgrounds and interests have personalized understandings of these words. Therefore, we propose a personalized search model with personal word embeddings for each individual user that mainly contain the word meanings that the user already knows and can reflect the user interests. To learn great personal word embeddings, we design a pre-training model that captures both the textual information of the query log and the information about user interests contained in the click-through data represented as a graph structure. With personal word embeddings, we obtain the personalized word and context-aware representations of the query and documents. Furthermore, we also employ the current session as the short-term search context to dynamically disambiguate the current query. Finally, we use a matching model to calculate the matching score between the personalized query and document representations for ranking. Experimental results on two large-scale query logs show that our designed model significantly outperforms state-of-the-art personalization models.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3217229393",
    "type": "article"
  },
  {
    "title": "Studying the clustering paradox and scalability of search in highly distributed environments",
    "doi": "https://doi.org/10.1145/2457465.2457468",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "Weimao Ke; Javed Mostafa",
    "corresponding_authors": "",
    "abstract": "With the ubiquitous production, distribution and consumption of information, today's digital environments such as the Web are increasingly large and decentralized. It is hardly possible to obtain central control over information collections and systems in these environments. Searching for information in these information spaces has brought about problems beyond traditional boundaries of information retrieval (IR) research. This article addresses one important aspect of scalability challenges facing information retrieval models and investigates a decentralized, organic view of information systems pertaining to search in large-scale networks. Drawing on observations from earlier studies, we conduct a series of experiments on decentralized searches in large-scale networked information spaces. Results show that how distributed systems interconnect is crucial to retrieval performance and scalability of searching. Particularly, in various experimental settings and retrieval tasks, we find a consistent phenomenon, namely, the Clustering Paradox , in which the level of network clustering (semantic overlay) imposes a scalability limit. Scalable searches are well supported by a specific, balanced level of network clustering emerging from local system interconnectivity. Departure from that level, either stronger or weaker clustering, leads to search performance degradation, which is dramatic in large-scale networks.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2014050873",
    "type": "article"
  },
  {
    "title": "Efficient Video Stream Monitoring for Near-Duplicate Detection and Localization in a Large-Scale Repository",
    "doi": "https://doi.org/10.1145/2516890",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Chih‐Yi Chiu; Tsung‐Han Tsai; Guei-Wun Han; Cheng-Yu Hsieh; Shengyang Li",
    "corresponding_authors": "",
    "abstract": "In this article, we study the efficiency problem of video stream near-duplicate monitoring in a large-scale repository. Existing stream monitoring methods are mainly designed for a short video to scan over a query stream; they have difficulty being scalable for a large number of long videos. We present a simple but effective algorithm called incremental similarity update to address the problem. That is, a similarity upper bound between two videos can be calculated incrementally by leveraging the prior knowledge of the previous calculation. The similarity upper bound takes a lightweight computation to filter out unnecessary time-consuming computation for the actual similarity between two videos, making the search process more efficient. We integrate the algorithm with inverted indexing to obtain a candidate list from the repository for the given query stream. Meanwhile, the algorithm is applied to scan each candidate for locating exact near-duplicate subsequences. We implement several state-of-the-art methods for comparison in terms of accuracy, execution time, and memory consumption. Experimental results demonstrate the proposed algorithm yields comparable accuracy, compact memory size, and more efficient execution time.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2170785073",
    "type": "article"
  },
  {
    "title": "Search by Screenshots for Universal Article Clipping in Mobile Apps",
    "doi": "https://doi.org/10.1145/3091107",
    "publication_date": "2017-06-23",
    "publication_year": 2017,
    "authors": "Kazutoshi Umemoto; Ruihua Song; Jian‐Yun Nie; Xing Xie; Katsumi Tanaka; Rui Yong",
    "corresponding_authors": "",
    "abstract": "To address the difficulty in clipping articles from various mobile applications (apps), we propose a novel framework called UniClip, which allows a user to snap a screen of an article to save the whole article in one place. The key task of the framework is search by screenshots , which has three challenges: (1) how to represent a screenshot; (2) how to formulate queries for effective article retrieval; and (3) how to identify the article from search results. We solve these by (1) segmenting a screenshot into structural units called blocks, (2) formulating effective search queries by considering the role of each block, and (3) aggregating the search result lists of multiple queries. To improve efficiency, we also extend our approach with learning-to-rank techniques so that we can find the desired article with only one query. Experimental results show that our approach achieves high retrieval performance ( F 1 = 0.868), which outperforms baselines based on keyword extraction and chunking methods. Learning-to-rank models improve our approach without learning by about 6%. A user study conducted to investigate the usability of UniClip reveals that ours is preferred by 21 out of 22 participants for its simplicity and effectiveness.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2674238586",
    "type": "article"
  },
  {
    "title": "Using local optimality criteria for efficient information retrieval with redundant information filters",
    "doi": "https://doi.org/10.1145/226163.226165",
    "publication_date": "1996-04-01",
    "publication_year": 1996,
    "authors": "Neil C. Rowe",
    "corresponding_authors": "Neil C. Rowe",
    "abstract": "We consider information retrieval when the data—for instance, multimedia—is computationally expensive to fetch. Our approach uses “information filters” to considerably narrow the universe of possibilities before retrieval. We are especially interested in redundant information filters that save time over more general but more costly filters. Efficient retrieval requires that decisions must be made about the necessity, order, and concurrent processing of proposed filters (an “execution plan”). We develop simple polynomial-time local criteria for optimal execution plans and show that most forms of concurrency are suboptimal with information filters. Although the general problem of finding an optimal execution plan is likely to be exponential in the number of filters, we show experimentally that our local optimality criteria, used in a polynomial-time algorithm, nearly always find the global optimum with 15 filters or less, a sufficient number of filters for most applications. Our methods require no special hardware and avoid the high processor idleness that is characteristic of massive-parallelism solutions to this problem. We apply our ideas to an important application, information retrieval of captioned data using natural-language understanding, a problem for which the natural-language processing can be the bottleneck if not implemented well.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1982769266",
    "type": "article"
  },
  {
    "title": "Computerized performance monitors as multidimensional systems",
    "doi": "https://doi.org/10.1145/226163.226167",
    "publication_date": "1996-04-01",
    "publication_year": 1996,
    "authors": "Rebecca Grant; Chris A. Higgins",
    "corresponding_authors": "",
    "abstract": "An increasing number of companies are introducing computer technology into more aspects of work. Effective use of information systems to support office and service work can improve staff productivity, broaden a company's market, or dramatically change its business. It can also increase the extent to which work is computer mediated and thus within the reach of software known as Computerized Performance Monitoring and Control Systems (CPMCSs). Virtually all research has studied CPMCSs as unidimensional systems. Employees are described as “monitored” or “unmonitored” or as subject to “high,” “moderate,” or “low” levels of monitoring. Research that does not clearly distinguish among possible monitor design cannot explain how designs may differ in effect. Nor can it suggest how to design better monitors. A multidimensional view of CPMCSs describes monitor designs in terms of object of measurements, tasks measured, recipient of data, reporting period, and message content. This view is derived from literature in control systems, organizational behavior, and management information systems. The multidimensional view can then be incorporated into causal models to explain contradictory results of earlier CPMCS research.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2072239094",
    "type": "article"
  },
  {
    "title": "Harp",
    "doi": "https://doi.org/10.1145/314516.314521",
    "publication_date": "1999-07-01",
    "publication_year": 1999,
    "authors": "Ee‐Peng Lim; Ying Lü",
    "corresponding_authors": "",
    "abstract": "The main purpose of a digital library is to facilitate users easy access to enormous amount of globally networked information. Typically, this information includes preexisting public library catalog data, digitized document collections, and other databases. In this article, we describe the distributed query system of a digital library prototype system known as HARP. In the HARP project, we have designed and implemented a distributed query processor and its query front-end to support integrated queries to preexisting public library catalogs and structured databases. This article describes our experiences in the design of an extended Sequel (SQL) query language known as HarpSQL. It also presents the design and implementation of the distributed query system. Our experience in distributed query processor and user interface design and development will be highlighted. We believe that our prototyping effort will provide useful lessons to the development of a complete digital library infrastructure.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2092950680",
    "type": "article"
  },
  {
    "title": "Authentication in office system internetworks",
    "doi": "https://doi.org/10.1145/357436.357437",
    "publication_date": "1983-07-01",
    "publication_year": 1983,
    "authors": "Jonathan Israël; Theodore A. Linden",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Authentication in office system internetworks Authors: Jay E. Israel Xerox Corporation, 3333 Coyote Hill Road, Palo Alto, CA Xerox Corporation, 3333 Coyote Hill Road, Palo Alto, CAView Profile , Theodore A. Linden Xerox Corporation, 3333 Coyote Hill Road, Palo Alto, CA Xerox Corporation, 3333 Coyote Hill Road, Palo Alto, CAView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 3pp 193–210https://doi.org/10.1145/357436.357437Published:01 July 1983Publication History 8citation627DownloadsMetricsTotal Citations8Total Downloads627Last 12 Months23Last 6 weeks4 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2014944752",
    "type": "article"
  },
  {
    "title": "Behavioral experiments on handmarkings",
    "doi": "https://doi.org/10.1145/42196.42199",
    "publication_date": "1987-10-01",
    "publication_year": 1987,
    "authors": "John D. Gould; Josiane Salaun",
    "corresponding_authors": "",
    "abstract": "Handmarkings or handwritten editing marks can be used as direct editing commands to an interactive computer system. Five exploratory experiments studied the potential value of handmarkings for editing text and pictures, as well as for some specific results. Circles are the most frequently used scoping mark, and arrows are the most frequently used operator and target indicators. Experimental comparisons showed that handmarkings have the potential to be faster than keyboards and mice for editing tasks. Their ultimate value will, however, depend on the style and details of their user-interface implementation.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2020572658",
    "type": "article"
  },
  {
    "title": "Message system mores",
    "doi": "https://doi.org/10.1145/357431.357435",
    "publication_date": "1983-04-01",
    "publication_year": 1983,
    "authors": "Douglas K. Brotz",
    "corresponding_authors": "Douglas K. Brotz",
    "abstract": "article Free Access Share on Message system mores: etiquette in Laurel Author: Douglas K. Brotz Computer Science Laboratory, Xerox Palo Alto Research Center, 3333 Coyote Hill Road, Palo Alto, CA Computer Science Laboratory, Xerox Palo Alto Research Center, 3333 Coyote Hill Road, Palo Alto, CAView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 2April 1983 pp 179–192https://doi.org/10.1145/357431.357435Online:01 April 1983Publication History 9citation376DownloadsMetricsTotal Citations9Total Downloads376Last 12 Months11Last 6 weeks3 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2068395575",
    "type": "article"
  },
  {
    "title": "ServiceFinder",
    "doi": "https://doi.org/10.1145/1281485.1281488",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "Xiao Fang; Olivia R. Liu Sheng; Michael Chau",
    "corresponding_authors": "",
    "abstract": "The rapid advancement of Internet technologies enables more and more educational institutes, companies, and government agencies to provide services, namely online services, through web portals. With hundreds of online services provided through a web portal, it is critical to design web portals, namely service portals, through which online services can be easily accessed by their consumers. This article addresses this critical issue from the perspective of service selection, that is, how to select a small number of service-links (i.e., hyperlinks pointing to online services) to be featured in the homepage of a service portal such that users can be directed to find the online services they seek most effectively. We propose a mathematically formulated metric to measure the effectiveness of the selected service-links in directing users to locate their desired online services and formally define the service selection problem. A solution method, ServiceFinder, is then proposed. Using real-world data obtained from the Utah State Government service portal, we show that ServiceFinder outperforms both the current practice of service selection and previous algorithms for adaptive website design. We also show that the performance of ServiceFinder is close to that of the optimal solution resulting from exhaustive search.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2084668590",
    "type": "article"
  },
  {
    "title": "A distributed, service-based framework for knowledge applications with multimedia",
    "doi": "https://doi.org/10.1145/1629096.1629100",
    "publication_date": "2009-11-01",
    "publication_year": 2009,
    "authors": "David Dupplaw; Srinandan Dasmahapatra; Bo Hu; Paul Lewis; Nigel Shadbolt",
    "corresponding_authors": "",
    "abstract": "The current trend in distributed systems is towards service-based integration. This article describes an ontology-driven framework implemented to provide knowledge management for data of different modalities, with multimedia processing, annotation, and reasoning provided by remote services. The framework was developed in, and is presented in the context of, the Medical Imaging and Advanced Knowledge Technologies (MIAKT) project that sought to support the Multidisciplinary Meetings (MDMs) that take place during breast cancer screening for diagnosing the patient. However, the architecture is entirely independent of the specific application domain and can be quickly prototyped into new domains. An Enterprise server provides resource access to a client-side presentation application which, in turn, provides knowledge visualization and markup of any supported media, as defined by a domain-dependent ontology-supported language.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2044506604",
    "type": "article"
  },
  {
    "title": "Building a framework for the probability ranking principle by a family of expected weighted rank",
    "doi": "https://doi.org/10.1145/1629096.1629098",
    "publication_date": "2009-11-01",
    "publication_year": 2009,
    "authors": "Edward Kai Fung Dang; Jack Wu; Robert W. P. Luk; Kam‐Fai Wong",
    "corresponding_authors": "",
    "abstract": "A new principles framework is presented for retrieval evaluation of ranked outputs. It applies decision theory to model relevance decision preferences and shows that the Probability Ranking Principle (PRP) specifies optimal ranking. It has two new components, namely a probabilistic evaluation model and a general measure of retrieval effectiveness. Its probabilities may be interpreted as subjective or objective ones. Its performance measure is the expected weighted rank which is the weighted average rank of a retrieval list. Starting from this measure, the expected forward rank and some existing retrieval effectiveness measures (e.g., top n precision and discounted cumulative gain) are instantiated using suitable weighting schemes after making certain assumptions. The significance of these instantiations is that the ranking prescribed by PRP is shown to be optimal simultaneously for all these existing performance measures. In addition, the optimal expected weighted rank may be used to normalize the expected weighted rank of retrieval systems for (summary) performance comparison (across different topics) between systems. The framework also extends PRP and our evaluation model to handle graded relevance, thereby generalizing the discussed, existing measures (e.g., top n precision) and probabilistic retrieval models for graded relevance.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2074530025",
    "type": "article"
  },
  {
    "title": "Adaptive Local Low-rank Matrix Approximation for Recommendation",
    "doi": "https://doi.org/10.1145/3360488",
    "publication_date": "2019-10-16",
    "publication_year": 2019,
    "authors": "Huafeng Liu; Liping Jing; Yuhua Qian; Jian Yu",
    "corresponding_authors": "",
    "abstract": "Low-rank matrix approximation (LRMA) has attracted more and more attention in the community of recommendation. Even though LRMA-based recommendation methods (including Global LRMA and Local LRMA) obtain promising results, they suffer from the complicated structure of the large-scale and sparse rating matrix, especially when the underlying system includes a large set of items with various types and a huge amount of users with diverse interests. Thus, they have to predefine the important parameters, such as the rank of the rating matrix and the number of submatrices. Moreover, most existing Local LRMA methods are usually designed in a two-phase separated framework and do not consider the missing mechanisms of rating matrix. In this article, a non-parametric unified Bayesian graphical model is proposed for A daptive Lo cal low-rank M atrix A pproximation ( ALoMA ). ALoMA has ability to simultaneously identify rating submatrices, determine the optimal rank for each submatrix, and learn the submatrix-specific user/item latent factors. Meanwhile, the missing mechanism is adopted to characterize the whole rating matrix. These four parts are seamlessly integrated and enhance each other in a unified framework. Specifically, the user-item rating matrix is adaptively divided into proper number of submatrices in ALoMA by exploiting the Chinese Restaurant Process. For each submatrix, by considering both global/local structure information and missing mechanisms, the latent user/item factors are identified in an optimal latent space by adopting automatic relevance determination technique. We theoretically analyze the model’s generalization error bounds and give an approximation guarantee. Furthermore, an efficient Gibbs sampling-based algorithm is designed to infer the proposed model. A series of experiments have been conducted on six real-world datasets ( Epinions , Douban , Dianping , Yelp , Movielens (10M), and Netflix ). The results demonstrate that ALoMA outperforms the state-of-the-art LRMA-based methods and can easily provide interpretable recommendation results.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2981260853",
    "type": "article"
  },
  {
    "title": "Fast construction of the HYB index",
    "doi": "https://doi.org/10.1145/1993036.1993040",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Hannah Bast; Marjan Celikik",
    "corresponding_authors": "",
    "abstract": "As shown in a series of recent works, the HYB index is an alternative to the inverted index (INV) that enables very fast prefix searches, which in turn is the basis for fast processing of many other types of advanced queries, including autocompletion, faceted search, error-tolerant search, database-style select and join, and semantic search. In this work we show that HYB can be constructed at least as fast as INV, and often up to twice as fast. This is because HYB, by its nature, requires only a half-inversion of the data and allows an efficient in-place instead of the traditional merge-based index construction. We also pay particular attention to the cache efficiency of the in-memory posting accumulation, an issue that has not been addressed in previous work, and show that our simple multilevel posting accumulation scheme yields much fewer cache misses compared to related approaches. Finally, we show that HYB supports fast dynamic index updates more easily than INV.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2026818349",
    "type": "article"
  },
  {
    "title": "TASC",
    "doi": "https://doi.org/10.1145/2699662",
    "publication_date": "2015-02-17",
    "publication_year": 2015,
    "authors": "Yonghong Tian; Mengren Qian; Tiejun Huang",
    "corresponding_authors": "",
    "abstract": "How to precisely and efficiently detect near-duplicate copies with complicated audiovisual transformations from a large-scale video database is a challenging task. To cope with this challenge, this article proposes a transformation-aware soft cascading (TASC) approach for multimodal video copy detection. Basically, our approach divides query videos into some categories and then for each category designs a transformation-aware chain to organize several detectors in a cascade structure. In each chain, efficient but simple detectors are placed in the forepart, whereas effective but complex detectors are located in the rear. To judge whether two videos are near-duplicates, a Detection-on-Copy-Units mechanism is introduced in the TASC, which makes the decision of copy detection depending on the similarity between their most similar fractions, called copy units (CUs), rather than the video-level similarity. Following this, we propose a CU search algorithm to find a pair of CUs from two videos and a CU-based localization algorithm to find the precise locations of their copy segments that are with the asserted CUs as the center. Moreover, to address the problem that the copies and noncopies are possibly linearly inseparable in the feature space, the TASC also introduces a flexible strategy, called soft decision boundary , to replace the single threshold strategy for each detector. Its basic idea is to automatically learn two thresholds for each detector to examine the easy-to-judge copies and noncopies, respectively, and meanwhile to train a nonlinear classifier to further check those hard-to-judge ones. Extensive experiments on three benchmark datasets showed that the TASC can achieve excellent copy detection accuracy and localization precision with a very high processing efficiency.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2042759615",
    "type": "article"
  },
  {
    "title": "Generalized Funnelling: Ensemble Learning and Heterogeneous Document Embeddings for Cross-Lingual Text Classification",
    "doi": "https://doi.org/10.1145/3544104",
    "publication_date": "2022-06-13",
    "publication_year": 2022,
    "authors": "Alejandro Moreo; Andrea Pedrotti; Fabrizio Sebastiani",
    "corresponding_authors": "",
    "abstract": "Funnelling ( Fun ) is a recently proposed method for cross-lingual text classification (CLTC) based on a two-tier learning ensemble for heterogeneous transfer learning (HTL). In this ensemble method, 1st-tier classifiers, each working on a different and language-dependent feature space, return a vector of calibrated posterior probabilities (with one dimension for each class) for each document, and the final classification decision is taken by a meta-classifier that uses this vector as its input. The meta-classifier can thus exploit class-class correlations, and this (among other things) gives Fun an edge over CLTC systems in which these correlations cannot be brought to bear. In this article, we describe Generalized Funnelling ( gFun ), a generalization of Fun consisting of an HTL architecture in which 1st-tier components can be arbitrary view-generating functions , i.e., language-dependent functions that each produce a language-independent representation (“view”) of the (monolingual) document. We describe an instance of gFun in which the meta-classifier receives as input a vector of calibrated posterior probabilities (as in Fun ) aggregated to other embedded representations that embody other types of correlations, such as word-class correlations (as encoded by Word-Class Embeddings ), word-word correlations (as encoded by Multilingual Unsupervised or Supervised Embeddings ), and word-context correlations (as encoded by multilingual BERT ). We show that this instance of gFun substantially improves over Fun and over state-of-the-art baselines by reporting experimental results obtained on two large, standard datasets for multilingual multilabel text classification. Our code that implements gFun is publicly available.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3207996109",
    "type": "article"
  },
  {
    "title": "Relevance Assessments for Web Search Evaluation: Should We Randomise or Prioritise the Pooled Documents?",
    "doi": "https://doi.org/10.1145/3494833",
    "publication_date": "2022-01-11",
    "publication_year": 2022,
    "authors": "Tetsuya Sakai; Sijie Tao; Zhaohao Zeng",
    "corresponding_authors": "",
    "abstract": "In the context of depth- k pooling for constructing web search test collections, we compare two approaches to ordering pooled documents for relevance assessors: The prioritisation strategy (PRI) used widely at NTCIR, and the simple randomisation strategy (RND). In order to address research questions regarding PRI and RND, we have constructed and released the WWW3E8 dataset, which contains eight independent relevance labels for 32,375 topic-document pairs, i.e., a total of 259,000 labels. Four of the eight relevance labels were obtained from PRI-based pools; the other four were obtained from RND-based pools. Using WWW3E8, we compare PRI and RND in terms of inter-assessor agreement, system ranking agreement, and robustness to new systems that did not contribute to the pools. We also utilise an assessor activity log we obtained as a byproduct of WWW3E8 to compare the two strategies in terms of assessment efficiency. Our main findings are: (a) The presentation order has no substantial impact on assessment efficiency; (b) While the presentation order substantially affects which documents are judged (highly) relevant, the difference between the inter-assessor agreement under the PRI condition and that under the RND condition is of no practical significance; (c) Different system rankings under the PRI condition are substantially more similar to one another than those under the RND condition; and (d) PRI-based relevance assessment files (qrels) are substantially and statistically significantly more robust to new systems than RND-based ones. Finding (d) suggests that PRI helps the assessors identify relevant documents that affect the evaluation of many existing systems, including those that did not contribute to the pools. Hence, if researchers need to evaluate their current IR systems using legacy IR test collections, we recommend the use of those constructed using the PRI approach unless they have a good reason to believe that their systems retrieve relevant documents that are vastly different from the pooled documents. While this robustness of PRI may also mean that the PRI-based pools are biased against future systems that retrieve highly novel relevant documents, one should note that there is no evidence that RND is any better in this respect.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4205544037",
    "type": "article"
  },
  {
    "title": "The Influences of a Knowledge Representation Tool on Searchers with Varying Cognitive Abilities",
    "doi": "https://doi.org/10.1145/3527661",
    "publication_date": "2022-04-14",
    "publication_year": 2022,
    "authors": "Bogeum Choi; Jaime Arguello; R. Capra; Austin R. Ward",
    "corresponding_authors": "",
    "abstract": "While current systems are effective in helping searchers resolve simple information needs (e.g., fact-finding), they provide less support for searchers working on complex information-seeking tasks. Complex search tasks involve a wide range of (meta)cognitive activities, including goal-setting, organizing information, drawing inferences, monitoring progress, and revising mental models and search strategies. We report on a lab study ( N = 32) that investigated the influences of a knowledge representation tool called the OrgBox, developed to support searchers with complex tasks. The OrgBox tool was integrated into a custom-built search system and allowed study participants to drag-and-drop textual passages into the tool, organize passages into logical groupings called “boxes”, and make notes on passages and boxes. The OrgBox was compared to a baseline tool (called the Bookmark) that allowed participants to save textual passages, but not organize them nor make notes. Knowledge representation tools such as the OrgBox may provide special benefits for users with different cognitive profiles. In this article, we explore two cognitive abilities: (1) working memory (WM) capacity and (2) switching (SW) ability. Participants in the study were asked to gather information on a complex subject and produce an outline for a hypothetical research article. We investigate the influences of the tool (OrgBox vs. Bookmark) and the participant’s working memory capacity and switching ability on three types of outcomes: (RQ1) search behaviors, (RQ2) post-task perceptions, and (RQ3) the quality of outlines produces by participants.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4224087634",
    "type": "article"
  },
  {
    "title": "Capture Salient Historical Information: A Fast and Accurate Non-autoregressive Model for Multi-turn Spoken Language Understanding",
    "doi": "https://doi.org/10.1145/3545800",
    "publication_date": "2022-07-05",
    "publication_year": 2022,
    "authors": "Lizhi Cheng; Weijia Jia; Wenmian Yang",
    "corresponding_authors": "",
    "abstract": "Spoken Language Understanding (SLU), a core component of the task-oriented dialogue system, expects a shorter inference facing the impatience of human users. Existing work increases inference speed by designing non-autoregressive models for single-turn SLU tasks but fails to apply to multi-turn SLU in confronting the dialogue history. The intuitive idea is to concatenate all historical utterances and utilize the non-autoregressive models directly. However, this approach seriously misses the salient historical information and suffers from the uncoordinated-slot problems. To overcome those shortcomings, we propose a novel model for multi-turn SLU named Salient History Attention with Layer-Refined Transformer (SHA-LRT), which comprises a SHA module, a Layer-Refined Mechanism (LRM), and a Slot Label Generation (SLG) task. SHA captures salient historical information for the current dialogue from both historical utterances and results via a well-designed history-attention mechanism. LRM predicts preliminary SLU results from Transformer’s middle states and utilizes them to guide the final prediction, and SLG obtains the sequential dependency information for the non-autoregressive encoder. Experiments on public datasets indicate that our model significantly improves multi-turn SLU performance (17.5% on Overall) with accelerating (nearly 15 times) the inference process over the state-of-the-art baseline as well as effective on the single-turn SLU tasks.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4283644197",
    "type": "article"
  },
  {
    "title": "MLI: A Multi-level Inference Mechanism for User Attributes in Social Networks",
    "doi": "https://doi.org/10.1145/3545797",
    "publication_date": "2022-06-30",
    "publication_year": 2022,
    "authors": "Hang Zhang; Yajun Yang; Xin Wang; Hong Gao; Qinghua Hu",
    "corresponding_authors": "",
    "abstract": "In the social network, each user has attributes for self-description called user attributes, which are semantically hierarchical. Attribute inference has become an essential way for social platforms to realize user classifications and targeted recommendations. Most existing approaches mainly focus on the flat inference problem neglecting the semantic hierarchy of user attributes, which will cause serious inconsistency in multi-level tasks. In this article, we propose a multi-level model MLI, where information propagation part collects attribute information by mining the global graph structure, and the attribute correction part realizes the mutual correction between different levels of attributes. Further, we put forward the concept of generalized semantic tree, a way of representing the hierarchical structure of user attributes, whose nodes are allowed to have multiple parent nodes unlike the regular tree. Both regular and generalized semantic trees are commonly used in practice, and can be handled by our model. Besides, by making the inference start from sub-networks with sufficient attribute information, we design a “Ripple” algorithm to improve the efficiency and effectiveness of our model. For evaluation purposes, we conduct extensive verification experiments on DBLP datasets. The experimental results show the superior effect of MLI, compared with the state-of-the-art methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4283741562",
    "type": "article"
  },
  {
    "title": "Contextual Path Retrieval: A Contextual Entity Relation Embedding-based Approach",
    "doi": "https://doi.org/10.1145/3502720",
    "publication_date": "2022-10-03",
    "publication_year": 2022,
    "authors": "Pei-Chi Lo; Ee‐Peng Lim",
    "corresponding_authors": "",
    "abstract": "Contextual path retrieval (CPR) refers to the task of finding contextual path(s) between a pair of entities in a knowledge graph that explains the connection between them in a given context. For this novel retrieval task, we propose the Embedding-based Contextual Path Retrieval (ECPR) framework. ECPR is based on a three-component structure that includes a context encoder and path encoder that encode query context and path, respectively, and a path ranker that assigns a ranking score to each candidate path to determine the one that should be the contextual path. For context encoding, we propose two novel context encoding methods, i.e., context-fused entity embeddings and contextualized embeddings. For path encoding, we propose PathVAE, an inductive embedding approach to generate path representations. Finally, we explore two path-ranking approaches. In our evaluation, we construct a synthetic dataset from Wikipedia and two real datasets of Wikinews articles constructed through crowdsourcing. Our experiments show that methods based on ECPR framework outperform baseline methods, and that our two proposed context encoders yield significantly better performance than baselines. We also analyze a few case studies to show the distinct features of ECPR-based methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4300865673",
    "type": "article"
  },
  {
    "title": "On the Vulnerability of Graph Learning-based Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3572834",
    "publication_date": "2022-11-24",
    "publication_year": 2022,
    "authors": "Senrong Xu; Liangyue Li; Zenan Li; Yuan Yao; Feng Xu; Zulong Chen; Quan Lu; Hanghang Tong",
    "corresponding_authors": "",
    "abstract": "Graph learning-based collaborative filtering (GLCF), which is built upon the message-passing mechanism of graph neural networks (GNNs), has received great recent attention and exhibited superior performance in recommender systems. However, although GNNs can be easily compromised by adversarial attacks as shown by the prior work, little attention has been paid to the vulnerability of GLCF. Questions like can GLCF models be just as easily fooled as GNNs remain largely unexplored. In this article, we propose to study the vulnerability of GLCF. Specifically, we first propose an adversarial attack against CLCF. Considering the unique challenges of attacking GLCF, we propose to adopt the greedy strategy in searching for the local optimal perturbations and design a reasonable attacking utility function to handle the non-differentiable ranking-oriented metrics. Next, we propose a defense to robustify GCLF. The defense is based on the observation that attacks usually introduce suspicious interactions into the graph to manipulate the message-passing process. We then propose to measure the suspicious score of each interaction and further reduce the message weight of suspicious interactions. We also give a theoretical guarantee of its robustness. Experimental results on three benchmark datasets show the effectiveness of both our attack and defense.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4309857249",
    "type": "article"
  },
  {
    "title": "SSR: Solving Named Entity Recognition Problems via a Single-stream Reasoner",
    "doi": "https://doi.org/10.1145/3655619",
    "publication_date": "2024-04-01",
    "publication_year": 2024,
    "authors": "Yuxiang Zhang; Junjie Wang; Xinyu Zhu; Tetsuya Sakai; Hayato Yamana",
    "corresponding_authors": "",
    "abstract": "Information Extraction (IE) focuses on transforming unstructured data into structured knowledge, of which Named Entity Recognition (NER) is a fundamental component. In the realm of Information Retrieval (IR), effectively recognizing entities can substantially enhance the precision of search and recommendation systems. Existing methods frame NER as a sequence labeling task, which requires extra data and, therefore may be limited in terms of sustainability. One promising solution is to employ a Machine Reading Comprehension (MRC) approach for NER tasks, thereby eliminating the dependence on additional data. This process encounters key challenges, including: (1) Unconventional predictions; (2) Inefficient multi-stream processing; (3) Absence of a proficient reasoning strategy. To this end, we present the Single-Stream Reasoner (SSR), a solution utilizing a reasoning strategy and standardized inputs. This yields a type-agnostic solution for both flat and nested NER tasks, without the need for additional data. On ten NER benchmarks, SSR achieved state-of-the-art results, highlighting its robustness. Furthermore, we illustrated its efficiency through convergence, inference speed, and low-resource scenario performance comparisons. Our architecture displays adaptability and can effortlessly merge with various foundational models and reasoning strategies, fostering advancements in both the IR and IE fields.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4393378644",
    "type": "article"
  },
  {
    "title": "Cross-domain NER under a Divide-and-Transfer Paradigm",
    "doi": "https://doi.org/10.1145/3655618",
    "publication_date": "2024-04-02",
    "publication_year": 2024,
    "authors": "Xinghua Zhang; Bowen Yu; Xin Cong; Taoyu Su; Quangang Li; Tingwen Liu; Hongbo Xu",
    "corresponding_authors": "",
    "abstract": "Cross-domain Named Entity Recognition (NER) transfers knowledge learned from a rich-resource source domain to improve the learning in a low-resource target domain. Most existing works are designed based on the sequence labeling framework, defining entity detection and type prediction as a monolithic process. However, they typically ignore the discrepant transferability of these two sub-tasks: the former locating spans corresponding to entities is largely domain-robust, whereas the latter owns distinct entity types across domains. Combining them into an entangled learning problem may contribute to the complexity of domain transfer. In this work, we propose the novel divide-and-transfer paradigm in which different sub-tasks are learned using separate functional modules for respective cross-domain transfer. To demonstrate the effectiveness of divide-and-transfer, we concretely implement two NER frameworks by applying this paradigm with different cross-domain transfer strategies. Experimental results on 10 different domain pairs show the notable superiority of our proposed frameworks. Experimental analyses indicate that significant advantages of the divide-and-transfer paradigm over prior monolithic ones originate from its better performance on low-resource data and a much greater transferability. It gives us a new insight into cross-domain NER. Our code is available on GitHub. 1",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4393519485",
    "type": "article"
  },
  {
    "title": "M <sup>3</sup> Rec: A Context-Aware Offline Meta-Level Model-Based Reinforcement Learning Approach for Cold-Start Recommendation",
    "doi": "https://doi.org/10.1145/3659947",
    "publication_date": "2024-04-25",
    "publication_year": 2024,
    "authors": "Yanan Wang; Yong Ge; Zhepeng Li; Li Li; Rui Chen",
    "corresponding_authors": "",
    "abstract": "Reinforcement learning (RL) has shown great promise in optimizing long-term user interest in recommender systems. However, existing RL-based recommendation methods need a large number of interactions for each user to learn the recommendation policy. The challenge becomes more critical when recommending to new users who have a limited number of interactions. To that end, in this article, we address the cold-start challenge in the RL-based recommender systems by proposing a novel context-aware offline meta-level model-based RL approach for user adaptation. Our proposed approach learns to infer each user's preference with a user context variable that enables recommendation systems to better adapt to new users with limited contextual information. To improve adaptation efficiency, our approach learns to recover the user choice function and reward from limited contextual information through an inverse RL method, which is used to assist the training of a meta-level recommendation agent. To avoid the need for online interaction, the proposed method is trained using historically collected offline data. Moreover, to tackle the challenge of offline policy training, we introduce a mutual information constraint between the user model and recommendation agent. Evaluation results show the superiority of our developed offline policy learning method when adapting to new users with limited contextual information. In addition, we provide a theoretical analysis of the recommendation performance bound.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4395445743",
    "type": "article"
  },
  {
    "title": "A Blueprint of IR Evaluation Integrating Task and User Characteristics",
    "doi": "https://doi.org/10.1145/3675162",
    "publication_date": "2024-07-01",
    "publication_year": 2024,
    "authors": "Kalervo Järvelin; Eero Sormunen",
    "corresponding_authors": "",
    "abstract": "Traditional search result evaluation metrics in information retrieval, such as MAP and NDCG, naively focus on topical relevance between a document and search topic and assume this relationship as mono-dimensional and often binary. They neglect document content overlap and assume gains piling up as the searcher examines the ranked list at greater length. We propose a novel search result evaluation framework based on multidimensional, graded relevance assessments, explicit modelling of document overlaps and attributes affecting document usability beyond relevance. Document relevance to a search task is seen to consist of several content themes and document usability attributes. Documents may also overlap regarding their content themes. Attributes such as document readability, trustworthiness, or language represent the entire document’s usability in the search task context, for a given searcher and her motivating task. The proposed framework evaluates the quality of a ranked search result, taking into account the contribution of each successive document, with estimated overlap across themes, and usability based on its attributes.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400190077",
    "type": "article"
  },
  {
    "title": "Adaptive Taxonomy Learning and Historical Patterns Modeling for Patent Classification",
    "doi": "https://doi.org/10.1145/3674834",
    "publication_date": "2024-07-11",
    "publication_year": 2024,
    "authors": "Tao Zou; Le Yu; Junchen Ye; Leilei Sun; Bowen Du; Deqing Wang",
    "corresponding_authors": "",
    "abstract": "Patent classification aims to assign multiple International Patent Classification (IPC) codes to a given patent. Existing methods for automated patent classification primarily focus on analyzing the text descriptions of patents. However, apart from the textual information, each patent is also associated with some assignees, and the knowledge of their previously applied patents can often be valuable for accurate classification. Furthermore, the hierarchical taxonomy defined by the IPC system provides crucial contextual information and enables models to leverage the correlations between IPC codes for improved classification accuracy. However, existing methods fail to incorporate the above aspects and lead to reduced performance. To address these limitations, we propose an integrated framework that comprehensively considers patent-related information for patent classification. To be specific, we first present an IPC codes correlations learning module to capture both horizontal and vertical information within the IPC codes. This module effectively captures the correlations by adaptively exchanging and aggregating messages among IPC codes at the same level (horizontal information) and from both parent and children codes (vertical information), which allows for a comprehensive integration of knowledge and relationships within the IPC hierarchical taxonomy. Additionally, we design a historical application patterns learning component to incorporate previous patents of the corresponding assignee by aggregating high-order temporal information via a dual-channel graph neural network. Finally, our approach combines the contextual information from patent texts, which encompasses the semantics of IPC codes, with assignees’ sequential preferences to make predictions. Experimental evaluations on real-world datasets demonstrate the superiority of our proposed approach over existing methods. Moreover, we present the model’s ability to capture the temporal patterns of assignees and the semantic dependencies among IPC codes.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400531530",
    "type": "article"
  },
  {
    "title": "Dual Contrastive Learning for Cross-domain Named Entity Recognition",
    "doi": "https://doi.org/10.1145/3678879",
    "publication_date": "2024-07-20",
    "publication_year": 2024,
    "authors": "Jingyun Xu; Junnan Yu; Yi Cai; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "Benefiting many information retrieval applications, named entity recognition (NER) has shown impressive progress. Recently, there has been a growing trend to decompose complex NER tasks into two subtasks (e.g., entity span detection (ESD) and entity type classification (ETC), to achieve better performance. Despite the remarkable success, from the perspective of representation, existing methods do not explicitly distinguish non-entities and entities, which may lead to ESD errors. Meanwhile, they do not explicitly distinguish entities with different entity types, which may lead to entity type misclassification. As such, the limited representation abilities may challenge some competitive NER methods, leading to unsatisfactory performance, especially in the low-resource setting (e.g., cross-domain NER). In light of these challenges, we propose to utilize contrastive learning to refine the original chaotic representations and learn the generalized representations for cross-domain NER. In particular, this article proposes a dual contrastive learning model (Dual-CL), which respectively utilizes a token-level contrastive learning module and a sentence-level contrastive learning module to enhance ESD, ETC for cross-domain NER. Empirical results on 10 domain pairs under two different settings show that Dual-CL achieves better performances than compared baselines in terms of several standard metrics. Moreover, we conduct detailed analyses to are presented to better understand each component’s effectiveness.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400850932",
    "type": "article"
  },
  {
    "title": "A Self-Distilled Learning to Rank Model for Ad-hoc Retrieval",
    "doi": "https://doi.org/10.1145/3681784",
    "publication_date": "2024-07-25",
    "publication_year": 2024,
    "authors": "Sanaz Keshvari; Farzan Saeedi; Hadi Sadoghi Yazdi; Faezeh Ensan",
    "corresponding_authors": "",
    "abstract": "Learning to rank models are broadly applied in ad hoc retrieval for scoring and sorting documents based on their relevance to textual queries. The generalizability of the trained model in the learning to rank approach, however, can have an impact on the retrieval performance, particularly when data includes noise and outliers, or is incorrectly collected or measured. In this paper, we introduce a Self-Distilled Learning to Rank (SDLR) framework for ad hoc retrieval, and analyze its performance over a range of retrieval datasets and also in the presence of features’ noise. SDLR assigns a confidence weight to each training sample, aiming at reducing the impact of noisy and outlier data in the training process. The confidence weight is approximated based on the feature’s distributions derived from the values observed for the features of the documents labeled for a query in a listwise training sample. SDLR includes a distillation process that facilitates passing on the underlying patterns in assigning confidence weights from the teacher model to the student one. We empirically illustrate that SDLR outperforms state-of-the-art learning to rank models in ad hoc retrieval. We thoroughly investigate the SDLR performance in different settings including when no distillation strategy is applied; when different portion of data are used for training the teacher and the student models, and when both teacher and student models are trained over identical data. We show that SDLR is more effective when training data are split between a teacher and a student model. We also show that SDLR’s performance is robust when data features are noisy.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4400976991",
    "type": "article"
  },
  {
    "title": "Mixture-of-languages Routing for Multilingual Dialogues",
    "doi": "https://doi.org/10.1145/3676956",
    "publication_date": "2024-08-05",
    "publication_year": 2024,
    "authors": "Jiahuan Pei; Guojun Yan; Maarten de Rijke; Pengjie Ren",
    "corresponding_authors": "",
    "abstract": "We consider multilingual dialogue systems and ask how the performance of a dialogue system can be improved by using information that is available in other languages than the language in which a conversation is being conducted. We adopt a collaborative chair-experts framework, where each expert agent can be either monolingual or cross-lingual, and a chair agent follows a mixture-of-experts procedure for globally optimizing multilingual task-oriented dialogue systems. We propose a mixture-of-languages routing framework that includes four functional components, i.e., input embeddings of multilingual dialogues, language model, pairwise alignment between the representation of every two languages, and mixture-of-languages. We quantify language characteristics of unity and diversity using a number of similarity metrics, i.e., genetic similarity and word and sentence similarity based on embeddings. Our main finding is that the performance of multilingual task-oriented dialogue systems can be greatly impacted by three key aspects, i.e., data sufficiency, language characteristics, and model design in a mixture-of-languages routing framework.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4401335915",
    "type": "article"
  },
  {
    "title": "Distinguish Confusion in Legal Judgment Prediction via Revised Relation Knowledge",
    "doi": "https://doi.org/10.1145/3689628",
    "publication_date": "2024-08-24",
    "publication_year": 2024,
    "authors": "Nuo Xu; Pinghui Wang; Junzhou Zhao; Feiyang Sun; Lin Lan; Jing Tao; Li Pan; Xiaohong Guan",
    "corresponding_authors": "",
    "abstract": "Legal Judgment Prediction (LJP) aims to automatically predict a law case’s judgment results based on the text description of its facts. In practice, the confusing law articles (or charges) problem frequently occurs, reflecting that the law cases applicable to similar articles (or charges) tend to be misjudged. Although some recent works based on prior knowledge solve this issue well, they ignore that confusion also occurs between law articles with a high posterior semantic similarity due to the data imbalance problem instead of only between the prior highly similar ones, which is this work’s further finding. This article proposes an end-to-end model named D-LADAN to solve the above challenges. On the one hand, D-LADAN constructs a graph among law articles based on their text definition and proposes a graph distillation operator (GDO) to distinguish the ones with a high prior semantic similarity. On the other hand, D-LADAN presents a novel momentum-updated memory mechanism to dynamically sense the posterior similarity between law articles (or charges) and a weighted GDO to adaptively capture the distinctions for revising the inductive bias caused by the data imbalance problem. We perform extensive experiments to demonstrate that D-LADAN significantly outperforms state-of-the-art methods in accuracy and robustness.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4401844544",
    "type": "article"
  },
  {
    "title": "Feature-Enhanced Neural Collaborative Reasoning for Explainable Recommendation",
    "doi": "https://doi.org/10.1145/3690381",
    "publication_date": "2024-08-28",
    "publication_year": 2024,
    "authors": "Xiaoyu Zhang; Shaoyun Shi; Yishan Li; Weizhi Ma; Peijie Sun; Min Zhang",
    "corresponding_authors": "",
    "abstract": "Providing reasonable explanations for a specific suggestion given by the recommender can help users trust the system more. As logic rule-based inference is concise, transparent, and aligned with human cognition, it can be adopted to improve the interpretability of recommendation models. Previous work that interprets user preference with logic rules merely focuses on the construction of rules while neglecting the usage of feature embeddings. This limits the model in capturing implicit relationships between features. In this article, we aim to improve both the effectiveness and explainability of recommendation models by simultaneously representing logic rules and feature embeddings. We propose a novel model-intrinsic explainable recommendation method named Feature-Enhanced Neural Collaborative Reasoning (FENCR) . The model automatically extracts representative logic rules from massive possibilities in a data-driven way. In addition, we utilize feature interaction-based neural modules to represent logic operators on embeddings. Experiments on two large public datasets show our model outperforms state-of-the-art neural logical recommendation models. Further case analyses demonstrate that FENCR can derive reasonable rules, indicating its high robustness and expandability. 1",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4401952059",
    "type": "article"
  },
  {
    "title": "MCAP: Low-Pass GNNs with Matrix Completion for Academic Recommendations",
    "doi": "https://doi.org/10.1145/3698193",
    "publication_date": "2024-10-01",
    "publication_year": 2024,
    "authors": "Dan Zhang; Shaojie Zheng; Yifan Zhu; Huihui Yuan; Jibing Gong; Jie Tang",
    "corresponding_authors": "",
    "abstract": "Graph Neural Networks (GNNs) are commonly used and have shown promising performance in recommendation systems. A major branch, Heterogeneous GNNs, models heterogeneous information by leveraging side information for academic paper recommendations. These networks use message passing and high-order propagation to learn representations for users and items. However, existing recommendation methods perform high-order propagation, leading to suboptimal representation learning. To address this issue, this paper proposes a framework called MCAP, which uses relation-aware GNNs and executes low-pass propagation with matrix completion to enhance academic paper recommendations. The framework uses an attention mechanism to learn top- U relationships by constructing a user-user relation graph based on common authors and venues from interacted items. To efficiently and effectively capture semantic-aware similar items, MCAP builds an item-item relation graph by fusing side information of papers using text embedding models (e.g., Mistral) and large language models (e.g., GPT-3.5-Turbo, GLM-4). Finally, the relation-aware user-user and item-item graphs are incorporated into existing GNN-based models to generate representations of users and papers to enhance academic paper recommendations. The effectiveness of the MCAP is validated using four academic datasets, AMiner-PC, AMiner-WeChat, CiteULike, and DBLP, with user-item interactions and side information of papers. Comprehensive experiments show that the MCAP outperforms state-of-the-art models in terms of Recall@5, NDCG@5, and HR@5 with 69.2%, 70.5%, and 77.6% on the AMiner-WeChat dataset. The code for MCAP is available at https://github.com/THUDM/MCAP .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403028789",
    "type": "article"
  },
  {
    "title": "Multi-agent Attacks for Black-box Social Recommendations",
    "doi": "https://doi.org/10.1145/3696105",
    "publication_date": "2024-10-21",
    "publication_year": 2024,
    "authors": "Shijie Wang; Wenqi Fan; Xiao-Yong Wei; Xiaowei Mei; Shanru Lin; Qing Li",
    "corresponding_authors": "",
    "abstract": "The rise of online social networks has facilitated the evolution of social recommender systems, which incorporate social relations to enhance users’ decision-making process. With the great success of Graph Neural Networks (GNNs) in learning node representations, GNN-based social recommendations have been widely studied to model user-item interactions and user-user social relations simultaneously. Despite their great successes, recent studies have shown that these advanced recommender systems are highly vulnerable to adversarial attacks, in which attackers can inject well-designed fake user profiles to disrupt recommendation performances. While most existing studies mainly focus on targeted attacks to promote target items on vanilla recommender systems, untargeted attacks to degrade the overall prediction performance are less explored on social recommendations under a black-box scenario. To perform untargeted attacks on social recommender systems, attackers can construct malicious social relationships for fake users to enhance the attack performance. However, the coordination of social relations and item profiles is challenging for attacking black-box social recommendations. To address this limitation, we first conduct several preliminary studies to demonstrate the effectiveness of cross-community connections and cold-start items in degrading recommendations performance. Specifically, we propose a novel framework MultiAttack based on multi-agent reinforcement learning to coordinate the generation of cold-start item profiles and cross-community social relations for conducting untargeted attacks on black-box social recommendations. Comprehensive experiments on various real-world datasets demonstrate the effectiveness of our proposed attacking framework under the black-box setting.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403602278",
    "type": "article"
  },
  {
    "title": "Understanding Before Recommendation: Semantic Aspect-Aware Review Exploitation via Large Language Models",
    "doi": "https://doi.org/10.1145/3704999",
    "publication_date": "2024-11-24",
    "publication_year": 2024,
    "authors": "Fan Liu; Yaqi Liu; Huilin Chen; Zhiyong Cheng; Liqiang Nie; Mohan Kankanhalli",
    "corresponding_authors": "",
    "abstract": "Recommendation systems harness user-item interactions like clicks and reviews to learn their representations. Previous studies improve recommendation accuracy and interpretability by modeling user preferences across various aspects and intents. However, the aspects and intents are inferred directly from user reviews or behavior patterns, suffering from the data noise and the data sparsity problem. Furthermore, it is difficult to understand the reasons behind recommendations due to the challenges of interpreting implicit aspects and intents. To address these constraints, we harness the sentiment analysis capabilities of Large Language Models (LLMs) to enhance the accuracy and interpretability of the conventional recommendation methods. Specifically, inspired by the deep semantic understanding offered by LLMs, we introduce a chain-based prompting strategy to uncover semantic aspect-aware interactions, which provide clearer insights into user behaviors at a fine-grained semantic level. To incorporate the rich interactions of various aspects, we propose the simple yet effective Semantic Aspect-based Graph Convolution Network (short for SAGCN). By performing graph convolutions on multiple semantic aspect graphs, SAGCN efficiently combines embeddings across multiple semantic aspects for final user and item representations. The effectiveness of the SAGCN was evaluated on four publicly available datasets through extensive experiments, which revealed that it outperforms all other competitors. Furthermore, interpretability analysis experiments were conducted to demonstrate the interpretability of incorporating semantic aspects into the model.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4404658147",
    "type": "article"
  },
  {
    "title": "The in-situ effect of offensive ads on search engine users",
    "doi": "https://doi.org/10.1145/3704438",
    "publication_date": "2024-12-18",
    "publication_year": 2024,
    "authors": "Elad Yom‐Tov; Alexandra Olteanu; Liat Levontin",
    "corresponding_authors": "",
    "abstract": "Unscrupulous advertisers may try to increase attention to search ads by using offensive ads, which can increase attention and recall to the detriment of individuals and society. Here we investigate whether offensive ads, when shown to search engine users, have such effects. We developed 12 search scenarios and created 4 versions of the search results page (SERP) for each scenario, where some of the ads were changed to be irrelevant and/or offensive. Crowdsourced judges found a strong correlation ( \\(\\geq 0.63\\) ) between the reported number of annoying ads and the actual number of offensive and irrelevant ads, suggesting people conflate these attributes. Furthermore, we found that judges who assessed the SERPs for themselves reported lower positive affect and higher negative affect than judges asked to imagine the results were provided to someone else. In the latter case offensive ads also lead to slightly lower positive ( \\(-4\\%\\) ) and higher negative affect ( \\(+61\\%\\) ). Finally, in a recall test, only 6% of judges reported seeing an offensive ad when using search engines. Our work should further detract advertisers from using offensive ads since, in addition to previously documented adverse effects, such ads have a small but statistically significant negative effect on people's emotional experience.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405553425",
    "type": "article"
  },
  {
    "title": "Thoroughly Modeling Multi-domain Pre-trained Recommendation as Language",
    "doi": "https://doi.org/10.1145/3708883",
    "publication_date": "2024-12-19",
    "publication_year": 2024,
    "authors": "Zekai Qu; Ruobing Xie; Chaojun Xiao; Yuan Yao; Zhiyuan Liu; Fengzong Lian; Zhanhui Kang; Jie Zhou",
    "corresponding_authors": "",
    "abstract": "With the thriving of the pre-trained language model (PLM) widely verified in various NLP tasks, pioneer efforts attempt to explore the possible cooperation of the general textual information in PLM with the personalized behavioral information in user historical behavior sequences to enhance sequential recommendation (SR). However, despite the commonalities of input format and task goal, there are huge gaps between the behavioral and textual information, which obstruct thoroughly modeling SR as language modeling via PLM. To bridge the gap, we propose a novel unified pre-trained language model enhanced sequential recommendation (UPSR) that thoroughly transfers the next item prediction task to a text generation task, aiming to build a unified pre-trained recommendation model for multi-domain recommendation tasks. We formally design five key indicators, namely naturalness, domain consistency, informativeness, noise &amp; ambiguity, and text length, to guide the text \\(\\rightarrow\\) item adaptation (selecting appropriate text to form the item textual representation) and behavior sequence \\(\\rightarrow\\) text sequence adaptation (transferring the sequence of item textual representations into a text sequence) differently for pre-training and fine-tuning stages, which are essential but under-explored by previous works. In experiments, we conduct extensive evaluations on seven datasets with both supervised and zero-shot settings and achieve the overall best performance. Comprehensive model analyses also provide valuable insights for behavior modeling via PLM, shedding light on large pre-trained recommendation models. The source codes will be released in the future.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405578085",
    "type": "article"
  },
  {
    "title": "Decoy Effect In Search Interaction: Understanding User Behavior and Measuring System Vulnerability",
    "doi": "https://doi.org/10.1145/3708884",
    "publication_date": "2024-12-19",
    "publication_year": 2024,
    "authors": "Nuo Chen; Jiqun Liu; Hanpei Fang; Yuankai Luo; Tetsuya Sakai; Xiao-Ming Wu",
    "corresponding_authors": "",
    "abstract": "This study addresses (1) the influence of the decoy effect, a cognitive bias where the presence of an inferior item alters preferences between two options, on users’ search interactions and (2) the measurement of information retrieval systems’ vulnerability to the decoy effect 1 . From the perspective of user behavior, this study investigates the influence of the decoy effect in information retrieval (IR) by examining how decoy results affect users’ interaction on search engine result pages (SERPs), particularly in terms of click-through likehood, browsing dwell time, and perceived document usefulness. We conducted an experiment based upon regression analysis on user interaction logs from three user study datasets which in total encompass 24 topics, 841 unique search sessions, and 2,685 queries. The findings indicate that decoys significantly increase the likelihood of document clicks and perceived usefulness. To investigate whether the influence of the decoy varies across different levels of task difficulty and user knowledge, we ran an additional experiment on one of the three datasets, which encompasses 6 topics, 166 search sessions and 652 queries. The results indicate that when the task is less challenging, users are more likely to click on a document with a decoy. Additionally, they spend more time on the target document and assign it a higher usefulness score. Furthermore, users with lower knowledge levels about the topic tend to give higher usefulness ratings to the target document. Regarding IR system evaluation, this study provides empirical insights into measuring the vulnerability of text retrieval models to potential decoy effect. An evaluation metric, namely DEcoy Judgement and Assessment VUlnerability (DEJA-VU), is proposed to evaluate the possibility of a retrieval model ranking results in a way that could trigger decoy biases. The experiments on the TREC 19 DL passage retrieval task and the TREC 20 DL passage retrieval task demonstrate that ColBERT and SPLADE show higher relevance-oriented retrieval effectiveness while also displaying lower vulnerability to decoy effect. Overall, this work advances the understanding of decoy effect, a well-established concept in cognitive psychology and behavioral economics, in a novel application field ( i.e., Information Retrieval). It contributes to modeling users’ search behavior in the context of cognitive biases, as well as assessment of the vulnerability of systems and ranking algorithms to the decoy effect.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405578323",
    "type": "article"
  },
  {
    "title": "Exploiting Real-time Search Engine Queries for Earthquake Detection: A Summary of Results",
    "doi": "https://doi.org/10.1145/3453842",
    "publication_date": "2021-05-25",
    "publication_year": 2021,
    "authors": "Qi Zhang; Hengshu Zhu; Qi Liu; Enhong Chen; Hui Xiong",
    "corresponding_authors": "",
    "abstract": "Online search engine has been widely regarded as the most convenient approach for information acquisition. Indeed, the intensive information-seeking behaviors of search engine users make it possible to exploit search engine queries as effective “crowd sensors” for event monitoring. While some researchers have investigated the feasibility of using search engine queries for coarse-grained event analysis, the capability of search engine queries for real-time event detection has been largely neglected. To this end, in this article, we introduce a large-scale and systematic study on exploiting real-time search engine queries for outbreak event detection, with a focus on earthquake rapid reporting. In particular, we propose a realistic system of real-time earthquake detection through monitoring millions of queries related to earthquakes from a dominant online search engine in China. Specifically, we first investigate a large set of queries for selecting the representative queries that are highly correlated with the outbreak of earthquakes. Then, based on the real-time streams of selected queries, we design a novel machine learning–enhanced two-stage burst detection approach for detecting earthquake events. Meanwhile, the location of an earthquake epicenter can be accurately estimated based on the spatial-temporal distribution of search engine queries. Finally, through the extensive comparison with earthquake catalogs from China Earthquake Networks Center, 2015, the detection precision of our system can achieve 87.9%, and the accuracy of location estimation (province level) is 95.7%. In particular, 50% of successfully detected results can be found within 62 s after earthquake, and 50% of successful locations can be found within 25.5 km of seismic epicenter. Our system also found more than 23.3% extra earthquakes that were felt by people but not publicly released, 12.1% earthquake-like special outbreaks, and meanwhile, revealed many interesting findings, such as the typical query patterns of earthquake rumor and regular memorial events. Based on these results, our system can timely feed back information to the search engine users according to various cases and accelerate the information release of felt earthquakes.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3164260432",
    "type": "article"
  },
  {
    "title": "A Document Retrieval Model Based on Digital Signal Filtering",
    "doi": "https://doi.org/10.1145/2809787",
    "publication_date": "2015-09-22",
    "publication_year": 2015,
    "authors": "Alberto Costa; Emanuele Di Buccio; Massimo Melucci",
    "corresponding_authors": "",
    "abstract": "Information retrieval (IR) systems are designed, in general, to satisfy the information need of a user who expresses it by means of a query, by providing him with a subset of documents selected from a collection and ordered by decreasing relevance to the query. Such systems are based on IR models, which define how to represent the documents and the query, as well as how to determine the relevance of a document for a query. In this article, we present a new IR model based on concepts taken from both IR and digital signal processing (like Fourier analysis of signals and filtering). This allows the whole IR process to be seen as a physical phenomenon, where the query corresponds to a signal, the documents correspond to filters, and the determination of the relevant documents to the query is done by filtering that signal. Tests showed that the quality of the results provided by this IR model is comparable with the state-of-the-art.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2005704104",
    "type": "article"
  },
  {
    "title": "XXS",
    "doi": "https://doi.org/10.1145/2629554",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Nieves R. Brisaboa; Ana Cerdeira-Pena; Gonzalo Navarro",
    "corresponding_authors": "",
    "abstract": "The eXtensible Markup Language (XML) is acknowledged as the de facto standard for semistructured data representation and data exchange on the Web and many other scenarios. A well-known shortcoming of XML is its verbosity, which increases manipulation, transmission, and processing costs. Various structure-blind and structure-conscious compression techniques can be applied to XML, and some are even access-friendly, meaning that the documents can be efficiently accessed in compressed form. Direct access is necessary to implement the query languages XPath and XQuery, which are the standard ones to exploit the expressiveness of XML. While a good deal of theoretical and practical proposals exist to solve XPath/XQuery operations on XML, only a few ones are well integrated with a compression format that supports the required access operations on the XML data. In this work we go one step further and design a compression format for XML collections that boosts the performance of XPath queries on the data. This is done by designing compressed representations of the XML data that support some complex operations apart from just accessing the data, and those are exploited to solve key components of the XPath queries. Our system, called XXS, is aimed at XML collections containing natural language text, which are compressed to within 35%--50% of their original size while supporting a large subset of XPath operations in time competitive with, and many times outperforming, the best state-of-the-art systems that work on uncompressed representations.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2036954656",
    "type": "article"
  },
  {
    "title": "Trustworthy Recommendation and Search: Introduction to the Special Issue - Part 1",
    "doi": "https://doi.org/10.1145/3579995",
    "publication_date": "2023-02-07",
    "publication_year": 2023,
    "authors": "Hongzhi Yin; Yizhou Sun; Guandong Xu; Evangelos Kanoulas",
    "corresponding_authors": "",
    "abstract": "introduction Trustworthy Recommendation and Search: Introduction to the Special Issue - Part 1 Authors: Hongzhi Yin The University of Queensland, Brisbane, QLD, Australia The University of Queensland, Brisbane, QLD, Australia 0000-0003-1395-261XView Profile , Yizhou Sun University of California, Los Angeles, CA, USA University of California, Los Angeles, CA, USA 0000-0003-1812-6843View Profile , Guandong Xu University of Technology Sydney, Sydney, NSW, Australia University of Technology Sydney, Sydney, NSW, Australia 0000-0003-4493-6663View Profile , Evangelos Kanoulas University of Amsterdam, Amsterdam, XH, Netherlands University of Amsterdam, Amsterdam, XH, Netherlands 0000-0002-8312-0694View Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 41Issue 3July 2023 Article No.: 51pp 1–5https://doi.org/10.1145/3579995Published:07 February 2023Publication History 0citation130DownloadsMetricsTotal Citations0Total Downloads130Last 12 Months130Last 6 weeks130 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4319348372",
    "type": "article"
  },
  {
    "title": "Syntactic-Informed Graph Networks for Sentence Matching",
    "doi": "https://doi.org/10.1145/3609795",
    "publication_date": "2023-07-19",
    "publication_year": 2023,
    "authors": "Xu Chen; Jun Xu; Zhenhua Dong; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Matching two natural language sentences is a fundamental problem in both natural language processing and information retrieval. Preliminary studies have shown that the syntactic structures help improve the matching accuracy, and different syntactic structures in natural language are complementary to sentence semantic understanding. Ideally, a matching model would leverage all syntactic information. Existing models, however, are only able to combine limited (usually one) types of syntactic information due to the complex and heterogeneous nature of the syntactic information. To deal with the problem, we propose a novel matching model, which formulates sentence matching as a representation learning task on a syntactic-informed heterogeneous graph. The model, referred to as SIGN (Syntactic-Informed Graph Network), first constructs a heterogeneous matching graph based on the multiple syntactic structures of two input sentences. Then the graph attention network algorithm is applied to the matching graph to learn the high-level representations of the nodes. With the help of the graph learning framework, the multiple syntactic structures, as well as the word semantics, can be represented and interacted in the matching graph and therefore collectively enhance the matching accuracy. We conducted comprehensive experiments on three public datasets. The results demonstrate that SIGN outperforms the state of the art and also can discriminate the sentences in an interpretable way.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4384822356",
    "type": "article"
  },
  {
    "title": "Unifying Token- and Span-level Supervisions for Few-shot Sequence Labeling",
    "doi": "https://doi.org/10.1145/3610403",
    "publication_date": "2023-07-20",
    "publication_year": 2023,
    "authors": "Zifeng Cheng; Qingyu Zhou; Zhiwei Jiang; Xuemin Zhao; Yunbo Cao; Qing Gu",
    "corresponding_authors": "",
    "abstract": "Few-shot sequence labeling aims to identify novel classes based on only a few labeled samples. Existing methods solve the data scarcity problem mainly by designing token-level or span-level labeling models based on metric learning. However, these methods are only trained at a single granularity (i.e., either token-level or span-level) and have some weaknesses of the corresponding granularity. In this article, we first unify token- and span-level supervisions and propose a Consistent Dual Adaptive Prototypical (CDAP) network for few-shot sequence labeling. CDAP contains the token- and span-level networks, jointly trained at different granularities. To align the outputs of two networks, we further propose a consistent loss to enable them to learn from each other. During the inference phase, we propose a consistent greedy inference algorithm that first adjusts the predicted probability and then greedily selects non-overlapping spans with maximum probability. Extensive experiments show that our model achieves new state-of-the-art results on three benchmark datasets. All the code and data of this work will be released at https://github.com/zifengcheng/CDAP .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4384934696",
    "type": "article"
  },
  {
    "title": "Teach and Explore: A Multiplex Information-guided Effective and Efficient Reinforcement Learning for Sequential Recommendation",
    "doi": "https://doi.org/10.1145/3630003",
    "publication_date": "2023-10-23",
    "publication_year": 2023,
    "authors": "Surong Yan; Chenglong Shi; Haosen Wang; Lei Chen; Ling Jiang; Guo Rui-lin; Kwei-Jay Lin",
    "corresponding_authors": "",
    "abstract": "Casting sequential recommendation (SR) as a reinforcement learning (RL) problem is promising and some RL-based methods have been proposed for SR. However, these models are sub-optimal due to the following limitations: (a) they fail to leverage the supervision signals in the RL training to capture users’ explicit preferences, leading to slow convergence; and (b) they do not utilize auxiliary information (e.g., knowledge graph) to avoid blindness when exploring users’ potential interests. To address the above-mentioned limitations, we propose a multiplex information-guided RL model (MELOD), which employs a novel RL training framework with Teach and Explore components for SR. We adopt a Teach component to accurately capture users’ explicit preferences and speed up RL convergence. Meanwhile, we design a dynamic intent induction network (DIIN) as a policy function to generate diverse predictions. We utilize the DIIN for the Explore component to mine users’ potential interests by conducting a sequential and knowledge information joint-guided exploration. Moreover, a sequential and knowledge-aware reward function is designed to achieve stable RL training. These components significantly improve MELOD’s performance and convergence against existing RL algorithms to achieve effectiveness and efficiency. Experimental results on seven real-world datasets show that our model significantly outperforms state-of-the-art methods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4387869251",
    "type": "article"
  },
  {
    "title": "rHDP: An Aspect Sharing-Enhanced Hierarchical Topic Model for Multi-Domain Corpus",
    "doi": "https://doi.org/10.1145/3631352",
    "publication_date": "2023-11-02",
    "publication_year": 2023,
    "authors": "Yitao Zhang; Changxuan Wan; Keli Xiao; Qizhi Wan; Dexi Liu; Xiping Liu",
    "corresponding_authors": "",
    "abstract": "Learning topic hierarchies from a multi-domain corpus is crucial in topic modeling as it reveals valuable structural information embedded within documents. Despite the extensive literature on hierarchical topic models, effectively discovering inter-topic correlations and differences among subtopics at the same level in the topic hierarchy, obtained from multiple domains, remains an unresolved challenge. This article proposes an enhanced nested Chinese restaurant process (nCRP), nCRP+, by introducing an additional mechanism based on Chinese restaurant franchise (CRF) for aspect-sharing pattern extraction in the original nCRP. Subsequently, by employing the distribution extracted from nCRP+ as the prior distribution for topic hierarchy in the hierarchical Dirichlet processes (HDP), we develop a hierarchical topic model for multi-domain corpus, named rHDP. We describe the model with the analogy of Chinese restaurant franchise based on the central kitchen and propose a hierarchical Gibbs sampling scheme to infer the model. Our method effectively constructs well-established topic hierarchies, accurately reflecting diverse parent-child topic relationships, explicit topic aspect sharing correlations for inter-topics, and differences between these shared topics. To validate the efficacy of our approach, we conduct experiments using a renowned public dataset and an online collection of Chinese financial documents. The experimental results confirm the superiority of our method over the state-of-the-art techniques in identifying multi-domain topic hierarchies, according to multiple evaluation metrics.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4388210421",
    "type": "article"
  },
  {
    "title": "(Un)likelihood Training for Interpretable Embedding",
    "doi": "https://doi.org/10.1145/3632752",
    "publication_date": "2023-11-13",
    "publication_year": 2023,
    "authors": "Jiaxin Wu; Chong‐Wah Ngo; W. K. Chan; Zhijian Hou",
    "corresponding_authors": "",
    "abstract": "Cross-modal representation learning has become a new normal for bridging the semantic gap between text and visual data. Learning modality agnostic representations in a continuous latent space, however, is often treated as a black-box data-driven training process. It is well known that the effectiveness of representation learning depends heavily on the quality and scale of training data. For video representation learning, having a complete set of labels that annotate the full spectrum of video content for training is highly difficult, if not impossible. These issues, black-box training and dataset bias, make representation learning practically challenging to be deployed for video understanding due to unexplainable and unpredictable results. In this article, we propose two novel training objectives, likelihood and unlikelihood functions, to unroll the semantics behind embeddings while addressing the label sparsity problem in training. The likelihood training aims to interpret semantics of embeddings beyond training labels, while the unlikelihood training leverages prior knowledge for regularization to ensure semantically coherent interpretation. With both training objectives, a new encoder-decoder network, which learns interpretable cross-modal representation, is proposed for ad-hoc video search. Extensive experiments on TRECVid and MSR-VTT datasets show that the proposed network outperforms several state-of-the-art retrieval models with a statistically significant performance margin.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4388638745",
    "type": "article"
  },
  {
    "title": "Exploring Dense Retrieval for Dialogue Response Selection",
    "doi": "https://doi.org/10.1145/3632750",
    "publication_date": "2023-11-14",
    "publication_year": 2023,
    "authors": "Tian Lan; Deng Cai; Yan Wang; Yixuan Su; Heyan Huang; Xian-Ling Mao",
    "corresponding_authors": "",
    "abstract": "Recent progress in deep learning has continuously improved the accuracy of dialogue response selection. However, in real-world scenarios, the high computation cost forces existing dialogue response selection models to rank only a small number of candidates, recalled by a coarse-grained model, precluding many high-quality candidates. To overcome this problem, we present a novel and efficient response selection model and a set of tailor-designed learning strategies to train it effectively. The proposed model consists of a dense retrieval module and an interaction layer, which could directly select the proper response from a large corpus. We conduct re-rank and full-rank evaluations on widely used benchmarks to evaluate our proposed model. Extensive experimental results demonstrate that our proposed model notably outperforms the state-of-the-art baselines on both re-rank and full-rank evaluations. Moreover, human evaluation results show that the response quality could be improved further by enlarging the candidate pool with nonparallel corpora. In addition, we also release high-quality benchmarks that are carefully annotated for more accurate dialogue response selection evaluation. All source codes, datasets, model parameters, and other related resources have been publicly available. 1",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4388657677",
    "type": "article"
  },
  {
    "title": "On the Impact of Showing Evidence from Peers in Crowdsourced Truthfulness Assessments",
    "doi": "https://doi.org/10.1145/3637872",
    "publication_date": "2023-12-19",
    "publication_year": 2023,
    "authors": "Jiechen Xu; Lei Han; Shazia Sadiq; Gianluca Demartini",
    "corresponding_authors": "",
    "abstract": "Misinformation has been rapidly spreading online. The common approach to dealing with it is deploying expert fact-checkers who follow forensic processes to identify the veracity of statements. Unfortunately, such an approach does not scale well. To deal with this, crowdsourcing has been looked at as an opportunity to complement the work done by trained journalists. In this article, we look at the effect of presenting the crowd with evidence from others while judging the veracity of statements. We implement variants of the judgment task design to understand whether and how the presented evidence may or may not affect the way crowd workers judge truthfulness and their performance. Our results show that, in certain cases, the presented evidence and the way in which it is presented may mislead crowd workers who would otherwise be more accurate if judging independently from others. Those who make appropriate use of the provided evidence, however, can benefit from it and generate better judgments.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4389950508",
    "type": "article"
  },
  {
    "title": "PIC matrices",
    "doi": "https://doi.org/10.1145/326440.326444",
    "publication_date": "1999-10-01",
    "publication_year": 1999,
    "authors": "Warren R. Greiff; W. Bruce Croft; Howard R. Turtle",
    "corresponding_authors": "",
    "abstract": "The inference network model of information retrieval allows a probabilistic interpretation of query operators. In particular, Boolean query operators are conveniently modeled as link matrices of the Bayesian Network. Prior work has shown, however, that these operators do not perform as well as the pnorm operators used for modeling query operators in the context of the vector space model. This motivates the search for alternative probabilistic formulations for these operators. The design of such alternatives must contend with the issue of computational tractability, since the evaluation of an arbitrary operator requires exponential time. We define a flexible class of link matrices that are natural candidates for the implementation of query operators and an O ( n 2 ) algorithm ( n = the number of parent nodes) for the computation of probabilities involving link matrices of this class. We present experimental results indicating that Boolean operators implemented in terms of link matrices from this class perform as well as pnorm operators in the context of the INQUERY inference network.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1972976101",
    "type": "article"
  },
  {
    "title": "Knowledge-based tools to promote shared goals and terminology between interface designers",
    "doi": "https://doi.org/10.1145/45945.48028",
    "publication_date": "1988-07-01",
    "publication_year": 1988,
    "authors": "Robert Neches",
    "corresponding_authors": "Robert Neches",
    "abstract": "Two tools that support cooperation are described: one for the construction of consistent and principled human-computer interfaces and the other for the construction of AI knowledge bases. These tools provide a central repository for design knowledge that otherwise would not be easily shared among users. The AI knowledge representation technology upon which the tools are founded is first described. A knowledge-based approach to interface construction is discussed, and how that approach applies to detecting design conflicts and inconsistencies stemming from two different kinds of team communication failure is illustrated. Next, a knowledge acquisition aid that is utilized within the interface construction paradigm and that also illustrates the same approach to supporting cooperative work is described. Finally, four sources of difficulty in team design efforts, which this approach seeks to address, are reviewed.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2031546091",
    "type": "article"
  },
  {
    "title": "Channel selection and effective communication for managerial decision making",
    "doi": "https://doi.org/10.1145/521.522",
    "publication_date": "1984-05-24",
    "publication_year": 1984,
    "authors": "Eileen M. Trauth; Stephen K. Kwan; Susanna Barber",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on Channel selection and effective communication for managerial decision making Authors: Eileen M. Trauth Boston Univ., Boston, MA Boston Univ., Boston, MAView Profile , Stephen K Kwan Boston Univ., Boston, MA Boston Univ., Boston, MAView Profile , Susanna Barber Emerson College, Boston, MA Emerson College, Boston, MAView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 2pp 123–140https://doi.org/10.1145/521.522Published:24 May 1984Publication History 6citation1,012DownloadsMetricsTotal Citations6Total Downloads1,012Last 12 Months41Last 6 weeks16 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2040264256",
    "type": "article"
  },
  {
    "title": "Meta methods for model sharing in personal information systems",
    "doi": "https://doi.org/10.1145/1402256.1402261",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Stefan Siersdorfer; Sergej Sizov",
    "corresponding_authors": "",
    "abstract": "This article introduces a methodology for automatically organizing document collections into thematic categories for Personal Information Management (PIM) through collaborative sharing of machine learning models in an efficient and privacy-preserving way. Our objective is to combine multiple independently learned models from several users to construct an advanced ensemble-based decision model by taking the knowledge of multiple users into account in a decentralized manner, for example, in a peer-to-peer overlay network. High accuracy of the corresponding supervised (classification) and unsupervised (clustering) methods is achieved by restrictively leaving out uncertain documents rather than assigning them to inappropriate topics or clusters with low confidence. We introduce a formal probabilistic model for the resulting ensemble based meta methods and explain how it can be used for constructing estimators and for goal-oriented tuning. Comprehensive evaluation results on different reference data sets illustrate the viability of our approach.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1963762504",
    "type": "article"
  },
  {
    "title": "Further Insights on Drawing Sound Conclusions from Noisy Judgments",
    "doi": "https://doi.org/10.1145/3186195",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "David M. Goldberg; Andrew Trotman; Xiao Wang; Wei Min; Zongru Wan",
    "corresponding_authors": "",
    "abstract": "The effectiveness of a search engine is typically evaluated using hand-labeled datasets, where the labels indicate the relevance of documents to queries. Often the number of labels needed is too large to be created by the best annotators, and so less expensive labels (e.g., from crowdsourcing) are used. This introduces errors in the labels, and thus errors in standard effectiveness metrics (such as P@k and DCG). These errors must be taken into consideration when using the metrics. Previous work has approached assessor error by taking aggregates over multiple inexpensive assessors. We take a different approach and introduce equations and algorithms that can adjust the metrics to the values they would have had if there were no annotation errors. This is especially important when two search engines are compared on their metrics. We give examples where one engine appeared to be statistically significantly better than the other, but the effect disappeared after the metrics were corrected for annotation error. In other words, the evidence supporting a statistical difference was illusory and caused by a failure to account for annotation error.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2800969132",
    "type": "article"
  },
  {
    "title": "Search Result Reranking with Visual and Structure Information Sources",
    "doi": "https://doi.org/10.1145/3329188",
    "publication_date": "2019-06-26",
    "publication_year": 2019,
    "authors": "Yiqun Liu; Junqi Zhang; Jiaxin Mao; Min Zhang; Shaoping Ma; Qi Tian; Yanxiong Lu; Leyu Lin",
    "corresponding_authors": "",
    "abstract": "Relevance estimation is among the most important tasks in the ranking of search results. Current methodologies mainly concentrate on text matching, link analysis, and user behavior models. However, users judge the relevance of search results directly from Search Engine Result Pages (SERPs), which provide valuable signals for reranking. In this article, we propose two different approaches to aggregate the visual, structure, as well as textual information sources of search results in relevance estimation. The first one is a late-fusion framework named Joint Relevance Estimation model (JRE). JRE estimates the relevance independently from screenshots, textual contents, and HTML source codes of search results and jointly makes the final decision through an inter-modality attention mechanism. The second one is an early-fusion framework named Tree-based Deep Neural Network (TreeNN), which embeds the texts and images into the HTML parse tree through a recursive process. To evaluate the performance of the proposed models, we construct a large-scale practical Search Result Relevance (SRR) dataset that consists of multiple information sources and relevance labels of over 60,000 search results. Experimental results show that the proposed two models achieve better performance than state-of-the-art ranking solutions as well as the original rankings of commercial search engines.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2955037254",
    "type": "article"
  },
  {
    "title": "Relevance Feedback",
    "doi": "https://doi.org/10.1145/3360487",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "Fiana Raiber; Oren Kurland",
    "corresponding_authors": "",
    "abstract": "Document retrieval methods that utilize relevance feedback often induce a single query model from the set of feedback documents, specifically, the relevant documents. We empirically show that for a few state-of-the-art query-model induction methods, retrieval performance can be significantly improved by constructing the query model from a subset of the relevant documents rather than from all of them. Motivated by this finding, we propose a new approach for relevance-feedback-based retrieval. The approach, derived from the risk minimization framework, is based on utilizing multiple query models induced from all subsets of the given relevant documents. Empirical evaluation shows that the approach posts performance that is statistically significantly better than that of applying the standard practice of utilizing a single query model induced from the relevant documents. While the average relative improvements are small to moderate, the robustness of the approach is substantially higher than that of a variety of reference comparison methods that address various challenges in using relevance feedback.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2979515568",
    "type": "article"
  },
  {
    "title": "MergeDTS",
    "doi": "https://doi.org/10.1145/3411753",
    "publication_date": "2020-09-10",
    "publication_year": 2020,
    "authors": "Chang Li; Ilya Markov; Maarten de Rijke; Masrour Zoghi",
    "corresponding_authors": "",
    "abstract": "Online ranker evaluation is one of the key challenges in information retrieval. Although the preferences of rankers can be inferred by interleaving methods, the problem of how to effectively choose the ranker pair that generates the interleaved list without degrading the user experience too much is still challenging. On the one hand, if two rankers have not been compared enough, the inferred preference can be noisy and inaccurate. On the other hand, if two rankers are compared too many times, the interleaving process inevitably hurts the user experience too much. This dilemma is known as the exploration versus exploitation tradeoff. It is captured by the K -armed dueling bandit problem, which is a variant of the K -armed bandit problem, where the feedback comes in the form of pairwise preferences. Today’s deployed search systems can evaluate a large number of rankers concurrently, and scaling effectively in the presence of numerous rankers is a critical aspect of K -armed dueling bandit problems. In this article, we focus on solving the large-scale online ranker evaluation problem under the so-called Condorcet assumption, where there exists an optimal ranker that is preferred to all other rankers. We propose Merge Double Thompson Sampling (MergeDTS), which first utilizes a divide-and-conquer strategy that localizes the comparisons carried out by the algorithm to small batches of rankers, and then employs Thompson Sampling to reduce the comparisons between suboptimal rankers inside these small batches. The effectiveness (regret) and efficiency (time complexity) of MergeDTS are extensively evaluated using examples from the domain of online evaluation for web search. Our main finding is that for large-scale Condorcet ranker evaluation problems, MergeDTS outperforms the state-of-the-art dueling bandit algorithms.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3085534303",
    "type": "article"
  },
  {
    "title": "The Impacts of Structural Difference and Temporality of Tweets on Retrieval Effectiveness",
    "doi": "https://doi.org/10.1145/2500751",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "Lifeng Jia; Clement Yu; Weiyi Meng",
    "corresponding_authors": "",
    "abstract": "To explore the information seeking behaviors in microblogosphere, the microblog track at TREC 2011 introduced a real-time ad-hoc retrieval task that aims at ranking relevant tweets in reverse-chronological order. We study this problem via a two-phase approach: 1) retrieving tweets in an ad-hoc way; 2) utilizing the temporal information of tweets to enhance the retrieval effectiveness of tweets. Tweets can be categorized into two types. One type consists of short messages not containing any URL of a Web page. The other type has at least one URL of a Web page in addition to a short message. These two types of tweets have different structures. In the first phase, to address the structural difference of tweets, we propose a method to rank tweets using the divide-and-conquer strategy. Specifically, we first rank the two types of tweets separately. This produces two rankings, one for each type. Then we merge these two rankings of tweets into one ranking. In the second phase, we first categorize queries into several types by exploring the temporal distributions of their top-retrieved tweets from the first phase; then we calculate the time-related relevance scores of tweets according to the classified types of queries; finally we combine the time scores with the IR scores from the first phase to produce a ranking of tweets. Experimental results achieved by using the TREC 2011 and TREC 2012 queries over the TREC Tweets2011 collection show that: (i) our way of ranking the two types of tweets separately and then merging them together yields better retrieval effectiveness than ranking them simultaneously; (ii) our way of incorporating temporal information into the retrieval process yields further improvements, and (iii) our method compares favorably with state-of-the-art methods in retrieval effectiveness.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1970779916",
    "type": "article"
  },
  {
    "title": "Embedded video in hypermedia documents",
    "doi": "https://doi.org/10.1145/211430.211439",
    "publication_date": "1995-10-01",
    "publication_year": 1995,
    "authors": "Dick C. A. Bulterman",
    "corresponding_authors": "Dick C. A. Bulterman",
    "abstract": "As the availability of digital video becomes commonplace, a shift in application focus will occur from merely accessing video as an independent data stream to embedding video with other multimedia data types into coordinated hypermedia presentations. The migration to embedded video will present new demands on application and support environments: processing of any one piece of video data will depend on how that data relates to other data streams active within the same presentation. This article describes presentation, synchronization, and interaction control issues for manipulating embedded video. First we describe the requirements for embedded video, contrasted against other forms of video use. Next we consider mechanisms for describing and implementing the behavior of embedded-video segments relative to other data items in a document; these relationships form the basis of implementing cooperative control among the events in a presentation. Finally we consider extending the possibilities for tailoring embedded video to the characteristics of the local runtime environment; this forms the basis for adaptive, application-level quality-of-service control of a presentation. In all cases, we describe a mechanism to externalize the behavior of hypermedia presentations containing resource-intensive data requirements so that effective control can be implemented by low-level system facilities based on application-specific requirements. We present our results in terms of the CMIFed authoring/presentation system.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2000362220",
    "type": "article"
  },
  {
    "title": "Templar",
    "doi": "https://doi.org/10.1145/203052.203061",
    "publication_date": "1995-07-01",
    "publication_year": 1995,
    "authors": "Alexander Tuzhilin",
    "corresponding_authors": "Alexander Tuzhilin",
    "abstract": "A software specification language Templar is defined in this article. The development of the language was guided by the following objectives: requirements specifications written in Templar should have a clear syntax and formal semantics, should be easy for a systems analyst to develop and for an end-user to understand, and it should be easy to map them into a broad range of design specifications. Templar is based on temporal logic and on the Activity-Event-Condition-Activity model of a rule which is an extension of the Event-Condition-Activity model in active databases. The language supports a rich set of modeling primitives, including rules, procedures, temporal logic operators, events, activities, hierarchical decomposition of activities, parallelism, and decisions combined together into a cohesive system.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3121451138",
    "type": "article"
  },
  {
    "title": "Inductive Contextual Relation Learning for Personalization",
    "doi": "https://doi.org/10.1145/3450353",
    "publication_date": "2021-05-25",
    "publication_year": 2021,
    "authors": "Chuxu Zhang; Huaxiu Yao; Lu Yu; Chao Huang; Dongjin Song; Haifeng Chen; Meng Jiang; Nitesh V. Chawla",
    "corresponding_authors": "",
    "abstract": "Web personalization, e.g., recommendation or relevance search, tailoring a service/product to accommodate specific online users, is becoming increasingly important. Inductive personalization aims to infer the relations between existing entities and unseen new ones, e.g., searching relevant authors for new papers or recommending new items to users. This problem, however, is challenging since most of recent studies focus on transductive problem for existing entities. In addition, despite some inductive learning approaches have been introduced recently, their performance is sub-optimal due to relatively simple and inflexible architectures for aggregating entity’s content. To this end, we propose the inductive contextual personalization (ICP) framework through contextual relation learning. Specifically, we first formulate the pairwise relations between entities with a ranking optimization scheme that employs neural aggregator to fuse entity’s heterogeneous contents. Next, we introduce a node embedding term to capture entity’s contextual relations, as a smoothness constraint over the prior ranking objective. Finally, the gradient descent procedure with adaptive negative sampling is employed to learn the model parameters. The learned model is capable of inferring the relations between existing entities and inductive ones. Thorough experiments demonstrate that ICP outperforms numerous baseline methods for two different applications, i.e., relevant author search and new item recommendation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3163957782",
    "type": "article"
  },
  {
    "title": "The Network Visibility Problem",
    "doi": "https://doi.org/10.1145/3460475",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Khashayar Gatmiry; Manuel Gomez-Rodriguez",
    "corresponding_authors": "",
    "abstract": "Social media is an attention economy where broadcasters are constantly competing for attention in their followers’ feeds. Broadcasters are likely to elicit greater attention from their followers if their posts remain visible at the top of their followers’ feeds for a longer period of time. However, this depends on the rate at which their followers receive information in their feeds, which in turn depends on the broadcasters they follow. Motivated by this observation and recent calls for fairness of exposure in social networks, in this article, we look at the task of recommending links from the perspective of visibility optimization. Given a set of candidate links provided by a link recommendation algorithm, our goal is to find a subset of those links that would provide the highest visibility to a set of broadcasters. To this end, we first show that this problem reduces to maximizing a nonsubmodular nondecreasing set function under matroid constraints. Then, we show that the set function satisfies a notion of approximate submodularity that allows the standard greedy algorithm to enjoy theoretical guarantees. Experiments on both synthetic and real data gathered from Twitter show that the greedy algorithm is able to consistently outperform several competitive baselines.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3209408294",
    "type": "article"
  },
  {
    "title": "Truncated Models for Probabilistic Weighted Retrieval",
    "doi": "https://doi.org/10.1145/3476837",
    "publication_date": "2021-12-08",
    "publication_year": 2021,
    "authors": "Jiaul H. Paik; Yash Agrawal; Sahil Rishi; Vaishal Shah",
    "corresponding_authors": "",
    "abstract": "Existing probabilistic retrieval models do not restrict the domain of the random variables that they deal with. In this article, we show that the upper bound of the normalized term frequency ( tf ) from the relevant documents is much smaller than the upper bound of the normalized tf from the whole collection. As a result, the existing models suffer from two major problems: (i) the domain mismatch causes data modeling error, (ii) since the outliers have very large magnitude and the retrieval models follow tf hypothesis, the combination of these two factors tends to overestimate the relevance score. In an attempt to address these problems, we propose novel weighted probabilistic models based on truncated distributions. We evaluate our models on a set of large document collections. Significant performance improvement over six existing probabilistic models is demonstrated.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4200605863",
    "type": "article"
  },
  {
    "title": "Re-Finding Behaviour in Vertical Domains",
    "doi": "https://doi.org/10.1145/2975590",
    "publication_date": "2017-06-05",
    "publication_year": 2017,
    "authors": "Seyedeh Sargol Sadeghi; Roi Blanco; Peter Mika; Mark Sanderson; Falk Scholer; David Vallet",
    "corresponding_authors": "",
    "abstract": "Re-finding is the process of searching for information that a user has previously encountered and is a common activity carried out with information retrieval systems. In this work, we investigate re-finding in the context of vertical search, differentiating and modeling user re-finding behavior within different media and topic domains, including images, news, reference material, and movies. We distinguish the re-finding behavior in vertical domains from re-finding in a general search context and engineer features that are effective in differentiating re-finding across the domains. The features are then used to build machine-learned models, achieving an accuracy of re-finding detection in verticals of 85.7% on average. Our results demonstrate that detecting re-finding in specific verticals is more difficult than examining re-finding for general search tasks. We then investigate the effectiveness of differentiating re-finding behavior in two restricted contexts: We consider the case where the history of a searcher’s interactions with the search system is not available. In this scenario, our features and models achieve an average accuracy of 77.5% across the domains. We then examine the detection of re-finding during the early part of a search session. Both of these restrictions represent potential real-world search scenarios, where a system is attempting to learn about a user but may have limited information available. Finally, we investigate in which types of domains re-finding is most difficult. Here, it would appear that re-finding images is particularly challenging for users. This research has implications for search engine design, in terms of adapting search results by predicting the type of user tasks and potentially enabling the presentation of vertical-specific results when re-finding is identified. To the best of our knowledge, this is the first work to investigate the issue of vertical re-finding.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2622329204",
    "type": "article"
  },
  {
    "title": "GVoS",
    "doi": "https://doi.org/10.1145/3041657",
    "publication_date": "2017-06-05",
    "publication_year": 2017,
    "authors": "Jiawei Jiang; Yunhai Tong; Hua Lu; Bin Cui; Kai Lei; Lele Yu",
    "corresponding_authors": "",
    "abstract": "The exponential increase of online videos greatly enriches the life of users but also brings huge numbers of near-duplicate videos (NDVs) that seriously challenge the video websites. The video websites entail NDV-related applications such as detection of copyright violation, video monitoring, video re-ranking, and video recommendation. Since these applications adopt different features and different processing procedures due to diverse scenarios, constructing separate and special-purpose systems for them incurs considerable costs on design, implementation, and maintenance. In this article, we propose a general NDV system on Storm (GVoS)—a popular distributed real-time stream processing platform—to simultaneously support a wide variety of video applications. The generality of GVoS is achieved in two aspects. First, we extract the reusable components from various applications. Second, we conduct the communication between components via a mechanism called Stream Shared Message (SSM) that contains the video-related data. Furthermore, we present an algorithm to reduce the size of SSM in order to avoid the data explosion and decrease the network latency. The experimental results demonstrate that GVoS can achieve performance almost the same as the customized systems. Meanwhile, GVoS accomplishes remarkably higher systematic versatility and efficiently facilitates the development of various NDV-related applications.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2623813840",
    "type": "article"
  },
  {
    "title": "Jointly Predicting Future Content in Multiple Social Media Sites Based on Multi-task Learning",
    "doi": "https://doi.org/10.1145/3495530",
    "publication_date": "2022-01-11",
    "publication_year": 2022,
    "authors": "Peng Zhang; Baoxi Liu; Tun Lu; Xianghua Ding; Hansu Gu; Ning Gu",
    "corresponding_authors": "",
    "abstract": "User-generated contents (UGC) in social media are the direct expression of users’ interests, preferences, and opinions. User behavior prediction based on UGC has increasingly been investigated in recent years. Compared to learning a person’s behavioral patterns in each social media site separately, jointly predicting user behavior in multiple social media sites and complementing each other (cross-site user behavior prediction) can be more accurate. However, cross-site user behavior prediction based on UGC is a challenging task due to the difficulty of cross-site data sampling, the complexity of UGC modeling, and uncertainty of knowledge sharing among different sites. For these problems, we propose a Cross-Site Multi-Task (CSMT) learning method to jointly predict user behavior in multiple social media sites. CSMT mainly derives from the hierarchical attention network and multi-task learning. Using this method, the UGC in each social media site can obtain fine-grained representations in terms of words, topics, posts, hashtags, and time slices as well as the relevances among them, and prediction tasks in different social media sites can be jointly implemented and complement each other. By utilizing two cross-site datasets sampled from Weibo, Douban, Facebook, and Twitter, we validate our method’s superiority on several classification metrics compared with existing related methods.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4206503466",
    "type": "article"
  },
  {
    "title": "Characterization and Prediction of Mobile Tasks",
    "doi": "https://doi.org/10.1145/3522711",
    "publication_date": "2022-03-30",
    "publication_year": 2022,
    "authors": "Yuan Tian; Ke Zhou; Dan Pelleg",
    "corresponding_authors": "",
    "abstract": "Mobile devices have become an increasingly ubiquitous part of our everyday life. We use mobile services to perform a broad range of tasks (e.g., booking travel or conducting remote office work), leading to often lengthy interactions with several distinct apps and services. Existing mobile systems handle mostly simple user needs, where a single app is taken as the unit of interaction. To understand users’ expectations and to provide context-aware services, it is important to model users’ interactions with their performed task in mind. To provide a comprehensive picture of common mobile tasks, we first conduct a small-scale user study to understand annotated mobile tasks in-depth, while we demonstrate that by using a set of features (temporal, similarity, and log sequence), we can identify if a pair of app usage belong to the same task effectively. Secondly, the proposed best task detection model is applied to a large-scale data set of commercial mobile app usage logs to infer characteristics of complex (multi-app) mobile tasks in the wild. By applying an unsupervised learning framework, we discover common mobile task types that span multiple apps based on various extracted characteristics. We observe that users generally perform 17 common tasks with 47 sub-tasks, ranging from “social media browsing” to “dining out” and “family entertainments”. Finally, we demonstrate that we can predict the next complex mobile task that users are likely to perform by leveraging features from the historically inferred mobile tasks and user contexts. Our work facilitates an in-depth understanding of mobile tasks at scale, enabling applications for promoting task-aware services.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4221028217",
    "type": "article"
  },
  {
    "title": "Reconciling the Quality vs Popularity Dichotomy in Online Cultural Markets",
    "doi": "https://doi.org/10.1145/3530790",
    "publication_date": "2022-04-14",
    "publication_year": 2022,
    "authors": "Rossano Gaeta; Michele Garetto; Giancarlo Ruffo; Alessandro Flammini",
    "corresponding_authors": "",
    "abstract": "We propose a simple model of an idealized online cultural market in which $N$ items, endowed with a hidden quality metric, are recommended to users by a ranking algorithm possibly biased by the current items' popularity. Our goal is to better understand the underlying mechanisms of the well-known fact that popularity bias can prevent higher-quality items from becoming more popular than lower-quality items, producing an undesirable misalignment between quality and popularity rankings. We do so under the assumption that users, having limited time/attention, are able to discriminate the best-quality only within a random subset of the items. We discover the existence of a harmful regime in which improper use of popularity can seriously compromise the emergence of quality, and a benign regime in which wise use of popularity, coupled with a small discrimination effort on behalf of users, guarantees the perfect alignment of quality and popularity ranking. Our findings clarify the effects of algorithmic popularity bias on quality outcomes, and may inform the design of more principled mechanisms for techno-social cultural markets.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4223904976",
    "type": "article"
  },
  {
    "title": "A Stack-Propagation Framework for Low-Resource Personalized Dialogue Generation",
    "doi": "https://doi.org/10.1145/3563389",
    "publication_date": "2022-09-12",
    "publication_year": 2022,
    "authors": "Haoyu Song; Weinan Zhang; Kaiyan Zhang; Ting Liu",
    "corresponding_authors": "",
    "abstract": "With the resurgent interest in building open-domain dialogue systems, the dialogue generation task has attracted increasing attention over the past few years. This task is usually formulated as a conditional generation problem, which aims to generate a natural and meaningful response given dialogue contexts and specific constraints, such as persona. And maintaining a consistent persona is essential for the dialogue systems to gain trust from the users. Although tremendous advancements have been brought, traditional persona-based dialogue models are typically trained by leveraging a large number of persona-dense dialogue examples. Yet, such persona-dense training data are expensive to obtain, leading to a limited scale. This work presents a novel approach to learning from limited training examples by regarding consistency understanding as a regularization of response generation. To this end, we propose a novel stack-propagation framework for learning a generation and understanding pipeline.Specifically, the framework stacks a Transformer encoder and two Transformer decoders, where the first decoder models response generation and the second serves as a regularizer and jointly models response generation and consistency understanding. The proposed framework can benefit from the stacked encoder and decoders to learn from much smaller personalized dialogue data while maintaining competitive performance. Under different low-resource settings, subjective and objective evaluations prove that the stack-propagation framework outperforms strong baselines in response quality and persona consistency and largely overcomes the shortcomings of traditional models that rely heavily on the persona-dense dialogue data.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4295290471",
    "type": "article"
  },
  {
    "title": "Exploring Time-aware Multi-pattern Group Venue Recommendation in LBSNs",
    "doi": "https://doi.org/10.1145/3564280",
    "publication_date": "2022-09-26",
    "publication_year": 2022,
    "authors": "Bi Liang; Xiangwu Meng; Yujie Zhang",
    "corresponding_authors": "",
    "abstract": "Location-based social networks (LBSNs) have become a popular platform for users to share their activities with friends and families, which provide abundant information for us to study issues of group venue recommendation by utilizing the characteristics of check-in data. Although there are some studies on group recommendation for venues, few studies consider the group’s venue preference in different temporal patterns. In this article, we discover that the group’s activity venue has a temporal effect, that is, the group’s preference for the activity venue is different at different times. For example, a couple of lovers prefer to travel to tropical regions in winter and relax in bars in the evening. Based on this discovery, we present a Time-aware Multi-pattern (TaMp) topic model to capture the group’s interest in the activity venue in multiple temporal patterns (including the daily pattern, the weekly pattern, the monthly pattern, and the quarterly pattern). The TaMp model takes into account the topic, members, temporality, and venue information of group activities and the latent relations among them, especially the strong correlation between the activity time and the corresponding activity venue. Then, we propose a group venue recommendation method based on the TaMp model. In addition, an improved grouping algorithm (iGA) in LBSNs is put forward to enhance the rationality of grouping and the accuracy of group venue recommendation. We conduct comprehensive experiments to evaluate the performance of TaMp on two real-world datasets. The results show that our proposed method outperforms the state-of-the-art group venue recommendation and demonstrates the significance of temporal effects in explaining group activities.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4297239169",
    "type": "article"
  },
  {
    "title": "Modeling User Reviews through Bayesian Graph Attention Networks for Recommendation",
    "doi": "https://doi.org/10.1145/3570500",
    "publication_date": "2022-11-09",
    "publication_year": 2022,
    "authors": "Yu Zhao; Qiang Xu; Ying Zou; Wei Li",
    "corresponding_authors": "",
    "abstract": "Recommender systems relieve users from cognitive overloading by predicting preferred items for users. Due to the complexity of interactions between users and items, graph neural networks (GNN) use graph structures to effectively model user–item interactions. However, existing GNN approaches have the following limitations: (1) User reviews are not adequately modeled in graphs. Therefore, user preferences and item properties that are described in user reviews are lost for modeling users and items; and (2) GNNs assume deterministic relations between users and items, which lack the stochastic modeling to estimate the uncertainties in neighbor relations. To mitigate the limitations, we build tripartite graphs to model user reviews as nodes that connect with users and items. We estimate neighbor relations with stochastic variables and propose a Bayesian graph attention network (i.e., ContGraph) to accurately predict user ratings. ContGraph incorporates the prior knowledge of user preferences to regularize the posterior inference of attention weights. Our experimental results show that ContGraph significantly outperforms 13 state-of-the-art models and improves the best performing baseline (i.e., ANR) by 5.23% on 25 datasets in the five-core version. Moreover, we show that correctly modeling the semantics of user reviews in graphs can help express the semantics of users and items.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4308605908",
    "type": "article"
  },
  {
    "title": "Weighting Passages Enhances Accuracy",
    "doi": "https://doi.org/10.1145/3428687",
    "publication_date": "2020-12-17",
    "publication_year": 2020,
    "authors": "Cristina Ioana Muntean; Franco Maria Nardini; Raffaele Perego; Nicola Tonellotto; Ophir Frieder",
    "corresponding_authors": "",
    "abstract": "We observe that in curated documents the distribution of the occurrences of salient terms, e.g., terms with a high Inverse Document Frequency, is not uniform, and such terms are primarily concentrated towards the beginning and the end of the document. Exploiting this observation, we propose a novel version of the classical BM25 weighting model, called BM25 Passage (BM25P), which scores query results by computing a linear combination of term statistics in the different portions of the document. We study a multiplicity of partitioning schemes of document content into passages and compute the collection-dependent weights associated with them on the basis of the distribution of occurrences of salient terms in documents. Moreover, we tune BM25P hyperparameters and investigate their impact on ad hoc document retrieval through fully reproducible experiments conducted using four publicly available datasets. Our findings demonstrate that our BM25P weighting model markedly and consistently outperforms BM25 in terms of effectiveness by up to 17.44% in NDCG@5 and 85% in NDCG@1, and up to 21% in MRR.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3112008364",
    "type": "article"
  },
  {
    "title": "Probabilistic Models for Contextual Agreement in Preferences",
    "doi": "https://doi.org/10.1145/2854147",
    "publication_date": "2016-06-09",
    "publication_year": 2016,
    "authors": "Loc Do; Hady W. Lauw",
    "corresponding_authors": "",
    "abstract": "The long-tail theory for consumer demand implies the need for more accurate personalization technologies to target items to the users who most desire them. A key tenet of personalization is the capacity to model user preferences. Most of the previous work on recommendation and personalization has focused primarily on individual preferences. While some focus on shared preferences between pairs of users, they assume that the same similarity value applies to all items. Here we investigate the notion of “context,” hypothesizing that while two users may agree on their preferences on some items, they may also disagree on other items. To model this, we design probabilistic models for the generation of rating differences between pairs of users across different items. Since this model also involves the estimation of rating differences on unseen items for the purpose of prediction, we further conduct a systematic analysis of matrix factorization and tensor factorization methods in this estimation, and propose a factorization model with a novel objective function of minimizing error in rating differences. Experiments on several real-life rating datasets show that our proposed model consistently yields context-specific similarity values that perform better on a prediction task than models relying on shared preferences.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2414601549",
    "type": "article"
  },
  {
    "title": "TAE Plus: Transportable Applications Environment Plus",
    "doi": "https://doi.org/10.1145/151480.151509",
    "publication_date": "1993-01-02",
    "publication_year": 1993,
    "authors": "Martha R. Szczur; Sylvia B. Sheppard",
    "corresponding_authors": "",
    "abstract": "The Transportable Applications Environment Plus (TAE Plus) is a NASA-developed user interface development environment (UIDE) for the rapid prototyping, evaluation, implementation, and management of user interfaces. TAE Plus provides an intuitive What You See Is What You Get (WYSIWYG) WorkBench for designing an application's user interface. The WorkBench supports the creation and sequencing of displays, including real-time, data-driven display objects. Users can define context-sensitive help for a target application. They can rehearse the user interface and also generate code automatically. In addition TAE Plus contains application services for the runtime manipulation and management of the user interface. Based on Motif and the MIT X Window System, TAE Plus runs on a variety of Unix- or VMS-based workstations. TAE Plus is an evolving system. User-defined requirements and new technology guide the development of each new version. Advances in virtual operating systems, human factors, computer graphics, command language design, standardization, and software portability are monitored and incorporated as they become available.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2065936537",
    "type": "article"
  },
  {
    "title": "An experimental distributed modeling system",
    "doi": "https://doi.org/10.1145/357431.357432",
    "publication_date": "1983-04-01",
    "publication_year": 1983,
    "authors": "Gary J Nutt",
    "corresponding_authors": "Gary J Nutt",
    "abstract": "article Free Access Share on An experimental distributed modeling system Author: Gary J. Nutt NBI, Inc., 1695 38th Street, P.O. Box 9001, Boulder, CO NBI, Inc., 1695 38th Street, P.O. Box 9001, Boulder, COView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 2pp 117–142https://doi.org/10.1145/357431.357432Published:01 April 1983Publication History 5citation502DownloadsMetricsTotal Citations5Total Downloads502Last 12 Months10Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1967906946",
    "type": "article"
  },
  {
    "title": "Office automation projects and their impact on organization, planning, and control",
    "doi": "https://doi.org/10.1145/2275.2277",
    "publication_date": "1984-10-01",
    "publication_year": 1984,
    "authors": "Charles E. Paddock; Richard W. Scamell",
    "corresponding_authors": "",
    "abstract": "article Free AccessOffice automation projects and their impact on organization, planning, and control Authors: Charles E. Paddock Arizona State Univ., Tempe Arizona State Univ., TempeView Profile , Richard W. Scamell Univ. of Houston, Houston, TX Univ. of Houston, Houston, TXView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 4Oct. 1984 pp 289–302https://doi.org/10.1145/2275.2277Published:01 October 1984Publication History 1citation988DownloadsMetricsTotal Citations1Total Downloads988Last 12 Months33Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1981595884",
    "type": "article"
  },
  {
    "title": "Projecting demand for electronic communications in automated offices",
    "doi": "https://doi.org/10.1145/357436.357438",
    "publication_date": "1983-07-01",
    "publication_year": 1983,
    "authors": "Stephen A. Smith; Robert I. Benjamin",
    "corresponding_authors": "",
    "abstract": "article Free AccessProjecting demand for electronic communications in automated offices Authors: Stephen A. Smith Department of Decision and Information Sciences, University of Santa Clara, Santa Clara, CA Department of Decision and Information Sciences, University of Santa Clara, Santa Clara, CAView Profile , Robert I. Benjamin Xerox Corporate Information Management, Rochester, NY Xerox Corporate Information Management, Rochester, NYView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 1Issue 3July 1983 pp 211–229https://doi.org/10.1145/357436.357438Published:01 July 1983Publication History 6citation1,533DownloadsMetricsTotal Citations6Total Downloads1,533Last 12 Months9Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1985107673",
    "type": "article"
  },
  {
    "title": "DITROFF/FFORTID, an adaptation of the UNIX/DITROFF for formatting bidirectional text",
    "doi": "https://doi.org/10.1145/4656.4658",
    "publication_date": "1985-10-01",
    "publication_year": 1985,
    "authors": "Cary Buchman; Daniel M. Berry; Jakob Gonczarowski",
    "corresponding_authors": "",
    "abstract": "DITROFF/FFORTID , a collection of pre- and postprocessors for the UNIX DITROFF (Device Independent Typesetter RunOFF) is described. DITROFF/FFORTID permits formatting of text involving a mixture of languages written from left to right and from right to left, such as English and Hebrew. The programs are table driven or macro-generated to permit them to be used for any languages written from left to right and from right to left so long as fonts with the proper character sets can be mounted on a typesetting device supported by DITROFF . The preprocessors are set up to permit phonetic, unidirectional input of all of the alphabets needed using only the two alphabets (each case counts as an alphabet) available on the input device. These macro-generated preprocessors can be adjusted to the user's pronunciation, the language's rules about a letter's form, depending on its position in the word, and the language of the user's input keyboard. The postprocessor is set up to properly change direction of formatting when the text switches to a language written in a different direction. The collection of programs is also designed to allow use of any of DITROFF 's preprocessors, such as PIC , EQN , TBL , and the various device drivers.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2058300571",
    "type": "article"
  },
  {
    "title": "Transportability to other languages: the natural language processing project in the AI program at MCC",
    "doi": "https://doi.org/10.1145/3914.3981",
    "publication_date": "1985-04-01",
    "publication_year": 1985,
    "authors": "Jonathan Slocum; Carol F. Justus",
    "corresponding_authors": "",
    "abstract": "We discuss a recently launched, long-term project in natural language processing, the primary concern of which is that natural language applications be transportable among human languages. In particular, we seek to develop system tools and linguistic processing techniques that are themselves language-independent to the maximum extent practical. In this paper we discuss our project goals and outline our intended approach, address some cross-linguistic requirements, and then present some new linguistic data that we feel support our approach.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2071911819",
    "type": "article"
  },
  {
    "title": "Dependable filtering",
    "doi": "https://doi.org/10.1145/1877766.1877771",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "Matteo Dell’Amico; Licia Capra",
    "corresponding_authors": "",
    "abstract": "Digital content production and distribution has radically changed our business models. An unprecedented volume of supply is now on offer, whetted by the demand of millions of users from all over the world. Since users cannot be expected to browse through millions of different items to find what they might like, filtering has become a popular technique to connect supply and demand: trusted users are first identified, and their opinions are then used to create recommendations. In this domain, users' trustworthiness has been measured according to one of the following two criteria: taste similarity (i.e., “I trust those who agree with me”), or social ties (i.e., “I trust my friends, and the people that my friends trust”). The former criterion aims at identifying concordant users, but is subject to abuse by malicious behaviors. The latter aims at detecting well-intentioned users, but fails to capture the natural subjectivity of tastes. In this article, we propose a new definition of trusted recommenders , addressing those users that are both well-intentioned and concordant. Based on this characterisation, we propose a novel approach to information filtering that we call dependable filtering . We describe alternative algorithms realizing this approach, and demonstrate, by means of extensive performance evaluation on a variety of real large-scale datasets, the high degree of both accuracy and robustness they entail.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2035070322",
    "type": "article"
  },
  {
    "title": "Special issue on searching speech",
    "doi": "https://doi.org/10.1145/2328967.2328968",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "Martha Larson; Franciska de Jong; Wessel Kraaij; Steve Renals",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2100620303",
    "type": "article"
  },
  {
    "title": "EmbeddedButtons",
    "doi": "https://doi.org/10.1145/146486.146547",
    "publication_date": "1992-10-01",
    "publication_year": 1992,
    "authors": "Eric A. Bier",
    "corresponding_authors": "Eric A. Bier",
    "abstract": "EmbeddedButtons is a library of routines and a runtime kernel that support the integration of buttons into document media, including text and graphics. Existing document editors can be modified to participate in this open architecture with the addition of a few simple routines. Unlike many button systems that insert special button objects into document media, this system supports turning existing document objects into buttons . As a consequence, buttons inherit all of the attributes of normal document objects, and the appearance of buttons can be edited using operations already familiar to users. Facilities are provided for linking buttons to application windows so that documents can serve as application control panels. Hence, user interface designers can lay out control panels using familiar document editors rather than special-purpose tools. Three classes of buttons have been implemented, including buttons that pop up a menu and buttons that store and display the value of a variable. New button classes, editors, and applications can be added at run time. Two editors, one for text and one for graphics, currently participate in the architecture.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2068873840",
    "type": "article"
  },
  {
    "title": "Productivity trends in certain office-intensive sectors of the U.S. Federal Government",
    "doi": "https://doi.org/10.1145/4656.214329",
    "publication_date": "1985-10-01",
    "publication_year": 1985,
    "authors": "Raymond R. Panko",
    "corresponding_authors": "Raymond R. Panko",
    "abstract": "It is often said that office productivity is virtually stagnant, increasing only about 4 percent every 10 years. The methodology used to estimate this 4 percent figure is examined and found to be inaccurate! There is no known way to estimate overall national office productivity trends. Productivity trends in a single part of the economy, however, can be examined, namely, office-intensive sectors of the U.S. federal government. Productivity in these sectors is found to be anything but stagnant, having increased 1.7 percent annually from 1967 to 1981 and 3.0 percent annually from 1977 through 1981.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2008336076",
    "type": "article"
  },
  {
    "title": "Ensuring court admissibility of computer-generated records",
    "doi": "https://doi.org/10.1145/4656.4659",
    "publication_date": "1985-10-01",
    "publication_year": 1985,
    "authors": "Roger King; Carolyn Stanley",
    "corresponding_authors": "",
    "abstract": "An informal methodology is described for optimizing the likelihood of computer-generated records being admissible in a U.S. court of law. This methodology is intended for individuals who are converting to automated office procedures, as well as for those whose businesses are already highly computerized. However, this paper does not purport to be a formal legal guide; rather, it is intended as an overview of this issue.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2035232155",
    "type": "article"
  },
  {
    "title": "An imperative sentence processor for voice interactive office applications",
    "doi": "https://doi.org/10.1145/4656.4660",
    "publication_date": "1985-10-01",
    "publication_year": 1985,
    "authors": "Alan W. Biermann; Linda S. Fineman; Kermit C. Gilbert",
    "corresponding_authors": "",
    "abstract": "An imperative sentence processor that enables a user to manipulate text with connected speech and touch-graphics input is described. The processor includes capabilities to follow dialogue focus, execute a variety of imperative commands, and handle nested noun groups, pronouns, and other phenomena. A micromodel of the system, giving enough of the structure to enable the reader to observe internal mechanisms in considerable detail, is included. This processor is designed to be transportable to a number of other office automation domains such as calendar management, message-passing, and desk calculation. Various examples and statistics related to its behavior in the text manipulation application are given. The system has been implemented in PASCAL and can run on any machine that supports this language.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2092564561",
    "type": "article"
  },
  {
    "title": "A Decision Procedure for XPath Containment",
    "doi": null,
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Pierre Genevès; Nabil Layaïda",
    "corresponding_authors": "",
    "abstract": "XPath is the standard language for addressing parts of an XML document. We present a sound and complete decision procedure for containment of XPath queries. The considered XPath fragment covers most of the language features used in practice. Specifically, we show how XPath queries can be translated into equivalent formulas in monadic second-order logic. Using this translation, we construct an optimized logical formulation of the containment problem, which is decided using tree automata. When the containment relation does not hold between two XPath expressions, a counter-example XML tree is generated. We provide a complexity analysis together with practical experiments that illustrate the efficiency of the decision procedure for realistic scenarios.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1904537309",
    "type": "article"
  },
  {
    "title": "User Profiling Based on Nonlinguistic Audio Data",
    "doi": "https://doi.org/10.1145/3474826",
    "publication_date": "2021-09-08",
    "publication_year": 2021,
    "authors": "Jiaxing Shen; Jiannong Cao; Oren Lederman; Shaojie Tang; Alex Pentland",
    "corresponding_authors": "",
    "abstract": "User profiling refers to inferring people’s attributes of interest ( AoIs ) like gender and occupation, which enables various applications ranging from personalized services to collective analyses. Massive nonlinguistic audio data brings a novel opportunity for user profiling due to the prevalence of studying spontaneous face-to-face communication. Nonlinguistic audio is coarse-grained audio data without linguistic content. It is collected due to privacy concerns in private situations like doctor-patient dialogues. The opportunity facilitates optimized organizational management and personalized healthcare, especially for chronic diseases. In this article, we are the first to build a user profiling system to infer gender and personality based on nonlinguistic audio. Instead of linguistic or acoustic features that are unable to extract, we focus on conversational features that could reflect AoIs. We firstly develop an adaptive voice activity detection algorithm that could address individual differences in voice and false-positive voice activities caused by people nearby. Secondly, we propose a gender-assisted multi-task learning method to combat dynamics in human behavior by integrating gender differences and the correlation of personality traits. According to the experimental evaluation of 100 people in 273 meetings, we achieved 0.759 and 0.652 in F1-score for gender identification and personality recognition, respectively.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3198746254",
    "type": "article"
  },
  {
    "title": "Interpretable Aspect-Aware Capsule Network for Peer Review Based Citation Count Prediction",
    "doi": "https://doi.org/10.1145/3466640",
    "publication_date": "2021-11-24",
    "publication_year": 2021,
    "authors": "Siqing Li; Yaliang Li; Wayne Xin Zhao; Bolin Ding; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Citation count prediction is an important task for estimating the future impact of research papers. Most of the existing works utilize the information extracted from the paper itself. In this article, we focus on how to utilize another kind of useful data signal (i.e., peer review text) to improve both the performance and interpretability of the prediction models. Specially, we propose a novel aspect-aware capsule network for citation count prediction based on review text. It contains two major capsule layers, namely the feature capsule layer and the aspect capsule layer, with two different routing approaches, respectively. Feature capsules encode the local semantics from review sentences as the input of aspect capsule layer, whereas aspect capsules aim to capture high-level semantic features that will be served as final representations for prediction. Besides the predictive capacity, we also enhance the model interpretability with two strategies. First, we use the topic distribution of the review text to guide the learning of aspect capsules so that each aspect capsule can represent a specific aspect in the review. Then, we use the learned aspect capsules to generate readable text for explaining the predicted citation count. Extensive experiments on two real-world datasets have demonstrated the effectiveness of the proposed model in both performance and interpretability.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3215915038",
    "type": "article"
  },
  {
    "title": "Grounded Task Prioritization with Context-Aware Sequential Ranking",
    "doi": "https://doi.org/10.1145/3486861",
    "publication_date": "2021-12-08",
    "publication_year": 2021,
    "authors": "Chuxu Zhang; Julia Kiseleva; Sunil Kumar Jauhar; Ryen W. White",
    "corresponding_authors": "",
    "abstract": "People rely on task management applications and digital assistants to capture and track their tasks, and help with executing them. The burden of organizing and scheduling time for tasks continues to reside with users of these systems, despite the high cognitive load associated with these activities. Users stand to benefit greatly from a task management system capable of prioritizing their pending tasks, thus saving them time and effort. In this article, we make three main contributions. First, we propose the problem of task prioritization, formulating it as a ranking over a user’s pending tasks given a history of previous interactions with a task management system. Second, we perform an extensive analysis on the large-scale anonymized, de-identified logs of a popular task management application, deriving a dataset of grounded, real-world tasks from which to learn and evaluate our proposed system. We also identify patterns in how people record tasks as complete, which vary consistently with the nature of the task. Third, we propose a novel contextual deep learning solution capable of performing personalized task prioritization. In a battery of tests, we show that this approach outperforms several operational baselines and other sequential ranking models from previous work. Our findings have implications for understanding the ways people prioritize and manage tasks with digital tools, and in the design of support for users of task management applications.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4200046588",
    "type": "article"
  },
  {
    "title": "Inverted Treaps",
    "doi": "https://doi.org/10.1145/3007186",
    "publication_date": "2017-01-04",
    "publication_year": 2017,
    "authors": "Roberto Konow; Gonzalo Navarro; Charles L. A. Clarke; Alejandro López-Ortíz",
    "corresponding_authors": "",
    "abstract": "We introduce a new representation of the inverted index that performs faster ranked unions and intersections while using similar space. Our index is based on the treap data structure, which allows us to intersect/merge the document identifiers while simultaneously thresholding by frequency, instead of the costlier two-step classical processing methods. To achieve compression, we represent the treap topology using different alternative compact data structures. Further, the treap invariants allow us to elegantly encode differentially both document identifiers and frequencies. We also show how to extend this representation to support incremental updates over the index. Results show that, under the tf-idf scoring scheme, our index uses about the same space as state-of-the-art compact representations, while performing up to 2--20 times faster on ranked single-word, union, or intersection queries. Under the BM25 scoring scheme, our index may use up to 40% more space than the others and outperforms them less frequently but still reaches improvement factors of 2--20 in the best cases. The index supporting incremental updates poses an overhead of 50%--100% over the static variants in terms of space, construction, and query time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2585936885",
    "type": "article"
  },
  {
    "title": "アラビア語のwhy‐質問の回答:ベースライン対RSTベースアプローチ",
    "doi": null,
    "publication_date": "2017-01-01",
    "publication_year": 2017,
    "authors": "Mounaim Aqil; A Alshenaifi Nouf",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2772903034",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1462198",
    "publication_date": "2009-02-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In spite of its tremendous value, metadata is generally sparse and incomplete, thereby hampering the effectiveness of digital information services. Many of the existing mechanisms for the automated creation of metadata rely primarily on content analysis ...",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4231915696",
    "type": "paratext"
  },
  {
    "title": "Evaluation of an algorithm for finding a match of a distorted texture pattern in a large image database",
    "doi": "https://doi.org/10.1145/267954.267956",
    "publication_date": "1998-01-01",
    "publication_year": 1998,
    "authors": "N. Vujovic; D. Brzaković",
    "corresponding_authors": "",
    "abstract": "Evaluation of an algorithm for finding a match for a random texture pattern in a large image database is presented. The algorithm was designed assuming that the random pattern may be subject to misregistration relative to its representation in the database and assuming that it may have missing parts. The potential applications involve authentication of legal documents, bank notes, or credit cards, where thin fibers are embedded randomly into the document medium during medium fabrication. The algorithm achieves image matching by a three-step hierarchical procedure, which starts by matching parts of fiber patterns while solving the misregistration problem and ends up by matching complete fiber patterns. Performance of the algorithm is studied both theoretically and experimentally. Theoretical analysis includes the study of the probability that two documents have the same pattern, and the probability of the algorithm establishing a wrong match, as well as the algorithm's performance in terms of processing time. Experiments involving over 250,000 trials using databases of synthetic documents, containing up to 100,000 documents, were used to confirm theoretical predictions. In addition, experiments involving a database containing real images were conducted in order to confirm that the algorithm has potential in real applications.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2084134550",
    "type": "article"
  },
  {
    "title": "Partitioned Signature File: Design Considerations and Performance Evaluation",
    "doi": null,
    "publication_date": "1989-01-01",
    "publication_year": 1989,
    "authors": "Dik Lun Lee; Chun-Wu Roger Leng",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2590023349",
    "type": "article"
  },
  {
    "title": "Learning Semantic Representations from Directed Social Links to Tag Microblog Users at Scale",
    "doi": "https://doi.org/10.1145/3377550",
    "publication_date": "2020-03-07",
    "publication_year": 2020,
    "authors": "Wayne Xin Zhao; Yupeng Hou; Junhua Chen; Jonathan J. H. Zhu; Eddy Jing Yin; Hanting Su; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "This article presents a network embedding approach to automatically generate tags for microblog users. Instead of using text data, we aim to annotate microblog users with meaningful tags by leveraging rich social link data. To utilize directed social links, we use two kinds of node representations for modeling user interest in terms of their followers and followees, respectively. To alleviate the sparsity problem, we propose a novel method based on two transformation functions for capturing implicit interest similarity. Different from previous works on capturing high-order proximity, our model is able to directly characterize the effect of the context user on the proximity of node pairs. Another novelty of our model is that the importance scores of users learned from the classic PageRank algorithm are utilized to set the link weights. By using such weights, our model is more capable of disentangling the interest similarity evidence of a link. We jointly consider the above factors when designing the final objective function. We construct a very large evaluation set consisting of 2.6M users, 0.5M tags, and 0.8B following links. To our knowledge, it is the largest reported dataset for microblog user tagging in the literature. Extensive experiments on this dataset demonstrate the effectiveness of the proposed approach. We implement this approach with several optimization techniques, which makes our model easy to scale to very large social networks. Ubiquitous social links provide important data resources to understand user interests. Our work provides an effective and efficient solution to annotate user interests solely using the link data, which has important practical value in industry. To illustrate the use of our models, we implement a demonstration system for visualizing, navigating, and searching microblog users.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3010283557",
    "type": "article"
  },
  {
    "title": "Dual Preference Distribution Learning for Item Recommendation",
    "doi": "https://doi.org/10.1145/3565798",
    "publication_date": "2022-10-10",
    "publication_year": 2022,
    "authors": "Xue Dong; Xuemeng Song; Na Zheng; Yinwei Wei; Zhongzhou Zhao",
    "corresponding_authors": "",
    "abstract": "Recommender systems can automatically recommend users with items that they probably like. The goal of them is to model the user-item interaction by effectively representing the users and items. Existing methods have primarily learned the user's preferences and item's features with vectorized embeddings, and modeled the user's general preferences to items by the interaction of them. In fact, users have their specific preferences to item attributes and different preferences are usually related. Therefore, exploring the fine-grained preferences as well as modeling the relationships among user's different preferences could improve the recommendation performance. Toward this end, we propose a dual preference distribution learning framework (DUPLE), which aims to jointly learn a general preference distribution and a specific preference distribution for a given user, where the former corresponds to the user's general preference to items and the latter refers to the user's specific preference to item attributes. Notably, the mean vector of each Gaussian distribution can capture the user's preferences, and the covariance matrix can learn their relationship. Moreover, we can summarize a preferred attribute profile for each user, depicting his/her preferred item attributes. We then can provide the explanation for each recommended item by checking the overlap between its attributes and the user's preferred attribute profile. Extensive quantitative and qualitative experiments on six public datasets demonstrate the effectiveness and explainability of the DUPLE method.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4221146647",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2891107",
    "publication_date": "2016-04-20",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Interpersonal ties are responsible for the structure of social networks and the transmission of information through these networks. Different types of social ties have essentially different influences on people. Awareness of the types of social ties can ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4236356036",
    "type": "paratext"
  },
  {
    "title": "On the Ordering of Pooled Web Pages, Gold Assessments, and Bronze Assessments",
    "doi": "https://doi.org/10.1145/3600227",
    "publication_date": "2023-05-27",
    "publication_year": 2023,
    "authors": "Tetsuya Sakai; Sijie Tao; Nuo Chen; Yujing Li; Maria Maistro; Zhumin Chu; Nicola Ferro",
    "corresponding_authors": "",
    "abstract": "The present study leverages a recent opportunity we had to create a new English web search test collection for the NTCIR-16 We Want Web (WWW-4) task, which concluded in June 2022. More specifically, through the test collection construction effort, we examined two factors that may affect the relevance assessments of depth- k pools, which in turn may affect the relative evaluation of different IR systems. The first factor is the document ordering strategy for the assessors, namely, prioritisation (PRI) and randomisation (RND). PRI is a method that has been used in NTCIR tasks for over a decade; it ranks the pooled documents by a kind of pseudorelevance for the assessors. The second factor is assessor type, i.e., Gold or Bronze. Gold assessors are the topic creators and therefore they “know” which documents are (highly) relevant and which are not; Bronze assessors are not the topic creators and may lack sufficient knowledge about the topics. We believe that our study is unique in that the authors of this article served as the Gold assessors when creating the WWW-4 test collection, which enabled us to closely examine why Bronze assessments differ from the Gold ones. Our research questions examine assessor efficiency ( RQ1 ), inter-assessor agreement ( RQ2 ), system ranking similarity with different qrels files ( RQ3 ), system ranking robustness to the choice of test topics ( RQ4 ), and the reasons why Bronze assessors tend to be more liberal than Gold assessors ( RQ5 ). The most remarkable of our results are as follows: First, in the comparisons for RQ1 through RQ4 , it turned out that what may matter more than the document ordering strategy (PRI vs. RND) and the assessor type (Gold vs. Bronze) is how well-motivated and/or well-trained the Bronze assessors are. Second, regarding RQ5 , of the documents originally judged nonrelevant by the Gold assessors contrary to the Bronze assessors in our experiments, almost one half were truly relevant according to the Gold assessors’ own reconsiderations. This result suggests that even Gold assessors are far from perfect; budget permitting, it may be beneficial to hire highly motivated Bronze assessors in addition to Gold assessors so they can complement each other.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4378549003",
    "type": "article"
  },
  {
    "title": "Decoupled Progressive Distillation for Sequential Prediction with Interaction Dynamics",
    "doi": "https://doi.org/10.1145/3632403",
    "publication_date": "2023-11-09",
    "publication_year": 2023,
    "authors": "Kaixi Hu; Lin Li; Qing Xie; Jianquan Liu; Xiaohui Tao; Guandong Xu",
    "corresponding_authors": "",
    "abstract": "Sequential prediction has great value for resource allocation due to its capability in analyzing intents for next prediction. A fundamental challenge arises from real-world interaction dynamics where similar sequences involving multiple intents may exhibit different next items. More importantly, the character of volume candidate items in sequential prediction may amplify such dynamics, making deep networks hard to capture comprehensive intents. This article presents a sequential prediction framework with Decoupled Progressive Distillation (DePoD), drawing on the progressive nature of human cognition. We redefine target and non-target item distillation according to their different effects in the decoupled formulation. This can be achieved through two aspects: (1) Regarding how to learn, our target item distillation with progressive difficulty increases the contribution of low-confidence samples in the later training phase while keeping high-confidence samples in the earlier phase. And, the non-target item distillation starts from a small subset of non-target items from which size increases according to the item frequency. (2) Regarding whom to learn from, a difference evaluator is utilized to progressively select an expert that provides informative knowledge among items from the cohort of peers. Extensive experiments on four public datasets show DePoD outperforms state-of-the-art methods in terms of accuracy-based metrics.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4388530342",
    "type": "article"
  },
  {
    "title": "Personalized and Diversified: Ranking Search Results in an Integrated Way",
    "doi": "https://doi.org/10.1145/3631989",
    "publication_date": "2023-11-09",
    "publication_year": 2023,
    "authors": "Shuting Wang; Zhicheng Dou; Jiongnan Liu; Qiannan Zhu; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Ambiguity in queries is a common problem in information retrieval. There are currently two solutions: Search result personalization and diversification. The former aims to tailor results for different users based on their preferences, but the limitations are redundant results and incomplete capture of user intents. The goal of the latter is to return results that cover as many aspects related to the query as possible. It improves diversity yet loses personality and cannot return the exact results the user wants. Intuitively, such two solutions can complement each other and bring more satisfactory reranking results. In this paper, we propose a novel framework, namely PnD to integrate personalization and diversification reasonably. We employ the degree of refinding to determine the weight of personalization dynamically. Moreover, to improve the diversity and relevance of reranked results simultaneously, we design a reset RNN structure (RRNN) with the “reset gate” to measure the influence of the newly selected document on novelty. Besides, we devise a “subtopic learning layer” to learn the virtual subtopics, which can yield fine-grained representations of queries, documents, and user profiles. Experimental results illustrate that our model can significantly outperform existing search result personalization and diversification methods.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4388539203",
    "type": "article"
  },
  {
    "title": "Contextualizing and Expanding Conversational Queries without Supervision",
    "doi": "https://doi.org/10.1145/3632622",
    "publication_date": "2023-11-17",
    "publication_year": 2023,
    "authors": "Antonios Minas Krasakis; Andrew Yates; Evangelos Kanoulas",
    "corresponding_authors": "",
    "abstract": "Most conversational passage retrieval systems try to resolve conversational dependencies by using an intermediate query resolution step. To do so, they synthesize conversational data or assume the availability of large-scale question rewriting datasets. To relax those conditions, we propose a zero-shot unified resolution–retrieval approach, that (i) contextualizes and (ii) expands query embeddings using the conversation history and without fine-tuning on conversational data. Contextualization biases the last user question embeddings towards the conversation. Query expansion is used in two ways: (i) abstractive expansion generates embeddings based on the current question and previous history, whereas (ii) extractive expansion tries to identify history term embeddings based on attention weights from the retriever. Our experiments demonstrate the effectiveness of both contextualization and unified expansion in improving conversational retrieval. Contextualization does so mostly by resolving anaphoras to the conversation and bringing their embeddings closer to the important resolution terms that were omitted. By adding embeddings to the query, expansion targets phenomena of ellipsis more explicitly, with our analysis verifying its effectiveness on identifying and adding important resolutions to the query. By combining contextualization and expansion, we find that our zero-shot unified resolution–retrieval methods are competitive and can even outperform supervised methods.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4388763343",
    "type": "article"
  },
  {
    "title": "Understanding or Manipulation: Rethinking Online Performance Gains of Modern Recommender Systems",
    "doi": "https://doi.org/10.1145/3637869",
    "publication_date": "2023-12-16",
    "publication_year": 2023,
    "authors": "Zhengbang Zhu; Rongjun Qin; Junjie Huang; Xinyi Dai; Yang Yu; Yong Yu; Weinan Zhang",
    "corresponding_authors": "",
    "abstract": "Recommender systems are expected to be assistants that help human users find relevant information automatically without explicit queries. As recommender systems evolve, increasingly sophisticated learning techniques are applied and have achieved better performance in terms of user engagement metrics such as clicks and browsing time. The increase in the measured performance, however, can have two possible attributions: a better understanding of user preferences, and a more proactive ability to utilize human bounded rationality to seduce user over-consumption. A natural following question is whether current recommendation algorithms are manipulating user preferences. If so, can we measure the manipulation level? In this article, we present a general framework for benchmarking the degree of manipulations of recommendation algorithms, in both slate recommendation and sequential recommendation scenarios. The framework consists of four stages, initial preference calculation, training data collection, algorithm training and interaction, and metrics calculation that involves two proposed metrics, Manipulation Score and Preference Shift. We benchmark some representative recommendation algorithms in both synthetic and real-world datasets under the proposed framework. We have observed that a high online click-through rate does not necessarily mean a better understanding of user initial preference, but ends in prompting users to choose more documents they initially did not favor. Moreover, we find that the training data have notable impacts on the manipulation degrees, and algorithms with more powerful modeling abilities are more sensitive to such impacts. The experiments also verified the usefulness of the proposed metrics for measuring the degree of manipulations. We advocate that future recommendation algorithm studies should be treated as an optimization problem with constrained user preference manipulations.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4389832989",
    "type": "article"
  },
  {
    "title": "XMovie",
    "doi": "https://doi.org/10.1145/211430.211440",
    "publication_date": "1995-10-01",
    "publication_year": 1995,
    "authors": "Ralf Keller; Wolfgang Effelsberg; Bernd Lamparter",
    "corresponding_authors": "",
    "abstract": "We describe a system for storing, transmitting, and presenting digital movies in a computer network. The hardware used in the system is standard hardware, as found in typical workstations today; no special hardware is required, but if available it can be used to provide better performance. The XMovie system has several innovative features. First, it contains a new algorithm for the gradual adaptation of the color lookup table during the presentation of the movie to ensure optimal color quality on low-end workstations. Second, it is a multistandard system supporting the compression techniques MPEG, Motion JPEG, and a newly developed extension to the well-known Color Cell Compression method. Third, it contains AdFEC, a new adaptable forward error correction method for our movie transmission protocol.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1979952949",
    "type": "article"
  },
  {
    "title": "The COSIE communications subsystem",
    "doi": "https://doi.org/10.1145/521.357414",
    "publication_date": "1984-05-24",
    "publication_year": 1984,
    "authors": "Douglas B. Terry; Sten F. Andler",
    "corresponding_authors": "",
    "abstract": "article Free Access Share on The COSIE communications subsystem: support for distributed office applications Authors: Douglas B. Terry Computer Science Div., EECS Dept., University of California, Berkley, CA Computer Science Div., EECS Dept., University of California, Berkley, CAView Profile , Sten Andler IBM Research Laboratory, 5600 Cottle Road, San Jose, CA IBM Research Laboratory, 5600 Cottle Road, San Jose, CAView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 2April 1984 pp 79–95https://doi.org/10.1145/521.357414Published:24 May 1984Publication History 3citation330DownloadsMetricsTotal Citations3Total Downloads330Last 12 Months8Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2043799474",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2094072",
    "publication_date": "2012-02-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The inverted index supports efficient full-text searches on natural language text collections. It requires some extra space over the compressed text that can be traded for search speed. It is usually fast for single-word searches, yet phrase searches ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4254132272",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1961209",
    "publication_date": "2011-04-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4255904075",
    "type": "paratext"
  },
  {
    "title": "ITS and user interface consistency",
    "doi": "https://doi.org/10.1145/128756.128761",
    "publication_date": "1992-01-02",
    "publication_year": 1992,
    "authors": "Charles Wiecha",
    "corresponding_authors": "Charles Wiecha",
    "abstract": "article Free Access Share on ITS and user interface consistency: a response to Grudin Author: Charles Wiecha IBM T. J. Watson Research Center IBM T. J. Watson Research CenterView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 10Issue 102 January 1992pp 112–114https://doi.org/10.1145/128756.128761Published:02 January 1992Publication History 2citation352DownloadsMetricsTotal Citations2Total Downloads352Last 12 Months6Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2038616044",
    "type": "article"
  },
  {
    "title": "Multi-Response Awareness for Retrieval-Based Conversations: Respond with Diversity via Dynamic Representation Learning",
    "doi": "https://doi.org/10.1145/3470450",
    "publication_date": "2021-09-20",
    "publication_year": 2021,
    "authors": "Rui Yan; Weiheng Liao; Dongyan Zhao; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Conversational systems now attract great attention due to their promising potential and commercial values. To build a conversational system with moderate intelligence is challenging and requires big (conversational) data, as well as interdisciplinary techniques. Thanks to the prosperity of the Web, the massive data available greatly facilitate data-driven methods such as deep learning for human-computer conversational systems. In general, retrieval-based conversational systems apply various matching schema between query utterances and responses, but the classic retrieval paradigm suffers from prominent weakness for conversations: the system finds similar responses given a particular query. For real human-to-human conversations, on the contrary, responses can be greatly different yet all are possibly appropriate. The observation reveals the diversity phenomenon in conversations. In this article, we ascribe the lack of conversational diversity to the reason that the query utterances are statically modeled regardless of candidate responses through traditional methods. To this end, we propose a dynamic representation learning strategy that models the query utterances and different response candidates in an interactive way. To be more specific, we propose a Respond-with-Diversity model augmented by the memory module interacting with both the query utterances and multiple candidate responses. Hence, we obtain dynamic representations for the input queries conditioned on different response candidates. We frame the model as an end-to-end learnable neural network. In the experiments, we demonstrate the effectiveness of the proposed model by achieving a good appropriateness score and much better diversity in retrieval-based conversations between humans and computers.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3199940397",
    "type": "article"
  },
  {
    "title": "Graph Technologies for User Modeling and Recommendation: Introduction to the Special Issue - Part 1",
    "doi": "https://doi.org/10.1145/3477596",
    "publication_date": "2021-09-27",
    "publication_year": 2021,
    "authors": "Xiangnan He; Zhaochun Ren; Emine Yilmaz; Marc Najork; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "introduction Share on Graph Technologies for User Modeling and Recommendation: Introduction to the Special Issue - Part 1 Authors: Xiangnan He University of Science and Technology of China, He Fei, China University of Science and Technology of China, He Fei, ChinaSearch about this author , Zhaochun Ren Shandong University, Qingdao, China Shandong University, Qingdao, ChinaSearch about this author , Emine Yilmaz University College London, United Kingdom University College London, United KingdomSearch about this author , Marc Najork Google Research, Mountain View, CA, United States Google Research, Mountain View, CA, United StatesSearch about this author , Tat-Seng Chua National University of Singapore, Republic of Singapore, Singapore National University of Singapore, Republic of Singapore, SingaporeSearch about this author Authors Info & Claims ACM Transactions on Information SystemsVolume 40Issue 2April 2022 Article No.: 21pp 1–5https://doi.org/10.1145/3477596Online:27 September 2021Publication History 0citation282DownloadsMetricsTotal Citations0Total Downloads282Last 12 Months282Last 6 weeks7 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3204674592",
    "type": "article"
  },
  {
    "title": "Beyond Relevance Ranking: A General Graph Matching Framework for Utility-Oriented Learning to Rank",
    "doi": "https://doi.org/10.1145/3464303",
    "publication_date": "2021-11-16",
    "publication_year": 2021,
    "authors": "Xinyi Dai; Yunjia Xi; Weinan Zhang; Qing Liu; Ruiming Tang; Xiuqiang He; Jiawei Hou; Jun Wang; Yong Yu",
    "corresponding_authors": "",
    "abstract": "Learning to rank from logged user feedback, such as clicks or purchases, is a central component of many real-world information systems. Different from human-annotated relevance labels, the user feedback is always noisy and biased. Many existing learning to rank methods infer the underlying relevance of query–item pairs based on different assumptions of examination, and still optimize a relevance based objective. Such methods rely heavily on the correct estimation of examination, which is often difficult to achieve in practice. In this work, we propose a general framework U-rank+ for learning to rank with logged user feedback from the perspective of graph matching. We systematically analyze the biases in user feedback, including examination bias and selection bias. Then, we take both biases into consideration for unbiased utility estimation that directly based on user feedback, instead of relevance. In order to maximize the estimated utility in an efficient manner, we design two different solvers based on Sinkhorn and LambdaLoss for U-rank+ . The former is based on a standard graph matching algorithm, and the latter is inspired by the traditional method of learning to rank. Both of the algorithms have good theoretical properties to optimize the unbiased utility objective while the latter is proved to be empirically more effective and efficient in practice. Our framework U-rank+ can deal with a general utility function and can be used in a widespread of applications including web search, recommendation, and online advertising. Semi-synthetic experiments on three benchmark learning to rank datasets demonstrate the effectiveness of U-rank+ . Furthermore, our proposed framework has been deployed on two different scenarios of a mainstream App store, where the online A/B testing shows that U-rank+ achieves an average improvement of 19.2% on click-through rate and 20.8% improvement on conversion rate in recommendation scenario, and 5.12% on platform revenue in online advertising scenario over the production baselines.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3213377352",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Section on Graph Technologies for User Modeling and Recommendation, Part 2",
    "doi": "https://doi.org/10.1145/3490180",
    "publication_date": "2021-12-14",
    "publication_year": 2021,
    "authors": "Xiangnan He; Zhaochun Ren; Emine Yılmaz; Marc Najork; Tat‐Seng Chua",
    "corresponding_authors": "",
    "abstract": "introduction Share on Introduction to the Special Section on Graph Technologies for User Modeling and Recommendation, Part 2 Authors: Xiangnan He University of Science and Technology of China, Hefei, China University of Science and Technology of China, Hefei, ChinaSearch about this author , Zhaochun Ren Shandong University, Qingdao, China Shandong University, Qingdao, ChinaSearch about this author , Emine Yilmaz Department of Computer Science, University College London, London, United Kingdom Department of Computer Science, University College London, London, United KingdomSearch about this author , Marc Najork Google Research, Mountain View, CA, United States Google Research, Mountain View, CA, United StatesSearch about this author , Tat-Seng Chua National University of Singapore, Singapore, Republic of Singapore National University of Singapore, Singapore, Republic of SingaporeSearch about this author Authors Info & Claims ACM Transactions on Information SystemsVolume 40Issue 3July 2022 Article No.: 42pp 1–5https://doi.org/10.1145/3490180Published:14 December 2021Publication History 0citation385DownloadsMetricsTotal Citations0Total Downloads385Last 12 Months385Last 6 weeks27 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4200381234",
    "type": "article"
  },
  {
    "title": "TOIS reviewers January 2006 through May 2007",
    "doi": "https://doi.org/10.1145/1281485.1281486",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "Gary Marchionini",
    "corresponding_authors": "Gary Marchionini",
    "abstract": "article TOIS reviewers January 2006 through May 2007 Share on Editor: Gary Marchionini View Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 25Issue 4October 2007 pp 15–eshttps://doi.org/10.1145/1281485.1281486Online:01 October 2007Publication History 0citation439DownloadsMetricsTotal Citations0Total Downloads439Last 12 Months4Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1987331397",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1402256",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4233600999",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1247715",
    "publication_date": "2007-07-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "XML is a rather verbose representation of semistructured data, which may require huge amounts of storage space. We propose a summarized representation of XML data, based on the concept of instance pattern, which can both provide succinct information and ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4242425053",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1281485",
    "publication_date": "2007-10-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The aim of this article is to produce an alternative view of the adaptive hypermedia (AH) domain from a contextually-aware open hypermedia (OH) perspective. We believe that a wide range of AH techniques can be supported with a small number of OH ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4252432878",
    "type": "paratext"
  },
  {
    "title": "A New Name - ACM Transactions on Information Systems, Editorial.",
    "doi": null,
    "publication_date": "1989-01-01",
    "publication_year": 1989,
    "authors": "Robert B. Allen",
    "corresponding_authors": "Robert B. Allen",
    "abstract": "",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W207125197",
    "type": "article"
  },
  {
    "title": "Reviewers for <i>ACM Transactions on Information Systems</i> Volume 37",
    "doi": "https://doi.org/10.1145/3365367",
    "publication_date": "2019-10-31",
    "publication_year": 2019,
    "authors": "Maarten de Rijke",
    "corresponding_authors": "Maarten de Rijke",
    "abstract": "research-article Share on Reviewers for ACM Transactions on Information Systems Volume 37 Author: Maarten de Rijke University of Amsterdam, Amsterdam, The Netherlands University of Amsterdam, Amsterdam, The NetherlandsView Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 37Issue 4October 2019 Article No.: 49pp 1–6https://doi.org/10.1145/3365367Published:04 December 2019Publication History 0citation125DownloadsMetricsTotal Citations0Total Downloads125Last 12 Months17Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3001540297",
    "type": "article"
  },
  {
    "title": "Tagging Items with Emerging Tags: A Neural Topic Model Based Few-Shot Learning Approach",
    "doi": "https://doi.org/10.1145/3641859",
    "publication_date": "2024-01-23",
    "publication_year": 2024,
    "authors": "Shangkun Che; Hongyan Liu; Shen Liu",
    "corresponding_authors": "",
    "abstract": "The tagging system has become a primary tool to organize information resources on the Internet, which benefits both users and the platforms. To build a successful tagging system, automatic tagging methods are desired. With the development of society, new tags keep emerging. The problem of tagging items with emerging tags is an open challenge for an automatic tagging system, and it has not been well studied in the literature. We define this problem as a tag-centered cold-start problem in this study and propose a novel neural topic model based few-shot learning method named NTFSL to solve the problem. In our proposed method, we innovatively fuse the topic modeling task with the few-shot learning task, endowing the model with the capability to infer effective topics to solve the tag-centered cold-start problem with the property of interpretability. Meanwhile, we propose a novel neural topic model for the topic modeling task to improve the quality of inferred topics, which helps enhance the tagging performance. Furthermore, we develop a novel inference method based on the variational auto-encoding framework for model inference. We conducted extensive experiments on two real-world datasets, and the results demonstrate the superior performance of our proposed model compared with state-of-the-art machine learning methods. Case studies also show the interpretability of the model.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4391136404",
    "type": "article"
  },
  {
    "title": "Generalized Weak Supervision for Neural Information Retrieval",
    "doi": "https://doi.org/10.1145/3647639",
    "publication_date": "2024-02-21",
    "publication_year": 2024,
    "authors": "Yen-Chieh Lien; Hamed Zamani; W. Bruce Croft",
    "corresponding_authors": "",
    "abstract": "Neural ranking models (NRMs) have demonstrated effective performance in several information retrieval (IR) tasks. However, training NRMs often requires large-scale training data, which is difficult and expensive to obtain. To address this issue, one can train NRMs via weak supervision, where a large dataset is automatically generated using an existing ranking model (called the weak labeler) for training NRMs. Weakly supervised NRMs can generalize from the observed data and significantly outperform the weak labeler. This paper generalizes this idea through an iterative re-labeling process, demonstrating that weakly supervised models can iteratively play the role of weak labeler and significantly improve ranking performance without using manually labeled data. The proposed Generalized Weak Supervision (GWS) solution is generic and orthogonal to the ranking model architecture. This paper offers four implementations of GWS: self-labeling, cross-labeling, joint cross- and self-labeling, and greedy multi-labeling. GWS also benefits from a query importance weighting mechanism based on query performance prediction methods to reduce noise in the generated training data. We further draw a theoretical connection between self-labeling and Expectation-Maximization. Our experiments on four retrieval benchmarks suggest that our implementations of GWS lead to substantial improvements compared to weak supervision if the weak labeler is sufficiently reliable.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4392004079",
    "type": "article"
  },
  {
    "title": "Few-shot Learning for Heterogeneous Information Networks",
    "doi": "https://doi.org/10.1145/3649311",
    "publication_date": "2024-02-27",
    "publication_year": 2024,
    "authors": "Yang Fang; Xiang Zhao; Weidong Xiao; Maarten de Rijke",
    "corresponding_authors": "",
    "abstract": "Heterogeneous information networks (HINs) are a key resource in many domain-specific retrieval and recommendation scenarios and in conversational environments. Current approaches to mining graph data often rely on abundant supervised information. However, supervised signals for graph learning tend to be scarce for a new task and only a handful of labeled nodes may be available. Meta-learning mechanisms are able to harness prior knowledge that can be adapted to new tasks. In this article, we design meta-learning framework for heterogeneous information networks ( META-HIN ), for few-shot learning problems on HINs. To the best of our knowledge, we are among the first to design a unified framework to realize the few-shot learning of HINs and facilitate different downstream tasks across different domains of graphs. Unlike most previous models, which focus on a single task on a single graph, META-HIN is able to deal with different tasks (node classification, link prediction, and anomaly detection are used as examples) across multiple graphs. Subgraphs are sampled to build the support and query set. Before being processed by the meta-learning module, subgraphs are modeled via a structure module to capture structural features. Then, a heterogeneous Graph Neural Network module is used as the base model to express the features of subgraphs. We also design a Generative Adversarial Network-based contrastive learning module that is able to exploit unsupervised information of the subgraphs. In our experiments, we fuse several datasets from multiple domains to verify META-HIN ’s broad applicability in a multiple-graph scenario. META-HIN consistently and significantly outperforms state-of-the-art alternatives on every task and across all datasets that we consider.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4392192111",
    "type": "article"
  },
  {
    "title": "Document-Level Relation Extraction with Progressive Self-Distillation",
    "doi": "https://doi.org/10.1145/3656168",
    "publication_date": "2024-06-25",
    "publication_year": 2024,
    "authors": "Quan Wang; Zhendong Mao; Jie Gao; Yongdong Zhang",
    "corresponding_authors": "",
    "abstract": "Document-level relation extraction (RE) aims to simultaneously predict relations (including no-relation cases denoted as NA) between all entity pairs in a document. It is typically formulated as a relation classification task with entities pre-detected in advance and solved by a hard-label training regime, which, however, neglects the divergence of the NA class and the correlations among other classes. This article introduces progressive self-distillation (PSD), a new training regime that employs online, self-knowledge distillation (KD) to produce and incorporate soft labels for document-level RE.The key idea of PSD is to gradually soften hard labels using past predictions from an RE model itself, which are adjusted adaptively as training proceeds. As such, PSD has to learn only one RE model within a single training pass, requiring no extra computation or annotation to pretrain another high-capacity teacher. PSD is conceptually simple, easy to implement, and generally applicable to various RE models to further improve their performance, without introducing additional parameters or significantly increasing training overheads into the models. It is also a general framework that can be flexibly extended to distilling various types of knowledge, rather than being restricted to soft labels themselves. Extensive experiments on four benchmarking datasets verify the effectiveness and generality of the proposed approach. The code is available at https://github.com/GaoJieCN/psd",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4394569802",
    "type": "article"
  },
  {
    "title": "Unifying Graph Neural Networks with a Generalized Optimization Framework",
    "doi": "https://doi.org/10.1145/3660852",
    "publication_date": "2024-04-25",
    "publication_year": 2024,
    "authors": "Chuan Shi; Meiqi Zhu; Yue Yu; Xiao Wang; Junping Du",
    "corresponding_authors": "",
    "abstract": "Graph Neural Networks (GNNs) have received considerable attention on graph-structured data learning for a wide variety of tasks. The well-designed propagation mechanism, which has been demonstrated effective, is the most fundamental part of GNNs. Although most of the GNNs basically follow a message passing manner, little effort has been made to discover and analyze their essential relations. In this article, we establish a surprising connection between different propagation mechanisms with an optimization problem. We show that despite the proliferation of various GNNs, in fact, their proposed propagation mechanisms are the optimal solutions of a generalized optimization framework with a flexible feature fitting function and a generalized graph regularization term. Actually, the optimization framework can not only help understand the propagation mechanisms of GNNs but also open up opportunities for flexibly designing new GNNs. Through analyzing the general solutions of the optimization framework, we provide a more convenient way for deriving corresponding propagation results of GNNs. We further discover that existing works usually utilize naïve graph convolutional kernels for feature fitting function or just utilize one-hop structural information (original topology graph) for graph regularization term. Correspondingly, we develop two novel objective functions considering adjustable graph kernels showing low-pass or high-pass filtering capabilities and one novel objective function considering high-order structural information during propagation, respectively. Extensive experiments on benchmark datasets clearly show that the newly proposed GNNs not only outperform the state-of-the-art methods but also have good ability to alleviate over-smoothing and further verify the feasibility for designing GNNs with the generalized unified optimization framework.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4395445721",
    "type": "article"
  },
  {
    "title": "Special Section on Efficiency in Neural Information Retrieval",
    "doi": "https://doi.org/10.1145/3641203",
    "publication_date": "2024-04-29",
    "publication_year": 2024,
    "authors": "Sebastian Bruch; Claudio Lucchese; Maria Maistro; Franco Maria Nardini",
    "corresponding_authors": "",
    "abstract": "We introduce a model of generalized Hebbian learning and retrieval in oscillatory neural networks modeling cortical areas such as hippocampus and olfactory cortex. Recent experiments have shown that synaptic plasticity depends on spike timing, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4395960181",
    "type": "article"
  },
  {
    "title": "XLORE 3: A Large-scale Multilingual Knowledge Graph from Heterogeneous Wiki Knowledge Resources",
    "doi": "https://doi.org/10.1145/3660521",
    "publication_date": "2024-08-19",
    "publication_year": 2024,
    "authors": "Kaisheng Zeng; Hailong Jin; Xin Lv; Fangwei Zhu; Lei Hou; Yi Zhang; Fan Pang; Yu Qi; Dingxiao Liu; Juanzi Li; Ling Feng",
    "corresponding_authors": "",
    "abstract": "In recent years, knowledge graph (KG) has attracted significant attention from academia and industry, resulting in the development of numerous technologies for KG construction, completion, and application. XLORE is one of the largest multilingual KGs built from Baidu Baike and Wikipedia via a series of knowledge modeling and acquisition methods. In this article, we utilize systematic methods to improve XLORE's data quality and present its latest version, XLORE 3, which enables the effective integration and management of heterogeneous knowledge from diverse resources. Compared with previous versions, XLORE 3 has three major advantages: (1) We design a comprehensive and reasonable schema, namely XLORE ontology, which can effectively organize and manage entities from various resources. (2) We merge equivalent entities in different languages to facilitate knowledge sharing. We provide a large-scale entity linking system to establish the associations between unstructured text and structured KG. (3) We design a multi-strategy knowledge completion framework, which leverages pre-trained language models and vast amounts of unstructured text to discover missing and new facts. The resulting KG contains 446 concepts, 2,608 properties, 66 million entities, and more than 2 billion facts. It is available and downloadable online at https://www.xlore.cn/ , providing a valuable resource for researchers and practitioners in various fields.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4396952095",
    "type": "article"
  },
  {
    "title": "Online and Offline Evaluation in Search Clarification",
    "doi": "https://doi.org/10.1145/3681786",
    "publication_date": "2024-07-25",
    "publication_year": 2024,
    "authors": "Leila Tavakoli; Johanne R. Trippas; Hamed Zamani; Falk Scholer; Mark Sanderson",
    "corresponding_authors": "",
    "abstract": "The effectiveness of clarification question models in engaging users within search systems is currently constrained, casting doubt on their overall usefulness. To improve the performance of these models, it is crucial to employ assessment approaches that encompass both real-time feedback from users (online evaluation) and the characteristics of clarification questions evaluated through human assessment (offline evaluation). However, the relationship between online and offline evaluations has been debated in information retrieval. This study aims to investigate how this discordance holds in search clarification. We use user engagement as ground truth and employ several offline labels to investigate to what extent the offline ranked lists of clarification resemble the ideal ranked lists based on online user engagement. Contrary to the current understanding that offline evaluations fall short of supporting online evaluations, we indicate that when identifying the most engaging clarification questions from the user’s perspective, online and offline evaluations correspond with each other. We show that the query length does not influence the relationship between online and offline evaluations, and reducing uncertainty in online evaluation strengthens this relationship. We illustrate that an engaging clarification needs to excel from multiple perspectives, and SERP quality and characteristics of the clarification are equally important. We also investigate if human labels can enhance the performance of Large Language Models (LLMs) and Learning-to-Rank (LTR) models in identifying the most engaging clarification questions from the user’s perspective by incorporating offline evaluations as input features. Our results indicate that LTR models do not perform better than individual offline labels. However, GPT, an LLM, emerges as the standout performer, surpassing all LTR models and offline labels.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400977018",
    "type": "article"
  },
  {
    "title": "Distributed Recommendation Systems: Survey and Research Directions",
    "doi": "https://doi.org/10.1145/3694783",
    "publication_date": "2024-09-06",
    "publication_year": 2024,
    "authors": "Qiqi Cai; Jian Cao; Guandong Xu; Nengjun Zhu",
    "corresponding_authors": "",
    "abstract": "With the explosive growth of online information, recommendation systems have become essential tools for alleviating information overload. In recent years, researchers have increasingly focused on centralized recommendation systems, capitalizing on the powerful computing capabilities of cloud servers and the rich historical data they store. However, the rapid development of edge computing and mobile devices in recent years has provided new alternatives for building recommendation systems. These alternatives offer advantages such as privacy protection and low-latency recommendations. To leverage the advantages of different computing nodes, including cloud servers, edge servers, and terminal devices, researchers have proposed recommendation systems that involve the collaboration of these nodes, known as distributed recommendation systems. This survey provides a systematic review of distributed recommendation systems. Specifically, we design a taxonomy for these systems from four perspectives and comprehensively summarize each study by category. In particular, we conduct a detailed analysis of the collaboration mechanisms of distributed recommendation systems. Finally, we discuss potential future research directions in this field.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402307441",
    "type": "article"
  },
  {
    "title": "LTP-MMF: Towards Long-term Provider Max-min Fairness Under Recommendation Feedback Loops",
    "doi": "https://doi.org/10.1145/3695867",
    "publication_date": "2024-09-13",
    "publication_year": 2024,
    "authors": "Xu Chen; Xiaopeng Ye; Jun Xu; Xiao Zhang; Weiran Shen; Ji-Rong Wen",
    "corresponding_authors": "",
    "abstract": "Multi-stakeholder recommender systems involve various roles, such as users, and providers. Previous work pointed out that max-min fairness (MMF) is a better metric to support weak providers. However, when considering MMF, the features or parameters of these roles vary over time, how to ensure long-term provider MMF has become a significant challenge. We observed that recommendation feedback loops (named RFL) will influence the provider MMF greatly in the long term. RFL means that recommender systems can only receive feedback on exposed items from users and update recommender models incrementally based on this feedback. When utilizing the feedback, the recommender model will regard the unexposed items as negative. In this way, the tail provider will not get the opportunity to be exposed, and its items will always be considered negative samples. Such phenomena will become more and more serious in RFL. To alleviate the problem, this paper proposes an online ranking model named Long-Term Provider Max-min Fairness (named LTP-MMF). Theoretical analysis shows that the long-term regret of LTP-MMF enjoys a sub-linear bound. Experimental results on three public recommendation benchmarks demonstrated that LTP-MMF can outperform the baselines in the long term.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402516107",
    "type": "article"
  },
  {
    "title": "Exploring Cross-site User Modeling Without Cross-site User Identity Linkage: A Case Study of Content Preference Prediction",
    "doi": "https://doi.org/10.1145/3697832",
    "publication_date": "2024-10-01",
    "publication_year": 2024,
    "authors": "Qi Zhou; Peng Zhang; Hansu Gu; Tun Lu; Ning Gu",
    "corresponding_authors": "",
    "abstract": "Performing user modeling on two or more social media platforms collaboratively and complementing each other (cross-site user modeling) has been a significant problem in the area of social media mining in recent years. The core of this problem is to get to know a person’s identities on multiple platforms and then train user models collaboratively among these platforms. However, for privacy protection, many people do not want their identities on different platforms to be linked and disclosed. For this problem, we set cross-site Content Preference Prediction as a task and propose a cross-site user modeling method without cross-site User Identity Linkage (UIL). The core thought borrowed from privacy-preserving recommender system research is to organize social media identities into groups to hide the identity linkage among platforms. Experiments on real-world datasets suggest that our method outperforms the existing cross-site user modeling methods with cross-site UIL regarding several metrics.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403028803",
    "type": "article"
  },
  {
    "title": "Meta Learning to Rank for Sparsely Supervised Queries",
    "doi": "https://doi.org/10.1145/3698876",
    "publication_date": "2024-10-08",
    "publication_year": 2024,
    "authors": "Xuyang Wu; Ajit Puthenputhussery; Hongwei Shang; Changsung Kang; Yi Fang",
    "corresponding_authors": "",
    "abstract": "Supervisory signals are a critical resource for training learning to rank models. In many real-world search and retrieval scenarios, these signals may not be readily available or could be costly to obtain for some queries. The examples include domains where labeling requires professional expertise, applications with strong privacy constraints, and user engagement information that are too scarce. We refer to these scenarios as sparsely supervised queries which pose significant challenges to traditional learning to rank models. In this work, we address sparsely supervised queries by proposing a novel meta learning to rank framework which leverages fast learning and adaption capability of meta-learning. The proposed approach accounts for the fact that different queries have different optimal parameters for their rankers, in contrast to traditional learning to rank models which only learn a global ranking model applied to all the queries. In consequence, the proposed method would yield significant advantages especially when new queries are of different characteristics with the training queries. Moreover, the proposed meta learning to rank framework is generic and flexible. We conduct a set of comprehensive experiments on both public datasets and a real-world e-commerce dataset. The results demonstrate that the proposed meta-learning approach can significantly enhance the performance of learning to rank models with sparsely labeled queries.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403221949",
    "type": "article"
  },
  {
    "title": "Learning Robust Sequential Recommenders through Confident Soft Labels",
    "doi": "https://doi.org/10.1145/3700876",
    "publication_date": "2024-10-17",
    "publication_year": 2024,
    "authors": "Shiguang Wu; Xin Xin; Pengjie Ren; Zhumin Chen; Jun Ma; Maarten de Rijke; Zhaochun Ren",
    "corresponding_authors": "",
    "abstract": "Sequential recommenders that are trained on implicit feedback are usually learned as a multi-class classification task through softmax-based loss functions on one-hot class labels. However, one-hot training labels are sparse and may lead to biased training and sub-optimal performance. Dense, soft labels have been shown to help improve recommendation performance. However, how to generate high-quality and confident soft labels from noisy sequential interactions between users and items is still an open question. We propose a new learning framework for sequential recommenders, CSRec, which introduces c onfident s oft labels to provide robust guidance when learning from user-item interactions. CSRec contains a teacher module that generates high-quality and confident soft labels and a student module that acts as the target recommender and is trained on the combination of dense, soft labels and sparse, one-hot labels. We propose and compare three approaches to constructing the teacher module: (i) model-level, (ii) data-level, and (iii) training-level. To evaluate the effectiveness and generalization ability of CSRec, we conduct experiments using various state-of-the-art sequential recommendation models as the target student module on four benchmark datasets. Our experimental results demonstrate that CSRec is effective in training better-performing sequential recommenders.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403485923",
    "type": "article"
  },
  {
    "title": "Variational Type Graph Autoencoder For Denoising On Event Recommendation",
    "doi": "https://doi.org/10.1145/3703156",
    "publication_date": "2024-11-05",
    "publication_year": 2024,
    "authors": "Shuo Zhang; Bi Liang; Yujie Zhang",
    "corresponding_authors": "",
    "abstract": "Recommendations for events play a pivotal role in facilitating the discovery of upcoming intriguing events within Event-Based Social Networks (EBSNs). Previous research has established the crucial significance of mining contextual features and implicit relationships to enhance recommendation performance and alleviate data sparsity issues. However, the noise inherent in contextual features exacerbates data sparsity and hampers the ability of previous methods to explore implicit relationships for mitigating data sparsity. To address this challenge, we propose a variational type graph autoencoder model that attenuates the influence of noise in different types of context features by introducing type-specific latent variables. Firstly, we introduce a heterogeneous denoising convolution module composed of two components: 1) Denoising attention aggregation is proposed to mitigate the influence of noisy structures and uncover implicit relationships. 2) A heterogeneous normalization module leverages context features within the same type to alleviate the effects of noise in context features and data sparsity. Furthermore, we propose a learnable heterogeneous mixture prior that assists in assigning different priors to distinct types of latent variables, effectively modeling different types of contextual features. Through comprehensive experiments conducted on real-world datasets, we demonstrate the compelling performance of our model compared to state-of-the-art competitive approaches.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404058294",
    "type": "article"
  },
  {
    "title": "Adapting Constrained Markov Decision Process for OCPC Bidding with Delayed Conversions",
    "doi": "https://doi.org/10.1145/3706420",
    "publication_date": "2024-11-29",
    "publication_year": 2024,
    "authors": "Leping Zhang; Xiao Zhang; Yichao Wang; X.Q. Li; Zhenhua Dong; Jun Xu",
    "corresponding_authors": "",
    "abstract": "Nowadays, optimized cost-per-click (OCPC) has been widely adopted in online advertising. In OCPC, the advertiser sets an expected cost-per-conversion and pays per click, while the platform automatically adjusts the bid on each click to meet advertiser's constraint. Existing bidding methods are based on feedback control, adjusting bids to keep the current cost-per-conversion close to the expected cost-per-conversion to avoid compensation. However, they overlook the conversion lag phenomenon: There always exists a time interval between the ad's click time and conversion time. This interval makes existing methods overestimate the cost-per-conversion and results in over conservative bidding policies which finally hurts the revenue. To address the issue, this paper proposes a novel bidding method, Bid-DC (Bidding with Delayed Conversions) which predicts the conversion probability of the clicked ads and used it to adjust the cost-per-conversion values. To ensure the bidding model can satisfy the advertiser's constraint, constrained Markov decision process (CMDP) is adapted to automatically learn the optimal parameters from the log data. Both online and offline experiments demonstrate that Bid-DC outperforms the state-of-the-art baselines in terms of improving revenue. Empirical analysis also showed Bid-DC can accurately estimate the cost-per-conversion and make more stable bids.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4404856314",
    "type": "article"
  },
  {
    "title": "Privacy-Preserving Sequential Recommendation with Collaborative Confusion",
    "doi": "https://doi.org/10.1145/3707204",
    "publication_date": "2024-12-06",
    "publication_year": 2024,
    "authors": "Wei Wang; Yujie Lin; Pengjie Ren; Zhumin Chen; Tsunenori Mine; Jianli Zhao; Qiang Zhao; Moyan Zhang; Xianye Ben; Yujun Li",
    "corresponding_authors": "",
    "abstract": "Sequential recommendation has attracted a lot of attention from both academia and industry, however the privacy risks associated with gathering and transferring users’ personal interaction data are often underestimated or ignored. Existing privacy-preserving studies are mainly applied to traditional collaborative filtering or matrix factorization rather than sequential recommendation. Moreover, these studies are mostly based on differential privacy or federated learning, which often lead to significant performance degradation, or have high requirements for communication. In this work, we address privacy-preserving from a different perspective. Unlike existing research, we capture collaborative signals of neighbor interaction sequences and directly inject indistinguishable items into the target sequence before the recommendation process begins, thereby increasing the perplexity of the target sequence. Even if the target interaction sequence is obtained by attackers, it is difficult to discern which ones are the actual user interaction records. To achieve this goal, we introduce a novel sequential recommender system called CLOUD ( C o L laborative-c O nfusion seq U ential recommen D er), which incorporates a collaborative confusion mechanism to modify the raw interaction sequences before conducting recommendation. Specifically, CLOUD first calculates the similarity between the target interaction sequence and other neighbor sequences to find similar sequences. Then, CLOUD considers the shared representation of the target sequence and similar sequences to determine the operation to be performed: keep, delete, or insert. A copy mechanism is designed to make items from similar sequences have a higher probability to be inserted into the target sequence. Finally, the modified sequence is used to train the recommender and predict the next item. We conduct extensive experiments on three benchmark datasets. The experimental results show that CLOUD achieves a maximum modification rate of 66.57% on interaction sequences, and obtains over 99% recommendation accuracy compared to the state-of-the-art sequential recommendation methods. This proves that CLOUD can effectively protect user privacy at minimal recommendation performance cost, which provides a new solution for privacy-preserving for sequential recommendation. Our implementation is available at https://github.com/weiwang0927/CLOUD .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405115696",
    "type": "article"
  },
  {
    "title": "Introduction to genomic information retrieval",
    "doi": "https://doi.org/10.1145/1055709.1055710",
    "publication_date": "2005-01-01",
    "publication_year": 2005,
    "authors": "Hugh Williams",
    "corresponding_authors": "Hugh Williams",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2000463550",
    "type": "article"
  },
  {
    "title": "Composition of Engineering Web Services with Distributed Data Flows and Computations | NIST",
    "doi": null,
    "publication_date": "2005-04-01",
    "publication_year": 2005,
    "authors": "D. Liu; Peng Jiao; Kincho H. Law; Gio Wiederhold; Ram D. Sriram",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2742547578",
    "type": "article"
  },
  {
    "title": "Knowledge Base Embedding for Sampling-Based Prediction",
    "doi": "https://doi.org/10.1145/3533769",
    "publication_date": "2022-06-11",
    "publication_year": 2022,
    "authors": "Richong Zhang; Jaein Kim; Jiajie Mei; Yongyi Mao",
    "corresponding_authors": "",
    "abstract": "Each link prediction task requires different degrees of answer diversity. While a link prediction task may expect up to a couple of answers, another may expect nearly a hundred answers. Given this fact, the performance of a link prediction model can be estimated more accurately if a flexible number of obtained answers are estimated instead of a predefined number of answers. Inspired by this, in this article, we analyze two evaluation criteria for link prediction tasks, respectively ranking-based protocol and sampling-based protocol. Furthermore, we study two classes of models on link prediction task, direct model and latent-variable model respectively, to demonstrate that latent-variable model performs better under the sampling-based protocol. We then propose a latent-variable model where the framework of Conditional Variational AutoEncoder (CVAE) is applied. Experimental study suggests that the proposed model performs comparably to the current state-of-the-art even under the conventional rank-based protocol. Under the sampling-based protocol, the proposed model is shown to outperform various state-of-the-art models.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4313426558",
    "type": "article"
  },
  {
    "title": "Explaining Recommendation Fairness from a User/Item Perspective",
    "doi": "https://doi.org/10.1145/3698877",
    "publication_date": "2024-10-05",
    "publication_year": 2024,
    "authors": "Jie Li; Yongli Ren; Mark Sanderson; Ke Deng",
    "corresponding_authors": "",
    "abstract": "Recommender systems play a crucial role in personalizing user experiences, yet ensuring fairness in their outcomes remains an elusive challenge. This work explores the impact of individual users or items on the fairness of recommender systems, thus addressing a significant knowledge gap in the field. We introduce an innovative approach called A dding-based C ounterfactual F airness R easoning ( ACFR ), designed to elucidate recommendation fairness from the unique perspectives of users and items. Conventional methodologies, like erasing-based counterfactual analysis, pose limitations, particularly in modern recommender systems dealing with a large number of users and items. These traditional methods, by excluding specific users or items, risk disrupting the crucial relational structure central to collaborative filtering recommendations. In contrast, ACFR employs an adding-based counterfactual analysis, a unique strategy allowing us to consider potential, yet-to-happen user-item interactions. This strategy preserves the core user-item relational structure, while predicting future behaviors of users or items. The commonly-used feature-based counterfactual analysis, relying on gradient-based optimization to identify interference on each feature, is not directly applicable in our case. In the recommendation scenario we consider, only interactions between users and items are present during model training—no distinct features are involved. Consequently, the traditional mechanism proves impractical for identifying interference on these existing interactions. Our extensive experiments validate the superiority of ACFR over traditional baseline methods, demonstrating significant improvements in recommendation fairness on benchmark datasets. This work, therefore, provides a fresh perspective and a promising methodology for enhancing fairness in recommender systems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403155149",
    "type": "article"
  },
  {
    "title": "Complete logical routings in computer mail systems",
    "doi": "https://doi.org/10.1145/5401.5404",
    "publication_date": "1986-01-01",
    "publication_year": 1986,
    "authors": "Patrick Martin; D. Tsichritzis",
    "corresponding_authors": "",
    "abstract": "The logical routing of a message in a computer mail system involves the identification and location of the set of intended recipients for that message. This function is carried out by the naming and addressing mechanism of the mail system. An important property of that mechanism is that it should be able to identify and locate all the intended recipients of a message, so that, once submitted, a message will not become lost or stuck in the system. We first discuss message addressing schemes , which are a framework for dealing with the naming and addressing problem. Message addressing schemes can also serve as a basis for the analysis of some of the properties of logical message routing within a system. We examine the conditions necessary for a complete message addressing scheme, that is, one that guarantees to deliver all possible messages.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2015245455",
    "type": "article"
  },
  {
    "title": "Editor's introduction",
    "doi": "https://doi.org/10.1145/357423.357424",
    "publication_date": "1983-01-01",
    "publication_year": 1983,
    "authors": "J.O. Limb",
    "corresponding_authors": "J.O. Limb",
    "abstract": "No abstract available.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4243046458",
    "type": "article"
  },
  {
    "title": "Special Issue of ACM TOIS on Contextual Search and Recommendation",
    "doi": null,
    "publication_date": "2015-03-01",
    "publication_year": 2015,
    "authors": "Paul N. Bennett; Kevyn Collins‐Thompson; Diane Kelly; Ryen W. White; Yi Zhang; guest eds",
    "corresponding_authors": "",
    "abstract": "Information systems that leverage contextual knowledge about their users and their search situations, such as histories, demographics, surroundings, constraints, or devices,canprovidetailoredsearchexperiencesandhigher-qualitytaskoutcomes.Within information retrieval, there is a growing focus on how knowledge of user interests, intentions, and context can improve aspects of search and recommendation, such as ranking and query suggestion, especially for exploratory and/or complex tasks that can span multiple queries or search sessions. The interactions that occur during these complex tasks provide context that can be leveraged by search systems to support users’ broader information-seeking activities. Next-generation recommender systems face analogous challenges, including integrating signals from user exploration to update recommendations in real time. The recent growth in work on complex task-oriented search and recommendation combined with the interest in context derived from mobile and situated devices—and across devices—make this an opportune time for a special issue in this area. Given the timeliness and breadth of the topic, as well as the level of interest in events such as related workshops, we believe that readers will ﬁnd these articles both informative and thought provoking. Guest Editors Paul N. Bennett Kevyn Collins-Thompson Diane Kelly Ryen W. White Yi Zhang",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2737143066",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2737806",
    "publication_date": "2015-03-17",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Personalization of support for information seeking depends crucially on the information retrieval system's knowledge of the task that led the person to engage in information seeking. Users work during information search sessions to satisfy their task ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233551052",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2766484",
    "publication_date": "2015-05-15",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Mobile devices enable people to look for information at the moment when their information needs are triggered. While experiencing complex information needs that require multiple search sessions, users may utilize desktop computers to fulfill information ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235033829",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2737814",
    "publication_date": "2015-03-23",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Social media provides valuable resources to analyze user behaviors and capture user preferences. This article focuses on analyzing user behaviors in social media systems and designing a latent class statistical mixture model, named temporal context-...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236423034",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2986034",
    "publication_date": "2016-10-03",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Given a query document, ranking the documents in a collection based on how similar they are to the query is an essential task with extensive applications. For collections that contain documents whose creation dates span several decades, this task is ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237805809",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2684820",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Patent prior art search is a task in patent retrieval with the goal of finding documents which describe prior art work related to a query patent. A query patent is a full patent application composed of hundreds of terms which does not represent a single ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239096360",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2647579",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Many articles in the online encyclopedia Wikipedia have hyperlinks to ambiguous article titles; these ambiguous links should be replaced with links to unambiguous articles, a process known as disambiguation. We propose a novel statistical topic model ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239629616",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2610992",
    "publication_date": "2014-04-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Ranked result lists with query-dependent snippets have become state of the art in text search. They are typically implemented by searching, at query time, for occurrences of the query words in the top-ranked documents. This document-based approach has ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239760407",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3001595",
    "publication_date": "2016-12-21",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Today, major commercial search engines are operating in a multinational fashion to provide web search services for millions of users who compose search queries by different languages. Hence, the search engine query log, which serves as the backbone of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241592689",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2737813",
    "publication_date": "2015-02-26",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A result page of a modern search engine often goes beyond a simple list of “10 blue links.” Many specific user needs (e.g., News, Image, Video) are addressed by so-called aggregated or vertical search solutions: specially presented documents, often ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242263396",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2576772",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247005763",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2806674",
    "publication_date": "2015-10-01",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Mobile social matching systems have the potential to transform the way we make new social ties, but only if we are able to overcome the many challenges that exist as to how systems can utilize contextual data to recommend interesting and relevant people ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4249016196",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2915200",
    "publication_date": "2016-05-05",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Social media platforms provide an increasingly popular means for individuals to share content online. Whilst this produces undoubted societal benefits, the ability for content to be spontaneously posted and reposted creates an ideal environment for ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251590797",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2954381",
    "publication_date": "2016-09-14",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The task of query performance prediction is to estimate the effectiveness of search performed in response to a query when no relevance judgments are available. We present a novel probabilistic analysis of the performance prediction task. The analysis ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252114355",
    "type": "paratext"
  },
  {
    "title": "Introduction to the special issue on video information retrieval",
    "doi": "https://doi.org/10.1145/211430.215258",
    "publication_date": "1995-10-01",
    "publication_year": 1995,
    "authors": "Scott Stevens; Thomas D. C. Little",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2062833103",
    "type": "article"
  },
  {
    "title": "A model for input and output of multilingual text in a windowing environment",
    "doi": "https://doi.org/10.1145/146486.146558",
    "publication_date": "1992-10-01",
    "publication_year": 1992,
    "authors": "Yutaka Kataoka; Masato Morisaki; Hiroshi Kuribayashi; Hiroyoshi Ohara",
    "corresponding_authors": "",
    "abstract": "The layered multilingual input/output(I/O) sytems we designed, based on typological studies of major-language writing conventions, unifies common features of such conventions to enable international and local utilization. The internationalization layer input module converts keystroke sequences to phonograms and ideograms. The corresponding output module displays position-independent and dependent characters. The localization layer positions language-specific functions outside the structure, integrating them as tables used by finite automaton interpreters and servers to add new languages and code sets without recompilation. The I/O system generates and displays stateful and stateless code sets, enabling interactive language switching. Going beyond POSIX locale model bounds, the system generates ISO 2022, ISO/DIS 10646 (1990), and Compound Text, defined for the interchange encoding format in X11 protocols, for basic polyglot text communication and processing. Able to generate multilingual code sets, the I/O system clearly demonstrates that code sets should be selected by applications which have purposes beyond selecting one element from a localization set. Functionality and functions related to text manipulation in an operating sytem (OS) must also be determined by such applications. A subset of this I/O system was implemented in the X window system as a basic use of X11R5 I/O by supplying basic code set generation and string manipulation to eliminate OS interference. To ensure polyglot string manipulation, the I/O system must clearly be implemented separately from an OS and its limitations.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3085476490",
    "type": "article"
  },
  {
    "title": "Fast Filtering of Search Results Sorted by Attribute",
    "doi": "https://doi.org/10.1145/3477982",
    "publication_date": "2021-11-24",
    "publication_year": 2021,
    "authors": "Franco Maria Nardini; Roberto Trani; Rossano Venturini",
    "corresponding_authors": "",
    "abstract": "Modern search services often provide multiple options to rank the search results, e.g., sort “by relevance”, “by price” or “by discount” in e-commerce. While the traditional rank by relevance effectively places the relevant results in the top positions of the results list, the rank by attribute could place many marginally relevant results in the head of the results list leading to poor user experience. In the past, this issue has been addressed by investigating the relevance-aware filtering problem, which asks to select the subset of results maximizing the relevance of the attribute-sorted list. Recently, an exact algorithm has been proposed to solve this problem optimally. However, the high computational cost of the algorithm makes it impractical for the Web search scenario, which is characterized by huge lists of results and strict time constraints. For this reason, the problem is often solved using efficient yet inaccurate heuristic algorithms. In this article, we first prove the performance bounds of the existing heuristics. We then propose two efficient and effective algorithms to solve the relevance-aware filtering problem. First, we propose OPT-Filtering, a novel exact algorithm that is faster than the existing state-of-the-art optimal algorithm. Second, we propose an approximate and even more efficient algorithm, ϵ-Filtering, which, given an allowed approximation error ϵ, finds a (1-ϵ)–optimal filtering, i.e., the relevance of its solution is at least (1-ϵ) times the optimum. We conduct a comprehensive evaluation of the two proposed algorithms against state-of-the-art competitors on two real-world public datasets. Experimental results show that OPT-Filtering achieves a significant speedup of up to two orders of magnitude with respect to the existing optimal solution, while ϵ-Filtering further improves this result by trading effectiveness for efficiency. In particular, experiments show that ϵ-Filtering can achieve quasi-optimal solutions while being faster than all state-of-the-art competitors in most of the tested configurations.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3215900597",
    "type": "article"
  },
  {
    "title": "The <i>Footprint</i> of Factorization Models and Their Applications in Collaborative Filtering",
    "doi": "https://doi.org/10.1145/3490475",
    "publication_date": "2021-11-29",
    "publication_year": 2021,
    "authors": "Jinze Wang; Yongli Ren; Jie Li; Ke Deng",
    "corresponding_authors": "",
    "abstract": "Factorization models have been successfully applied to the recommendation problems and have significant impact to both academia and industries in the field of Collaborative Filtering ( CF ). However, the intermediate data generated in factorization models’ decision making process (or training process , footprint ) have been overlooked even though they may provide rich information to further improve recommendations. In this article, we introduce the concept of Convergence Pattern, which records how ratings are learned step-by-step in factorization models in the field of CF. We show that the concept of Convergence Patternexists in both the model perspective (e.g., classical Matrix Factorization ( MF ) and deep-learning factorization) and the training (learning) perspective (e.g., stochastic gradient descent ( SGD ), alternating least squares ( ALS ), and Markov Chain Monte Carlo ( MCMC )). By utilizing the Convergence Pattern, we propose a prediction model to estimate the prediction reliability of missing ratings and then improve the quality of recommendations. Two applications have been investigated: (1) how to evaluate the reliability of predicted missing ratings and thus recommend those ratings with high reliability. (2) How to explore the estimated reliability to adjust the predicted ratings to further improve the predication accuracy. Extensive experiments have been conducted on several benchmark datasets on three recommendation tasks: decision-aware recommendation, rating predicted, and Top- N recommendation. The experiment results have verified the effectiveness of the proposed methods in various aspects.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3216569295",
    "type": "article"
  },
  {
    "title": "Component-based Analysis of Dynamic Search Performance",
    "doi": "https://doi.org/10.1145/3483237",
    "publication_date": "2021-11-22",
    "publication_year": 2021,
    "authors": "Ameer Albahem; Damiano Spina; Falk Scholer; Lawrence Cavedon",
    "corresponding_authors": "",
    "abstract": "In many search scenarios, such as exploratory, comparative, or survey-oriented search, users interact with dynamic search systems to satisfy multi-aspect information needs. These systems utilize different dynamic approaches that exploit various user feedback granularity types. Although studies have provided insights about the role of many components of these systems, they used black-box and isolated experimental setups. Therefore, the effects of these components or their interactions are still not well understood. We address this by following a methodology based on Analysis of Variance (ANOVA). We built a Grid Of Points that consists of systems based on different ways to instantiate three components: initial rankers, dynamic rerankers, and user feedback granularity. Using evaluation scores based on the TREC Dynamic Domain collections, we built several ANOVA models to estimate the effects. We found that (i) although all components significantly affect search effectiveness, the initial ranker has the largest effective size, (ii) the effect sizes of these components vary based on the length of the search session and the used effectiveness metric, and (iii) initial rankers and dynamic rerankers have more prominent effects than user feedback granularity. To improve effectiveness, we recommend improving the quality of initial rankers and dynamic rerankers. This does not require eliciting detailed user feedback, which might be expensive or invasive.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3217373882",
    "type": "article"
  },
  {
    "title": "A Comparison between Term-Independence Retrieval Models for Ad Hoc Retrieval",
    "doi": "https://doi.org/10.1145/3483612",
    "publication_date": "2021-12-08",
    "publication_year": 2021,
    "authors": "Edward Kai Fung Dang; Robert W. P. Luk; James Allan",
    "corresponding_authors": "",
    "abstract": "In Information Retrieval, numerous retrieval models or document ranking functions have been developed in the quest for better retrieval effectiveness. Apart from some formal retrieval models formulated on a theoretical basis, various recent works have applied heuristic constraints to guide the derivation of document ranking functions. While many recent methods are shown to improve over established and successful models, comparison among these new methods under a common environment is often missing. To address this issue, we perform an extensive and up-to-date comparison of leading term-independence retrieval models implemented in our own retrieval system. Our study focuses on the following questions: (RQ1) Is there a retrieval model that consistently outperforms all other models across multiple collections; (RQ2) What are the important features of an effective document ranking function? Our retrieval experiments performed on several TREC test collections of a wide range of sizes (up to the terabyte-sized Clueweb09 Category B) enable us to answer these research questions. This work also serves as a reproducibility study for leading retrieval models. While our experiments show that no single retrieval model outperforms all others across all tested collections, some recent retrieval models, such as MATF and MVD, consistently perform better than the common baselines.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4200247715",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2493175",
    "publication_date": "2013-07-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Several questions remain unanswered by the existing literature concerning the deployment of query-dependent features within learning to rank. In this work, we investigate three research questions in order to empirically ascertain best practices for ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231232118",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2414782",
    "publication_date": "2013-01-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Software developers increasingly rely on information from the Web, such as documents or code examples on application programming interfaces (APIs), to facilitate their development processes. However, API documents often do not include enough information ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233893325",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2457465",
    "publication_date": "2013-05-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Query reformulation modifies the original query with the aim of better matching the vocabulary of the relevant documents, and consequently improving ranking effectiveness. Previous models typically generate words and phrases related to the original ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239202079",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2536736",
    "publication_date": "2013-11-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Ranker evaluation is central to the research into search engines, be it to compare rankers or to provide feedback for learning to rank. Traditional evaluation approaches do not scale well because they require explicit relevance judgments of document-...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245694456",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1993036",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The emergence of large-scale social Web communities has enabled users to share online vast amounts of multimedia content. An analysis of YouTube reveals a high amount of redundancy, in the form of videos with overlapping or duplicated content. We use ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251800501",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2037661",
    "publication_date": "2011-12-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Dynamic pruning strategies for information retrieval systems can increase querying efficiency without decreasing effectiveness by using upper bounds to safely omit scoring documents that are unlikely to make the final retrieved set. Often, such upper ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252096064",
    "type": "paratext"
  },
  {
    "title": "TOIS Reviewers",
    "doi": "https://doi.org/10.1145/2382438.2382446",
    "publication_date": "2012-11-01",
    "publication_year": 2012,
    "authors": "Jamie Callan",
    "corresponding_authors": "Jamie Callan",
    "abstract": "editorial Free Access Share on TOIS Reviewers: October 2009 To September 2012 Editor: Jamie Callan View Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 30Issue 4November 2012 Article No.: 27pp 1–3https://doi.org/10.1145/2382438.2382446Published:01 November 2012Publication History 0citation337DownloadsMetricsTotal Citations0Total Downloads337Last 12 Months21Last 6 weeks5 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1965758347",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2180868",
    "publication_date": "2012-05-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Community Question Answering (CQA) is a popular type of service where users ask questions and where answers are obtained from other users or from historical question-answer pairs. CQA archives contain large volumes of questions organized into a ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4229862807",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1658377",
    "publication_date": "2010-01-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Information retrieval (IR) systems typically compress their indexes in order to increase their efficiency. Static pruning is a form of lossy data compression: it removes from the index, data that is estimated to be the least important to retrieval ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230889855",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1852102",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4238081345",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1740592",
    "publication_date": "2010-05-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article introduces an architecture for a document-partitioned search engine, based on a novel approach combining collection selection and load balancing, called load-driven routing. By exploiting the query-vector document model, and the incremental ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239016508",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2328967",
    "publication_date": "2012-08-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240074253",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1877766",
    "publication_date": "2010-12-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244638171",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2382438",
    "publication_date": "2012-11-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Traditional machine-learned ranking systems for Web search are often trained to capture stationary relevance of documents to queries, which have limited ability to track nonstationary user intention in a timely manner. In recency search, for instance, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245262420",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1629096",
    "publication_date": "2009-11-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A new principles framework is presented for retrieval evaluation of ranked outputs. It applies decision theory to model relevance decision preferences and shows that the Probability Ranking Principle (PRP) specifies optimal ranking. It has two new ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246914190",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1508850",
    "publication_date": "2009-05-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The language-modeling approach to information retrieval provides an effective statistical framework for tackling various problems and often achieves impressive empirical performance. However, most previous work on language models for information ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248709446",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1777432",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254517250",
    "type": "paratext"
  },
  {
    "title": "TOIS reviewers June 2007 through May 2008",
    "doi": "https://doi.org/10.1145/1402256.1402265",
    "publication_date": "2008-09-01",
    "publication_year": 2008,
    "authors": "Gary Marchionini",
    "corresponding_authors": "Gary Marchionini",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2021134260",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1229179",
    "publication_date": "2007-04-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The so-called “redundancy-based” approach to question answering represents a successful strategy for mining answers to factoid questions such as “Who shot Abraham Lincoln?” from the World Wide Web. Through contrastive and ablation experiments with ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4229872026",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3133943",
    "publication_date": "2017-09-15",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Many applications require semantic understanding of short texts, and inferring discriminative and coherent latent topics is a critical and fundamental task in these applications. Conventional topic models largely rely on word co-occurrences to derive ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234757566",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1198296",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Standard Information Retrieval (IR) metrics are not well suited for new paradigms like XML or Web IR in which retrievable information units are document elements and/or sets of related documents. Part of the problem stems from the classical hypotheses ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236403761",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1344411",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239174577",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1361684",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240757433",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3026478",
    "publication_date": "2017-06-09",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Click-through information is considered as a valuable source of users’ implicit relevance feedback for commercial search engines. As existing studies have shown that the search result position in a search engine result page (SERP) has a very strong ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246524600",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3077622",
    "publication_date": "2017-08-30",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "It has long been suspected that web archives and search engines favor Western and English language webpages. In this article, we quantitatively explore how well indexed and archived Arabic language webpages are as compared to those from other languages. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251977285",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1416950",
    "publication_date": "2008-12-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In information retrieval research, comparing retrieval approaches requires test collections consisting of documents, user requests and relevance assessments. Obtaining relevance assessments that are as sound and complete as possible is crucial for the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253036360",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1292591",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In dynamic environments, such as the World Wide Web, a changing document collection, query population, and set of search services demands frequent repetition of search effectiveness (relevance) evaluations. Reconstructing static test collections, such ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254568175",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3112649",
    "publication_date": "2017-08-24",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In recent years, mobile devices have become the most popular interface for users to retrieve and access information: recent reports show that users spend significantly more time and issue more search queries on mobile devices than on desktops in the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256579837",
    "type": "paratext"
  },
  {
    "title": "Trustworthy Recommendation and Search: Introduction to the Special Section - Part 2",
    "doi": "https://doi.org/10.1145/3604776",
    "publication_date": "2023-07-28",
    "publication_year": 2023,
    "authors": "Hongzhi Yin; Yizhou Sun; Guandong Xu; Evangelos Kanoulas",
    "corresponding_authors": "",
    "abstract": "introduction Share on Trustworthy Recommendation and Search: Introduction to the Special Section - Part 2 Authors: Hongzhi Yin The University of Queensland Australia The University of Queensland Australia 0000-0003-1395-261XSearch about this author , Yizhou Sun University of California, Los Angeles, USA University of California, Los Angeles, USA 0000-0003-1812-6843Search about this author , Guandong Xu University of Technology Sydney, Australia University of Technology Sydney, Australia 0000-0003-4493-6663Search about this author , Evangelos Kanoulas University of Amsterdam, Netherlands University of Amsterdam, Netherlands 0000-0002-8312-0694Search about this author Authors Info & Claims ACM Transactions on Information SystemsVolume 41Issue 4Article No.: 82pp 1–6https://doi.org/10.1145/3604776Published:28 July 2023Publication History 0citation0DownloadsMetricsTotal Citations0Total Downloads0Last 12 Months0Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385343091",
    "type": "article"
  },
  {
    "title": "Towards Efficient Coarse-grained Dialogue Response Selection",
    "doi": "https://doi.org/10.1145/3597609",
    "publication_date": "2023-08-04",
    "publication_year": 2023,
    "authors": "Tian Lan; Xian-Ling Mao; Wei Wei; Xiaoyan Gao; Heyan Huang",
    "corresponding_authors": "",
    "abstract": "Coarse-grained response selection is a fundamental and essential subsystem for the widely used retrieval-based chatbots, aiming to recall a coarse-grained candidate set from a large-scale dataset. The dense retrieval technique has recently been proven very effective in building such a subsystem. However, dialogue dense retrieval models face two problems in real scenarios: (1) the multi-turn dialogue history is re-computed in each turn, leading to inefficient inference; (2) the index storage of the offline index is enormous, significantly increasing the deployment cost. To address these problems, we propose an efficient coarse-grained response selection subsystem consisting of two novel methods. Specifically, to address the first problem, we propose the H ierarchical D ense R etrieval. It caches rich multi-vector representations of the dialogue history and only encodes the latest user’s utterance, leading to better inference efficiency. Then, to address the second problem, we design the D eep S emantic H ashing to reduce the index storage while effectively saving its recall accuracy notably. Extensive experimental results prove the advantages of the two proposed methods over previous works. Specifically, with the limited performance loss, our proposed coarse-grained response selection model achieves over 5x FLOPs speedup and over 192x storage compression ratio. Moreover, our source codes have been publicly released. 1",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385583991",
    "type": "article"
  },
  {
    "title": "BERD+: A Generic Sequential Recommendation Framework by Eliminating Unreliable Data with Item- and Attribute-level Signals",
    "doi": "https://doi.org/10.1145/3611008",
    "publication_date": "2023-08-10",
    "publication_year": 2023,
    "authors": "Yatong Sun; Xiaochun Yang; Zhu Sun; Bin Wang",
    "corresponding_authors": "",
    "abstract": "Most sequential recommendation systems (SRSs) predict the next item as the target for users given its preceding items as input, assuming the target is definitely related to its input. However, users may unintentionally click items that are inconsistent with their preference due to external factors, causing unreliable instances whose target mismatches the input. We, for the first time , verify SRSs can be misguided by such unreliable instances and design a generic SRS framework B y E liminating un R eliable D ata (BERD+), which can be flexibly plugged into existing SRSs. Specifically, BRED+ is guided with observations on the training process of instances: Unreliable instances generally have high training loss; high-loss instances are not necessarily unreliable but uncertain ones caused by blurry sequential patterns; and item attributes help rectify instance loss and uncertainty, but may also introduce disturbance. Accordingly, BERD+ models both the loss and uncertainty of each instance via a Gaussian distribution, whereby a heterogeneous uncertainty-aware graph convolution network is designed to learn accurate embeddings for different entities while reducing the disturbance caused by uncertain attribute values. Thereafter, an explicit preference extractor rectifies instance loss and uncertainty and reduces the disturbance caused by less-focused attribute types. Finally, instances with high loss and low uncertainty are eliminated as unreliable data. Extensive experiments verify the efficacy of BERD+.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4385724454",
    "type": "article"
  },
  {
    "title": "Policy-driven Knowledge Selection and Response Generation for Document-grounded Dialogue",
    "doi": "https://doi.org/10.1145/3617829",
    "publication_date": "2023-08-29",
    "publication_year": 2023,
    "authors": "Longxuan Ma; Jiapeng Li; Mingda Li; Weinan Zhang; Ting Liu",
    "corresponding_authors": "",
    "abstract": "Document-grounded dialogue (DGD) uses documents as external knowledge for dialogue generation. Correctly understanding the dialogue context is crucial for selecting knowledge from the document and generating proper responses. In this article, we propose using a dialogue policy to help the dialogue understanding in DGD. Our dialogue policy consists of two kinds of guiding signals: utterance function and topic transfer intent. The utterance function reflects the purpose and style of an utterance, and the topic transfer intent reflects the topic and content of an utterance. We propose a novel framework exploiting our dialogue policy for two core tasks in DGD, namely, knowledge selection (KS) and response generation (RG). The framework consists of two modules: the policy planner leverages policy-aware dialogue representation to select knowledge and predict the policy of the response; the generator uses policy/knowledge-aware dialogue representation for response generation. Our policy-driven model gets state-of-the-art performance on three public benchmarks, and we provide a detailed analysis of the experimental results. Our code/data will be released on GitHub.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386251317",
    "type": "article"
  },
  {
    "title": "Document Ranking on a Weight-Partitioned Signature File",
    "doi": null,
    "publication_date": "1996-01-01",
    "publication_year": 1996,
    "authors": "Dik Lun Lee; Liming Ren",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2416199683",
    "type": "article"
  },
  {
    "title": "Managing transient internetwork links in the Xerox internet",
    "doi": "https://doi.org/10.1145/1206.1484",
    "publication_date": "1984-08-23",
    "publication_year": 1984,
    "authors": "Siranush Radicati",
    "corresponding_authors": "Siranush Radicati",
    "abstract": "article Free Access Share on Managing transient internetwork links in the Xerox internet Author: Siranush Radicati Xerox Corp. Xerox Corp.View Profile Authors Info & Claims ACM Transactions on Information SystemsVolume 2Issue 3July 1984 pp 213–225https://doi.org/10.1145/1206.1484Published:23 August 1984Publication History 0citation298DownloadsMetricsTotal Citations0Total Downloads298Last 12 Months5Last 6 weeks2 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my Alerts New Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2611327776",
    "type": "article"
  },
  {
    "title": "Selected Papers from the Conference on Office Information Systems (Toronto, 1984) - Editor's Introduction.",
    "doi": null,
    "publication_date": "1984-01-01",
    "publication_year": 1984,
    "authors": "Clarence A. Ellis",
    "corresponding_authors": "Clarence A. Ellis",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W27730301",
    "type": "article"
  },
  {
    "title": "Editor's introduction",
    "doi": "https://doi.org/10.1145/1206.357412",
    "publication_date": "1984-08-23",
    "publication_year": 1984,
    "authors": "Clarence A. Ellis",
    "corresponding_authors": "Clarence A. Ellis",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4251949308",
    "type": "article"
  },
  {
    "title": "On Deductive Database with Incomplete Information.",
    "doi": null,
    "publication_date": "1995-01-01",
    "publication_year": 1995,
    "authors": "Quinzheng Kong; G. Chen",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2407552796",
    "type": "article"
  },
  {
    "title": "TOIS reviewers 2003--2005",
    "doi": "https://doi.org/10.1145/1125857.1125862",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Gary Marchionini",
    "corresponding_authors": "Gary Marchionini",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2024487449",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3289475",
    "publication_date": "2019-01-16",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article addresses the problem of matching the most similar data objects to a given query object. We adopt a generic model of similarity that involves the domain of objects and metric distance functions only. We examine the case of a large dataset ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232338356",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1125857",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Digital representations are widely used for audiovisual content, enabling the creation of large online repositories of video, allowing access such as video on demand. However, the ease of copying and distribution of digital video makes piracy a growing ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233298802",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1148020",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234623818",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1185877",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Document-centric XML is a mixture of text and structure. With the increased availability of document-centric XML documents comes a need for query facilities in which both structural constraints and constraints on the content of the documents can be ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235906764",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3368262",
    "publication_date": "2019-12-20",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In the personalized Point-Of-Interest (POI) (or venue) recommendation, the diversity of recommended POIs is an important aspect. Diversity is especially important when POIs are recommended in the target users’ frequently visited areas, because users are ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239052272",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1165774",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In information retrieval, retrieving relevant passages, as opposed to whole documents, not only directly benefits the end user by filtering out the irrelevant information within a long relevant document, but also improves retrieval accuracy in general. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240483844",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3211967",
    "publication_date": "2018-10-10",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "When content consumers explicitly judge content positively, we consider them to be engaged. Unfortunately, explicit user evaluations are difficult to collect, as they require user effort. Therefore, we propose to use device interactions as implicit ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242996601",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3306215",
    "publication_date": "2019-03-20",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Faceted search has become a common feature on most search interfaces in e-commerce websites, digital libraries, government’s open information portals, and so on. Beyond the existing studies on developing algorithms for faceted search and empirical ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244534736",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3146384",
    "publication_date": "2018-04-25",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Recommending venues or points-of-interest (POIs) is a hot topic in recent years, especially for tourism applications and mobile users. We propose and evaluate several suggestion methods, taking an effectiveness, feasibility, efficiency, and privacy ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245488230",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3357218",
    "publication_date": "2019-12-10",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We propose a Joint Neural Collaborative Filtering (J-NCF) method for recommender systems. The J-NCF model applies a joint neural network that couples deep feature learning and deep interaction modeling with a rating matrix. Deep feature learning ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248608063",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3320115",
    "publication_date": "2019-07-20",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254680408",
    "type": "paratext"
  },
  {
    "title": "Special Issue Proposal: Conversational Search and Recommendation",
    "doi": "https://doi.org/10.1145/3381926",
    "publication_date": "2020-05-07",
    "publication_year": 2020,
    "authors": "Claudia Hauff; Julia Kiseleva; Mark Sanderson; Hamed Zamani; Yongfeng Zhang",
    "corresponding_authors": "",
    "abstract": "The rapid growth in speech and small screen interfaces, particularly on mobile devices, has significantly influenced the way users interact with intelligent systems to satisfy their information needs. The growing interest in personal digital assistants, such as Amazon Alexa, Apple Siri, Google Assistant, and Microsoft Cortana, demonstrates the willingness of users to employ conversational interactions. In this special issue, we focus on interactions with information seeking goals. This includes conversational search and recommendation. Given the importance of the topic to both academia and industry and the recent availability of multiple public datasets in this area, we believe that the time is right to propose a special issue on this topic, and ACM Transactions on Information Systems is the perfect venue for it.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3041350820",
    "type": "article"
  },
  {
    "title": "TOIS reviewers",
    "doi": "https://doi.org/10.1145/944012.944018",
    "publication_date": "2003-10-01",
    "publication_year": 2003,
    "authors": "ACM Transactions on Information Systems staff",
    "corresponding_authors": "ACM Transactions on Information Systems staff",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239100332",
    "type": "article"
  },
  {
    "title": "Editorial Message from the New Editor-in-Chief",
    "doi": "https://doi.org/10.1145/3447945",
    "publication_date": "2021-07-15",
    "publication_year": 2021,
    "authors": "Min Zhang",
    "corresponding_authors": "Min Zhang",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3178063896",
    "type": "article"
  },
  {
    "title": "Author Index",
    "doi": "https://doi.org/10.1145/291128.291133",
    "publication_date": "1998-10-01",
    "publication_year": 1998,
    "authors": "W. Bruce Croft; Robert L. Allen; Alex Borgida; Mic Bowman; Shih‐Fu Chang; Prasun Dewan; Luis Gravano; Marti A. Hearst; Magid Igbaria; Matthias Jarke; Ray R. Larson; John J. Leggett; David Lewis; Paolo Paolini; George Robertson; Peter Scháuble; Alan F. Smeaton; Norbert Streitz",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4232362399",
    "type": "paratext"
  },
  {
    "title": "Author Index",
    "doi": "https://doi.org/10.1145/237496.237500",
    "publication_date": "1996-10-01",
    "publication_year": 1996,
    "authors": "Author Index",
    "corresponding_authors": "Author Index",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242743800",
    "type": "paratext"
  },
  {
    "title": "Introduction to the Special Issue on Social Science Perspectives on IS.",
    "doi": null,
    "publication_date": "1994-01-01",
    "publication_year": 1994,
    "authors": "Robert A. King",
    "corresponding_authors": "Robert A. King",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W189790480",
    "type": "article"
  },
  {
    "title": "Computer-Human Interaction and ACM TOIS - Editorial.",
    "doi": null,
    "publication_date": "1991-01-01",
    "publication_year": 1991,
    "authors": "Robert B. Allen",
    "corresponding_authors": "Robert B. Allen",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W85956047",
    "type": "article"
  }
]
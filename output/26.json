[
  {
    "title": "Multiplierless multiple constant multiplication",
    "doi": "https://doi.org/10.1145/1240233.1240234",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Yevgen Voronenko; Markus Püschel",
    "corresponding_authors": "",
    "abstract": "A variable can be multiplied by a given set of fixed-point constants using a multiplier block that consists exclusively of additions, subtractions, and shifts. The generation of a multiplier block from the set of constants is known as the multiple constant multiplication (MCM) problem. Finding the optimal solution, namely, the one with the fewest number of additions and subtractions, is known to be NP-complete. We propose a new algorithm for the MCM problem, which produces solutions that require up to 20% less additions and subtractions than the best previously known algorithm. At the same time our algorithm, in contrast to the closest competing algorithm, is not limited by the constant bitwidths. We present our algorithm using a unifying formal framework for the best, graph-based MCM algorithms and provide a detailed runtime analysis and experimental evaluation. We show that our algorithm can handle problem sizes as large as 100 32-bit constants in a time acceptable for most applications. The implementation of the new algorithm is available at www.spiral.net.",
    "cited_by_count": 414,
    "openalex_id": "https://openalex.org/W2001254103",
    "type": "article"
  },
  {
    "title": "Compressed representations of sequences and full-text indexes",
    "doi": "https://doi.org/10.1145/1240233.1240243",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Paolo Ferragina; Giovanni Manzini; Veli Mäkinen; Gonzalo Navarro",
    "corresponding_authors": "",
    "abstract": "Given a sequence S = s 1 s 2 … s n of integers smaller than r = O (polylog( n )), we show how S can be represented using nH 0 ( S ) + o ( n ) bits, so that we can know any s q , as well as answer rank and select queries on S , in constant time. H 0 ( S ) is the zero-order empirical entropy of S and nH 0 ( S ) provides an information-theoretic lower bound to the bit storage of any sequence S via a fixed encoding of its symbols. This extends previous results on binary sequences, and improves previous results on general sequences where those queries are answered in O (log r ) time. For larger r , we can still represent S in nH 0 ( S ) + o ( n log r ) bits and answer queries in O (log r /log log n ) time. Another contribution of this article is to show how to combine our compressed representation of integer sequences with a compression boosting technique to design compressed full-text indexes that scale well with the size of the input alphabet Σ. Specifically, we design a variant of the FM-index that indexes a string T [1, n ] within nH k ( T ) + o ( n ) bits of storage, where H k ( T ) is the k th-order empirical entropy of T . This space bound holds simultaneously for all k ≤ α log |Σ| n , constant 0 &lt; α &lt; 1, and |Σ| = O (polylog( n )). This index counts the occurrences of an arbitrary pattern P [1, p ] as a substring of T in O ( p ) time; it locates each pattern occurrence in O (log 1+ε n ) time for any constant 0 &lt; ε &lt; 1; and reports a text substring of length ℓ in O (ℓ + log 1+ε n ) time. Compared to all previous works, our index is the first that removes the alphabet-size dependance from all query times, in particular, counting time is linear in the pattern length. Still, our index uses essentially the same space of the k th-order entropy of the text T , which is the best space obtained in previous work. We can also handle larger alphabets of size |Σ| = O ( n β ), for any 0 &lt; β &lt; 1, by paying o ( n log|Σ|) extra space and multiplying all query times by O (log |Σ|/log log n ).",
    "cited_by_count": 388,
    "openalex_id": "https://openalex.org/W2107082304",
    "type": "article"
  },
  {
    "title": "Succinct indexable dictionaries with applications to encoding <i>k</i> -ary trees, prefix sums and multisets",
    "doi": "https://doi.org/10.1145/1290672.1290680",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Rajeev Raman; Venkatesh Raman; Srinivasa Rao Satti",
    "corresponding_authors": "",
    "abstract": "We consider the indexable dictionary problem, which consists of storing a set S ⊆ {0,…, m − 1} for some integer m while supporting the operations of rank( x ), which returns the number of elements in S that are less than x if x ∈ S , and −1 otherwise; and select( i ), which returns the i th smallest element in S . We give a data structure that supports both operations in O (1) time on the RAM model and requires B( n, m ) + o ( n ) + O (lg lg m ) bits to store a set of size n , where B( n, m ) = ⌊lg ( m / n )⌋ is the minimum number of bits required to store any n -element subset from a universe of size m . Previous dictionaries taking this space only supported (yes/no) membership queries in O (1) time. In the cell probe model we can remove the O (lg lg m ) additive term in the space bound, answering a question raised by Fich and Miltersen [1995] and Pagh [2001]. We present extensions and applications of our indexable dictionary data structure, including: —an information-theoretically optimal representation of a k -ary cardinal tree that supports standard operations in constant time; —a representation of a multiset of size n from {0,…, m − 1} in B( n, m + n ) + o ( n ) bits that supports (appropriate generalizations of) rank and select operations in constant time; and + O (lg lg m ) —a representation of a sequence of n nonnegative integers summing up to m in B( n, m + n ) + o ( n ) bits that supports prefix sum queries in constant time.",
    "cited_by_count": 373,
    "openalex_id": "https://openalex.org/W1974033543",
    "type": "article"
  },
  {
    "title": "Coresets, sparse greedy approximation, and the Frank-Wolfe algorithm",
    "doi": "https://doi.org/10.1145/1824777.1824783",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Kenneth L. Clarkson",
    "corresponding_authors": "Kenneth L. Clarkson",
    "abstract": "The problem of maximizing a concave function f(x) in the unit simplex Δ can be solved approximately by a simple greedy algorithm. For given k , the algorithm can find a point x ( k ) on a k -dimensional face of Δ, such that f ( x ( k ) ≥ f(x * ) − O (1/ k ). Here f ( x * ) is the maximum value of f in Δ, and the constant factor depends on f . This algorithm and analysis were known before, and related to problems of statistics and machine learning, such as boosting, regression, and density mixture estimation. In other work, coming from computational geometry, the existence of ϵ-coresets was shown for the minimum enclosing ball problem by means of a simple greedy algorithm. Similar greedy algorithms, which are special cases of the Frank-Wolfe algorithm, were described for other enclosure problems. Here these results are tied together, stronger convergence results are reviewed, and several coreset bounds are generalized or strengthened.",
    "cited_by_count": 368,
    "openalex_id": "https://openalex.org/W2109706083",
    "type": "article"
  },
  {
    "title": "Skip graphs",
    "doi": "https://doi.org/10.1145/1290672.1290674",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "James Aspnes; Gauri Shah",
    "corresponding_authors": "",
    "abstract": "Skip graphs are a novel distributed data structure, based on skip lists, that provide the full functionality of a balanced tree in a distributed system where resources are stored in separate nodes that may fail at any time. They are designed for use in searching peer-to-peer systems, and by providing the ability to perform queries based on key ordering, they improve on existing search tools that provide only hash table functionality. Unlike skip lists or other tree data structures, skip graphs are highly resilient, tolerating a large fraction of failed nodes without losing connectivity. In addition, simple and straightforward algorithms can be used to construct a skip graph, insert new nodes into it, search it, and detect and repair errors within it introduced due to node failures.",
    "cited_by_count": 331,
    "openalex_id": "https://openalex.org/W2293292771",
    "type": "article"
  },
  {
    "title": "Fully Functional Static and Dynamic Succinct Trees",
    "doi": "https://doi.org/10.1145/2601073",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Gonzalo Navarro; Kunihiko Sadakane",
    "corresponding_authors": "",
    "abstract": "We propose new succinct representations of ordinal trees and match various space/time lower bounds. It is known that any n -node static tree can be represented in 2 n + o ( n ) bits so that a number of operations on the tree can be supported in constant time under the word-RAM model. However, the data structures are complicated and difficult to dynamize. We propose a simple and flexible data structure, called the range min-max tree , that reduces the large number of relevant tree operations considered in the literature to a few primitives that are carried out in constant time on polylog-sized trees. The result is extended to trees of arbitrary size, retaining constant time and reaching 2 n + O ( n /polylog( n )) bits of space. This space is optimal for a core subset of the operations supported and significantly lower than in any previous proposal. For the dynamic case, where insertion/deletion (indels) of nodes is allowed, the existing data structures support a very limited set of operations. Our data structure builds on the range min-max tree to achieve 2 n + O ( n /log n ) bits of space and O (log n ) time for all operations supported in the static scenario, plus indels. We also propose an improved data structure using 2 n + O ( n log log n /log n ) bits and improving the time to the optimal O (log n /log log n ) for most operations. We extend our support to forests, where whole subtrees can be attached to or detached from others, in time O (log 1+ϵ n ) for any ϵ &gt; 0. Such operations had not been considered before. Our techniques are of independent interest. An immediate derivation yields an improved solution to range minimum/maximum queries where consecutive elements differ by ± 1, achieving n + O ( n /polylog( n )) bits of space. A second one stores an array of numbers supporting operations sum and search and limited updates, in optimal time O (log n /log log n ). A third one allows representing dynamic bitmaps and sequences over alphabets of size σ, supporting rank/select and indels, within zero-order entropy bounds and time O (log n log σ/(log log n ) 2 ) for all operations. This time is the optimal O (log n /log log n ) on bitmaps and polylog-sized alphabets. This improves upon the best existing bounds for entropy-bounded storage of dynamic sequences, compressed full-text self-indexes, and compressed-space construction of the Burrows-Wheeler transform.",
    "cited_by_count": 206,
    "openalex_id": "https://openalex.org/W2147935317",
    "type": "article"
  },
  {
    "title": "Algorithmic construction of sets for <i>k</i> -restrictions",
    "doi": "https://doi.org/10.1145/1150334.1150336",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Noga Alon; Dana Moshkovitz; Muli Safra",
    "corresponding_authors": "",
    "abstract": "This work addresses k-restriction problems , which unify combinatorial problems of the following type: The goal is to construct a short list of strings in Σ m that satisfies a given set of k -wise demands. For every k positions and every demand, there must be at least one string in the list that satisfies the demand at these positions. Problems of this form frequently arise in different fields in Computer Science.The standard approach for deterministically solving such problems is via almost k -wise independence or k -wise approximations for other distributions. We offer a generic algorithmic method that yields considerably smaller constructions. To this end, we generalize a previous work of Naor et al. [1995]. Among other results, we enhance the combinatorial objects in the heart of their method, called splitters, and construct multi-way splitters , using a new discrete version of the topological Necklace Splitting Theorem [Alon 1987].We utilize our methods to show improved constructions for group testing [Ngo and Du 2000] and generalized hashing [Alon et al. 2003], and an improved inapproximability result for SET-COVER under the assumption P ≠ NP .",
    "cited_by_count": 308,
    "openalex_id": "https://openalex.org/W2126479983",
    "type": "article"
  },
  {
    "title": "Fast sparse matrix multiplication",
    "doi": "https://doi.org/10.1145/1077464.1077466",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Raphael Yuster; Uri Zwick",
    "corresponding_authors": "",
    "abstract": "Let A and B two n × n matrices over a ring R (e.g., the reals or the integers) each containing at most m nonzero elements. We present a new algorithm that multiplies A and B using O ( m 0.7 n 1.2 + n 2+ o (1) ) algebraic operations (i.e., multiplications, additions and subtractions) over R . The naïve matrix multiplication algorithm, on the other hand, may need to perform Ω( mn ) operations to accomplish the same task. For m ≤ n 1.14 , the new algorithm performs an almost optimal number of only n 2+ o (1) operations. For m ≤ n 1.68 , the new algorithm is also faster than the best known matrix multiplication algorithm for dense matrices which uses O ( n 2.38 ) algebraic operations. The new algorithm is obtained using a surprisingly straightforward combination of a simple combinatorial idea and existing fast rectangular matrix multiplication algorithms. We also obtain improved algorithms for the multiplication of more than two sparse matrices. As the known fast rectangular matrix multiplication algorithms are far from being practical, our result, at least for now, is only of theoretical value.",
    "cited_by_count": 258,
    "openalex_id": "https://openalex.org/W2043670592",
    "type": "article"
  },
  {
    "title": "Algorithms for power savings",
    "doi": "https://doi.org/10.1145/1290672.1290678",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Sandy Irani; Sandeep K. Shukla; Rajesh K. Gupta",
    "corresponding_authors": "",
    "abstract": "This article examines two different mechanisms for saving power in battery-operated embedded systems. The first strategy is that the system can be placed in a sleep state if it is idle. However, a fixed amount of energy is required to bring the system back into an active state in which it can resume work. The second way in which power savings can be achieved is by varying the speed at which jobs are run. We utilize a power consumption curve P ( s ) which indicates the power consumption level given a particular speed. We assume that P ( s ) is convex, nondecreasing, and nonnegative for s ≥ 0. The problem is to schedule arriving jobs in a way that minimizes total energy use and so that each job is completed after its release time and before its deadline. We assume that all jobs can be preempted and resumed at no cost. Although each problem has been considered separately, this is the first theoretical analysis of systems that can use both mechanisms. We give an offline algorithm that is within a factor of 2 of the optimal algorithm. We also give an online algorithm with a constant competitive ratio.",
    "cited_by_count": 230,
    "openalex_id": "https://openalex.org/W2145398804",
    "type": "article"
  },
  {
    "title": "A 4 <i>k</i> <sup>2</sup> kernel for feedback vertex set",
    "doi": "https://doi.org/10.1145/1721837.1721848",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Stéphan Thomassé",
    "corresponding_authors": "Stéphan Thomassé",
    "abstract": "We prove that given an undirected graph G on n vertices and an integer k , one can compute, in polynomial time in n , a graph G′ with at most 4 k 2 vertices and an integer k′ such that G has a feedback vertex set of size at most k iff G′ has a feedback vertex set of size at most k′ . This result improves a previous O ( k 11 ) kernel of Burrage et al., and a more recent cubic kernel of Bodlaender. This problem was communicated by Fellows.",
    "cited_by_count": 205,
    "openalex_id": "https://openalex.org/W1974810008",
    "type": "article"
  },
  {
    "title": "An optimal decomposition algorithm for tree edit distance",
    "doi": "https://doi.org/10.1145/1644015.1644017",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Erik D. Demaine; Shay Mozes; Benjamin Rossman; Oren Weimann",
    "corresponding_authors": "",
    "abstract": "The edit distance between two ordered rooted trees with vertex labels is the minimum cost of transforming one tree into the other by a sequence of elementary operations consisting of deleting and relabeling existing nodes, as well as inserting new nodes. In this article, we present a worst-case O ( n 3 )-time algorithm for the problem when the two trees have size n , improving the previous best O ( n 3 log n )-time algorithm. Our result requires a novel adaptive strategy for deciding how a dynamic program divides into subproblems, together with a deeper understanding of the previous algorithms for the problem. We prove the optimality of our algorithm among the family of decomposition strategy algorithms—which also includes the previous fastest algorithms—by tightening the known lower bound of Ω( n 2 log 2 n ) to Ω( n 3 ), matching our algorithm's running time. Furthermore, we obtain matching upper and lower bounds for decomposition strategy algorithms of Θ( nm 2 (1 + log n / m )) when the two trees have sizes m and n and m &lt; n .",
    "cited_by_count": 204,
    "openalex_id": "https://openalex.org/W2171643895",
    "type": "article"
  },
  {
    "title": "Cache-Oblivious Algorithms",
    "doi": "https://doi.org/10.1145/2071379.2071383",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Matteo Frigo; Charles E. Leiserson; Harald Prokop; Sridhar Ramachandran",
    "corresponding_authors": "",
    "abstract": "This article presents asymptotically optimal algorithms for rectangular matrix transpose, fast Fourier transform (FFT), and sorting on computers with multiple levels of caching. Unlike previous optimal algorithms, these algorithms are cache oblivious : no variables dependent on hardware parameters, such as cache size and cache-line length, need to be tuned to achieve optimality. Nevertheless, these algorithms use an optimal amount of work and move data optimally among multiple levels of cache. For a cache with size M and cache-line length B where M = Ω ( B 2 ), the number of cache misses for an m × n matrix transpose is Θ (1 + mn / B ). The number of cache misses for either an n -point FFT or the sorting of n numbers is Θ (1 + ( n / B )(1 + log M n )). We also give a Θ ( mnp )-work algorithm to multiply an m × n matrix by an n × p matrix that incurs Θ (1 + ( mn + np + mp )/ B + mnp / B √ M ) cache faults. We introduce an “ideal-cache” model to analyze our algorithms. We prove that an optimal cache-oblivious algorithm designed for two levels of memory is also optimal for multiple levels and that the assumption of optimal replacement in the ideal-cache model can be simulated efficiently by LRU replacement. We offer empirical evidence that cache-oblivious algorithms perform well in practice.",
    "cited_by_count": 190,
    "openalex_id": "https://openalex.org/W2052196304",
    "type": "article"
  },
  {
    "title": "Energy-efficient algorithms for flow time minimization",
    "doi": "https://doi.org/10.1145/1290672.1290686",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Susanne Albers; Hiroshi Fujiwara",
    "corresponding_authors": "",
    "abstract": "We study scheduling problems in battery-operated computing devices, aiming at schedules with low total energy consumption. While most of the previous work has focused on finding feasible schedules in deadline-based settings, in this article we are interested in schedules that guarantee good response times. More specifically, our goal is to schedule a sequence of jobs on a variable-speed processor so as to minimize the total cost consisting of the energy consumption and the total flow time of all jobs. We first show that when the amount of work, for any job, may take an arbitrary value, then no online algorithm can achieve a constant competitive ratio. Therefore, most of the article is concerned with unit-size jobs. We devise a deterministic constant competitive online algorithm and show that the offline problem can be solved in polynomial time.",
    "cited_by_count": 188,
    "openalex_id": "https://openalex.org/W2048730512",
    "type": "article"
  },
  {
    "title": "Faster Parameterized Algorithms Using Linear Programming",
    "doi": "https://doi.org/10.1145/2566616",
    "publication_date": "2014-10-30",
    "publication_year": 2014,
    "authors": "Daniel Lokshtanov; N. S. Narayanaswamy; Venkatesh Raman; M. S. Ramanujan; Saket Saurabh",
    "corresponding_authors": "",
    "abstract": "We investigate the parameterized complexity of Vertex Cover parameterized by the difference between the size of the optimal solution and the value of the linear programming (LP) relaxation of the problem. By carefully analyzing the change in the LP value in the branching steps, we argue that combining previously known preprocessing rules with the most straightforward branching algorithm yields an O *(2.618 k ) algorithm for the problem. Here, k is the excess of the vertex cover size over the LP optimum, and we write O *( f ( k )) for a time complexity of the form O ( f ( k ) n O (1) ). We proceed to show that a more sophisticated branching algorithm achieves a running time of O *(2.3146 k ). Following this, using previously known as well as new reductions, we give O *(2.3146 k ) algorithms for the parameterized versions of Above Guarantee Vertex Cover , Odd Cycle Transversal , Split Vertex Deletion, and Almost 2-SAT , and O *(1.5214 k ) algorithms for König Vertex Deletion and Vertex Cover parameterized by the size of the smallest odd cycle transversal and König vertex deletion set. These algorithms significantly improve the best known bounds for these problems. The most notable improvement among these is the new bound for Odd Cycle Transversal —this is the first algorithm that improves on the dependence on k of the seminal O *(3 k ) algorithm of Reed, Smith, and Vetta. Finally, using our algorithm, we obtain a kernel for the standard parameterization of Vertex Cover with at most 2 k − c log k vertices. Our kernel is simpler than previously known kernels achieving the same size bound.",
    "cited_by_count": 185,
    "openalex_id": "https://openalex.org/W2166115470",
    "type": "article"
  },
  {
    "title": "Algorithms for distributed functional monitoring",
    "doi": "https://doi.org/10.1145/1921659.1921667",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Graham Cormode; S. Muthukrishnan; Ke Yi",
    "corresponding_authors": "",
    "abstract": "Consider the following problem: We have k players each receiving a stream of items, and communicating with a central coordinator. Let the multiset of items received by player i up until time t be A i ( t ). The coordinator's task is to monitor a given function f computed over the union of the inputs ∪ i A i ( t ), continuously at all times t . The goal is to minimize the number of bits communicated between the players and the coordinator. Of interest is the approximate version where the coordinator outputs 1 if f ≥ τ and 0 if f ≤ (1−ϵ)τ. This defines the ( k , f ,τ,ϵ) distributed functional monitoring problem. Functional monitoring problems are fundamental in distributed systems, in particular sensor networks, where we must minimize communication; they also connect to the well-studied streaming model and communication complexity. Yet few formal bounds are known for functional monitoring. We give upper and lower bounds for the ( k , f ,τ,ϵ) problem for some of the basic f 's. In particular, we study the frequency moments F p for p =0,1,2. For F 0 and F 1 , we obtain monitoring algorithms with cost almost the same as algorithms that compute the function for a single instance of time. However, for F 2 the monitoring problem seems to be much harder than computing the function for a single time instance. We give a carefully constructed multiround algorithm that uses “sketch summaries” at multiple levels of details and solves the ( k , F 2 ,τ,ϵ) problem with communication Õ ( k 2 /ϵ + k 3/2 /ϵ 3 ). Our algorithmic techniques are likely to be useful for other functional monitoring problems as well.",
    "cited_by_count": 182,
    "openalex_id": "https://openalex.org/W3137191742",
    "type": "article"
  },
  {
    "title": "The string edit distance matching problem with moves",
    "doi": "https://doi.org/10.1145/1186810.1186812",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Graham Cormode; S. Muthukrishnan",
    "corresponding_authors": "",
    "abstract": "The edit distance between two strings S and R is defined to be the minimum number of character inserts, deletes, and changes needed to convert R to S . Given a text string t of length n , and a pattern string p of length m , informally, the string edit distance matching problem is to compute the smallest edit distance between p and substrings of t . We relax the problem so that: (a) we allow an additional operation, namely, substring moves ; and (b) we allow approximation of this string edit distance. Our result is a near-linear time deterministic algorithm to produce a factor of O (log n log* n ) approximation to the string edit distance with moves. This is the first known significantly subquadratic algorithm for a string edit distance problem in which the distance involves nontrivial alignments. Our results are obtained by embedding strings into L 1 vector space using a simplified parsing technique, which we call edit-sensitive parsing (ESP).",
    "cited_by_count": 169,
    "openalex_id": "https://openalex.org/W1982055477",
    "type": "article"
  },
  {
    "title": "Tight bounds for worst-case equilibria",
    "doi": "https://doi.org/10.1145/1186810.1186814",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Artur Czumaj; Berthold Vöcking",
    "corresponding_authors": "",
    "abstract": "We study the problem of traffic routing in noncooperative networks. In such networks, users may follow selfish strategies to optimize their own performance measure and therefore, their behavior does not have to lead to optimal performance of the entire network. In this article we investigate the worst-case coordination ratio, which is a game-theoretic measure aiming to reflect the price of selfish routing. Following a line of previous work, we focus on the most basic networks consisting of parallel links with linear latency functions. Our main result is that the worst-case coordination ratio on m parallel links of possibly different speeds is Θ(log m /log log log m ). In fact, we are able to give an exact description of the worst-case coordination ratio, depending on the number of links and ratio of speed of the fastest link over the speed of the slowest link. For example, for the special case in which all m parallel links have the same speed, we can prove that the worst-case coordination ratio is Γ (−1) ( m ) + Θ(1), with Γ denoting the Gamma (factorial) function. Our bounds entirely resolve an open problem posed recently by Koutsoupias and Papadimitriou [1999].",
    "cited_by_count": 166,
    "openalex_id": "https://openalex.org/W1966132455",
    "type": "article"
  },
  {
    "title": "A better approximation ratio for the vertex cover problem",
    "doi": "https://doi.org/10.1145/1597036.1597045",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "George Karakostas",
    "corresponding_authors": "George Karakostas",
    "abstract": "We reduce the approximation factor for the vertex cover to 2 − Θ (1/√log n ) (instead of the previous 2 − Θ ln ln n /2ln n obtained by Bar-Yehuda and Even [1985] and Monien and Speckenmeyer [1985]). The improvement of the vanishing factor comes as an application of the recent results of Arora et al. [2004] that improved the approximation factor of the sparsest cut and balanced cut problems. In particular, we use the existence of two big and well-separated sets of nodes in the solution of the semidefinite relaxation for balanced cut, proven by Arora et al. [2004]. We observe that a solution of the semidefinite relaxation for vertex cover, when strengthened with the triangle inequalities, can be transformed into a solution of a balanced cut problem, and therefore the existence of big well-separated sets in the sense of Arora et al. [2004] translates into the existence of a big independent set.",
    "cited_by_count": 151,
    "openalex_id": "https://openalex.org/W2030970869",
    "type": "article"
  },
  {
    "title": "Uniform deterministic dictionaries",
    "doi": "https://doi.org/10.1145/1328911.1328912",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Milan Ružić",
    "corresponding_authors": "Milan Ružić",
    "abstract": "We present a new analysis of the well-known family of multiplicative hash functions, and improved deterministic algorithms for selecting “good” hash functions. The main motivation is realization of deterministic dictionaries with fast lookups and reasonably fast updates. The model of computation is the Word RAM, and it is assumed that the machine word-size matches the size of keys in bits. Many of the modern solutions to the dictionary problem are weakly nonuniform, that is, they require a number of constants to be computed at “compile time” for the stated time bounds to hold. The currently fastest deterministic dictionary uses constants not known to be computable in polynomial time. In contrast, our dictionaries do not require any special constants or instructions, and running times are independent of word (and key) length. Our family of dynamic dictionaries achieves a performance of the following type: lookups in time O ( t ) and updates in amortized time O ( n 1/ t ), for an appropriate parameter function t . Update procedures require division, whereas searching uses multiplication only.",
    "cited_by_count": 149,
    "openalex_id": "https://openalex.org/W2109089989",
    "type": "article"
  },
  {
    "title": "Improved algorithms for orienteering and related problems",
    "doi": "https://doi.org/10.1145/2229163.2229167",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Chandra Chekuri; Nitish Korula; Martin Pál",
    "corresponding_authors": "",
    "abstract": "In this article, we consider the orienteering problem in undirected and directed graphs and obtain improved approximation algorithms. The point to point-orienteering problem is the following: Given an edge-weighted graph G =( V, E ) (directed or undirected), two nodes s, t ∈ V and a time limit B , find an s - t walk in G of total length at most B that maximizes the number of distinct nodes visited by the walk. This problem is closely related to tour problems such as TSP as well as network design problems such as k -MST. Orienteering with time-windows is the more general problem in which each node v has a specified time-window [ R ( v ), D ( v )] and a node v is counted as visited by the walk only if v is visited during its time-window. We design new and improved algorithms for the orienteering problem and orienteering with time-windows. Our main results are the following: — A (2+ϵ) approximation for orienteering in undirected graphs, improving upon the 3-approximation of Bansal et al. [2004]. — An O (log 2 OPT) approximation for orienteering in directed graphs, where OPT ≤ n is the number of vertices visited by an optimal solution. Previously, only a quasipolynomial-time algorithm due to Chekuri and Pál [2005] achieved a polylogarithmic approximation (a ratio of O (log OPT)). — Given an α approximation for orienteering, we show an O (α ċ max{log OPT, log l max / l min }) approximation for orienteering with time-windows, where l max and l min are the lengths of the longest and shortest time-windows respectively.",
    "cited_by_count": 146,
    "openalex_id": "https://openalex.org/W2622090745",
    "type": "article"
  },
  {
    "title": "Kernelization Lower Bounds Through Colors and IDs",
    "doi": "https://doi.org/10.1145/2650261",
    "publication_date": "2014-10-30",
    "publication_year": 2014,
    "authors": "Michael Dom; Daniel Lokshtanov; Saket Saurabh",
    "corresponding_authors": "",
    "abstract": "In parameterized complexity, each problem instance comes with a parameter k , and a parameterized problem is said to admit a polynomial kernel if there are polynomial time preprocessing rules that reduce the input instance to an instance with size polynomial in k . Many problems have been shown to admit polynomial kernels, but it is only recently that a framework for showing the nonexistence of polynomial kernels for specific problems has been developed by Bodlaender et al. [2009] and Fortnow and Santhanam [2008]. With few exceptions, all known kernelization lower bounds results have been obtained by directly applying this framework. In this article, we show how to combine these results with combinatorial reductions that use colors and IDs in order to prove kernelization lower bounds for a variety of basic problems. To follow we give a summary of our main results. All results are under the assumption that the polynomial hierarchy does not collapse to the third level. —We show that the Steiner Tree problem parameterized by the number of terminals and solution size k , and the Connected Vertex Cover and Capacitated Vertex Cover problems do not admit a polynomial kernel. The two latter results are surprising because the closely related Vertex Cover problem admits a kernel with at most 2 k vertices. —Alon and Gutner [2008] obtain a k poly ( h ) kernel for Dominating Set in H -Minor Free Graphs parameterized by h = | H | and solution size k , and ask whether kernels of smaller size exist. We partially resolve this question by showing that Dominating Set in H -Minor Free Graphs does not admit a kernel with size polynomial in k + h . —Harnik and Naor [2007] obtain a “compression algorithm” for the Sparse Subset Sum problem. We show that their algorithm is essentially optimal by showing that the instances cannot be compressed further. —The Hitting Set and Set Cover problems are among the most-studied problems in algorithmics. Both problems admit a kernel of size k O ( d ) when parameterized by solution size k and maximum set size d . We show that neither of them, along with the Unique Coverage and Bounded Rank Disjoint Sets problems, admits a polynomial kernel. The existence of polynomial kernels for several of the problems mentioned previously was an open problem explicitly stated in the literature [Alon and Gutner 2008; Betzler 2006; Guo and Niedermeier 2007; Guo et al. 2007; Moser et al. 2007]. Many of our results also rule out the existence of compression algorithms, a notion similar to kernelization defined by Harnik and Naor [2007], for the problems in question.",
    "cited_by_count": 139,
    "openalex_id": "https://openalex.org/W2052712469",
    "type": "article"
  },
  {
    "title": "How to meet asynchronously (almost) everywhere",
    "doi": "https://doi.org/10.1145/2344422.2344427",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Jurek Czyzowicz; Andrzej Pelc; Arnaud Labourel",
    "corresponding_authors": "",
    "abstract": "Two mobile agents (robots) with distinct labels have to meet in an arbitrary, possibly infinite, unknown connected graph or in an unknown connected terrain in the plane. Agents are modeled as points, and the route of each of them only depends on its label and on the unknown environment. The actual walk of each agent also depends on an asynchronous adversary that may arbitrarily vary the speed of the agent, stop it, or even move it back and forth, as long as the walk of the agent is continuous, does not leave its route and covers all of it. Meeting in a graph means that both agents must be at the same time in some node or in some point inside an edge of the graph, while meeting in a terrain means that both agents must be at the same time in some point of the terrain. Does there exist a deterministic algorithm that allows any two agents to meet in any unknown environment in spite of this very powerful adversary? We give deterministic rendezvous algorithms for agents starting at arbitrary nodes of any anonymous connected graph (finite or infinite) and for agents starting at any interior points with rational coordinates in any closed region of the plane with path-connected interior. In the geometric scenario agents may have different compasses and different units of length. While our algorithms work in a very general setting -- agents can, indeed, meet almost everywhere -- we show that none of these few limitations imposed on the environment can be removed. On the other hand, our algorithm also guarantees the following approximate rendezvous for agents starting at arbitrary interior points of a terrain as previously stated agents will eventually get to within an arbitrarily small positive distance from each other.",
    "cited_by_count": 137,
    "openalex_id": "https://openalex.org/W2621800709",
    "type": "article"
  },
  {
    "title": "Optimal Bounds for Johnson-Lindenstrauss Transforms and Streaming Problems with Subconstant Error",
    "doi": "https://doi.org/10.1145/2483699.2483706",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "T. S. Jayram; David P. Woodruff",
    "corresponding_authors": "",
    "abstract": "The Johnson-Lindenstrauss transform is a dimensionality reduction technique with a wide range of applications to theoretical computer science. It is specified by a distribution over projection matrices from R n → R k where k n and states that k = O ( ε −2 log 1/ δ ) dimensions suffice to approximate the norm of any fixed vector in R n to within a factor of 1 ± ε with probability at least 1 − δ . In this article, we show that this bound on k is optimal up to a constant factor, improving upon a previous Ω (( ε −2 log 1/ δ )/log(1/ ε )) dimension bound of Alon. Our techniques are based on lower bounding the information cost of a novel one-way communication game and yield the first space lower bounds in a data stream model that depend on the error probability δ . For many streaming problems, the most naïve way of achieving error probability δ is to first achieve constant probability, then take the median of O (log 1/ δ ) independent repetitions. Our techniques show that for a wide range of problems, this is in fact optimal! As an example, we show that estimating the ℓ p -distance for any p ∈ [0,2] requires Ω ( ε −2 log n log 1/ δ ) space, even for vectors in {0,1} n . This is optimal in all parameters and closes a long line of work on this problem. We also show the number of distinct elements requires Ω ( ε −2 log 1/ δ + log n ) space, which is optimal if ε −2 = Ω (log n ). We also improve previous lower bounds for entropy in the strict turnstile and general turnstile models by a multiplicative factor of Ω (log 1/ δ ). Finally, we give an application to one-way communication complexity under product distributions, showing that, unlike the case of constant δ , the VC-dimension does not characterize the complexity when δ = o (1).",
    "cited_by_count": 124,
    "openalex_id": "https://openalex.org/W2132032691",
    "type": "article"
  },
  {
    "title": "An Almost Optimal Unrestricted Fast Johnson-Lindenstrauss Transform",
    "doi": "https://doi.org/10.1145/2483699.2483701",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Nir Ailon; Edo Liberty",
    "corresponding_authors": "",
    "abstract": "The problems of random projections and sparse reconstruction have much in common and individually received much attention. Surprisingly, until now they progressed in parallel and remained mostly separate. Here, we employ new tools from probability in Banach spaces that were successfully used in the context of sparse reconstruction to advance on an open problem in random pojection. In particular, we generalize and use an intricate result by Rudelson and Veshynin [2008] for sparse reconstruction which uses Dudley’s theorem for bounding Gaussian processes. Our main result states that any set of N = exp( Õ ( n )) real vectors in n dimensional space can be linearly mapped to a space of dimension k = O (log N polylog( n )), while (1) preserving the pairwise distances among the vectors to within any constant distortion and (2) being able to apply the transformation in time O ( n log n ) on each vector. This improves on the best known bound N = exp( Õ ( n 1/2 )) achieved by Ailon and Liberty [2009] and N = exp( Õ ( n 1/3 )) by Ailon and Chazelle [2010]. The dependence in the distortion constant however is suboptimal, and since the publication of an early version of the work, the gap between upper and lower bounds has been considerably tightened obtained by Krahmer and Ward [2011]. For constant distortion, this settles the open question posed by these authors up to a polylog( n ) factor while considerably simplifying their constructions.",
    "cited_by_count": 123,
    "openalex_id": "https://openalex.org/W2116019049",
    "type": "article"
  },
  {
    "title": "On Problems as Hard as CNF-SAT",
    "doi": "https://doi.org/10.1145/2925416",
    "publication_date": "2016-05-24",
    "publication_year": 2016,
    "authors": "Marek Cygan; Holger Dell; Daniel Lokshtanov; Dániel Marx; Jesper Nederlof; Yoshio Okamoto; Ramamohan Paturi; Saket Saurabh; Magnus Wahlström",
    "corresponding_authors": "",
    "abstract": "The field of exact exponential time algorithms for non-deterministic polynomial-time hard problems has thrived since the mid-2000s. While exhaustive search remains asymptotically the fastest known algorithm for some basic problems, non-trivial exponential time algorithms have been found for a myriad of problems, including G raph C oloring , H amiltonian P ath , D ominating S et , and 3-CNF-S at . In some instances, improving these algorithms further seems to be out of reach. The CNF-S at problem is the canonical example of a problem for which the trivial exhaustive search algorithm runs in time O (2 n ), where n is the number of variables in the input formula. While there exist non-trivial algorithms for CNF-S at that run in time o (2 n ), no algorithm was able to improve the growth rate 2 to a smaller constant, and hence it is natural to conjecture that 2 is the optimal growth rate. The strong exponential time hypothesis (SETH) by Impagliazzo and Paturi [JCSS 2001] goes a little bit further and asserts that, for every ϵ &lt; 1, there is a (large) integer k such that k -CNF-S at cannot be computed in time 2 ϵ n . In this article, we show that, for every ϵ &lt; 1, the problems H itting S et , S et S plitting , and NAE-S at cannot be computed in time O (2 ϵ n ) unless SETH fails. Here n is the number of elements or variables in the input. For these problems, we actually get an equivalence to SETH in a certain sense. We conjecture that SETH implies a similar statement for S et C over and prove that, under this assumption, the fastest known algorithms for S teiner T ree , C onnected V ertex C over , S et P artitioning , and the pseudo-polynomial time algorithm for S ubset S um cannot be significantly improved. Finally, we justify our assumption about the hardness of S et C over by showing that the parity of the number of solutions to S et C over cannot be computed in time O (2 ϵ n ) for any ϵ &lt; 1 unless SETH fails.",
    "cited_by_count": 123,
    "openalex_id": "https://openalex.org/W2404960361",
    "type": "article"
  },
  {
    "title": "Finding small separators in linear time via treewidth reduction",
    "doi": "https://doi.org/10.1145/2500119",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Dáaniel Marx; Barry O’Sullivan; Igor Razgon",
    "corresponding_authors": "",
    "abstract": "We present a method for reducing the treewidth of a graph while preserving all of its minimal s - t separators up to a certain fixed size k . This technique allows us to solve s - t Cut and Multicut problems with various additional restrictions (e.g., the vertices being removed from the graph form an independent set or induce a connected graph) in linear time for every fixed number k of removed vertices. Our results have applications for problems that are not directly defined by separators, but the known solution methods depend on some variant of separation. For example, we can solve similarly restricted generalizations of Bipartization (delete at most k vertices from G to make it bipartite) in almost linear time for every fixed number k of removed vertices. These results answer a number of open questions in the area of parameterized complexity. Furthermore, our technique turns out to be relevant for ( H , C , K )- and ( H , C ,≤K)-coloring problems as well, which are cardinality constrained variants of the classical H -coloring problem. We make progress in the classification of the parameterized complexity of these problems by identifying new cases that can be solved in almost linear time for every fixed cardinality bound.",
    "cited_by_count": 120,
    "openalex_id": "https://openalex.org/W1981591809",
    "type": "article"
  },
  {
    "title": "Constraint Solving via Fractional Edge Covers",
    "doi": "https://doi.org/10.1145/2636918",
    "publication_date": "2014-08-25",
    "publication_year": 2014,
    "authors": "Martin Grohe; Dániel Marx",
    "corresponding_authors": "",
    "abstract": "Many important combinatorial problems can be modeled as constraint satisfaction problems. Hence, identifying polynomial-time solvable classes of constraint satisfaction problems has received a lot of attention. In this article, we are interested in structural properties that can make the problem tractable. So far, the largest structural class that is known to be polynomial-time solvable is the class of bounded hypertree width instances introduced by Gottlob et al. [2002]. Here we identify a new class of polynomial-time solvable instances: those having bounded fractional edge cover number. Combining hypertree width and fractional edge cover number, we then introduce the notion of fractional hypertree width. We prove that constraint satisfaction problems with bounded fractional hypertree width can be solved in polynomial time (provided that the tree decomposition is given in the input). Together with a recent approximation algorithm for finding such decompositions [Marx 2010], it follows that bounded fractional hypertree width is now the most generally known structural property that guarantees polynomial-time solvability.",
    "cited_by_count": 114,
    "openalex_id": "https://openalex.org/W2624220145",
    "type": "article"
  },
  {
    "title": "Approximation Algorithms for Computing Maximin Share Allocations",
    "doi": "https://doi.org/10.1145/3147173",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Georgios Amanatidis; Evangelos Markakis; Afshin Nikzad; Amin Saberi",
    "corresponding_authors": "",
    "abstract": "We study the problem of computing maximin share guarantees, a recently introduced fairness notion. Given a set of $n$ agents and a set of goods, the maximin share of a single agent is the best that she can guarantee to herself, if she would be allowed to partition the goods in any way she prefers, into $n$ bundles, and then receive her least desirable bundle. The objective then in our problem is to find a partition, so that each agent is guaranteed her maximin share. In settings with indivisible goods, such allocations are not guaranteed to exist, so we resort to approximation algorithms. Our main result is a $2/3$-approximation, that runs in polynomial time for any number of agents. This improves upon the algorithm of Procaccia and Wang, which also produces a $2/3$-approximation but runs in polynomial time only for a constant number of agents. To achieve this, we redesign certain parts of their algorithm. Furthermore, motivated by the apparent difficulty, both theoretically and experimentally, in finding lower bounds on the existence of approximate solutions, we undertake a probabilistic analysis. We prove that in randomly generated instances, with high probability there exists a maximin share allocation. This can be seen as a justification of the experimental evidence reported in relevant works. Finally, we provide further positive results for two special cases that arise from previous works. The first one is the intriguing case of $3$ agents, for which it is already known that exact maximin share allocations do not always exist (contrary to the case of $2$ agents). We provide a $7/8$-approximation algorithm, improving the previously known result of $3/4$. The second case is when all item values belong to $\\{0, 1, 2\\}$, extending the $\\{0, 1\\}$ setting studied in Bouveret and Lema\\^itre. We obtain an exact algorithm for any number of agents in this case.",
    "cited_by_count": 105,
    "openalex_id": "https://openalex.org/W1542025417",
    "type": "article"
  },
  {
    "title": "Linear Kernels and Single-Exponential Algorithms Via Protrusion Decompositions",
    "doi": "https://doi.org/10.1145/2797140",
    "publication_date": "2015-12-08",
    "publication_year": 2015,
    "authors": "Eun Jung Kim; Alexander Langer; Christophe Paul; Felix Reidl; Peter Rossmanith; Ignasi Sau; Somnath Sikdar",
    "corresponding_authors": "",
    "abstract": "We present a linear-time algorithm to compute a decomposition scheme for graphs G that have a set X ⊆ V ( G ), called a treewidth-modulator , such that the treewidth of G − X is bounded by a constant. Our decomposition, called a protrusion decomposition , is the cornerstone in obtaining the following two main results. Our first result is that any parameterized graph problem (with parameter k ) that has a finite integer index and such that Y es -instances have a treewidth-modulator of size O ( k ) admits a linear kernel on the class of H -topological-minor-free graphs, for any fixed graph H . This result partially extends previous meta-theorems on the existence of linear kernels on graphs of bounded genus and H -minor-free graphs. Let F be a fixed finite family of graphs containing at least one planar graph. Given an n -vertex graph G and a non-negative integer k , P lanar - F -D eletion asks whether G has a set X ⊆ V ( G ) such that | X | ⩽ k and G − X is H -minor-free for every H ϵ F . As our second application, we present the first single-exponential algorithm to solve P lanar - F -D eletion . Namely, our algorithm runs in time 2 O ( k ) · n 2 , which is asymptotically optimal with respect to k . So far, single-exponential algorithms were only known for special cases of the family F .",
    "cited_by_count": 104,
    "openalex_id": "https://openalex.org/W1838629830",
    "type": "article"
  },
  {
    "title": "Solving Connectivity Problems Parameterized by Treewidth in Single Exponential Time",
    "doi": "https://doi.org/10.1145/3506707",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Marek Cygan; Jesper Nederlof; Marcin Pilipczuk; Michał Pilipczuk; Johan M. M. van Rooij; Jakub Onufry Wojtaszczyk",
    "corresponding_authors": "",
    "abstract": "For the vast majority of local problems on graphs of small treewidth (where, by local we mean that a solution can be verified by checking separately the neighbourhood of each vertex), standard dynamic programming techniques give c tw | V | O(1) time algorithms, where tw is the treewidth of the input graph G = ( V,E ) and c is a constant. On the other hand, for problems with a global requirement (usually connectivity) the best–known algorithms were naive dynamic programming schemes running in at least tw tw time. We bridge this gap by introducing a technique we named Cut&amp;Count that allows to produce c tw | V | O(1) time Monte-Carlo algorithms for most connectivity-type problems, including Hamiltonian Path , Steiner Tree , Feedback Vertex Set and Connected Dominating Set . These results have numerous consequences in various fields, like parameterized complexity, exact and approximate algorithms on planar and H -minor-free graphs and exact algorithms on graphs of bounded degree. The constant c in our algorithms is in all cases small, and in several cases we are able to show that improving those constants would cause the Strong Exponential Time Hypothesis to fail. In all these fields we are able to improve the best-known results for some problems. Also, looking from a more theoretical perspective, our results are surprising since the equivalence relation that partitions all partial solutions with respect to extendability to global solutions seems to consist of at least tw tw equivalence classes for all these problems. Our results answer an open problem raised by Lokshtanov, Marx and Saurabh [SODA’11]. In contrast to the problems aimed at minimizing the number of connected components that we solve using Cut&amp;Count as mentioned above, we show that, assuming the Exponential Time Hypothesis, the aforementioned gap cannot be bridged for some problems that aim to maximize the number of connected components like Cycle Packing .",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2950987206",
    "type": "article"
  },
  {
    "title": "Fixed-parameter algorithms for ( <i>k</i> , <i>r</i> )-center in planar graphs and map graphs",
    "doi": "https://doi.org/10.1145/1077464.1077468",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Erik D. Demaine; Fedor V. Fomin; MohammadTaghi Hajiaghayi; Dimitrios M. Thilikos",
    "corresponding_authors": "",
    "abstract": "The ( k , r )-center problem asks whether an input graph G has ≤ k vertices (called centers ) such that every vertex of G is within distance ≤ r from some center. In this article, we prove that the ( k , r )-center problem, parameterized by k and R , is fixed-parameter tractable (FPT) on planar graphs, i.e., it admits an algorithm of complexity f ( k , r ) n O (1) where the function f is independent of n . In particular, we show that f ( k,r ) = 2 O ( r log r ) √k , where the exponent of the exponential term grows sublinearly in the number of centers. Moreover, we prove that the same type of FPT algorithms can be designed for the more general class of map graphs introduced by Chen, Grigni, and Papadimitriou. Our results combine dynamic-programming algorithms for graphs of small branchwidth and a graph-theoretic result bounding this parameter in terms of k and r . Finally, a byproduct of our algorithm is the existence of a PTAS for the r -domination problem in both planar graphs and map graphs.Our approach builds on the seminal results of Robertson and Seymour on Graph Minors, and as a result is much more powerful than the previous machinery of Alber et al. for exponential speedup on planar graphs. To demonstrate the versatility of our results, we show how our algorithms can be extended to general parameters that are “large” on grids. In addition, our use of branchwidth instead of the usual treewidth allows us to obtain much faster algorithms, and requires more complicated dynamic programming than the standard leaf/introduce/forget/join structure of nice tree decompositions. Our results are also unique in that they apply to classes of graphs that are not minor-closed, namely, constant powers of planar graphs and map graphs.",
    "cited_by_count": 154,
    "openalex_id": "https://openalex.org/W2007069176",
    "type": "article"
  },
  {
    "title": "Nearest-neighbor-preserving embeddings",
    "doi": "https://doi.org/10.1145/1273340.1273347",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Piotr Indyk; Assaf Naor",
    "corresponding_authors": "",
    "abstract": "In this article we introduce the notion of nearest-neighbor-preserving embeddings. These are randomized embeddings between two metric spaces which preserve the (approximate) nearest-neighbors. We give two examples of such embeddings for Euclidean metrics with low “intrinsic” dimension. Combining the embeddings with known data structures yields the best-known approximate nearest-neighbor data structures for such metrics.",
    "cited_by_count": 144,
    "openalex_id": "https://openalex.org/W2024930473",
    "type": "article"
  },
  {
    "title": "Computing almost shortest paths",
    "doi": "https://doi.org/10.1145/1103963.1103968",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Michael Elkin",
    "corresponding_authors": "Michael Elkin",
    "abstract": "We study the &lt;i&gt;s-sources almost shortest paths&lt;/i&gt; (abbreviated &lt;i&gt;s-ASP&lt;/i&gt;) problem. Given an unweighted graph &lt;i&gt;G&lt;/i&gt; &amp;equals; (&lt;i&gt;V,E&lt;/i&gt;), and a subset &lt;i&gt;S&lt;/i&gt; &amp;sube; &lt;i&gt;V&lt;/i&gt; of &lt;i&gt;s&lt;/i&gt; nodes, the goal is to compute almost shortest paths between all the pairs of nodes &lt;i&gt;S&lt;/i&gt; &amp;times; &lt;i&gt;V&lt;/i&gt;. We devise an algorithm with running time &lt;i&gt;O&lt;/i&gt;(&amp;mid;&lt;i&gt;E&lt;/i&gt;&amp;mid;&lt;i&gt;n&lt;/i&gt;&lt;sup&gt;&amp;rho;&lt;/sup&gt; &amp;plus; &lt;i&gt;s&lt;/i&gt; &amp;middot; &lt;i&gt;n&lt;/i&gt;&lt;sup&gt;1 &amp;plus; &amp;zeta;)&lt;/sup&gt; for this problem that computes the paths &lt;i&gt;P&lt;/i&gt;&lt;sub&gt;&lt;i&gt;u,w&lt;/i&gt;&lt;/sub&gt; for all pairs (&lt;i&gt;u,w&lt;/i&gt;) &amp;isin; &lt;i&gt;S&lt;/i&gt; &amp;times; &lt;i&gt;V&lt;/i&gt; such that the length of &lt;i&gt;P&lt;/i&gt;&lt;sub&gt;&lt;i&gt;u,w&lt;/i&gt;&lt;/sub&gt; is at most (1 &amp;plus; &amp;epsi;) &lt;i&gt;d&lt;/i&gt;&lt;sub&gt;&lt;i&gt;G&lt;/i&gt;&lt;/sub&gt;(&lt;i&gt;u,w&lt;/i&gt;) &amp;plus; &amp;beta;(&amp;zeta;,&amp;rho;,&amp;epsi;), and &amp;beta;(&amp;zeta;,&amp;rho;,&amp;epsi;) is constant when &amp;zeta;, &amp;rho;, and &amp;epsi; are arbitrarily small constants. We also devise a distributed protocol for the &lt;i&gt;s&lt;/i&gt;-ASP problem that computes the paths &lt;i&gt;P&lt;/i&gt;&lt;inf&gt;&lt;i&gt;u,w&lt;/i&gt;&lt;/inf&gt; as above, and has time and communication complexities of &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;s&lt;/i&gt; &amp;middot; &lt;i&gt;Diam(G)&lt;/i&gt; &amp;plus; &lt;i&gt;n&lt;/i&gt;&lt;sup&gt;1 &amp;plus; &amp;zeta;/2&lt;/sup&gt;) (respectively, &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;s&lt;/i&gt; &amp;middot; &lt;i&gt;Diam(G)&lt;/i&gt; log&lt;sup&gt;3&lt;/sup&gt; &lt;i&gt;n&lt;/i&gt; &amp;plus; &lt;i&gt;n&lt;/i&gt;&lt;sup&gt;1 &amp;plus; &amp;zeta;/2&lt;/sup&gt; log &lt;i&gt;n&lt;/i&gt;)) and &lt;i&gt;O&lt;/i&gt;(&amp;mid;&lt;i&gt;E&lt;/i&gt;&amp;mid; &lt;i&gt;n&lt;/i&gt;&lt;sup&gt;&amp;rho;&lt;/sup&gt; &amp;plus; &lt;i&gt;s&lt;/i&gt; &amp;middot; &lt;i&gt;n&lt;/i&gt;&lt;sup&gt;1 &amp;plus; &amp;zeta;)&lt;/sup&gt; (respectively, &lt;i&gt;O&lt;/i&gt;(&amp;mid;&lt;i&gt;E&lt;/i&gt;&amp;mid; &lt;i&gt;n&lt;/i&gt;&lt;sup&gt;&amp;rho;&lt;/sup&gt; &amp;plus; &lt;i&gt;s&lt;/i&gt; &amp;middot; &lt;i&gt;n&lt;/i&gt;&lt;sup&gt;1 &amp;plus; &amp;zeta;&lt;/sup&gt; &amp;plus; &lt;i&gt;n&lt;/i&gt;&lt;sup&gt;1 &amp;plus; &amp;rho; &amp;plus; &amp;zeta;(&amp;rho; &amp;minus; &amp;zeta;/2)/2)) in the synchronous (respectively asynchronous) setting. Our sequential algorithm, as well as the distributed protocol, is based on a novel algorithm for constructing (1 &amp;plus; &amp;epsi;, &amp;beta;(&amp;zeta;,&amp;rho;, &amp;epsi;))-spanners of size &lt;i&gt;O&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt;&lt;sup&gt;1 &amp;plus; &amp;zeta;&lt;/sup&gt;), developed in this article. This algorithm has running time of &lt;i&gt;O&lt;/i&gt;(&amp;mid;&lt;i&gt;E&lt;/i&gt;&amp;mid; &lt;i&gt;n&lt;/i&gt;&lt;sup&gt;&amp;rho;&lt;/sup&gt;), which is significantly faster than the previously known algorithm given in Elkin and Peleg [2001], whose running time is &lt;i&gt;&amp;Otilde;&lt;/i&gt;(&lt;i&gt;n&lt;/i&gt;&lt;sup&gt;2 &amp;plus; &amp;rho;&lt;/sup&gt;). We also develop the first distributed protocol for constructing (1 &amp;plus; &amp;epsi;,&amp;beta;)-spanners. The communication complexity of this protocol is near optimal.",
    "cited_by_count": 138,
    "openalex_id": "https://openalex.org/W1987669032",
    "type": "article"
  },
  {
    "title": "Dynamic entropy-compressed sequences and full-text indexes",
    "doi": "https://doi.org/10.1145/1367064.1367072",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Veli Mäkinen; Gonzalo Navarro",
    "corresponding_authors": "",
    "abstract": "We give new solutions to the Searchable Partial Sums with Indels problem. Given a sequence of n k -bit numbers, we present a structure taking kn + o ( kn ) bits of space, able of performing operations sum , search , insert , and delete , all in O (log n ) worst-case time, for any k = O (log n ). This extends previous results by Hon et al. [2003c] achieving the same space and O (log n /log log n ) time complexities for the queries, yet offering complexities for insert and delete that are amortized and worse than ours, and supported only for k = O (1). Our result matches an existing lower bound for large values of k . We also give new solutions to the Dynamic Sequence problem. Given a sequence of n symbols in the range [1,σ] with binary zero-order entropy H 0 , we present a dynamic data structure that requires nH 0 + o ( n log σ) bits of space, which is able of performing rank and select , as well as inserting and deleting symbols at arbitrary positions, in O (log n log σ) time. Our result is the first entropy-bound dynamic data structure for rank and select over general sequences. In the case σ = 2, where both previous problems coincide, we improve the dynamic solution of Hon et al. [2003c] in that we compress the sequence. The only previous result with entropy-bound space for dynamic binary sequences is by Blandford and Blelloch [2004], which has the same complexities as our structure, but does not achieve constant 1 multiplying the entropy term in the space complexity. Finally, we present a new dynamic compressed full-text self-index, for a collection of texts over an alphabet of size σ, of overall length n and h th order empirical entropy H h . The index requires nH h + o ( n log σ) bits of space, for any h ≤ α log sigma n and constant 0 &lt; α &lt; 1. It can count the number of occurrences of a pattern of length m in time O ( m log n log σ). Each such occurrence can be reported in O (log 2 n log log n ) time, and displaying a context of length ℓ from a text takes time O (log n (ℓ log σ + log n log log n )). Insertion/deletion of a text to/from the collection takes O (log n log σ) time per symbol. This significantly improves the space of a previous result by Chan et al. [2004] in exchange for a slight time complexity penalty. We achieve at the same time the first dynamic index requiring essentially nH h bits of space, and the first construction of a compressed full-text self-index within that working space. Previous results achieve at best O ( nH h space with constants larger than 1 [Ferragina and Manzini 2000; Arroyuelo and Navarro 2005] and higher time complexities. An important result we prove in this paper is that the wavelet tree of the Burrows-Wheeler transform of a text, if compressed with a technique that achieves zero-order compression locally (e.g., Raman et al. [2002]), automatically achieves h th order entropy space for any h . This unforeseen relation is essential for the results of the previous paragraph, but it also derives into significant simplifications on many existing static compressed full-text self-indexes that build on wavelet trees.",
    "cited_by_count": 137,
    "openalex_id": "https://openalex.org/W2027244654",
    "type": "article"
  },
  {
    "title": "Approximating rank-width and clique-width quickly",
    "doi": "https://doi.org/10.1145/1435375.1435385",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Sang‐il Oum",
    "corresponding_authors": "Sang‐il Oum",
    "abstract": "Rank-width was defined by Oum and Seymour [2006] to investigate clique-width. They constructed an algorithm that either outputs a rank-decomposition of width at most f ( k ) for some function f or confirms that rank-width is larger than k in time O (| V | 9 log | V |) for an input graph G = ( V , E ) and a fixed k . We develop three separate algorithms of this kind with faster running time. We construct an O (| V | 4 )-time algorithm with f ( k ) = 3 k + 1 by constructing a subroutine for the previous algorithm; we avoid generic algorithms minimizing submodular functions used by Oum and Seymour. Another one is an O (| V | 3 )-time algorithm with f ( k ) = 24 k , achieved by giving a reduction from graphs to binary matroids; then we use an approximation algorithm for matroid branch-width by Hliněný [2005]. Finally we construct an O (| V | 3 )-time algorithm with f ( k ) = 3 k − 1 by combining the ideas of the two previously cited papers.",
    "cited_by_count": 137,
    "openalex_id": "https://openalex.org/W2171507355",
    "type": "article"
  },
  {
    "title": "Maintaining information in fully dynamic trees with top trees",
    "doi": "https://doi.org/10.1145/1103963.1103966",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Stephen Alstrup; Jacob Holm; Kristian de Lichtenberg; Mikkel Thorup",
    "corresponding_authors": "",
    "abstract": "We design top trees as a new simpler interface for data structures maintaining information in a fully dynamic forest. We demonstrate how easy and versatile they are to use on a host of different applications. For example, we show how to maintain the diameter, center, and median of each tree in the forest. The forest can be updated by insertion and deletion of edges and by changes to vertex and edge weights. Each update is supported in O (log n ) time, where n is the size of the tree(s) involved in the update. Also, we show how to support nearest common ancestor queries and level ancestor queries with respect to arbitrary roots in O (log n ) time. Finally, with marked and unmarked vertices, we show how to compute distances to a nearest marked vertex. The latter has applications to approximate nearest marked vertex in general graphs, and thereby to static optimization problems over shortest path metrics.Technically speaking, top trees are easily implemented either with Frederickson's [1997a] topology trees or with Sleator and Tarjan's [1983] dynamic trees. However, we claim that the interface is simpler for many applications, and indeed our new bounds are quadratic improvements over previous bounds where they exist.",
    "cited_by_count": 133,
    "openalex_id": "https://openalex.org/W1990488650",
    "type": "article"
  },
  {
    "title": "Convergence time to Nash equilibrium in load balancing",
    "doi": "https://doi.org/10.1145/1273340.1273348",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Eyal Even-Dar; Alex Kesselman; Yishay Mansour",
    "corresponding_authors": "",
    "abstract": "We study the number of steps required to reach a pure Nash equilibrium in a load balancing scenario where each job behaves selfishly and attempts to migrate to a machine which will minimize its cost. We consider a variety of load balancing models, including identical, restricted, related, and unrelated machines. Our results have a crucial dependence on the weights assigned to jobs. We consider arbitrary weights, integer weights, k distinct weights, and identical (unit) weights. We look both at an arbitrary schedule (where the only restriction is that a job migrates to a machine which lowers its cost) and specific efficient schedulers (e.g., allowing the largest weight job to move first). A by-product of our results is establishing a connection between various scheduling models and the game-theoretic notion of potential games. We show that load balancing in unrelated machines is a generalized ordinal potential game, load balancing in related machines is a weighted potential game, and load balancing in related machines and unit weight jobs is an exact potential game.",
    "cited_by_count": 133,
    "openalex_id": "https://openalex.org/W2072951587",
    "type": "article"
  },
  {
    "title": "Clustering for metric and nonmetric distance measures",
    "doi": "https://doi.org/10.1145/1824777.1824779",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Marcel R. Ackermann; Johannes Blömer; Christian Sohler",
    "corresponding_authors": "",
    "abstract": "We study a generalization of the k -median problem with respect to an arbitrary dissimilarity measure D. Given a finite set P of size n , our goal is to find a set C of size k such that the sum of errors D( P,C ) = ∑ p ∈ P min c ∈ C {D( p,c )} is minimized. The main result in this article can be stated as follows: There exists a (1+ϵ)-approximation algorithm for the k -median problem with respect to D, if the 1-median problem can be approximated within a factor of (1+ϵ) by taking a random sample of constant size and solving the 1-median problem on the sample exactly. This algorithm requires time n 2 O ( mk log( mk /ϵ)), where m is a constant that depends only on ϵ and D. Using this characterization, we obtain the first linear time (1+ϵ)-approximation algorithms for the k -median problem in an arbitrary metric space with bounded doubling dimension, for the Kullback-Leibler divergence (relative entropy), for the Itakura-Saito divergence, for Mahalanobis distances, and for some special cases of Bregman divergences. Moreover, we obtain previously known results for the Euclidean k -median problem and the Euclidean k -means problem in a simplified manner. Our results are based on a new analysis of an algorithm of Kumar et al. [2004].",
    "cited_by_count": 123,
    "openalex_id": "https://openalex.org/W2620598837",
    "type": "article"
  },
  {
    "title": "A general approach to online network optimization problems",
    "doi": "https://doi.org/10.1145/1198513.1198522",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Noga Alon; Baruch Awerbuch; Yossi Azar; Niv Buchbinder; Joseph Naor",
    "corresponding_authors": "",
    "abstract": "We study a wide range of online graph and network optimization problems, focusing on problems that arise in the study of connectivity and cuts in graphs. In a general online network design problem, we have a communication network known to the algorithm in advance. What is not known in advance are the connectivity (bandwidth) or cut demands between vertices in the network which arrive online.We develop a unified framework for designing online algorithms for problems involving connectivity and cuts. We first present a general O (log m )-competitive deterministic algorithm for generating a fractional solution that satisfies the online connectivity or cut demands, where m is the number of edges in the graph. This may be of independent interest for solving fractional online bandwidth allocation problems, and is applicable to both directed and undirected graphs. We then show how to obtain integral solutions via an online rounding of the fractional solution. This part of the framework is problem dependent, and applies various tools including results on approximate max-flow min-cut for multicommodity flow, the Hierarchically Separated Trees (HST) method and its extensions, certain rounding techniques for dependent variables, and Räcke's new hierarchical decomposition of graphs.Specifically, our results for the integral case include an O (log m log n )-competitive randomized algorithm for the online nonmetric facility location problem and for a generalization of the problem called the multicast problem. In the nonmetric facility location problem, m is the number of facilities and n is the number of clients. The competitive ratio is nearly tight. We also present an O (log 2 n log k )-competitive randomized algorithm for the online group Steiner problem in trees and an O (log 3 n log k )-competitive randomized algorithm for the problem in general graphs, where n is the number of vertices in the graph and k is the number of groups. Finally, we design a deterministic O (log 3 n log log n )-competitive algorithm for the online multi-cut problem.",
    "cited_by_count": 117,
    "openalex_id": "https://openalex.org/W1973444128",
    "type": "article"
  },
  {
    "title": "Resilient dictionaries",
    "doi": "https://doi.org/10.1145/1644015.1644016",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Irene Finocchi; Fabrizio Grandoni; Giuseppe F. Italiano",
    "corresponding_authors": "",
    "abstract": "We address the problem of designing data structures in the presence of faults that may arbitrarily corrupt memory locations. More precisely, we assume that an adaptive adversary can arbitrarily overwrite the content of up to δ memory locations, that corrupted locations cannot be detected, and that only O (1) memory locations are safe. In this framework, we call a data structure resilient if it is able to operate correctly (at least) on the set of uncorrupted values. We present a resilient dictionary, implementing search, insert, and delete operations. Our dictionary has O (log n + δ) expected amortized time per operation, and O ( n ) space complexity, where n denotes the current number of keys in the dictionary. We also describe a deterministic resilient dictionary, with the same amortized cost per operation over a sequence of at least δ ϵ operations, where ϵ &gt; 0 is an arbitrary constant. Finally, we show that any resilient comparison-based dictionary must take Ω(log n + δ) expected time per search. Our results are achieved by means of simple, new techniques which might be of independent interest for the design of other resilient algorithms.",
    "cited_by_count": 117,
    "openalex_id": "https://openalex.org/W2295958421",
    "type": "article"
  },
  {
    "title": "The priority R-tree",
    "doi": "https://doi.org/10.1145/1328911.1328920",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Lars Arge; Mark de Berg; Herman Haverkort; Ke Yi",
    "corresponding_authors": "",
    "abstract": "We present the priority R-tree, or PR-tree, which is the first R-tree variant that always answers a window query using O (( N / B ) 1−1/ d + T / B ) I/Os, where N is the number of d -dimensional (hyper-) rectangles stored in the R-tree, B is the disk block size, and T is the output size. This is provably asymptotically optimal and significantly better than other R-tree variants, where a query may visit all N / B leaves in the tree even when T = 0. We also present an extensive experimental study of the practical performance of the PR-tree using both real-life and synthetic data. This study shows that the PR-tree performs similarly to the best-known R-tree variants on real-life and relatively nicely distributed data, but outperforms them significantly on more extreme data.",
    "cited_by_count": 115,
    "openalex_id": "https://openalex.org/W2024199467",
    "type": "article"
  },
  {
    "title": "Combinatorial bounds via measure and conquer",
    "doi": "https://doi.org/10.1145/1435375.1435384",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Fedor V. Fomin; Fabrizio Grandoni; A. V. Pyatkin; Alexey A. Stepanov",
    "corresponding_authors": "",
    "abstract": "We provide an algorithm listing all minimal dominating sets of a graph on n vertices in time O (1.7159 n ). This result can be seen as an algorithmic proof of the fact that the number of minimal dominating sets in a graph on n vertices is at most 1.7159 n , thus improving on the trivial O (2 n /√ n ) bound. Our result makes use of the measure-and-conquer technique which was recently developed in the area of exact algorithms. Based on this result, we derive an O (2.8718 n ) algorithm for the domatic number problem.",
    "cited_by_count": 113,
    "openalex_id": "https://openalex.org/W2085870956",
    "type": "article"
  },
  {
    "title": "Getting the best response for your erg",
    "doi": "https://doi.org/10.1145/1367064.1367078",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Kirk Pruhs; Patchrawat Uthaisombut; Gerhard J. Woeginger",
    "corresponding_authors": "",
    "abstract": "We consider the speed scaling problem of minimizing the average response time of a collection of dynamically released jobs subject to a constraint A on energy used. We propose an algorithmic approach in which an energy optimal schedule is computed for a huge A , and then the energy optimal schedule is maintained as A decreases. We show that this approach yields an efficient algorithm for equi-work jobs. We note that the energy optimal schedule has the surprising feature that the job speeds are not monotone functions of the available energy. We then explain why this algorithmic approach is problematic for arbitrary work jobs. Finally, we explain how to use the algorithm for equi-work jobs to obtain an algorithm for arbitrary work jobs that is O (1)-approximate with respect to average response time, given an additional factor of (1 + ϵ) energy.",
    "cited_by_count": 113,
    "openalex_id": "https://openalex.org/W2152575945",
    "type": "article"
  },
  {
    "title": "Multicommodity demand flow in a tree and packing integer programs",
    "doi": "https://doi.org/10.1145/1273340.1273343",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Chandra Chekuri; Marcelo Mydlarz; F. Bruce Shepherd",
    "corresponding_authors": "",
    "abstract": "We consider requests for capacity in a given tree network T = ( V , E ) where each edge e of the tree has some integer capacity u e . Each request f is a node pair with an integer demand d f and a profit w f which is obtained if the request is satisfied. The objective is to find a set of demands that can be feasibly routed in the tree and which provides a maximum profit. This generalizes well-known problems, including the knapsack and b -matching problems. When all demands are 1, we have the integer multicommodity flow problem. Garg et al. [1997] had shown that this problem is NP-hard and gave a 2-approximation algorithm for the cardinality case (all profits are 1) via a primal-dual algorithm. Our main result establishes that the integrality gap of the natural linear programming relaxation is at most 4 for the case of arbitrary profits. Our proof is based on coloring paths on trees and this has other applications for wavelength assignment in optical network routing. We then consider the problem with arbitrary demands. When the maximum demand d max is at most the minimum edge capacity u min , we show that the integrality gap of the LP is at most 48. This result is obtained by showing that the integrality gap for the demand version of such a problem is at most 11.542 times that for the unit-demand case. We use techniques of Kolliopoulos and Stein [2004, 2001] to obtain this. We also obtain, via this method, improved algorithms for line and ring networks. Applications and connections to other combinatorial problems are discussed.",
    "cited_by_count": 111,
    "openalex_id": "https://openalex.org/W2170344325",
    "type": "article"
  },
  {
    "title": "Low distortion spanners",
    "doi": "https://doi.org/10.1145/1644015.1644022",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Seth Pettie",
    "corresponding_authors": "Seth Pettie",
    "abstract": "A spanner of an undirected unweighted graph is a subgraph that approximates the distance metric of the original graph with some specified accuracy. Specifically, we say H ⊆ G is an f -spanner of G if any two vertices u , v at distance d in G are at distance at most f ( d ) in H . There is clearly some trade-off between the sparsity of H and the distortion function f , though the nature of the optimal trade-off is still poorly understood. In this article we present a simple, modular framework for constructing sparse spanners that is based on interchangable components called connection schemes . By assembling connection schemes in different ways we can recreate the additive 2- and 6-spanners of Aingworth et al. [1999] and Baswana et al. [2009], and give spanners whose multiplicative distortion quickly tends toward 1. Our results rival the simplicity of all previous algorithms and provide substantial improvements (up to a doubly exponential reduction in edge density) over the comparable spanners of Elkin and Peleg [2004] and Thorup and Zwick [2006].",
    "cited_by_count": 110,
    "openalex_id": "https://openalex.org/W2061507472",
    "type": "article"
  },
  {
    "title": "Achieving anonymity via clustering",
    "doi": "https://doi.org/10.1145/1798596.1798602",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Gagan Aggarwal; Rina Panigrahy‎; Tomás Feder; Dilys Thomas; Krishnaram Kenthapadi; Samir Khuller; An Zhu",
    "corresponding_authors": "",
    "abstract": "Publishing data for analysis from a table containing personal records, while maintaining individual privacy, is a problem of increasing importance today. The traditional approach of deidentifying records is to remove identifying fields such as social security number, name, etc. However, recent research has shown that a large fraction of the U.S. population can be identified using nonkey attributes (called quasi-identifiers) such as date of birth, gender, and zip code. The k -anonymity model protects privacy via requiring that nonkey attributes that leak information are suppressed or generalized so that, for every record in the modified table, there are at least k −1 other records having exactly the same values for quasi-identifiers. We propose a new method for anonymizing data records, where quasi-identifiers of data records are first clustered and then cluster centers are published. To ensure privacy of the data records, we impose the constraint that each cluster must contain no fewer than a prespecified number of data records. This technique is more general since we have a much larger choice for cluster centers than k -anonymity. In many cases, it lets us release a lot more information without compromising privacy. We also provide constant factor approximation algorithms to come up with such a clustering. This is the first set of algorithms for the anonymization problem where the performance is independent of the anonymity parameter k . We further observe that a few outlier points can significantly increase the cost of anonymization. Hence, we extend our algorithms to allow an ϵ fraction of points to remain unclustered, that is, deleted from the anonymized publication. Thus, by not releasing a small fraction of the database records, we can ensure that the data published for analysis has less distortion and hence is more useful. Our approximation algorithms for new clustering objectives are of independent interest and could be applicable in other clustering scenarios as well.",
    "cited_by_count": 110,
    "openalex_id": "https://openalex.org/W2069845605",
    "type": "article"
  },
  {
    "title": "Additive spanners and (α, β)-spanners",
    "doi": "https://doi.org/10.1145/1868237.1868242",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Surender Baswana; Telikepalli Kavitha; Kurt Mehlhorn; Seth Pettie",
    "corresponding_authors": "",
    "abstract": "An (α, β)-spanner of an unweighted graph G is a subgraph H that distorts distances in G up to a multiplicative factor of α and an additive term β. It is well known that any graph contains a (multiplicative) (2 k −1, 0)-spanner of size O ( n 1+1/ k ) and an (additive) (1,2)-spanner of size O ( n 3/2 ). However no other additive spanners are known to exist. In this article we develop a couple of new techniques for constructing (α, β)-spanners. Our first result is an additive (1,6)-spanner of size O ( n 4/3 ). The construction algorithm can be understood as an economical agent that assigns costs and values to paths in the graph, purchasing affordable paths and ignoring expensive ones, which are intuitively well approximated by paths already purchased. We show that this path buying algorithm can be parameterized in different ways to yield other sparseness-distortion tradeoffs. Our second result addresses the problem of which (α, β)-spanners can be computed efficiently, ideally in linear time. We show that, for any k , a ( k , k −1)-spanner with size O ( kn 1+1/ k ) can be found in linear time, and, further, that in a distributed network the algorithm terminates in a constant number of rounds. Previous spanner constructions with similar performance had roughly twice the multiplicative distortion.",
    "cited_by_count": 109,
    "openalex_id": "https://openalex.org/W2099237198",
    "type": "article"
  },
  {
    "title": "Provably good moving least squares",
    "doi": "https://doi.org/10.1145/1361192.1361195",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Ravikrishna Kolluri",
    "corresponding_authors": "Ravikrishna Kolluri",
    "abstract": "We analyze a moving least squares (MLS) interpolation scheme for reconstructing a surface from point cloud data. The input is a sufficiently dense set of sample points that lie near a closed surface F with approximate surface normals. The output is a reconstructed surface passing near the sample points. For each sample point s in the input, we define a linear point function that represents the local shape of the surface near s . These point functions are combined by a weighted average, yielding a three-dimensional function I . The reconstructed surface is implicitly defined as the zero set of I . We prove that the function I is a good approximation to the signed distance function of the sampled surface F and that the reconstructed surface is geometrically close to and isotopic to F . Our sampling requirements are derived from the local feature size function used in Delaunay-based surface reconstruction algorithms. Our analysis can handle noisy data provided the amount of noise in the input dataset is small compared to the feature size of F .",
    "cited_by_count": 106,
    "openalex_id": "https://openalex.org/W2617010780",
    "type": "article"
  },
  {
    "title": "Compact name-independent routing with minimum stretch",
    "doi": "https://doi.org/10.1145/1367064.1367077",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Ittai Abraham; Cyril Gavoille; Dahlia Malkhi; Noam Nisan; Mikkel Thorup",
    "corresponding_authors": "",
    "abstract": "Given a weighted undirected network with arbitrary node names, we present a compact routing scheme, using a Õ (√n,) space routing table at each node, and routing along paths of stretch 3, that is, at most thrice as long as the minimum cost paths. This is optimal in a very strong sense. It is known that no compact routing using o ( n ) space per node can route with stretch below 3. Also, it is known that any stretch below 5 requires Ω(√ n ,)space per node.",
    "cited_by_count": 101,
    "openalex_id": "https://openalex.org/W1967359086",
    "type": "article"
  },
  {
    "title": "Shortest paths in directed planar graphs with negative lengths",
    "doi": "https://doi.org/10.1145/1721837.1721846",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Philip N. Klein; Shay Mozes; Oren Weimann",
    "corresponding_authors": "",
    "abstract": "We give an O ( n log 2 n )-time, linear-space algorithm that, given a directed planar graph with positive and negative arc-lengths, and given a node s , finds the distances from s to all nodes.",
    "cited_by_count": 97,
    "openalex_id": "https://openalex.org/W1988593903",
    "type": "article"
  },
  {
    "title": "Approximating fractional hypertree width",
    "doi": "https://doi.org/10.1145/1721837.1721845",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Dániel Marx",
    "corresponding_authors": "Dániel Marx",
    "abstract": "Fractional hypertree width is a hypergraph measure similar to tree width and hypertree width. Its algorithmic importance comes from the fact that, as shown in previous work, Constraint Satisfaction Problems (CSP) and various problems in database theory are polynomial-time solvable if the input contains a bounded-width fractional hypertree decomposition of the hypergraph of the constraints. In this article, we show that for every fixed w ≥ 1, there is a polynomial-time algorithm that, given a hypergraph H with fractional hypertree width at most w , computes a fractional hypertree decomposition of width O ( w 3 ) for H . This means that polynomial-time algorithms relying on bounded-width fractional hypertree decompositions no longer need to be given a decomposition explicitly in the input, since an appropriate decomposition can be computed in polynomial time. Therefore, if H is a class of hypergraphs with bounded fractional hypertree width, then a CSP restricted to instances whose structure is in H is polynomial-time solvable. This makes bounded fractional hypertree width the most general known hypergraph property that makes CSP, Boolean conjunctive queries, and conjunctive query containment polynomial-time solvable.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W1983022219",
    "type": "article"
  },
  {
    "title": "Compression via Matroids",
    "doi": "https://doi.org/10.1145/2635810",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Stefan Kratsch; Magnus Wahlström",
    "corresponding_authors": "",
    "abstract": "The Odd Cycle Transversal problem (OCT) asks whether a given undirected graph can be made bipartite by deleting at most k of its vertices. In a breakthrough result, Reed, Smith, and Vetta (Operations Research Letters, 2004) gave a O (4 k kmn) time algorithm for it; this also implies that instances of the problem can be reduced to a so-called problem kernel of size O (4 k ). Since then, the existence of a polynomial kernel for OCT (i.e., a kernelization with size bounded polynomially in k ) has turned into one of the main open questions in the study of kernelization, open even for the special case of planar input graphs. This work provides the first (randomized) polynomial kernelization for OCT. We introduce a novel kernelization approach based on matroid theory, where we encode all relevant information about a problem instance into a matroid with a representation of size polynomial in k . This represents the first application of matroid theory to kernelization.",
    "cited_by_count": 90,
    "openalex_id": "https://openalex.org/W2119741712",
    "type": "article"
  },
  {
    "title": "Exponential Time Complexity of the Permanent and the Tutte Polynomial",
    "doi": "https://doi.org/10.1145/2635812",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Holger Dell; Thore Husfeldt; Dániel Marx; Nina Taslaman; Martin Wahlén",
    "corresponding_authors": "",
    "abstract": "We show conditional lower bounds for well-studied #P-hard problems: The number of satisfying assignments of a 2-CNF formula with n variables cannot be computed in time exp( o ( n )), and the same is true for computing the number of all independent sets in an n -vertex graph. The permanent of an n × n matrix with entries 0 and 1 cannot be computed in time exp( o ( n )). The Tutte polynomial of an n -vertex multigraph cannot be computed in time exp( o ( n )) at most evaluation points ( x , y ) in the case of multigraphs, and it cannot be computed in time exp( o ( n /poly log n )) in the case of simple graphs. Our lower bounds are relative to (variants of) the Exponential Time Hypothesis (ETH), which says that the satisfiability of n -variable 3-CNF formulas cannot be decided in time exp( o ( n )). We relax this hypothesis by introducing its counting version #ETH; namely, that the satisfying assignments cannot be counted in time exp( o ( n )). In order to use #ETH for our lower bounds, we transfer the sparsification lemma for d -CNF formulas to the counting setting.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W2021372200",
    "type": "article"
  },
  {
    "title": "On the Complexity of Approximating a Nash Equilibrium",
    "doi": "https://doi.org/10.1145/2483699.2483703",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Constantinos Daskalakis",
    "corresponding_authors": "Constantinos Daskalakis",
    "abstract": "We show that computing a relatively (i.e., multiplicatively as opposed to additively) approximate Nash equilibrium in two-player games is PPAD-complete, even for constant values of the approximation. Our result is the first constant inapproximability result for Nash equilibrium, since the original results on the computational complexity of the problem [Daskalakis et al. 2006a; Chen and Deng 2006]. Moreover, it provides an apparent---assuming that PPAD is not contained in TIME(n O(log n) )---dichotomy between the complexities of additive and relative approximations, as for constant values of additive approximation a quasi-polynomial-time algorithm is known [Lipton et al. 2003]. Such a dichotomy does not exist for values of the approximation that scale inverse-polynomially with the size of the game, where both relative and additive approximations are PPAD-complete [Chen et al. 2006]. As a byproduct, our proof shows that (unconditionally) the sparse-support lemma [Lipton et al. 2003] cannot be extended to relative notions of constant approximation.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W2126211987",
    "type": "article"
  },
  {
    "title": "Gathering Despite Mischief",
    "doi": "https://doi.org/10.1145/2629656",
    "publication_date": "2014-08-11",
    "publication_year": 2014,
    "authors": "Yoann Dieudonné; Andrzej Pelc; David Peleg",
    "corresponding_authors": "",
    "abstract": "A team consisting of an unknown number of mobile agents, starting from different nodes of an unknown network, have to meet at the same node. Agents move in synchronous rounds. Each agent has a different label. Up to f of the agents are Byzantine. We consider two levels of Byzantine behavior. A strongly Byzantine agent can choose an arbitrary port when it moves and it can convey arbitrary information to other agents, while a weakly Byzantine agent can do the same, except changing its label. What is the minimum number of good agents that guarantees deterministic gathering of all of them, with termination? We solve exactly this Byzantine gathering problem in arbitrary networks for weakly Byzantine agents and give approximate solutions for strongly Byzantine agents, both when the size of the network is known and when it is unknown. It turns out that both the strength versus the weakness of Byzantine behavior and the knowledge of network size significantly impact the results. For weakly Byzantine agents, we show that any number of good agents permits solving the problem for networks of known size. If the size is unknown, then this minimum number is f +2. More precisely, we show a deterministic polynomial algorithm that gathers all good agents in an arbitrary network, provided that there are at least f +2 of them. We also provide a matching lower bound: we prove that if the number of good agents is at most f +1, then they are not able to gather deterministically with termination in some networks. For strongly Byzantine agents, we give a lower bound of f +1, even when the graph is known: we show that f good agents cannot gather deterministically in the presence of f Byzantine agents even in a ring of known size. On the positive side, we give deterministic gathering algorithms for at least 2 f +1 good agents when the size of the network is known and for at least 4 f +2 good agents when it is unknown.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W2128634904",
    "type": "article"
  },
  {
    "title": "Submodular secretary problem and extensions",
    "doi": "https://doi.org/10.1145/2500121",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "MohammadHossein Bateni; MohammadTaghi Hajiaghayi; Morteza Zadimoghaddam",
    "corresponding_authors": "",
    "abstract": "Online auction is the essence of many modern markets, particularly networked markets, in which information about goods, agents, and outcomes is revealed over a period of time, and the agents must make irrevocable decisions without knowing future information. Optimal stopping theory, especially the classic secretary problem , is a powerful tool for analyzing such online scenarios which generally require optimizing an objective function over the input. The secretary problem and its generalization the multiple-choice secretary problem were under a thorough study in the literature. In this article, we consider a very general setting of the latter problem called the submodular secretary problem , in which the goal is to select k secretaries so as to maximize the expectation of a (not necessarily monotone) submodular function which defines efficiency of the selected secretarial group based on their overlapping skills. We present the first constant-competitive algorithm for this case. In a more general setting in which selected secretaries should form an independent (feasible) set in each of l given matroids as well, we obtain an O ( l log 2 r )-competitive algorithm generalizing several previous results, where r is the maximum rank of the matroids. Another generalization is to consider l knapsack constraints (i.e., a knapsack constraint assigns a nonnegative cost to each secretary, and requires that the total cost of all the secretaries employed be no more than a budget value) instead of the matroid constraints, for which we present an O ( l )-competitive algorithm. In a sharp contrast, we show for a more general setting of subadditive secretary problem , there is no õ (√ n )-competitive algorithm and thus submodular functions are the most general functions to consider for constant-competitiveness in our setting. We complement this result by giving a matching O (√ n )-competitive algorithm for the subadditive case. At the end, we consider some special cases of our general setting as well.",
    "cited_by_count": 87,
    "openalex_id": "https://openalex.org/W2036190740",
    "type": "article"
  },
  {
    "title": "Kernel(s) for problems with no kernel",
    "doi": "https://doi.org/10.1145/2344422.2344428",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Daniel Binkele-Raible; Henning Fernau; Fedor V. Fomin; Daniel Lokshtanov; Saket Saurabh; Yngve Villanger",
    "corresponding_authors": "",
    "abstract": "The k -Leaf Out-Branching problem is to find an out-branching, that is a rooted oriented spanning tree, with at least k leaves in a given digraph. The problem has recently received much attention from the viewpoint of parameterized algorithms. Here, we take a kernelization based approach to the k -Leaf-Out-Branching problem. We give the first polynomial kernel for Rooted k -Leaf-Out-Branching, a variant of k -Leaf-Out-Branching where the root of the tree searched for is also a part of the input. Our kernel with O ( k 3 ) vertices is obtained using extremal combinatorics. For the k -Leaf-Out-Branching problem, we show that no polynomial-sized kernel is possible unless coNP is in NP/poly . However, our positive results for Rooted k -Leaf-Out-Branching immediately imply that the seemingly intractable k -Leaf-Out-Branching problem admits a data reduction to n independent polynomial-sized kernels. These two results, tractability and intractability side by side, are the first ones separating Karp kernelization from Turing kernelization . This answers affirmatively an open problem regarding “cheat kernelization” raised by Mike Fellows and Jiong Guo independently.",
    "cited_by_count": 83,
    "openalex_id": "https://openalex.org/W1999681430",
    "type": "article"
  },
  {
    "title": "Deterministic Rendezvous, Treasure Hunts, and Strongly Universal Exploration Sequences",
    "doi": "https://doi.org/10.1145/2601068",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Amnon Ta‐Shma; Uri Zwick",
    "corresponding_authors": "",
    "abstract": "We obtain several improved solutions for the deterministic rendezvous problem in general undirected graphs. Our solutions answer several problems left open by Dessmark et al. We also introduce an interesting variant of the rendezvous problem, which we call the deterministic treasure hunt problem. Both the rendezvous and the treasure hunt problems motivate the study of universal traversal sequences and universal exploration sequences with some strengthened properties. We call such sequences strongly universal traversal (exploration) sequences . We give an explicit construction of strongly universal exploration sequences. The existence of strongly universal traversal sequences, as well as the solution of the most difficult variant of the deterministic treasure hunt problem, are left as intriguing open problems.",
    "cited_by_count": 83,
    "openalex_id": "https://openalex.org/W2114858735",
    "type": "article"
  },
  {
    "title": "Alphabet-Independent Compressed Text Indexing",
    "doi": "https://doi.org/10.1145/2635816",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Djamal Belazzougui; Gonzalo Navarro",
    "corresponding_authors": "",
    "abstract": "Self-indexes are able to represent a text asymptotically within the information-theoretic lower bound under the k th order entropy model and offer access to any text substring and indexed pattern searches. Their time complexities are not optimal, however; in particular, they are always multiplied by a factor that depends on the alphabet size. In this article, we achieve, for the first time, full alphabet independence in the time complexities of self-indexes while retaining space optimality. We also obtain some relevant byproducts.",
    "cited_by_count": 81,
    "openalex_id": "https://openalex.org/W2074229180",
    "type": "article"
  },
  {
    "title": "Optimal Lower and Upper Bounds for Representing Sequences",
    "doi": "https://doi.org/10.1145/2629339",
    "publication_date": "2015-04-13",
    "publication_year": 2015,
    "authors": "Djamal Belazzougui; Gonzalo Navarro",
    "corresponding_authors": "",
    "abstract": "Sequence representations supporting the queries access , select , and rank are at the core of many data structures. There is a considerable gap between the various upper bounds and the few lower bounds known for such representations, and how they relate to the space used. In this article, we prove a strong lower bound for rank , which holds for rather permissive assumptions on the space used, and give matching upper bounds that require only a compressed representation of the sequence. Within this compressed space, the operations access and select can be solved in constant or almost-constant time, which is optimal for large alphabets. Our new upper bounds dominate all of the previous work in the time/space map.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W2164107415",
    "type": "article"
  },
  {
    "title": "An Improved Approximation for <i>k</i> -Median and Positive Correlation in Budgeted Optimization",
    "doi": "https://doi.org/10.1145/2981561",
    "publication_date": "2017-03-06",
    "publication_year": 2017,
    "authors": "Jarosław Byrka; Thomas Pensyl; Bartosz Rybicki; Aravind Srinivasan; Khoa Trinh",
    "corresponding_authors": "",
    "abstract": "Dependent rounding is a useful technique for optimization problems with hard budget constraints. This framework naturally leads to negative correlation properties. However, what if an application naturally calls for dependent rounding on the one hand and desires positive correlation on the other? More generally, we develop algorithms that guarantee the known properties of dependent rounding but also have nearly bestpossible behavior—near-independence, which generalizes positive correlation—on “small” subsets of the variables. The recent breakthrough of Li and Svensson for the classical k -median problem has to handle positive correlation in certain dependent rounding settings, and does so implicitly. We improve upon Li-Svensson’s approximation ratio for k -median from 2.732 + ϵ to 2.675 + ϵ by developing an algorithm that improves upon various aspects of their work. Our dependent rounding approach helps us improve the dependence of the runtime on the parameter ϵ from Li-Svensson’s N O (1/ϵ 2 ) to N O ((1/ϵ)log(1/ϵ)) .",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W3162678658",
    "type": "article"
  },
  {
    "title": "Dynamic Time Warping and Geometric Edit Distance",
    "doi": "https://doi.org/10.1145/3230734",
    "publication_date": "2018-08-21",
    "publication_year": 2018,
    "authors": "Omer Gold; Micha Sharir",
    "corresponding_authors": "",
    "abstract": "Dynamic Time Warping (DTW) and Geometric Edit Distance (GED) are basic similarity measures between curves or general temporal sequences (e.g., time series) that are represented as sequences of points in some metric space ( X , dist). The DTW and GED measures are massively used in various fields of computer science and computational biology. Consequently, the tasks of computing these measures are among the core problems in P. Despite extensive efforts to find more efficient algorithms, the best-known algorithms for computing the DTW or GED between two sequences of points in X = R d are long-standing dynamic programming algorithms that require quadratic runtime, even for the one-dimensional case d = 1, which is perhaps one of the most used in practice. In this article, we break the nearly 50-year-old quadratic time bound for computing DTW or GED between two sequences of n points in R by presenting deterministic algorithms that run in O ( n 2 log log log n / log log n ) time. Our algorithms can be extended to work also for higher-dimensional spaces R d , for any constant d , when the underlying distance-metric dist is polyhedral (e.g., L 1 , L infin ).",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W2963606058",
    "type": "article"
  },
  {
    "title": "Known Algorithms on Graphs of Bounded Treewidth Are Probably Optimal",
    "doi": "https://doi.org/10.1145/3170442",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Daniel Lokshtanov; Dániel Marx; Saket Saurabh",
    "corresponding_authors": "",
    "abstract": "We obtain a number of lower bounds on the running time of algorithms solving problems on graphs of bounded treewidth. We prove the results under the Strong Exponential Time Hypothesis of Impagliazzo and Paturi. In particular, assuming that n -variable m -clause SAT cannot be solved in time (2-ϵ) n m O (1) , we show that for any ϵ &gt; 0: • I ndependent S et cannot be solved in time (2-ϵ) tw( G ) | V ( G )| O (1) , • D ominating S et cannot be solved in time (3-ϵ) tw( G ) | V ( G )| O (1) , • M ax C ut cannot be solved in time (2-ϵ) tw( G ) | V ( G )| O (1) , • O dd C ycle T ransversal cannot be solved in time (3-ϵ) tw( G ) | V ( G )| O (1) , • For any fixed q ≥ 3, q -C oloring cannot be solved in time ( q -ϵ) tw ( G ) | V ( G )| O (1) , • P artition I nto T riangles cannot be solved in time (2-ϵ) tw ( G ) | V ( G )| O (1) . Our lower bounds match the running times for the best known algorithms for the problems, up to the ϵ in the base.",
    "cited_by_count": 63,
    "openalex_id": "https://openalex.org/W2800485060",
    "type": "article"
  },
  {
    "title": "On Problems Equivalent to (min,+)-Convolution",
    "doi": "https://doi.org/10.1145/3293465",
    "publication_date": "2019-01-08",
    "publication_year": 2019,
    "authors": "Marek Cygan; Marcin Mucha; Karol Węgrzycki; Michał Włodarczyk",
    "corresponding_authors": "",
    "abstract": "In recent years, significant progress has been made in explaining the apparent hardness of improving upon the naive solutions for many fundamental polynomially solvable problems. This progress has come in the form of conditional lower bounds—reductions from a problem assumed to be hard. The hard problems include 3SUM, All-Pairs Shortest Path, SAT, Orthogonal Vectors, and others. In the (min ,+)-convolution problem, the goal is to compute a sequence ( c [ i ]) n-1 i=0 , where c [ k ] = min i=0,…; , k { a [ i ] + b [ k - i ]}, given sequences ( a [ i ]) n-1 i=0 and ( b [ i ]) n-1 i=0 . This can easily be done in O( n 2 ) time, but no O ( n 2-ε ) algorithm is known for ε &gt; 0. In this article, we undertake a systematic study of the (min ,+)-convolution problem as a hardness assumption. First, we establish the equivalence of this problem to a group of other problems, including variants of the classic knapsack problem and problems related to subadditive sequences. The (min ,+)-convolution problem has been used as a building block in algorithms for many problems, notably problems in stringology. It has also appeared as an ad hoc hardness assumption. Second, we investigate some of these connections and provide new reductions and other results. We also explain why replacing this assumption with the Strong Exponential Time Hypothesis might not be possible for some problems.",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W3125825223",
    "type": "article"
  },
  {
    "title": "Proximity Results and Faster Algorithms for Integer Programming Using the Steinitz Lemma",
    "doi": "https://doi.org/10.1145/3340322",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Friedrich Eisenbrand; Robert Weismantel",
    "corresponding_authors": "",
    "abstract": "We consider integer programming problems in standard form max { c T x : Ax = b , x ⩾ 0, x ∈ Z n } where A ∈ Z m × n , b ∈ Z m , and c ∈ Z n . We show that such an integer program can be solved in time ( m ⋅ Δ) O ( m ) ⋅ \\Vert b\\Vert ∞ 2 , where Δ is an upper bound on each absolute value of an entry in A . This improves upon the longstanding best bound of Papadimitriou [27] of ( m ⋅ Δ) O ( m 2 ) , where in addition, the absolute values of the entries of b also need to be bounded by Δ. Our result relies on a lemma of Steinitz that states that a set of vectors in R m that is contained in the unit ball of a norm and that sum up to zero can be ordered such that all partial sums are of norm bounded by m . We also use the Steinitz lemma to show that the ℓ 1 -distance of an optimal integer and fractional solution, also under the presence of upper bounds on the variables, is bounded by m ⋅ (2, m ⋅ Δ +1) m . Here Δ is again an upper bound on the absolute values of the entries of A . The novel strength of our bound is that it is independent of n . We provide evidence for the significance of our bound by applying it to general knapsack problems where we obtain structural and algorithmic results that improve upon the recent literature.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2985292442",
    "type": "article"
  },
  {
    "title": "Optimal-Time Dictionary-Compressed Indexes",
    "doi": "https://doi.org/10.1145/3426473",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Anders Roy Christiansen; Mikko Berggren Ettienne; Tomasz Kociumaka; Gonzalo Navarro; Nicola Prezza",
    "corresponding_authors": "",
    "abstract": "We describe the first self-indexes able to count and locate pattern occurrences in optimal time within a space bounded by the size of the most popular dictionary compressors. To achieve this result, we combine several recent findings, including string attractors - new combinatorial objects encompassing most known compressibility measures for highly repetitive texts - and grammars based on locally consistent parsing. More in detail, letγbe the size of the smallest attractor for a text T of length n. The measureγis an (asymptotic) lower bound to the size of dictionary compressors based on Lempel-Ziv, context-free grammars, and many others. The smallest known text representations in terms of attractors use space O(γlog (n/i3)), and our lightest indexes work within the same asymptotic space. Let ϵ > 0 be a suitably small constant fixed at construction time, m be the pattern length, and occ be the number of its text occurrences. Our index counts pattern occurrences in O(m+log 2+ϵ n) time and locates them in O(m+(occ+1)log ϵ n) time. These times already outperform those of most dictionary-compressed indexes, while obtaining the least asymptotic space for any index searching within O((m+occ),polylog, n) time. Further, by increasing the space to O(γlog (n/i3)log ϵ n), we reduce the locating time to the optimal O(m+occ), and within O(γlog (n/i3)log n) space we can also count in optimal O(m) time. No dictionary-compressed index had obtained this time before. All our indexes can be constructed in O(n) space and O(nlog n) expected time. As a by-product of independent interest, we show how to build, in O(n) expected time and without knowing the sizeγof the smallest attractor (which is NP-hard to find), a run-length context-free grammar of size O(γlog (n/i3)) generating (only) T. As a result, our indexes can be built without knowingi3.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W3116542221",
    "type": "article"
  },
  {
    "title": "Online Metric Algorithms with Untrusted Predictions",
    "doi": "https://doi.org/10.1145/3582689",
    "publication_date": "2023-02-22",
    "publication_year": 2023,
    "authors": "Antonios Antoniadis; Christian Coester; Marek Eliáš; Adam Polak; Bertrand Simon",
    "corresponding_authors": "",
    "abstract": "Machine-learned predictors, although achieving very good results for inputs resembling training data, cannot possibly provide perfect predictions in all situations. Still, decision-making systems that are based on such predictors need not only benefit from good predictions, but should also achieve a decent performance when the predictions are inadequate. In this article, we propose a prediction setup for arbitrary metrical task systems (MTS) (e.g., caching , k -server, and convex body chasing ) and online matching on the line . We utilize results from the theory of online algorithms to show how to make the setup robust. Specifically, for caching, we present an algorithm whose performance, as a function of the prediction error, is exponentially better than what is achievable for general MTS. Finally, we present an empirical evaluation of our methods on real-world datasets, which suggests practicality.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3035590076",
    "type": "article"
  },
  {
    "title": "New Extremal bounds for Reachability and Strong-Connectivity Preservers under failures",
    "doi": "https://doi.org/10.1145/3720545",
    "publication_date": "2025-03-07",
    "publication_year": 2025,
    "authors": "Diptarka Chakraborty; Keerti Choudhary",
    "corresponding_authors": "",
    "abstract": "In this paper, we consider the question of computing sparse subgraphs for any input directed graph \\(G=(V,E)\\) on \\(n\\) vertices and \\(m\\) edges, that preserves reachability and/or strong connectivity structures. We show \\(O(n+\\min\\{|{\\mathcal{P}}|\\sqrt{n},n\\sqrt{|{\\mathcal{P} }|}\\})\\) bound on a subgraph that is an \\(1\\) -fault-tolerant reachability preserver for a given vertex-pair set \\({\\mathcal{P}}\\subseteq V\\times V\\) , i.e., it preserves reachability between any pair of vertices in \\({\\mathcal{P}}\\) under single edge (or vertex) failure. Our result is a significant improvement over the previous best \\(O(n|{\\mathcal{P}}|)\\) bound obtained as a corollary of single-source reachability preserver construction. We prove our upper bound by exploiting the special structure of single fault-tolerant reachability preserver for any pair, and then considering the interaction among such structures for different pairs. We also present the first sub-quadratic bound of at most \\(\\tilde{O}(k2^{k}n^{2-1/k})\\) size, for strong-connectivity preservers of directed graphs under \\(k\\) failures. To the best of our knowledge no non-trivial bound for this problem was known before, for a general \\(k\\) . We get our result by adopting the color-coding technique of Alon, Yuster, and Zwick [JACM’95].",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3038069570",
    "type": "article"
  },
  {
    "title": "Rank-maximal matchings",
    "doi": "https://doi.org/10.1145/1198513.1198520",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Robert W. Irving; Telikepalli Kavitha; Kurt Mehlhorn; Dimitrios Michail; Katarzyna Paluch",
    "corresponding_authors": "",
    "abstract": "Suppose that each member of a set A of applicants ranks a subset of a set P of posts in an order of preference, possibly involving ties. A matching is a set of (applicant, post) pairs such that each applicant and each post appears in at most one pair. A rank-maximal matching is one in which the maximum possible number of applicants are matched to their first choice post, and subject to that condition, the maximum possible number are matched to their second choice post, and so on. This is a relevant concept in any practical matching situation and it was first studied by Irving [2003].We give an algorithm to compute a rank-maximal matching with running time O (min( n + C , C √ n ) m ), where C is the maximal rank of an edge used in a rank-maximal matching, n is the number of applicants and posts and m is the total size of the preference lists.",
    "cited_by_count": 109,
    "openalex_id": "https://openalex.org/W2045342277",
    "type": "article"
  },
  {
    "title": "Frugal path mechanisms",
    "doi": "https://doi.org/10.1145/1186810.1186813",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Aaron Archer; Éva Tardos",
    "corresponding_authors": "",
    "abstract": "We consider the problem of selecting a low-cost s - t path in a graph where the edge costs are a secret, known only to the various economic agents who own them. To solve this problem, Nisan and Ronen applied the celebrated Vickrey-Clarke-Groves (VCG) mechanism, which pays a premium to induce the edges so as to reveal their costs truthfully. We observe that this premium can be unacceptably high. There are simple instances where the mechanism pays Θ( n ) times the actual cost of the path, even if there is an alternate path available that costs only (1 + ϵ) times as much. This inspires the frugal path problem, which is to design a mechanism that selects a path and induces truthful cost revelation, without paying such a high premium. This article contributes negative results on the frugal path problem. On two large classes of graphs, including those having three node-disjoint s - t paths, we prove that no reasonable mechanism can always avoid paying a high premium to induce truthtelling. In particular, we introduce a general class of min function mechanisms, and show that all min function mechanisms can be forced to overpay just as badly as VCG. Meanwhile, we prove that every truthful mechanism satisfying some reasonable properties is a min function mechanism. Our results generalize to the problem of hiring a team to complete a task, where the analog of a path in the graph is a subset of the agents constituting a team capable of completing the task.",
    "cited_by_count": 100,
    "openalex_id": "https://openalex.org/W2061256213",
    "type": "article"
  },
  {
    "title": "Novel architectures for P2P applications",
    "doi": "https://doi.org/10.1145/1273340.1273350",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Moni Naor; Udi Wieder",
    "corresponding_authors": "",
    "abstract": "We propose a new approach for constructing P2P networks based on a dynamic decomposition of a continuous space into cells corresponding to servers. We demonstrate the power of this approach by suggesting two new P2P architectures and various algorithms for them. The first serves as a DHT (distributed hash table) and the other is a dynamic expander network. The DHT network, which we call Distance Halving, allows logarithmic routing and load while preserving constant degrees. It offers an optimal tradeoff between degree and path length in the sense that degree d guarantees a path length of O (log d n ). Another advantage over previous constructions is its relative simplicity. A major new contribution of this construction is a dynamic caching technique that maintains low load and storage, even under the occurrence of hot spots. Our second construction builds a network that is guaranteed to be an expander. The resulting topologies are simple to maintain and implement. Their simplicity makes it easy to modify and add protocols. A small variation yields a DHT which is robust against random Byzantine faults. Finally we show that, using our approach, it is possible to construct any family of constant degree graphs in a dynamic environment, though with worse parameters. Therefore, we expect that more distributed data structures could be designed and implemented in a dynamic environment.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W2134261469",
    "type": "article"
  },
  {
    "title": "Secure multiparty computation of approximations",
    "doi": "https://doi.org/10.1145/1159892.1159900",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Joan Feigenbaum; Yuval Ishai; Tal Malkin; Kobbi Nissim; Martin J. Strauss; Rebecca N. Wright",
    "corresponding_authors": "",
    "abstract": "Approximation algorithms can sometimes provide efficient solutions when no efficient exact computation is known. In particular, approximations are often useful in a distributed setting where the inputs are held by different parties and may be extremely large. Furthermore, for some applications, the parties want to compute a function of their inputs securely without revealing more information than necessary. In this work, we study the question of simultaneously addressing the above efficiency and security concerns via what we call secure approximations. We start by extending standard definitions of secure (exact) computation to the setting of secure approximations. Our definitions guarantee that no additional information is revealed by the approximation beyond what follows from the output of the function being approximated. We then study the complexity of specific secure approximation problems. In particular, we obtain a sublinear-communication protocol for securely approximating the Hamming distance and a polynomial-time protocol for securely approximating the permanent and related #P-hard problems.",
    "cited_by_count": 98,
    "openalex_id": "https://openalex.org/W2152590851",
    "type": "article"
  },
  {
    "title": "Compressed indexes for dynamic text collections",
    "doi": "https://doi.org/10.1145/1240233.1240244",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Ho-Leung Chan; Wing-Kai Hon; Tak‐Wah Lam; Kunihiko Sadakane",
    "corresponding_authors": "",
    "abstract": "Let T be a string with n characters over an alphabet of constant size. A recent breakthrough on compressed indexing allows us to build an index for T in optimal space (i.e., O ( n ) bits), while supporting very efficient pattern matching [Ferragina and Manzini 2000; Grossi and Vitter 2000]. Yet the compressed nature of such indexes also makes them difficult to update dynamically. This article extends the work on optimal-space indexing to a dynamic collection of texts. Our first result is a compressed solution to the library management problem, where we show an index of O ( n ) bits for a text collection L of total length n , which can be updated in O (| T | log n ) time when a text T is inserted or deleted from L ; also, the index supports searching the occurrences of any pattern P in all texts in L in O (| P | log n + occ log 2 n ) time, where occ is the number of occurrences. Our second result is a compressed solution to the dictionary matching problem, where we show an index of O ( d ) bits for a pattern collection D of total length d , which can be updated in O (| P | log 2 d ) time when a pattern P is inserted or deleted from D ; also, the index supports searching the occurrences of all patterns of D in any text T in O ((| T | + occ )log 2 d ) time. When compared with the O ( d log d )-bit suffix-tree-based solution of Amir et al. [1995], the compact solution increases the query time by roughly a factor of log d only. The solution to the dictionary matching problem is based on a new compressed representation of a suffix tree. Precisely, we give an O ( n )-bit representation of a suffix tree for a dynamic collection of texts whose total length is n , which supports insertion and deletion of a text T in O (| T | log 2 n ) time, as well as all suffix tree traversal operations, including forward and backward suffix links. This work can be regarded as a generalization of the compressed representation of static texts. In the study of the aforementioned result, we also derive the first O ( n )-bit representation for maintaining n pairs of balanced parentheses in O (log n /log log n ) time per operation, matching the time complexity of the previous O ( n log n )-bit solution.",
    "cited_by_count": 96,
    "openalex_id": "https://openalex.org/W1999058046",
    "type": "article"
  },
  {
    "title": "Approximate distance oracles for unweighted graphs in expected <i>O</i> ( <i>n</i> <sup>2</sup> ) time",
    "doi": "https://doi.org/10.1145/1198513.1198518",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Surender Baswana; Sandeep Sen",
    "corresponding_authors": "",
    "abstract": "Let G = ( V , E ) be an undirected graph on n vertices, and let δ( u , v ) denote the distance in G between two vertices u and v . Thorup and Zwick showed that for any positive integer t , the graph G can be preprocessed to build a data structure that can efficiently report t -approximate distance between any pair of vertices. That is, for any u , v ∈ V , the distance reported is at least δ( u , v ) and at most t δ( u , v ). The remarkable feature of this data structure is that, for t ≥3, it occupies subquadratic space, that is, it does not store all-pairs distances explicitly, and still it can answer any t -approximate distance query in constant time. They named the data structure “approximate distance oracle” because of this feature. Furthermore, the trade-off between the stretch t and the size of the data structure is essentially optimal.In this article, we show that we can actually construct approximate distance oracles in expected O ( n 2 ) time if the graph is unweighted. One of the new ideas used in the improved algorithm also leads to the first expected linear-time algorithm for computing an optimal size (2, 1)-spanner of an unweighted graph. A (2, 1) spanner of an undirected unweighted graph G = ( V , E ) is a subgraph ( V , Ê), Ê ⊆ E , such that for any two vertices u and v in the graph, their distance in the subgraph is at most 2δ( u , v ) + 1.",
    "cited_by_count": 96,
    "openalex_id": "https://openalex.org/W2157760787",
    "type": "article"
  },
  {
    "title": "Faster fixed parameter tractable algorithms for finding feedback vertex sets",
    "doi": "https://doi.org/10.1145/1159892.1159898",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Venkatesh Raman; Saket Saurabh; C. R. Subramanian",
    "corresponding_authors": "",
    "abstract": "A feedback vertex set ( fvs ) of a graph is a set of vertices whose removal results in an acyclic graph. We show that if an undirected graph on n vertices with minimum degree at least 3 has a fvs on at most 1/3 n 1 − ϵ vertices, then there is a cycle of length at most 6/ϵ (for ϵ ≥ 1/2, we can even improve this to just 6).Using this, we obtain a O ((12 log k /log log k + 6) k n ω algorithm for testing whether an undirected graph on n vertices has a fvs of size at most k . Here n ω is the complexity of the best matrix multiplication algorithm. The previous best parameterized algorithm for this problem took O ((2 k + 1) k n 2 ) time.We also investigate the fixed parameter complexity of weighted feedback vertex set problem in weighted undirected graphs.",
    "cited_by_count": 95,
    "openalex_id": "https://openalex.org/W2125350407",
    "type": "article"
  },
  {
    "title": "Label-guided graph exploration by a finite automaton",
    "doi": "https://doi.org/10.1145/1383369.1383373",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Reuven Cohen; Pierre Fraigniaud; David Ilcinkas; Amos Korman; David Peleg",
    "corresponding_authors": "",
    "abstract": "A finite automaton, simply referred to as a robot , has to explore a graph, that is, visit all the nodes of the graph. The robot has no a priori knowledge of the topology of the graph, nor of its size. It is known that for any k -state robot, there exists a graph of maximum degree 3 that the robot cannot explore. This article considers the effects of allowing the system designer to add short labels to the graph nodes in a preprocessing stage, for helping the exploration by the robot. We describe an exploration algorithm that, given appropriate 2-bit labels (in fact, only 3-valued labels), allows a robot to explore all graphs. Furthermore, we describe a suitable labeling algorithm for generating the required labels in linear time. We also show how to modify our labeling scheme so that a robot can explore all graphs of bounded degree, given appropriate 1-bit labels. In other words, although there is no robot able to explore all graphs of maximum degree 3, there is a robot R, and a way to color in black or white the nodes of any bounded-degree graph G , so that R can explore the colored graph G . Finally, we give impossibility results regarding graph exploration by a robot with no internal memory (i.e., a single-state automaton).",
    "cited_by_count": 93,
    "openalex_id": "https://openalex.org/W2147342018",
    "type": "article"
  },
  {
    "title": "An <i>O</i> ( <i>n</i> log <i>n</i> ) approximation scheme for Steiner tree in planar graphs",
    "doi": "https://doi.org/10.1145/1541885.1541892",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Glencora Borradaile; Philip N. Klein; Claire Mathieu",
    "corresponding_authors": "",
    "abstract": "We give a Polynomial-Time Approximation Scheme (PTAS) for the Steiner tree problem in planar graphs. The running time is O ( n log n ).",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W2045749371",
    "type": "article"
  },
  {
    "title": "Succinct ordinal trees with level-ancestor queries",
    "doi": "https://doi.org/10.1145/1198513.1198516",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Richard F. Geary; Rajeev Raman; Venkatesh Raman",
    "corresponding_authors": "",
    "abstract": "We consider succinct or space-efficient representations of trees that efficiently support a variety of navigation operations. We focus on static ordinal trees, that is, arbitrary static rooted trees where the children of each node are ordered. The set of operations is essentially the union of the sets of operations supported by previous succinct representations [Jacobson 1989; Munro and Raman 2001; Benoit et al. 1999] to which we add the level-ancestor operation.Our representation takes 2 n + o ( n ) bits to represent an n -node tree, which is within o ( n ) bits of the information-theoretic minimum, and supports all operations in O (1) time on the RAM model. These operations also provide a mapping from the n nodes of the tree onto the integers {1, …, n }. In addition to the existing motivations for studying such data structures, we are motivated by the problem of representing XML documents compactly so that XPath queries can be supported efficiently.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W2061916218",
    "type": "article"
  },
  {
    "title": "Low-dimensional lattice basis reduction revisited",
    "doi": "https://doi.org/10.1145/1597036.1597050",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Phong Q. Nguyễn; Damien Stehlé",
    "corresponding_authors": "",
    "abstract": "Lattice reduction is a geometric generalization of the problem of computing greatest common divisors. Most of the interesting algorithmic problems related to lattice reduction are NP-hard as the lattice dimension increases. This article deals with the low-dimensional case. We study a greedy lattice basis reduction algorithm for the Euclidean norm, which is arguably the most natural lattice basis reduction algorithm because it is a straightforward generalization of an old two-dimensional algorithm of Lagrange, usually known as Gauss' algorithm, and which is very similar to Euclid's gcd algorithm. Our results are twofold. From a mathematical point of view, we show that up to dimension four, the output of the greedy algorithm is optimal: The output basis reaches all the successive minima of the lattice. However, as soon as the lattice dimension is strictly higher than four, the output basis may be arbitrarily bad as it may not even reach the first minimum. More importantly, from a computational point of view, we show that up to dimension four, the bit-complexity of the greedy algorithm is quadratic without fast integer arithmetic, just like Euclid's gcd algorithm. This was already proved by Semaev up to dimension three using rather technical means, but it was previously unknown whether or not the algorithm was still polynomial in dimension four. We propose two different analyzes: a global approach based on the geometry of the current basis when the length decrease stalls, and a local approach showing directly that a significant length decrease must occur every O (1) consecutive steps. Our analyzes simplify Semaev's analysis in dimensions two and three, and unify the cases of dimensions two to four. Although the global approach is much simpler, we also present the local approach because it gives further information on the behavior of the algorithm.",
    "cited_by_count": 92,
    "openalex_id": "https://openalex.org/W2092901733",
    "type": "article"
  },
  {
    "title": "Optimal branch-decomposition of planar graphs in <i>O</i> ( <i>n</i> <sup>3</sup> ) Time",
    "doi": "https://doi.org/10.1145/1367064.1367070",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Qian‐Ping Gu; Hisao Tamaki",
    "corresponding_authors": "",
    "abstract": "We give an O ( n 3 ) time algorithm for constructing a minimum-width branch-decomposition of a given planar graph with n vertices. This is achieved through a refinement to the previously best known algorithm of Seymour and Thomas, which runs in O ( n 4 ) time.",
    "cited_by_count": 89,
    "openalex_id": "https://openalex.org/W2048794017",
    "type": "article"
  },
  {
    "title": "Experimental analysis of dynamic all pairs shortest path algorithms",
    "doi": "https://doi.org/10.1145/1198513.1198519",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Camil Demetrescu; Giuseppe F. Italiano",
    "corresponding_authors": "",
    "abstract": "We present the results of an extensive computational study on dynamic algorithms for all pairs shortest path problems. We describe our implementations of the recent dynamic algorithms of King [1999] and of Demetrescu and Italiano [2006], and compare them to the dynamic algorithm of Ramalingam and Reps and to static algorithms on random, real-world and hard instances. Our experimental data suggest that some of the dynamic algorithms and their algorithmic techniques can be really of practical value in many situations.",
    "cited_by_count": 88,
    "openalex_id": "https://openalex.org/W1991778515",
    "type": "article"
  },
  {
    "title": "Fault-tolerant facility location",
    "doi": "https://doi.org/10.1145/1383369.1383382",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Chaitanya Swamy; David B. Shmoys",
    "corresponding_authors": "",
    "abstract": "We consider a fault-tolerant generalization of the classical uncapacitated facility location problem, where each client j has a requirement that r j distinct facilities serve it, instead of just one. We give a 2.076-approximation algorithm for this problem using LP rounding, which is currently the best-known performance guarantee. Our algorithm exploits primal and dual complementary slackness conditions and is based on clustered randomized rounding . A technical difficulty that we overcome is the presence of terms with negative coefficients in the dual objective function, which makes it difficult to bound the cost in terms of dual variables. For the case where all requirements are the same, we give a primal-dual 1.52-approximation algorithm. We also consider a fault-tolerant version of the k -median problem. In the metric k -median problem, we are given n points in a metric space. We must select k of these to be centers, and then assign each input point j to the selected center that is closest to it. In the fault-tolerant version we want j to be assigned to r j distinct centers. The goal is to select the k centers so as to minimize the sum of assignment costs. The primal-dual algorithm for fault-tolerant facility location with uniform requirements also yields a 4-approximation algorithm for the fault-tolerant k -median problem for this case. This the first constant-factor approximation algorithm for the uniform requirements case.",
    "cited_by_count": 86,
    "openalex_id": "https://openalex.org/W1967391655",
    "type": "article"
  },
  {
    "title": "The relative worst order ratio for online algorithms",
    "doi": "https://doi.org/10.1145/1240233.1240245",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Joan Boyar; Lene M. Favrholdt",
    "corresponding_authors": "",
    "abstract": "We define a new measure for the quality of online algorithms, the relative worst order ratio , using ideas from the max/max ratio [Ben-David and Borodin 1994] and from the random order ratio [Kenyon 1996]. The new ratio is used to compare online algorithms directly by taking the ratio of their performances on their respective worst permutations of a worst-case sequence. Two variants of the bin packing problem are considered: the classical bin packing problem, where the goal is to fit all items in as few bins as possible, and the dual bin packing problem, which is the problem of maximizing the number of items packed in a fixed number of bins. Several known algorithms are compared using this new measure, and a new, simple variant of first-fit is proposed for dual bin packing. Many of our results are consistent with those previously obtained with the competitive ratio or the competitive ratio on accommodating sequences, but new separations and easier proofs are found.",
    "cited_by_count": 85,
    "openalex_id": "https://openalex.org/W2070091108",
    "type": "article"
  },
  {
    "title": "Faster approximation schemes for fractional multicommodity flow problems",
    "doi": "https://doi.org/10.1145/1328911.1328924",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "George Karakostas",
    "corresponding_authors": "George Karakostas",
    "abstract": "We present fully polynomial approximation schemes for concurrent multicommodity flow problems that run in time of the minimum possible dependencies on the number of commodities k . We show that by modifying the algorithms by Garg and Könemann [1998] and Fleischer [2000], we can reduce their running time on a graph with n vertices and m edges from Õ (ε −2 ( m 2 + km )) to Õ (ε −2 m 2 ) for an implicit representation of the output, or Õ (ε −2 ( m 2 + kn for an explicit representation, where Õ ( f ) denotes a quantity that is O ( f log O (1) m ). The implicit representation consists of a set of trees rooted at sources (there can be more than one tree per source), and with sinks as their leaves, together with flow values for the flow directed from the source to the sinks in a particular tree. Given this implicit representation, the approximate value of the concurrent flow is known, but if we want the explicit flow per commodity per edge, we would have to combine all these trees together, and the cost of doing so may be prohibitive. In case we want to calculate explicitly the solution flow, we modify our schemes so that they run in time polylogarithmic in nk ( n is the number of nodes in the network). This is within a polylogarithmic factor of the trivial lower bound of time Ω( nk ) needed to explicitly write down a multicommodity flow of k commodities in a network of n nodes. Therefore our schemes are within a polylogarithmic factor of the minimum possible dependencies of the running time on the number of commodities k .",
    "cited_by_count": 84,
    "openalex_id": "https://openalex.org/W2020899710",
    "type": "article"
  },
  {
    "title": "Foreword to special issue on SODA 2002",
    "doi": "https://doi.org/10.1145/1186810.1186811",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "David Eppstein",
    "corresponding_authors": "David Eppstein",
    "abstract": "No abstract available.",
    "cited_by_count": 82,
    "openalex_id": "https://openalex.org/W1999497750",
    "type": "article"
  },
  {
    "title": "Multipartite priority queues",
    "doi": "https://doi.org/10.1145/1435375.1435389",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Amr Elmasry; Claus Jensen; Jyrki Katajainen",
    "corresponding_authors": "",
    "abstract": "We introduce a framework for reducing the number of element comparisons performed in priority-queue operations. In particular, we give a priority queue which guarantees the worst-case cost of O (1) per minimum finding and insertion, and the worst-case cost of O (log n ) with at most log n + O (1) element comparisons per deletion, improving the bound of 2 log n + O (1) known for binomial queues. Here, n denotes the number of elements stored in the data structure prior to the operation in question, and log n equals log 2 (max {2, n}). As an immediate application of the priority queue developed, we obtain a sorting algorithm that is optimally adaptive with respect to the inversion measure of disorder, and that sorts a sequence having n elements and I inversions with at most n log ( I / n ) + O ( n ) element comparisons.",
    "cited_by_count": 81,
    "openalex_id": "https://openalex.org/W2143838916",
    "type": "article"
  },
  {
    "title": "To fill or not to fill",
    "doi": "https://doi.org/10.1145/1978782.1978791",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Samir Khuller; Azarakhsh Malekian; Julián Mestre",
    "corresponding_authors": "",
    "abstract": "In this article we study several routing problems that generalize shortest paths and the traveling salesman problem. We consider a more general model that incorporates the actual cost in terms of gas prices. We have a vehicle with a given tank capacity. We assume that at each vertex gas may be purchased at a certain price. The objective is to find the cheapest route to go from s to t , or the cheapest tour visiting a given set of locations. We show that the problem of finding a cheapest plan to go from s to t can be solved in polynomial time. For most other versions, however, the problem is NP-complete and we develop polynomial-time approximation algorithms for these versions.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W1967218716",
    "type": "article"
  },
  {
    "title": "Minimizing movement",
    "doi": "https://doi.org/10.1145/1541885.1541891",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Erik D. Demaine; MohammadTaghi Hajiaghayi; Hamid Mahini; Amin S. Sayedi-Roshkhar; Shayan Oveisgharan; Morteza Zadimoghaddam",
    "corresponding_authors": "",
    "abstract": "We give approximation algorithms and inapproximability results for a class of movement problems. In general, these problems involve planning the coordinated motion of a large collection of objects (representing anything from a robot swarm or firefighter team to map labels or network messages) to achieve a global property of the network while minimizing the maximum or average movement. In particular, we consider the goals of achieving connectivity (undirected and directed), achieving connectivity between a given pair of vertices, achieving independence (a dispersion problem), and achieving a perfect matching (with applications to multicasting). This general family of movement problems encompasses an intriguing range of graph and geometric algorithms, with several real-world applications and a surprising range of approximability. In some cases, we obtain tight approximation and inapproximability results using direct techniques (without use of PCP), assuming just that P ≠ NP.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W2294364704",
    "type": "article"
  },
  {
    "title": "Adversarial Queuing on the Multiple Access Channel",
    "doi": "https://doi.org/10.1145/2071379.2071384",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Bogdan S. Chlebus; Dariusz R. Kowalski; Mariusz A. Rokicki",
    "corresponding_authors": "",
    "abstract": "We study deterministic broadcasting on multiple access channels when packets are injected continuously. The quality of service is considered in the framework of adversarial queuing. An adversary is determined by injection rate and burstiness, the latter denoting the number of packets that can be injected simultaneously in a round. We consider only injection rates that are less than 1. A protocol is stable when the numbers of packets in queues stay bounded at all rounds, and it is of fair latency when waiting times of packets in queues are O (burstiness/rate). For channels with collision detection, we give a full-sensing protocol of fair latency for injection rates that are at most 1 2(⌈lg n ⌉ + 1), where n is the number of stations, and show that fair latency is impossible to achieve for injection rates that are ω (1 log n ). For channels without collision detection, we present a full-sensing protocol of fair latency for injection rates that are at most 1 c lg 2 n , for some c &gt; 0. We show that there exists an acknowledgment-based protocol that has fair latency for injection rates that are at most 1 cn lg 2 n , for some c &gt; 0, and develop an explicit acknowledgment-based protocol of fair latency for injection rates that are at most 1 27 n 2 ln n . Regarding impossibility to achieve just stability by restricted protocols, we prove that no acknowledgment-based protocol can be stable for injection rates larger than 3 1 + lg n .",
    "cited_by_count": 75,
    "openalex_id": "https://openalex.org/W2060305232",
    "type": "article"
  },
  {
    "title": "Polynomial kernels for dominating set in graphs of bounded degeneracy and beyond",
    "doi": "https://doi.org/10.1145/2390176.2390187",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Geevarghese Philip; Venkatesh Raman; Somnath Sikdar",
    "corresponding_authors": "",
    "abstract": "We show that for every fixed j ≥ i ≥ 1, the k -D ominating S et problem restricted to graphs that do not have K ij (the complete bipartite graph on ( i + j ) vertices, where the two parts have i and j vertices, respectively) as a subgraph is fixed parameter tractable (FPT) and has a polynomial kernel. We describe a polynomial-time algorithm that, given a K i,j -free graph G and a nonnegative integer k , constructs a graph H (the “kernel”) and an integer k ' such that (1) G has a dominating set of size at most k if and only if H has a dominating set of size at most k ', (2) H has O (( j + 1) i + 1 k i 2 ) vertices, and (3) k ' = O (( j + 1) i + 1 k i 2 ). Since d -degenerate graphs do not have K d+1,d+1 as a subgraph, this immediately yields a polynomial kernel on O (( d + 2) d +2 k ( d + 1) 2 ) vertices for the k -D ominating S et problem on d -degenerate graphs, solving an open problem posed by Alon and Gutner [Alon and Gutner 2008; Gutner 2009]. The most general class of graphs for which a polynomial kernel was previously known for k -D ominating S et is the class of K h -topological-minor-free graphs [Gutner 2009]. Graphs of bounded degeneracy are the most general class of graphs for which an FPT algorithm was previously known for this problem. K h -topological-minor-free graphs are K i,j -free for suitable values of i,j (but not vice-versa), and so our results show that k -D ominating S et has both FPT algorithms and polynomial kernels in strictly more general classes of graphs. Using the same techniques, we also obtain an O ( jk i ) vertex-kernel for the k -I ndependent D ominating S et problem on K i,j -free graphs.",
    "cited_by_count": 74,
    "openalex_id": "https://openalex.org/W2076551320",
    "type": "article"
  },
  {
    "title": "Incremental Cycle Detection, Topological Ordering, and Strong Component Maintenance",
    "doi": "https://doi.org/10.1145/2071379.2071382",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Bernhard Haeupler; Telikepalli Kavitha; Rogers Mathew; Siddhartha Sen; Robert E. Tarjan",
    "corresponding_authors": "",
    "abstract": "We present two online algorithms for maintaining a topological order of a directed n -vertex acyclic graph as arcs are added, and detecting a cycle when one is created. Our first algorithm handles m arc additions in O( m 3/2 ) time. For sparse graphs ( m / n = O(1)), this bound improves the best previous bound by a logarithmic factor, and is tight to within a constant factor among algorithms satisfying a natural locality property. Our second algorithm handles an arbitrary sequence of arc additions in O( n 5/2 ) time. For sufficiently dense graphs, this bound improves the best previous bound by a polynomial factor. Our bound may be far from tight: we show that the algorithm can take Ω( n 2 2 √2 lg n ) time by relating its performance to a generalization of the k -levels problem of combinatorial geometry. A completely different algorithm running in Θ( n 2 log n ) time was given recently by Bender, Fineman, and Gilbert. We extend both of our algorithms to the maintenance of strong components, without affecting the asymptotic time bounds.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W2055688322",
    "type": "article"
  },
  {
    "title": "Fully dynamic randomized algorithms for graph spanners",
    "doi": "https://doi.org/10.1145/2344422.2344425",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Surender Baswana; Sumeet Khurana; Soumojit Sarkar",
    "corresponding_authors": "",
    "abstract": "Spanner of an undirected graph G = ( V,E ) is a subgraph that is sparse and yet preserves all-pairs distances approximately. More formally, a spanner with stretch t ∈ ℕ is a subgraph ( V,E S ), E S ⊆ E such that the distance between any two vertices in the subgraph is at most t times their distance in G . Though G is trivially a t -spanner of itself, the research as well as applications of spanners invariably deal with a t -spanner that has as small number of edges as possible. We present fully dynamic algorithms for maintaining spanners in centralized as well as synchronized distributed environments. These algorithms are designed for undirected unweighted graphs and use randomization in a crucial manner. Our algorithms significantly improve the existing fully dynamic algorithms for graph spanners. The expected size (number of edges) of a t -spanner maintained at each stage by our algorithms matches, up to a polylogarithmic factor, the worst case optimal size of a t -spanner. The expected amortized time (or messages communicated in distributed environment) to process a single insertion/deletion of an edge by our algorithms is close to optimal.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W2063860324",
    "type": "article"
  },
  {
    "title": "The price of anarchy in network creation games",
    "doi": "https://doi.org/10.1145/2151171.2151176",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Erik D. Demaine; MohammadTaghi Hajiaghayi; Hamid Mahini; Morteza Zadimoghaddam",
    "corresponding_authors": "",
    "abstract": "We study Nash equilibria in the setting of network creation games introduced recently by Fabrikant, Luthra, Maneva, Papadimitriou, and Shenker. In this game we have a set of selfish node players, each creating some incident links, and the goal is to minimize α times the cost of the created links plus sum of the distances to all other players. Fabrikant et al. proved an upper bound O (√α) on the price of anarchy: the relative cost of the lack of coordination. Albers, Eilts, Even-Dar, Mansour, and Roditty show that the price of anarchy is constant for α = O (√ n ) and for α ≥ 12 n ⌈ lg n ⌉, and that the price of anarchy is 15(1+(min{α 2 / n , n 2 /α}) 1/3 ) for any α. The latter bound shows the first sublinear worst-case bound, O ( n 1/3 ), for all α. But no better bound is known for α between ω(√ n ) and o ( n lg n ). Yet α ≈ n is perhaps the most interesting range, for it corresponds to considering the average distance (instead of the sum of distances) to other nodes to be roughly on par with link creation (effectively dividing α by n ). In this article, we prove the first o ( n ε ) upper bound for general α, namely 2 O (√ lg n ) . We also prove a constant upper bound for α = O ( n 1-ε ) for any fixed ε &gt; 0, substantially reducing the range of α for which constant bounds have not been obtained. Along the way, we also improve the constant upper bound by Albers et al. (with the lead constant of 15 ) to 6 for α &lt; ( n /2) 1/2 and to 4 for α &lt; ( n /2) 1/3 . Next we consider the bilateral network variant of Corbo and Parkes, in which links can be created only with the consent of both endpoints and the link price is shared equally by the two. Corbo and Parkes show an upper bound of O (√α) and a lower bound of Ω(lgα) for α ≤ n . In this article, we show that in fact the upper bound O (√α) is tight for α ≤ n , by proving a matching lower bound of Ω(√α). For α &gt; n , we prove that the price of anarchy is Θ( n /√ α). Finally we introduce a variant of both network creation games, in which each player desires to minimize α times the cost of its created links plus the maximum distance (instead of the sum of distances) to the other players. This variant of the problem is naturally motivated by considering the worst case instead of the average case. Interestingly, for the original (unilateral) game, we show that the price of anarchy is at most 2 for α ≥ n , O (min {4 √lg n , ( n /α) 1/3 }) for 2√ lg n ≤ α ≤ n , and O ( n 2/α ) for α &lt; 2√ lg n . For the bilateral game, we prove matching upper and lower bounds of Θ( n /α + 1) for α ≤ n , and an upper bound of 2 for α &gt; n .",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W2034379999",
    "type": "article"
  },
  {
    "title": "Fully compressed suffix trees",
    "doi": "https://doi.org/10.1145/2000807.2000821",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Luís M. S.​Russo; Gonzalo Navarro; Arlindo L. Oliveira",
    "corresponding_authors": "",
    "abstract": "Suffix trees are by far the most important data structure in stringology, with a myriad of applications in fields like bioinformatics and information retrieval. Classical representations of suffix trees require Θ( n log n ) bits of space, for a string of size n . This is considerably more than the n log 2 σ bits needed for the string itself, where σ is the alphabet size. The size of suffix trees has been a barrier to their wider adoption in practice. Recent compressed suffix tree representations require just the space of the compressed string plus Θ( n ) extra bits. This is already spectacular, but the linear extra bits are still unsatisfactory when σ is small as in DNA sequences. In this article, we introduce the first compressed suffix tree representation that breaks this Θ( n )-bit space barrier. The Fully Compressed Suffix Tree (FCST) representation requires only sublinear space on top of the compressed text size, and supports a wide set of navigational operations in almost logarithmic time. This includes extracting arbitrary text substrings, so the FCST replaces the text using almost the same space as the compressed text. An essential ingredient of FCSTs is the lowest common ancestor (LCA) operation. We reveal important connections between LCAs and suffix tree navigation. We also describe how to make FCSTs dynamic, that is, support updates to the text. The dynamic FCST also supports several operations. In particular, it can build the static FCST within optimal space and polylogarithmic time per symbol. Our theoretical results are also validated experimentally, showing that FCSTs are very effective in practice as well.",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W2135208303",
    "type": "article"
  },
  {
    "title": "Santa claus meets hypergraph matchings",
    "doi": "https://doi.org/10.1145/2229163.2229168",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Arash Asadpour; Uriel Feige; Amin Saberi",
    "corresponding_authors": "",
    "abstract": "We consider the restricted assignment version of the problem of max-min fair allocation of indivisible goods, also known as the Santa Claus problem . There are m items and n players. Every item has some nonnegative value, and every player is interested in only some of the items. The goal is to distribute the items to the players in a way that maximizes the minimum of the sum of the values of the items given to any player. It was previously shown via a nonconstructive proof that uses the Lovász local lemma that the integrality gap of a certain configuration LP for the problem is no worse than some (unspecified) constant. This gives a polynomial-time algorithm to estimate the optimum value of the problem within a constant factor, but does not provide a polynomial-time algorithm for finding a corresponding allocation. We use a different approach to analyze the integrality gap. Our approach is based upon local search techniques for finding perfect matchings in certain classes of hypergraphs. As a result, we prove that the integrality gap of the configuration LP is no worse than 1/4. Our proof provides a local search algorithm which finds the corresponding allocation, but is nonconstructive in the sense that this algorithm is not known to converge to a local optimum in a polynomial number of steps.",
    "cited_by_count": 69,
    "openalex_id": "https://openalex.org/W2001927417",
    "type": "article"
  },
  {
    "title": "The traveling salesman problem in bounded degree graphs",
    "doi": "https://doi.org/10.1145/2151171.2151181",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Andreas Björklund; Thore Husfeldt; Petteri Kaski; Mikko Koivisto",
    "corresponding_authors": "",
    "abstract": "We show that the traveling salesman problem in bounded-degree graphs can be solved in time O ((2-ϵ) n ), where ϵ &gt; 0 depends only on the degree bound but not on the number of cities, n . The algorithm is a variant of the classical dynamic programming solution due to Bellman, and, independently, Held and Karp. In the case of bounded integer weights on the edges, we also give a polynomial-space algorithm with running time O ((2-ϵ) n ) on bounded-degree graphs. In addition, we present an analogous analysis of Ryser's algorithm for the permanent of matrices with a bounded number of nonzero entries in each column.",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2012438638",
    "type": "article"
  },
  {
    "title": "Streaming and fully dynamic centralized algorithms for constructing and maintaining sparse spanners",
    "doi": "https://doi.org/10.1145/1921659.1921666",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Michael Elkin",
    "corresponding_authors": "Michael Elkin",
    "abstract": "We present a streaming algorithm for constructing sparse spanners and show that our algorithm significantly outperforms the state-of-the-art algorithm for this task (due to Feigenbaum et al.). Specifically, the processing time per edge of our algorithm is O (1), and it is drastically smaller than that of the algorithm of Feigenbaum et al., and all other efficiency parameters of our algorithm are no greater (and some of them are strictly smaller) than the respective parameters of the state-of-the-art algorithm. We also devise a fully dynamic centralized algorithm maintaining sparse spanners. This algorithm has incremental update time of O (1), and a nontrivial decremental update time. To our knowledge, this is the first fully dynamic centralized algorithm for maintaining sparse spanners that provides nontrivial bounds on both incremental and decremental update time for a wide range of stretch parameter t .",
    "cited_by_count": 66,
    "openalex_id": "https://openalex.org/W2044246186",
    "type": "article"
  },
  {
    "title": "A New Approach to Incremental Cycle Detection and Related Problems",
    "doi": "https://doi.org/10.1145/2756553",
    "publication_date": "2015-12-08",
    "publication_year": 2015,
    "authors": "Michael A. Bender; Jeremy T. Fineman; Seth Gilbert; Robert E. Tarjan",
    "corresponding_authors": "",
    "abstract": "We consider the problem of detecting a cycle in a directed graph that grows by arc insertions and the related problems of maintaining a topological order and the strong components of such a graph. For these problems, we give two algorithms, one suited to sparse graphs, the other to dense graphs. The former takes O (min { m 1/2 , n 2/3 } m ) time to insert m arcs into an n -vertex graph; the latter takes O ( n 2 log n ) time. Our sparse algorithm is substantially simpler than a previous O ( m 3/2 )-time algorithm; it is also faster on graphs of sufficient density. The time bound of our dense algorithm beats the previously best time bound of O ( n 5/2 ) for dense graphs. Our algorithms rely for their efficiency on vertex numberings weakly consistent with topological order: we allow ties. Bounds on the size of the numbers give bounds on running time.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W1558383352",
    "type": "article"
  },
  {
    "title": "Approximating minimum-cost connectivity problems via uncrossable bifamilies",
    "doi": "https://doi.org/10.1145/2390176.2390177",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Zeev Nutov",
    "corresponding_authors": "Zeev Nutov",
    "abstract": "We give approximation algorithms for the Survivable Network problem. The input consists of a graph G = ( V,E ) with edge/node-costs, a node subset S ⊆ V , and connectivity requirements { r ( s,t ): s,t ∈ T ⊆ V }. The goal is to find a minimum cost subgraph H of G that for all s,t ∈ T contains r ( s,t ) pairwise edge-disjoint st -paths such that no two of them have a node in S ∖ { s,t } in common. Three extensively studied particular cases are: Edge-Connectivity Survivable Network ( S = ∅), Node-Connectivity Survivable Network ( S = V ), and Element-Connectivity Survivable Network ( r ( s,t ) = 0 whenever s ∈ S or t ∈ S ). Let k = max s,t ∈ T r ( s,t ). In Rooted Survivable Network, there is s ∈ T such that r ( u,t ) = 0 for all u ≠ s , and in the Subset k -Connected Subgraph problem r ( s,t ) = k for all s,t ∈ T . For edge-costs, our ratios are O ( k log k ) for Rooted Survivable Network and O ( k 2 log k ) for Subset k -Connected Subgraph. This improves the previous ratio O ( k 2 log n ), and for constant values of k settles the approximability of these problems to a constant. For node-costs, our ratios are as follows. — O ( k log | T |) for Element-Connectivity Survivable Network, matching the best known ratio for Edge-Connectivity Survivable Network. — O ( k 2 log | T |) for Rooted Survivable Network and O ( k 3 log | T |) for Subset k -Connected Subgraph, improving the ratio O ( k 8 log 2 | T |). — O ( k 4 log 2 | T |) for Survivable Network; this is the first nontrivial approximation algorithm for the node-costs version of the problem.",
    "cited_by_count": 59,
    "openalex_id": "https://openalex.org/W2052656799",
    "type": "article"
  },
  {
    "title": "Faster Fully Compressed Pattern Matching by Recompression",
    "doi": "https://doi.org/10.1145/2631920",
    "publication_date": "2015-01-13",
    "publication_year": 2015,
    "authors": "Artur Jeż",
    "corresponding_authors": "Artur Jeż",
    "abstract": "In this article, a fully compressed pattern matching problem is studied. The compression is represented by straight-line programs (SLPs)—that is, context-free grammars generating exactly one string; the term fully means that both the pattern and the text are given in the compressed form. The problem is approached using a recently developed technique of local recompression: the SLPs are refactored so that substrings of the pattern and text are encoded in both SLPs in the same way. To this end, the SLPs are locally decompressed and then recompressed in a uniform way. This technique yields an O (( n + m ) log M ) algorithm for compressed pattern matching, assuming that M fits in O (1) machine words, where n ( m ) is the size of the compressed representation of the text (pattern, respectively), and M is the size of the decompressed pattern. If only m + n fits in O (1) machine words, the running time increases to O (( n + m ) log M log ( n + m )). The previous best algorithm due to Lifshits has O ( n 2 m ) running time.",
    "cited_by_count": 58,
    "openalex_id": "https://openalex.org/W2045427051",
    "type": "article"
  },
  {
    "title": "Directed Subset Feedback Vertex Set Is Fixed-Parameter Tractable",
    "doi": "https://doi.org/10.1145/2700209",
    "publication_date": "2015-04-13",
    "publication_year": 2015,
    "authors": "Rajesh Chitnis; Marek Cygan; Mohammataghi Hajiaghayi; Dániel Marx",
    "corresponding_authors": "",
    "abstract": "Given a graph G and an integer k , the Feedback Vertex Set (FVS) problem asks if there is a vertex set T of size at most k that hits all cycles in the graph. The first fixed-parameter algorithm for FVS in undirected graphs appeared in a monograph of Mehlhorn in 1984. The fixed-parameter tractability (FPT) status of FVS in directed graphs was a long-standing open problem until Chen et al. (STOC ’08, JACM ’08) showed that it is fixed-parameter tractable by giving a 4 k k ! · n O (1) time algorithm. There are two subset versions of this problems: We are given an additional subset S of vertices (resp., edges), and we want to hit all cycles passing through a vertex of S (resp., an edge of S ); the two variants are known to be equivalent in the parameterized sense. Recently, the Subset FVS problem in undirected graphs was shown to be FPT by Cygan et al. (ICALP’11, SIDMA’13) and independently by Kakimura et al. (SODA ’12). We generalize the result of Chen et al. (STOC ’08, JACM ’08) by showing that a Subset FVS in directed graphs can be solved in time 2 O ( k 3 ) ċ n O (1) (i.e., FPT parameterized by size k of the solution). By our result, we complete the picture for FVS problems and their subset versions in undirected and directed graphs. The technique of random sampling of important separators was used by Marx and Razgon (STOC ’11, SICOMP ’14) to show that Undirected Multicut is FPT, and it was generalized by Chitnis et al. (SODA ’12, SICOMP ’13) to directed graphs to show that Directed Multiway Cut is FPT. In addition to proving the FPT of a Directed Subset FVS, we reformulate the random sampling of important separators technique in an abstract way that can be used with a general family of transversal problems. We believe this general approach will be useful for showing the FPT of other problems in directed graphs. Moreover, we modify the probability distribution used in the technique to achieve better running time; in particular, this gives an improvement from 2 2 O ( k ) to 2 O ( k 2 ) in the parameter dependence of the Directed Multiway Cut algorithm of Chitnis et al. (SODA ’12, SICOMP ’13).",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W1846185267",
    "type": "article"
  },
  {
    "title": "The fréchet distance revisited and extended",
    "doi": "https://doi.org/10.1145/2532646",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Sariel Har-Peled; Benjamin Raichel",
    "corresponding_authors": "",
    "abstract": "Given two simplicial complexes in R d and start and end vertices in each complex, we show how to compute curves (in each complex) between these vertices, such that the weak Fréchet distance between these curves is minimized. As a polygonal curve is a complex, this generalizes the regular notion of weak Fréchet distance between curves. We also generalize the algorithm to handle an input of k simplicial complexes. Using this new algorithm, we can solve a slew of new problems, from computing a mean curve for a given collection of curves to various motion planning problems. Additionally, we show that for the mean curve problem, when the k input curves are c -packed, one can (1+ε-approximate the mean curve in near-linear time, for fixed k and ε. Additionally, we present an algorithm for computing the strong Fréchet distance between two curves, which is simpler than previous algorithms and avoids using parametric search.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2010536454",
    "type": "article"
  },
  {
    "title": "Persistent Predecessor Search and Orthogonal Point Location on the Word RAM",
    "doi": "https://doi.org/10.1145/2483699.2483702",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Timothy M. Chan",
    "corresponding_authors": "Timothy M. Chan",
    "abstract": "We answer a basic data structuring question (e.g., raised by Dietz and Raman [1991]): Can van Emde Boas trees be made persistent, without changing their asymptotic query/update time? We present a (partially) persistent data structure that supports predecessor search in a set of integers in {1, ..., U } under an arbitrary sequence of n insertions and deletions, with O (log log U ) expected query time and expected amortized update time, and O ( n ) space. The query bound is optimal in U for linear-space structures and improves previous near- O ((log log U ) 2 ) methods. The same method solves a fundamental problem from computational geometry: point location in orthogonal planar subdivisions (where edges are vertical or horizontal). We obtain the first static data structure achieving O (log log U ) worst-case query time and linear space. This result is again optimal in U for linear-space structures and improves the previous O ((log log U ) 2 ) method by de Berg et al. [1995]. The same result also holds for higher-dimensional subdivisions that are orthogonal binary space partitions, and for certain nonorthogonal planar subdivisions such as triangulations without small angles. Many geometric applications follow, including improved query times for orthogonal range reporting for dimensions ≥ 3 on the RAM. Our key technique is an interesting new van-Emde-Boas--style recursion that alternates between two strategies, both quite simple.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2129029222",
    "type": "article"
  },
  {
    "title": "Testing Planarity of Partially Embedded Graphs",
    "doi": "https://doi.org/10.1145/2629341",
    "publication_date": "2015-04-13",
    "publication_year": 2015,
    "authors": "Patrizio Angelini; Giuseppe Di Battista; Fabrizio Frati; Vít Jelínek; Jan Kratochvı́l; Maurizio Patrignani; Ignaz Rutter",
    "corresponding_authors": "",
    "abstract": "We study the following problem: given a planar graph G and a planar drawing (embedding) of a subgraph of G , can such a drawing be extended to a planar drawing of the entire graph G ? This problem fits the paradigm of extending a partial solution for a problem to a complete one, which has been studied before in many different settings. Unlike many cases, in which the presence of a partial solution in the input makes an otherwise easy problem hard, we show that the planarity question remains polynomial-time solvable. Our algorithm is based on several combinatorial lemmas, which show that the planarity of partially embedded graphs exhibits the ‘TONCAS’ behavior “the obvious necessary conditions for planarity are also sufficient.” These conditions are expressed in terms of the interplay between (1) the rotation system and containment relationships between cycles and (2) the decomposition of a graph into its connected, biconnected, and triconnected components. This implies that no dynamic programming is needed for a decision algorithm and that the elements of the decomposition can be processed independently. Further, by equipping the components of the decomposition with suitable data structures and by carefully splitting the problem into simpler subproblems, we make our algorithm run in linear time. Finally, we consider several generalizations of the problem, such as minimizing the number of edges of the partial embedding that need to be rerouted to extend it, and argue that they are NP-hard. We also apply our algorithm to the simultaneous graph drawing problem Simultaneous Embedding with Fixed Edges (Sefe) . There we obtain a linear-time algorithm for the case that one of the input graphs or the common graph has a fixed planar embedding.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2622290498",
    "type": "article"
  },
  {
    "title": "Maximizing <i>k</i> -Submodular Functions and Beyond",
    "doi": "https://doi.org/10.1145/2850419",
    "publication_date": "2016-08-03",
    "publication_year": 2016,
    "authors": "Justin Ward; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "We consider the maximization problem in the value oracle model of functions defined on k -tuples of sets that are submodular in every orthant and r -wise monotone, where k ⩾ 2 and 1 ⩽ r ⩽ k . We give an analysis of a deterministic greedy algorithm that shows that any such function can be approximated to a factor of 1/(1 + r ). For r = k , we give an analysis of a randomized greedy algorithm that shows that any such function can be approximated to a factor of 1/(1+√ k /2. In the case of k = r = 2, the considered functions correspond precisely to bisubmodular functions, in which case we obtain an approximation guarantee of 1/2. We show that, as in the case of submodular functions, this result is the best possible both in the value query model and under the assumption that NP ≠ RP . Extending a result of Ando et al., we show that for any k ⩾ 3, submodularity in every orthant and pairwise monotonicity (i.e., r = 2) precisely characterize k -submodular functions. Consequently, we obtain an approximation guarantee of 1/3 (and thus independent of k ) for the maximization problem of k -submodular functions.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W1771852678",
    "type": "article"
  },
  {
    "title": "The Traveling Salesman Problem for Lines, Balls, and Planes",
    "doi": "https://doi.org/10.1145/2850418",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Adrian Dumitrescu; Csaba D. Tóth",
    "corresponding_authors": "",
    "abstract": "We revisit the traveling salesman problem with neighborhoods (TSPN) and propose several new approximation algorithms. These constitute either first approximations (for hyperplanes, lines, and balls in R d , for d ⩾ 3) or improvements over previous approximations achievable in comparable times (for unit disks in the plane). (I) Given a set of n hyperplanes in R d , a traveling salesman problem (TSP) tour whose length is at most O (1) times the optimal can be computed in O ( n ) time when d is constant. (II) Given a set of n lines in R d , a TSP tour whose length is at most O (log 3 n ) times the optimal can be computed in polynomial time for all d . (III) Given a set of n unit balls in R d , a TSP tour whose length is at most O (1) times the optimal can be computed in polynomial time when d is constant.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W1870153077",
    "type": "article"
  },
  {
    "title": "Fully Polynomial FPT Algorithms for Some Classes of Bounded Clique-width Graphs",
    "doi": "https://doi.org/10.1145/3310228",
    "publication_date": "2019-06-07",
    "publication_year": 2019,
    "authors": "David Coudert; Guillaume Ducoffe; Alexandru Popa",
    "corresponding_authors": "",
    "abstract": "Recently, hardness results for problems in P were achieved using reasonable complexity-theoretic assumptions such as the Strong Exponential Time Hypothesis. According to these assumptions, many graph-theoretic problems do not admit truly subquadratic algorithms. A central technique used to tackle the difficulty of the above-mentioned problems is fixed-parameter algorithms with polynomial dependency in the fixed parameter (P-FPT). Applying this technique to clique-width , an important graph parameter, remained to be done. In this article, we study several graph-theoretic problems for which hardness results exist such as cycle problems , distance problems , and maximum matching . We give hardness results and P-FPT algorithms, using clique-width and some of its upper bounds as parameters. We believe that our most important result is an algorithm in O ( k 4 ⋅ n + m )-time for computing a maximum matching, where k is either the modular-width of the graph or the P 4 -sparseness. The latter generalizes many algorithms that have been introduced so far for specific subclasses such as cographs. Our algorithms are based on preprocessing methods using modular decomposition and split decomposition. Thus they can also be generalized to some graph classes with unbounded clique-width.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2949142592",
    "type": "article"
  },
  {
    "title": "Point Line Cover",
    "doi": "https://doi.org/10.1145/2832912",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Stefan Kratsch; Geevarghese Philip; Saurabh Ray",
    "corresponding_authors": "",
    "abstract": "The input to the NP-hard point line cover problem (PLC) consists of a set P of n points on the plane and a positive integer k ; the question is whether there exists a set of at most k lines that pass through all points in P . By straightforward reduction rules, one can efficiently reduce any input to one with at most k 2 points. We show that this easy reduction is already essentially tight under standard assumptions. More precisely, unless the polynomial hierarchy collapses to its third level, for any ϵ &gt; 0, there is no polynomial-time algorithm that reduces every instance ( P , k ) of PLC to an equivalent instance with O ( k 2 −ϵ) points. This answers, in the negative, an open problem posed by Lokshtanov [2009]. Our proof uses the notion of a kernel from parameterized complexity, and the machinery for deriving lower bounds on the size of kernels developed by Dell and van Melkebeek [2010, 2014]. It has two main ingredients: We first show, by reduction from vertex cover , that—unless the polynomial hierarchy collapses—PLC has no kernel of total size O ( k 2 −ϵ) bits. This does not directly imply the claimed lower bound on the number of points , since the best-known polynomial-time encoding of a PLC instance with n points requires ω( n 2 ) bits. To get around this hurdle, we build on work of Alon [1986] and devise an oracle communication protocol of cost O ( n log n ) for PLC. This protocol, together with the lower bound on the total size (which also holds for such protocols), yields the stated lower bound on the number of points. While a number of essentially tight polynomial lower bounds on total sizes of kernels are known, our result is—to the best of our knowledge—the first to show a nontrivial lower bound for structural/secondary parameters. It is also the first example of a lower bound for kernelization that makes use of the full power of the oracle communication protocol lower bounds that can be obtained from the work of Dell and van Melkebeek. We combine the main abstract ideas of our proof to derive a general recipe that could be used to obtain such lower bounds for other problems with unknown or insufficiently strong encodings.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W1699753700",
    "type": "article"
  },
  {
    "title": "A Simplified 1.5-Approximation Algorithm for Augmenting Edge-Connectivity of a Graph from 1 to 2",
    "doi": "https://doi.org/10.1145/2786981",
    "publication_date": "2015-11-17",
    "publication_year": 2015,
    "authors": "Guy Kortsarz; Zeev Nutov",
    "corresponding_authors": "",
    "abstract": "The Tree Augmentation Problem (TAP) is as follows: given a connected graph G =( V , ε ) and an edge set E on V , find a minimum size subset of edges F ⊆ E such that ( V , ε ∪ F ) is 2-edge-connected. In the conference version [Even et al. 2001] was sketched a 1.5-approximation algorithm for the problem. Since a full proof was very complex and long, the journal version was cut into two parts. The first part [Even et al. 2009] only proved ratio 1.8. An attempt to simplify the second part produced an error in Even et al. [2011]. Here we give a correct, different, and self-contained proof of the ratio 1.5 that is also substantially simpler and shorter than the previous proofs.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2287418059",
    "type": "article"
  },
  {
    "title": "Online Vertex-Weighted Bipartite Matching",
    "doi": "https://doi.org/10.1145/3326169",
    "publication_date": "2019-06-17",
    "publication_year": 2019,
    "authors": "Zhiyi Huang; Zhihao Gavin Tang; Xiaowei Wu; Yuhao Zhang",
    "corresponding_authors": "",
    "abstract": "We introduce a weighted version of the ranking algorithm by Karp et al. (STOC 1990), and we prove a competitive ratio of 0.6534 for the vertex-weighted online bipartite matching problem when online vertices arrive in random order. Our result shows that random arrivals help beating the 1-1/e barrier even in the vertex-weighted case. We build on the randomized primal-dual framework by Devanur et al. (SODA 2013) and design a two dimensional gain sharing function, which depends not only on the rank of the offline vertex, but also on the arrival time of the online vertex. To our knowledge, this is the first competitive ratio strictly larger than 1-1/e for an online bipartite matching problem achieved under the randomized primal-dual framework. Our algorithm has a natural interpretation that offline vertices offer a larger portion of their weights to the online vertices as time increases, and each online vertex matches the neighbor with the highest offer at its arrival.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2952720641",
    "type": "article"
  },
  {
    "title": "Scaling Algorithms for Weighted Matching in General Graphs",
    "doi": "https://doi.org/10.1145/3155301",
    "publication_date": "2018-01-03",
    "publication_year": 2018,
    "authors": "Ran Duan; Seth Pettie; Hsin-Hao Su",
    "corresponding_authors": "",
    "abstract": "We present a new scaling algorithm for maximum (or minimum) weight perfect matching on general, edge weighted graphs. Our algorithm runs in O ( m √ n log( nN )) time, O ( m √ n ) per scale, which matches the running time of the best cardinality matching algorithms on sparse graphs [16, 20, 36, 37]. Here, m , n , and N bound the number of edges, vertices, and magnitude, respectively, of any integer edge weight. Our result improves on a 25-year-old algorithm of Gabow and Tarjan, which runs in O ( m √ n log n α ( m , n ) log( nN )) time.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2782000683",
    "type": "article"
  },
  {
    "title": "Heavy Hitters and the Structure of Local Privacy",
    "doi": "https://doi.org/10.1145/3344722",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "Mark Bun; Jelani Nelson; Uri Stemmer",
    "corresponding_authors": "",
    "abstract": "We present a new locally differentially private algorithm for the heavy hitters problem that achieves optimal worst-case error as a function of all standardly considered parameters. Prior work obtained error rates that depend optimally on the number of users, the size of the domain, and the privacy parameter but depend sub-optimally on the failure probability. We strengthen existing lower bounds on the error to incorporate the failure probability and show that our new upper bound is tight with respect to this parameter as well. Our lower bound is based on a new understanding of the structure of locally private protocols. We further develop these ideas to obtain the following general results beyond heavy hitters. • Advanced Grouposition : In the local model, group privacy for k users degrades proportionally to ≈√ k instead of linearly in k as in the central model. Stronger group privacy yields improved max-information guarantees, as well as stronger lower bounds (via “packing arguments”), over the central model. • Building on a transformation of Bassily and Smith (STOC 2015), we give a generic transformation from any non-interactive approximate-private local protocol into a pure-private local protocol. Again in contrast with the central model, this shows that we cannot obtain more accurate algorithms by moving from pure to approximate local privacy.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2980195532",
    "type": "article"
  },
  {
    "title": "On the Complexity of String Matching for Graphs",
    "doi": "https://doi.org/10.1145/3588334",
    "publication_date": "2023-03-16",
    "publication_year": 2023,
    "authors": "Massimo Equi; Veli Mäkinen; Alexandru I. Tomescu; Roberto Grossi",
    "corresponding_authors": "",
    "abstract": "Exact string matching in labeled graphs is the problem of searching paths of a graph G=(V, E) such that the concatenation of their node labels is equal to a given pattern string P [1. m ]. This basic problem can be found at the heart of more complex operations on variation graphs in computational biology, of query operations in graph databases, and of analysis operations in heterogeneous networks. We prove a conditional lower bound stating that, for any constant ε &gt; 0, an O (| E | 1 - ε m ) time, or an O (| E | m 1 - ε )time algorithm for exact string matching in graphs, with node labels and pattern drawn from a binary alphabet, cannot be achieved unless the Strong Exponential Time Hypothesis ( SETH ) is false. This holds even if restricted to undirected graphs with maximum node degree 2—that is, to zig-zag matching in bidirectional strings , or to deterministic directed acyclic graphs whose nodes have maximum sum of indegree and outdegree 3. These restricted cases make the lower bound stricter than what can be directly derived from related bounds on regular expression matching (Backurs and Indyk, FOCS’16). In fact, our bounds are tight in the sense that lowering the degree or the alphabet size yields linear time solvable problems. An interesting corollary is that exact and approximate matching are equally hard (i.e., quadratic time) in graphs under SETH . In comparison, the same problems restricted to strings have linear time vs quadratic time solutions, respectively (approximate pattern matching having also a matching SETH lower bound (Backurs and Indyk, STOC’15)).",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4327590906",
    "type": "article"
  },
  {
    "title": "When indexing equals compression",
    "doi": "https://doi.org/10.1145/1198513.1198521",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Luca Foschini; Roberto Grossi; Ankur Gupta; Jeffrey Scott Vitter",
    "corresponding_authors": "",
    "abstract": "We report on a new experimental analysis of high-order entropy-compressed suffix arrays, which retains the theoretical performance of previous work and represents an improvement in practice. Our experiments indicate that the resulting text index offers state-of-the-art compression. In particular, we require roughly 20% of the original text size---without requiring a separate instance of the text. We can additionally use a simple notion to encode and decode block-sorting transforms (such as the Burrows--Wheeler transform), achieving a compression ratio comparable to that of bzip2. We also provide a compressed representation of suffix trees (and their associated text) in a total space that is comparable to that of the text alone compressed with gzip.",
    "cited_by_count": 78,
    "openalex_id": "https://openalex.org/W1969046465",
    "type": "article"
  },
  {
    "title": "Optimal constrained graph exploration",
    "doi": "https://doi.org/10.1145/1159892.1159897",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Christian A. Duncan; Stephen Kobourov; V. S. Anil Kumar",
    "corresponding_authors": "",
    "abstract": "We address the problem of constrained exploration of an unknown graph G = ( V , E ) from a given start node s with either a tethered robot or a robot with a fuel tank of limited capacity, the former being a tighter constraint. In both variations of the problem, the robot can only move along the edges of the graph, for example, it cannot jump between nonadjacent nodes. In the tethered robot case, if the tether (rope) has length l , then the robot must remain within distance l from the start node s . In the second variation, a fuel tank of limited capacity forces the robot to return to s after traversing C edges. The efficiency of algorithms for both variations of the problem is measured by the number of edges traversed during the exploration. We present an algorithm for a tethered robot that explores the graph in Θ(| E |) edge traversals. The problem of exploration using a robot with a limited fuel tank capacity can be solved with a simple reduction from the tethered robot case and also yields a Θ(| E |) algorithm. This improves on the previous best-known bound of O (| E | + | V |log 2 | V |). Since the lower bound for the graph exploration problems is Ω(| E |), our algorithm is optimal within a constant factor.",
    "cited_by_count": 76,
    "openalex_id": "https://openalex.org/W2149735608",
    "type": "article"
  },
  {
    "title": "A linear-time approximation algorithm for weighted matchings in graphs",
    "doi": "https://doi.org/10.1145/1077464.1077472",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Doratha Vinkemeier; Stefan Hougardy",
    "corresponding_authors": "",
    "abstract": "Approximation algorithms have so far mainly been studied for problems that are not known to have polynomial time algorithms for solving them exactly. Here we propose an approximation algorithm for the weighted matching problem in graphs which can be solved in polynomial time. The weighted matching problem is to find a matching in an edge weighted graph that has maximum weight. The first polynomial-time algorithm for this problem was given by Edmonds in 1965. The fastest known algorithm for the weighted matching problem has a running time of O ( nm + n 2 log n ). Many real world problems require graphs of such large size that this running time is too costly. Therefore, there is considerable need for faster approximation algorithms for the weighted matching problem. We present a linear-time approximation algorithm for the weighted matching problem with a performance ratio arbitrarily close to 2/3. This improves the previously best performance ratio of 1/2. Our algorithm is not only of theoretical interest, but because it is easy to implement and the constants involved are quite small it is also useful in practice.",
    "cited_by_count": 73,
    "openalex_id": "https://openalex.org/W2028468530",
    "type": "article"
  },
  {
    "title": "Dynamic text and static pattern matching",
    "doi": "https://doi.org/10.1145/1240233.1240242",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Amihood Amir; Gad M. Landau; Moshe Lewenstein; Dina Sokol",
    "corresponding_authors": "",
    "abstract": "In this article, we address a new version of dynamic pattern matching. The dynamic text and static pattern matching problem is the problem of finding a static pattern in a text that is continuously being updated. The goal is to report all new occurrences of the pattern in the text after each text update. We present an algorithm for solving the problem where the text update operation is changing the symbol value of a text location. Given a text of length n and a pattern of length m , our algorithm preprocesses the text in time O ( n log log m ), and the pattern in time O ( m log m ). The extra space used is O ( n + m log m ). Following each text update, the algorithm deletes all prior occurrences of the pattern that no longer match, and reports all new occurrences of the pattern in the text in O (log log m ) time. We note that the complexity is not proportional to the number of pattern occurrences, since all new occurrences can be reported in a succinct form.",
    "cited_by_count": 71,
    "openalex_id": "https://openalex.org/W1991166425",
    "type": "article"
  },
  {
    "title": "Improved approximation results for the stable marriage problem",
    "doi": "https://doi.org/10.1145/1273340.1273346",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Magnús M. Halldórsson; Kazuo Iwama; Shuichi Miyazaki; Hiroki Yanagisawa",
    "corresponding_authors": "",
    "abstract": "The stable marriage problem has recently been studied in its general setting, where both ties and incomplete lists are allowed. It is NP-hard to find a stable matching of maximum size, while any stable matching is a maximal matching and thus trivially we can obtain a 2-approximation algorithm. In this article, we give the first nontrivial result for approximation of factor less than two. Our algorithm achieves an approximation ratio of 2/(1 + L −2 ) for instances in which only men have ties of length at most L . When both men and women are allowed to have ties but the lengths are limited to two, then we show a ratio of 13/7(&lt;1.858). We also improve the lower bound on the approximation ratio to 21/19(&gt;1.1052).",
    "cited_by_count": 70,
    "openalex_id": "https://openalex.org/W2071503214",
    "type": "article"
  },
  {
    "title": "The <i>k</i> -traveling repairmen problem",
    "doi": "https://doi.org/10.1145/1290672.1290677",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Jittat Fakcharoenphol; Chris Harrelson; Satish Rao",
    "corresponding_authors": "",
    "abstract": "We consider the k -traveling repairmen problem, also known as the minimum latency problem, to multiple repairmen. We give a polynomial-time 8.497α-approximation algorithm for this generalization, where α denotes the best achievable approximation factor for the problem of finding the least-cost rooted tree spanning i vertices of a metric. For the latter problem, a (2 + ε)-approximation is known. Our results can be compared with the best-known approximation algorithm using similar techniques for the case k = 1, which is 3.59α. Moreover, recent work of Chaudry et al. [2003] shows how to remove the factor of α, thus improving all of these results by that factor. We are aware of no previous work on the approximability of the present problem. In addition, we give a simple proof of the 3.59α-approximation result that can be more easily extended to the case of multiple repairmen, and may be of independent interest.",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W2062962786",
    "type": "article"
  },
  {
    "title": "Limitations of cross-monotonic cost-sharing schemes",
    "doi": "https://doi.org/10.1145/1361192.1361201",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Nicole Immorlica; Mohammad Mahdian; Vahab Mirrokni",
    "corresponding_authors": "",
    "abstract": "A cost-sharing scheme is a set of rules defining how to share the cost of a service (often computed by solving a combinatorial optimization problem) amongs serviced customers. A cost-sharing scheme is cross-monotonic if it satisfies the property that everyone is better off when the set of people who receive the service expands. In this article, we develop a novel technique for proving upper bounds on the budget-balance factor of cross-monotonic cost-sharing schemes or the worst-case ratio of recovered cost to total cost. We apply this technique to games defined, based on several combinatorial optimization problems, including the problems of edge cover, vertex cover, set cover, and metric facility location and, in each case, derive tight or nearly-tight bounds. In particular, we show that for the facility location game, there is no cross-monotonic cost-sharing scheme that recovers more than a third of the total cost. This result, together with a recent 1/3-budget-balanced cross-monotonic cost-sharing scheme of Pál and Tardos [2003] closes the gap for the facility location game. For the vertex cover and set cover games, we show that no cross-monotonic cost-sharing scheme can recover more than a O ( n −1/3 ) and O (1/ n ) fraction of the total cost, respectively. Finally, we study the implications of our results on the existence of group-strategyproof mechanisms. We show that every group-strategyproof mechanism corresponds to a cost-sharing scheme that satisfies a condition weaker than cross-monotonicity. Using this, we prove that group-strategyproof mechanisms satisfying additional properties give rise to cross-monotonic cost-sharing schemes and therefore our upper bounds hold.",
    "cited_by_count": 67,
    "openalex_id": "https://openalex.org/W2114752827",
    "type": "article"
  },
  {
    "title": "Taxes for linear atomic congestion games",
    "doi": "https://doi.org/10.1145/1868237.1868251",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Ioannis Caragiannis; Christos Kaklamanis; Panagiotis Kanellopoulos",
    "corresponding_authors": "",
    "abstract": "We study congestion games where players aim to access a set of resources. Each player has a set of possible strategies and each resource has a function associating the latency it incurs to the players using it. Players are non--cooperative and each wishes to follow a strategy that minimizes her own latency with no regard to the global optimum. Previous work has studied the impact of this selfish behavior on system performance. In this article, we study the question of how much the performance can be improved if players are forced to pay taxes for using resources. Our objective is to extend the original game so that selfish behavior does not deteriorate performance. We consider atomic congestion games with linear latency functions and present both negative and positive results. Our negative results show that optimal system performance cannot be achieved even in very simple games. On the positive side, we show that there are ways to assign taxes that can improve the performance of linear congestion games by forcing players to follow strategies where the total latency suffered is within a factor of 2 of the minimum possible; this result is shown to be tight. Furthermore, even in cases where in the absence of taxes the system behavior may be very poor, we show that the total disutility of players (latency plus taxes) is not much larger than the optimal total latency. Besides existential results, we show how to compute taxes in time polynomial in the size of the game by solving convex quadratic programs. Similar questions have been extensively studied in the model of non-atomic congestion games. To the best of our knowledge, this is the first study of the efficiency of taxes in atomic congestion games.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W2070173191",
    "type": "article"
  },
  {
    "title": "Delays induce an exponential memory gap for rendezvous in trees",
    "doi": "https://doi.org/10.1145/1810479.1810524",
    "publication_date": "2010-06-13",
    "publication_year": 2010,
    "authors": "Pierre Fraigniaud; Andrzej Pelc",
    "corresponding_authors": "",
    "abstract": "The aim of rendezvous in a graph is meeting of two mobile agents at some node of an unknown anonymous connected graph. The two identical agents start from arbitrary nodes in the graph and move from node to node with the goal of meeting. In this paper, we focus on rendezvous in trees, and, analogously to the efforts that have been made for solving the exploration problem with compact automata, we study the size of memory of mobile agents that permits to solve the rendezvous problem deterministically.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W2081055073",
    "type": "article"
  },
  {
    "title": "Rectangular layouts and contact graphs",
    "doi": "https://doi.org/10.1145/1328911.1328919",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Adam L. Buchsbaum; Emden R. Gansner; Cecilia M. Procopiuc; Suresh Venkatasubramanian",
    "corresponding_authors": "",
    "abstract": "Contact graphs of isothetic rectangles unify many concepts from applications including VLSI and architectural design, computational geometry, and GIS. Minimizing the area of their corresponding rectangular layouts is a key problem. We study the area-optimization problem and show that it is NP-hard to find a minimum-area rectangular layout of a given contact graph. We present O ( n )-time algorithms that construct O ( n 2 )-area rectangular layouts for general contact graphs and O ( n log n )-area rectangular layouts for trees. (For trees, this is an O (log n )-approximation algorithm.) We also present an infinite family of graphs (respectively, trees) that require Ω( n 2 ) (respectively, Ω( n log n ))area. We derive these results by presenting a new characterization of graphs that admit rectangular layouts, using the related concept of rectangular duals . A corollary to our results relates the class of graphs that admit rectangular layouts to rectangle-of-influence drawings .",
    "cited_by_count": 61,
    "openalex_id": "https://openalex.org/W1973624728",
    "type": "article"
  },
  {
    "title": "On distributing symmetric streaming computations",
    "doi": "https://doi.org/10.1145/1824777.1824786",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Jon Feldman; S. Muthukrishnan; Anastasios Sidiropoulos; Clifford Stein; Zoya Svitkina",
    "corresponding_authors": "",
    "abstract": "A common approach for dealing with large datasets is to stream over the input in one pass, and perform computations using sublinear resources. For truly massive datasets, however, even making a single pass over the data is prohibitive. Therefore, streaming computations must be distributed over many machines. In practice, obtaining significant speedups using distributed computation has numerous challenges including synchronization, load balancing, overcoming processor failures, and data distribution. Successful systems in practice such as Google's MapReduce and Apache's Hadoop address these problems by only allowing a certain class of highly distributable tasks defined by local computations that can be applied in any order to the input. The fundamental question that arises is: How does the class of computational tasks supported by these systems differ from the class for which streaming solutions exist? We introduce a simple algorithmic model for massive, unordered, distributed (mud) computation, as implemented by these systems. We show that in principle, mud algorithms are equivalent in power to symmetric streaming algorithms. More precisely, we show that any symmetric (order-invariant) function that can be computed by a streaming algorithm can also be computed by a mud algorithm, with comparable space and communication complexity. Our simulation uses Savitch's theorem and therefore has superpolynomial time complexity. We extend our simulation result to some natural classes of approximate and randomized streaming algorithms. We also give negative results, using communication complexity arguments to prove that extensions to private randomness, promise problems, and indeterminate functions are impossible. We also introduce an extension of the mud model to multiple keys and multiple rounds.",
    "cited_by_count": 60,
    "openalex_id": "https://openalex.org/W2149565746",
    "type": "article"
  },
  {
    "title": "Approximating the distance to properties in bounded-degree and general sparse graphs",
    "doi": "https://doi.org/10.1145/1497290.1497298",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Sharon Marko; Dana Ron",
    "corresponding_authors": "",
    "abstract": "We address the problem of approximating the distance of bounded-degree and general sparse graphs from having some predetermined graph property P . That is, we are interested in sublinear algorithms for estimating the fraction of edge modifications (additions or deletions) that must be performed on a graph so that it obtains P . This fraction is taken with respect to a given upper bound m on the number of edges. In particular, for graphs with degree bound d over n vertices, m = dn . To perform such an approximation the algorithm may ask for the degree of any vertex of its choice, and may ask for the neighbors of any vertex. The problem of estimating the distance to having a property was first explicitly addressed by Parnas et al. [2006]. In the context of graphs this problem was studied by Fischer and Newman [2007] in the dense graphs model. In this model the fraction of edge modifications is taken with respect to n 2 , and the algorithm may ask for the existence of an edge between any pair of vertices of its choice. Fischer and Newman showed that every graph property that has a testing algorithm in this model, with query complexity independent of the size of the graph, also has a distance approximation algorithm with query complexity that is independent of the size of graph. In this work we focus on bounded-degree and general sparse graphs, and give algorithms for all properties shown to have efficient testing algorithms by Goldreich and Ron [2002]. Specifically, these properties are k -edge connectivity, subgraph freeness (for constant-size subgraphs), being an Eulerian graph, and cycle freeness. A variant of our subgraph-freeness algorithm approximates the size of a minimum vertex cover of a graph in sublinear time. This approximation improves on a recent result of Parnas and Ron [2007].",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2081449822",
    "type": "article"
  },
  {
    "title": "Tree exploration with logarithmic memory",
    "doi": "https://doi.org/10.1145/1921659.1921663",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Christoph Ambühl; Leszek Gąsieniec; Andrzej Pelc; Tomasz Radzik; Xiaohui Zhang",
    "corresponding_authors": "",
    "abstract": "We consider the task of network exploration by a mobile agent (robot) with small memory. The agent has to traverse all nodes and edges of a network (represented as an undirected connected graph), and return to the starting node. Nodes of the network are unlabeled and edge ports are locally labeled at each node. The agent has no a priori knowledge of the topology of the network or of its size, and cannot mark nodes in any way. Under such weak assumptions, cycles in the network may prevent feasibility of exploration, hence we restrict attention to trees. We present an algorithm to accomplish tree exploration (with return) using O (log n )-bit memory for all n -node trees. This strengthens the result from Diks et al. [2004], where O (log 2 n )-bit memory was used for tree exploration, and matches the lower bound on memory size proved there. We also extend our O (log n )-bit memory traversal mechanism to a weaker model in which ports at each node are ordered in circular manner, however, the explicit values of port numbers are not available.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W2152623377",
    "type": "article"
  },
  {
    "title": "The compressed permuterm index",
    "doi": "https://doi.org/10.1145/1868237.1868248",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Paolo Ferragina; Rossano Venturini",
    "corresponding_authors": "",
    "abstract": "The Permuterm index [Garfield 1976] is a time-efficient and elegant solution to the string dictionary problem in which pattern queries may possibly include one wild-card symbol (called Tolerant Retrieval problem). Unfortunately the Permuterm index is space inefficient because it quadruples the dictionary size. In this article we propose the Compressed Permuterm Index which solves the Tolerant Retrieval problem in time proportional to the length of the searched pattern, and space close to the k th order empirical entropy of the indexed dictionary. We also design a dynamic version of this index that allows to efficiently manage insertion in, and deletion from, the dictionary of individual strings. The result is based on a simple variant of the Burrows-Wheeler Transform, defined on a dictionary of strings of variable length, that allows to efficiently solve the Tolerant Retrieval problem via known (dynamic) compressed indexes [Navarro and Mäkinen 2007]. We will complement our theoretical study with a significant set of experiments that show that the Compressed Permuterm Index supports fast queries within a space occupancy that is close to the one achievable by compressing the string dictionary via gzip or bzip. This improves known approaches based on Front-Coding [Witten et al. 1999] by more than 50% in absolute space occupancy, still guaranteeing comparable query time.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2050635028",
    "type": "article"
  },
  {
    "title": "On the online unit clustering problem",
    "doi": "https://doi.org/10.1145/1868237.1868245",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Leah Epstein; Rob van Stee",
    "corresponding_authors": "",
    "abstract": "We continue the study of the online unit clustering problem, introduced by Chan and Zarrabi-Zadeh ( Workshop on Approximation and Online Algorithms 2006 , LNCS 4368, p. 121--131. Springer, 2006). We design a deterministic algorithm with a competitive ratio of 7/4 for the one-dimensional case. This is the first deterministic algorithm that beats the bound of 2. It also has a better competitive ratio than the previous randomized algorithms. Moreover, we provide the first non-trivial deterministic lower bound, improve the randomized lower bound, and prove the first lower bounds for higher dimensions.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2073006754",
    "type": "article"
  },
  {
    "title": "Ordering by weighted number of wins gives a good ranking for weighted tournaments",
    "doi": "https://doi.org/10.1145/1798596.1798608",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Don Coppersmith; Lisa Fleischer; Atri Rurda",
    "corresponding_authors": "",
    "abstract": "We consider the following simple algorithm for feedback arc set problem in weighted tournaments: order the vertices by their weighted indegrees. We show that this algorithm has an approximation guarantee of 5 if the weights satisfy probability constraints (for any pair of vertices u and v , w uv + w vu =1). Special cases of the feedback arc set problem in such weighted tournaments include the feedback arc set problem in unweighted tournaments and rank aggregation. To complement the upper bound, for any constant ϵ&gt;0, we exhibit an infinite family of (unweighted) tournaments for which the aforesaid algorithm ( irrespective of how ties are broken) has an approximation ratio of 5-ϵ.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2621110502",
    "type": "article"
  },
  {
    "title": "Wireless scheduling with power control",
    "doi": "https://doi.org/10.1145/2390176.2390183",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Magnús M. Halldórsson",
    "corresponding_authors": "Magnús M. Halldórsson",
    "abstract": "We consider the scheduling of arbitrary wireless links in the physical model of interference to minimize the time for satisfying all requests. We study here the combined problem of scheduling and power control, where we seek both an assignment of power settings and a partition of the links so that each set satisfies the signal-to-interference-plus-noise (SINR) constraints. We give an algorithm that attains an approximation ratio of O (log n ċ log log Δ), where n is the number of links and Δ is the ratio between the longest and the shortest link length. Under the natural assumption that lengths are represented in binary, this gives the first approximation ratio that is polylogarithmic in the size of the input. The algorithm has the desirable property of using an oblivious power assignment, where the power assigned to a sender depends only on the length of the link. We give evidence that this dependence on Δ is unavoidable, showing that any reasonably behaving oblivious power assignment results in a Ω(log log Δ)-approximation. These results hold also for the (weighted) capacity problem of finding a maximum (weighted) subset of links that can be scheduled in a single time slot. In addition, we obtain improved approximation for a bidirectional variant of the scheduling problem, give partial answers to questions about the utility of graphs for modeling physical interference, and generalize the setting from the standard 2-dimensional Euclidean plane to doubling metrics. Finally, we explore the utility of graph models in capturing wireless interference.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W1750839748",
    "type": "article"
  },
  {
    "title": "Adaptive Uncertainty Resolution in Bayesian Combinatorial Optimization Problems",
    "doi": "https://doi.org/10.1145/2071379.2071380",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Sudipto Guha; Kamesh Munagala",
    "corresponding_authors": "",
    "abstract": "In several applications such as databases, planning, and sensor networks, parameters such as selectivity, load, or sensed values are known only with some associated uncertainty. The performance of such a system (as captured by some objective function over the parameters) is significantly improved if some of these parameters can be probed or observed. In a resource constrained situation, deciding which parameters to observe in order to optimize system performance, itself becomes an interesting and important optimization problem. This general problem is the focus of this article. One of the most important considerations in this framework is whether adaptivity is required for the observations. Adaptive observations introduce blocking or sequential operations in the system whereas nonadaptive observations can be performed in parallel. One of the important questions in this regard is to characterize the benefit of adaptivity for probes and observation. We present general techniques for designing constant factor approximations to the optimal observation schemes for several widely used scheduling and metric objective functions. We show a unifying technique that relates this optimization problem to the outlier version of the corresponding deterministic optimization. By making this connection, our technique shows constant factor upper bounds for the benefit of adaptivity of the observation schemes. We show that while probing yields significant improvement in the objective function, being adaptive about the probing is not beneficial beyond constant factors.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W1973081829",
    "type": "article"
  },
  {
    "title": "Set connectivity problems in undirected graphs and the directed steiner network problem",
    "doi": "https://doi.org/10.1145/1921659.1921664",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Chandra Chekuri; Guy Even; Anupam Gupta; Danny Segev",
    "corresponding_authors": "",
    "abstract": "In the generalized connectivity problem, we are given an edge-weighted graph G = ( V , E ) and a collection D = {( S 1 , T 1 ), …, ( S k , T k )} of distinct demands each demand ( S i , T i ) is a pair of disjoint vertex subsets. We say that a subgraph F of G connects a demand ( S i , T i ) when it contains a path with one endpoint in S i and the other in T i . The goal is to identify a minimum weight subgraph that connects all demands in D . Alon et al. (SODA '04) introduced this problem to study online network formation settings and showed that it captures some well-studied problems such as Steiner forest, facility location with nonmetric costs, tree multicast, and group Steiner tree. Obtaining a nontrivial approximation ratio for generalized connectivity was left as an open problem. We describe the first poly-logarithmic approximation algorithm for generalized connectivity that has a performance guarantee of O (log 2 n log 2 k ). Here, n is the number of vertices in G and k is the number of demands. We also prove that the cut-covering relaxation of this problem has an O (log 3 n log 2 k ) integrality gap. Building upon the results for generalized connectivity, we obtain improved approximation algorithms for two problems that contain generalized connectivity as a special case. For the directed Steiner network problem, we obtain an O ( k 1/2 + ϵ ) approximation which improves on the currently best performance guarantee of Õ ( k 2/3 ) due to Charikar et al. (SODA '98). For the set connector problem, recently introduced by Fukunaga and Nagamochi (IPCO '07), we present a poly-logarithmic approximation; this result improves on the previously known ratio which can be Ω( n ) in the worst case.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2620939520",
    "type": "article"
  },
  {
    "title": "Improved Deterministic Algorithms for Decremental Reachability and Strongly Connected Components",
    "doi": "https://doi.org/10.1145/2483699.2483707",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Jakub Łącki",
    "corresponding_authors": "Jakub Łącki",
    "abstract": "This article presents a new deterministic algorithm for decremental maintenance of the transitive closure in a directed graph. The algorithm processes any sequence of edge deletions in O ( mn ) time and answers queries in constant time. Previously, such time bound has only been achieved by a randomized Las Vegas algorithm. In addition to that, a few decremental algorithms for maintaining strongly connected components are shown, whose time complexity is O ( n 1.5 ) for planar graphs, O ( n log n ) for graphs with bounded treewidth and O ( mn ) for general digraphs.",
    "cited_by_count": 52,
    "openalex_id": "https://openalex.org/W2035767178",
    "type": "article"
  },
  {
    "title": "Replacement Paths and Distance Sensitivity Oracles via Fast Matrix Multiplication",
    "doi": "https://doi.org/10.1145/2438645.2438646",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Oren Weimann; Raphael Yuster",
    "corresponding_authors": "",
    "abstract": "A distance sensitivity oracle of an n -vertex graph G = ( V , E ) is a data structure that can report shortest paths when edges of the graph fail. A query ( u ∈ V , v ∈ V , S ⊆ E ) to this oracle returns a shortest u -to- v path in the graph G ′ = ( V , E ∖ S ). We present randomized (Monte Carlo) algorithms for constructing a distance sensitivity oracle of size Õ ( n 3−α ) for | S | = O (lg n /lg lg n ) and any choice of 0 &lt; α &lt; 1. For real edge-lengths, the oracle is constructed in O ( n 4−α ) time and a query to this oracle takes Õ ( n 2−2(1−α)/|S| ) time. For integral edge-lengths in {− M ,..., M }, using the current ω &lt; 2.376 matrix multiplication exponent, the oracle is constructed in O ( Mn 3.376−α ) time with Õ ( n 2−(1−α)/|S| ) query, or alternatively in O ( M 0.681 n 3.575−α ) time with Õ ( n 2−2(1−α)/|S| ) query. Distance sensitivity oracles generalize the replacement paths problem in which u and v are known in advance and | S | = 1. In other words, if P is a shortest path from u to v in G , then the replacement paths problem asks to compute, for every edge e on P , a shortest u -to- v path that avoids e . Our new technique for constructing distance sensitivity oracles using fast matrix multiplication also yields the first subcubic-time algorithm for the replacement paths problem when the edge-lengths are small integers. In particular, it yields a randomized (Monte Carlo) Õ ( Mn 2.376 + M 2 3 n 2.584 )-time algorithm for the replacement paths problem assuming M ≤ n 0.624 . Finally, we mention that both our replacement paths algorithm and our distance sensitivity oracle can be made to work, in the same time and space bounds, for the case of failed vertices rather than edges, that is, when S is a set of vertices and we seek a shortest u -to- v path in the graph obtained from G by removing all vertices in S and their adjacent edges.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W1963633992",
    "type": "article"
  },
  {
    "title": "A Quasi-Polynomial Time Partition Oracle for Graphs with an Excluded Minor",
    "doi": "https://doi.org/10.1145/2629508",
    "publication_date": "2015-01-13",
    "publication_year": 2015,
    "authors": "Reut Levi; Dana Ron",
    "corresponding_authors": "",
    "abstract": "Motivated by the problem of testing planarity and related properties, we study the problem of designing efficient partition oracles . A partition oracle is a procedure that, given access to the incidence lists representation of a bounded-degree graph G = ( V,E ) and a parameter ϵ, when queried on a vertex v ∈ V , returns the part (subset of vertices) that v belongs to in a partition of all graph vertices. The partition should be such that all parts are small, each part is connected, and if the graph has certain properties, the total number of edges between parts is at most ϵ | V |. In this work, we give a partition oracle for graphs with excluded minors whose query complexity is quasi-polynomial in 1/ϵ, improving on the result of Hassidim et al. ( Proceedings of FOCS 2009 ), who gave a partition oracle with query complexity exponential in 1/ϵ. This improvement implies corresponding improvements in the complexity of testing planarity and other properties that are characterized by excluded minors as well as sublinear-time approximation algorithms that work under the promise that the graph has an excluded minor.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2444233166",
    "type": "article"
  },
  {
    "title": "Succinct indexes for strings, binary relations and multilabeled trees",
    "doi": "https://doi.org/10.1145/2000807.2000820",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Jérémy Barbay; Meng He; J. Ian Munro; Srinivasa Rao Satti",
    "corresponding_authors": "",
    "abstract": "We define and design succinct indexes for several abstract data types (ADTs). The concept is to design auxiliary data structures that ideally occupy asymptotically less space than the information-theoretic lower bound on the space required to encode the given data, and support an extended set of operations using the basic operators defined in the ADT. The main advantage of succinct indexes as opposed to succinct (integrated data/index) encodings is that we make assumptions only on the ADT through which the main data is accessed, rather than the way in which the data is encoded. This allows more freedom in the encoding of the main data. In this article, we present succinct indexes for various data types, namely strings, binary relations and multilabeled trees. Given the support for the interface of the ADTs of these data types, we can support various useful operations efficiently by constructing succinct indexes for them. When the operators in the ADTs are supported in constant time, our results are comparable to previous results, while allowing more flexibility in the encoding of the given data. Using our techniques, we design a succinct encoding that represents a string of length n over an alphabet of size σ using n H k ( S ) + lg σ · o ( n ) + O ( n lg σ/lg lg lg σ) bits to support access/rank/select operations in o ((lg lg σ) 1+ϵ ) time, for any fixed constant ϵ &gt; 0. We also design a succinct text index using n H 0 ( S ) + O ( n lg σ/lg lg σ) bits that supports finding all the occ occurrences of a given pattern of length m in O ( m lg lg σ + occ lg n /lg ϵ σ) time, for any fixed constant 0 &lt; ϵ &lt; 1. Previous results on these two problems either have a lg σ factor instead of lg lg σ in the running time, or are not compressed. Finally, we present succinct encodings of binary relations and multi-labeled trees that are more compact than previous structures.",
    "cited_by_count": 51,
    "openalex_id": "https://openalex.org/W2623433906",
    "type": "article"
  },
  {
    "title": "On the set multicover problem in geometric settings",
    "doi": "https://doi.org/10.1145/2390176.2390185",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Chandra Chekuri; Kenneth L. Clarkson; Sariel Har-Peled",
    "corresponding_authors": "",
    "abstract": "We consider the set multicover problem in geometric settings. Given a set of points P and a collection of geometric shapes (or sets) F , we wish to find a minimum cardinality subset of F such that each point p ∈ P is covered by (contained in) at least d(p) sets. Here, d(p) is an integer demand (requirement) for p. When the demands d(p) = 1 for all p, this is the standard set cover problem. The set cover problem in geometric settings admits an approximation ratio that is better than that for the general version. In this article, we show that similar improvements can be obtained for the multicover problem as well. In particular, we obtain an O (log opt) approximation for set systems of bounded VC-dimension, and an O (1) approximation for covering points by half-spaces in three dimensions and for some other classes of shapes.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W1993324779",
    "type": "article"
  },
  {
    "title": "Interval Deletion Is Fixed-Parameter Tractable",
    "doi": "https://doi.org/10.1145/2629595",
    "publication_date": "2015-01-13",
    "publication_year": 2015,
    "authors": "Yixin Cao; Dániel Marx",
    "corresponding_authors": "",
    "abstract": "We study the minimum interval deletion problem, which asks for the removal of a set of at most k vertices to make a graph of n vertices into an interval graph. We present a parameterized algorithm of runtime 10 k ⋅ n O (1) for this problem—that is, we show that the problem is fixed-parameter tractable.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2003744153",
    "type": "article"
  },
  {
    "title": "Simultaneous PQ-Ordering with Applications to Constrained Embedding Problems",
    "doi": "https://doi.org/10.1145/2738054",
    "publication_date": "2015-12-08",
    "publication_year": 2015,
    "authors": "Thomas Bläsius; Ignaz Rutter",
    "corresponding_authors": "",
    "abstract": "In this article, we define and study the new problem of S imultaneous PQ-O rdering . Its input consists of a set of PQ-trees, which represent sets of circular orders of their leaves, together with a set of child-parent relations between these PQ-trees, such that the leaves of the child form a subset of the leaves of the parent. S imultaneous PQ-O rdering asks whether orders of the leaves of each of the trees can be chosen simultaneously ; that is, for every child-parent relation, the order chosen for the parent is an extension of the order chosen for the child. We show that S imultaneous PQ-O rdering is NP -complete in general, and we identify a family of instances that can be solved efficiently, the 2-fixed instances . We show that this result serves as a framework for several other problems that can be formulated as instances of S imultaneous PQ-O rdering . In particular, we give linear-time algorithms for recognizing simultaneous interval graphs and extending partial interval representations. Moreover, we obtain a linear-time algorithm for P artially PQ-C onstrained P lanarity for biconnected graphs, which asks for a planar embedding in the presence of PQ-trees that restrict the possible orderings of edges around vertices, and a quadratic-time algorithm for S imultaneous E mbedding with F ixed E dges for biconnected graphs with a connected intersection. Both results can be extended to the case where the input graphs are not necessarily biconnected but have the property that each cutvertex is contained in at most two nontrivial blocks. This includes, for example, the case where both graphs have a maximum degree of 5.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W1594437943",
    "type": "article"
  },
  {
    "title": "The effectiveness of stackelberg strategies and tolls for network congestion games",
    "doi": "https://doi.org/10.1145/2344422.2344426",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Chaitanya Swamy",
    "corresponding_authors": "Chaitanya Swamy",
    "abstract": "It is well known that in a network with arbitrary (convex) latency functions that are a function of edge traffic, the worst-case ratio, over all inputs, of the system delay caused due to selfish behavior versus the system delay of the optimal centralized solution may be unbounded even if the system consists of only two parallel links. This ratio is called the price of anarchy (PoA). In this article, we investigate ways by which one can reduce the performance degradation due to selfish behavior. We investigate two primary methods (a) Stackelberg routing strategies , where a central authority, for example, network manager, controls a fixed fraction of the flow, and can route this flow in any desired way so as to influence the flow of selfish users; and (b) network tolls , where tolls are imposed on the edges to modify the latencies of the edges, and thereby influence the induced Nash equilibrium. We obtain results demonstrating the effectiveness of both Stackelberg strategies and tolls in controlling the price of anarchy. For Stackelberg strategies, we obtain the first results for nonatomic routing in graphs more general than parallel-link graphs, and strengthen existing results for parallel-link graphs. (i) In series-parallel graphs, we show that Stackelberg routing reduces the PoA to a constant (depending on the fraction of flow controlled). (ii) For general graphs, we obtain latency-class specific bounds on the PoA with Stackelberg routing, which give a continuous trade-off between the fraction of flow controlled and the price of anarchy. (iii) In parallel-link graphs, we show that for any given class L of latency functions, Stackelberg routing reduces the PoA to at most α + (1-α)ċρ( L ), where α is the fraction of flow controlled and ρ( L ) is the PoA of class L (when α = 0). For network tolls, motivated by the known strong results for nonatomic games, we consider the more general setting of atomic splittable routing games. We show that tolls inducing an optimal flow always exist, even for general asymmetric games with heterogeneous users, and can be computed efficiently by solving a convex program . This resolves a basic open question about the effectiveness of tolls for atomic splittable games. Furthermore, we give a complete characterization of flows that can be induced via tolls.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2618717009",
    "type": "article"
  },
  {
    "title": "Simple Deterministic Algorithms for Fully Dynamic Maximal Matching",
    "doi": "https://doi.org/10.1145/2700206",
    "publication_date": "2015-11-16",
    "publication_year": 2015,
    "authors": "Ofer Neiman; Shay Solomon",
    "corresponding_authors": "",
    "abstract": "A maximal matching can be maintained in fully dynamic (supporting both addition and deletion of edges) n -vertex graphs using a trivial deterministic algorithm with a worst-case update time of O ( n ). No deterministic algorithm that outperforms the naïve O ( n ) one was reported up to this date. The only progress in this direction is due to Ivković and Lloyd, who in 1993 devised a deterministic algorithm with an amortized update time of O (( n + m ) √2/2 ), where m is the number of edges. In this article, we show the first deterministic fully dynamic algorithm that outperforms the trivial one. Specifically, we provide a deterministic worst-case update time of O (√ m ). Moreover, our algorithm maintains a matching, which in fact is a 3/2-approximate maximum cardinality matching (MCM). We remark that no fully dynamic algorithm for maintaining (2 − ϵ)-approximate MCM improving upon the naïve O ( n ) was known prior to this work, even allowing amortized time bounds and randomization. For low arboricity graphs (e.g., planar graphs and graphs excluding fixed minors), we devise another simple deterministic algorithm with sublogarithmic update time. Specifically, it maintains a fully dynamic maximal matching with amortized update time of O (log n /log log n ). This result addresses an open question of Onak and Rubinfeld [2010]. We also show a deterministic algorithm with optimal space usage, which for arbitrary graphs maintains a maximal matching in amortized O (√ m ) time and uses only O ( n + m ) space.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2244920958",
    "type": "article"
  },
  {
    "title": "Subquadratic Algorithms for the Diameter and the Sum of Pairwise Distances in Planar Graphs",
    "doi": "https://doi.org/10.1145/3218821",
    "publication_date": "2018-12-07",
    "publication_year": 2018,
    "authors": "Sergio Cabello",
    "corresponding_authors": "Sergio Cabello",
    "abstract": "In this article, we show how to compute for n -vertex planar graphs in O ( n 11/6 polylog( n )) expected time the diameter and the sum of the pairwise distances. The algorithms work for directed graphs with real weights and no negative cycles. In O ( n 15/8 polylog( n )) expected time, we can also compute the number of pairs of vertices at distances smaller than a given threshold. These are the first algorithms for these problems using time O ( n c ) for some constant c &lt; 2, even when restricted to undirected, unweighted planar graphs.",
    "cited_by_count": 45,
    "openalex_id": "https://openalex.org/W2903797494",
    "type": "article"
  },
  {
    "title": "Co-Nondeterminism in Compositions",
    "doi": "https://doi.org/10.1145/2635808",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Stefan Kratsch",
    "corresponding_authors": "Stefan Kratsch",
    "abstract": "The field of kernelization offers a rigorous way of studying the ubiquitous technique of data reduction and preprocessing for combinatorially hard problems. A widely accepted definition of useful data reduction is that of a polynomial kernelization where the output instance is guaranteed to be of size polynomial in some parameter of the input. The fairly recent development of a framework for kernelization lower bounds has made this notion even more attractive as we can now classify many problems into admitting or not admitting polynomial kernelizations. The central notion of the framework is that of a polynomial-time composition algorithm due to Bodlaender et al. (ICALP 2008, JSCC 2009): given t input instances, an or -composition algorithm returns a single-output instance with bounded parameter value that is yes if and only if one of t input instances is yes; it encodes the logical OR of the input instances. Based on a result of Fortnow and Santhanam (STOC 2008, JSCC 2011), Bodlaender et al. show that an or -composition for an NP-hard problem rules out polynomial kernelizations for it unless NP ⊆ coNP/poly (which is known to imply a collapse of the polynomial hierarchy). It is implicit in the work of Fortnow and Santhanam that even co-nondeterministic composition algorithms suffice to rule out polynomial kernelizations. This was first observed in unpublished work of Chen and Müller, and it is an explicit conclusion of recent results by Dell and van Melkebeek (STOC 2010). However, in contrast to the numerous applications of deterministic composition, the added power of co-nondeterminism has not yet been harnessed to obtain kernelization lower bounds. In this work, we present the first example of how co-nondeterminism can help to make a composition algorithm. We study the existence of polynomial kernels for a Ramsey-type problem where, given a graph G and an integer k , the question is whether G contains an independent set or a clique of size at least k . It was asked by Rod Downey whether this problem admits a polynomial kernelization with respect to k ; such a result would greatly speed up the computation of Ramsey numbers. We provide a co-nondeterministic composition based on embedding t instances into a single host graph H . The crux is that the host graph H needs to observe a bound of ℓ ∈ O (log t ) on both its maximum independent set and maximum clique size, while also having a cover of its vertex set by independent sets and cliques all of size ℓ; the co-nondeterministic composition is built around the search for such graphs. Thus, we show that, unless NP ⊆ coNP/poly, the problem does not admit a kernelization with polynomial size guarantee.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2133839241",
    "type": "article"
  },
  {
    "title": "Representative Families of Product Families",
    "doi": "https://doi.org/10.1145/3039243",
    "publication_date": "2017-03-13",
    "publication_year": 2017,
    "authors": "Fedor V. Fomin; Daniel Lokshtanov; Fahad Panolan; Saket Saurabh",
    "corresponding_authors": "",
    "abstract": "A subfamily F′ of a set family F is said to q - represent F if for every A ∈ F and B of size q such that A ∩ B = ∅ there exists a set A′ ∈ F′ such that A′ ∩ B = ∅. Recently, we provided an algorithm that, for a given family F of sets of size p together with an integer q , efficiently computes a q -representative family F′ of F of size approximately (p+q p). In this article, we consider the efficient computation of q -representative families for product families F . A family F is a product family if there exist families A and B such that F = { A , ∪, B : A ∈ A , B ∈ B , A , ∩, B = ∅}. Our main technical contribution is an algorithm that, given A , B and q , computes a q -representative family F′ of F . The running time of our algorithm is sublinear in | F | for many choices of A , B , and q that occur naturally in several dynamic programming algorithms. We also give an algorithm for the computation of q -representative families for product families F in the more general setting where q -representation also involves independence in a matroid in addition to disjointness. This algorithm considerably outperforms the naive approach where one first computes F from A and B and then computes the q -representative family F′ from F . We give two applications of our new algorithms for computing q -representative families for product families. The first is a 3.8408 k n O (1) deterministic algorithm for the M ultilinear M onomial D etection ( k -M l D) problem. The second is a significant improvement of deterministic dynamic programming algorithms for “connectivity problems” on graphs of bounded treewidth.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2602820822",
    "type": "article"
  },
  {
    "title": "Deterministic Algorithms for Submodular Maximization Problems",
    "doi": "https://doi.org/10.1145/3184990",
    "publication_date": "2018-06-16",
    "publication_year": 2018,
    "authors": "Niv Buchbinder; Moran Feldman",
    "corresponding_authors": "",
    "abstract": "Randomization is a fundamental tool used in many theoretical and practical areas of computer science. We study here the role of randomization in the area of submodular function maximization. In this area, most algorithms are randomized, and in almost all cases the approximation ratios obtained by current randomized algorithms are superior to the best results obtained by known deterministic algorithms. Derandomization of algorithms for general submodular function maximization seems hard since the access to the function is done via a value oracle. This makes it hard, for example, to apply standard derandomization techniques such as conditional expectations. Therefore, an interesting fundamental problem in this area is whether randomization is inherently necessary for obtaining good approximation ratios. In this work, we give evidence that randomization is not necessary for obtaining good algorithms by presenting a new technique for derandomization of algorithms for submodular function maximization. Our high level idea is to maintain explicitly a (small) distribution over the states of the algorithm, and carefully update it using marginal values obtained from an extreme point solution of a suitable linear formulation. We demonstrate our technique on two recent algorithms for unconstrained submodular maximization and for maximizing a submodular function subject to a cardinality constraint. In particular, for unconstrained submodular maximization we obtain an optimal deterministic 1/2-approximation showing that randomization is unnecessary for obtaining optimal results for this setting.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W3160905013",
    "type": "article"
  },
  {
    "title": "Faster Pseudopolynomial Time Algorithms for Subset Sum",
    "doi": "https://doi.org/10.1145/3329863",
    "publication_date": "2019-06-12",
    "publication_year": 2019,
    "authors": "Konstantinos Koiliaris; Chao Xu",
    "corresponding_authors": "",
    "abstract": "Given a (multi) set S of n positive integers and a target integer u , the subset sum problem is to decide if there is a subset of S that sums up to u . We present a series of new algorithms that compute and return all the realizable subset sums up to the integer u in Õ(min { √ n u , u 5/4 ,σ }), where σ is the sum of all elements of S and Õ hides polylogarithmic factors. We also present a modified algorithm for integers modulo m , which computes all the realizable subset sums modulo m in Õ(min { √ n m , m 5/4 }) time. Our contributions improve upon the standard dynamic programming algorithm that runs in O ( nu ) time. To the best of our knowledge, the new algorithms are the fastest deterministic algorithms for this problem. The new results can be employed in various algorithmic problems, from graph bipartition to computational social choice. Finally, we also improve a result on covering Z m , which might be of independent interest.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W2952672079",
    "type": "article"
  },
  {
    "title": "Approximation Schemes for Clustering with Outliers",
    "doi": "https://doi.org/10.1145/3301446",
    "publication_date": "2019-02-18",
    "publication_year": 2019,
    "authors": "Zachary Friggstad; Kamyar Khodamoradi; Mohsen Rezapour; Mohammad R. Salavatipour",
    "corresponding_authors": "",
    "abstract": "Clustering problems are well studied in a variety of fields, such as data science, operations research, and computer science. Such problems include variants of center location problems, k -median and k -means to name a few. In some cases, not all data points need to be clustered; some may be discarded for various reasons. For instance, some points may arise from noise in a dataset or one might be willing to discard a certain fraction of the points to avoid incurring unnecessary overhead in the cost of a clustering solution. We study clustering problems with outliers. More specifically, we look at uncapacitated facility location (UFL), k - median , and k - means . In these problems, we are given a set X of data points in a metric space δ(., .), a set C of possible centers (each maybe with an opening cost), maybe an integer parameter k , plus an additional parameter z as the number of outliers. In uncapacitated facility location with outliers, we have to open some centers, discard up to z points of X , and assign every other point to the nearest open center, minimizing the total assignment cost plus center opening costs. In k - median and k - means , we have to open up to k centers, but there are no opening costs. In k - means , the cost of assigning j to i is δ 2 ( j , i ). We present several results. Our main focus is on cases where δ is a doubling metric (this includes fixed dimensional Euclidean metrics as a special case) or is the shortest path metrics of graphs from a minor-closed family of graphs. For uniform-cost UFL with outliers on such metrics, we show that a multiswap simple local search heuristic yields a PTAS. With a bit more work, we extend this to bicriteria approximations for the k - median and k - means problems in the same metrics where, for any constant ϵ &gt; 0, we can find a solution using (1 + ϵ) k centers whose cost is at most a (1 + ϵ)-factor of the optimum and uses at most z outliers. Our algorithms are all based on natural multiswap local search heuristics. We also show that natural local search heuristics that do not violate the number of clusters and outliers for k - median (or k - means ) will have unbounded gap even in Euclidean metrics. Furthermore, we show how our analysis can be extended to general metrics for k - means with outliers to obtain a (25 + ϵ, 1 + ϵ)-approximation: an algorithm that uses at most (1 + ϵ) k clusters and whose cost is at most 25 + ϵ of optimum and uses no more than z outliers.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2963287397",
    "type": "article"
  },
  {
    "title": "LIMITS and Applications of Group Algebras for Parameterized Problems",
    "doi": "https://doi.org/10.1145/2885499",
    "publication_date": "2016-05-24",
    "publication_year": 2016,
    "authors": "Ioannis Koutis; Ryan Williams",
    "corresponding_authors": "",
    "abstract": "The fastest known randomized algorithms for several parameterized problems use reductions to the k -M l D problem: detection of multilinear monomials of degree k in polynomials presented as circuits. The fastest known algorithm for k -M l D is based on 2 k evaluations of the circuit over a suitable algebra. We use communication complexity to show that it is essentially optimal within this evaluation framework. On the positive side, we give additional applications of the method: finding a copy of a given tree on k nodes, a minimum set of nodes that dominate at least t nodes, and an m -dimensional k -matching. In each case, we achieve a faster algorithm than what was known before. We also apply the algebraic method to problems in exact counting. Among other results, we show that a variation of it can break the trivial upper bounds for the disjoint summation problem.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2408491755",
    "type": "article"
  },
  {
    "title": "Fully Polynomial-Time Parameterized Computations for Graphs and Matrices of Low Treewidth",
    "doi": "https://doi.org/10.1145/3186898",
    "publication_date": "2018-06-16",
    "publication_year": 2018,
    "authors": "Fedor V. Fomin; Daniel Lokshtanov; Saket Saurabh; Michał Pilipczuk; Marcin Wrochna",
    "corresponding_authors": "",
    "abstract": "We investigate the complexity of several fundamental polynomial-time solvable problems on graphs and on matrices, when the given instance has low treewidth; in the case of matrices, we consider the treewidth of the graph formed by non-zero entries. In each of the considered cases, the best known algorithms working on general graphs run in polynomial time; however, the exponent of the polynomial is large. Therefore, our main goal is to construct algorithms with running time of the form poly( k )⋅ n or poly( k )⋅ n log n , where k is the width of the tree decomposition given on the input. Such procedures would outperform the best known algorithms for the considered problems already for moderate values of the treewidth, like O ( n 1/ c ) for a constant c . Our results include the following: — an algorithm for computing the determinant and the rank of an n × n matrix using O ( k 3 ⋅ n ) time and arithmetic operations; —an algorithm for solving a system of linear equations using O ( k 3 ⋅ n ) time and arithmetic operations; —an O ( k 3 ⋅ n log n )-time randomized algorithm for finding the cardinality of a maximum matching in a graph; —an O ( k 4 ⋅ n log 2 n )-time randomized algorithm for constructing a maximum matching in a graph; —an O ( k 2 ⋅ n log n )-time algorithm for finding a maximum vertex flow in a directed graph. Moreover, we give an approximation algorithm for treewidth with time complexity suited to the running times as above. Namely, the algorithm, when given a graph G and integer k , runs in time O ( k 7 ⋅ n log n ) and either correctly reports that the treewidth of G is larger than k , or constructs a tree decomposition of G of width O ( k 2 ). The above results stand in contrast with the recent work of Abboud et al. (SODA 2016), which shows that the existence of algorithms with similar running times is unlikely for the problems of finding the diameter and the radius of a graph of low treewidth.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W4230551286",
    "type": "article"
  },
  {
    "title": "Rapid Mixing from Spectral Independence beyond the Boolean Domain",
    "doi": "https://doi.org/10.1145/3531008",
    "publication_date": "2022-04-27",
    "publication_year": 2022,
    "authors": "Weiming Feng; Heng Guo; Yitong Yin; Chihao Zhang",
    "corresponding_authors": "",
    "abstract": "We extend the notion of spectral independence (introduced by Anari, Liu, and Oveis Gharan [ 4 ]) from the Boolean domain to general discrete domains. This property characterises distributions with limited correlations and implies that the corresponding Glauber dynamics is rapidly mixing. As a concrete application, we show that Glauber dynamics for sampling proper q -colourings mixes in polynomial-time for the family of triangle-free graphs with maximum degree Δ provided q ≥ ( α * + δ )Δ where α * ≈ 1.763 is the unique solution to α * = exp (1/ α * ) and δ Þ 0 is any constant. This is the first efficient algorithm for sampling proper q -colourings in this regime with possibly unbounded Δ. Our main tool of establishing spectral independence is the recursive coupling by Goldberg, Martin, and Paterson [ 25 ].",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W3116442988",
    "type": "article"
  },
  {
    "title": "On a generalization of the stable roommates problem",
    "doi": "https://doi.org/10.1145/1077464.1077474",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Katarı́na Cechlárová; Tamás Fleiner",
    "corresponding_authors": "",
    "abstract": "We consider two generalizations of the stable roommates problem: a) we allow parallel edges in the underlying graph, and b) we study a problem with multiple partners. We reduce both problems to the classical stable roommates problem and describe an extension of Irving's algorithm that solves the generalized problem efficiently. We give a direct proof of a recent result on the structure of stable many-to-many matchings (so called stable b -matchings) as a by-product of the justification of the algorithm.",
    "cited_by_count": 72,
    "openalex_id": "https://openalex.org/W2015602482",
    "type": "article"
  },
  {
    "title": "Generic quantum Fourier transforms",
    "doi": "https://doi.org/10.1145/1198513.1198525",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Cristopher Moore; Daniel N. Rockmore; Alexander Russell",
    "corresponding_authors": "",
    "abstract": "The quantum Fourier transform (QFT) is a principal ingredient appearing in many efficient quantum algorithms. We present a generic framework for the construction of efficient quantum circuits for the QFT by “quantizing” the highly successful separation of variables technique for the construction of efficient classical Fourier transforms. Specifically, we apply Bratteli diagrams, Gel'fand-Tsetlin bases, and strong generating sets of small adapted diameter to provide efficient quantum circuits for the QFT over a wide variety of finite Abelian and non-Abelian groups, including all families of groups for which efficient QFTs are currently known and many new families as well. Moreover, our method provides the first subexponential-size quantum circuits for the QFT over the linear groups GL k ( q ), SL k ( q ), and the finite groups of Lie type, for any fixed prime power q .",
    "cited_by_count": 68,
    "openalex_id": "https://openalex.org/W2030937251",
    "type": "article"
  },
  {
    "title": "The NP-completeness column",
    "doi": "https://doi.org/10.1145/1077464.1077476",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "David S. Johnson",
    "corresponding_authors": "David S. Johnson",
    "abstract": "This is the 24th edition of a column that covers new developments in the theory of NP-completeness. The presentation is modeled on that which M. R. Garey and I used in our book “Computers and Intractability: A Guide to the Theory of NP-Completeness,” W. H. Freeman &amp; Co., New York, 1979, hereinafter referred to as “[G&amp;J].”” Previous columns, the first 23 of which appeared in J. Algorithms , will be referred to by a combination of their sequence number and year of appearance, e.g. “[Col 1, 1981].” This edition of the column describes the history and purpose of the column and the status of the open problems from [G&amp;J] and previous columns.",
    "cited_by_count": 65,
    "openalex_id": "https://openalex.org/W2077803317",
    "type": "article"
  },
  {
    "title": "Approximation algorithms and hardness results for cycle packing problems",
    "doi": "https://doi.org/10.1145/1290672.1290685",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Michael Krivelevich; Zeev Nutov; Mohammad R. Salavatipour; Jacques Verstraëte; Raphael Yuster",
    "corresponding_authors": "",
    "abstract": "The cycle packing number ν e ( G ) of a graph G is the maximum number of pairwise edge-disjoint cycles in G . Computing ν e ( G ) is an NP-hard problem. We present approximation algorithms for computing ν e ( G ) in both undirected and directed graphs. In the undirected case we analyze a variant of the modified greedy algorithm suggested by Caprara et al. [2003] and show that it has approximation ratio Θ(√log n ), where n = | V ( G )|. This improves upon the previous O (log n ) upper bound for the approximation ratio of this algorithm. In the directed case we present a √ n -approximation algorithm. Finally, we give an O ( n 2/3 )-approximation algorithm for the problem of finding a maximum number of edge-disjoint cycles that intersect a specified subset S of vertices. We also study generalizations of these problems. Our approximation ratios are the currently best-known ones and, in addition, provide upper bounds on the integrality gap of standard LP-relaxations of these problems. In addition, we give lower bounds for the integrality gap and approximability of ν e ( G ) in directed graphs. Specifically, we prove a lower bound of Ω(log n /loglog n ) for the integrality gap of edge-disjoint cycle packing. We also show that it is quasi-NP-hard to approximate ν e ( G ) within a factor of O (log 1 − ε n ) for any constant ε &gt; 0. This improves upon the previously known APX-hardness result for this problem.",
    "cited_by_count": 62,
    "openalex_id": "https://openalex.org/W2060363698",
    "type": "article"
  },
  {
    "title": "An approximation algorithm for scheduling malleable tasks under general precedence constraints",
    "doi": "https://doi.org/10.1145/1159892.1159899",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Klaus Jansen; Hu Zhang",
    "corresponding_authors": "",
    "abstract": "In this article, we study the problem of scheduling malleable tasks with precedence constraints. We are given m identical processors and n tasks. For each task the processing time is a function of the number of processors allotted to it. In addition, the tasks must be processed according to the precedence constraints. The goal is to minimize the makespan (maximum completion time) of the resulting schedule. The best previous approximation algorithm (that works in two phases) in Lepère et al. [2002b] has a ratio 3 + √5≈ 5.236. We develop an improved approximation algorithm with a ratio at most 100/43 + 100(√4349 − 7)/2451 ≈ 4.730598. We also show that our resulting ratio is asymptotically tight.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W1967030015",
    "type": "article"
  },
  {
    "title": "Roundtrip spanners and roundtrip routing in directed graphs",
    "doi": "https://doi.org/10.1145/1367064.1367069",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Iam Roditty; Mikkel Thorup; Uri Zwick",
    "corresponding_authors": "",
    "abstract": "We introduce the notion of roundtrip-spanners of weighted directed graphs and describe efficient algorithms for their construction. We show that for every integer k ≥ 1 and any ϵ &gt; 0, any directed graph on n vertices with edge weights in the range [1, W ] has a (2 k + ϵ)-roundtrip-spanner with O (min{( k 2 /ϵ) n 1 + 1/ k (log( nW ), ( k /ϵ) 2 n 1 + 1/ k ,(log n ) 2−1/ k }) edges. We then extend these constructions and obtain compact roundtrip routing schemes. For every integer k ≥ 1 and every ϵ &gt; 0, we describe a roundtrip routing scheme that has stretch 4 k + ϵ, and uses at each vertex a routing table of size Õ (( k 2 /ϵ) n 1/ k log( nW )). We also show that any weighted directed graph with arbitrary/ positive edge weights has a 3-roundtrip-spanner with O ( n 3/2 ) edges. This result is optimal. Finally, we present a stretch 3 roundtrip routing scheme that uses local routing tables of size Õ ( n 1/2 ). This routing scheme is essentially optimal. The roundtrip-spanner constructions and the roundtrip routing schemes for directed graphs that we describe are only slightly worse than the best available spanners and routing schemes for undirected graphs. Our roundtrip routing schemes substantially improve previous results of Cowen and Wagner. Our results are obtained by combining ideas of Cohen, Cowen and Wagner, Thorup and Zwick, with some new ideas.",
    "cited_by_count": 57,
    "openalex_id": "https://openalex.org/W1971316210",
    "type": "article"
  },
  {
    "title": "Approximate parameterized matching",
    "doi": "https://doi.org/10.1145/1273340.1273345",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Carmit Hazay; Moshe Lewenstein; Dina Sokol",
    "corresponding_authors": "",
    "abstract": "Two equal length strings s and s ′, over alphabets Σ s and Σ s ′, parameterize match if there exists a bijection π : Σ s → Σ s ′ such that π ( s ) = s ′, where π ( s ) is the renaming of each character of s via π. Parameterized matching is the problem of finding all parameterized matches of a pattern string p in a text t , and approximate parameterized matching is the problem of finding at each location a bijection π that maximizes the number of characters that are mapped from p to the appropriate | p |-length substring of t . Parameterized matching was introduced as a model for software duplication detection in software maintenance systems and also has applications in image processing and computational biology. For example, approximate parameterized matching models image searching with variable color maps in the presence of errors. We consider the problem for which an error threshold, k , is given, and the goal is to find all locations in t for which there exists a bijection π which maps p into the appropriate | p |-length substring of t with at most k mismatched mapped elements. Our main result is an algorithm for this problem with O ( nk 1.5 + mk log m ) time complexity, where m = | p | and n =| t |. We also show that when | p | = | t | = m , the problem is equivalent to the maximum matching problem on graphs, yielding a O ( m + k 1.5 ) solution.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2028744820",
    "type": "article"
  },
  {
    "title": "Atomic congestion games among coalitions",
    "doi": "https://doi.org/10.1145/1383369.1383383",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Dimitris Fotakis; Spyros Kontogiannis; Paul G. Spirakis",
    "corresponding_authors": "",
    "abstract": "We consider algorithmic questions concerning the existence, tractability, and quality of Nash equilibria, in atomic congestion games among users participating in selfish coalitions. We introduce a coalitional congestion model among atomic players and demonstrate many interesting similarities with the noncooperative case. For example, there exists a potential function proving the existence of pure Nash equilibria (PNE) in the unrelated parallel links setting; in the network setting, the finite improvement property collapses as soon as we depart from linear delays, but there is an exact potential (and thus PNE) for linear delays. The price of anarchy on identical parallel links demonstrates a quite surprising threshold behavior: It persists on being asymptotically equal to that in the case of the noncooperative KP-model, unless the number of coalitions is sublogarithmic . We also show crucial differences, mainly concerning the hardness of algorithmic problems that are solved efficiently in the noncooperative case. Although we demonstrate convergence to robust PNE, we also prove the hardness of computing them. On the other hand, we propose a generalized fully mixed Nash equilibrium that can be efficiently constructed in most cases. Finally, we propose a natural improvement policy and prove its convergence in pseudopolynomial time to PNE which are robust against (even dynamically forming) coalitions of small size.",
    "cited_by_count": 56,
    "openalex_id": "https://openalex.org/W2089904040",
    "type": "article"
  },
  {
    "title": "Structure and linear-time recognition of 4-leaf powers",
    "doi": "https://doi.org/10.1145/1435375.1435386",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Andreas Brandstädt; Van Bang Lê; R. Sritharan",
    "corresponding_authors": "",
    "abstract": "A graph G is the k-leaf power of a tree T if its vertices are leaves of T such that two vertices are adjacent in G if and only if their distance in T is at most k . Then T is a k-leaf root of G . This notion was introduced and studied by Nishimura, Ragde, and Thilikos [2002], motivated by the search for underlying phylogenetic trees. Their results imply an O ( n 3 )-time recognition algorithm for 4-leaf powers. Recently, Rautenbach [2006] as well as Dom et al. [2005] characterized 4-leaf powers without true twins in terms of forbidden subgraphs. We give new characterizations for 4-leaf powers and squares of trees by a complete structural analysis. As a consequence, we obtain a conceptually simple linear-time recognition of 4-leaf powers.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2087058366",
    "type": "article"
  },
  {
    "title": "A 1.8 approximation algorithm for augmenting edge-connectivity of a graph from 1 to 2",
    "doi": "https://doi.org/10.1145/1497290.1497297",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Guy Even; Jon Feldman; Guy Kortsarz; Zeev Nutov",
    "corresponding_authors": "",
    "abstract": "We present a 1.8-approximation algorithm for the following NP-hard problem: Given a connected graph G = ( V , E ) and an edge set E on V disjoint to E , find a minimum-size subset of edges F ⊆ E such that ( V , E ∪ F ) is 2-edge-connected. Our result improves and significantly simplifies the approximation algorithm with ratio 1.875 + ε of Nagamochi.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2057915045",
    "type": "article"
  },
  {
    "title": "Length-bounded cuts and flows",
    "doi": "https://doi.org/10.1145/1868237.1868241",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Georg Baier; Thomas Erlebach; Alexander Hall; Ekkehard Köhler; Petr Kolman; Ondřej Pangrác; Heiko Schilling; Martin Skutella",
    "corresponding_authors": "",
    "abstract": "For a given number L , an L -length-bounded edge-cut (node-cut, respectively) in a graph G with source s and sink t is a set C of edges (nodes, respectively) such that no s - t -path of length at most L remains in the graph after removing the edges (nodes, respectively) in C . An L -length-bounded flow is a flow that can be decomposed into flow paths of length at most L . In contrast to classical flow theory, we describe instances for which the minimum L -length-bounded edge-cut (node-cut, respectively) is Θ( n 2/3 )-times (Θ(√ n )-times, respectively) larger than the maximum L -length-bounded flow, where n denotes the number of nodes; this is the worst case. We show that the minimum length-bounded cut problem is NP -hard to approximate within a factor of 1.1377 for L ≥ 5 in the case of node-cuts and for L ≥ 4 in the case of edge-cuts. We also describe algorithms with approximation ratio O (min{ L , n/L }) ⊆ O √ n in the node case and O (min { L , n 2 / L 2 ,√ m } ⊆ O 2/3 in the edge case, where m denotes the number of edges. Concerning L -length-bounded flows, we show that in graphs with unit-capacities and general edge lengths it is NP -complete to decide whether there is a fractional length-bounded flow of a given value. We analyze the structure of optimal solutions and present further complexity results.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2025838844",
    "type": "article"
  },
  {
    "title": "Approximation schemes for wireless networks",
    "doi": "https://doi.org/10.1145/1383369.1383380",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Tim Nieberg; Johann L. Hurink; Walter Kern",
    "corresponding_authors": "",
    "abstract": "Wireless networks are created by the communication links between a collection of radio transceivers. The nature of wireless transmissions does not lead to arbitrary undirected graphs but to structured graphs which we characterize by the polynomially bounded growth property. In contrast to many existing graph models for wireless networks, the property of polynomially bounded growth is defined independently of geometric data such as positional information. On such wireless networks, we present an approach that can be used to create polynomial-time approximation schemes for several optimization problems called the local neighborhood-based scheme. We apply this approach to the problems of seeking maximum (weight) independent sets and minimum dominating sets. These are two important problems in the area of wireless communication networks and are also used in many applications ranging from clustering to routing strategies. However, the approach is presented in a general fashion since it can be applied to other problems as well. The approach for the approximation schemes is robust in the sense that it accepts any undirected graph as input and either outputs a solution of desired quality or correctly asserts that the graph presented as input does not satisfy the structural assumption of a wireless network (an NP-hard problem).",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2147465311",
    "type": "article"
  },
  {
    "title": "Fast asynchronous Byzantine agreement and leader election with full information",
    "doi": "https://doi.org/10.1145/1824777.1824788",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Bruce M. Kapron; David Kempe; Valerie King; Jared Saia; Vishal Sanwalani",
    "corresponding_authors": "",
    "abstract": "We resolve two long-standing open problems in distributed computation by describing polylogarithmic protocols for Byzantine agreement and leader election in the asynchronous full information model with a nonadaptive malicious adversary. All past protocols for asynchronous Byzantine agreement had been exponential, and no protocol for asynchronous leader election had been known. Our protocols tolerate up to (1/3 − ϵ) ⋅ n faulty processors, for any positive constant ϵ. They are Monte Carlo, succeeding with probability 1 − o (1) for Byzantine agreement, and constant probability for leader election. A key technical contribution of our article is a new approach for emulating Feige's lightest bin protocol, even with adversarial message scheduling.",
    "cited_by_count": 53,
    "openalex_id": "https://openalex.org/W2160685416",
    "type": "article"
  },
  {
    "title": "Latency-constrained aggregation in sensor networks",
    "doi": "https://doi.org/10.1145/1644015.1644028",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Luca Becchetti; Alberto Marchetti-Spaccamela; Andrea Vitaletti; Peter Korteweg; Martin Skutella; Leen Stougie",
    "corresponding_authors": "",
    "abstract": "A sensor network consists of sensing devices which may exchange data through wireless communication; sensor networks are highly energy constrained since they are usually battery operated. Data aggregation is a possible way to save energy consumption: nodes may delay data in order to aggregate them into a single packet before forwarding them towards some central node (sink). However, many applications impose constraints on the maximum delay of data; this translates into latency constraints for data arriving at the sink. We study the problem of data aggregation to minimize maximum energy consumption under latency constraints on sensed data delivery, and we assume unique communication paths that form an intree rooted at the sink. We prove that the offline problem is strongly NP-hard and we design a 2-approximation algorithm. The latter uses a novel rounding technique. Almost all real-life sensor networks are managed online by simple distributed algorithms in the nodes. In this context we consider both the case in which sensor nodes are synchronized or not. We assess the performance of the algorithm by competitive analysis. We also provide lower bounds for the models we consider, in some cases showing optimality of the algorithms we propose. Most of our results also hold when minimizing the total energy consumption of all nodes.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2160543991",
    "type": "article"
  },
  {
    "title": "Optimal dynamic vertical ray shooting in rectilinear planar subdivisions",
    "doi": "https://doi.org/10.1145/1541885.1541889",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Yoav Giora; Haim Kaplan",
    "corresponding_authors": "",
    "abstract": "We consider the dynamic vertical ray shooting problem against horizontal disjoint segments, that is, the task of maintaining a dynamic set S of n nonintersecting horizontal line segments in the plane under a query that reports the first segment in S intersecting a vertical ray from a query point. We develop a linear-size structure that supports queries, insertions, and deletion in O (log n ) worst-case time. Our structure works in the comparison model on a random access machine.",
    "cited_by_count": 48,
    "openalex_id": "https://openalex.org/W2116268321",
    "type": "article"
  },
  {
    "title": "A near-optimal algorithm for estimating the entropy of a stream",
    "doi": "https://doi.org/10.1145/1798596.1798604",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Amit Chakrabarti; Graham Cormode; Andrew McGregor",
    "corresponding_authors": "",
    "abstract": "We describe a simple algorithm for approximating the empirical entropy of a stream of m values up to a multiplicative factor of (1+ϵ) using a single pass, O (ϵ −2 log (δ −1 ) log m ) words of space, and O (log ϵ −1 + log log δ −1 + log log m ) processing time per item in the stream. Our algorithm is based upon a novel extension of a method introduced by Alon et al. [1999]. This improves over previous work on this problem. We show a space lower bound of Ω(ϵ −2 /log 2 (ϵ −1 )), demonstrating that our algorithm is near-optimal in terms of its dependency on ϵ. We show that generalizing to multiplicative-approximation of the k th-order entropy requires close to linear space for k ≥1. In contrast we show that additive-approximation is possible in a single pass using only poly-logarithmic space. Lastly, we show how to compute a multiplicative approximation to the entropy of a random walk on an undirected graph.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2104635635",
    "type": "article"
  },
  {
    "title": "Geodesic Fréchet distance inside a simple polygon",
    "doi": "https://doi.org/10.1145/1868237.1868247",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Atlas F. Cook; Carola Wenk",
    "corresponding_authors": "",
    "abstract": "We present an alternative to parametric search that applies to both the nongeodesic and geodesic Fréchet optimization problems. This randomized approach is based on a variant of red-blue intersections and is appealing due to its elegance and practical efficiency when compared to parametric search. We introduce the first algorithm to compute the geodesic Fréchet distance between two polygonal curves A and B inside a simple bounding polygon P . The geodesic Fréchet decision problem is solved almost as fast as its nongeodesic sibling in O ( N 2 log k ) time and O ( k + N ) space after O(k) preprocessing, where N is the larger of the complexities of A and B and k is the complexity of P . The geodesic Fréchet optimization problem is solved by a randomized approach in O ( k + N 2 log kN log N ) expected time and O ( k + N 2 ) space. This runtime is only a logarithmic factor larger than the standard nongeodesic Fréchet algorithm [Alt and Godau 1995]. Results are also presented for the geodesic Fréchet distance in a polygonal domain with obstacles and the geodesic Hausdorff distance for sets of points or sets of line segments inside a simple polygon P .",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2113946784",
    "type": "article"
  },
  {
    "title": "Elimination graphs",
    "doi": "https://doi.org/10.1145/2151171.2151177",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Yuli Ye; Allan Borodin",
    "corresponding_authors": "",
    "abstract": "In this article we study graphs with inductive neighborhood properties. Let P be a graph property, a graph G = ( V, E ) with n vertices is said to have an inductive neighborhood property with respect to P if there is an ordering of vertices v 1 , …, v n such that the property P holds on the induced subgraph G [ N ( v i )∩ V i ], where N ( v i ) is the neighborhood of v i and V i = { v i , …, v n }. It turns out that if we take P as a graph with maximum independent set size no greater than k , then this definition gives a natural generalization of both chordal graphs and ( k + 1)-claw-free graphs. We refer to such graphs as inductive k -independent graphs. We study properties of such families of graphs, and we show that several natural classes of graphs are inductive k -independent for small k . In particular, any intersection graph of translates of a convex object in a two dimensional plane is an inductive 3 -independent graph; furthermore, any planar graph is an inductive 3 -independent graph. For any fixed constant k , we develop simple, polynomial time approximation algorithms for inductive k -independent graphs with respect to several well-studied NP-complete problems. Our generalized formulation unifies and extends several previously known results.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2294341534",
    "type": "article"
  },
  {
    "title": "All-pairs shortest paths for unweighted undirected graphs in <i>o</i> ( <i>mn</i> ) time",
    "doi": "https://doi.org/10.1145/2344422.2344424",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Timothy M. Chan",
    "corresponding_authors": "Timothy M. Chan",
    "abstract": "We revisit the all-pairs-shortest-paths problem for an unweighted undirected graph with n vertices and m edges. We present new algorithms with the following running times: { O ( mn /log n ) if m &gt; n log n log log log n O ( mn log log n /log n ) if m &gt; n log log n O ( n 2 log 2 log n /log n ) if m ≤ n log log n . These represent the best time bounds known for the problem for all m ≪ n 1.376 . We also obtain a similar type of result for the diameter problem for unweighted directed graphs.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2623150993",
    "type": "article"
  },
  {
    "title": "Comparison-based time-space lower bounds for selection",
    "doi": "https://doi.org/10.1145/1721837.1721842",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Timothy M. Chan",
    "corresponding_authors": "Timothy M. Chan",
    "abstract": "We establish the first nontrivial lower bounds on time-space trade-offs for the selection problem. We prove that any comparison-based randomized algorithm for finding the median requires Ω( n log log S n ) expected time in the RAM model (or more generally in the comparison branching program model), if we have S bits of extra space besides the read-only input array. This bound is tight for all S &gt; log n , and remains true even if the array is given in a random order. Our result thus answers a 16-year-old question of Munro and Raman [1996], and also complements recent lower bounds that are restricted to sequential access, as in the multipass streaming model [Chakrabarti et al. 2008b]. We also prove that any comparison-based, deterministic, multipass streaming algorithm for finding the median requires Ω( n log * ( n / s )+ n log s n ) worst-case time (in scanning plus comparisons), if we have s cells of space. This bound is also tight for all s &gt;log 2 n . We get deterministic lower bounds for I/O-efficient algorithms as well. The proofs in this article are self-contained and do not rely on communication complexity techniques.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W1980190601",
    "type": "article"
  },
  {
    "title": "Online Optimization with Uncertain Information",
    "doi": "https://doi.org/10.1145/2071379.2071381",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Mohammad Mahdian; Hamid Nazerzadeh; Amin Saberi",
    "corresponding_authors": "",
    "abstract": "We introduce a new framework for designing online algorithms that can incorporate additional information about the input sequence, while maintaining a reasonable competitive ratio if the additional information is incorrect. Within this framework, we present online algorithms for several problems including allocation of online advertisement space, load balancing, and facility location.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2128606244",
    "type": "article"
  },
  {
    "title": "On exact algorithms for treewidth",
    "doi": "https://doi.org/10.1145/2390176.2390188",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Hans L. Bodlaender; Fedor V. Fomin; Arie M. C. A. Koster; Dieter Kratsch; Dimitrios M. Thilikos",
    "corresponding_authors": "",
    "abstract": "We give experimental and theoretical results on the problem of computing the treewidth of a graph by exact exponential-time algorithms using exponential space or using only polynomial space. We first report on an implementation of a dynamic programming algorithm for computing the treewidth of a graph with running time O *(2 n ). This algorithm is based on the old dynamic programming method introduced by Held and Karp for the Traveling Salesman problem. We use some optimizations that do not affect the worst case running time but improve on the running time on actual instances and can be seen to be practical for small instances. We also consider the problem of computing Treewidth under the restriction that the space used is only polynomial and give a simple O *(4 n ) algorithm that requires polynomial space. We also show that with a more complicated algorithm using balanced separators, Treewidth can be computed in O *(2.9512 n ) time and polynomial space.",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W1969259020",
    "type": "article"
  },
  {
    "title": "Scalably scheduling processes with arbitrary speedup curves",
    "doi": "https://doi.org/10.1145/2229163.2229172",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Jeff Edmonds; Kirk Pruhs",
    "corresponding_authors": "",
    "abstract": "We give a scalable ((1+ϵ)-speed O (1)-competitive) nonclairvoyant algorithm for scheduling jobs with sublinear nondecreasing speedup curves on multiple processors with the objective of average response time.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2124402683",
    "type": "article"
  },
  {
    "title": "Optimal Pattern Matching in LZW Compressed Strings",
    "doi": "https://doi.org/10.1145/2483699.2483705",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Paweł Gawrychowski",
    "corresponding_authors": "Paweł Gawrychowski",
    "abstract": "We consider the following variant of the classical pattern matching problem: given an uncompressed pattern p [1.. m ] and a compressed representation of a string t [1.. N ], does p occur in t ? When t is compressed using the LZW method, we are able to detect the occurrence in optimal linear time, thus answering a question of Amir et al. [1994]. Previous results implied solutions with complexities O ( n log m + m ) Amir et al. [1994], O ( n + m 1+ε ) [Kosaraju 1995], or (randomized) O ( n log Nn + m ) [Farach and Thorup 1995], where n is the size of the compressed representation of t . Our algorithm is conceptually simple and fully deterministic.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2140687800",
    "type": "article"
  },
  {
    "title": "Tight Kernel Bounds for Problems on Graphs with Small Degeneracy",
    "doi": "https://doi.org/10.1145/3108239",
    "publication_date": "2017-07-31",
    "publication_year": 2017,
    "authors": "Marek Cygan; Fabrizio Grandoni; Danny Hermelin",
    "corresponding_authors": "",
    "abstract": "Kernelization is a strong and widely applied technique in parameterized complexity. In a nutshell, a kernelization algorithm for a parameterized problem transforms in polynomial time a given instance of the problem into an equivalent instance whose size depends solely on the parameter. Recent years have seen major advances in the study of both upper and lower bound techniques for kernelization, and by now this area has become one of the major research threads in parameterized complexity. In this article, we consider kernelization for problems on d -degenerate graphs, that is, graphs such that any subgraph contains a vertex of degree at most d . This graph class generalizes many classes of graphs for which effective kernelization is known to exist, for example, planar graphs, H -minor free graphs, and H -topological-minor free graphs. We show that for several natural problems on d -degenerate graphs the best-known kernelization upper bounds are essentially tight. In particular, using intricate constructions of weak compositions, we prove that unless coNP ⊆ NP/poly: • D ominating S et has no kernels of size O ( k ( d −1)( d −3)−ε ) for any ε &gt; 0. The current best upper bound is O ( k (d+1) 2 ). • I ndependent D ominating S et has no kernels of size O ( k d −4−ε ) for any ε &gt; 0. The current best upper bound is O ( k d +1 ). • I nduced M atching has no kernels of size O ( k d −3−ε ) for any ε &gt; 0. The current best upper bound is O ( k d ). To the best of our knowledge, D ominating S et is the the first problem where a lower bound with superlinear dependence on d (in the exponent) can be proved. In the last section of the article, we also give simple kernels for C onnected V ertex C over and C apacitated V ertex C over of size O ( k d ) and O ( k d +1 ), respectively. We show that the latter problem has no kernels of size O ( k d −ε ) unless coNP ⊆ NP/poly by a simple reduction from d -E xact S et C over (the same lower bound for C onnected V ertex C over on d -degenerate graphs is already known).",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2153676433",
    "type": "article"
  },
  {
    "title": "Min <i>st</i> -Cut Oracle for Planar Graphs with Near-Linear Preprocessing Time",
    "doi": "https://doi.org/10.1145/2684068",
    "publication_date": "2015-01-13",
    "publication_year": 2015,
    "authors": "Glencora Borradaile; Piotr Sankowski; Christian Wulff‐Nilsen",
    "corresponding_authors": "",
    "abstract": "For an undirected n -vertex planar graph G with nonnegative edge weights, we consider the following type of query: given two vertices s and t in G , what is the weight of a min st -cut in G ? We show how to answer such queries in constant time with O ( n log 4 n ) preprocessing time and O ( n log n ) space. We use a Gomory-Hu tree to represent all the pairwise min cuts implicitly. Previously, no subquadratic time algorithm was known for this problem. Since all-pairs min cut and the minimum-cycle basis are dual problems in planar graphs, we also obtain an implicit representation of a minimum-cycle basis in O ( n log 4 n ) time and O ( n log n ) space. Additionally, an explicit representation can be obtained in O ( C ) time and space where C is the size of the basis. These results require that shortest paths are unique. This can be guaranteed either by using randomization without overhead or deterministically with an additional log 2 n factor in the preprocessing times.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W1980410492",
    "type": "article"
  },
  {
    "title": "Improved Approximation Algorithms for Matroid and Knapsack Median Problems and Applications",
    "doi": "https://doi.org/10.1145/2963170",
    "publication_date": "2016-08-03",
    "publication_year": 2016,
    "authors": "Chaitanya Swamy",
    "corresponding_authors": "Chaitanya Swamy",
    "abstract": "We consider the matroid median problem [Krishnaswamy et al. 2011], wherein we are given a set of facilities with opening costs and a matroid on the facility-set, and clients with demands and connection costs, and we seek to open an independent set of facilities and assign clients to open facilities so as to minimize the sum of the facility-opening and client-connection costs. We give a simple 8-approximation algorithm for this problem based on LP-rounding, which improves upon the 16-approximation in Krishnaswamy et al. [2011]. We illustrate the power and versatility of our techniques by deriving (a) an 8-approximation for the two-matroid median problem, a generalization of matroid median that we introduce involving two matroids; and (b) a 24-approximation algorithm for matroid median with penalties , which is a vast improvement over the 360-approximation obtained in Krishnaswamy et al. [2011]. We show that a variety of seemingly disparate facility-location problems considered in the literature—data placement problem, mobile facility location, k -median forest, metric uniform minimum-latency Uncapacitated Facility Location (UFL)—in fact reduce to the matroid median or two-matroid median problems, and thus obtain improved approximation guarantees for all these problems. Our techniques also yield an improvement for the knapsack median problem.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W1524471135",
    "type": "article"
  },
  {
    "title": "Race to idle",
    "doi": "https://doi.org/10.1145/2556953",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Susanne Albers; Antonios Antoniadis",
    "corresponding_authors": "",
    "abstract": "We study an energy conservation problem where a variable-speed processor is equipped with a sleep state. Executing jobs at high speeds and then setting the processor asleep is an approach that can lead to further energy savings compared to standard dynamic speed scaling. We consider classical deadline-based scheduling, that is, each job is specified by a release time, a deadline and a processing volume. For general convex power functions, Irani et al. [2007] devised an offline 2-approximation algorithm. Roughly speaking, the algorithm schedules jobs at a critical speed s crit that yields the smallest energy consumption while jobs are processed. For power functions P ( s ) = s α &amp; γ, where s is the processor speed, Han et al. [2010] gave an α α + 2)-competitive online algorithm. We investigate the offline setting of speed scaling with a sleep state. First, we prove NP-hardness of the optimization problem. Additionally, we develop lower bounds, for general convex power functions: No algorithm that constructs s crit -schedules, which execute jobs at speeds of at least s crit , can achieve an approximation factor smaller than 2. Furthermore, no algorithm that minimizes the energy expended for processing jobs can attain an approximation ratio smaller than 2. We then present an algorithmic framework for designing good approximation algorithms. For general convex power functions, we derive an approximation factor of 4/3. For power functions P ( s ) = β s α + γ, we obtain an approximation of 137/117 &gt; 1.171. We finally show that our framework yields the best approximation guarantees for the class of s crit -schedules. For general convex power functions, we give another 2-approximation algorithm. For functions P ( s ) = β s α + γ, we present tight upper and lower bounds on the best possible approximation factor. The ratio is exactly eW −1 (− e −1−1/ e )/( eW −1 (− e −1−1/ e )+1) &gt; 1.211, where W -1 is the lower branch of the Lambert W function.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2135755782",
    "type": "article"
  },
  {
    "title": "Max-Sum Diversification, Monotone Submodular Functions, and Dynamic Updates",
    "doi": "https://doi.org/10.1145/3086464",
    "publication_date": "2017-07-13",
    "publication_year": 2017,
    "authors": "Allan Borodin; Aadhar Jain; Hyun Chul Lee; Yuli Ye",
    "corresponding_authors": "",
    "abstract": "Result diversification is an important aspect in web-based search, document summarization, facility location, portfolio management, and other applications. Given a set of ranked results for a set of objects (e.g., web documents, facilities, etc.) with a distance between any pair, the goal is to select a subset S satisfying the following three criteria: (a) the subset S satisfies some constraint (e.g., bounded cardinality), (b) the subset contains results of high “quality,” and (c) the subset contains results that are “diverse” relative to the distance measure. The goal of result diversification is to produce a diversified subset while maintaining high quality as much as possible. We study a broad class of problems where the distances are a metric, where the constraint is given by independence in a matroid, where quality is determined by a monotone submodular function and diversity is defined as the sum of distances between objects in S . Our problem is a generalization of the max-sum diversification problem studied in Gollapudi and Sharma [2009], which in turn is a generalization of the max-sum p-dispersion problem studied extensively in location theory. It is NP-hard even with the triangle inequality. We propose two simple and natural algorithms: a greedy algorithm for a cardinality constraint and a local search algorithm for an arbitrary matroid constraint. We prove that both algorithms achieve constant approximation ratios.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2735816714",
    "type": "article"
  },
  {
    "title": "Efficient Algorithms for Constructing Very Sparse Spanners and Emulators",
    "doi": "https://doi.org/10.1145/3274651",
    "publication_date": "2018-11-16",
    "publication_year": 2018,
    "authors": "Michael Elkin; Ofer Neiman",
    "corresponding_authors": "",
    "abstract": "Miller et al. [48] devised a distributed 1 algorithm in the CONGEST model that, given a parameter k = 1,2,…, constructs an O ( k )-spanner of an input unweighted n -vertex graph with O ( n 1+1/ k ) expected edges in O ( k ) rounds of communication. In this article, we improve the result of Reference [48] by showing a k -round distributed algorithm in the same model that constructs a (2 k −1)-spanner with O ( n 1+1/ k }/ϵ) edges, with probability 1−ϵ for any ϵ&gt;0. Moreover, when k =ω(log n ), our algorithm produces (still in k rounds) ultra-sparse spanners, i.e., spanners of size n (1+ o (1)), with probability 1− o (1). To our knowledge, this is the first distributed algorithm in the CONGEST or in the PRAM models that constructs spanners or skeletons (i.e., connected spanning subgraphs) that are sparse. Our algorithm can also be implemented in linear time in the standard centralized model, and for large k , it provides spanners that are sparser than any other spanner given by a known (near-)linear time algorithm. We also devise improved bounds (and algorithms realizing these bounds) for (1+ϵ, β)-spanners and emulators. In particular, we show that for any unweighted n -vertex graph and any ϵ &gt; 0, there exists a (1+ ϵ, (log log n / ϵ) log log n )-emulator with O ( n ) edges. All previous constructions of (1+ϵ, β)-spanners and emulators employ a superlinear number of edges for all choices of parameters. Finally, we provide some applications of our results to approximate shortest paths’ computation in unweighted graphs.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2900806478",
    "type": "article"
  },
  {
    "title": "Combinatorial Algorithm for Restricted Max-Min Fair Allocation",
    "doi": "https://doi.org/10.1145/3070694",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Chidambaram Annamalai; Christos Kalaitzis; Ola Svensson",
    "corresponding_authors": "",
    "abstract": "We study the basic allocation problem of assigning resources to players to maximize fairness. This is one of the few natural problems that enjoys the intriguing status of having a better estimation algorithm than approximation algorithm. Indeed, a certain Configuration-LP can be used to estimate the value of the optimal allocation to within a factor of 4+ ε. In contrast, however, the best-known approximation algorithm for the problem has an unspecified large constant guarantee. In this article, we significantly narrow this gap by giving a 13-approximation algorithm for the problem. Our approach develops a local search technique introduced by Haxell [13] for hypergraph matchings and later used in this context by Asadpour, Feige, and Saberi [2]. For our local search procedure to terminate in polynomial time, we introduce several new ideas, such as lazy updates and greedy players . Besides the improved approximation guarantee, the highlight of our approach is that it is purely combinatorial and uses the Configuration-LP only in the analysis.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2168581227",
    "type": "article"
  },
  {
    "title": "The Complexity of Independent Set Reconfiguration on Bipartite Graphs",
    "doi": "https://doi.org/10.1145/3280825",
    "publication_date": "2018-10-30",
    "publication_year": 2018,
    "authors": "Daniel Lokshtanov; Amer E. Mouawad",
    "corresponding_authors": "",
    "abstract": "We settle the complexity of the I ndependent S et R econfiguration problem on bipartite graphs under all three commonly studied reconfiguration models. We show that under the token jumping or token addition/removal model, the problem is NP-complete. For the token sliding model, we show that the problem remains PSPACE-complete.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2899024477",
    "type": "article"
  },
  {
    "title": "On Hierarchical Routing in Doubling Metrics",
    "doi": "https://doi.org/10.1145/2915183",
    "publication_date": "2016-08-16",
    "publication_year": 2016,
    "authors": "T-H. Hubert Chan; Anupam Gupta; Bruce M. Maggs; Shuheng Zhou",
    "corresponding_authors": "",
    "abstract": "We study the problem of routing in doubling metrics and show how to perform hierarchical routing in such metrics with small stretch and compact routing tables (i.e., with a small amount of routing information stored at each vertex). We say that a metric ( X , d ) has doubling dimension dim(&lt;i&lt;X&lt;/i&lt;) at most α if every ball can be covered by 2 α balls of half its radius. (A doubling metric is one whose doubling dimension dim(&lt;i&lt;X&lt;/i&lt;) is a constant.) We consider the metric space induced by the shortest-path distance in an underlying undirected graph G . We show how to perform (1 + τ)-stretch routing on such a metric for any 0 &lt; τ ≤ 1 with routing tables of size at most (α/τ) O (α) log Δlog δ bits with only (α/τ) O (α) log Δ entries , where Δ is the diameter of the graph, and δ is the maximum degree of the graph G ; hence, the number of routing table entries is just τ − O (1) log Δ for doubling metrics. These results extend and improve on those of Talwar (2004). We also give better constructions of sparse spanners for doubling metrics than those obtained from the routing tables earlier; for τ &gt; 0, we give algorithms to construct (1 + τ)-stretch spanners for a metric ( X , d ) with maximum degree at most (2 + 1/τ) O(dim(X)) , matching the results of Das et al. for Euclidean metrics.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W3137290582",
    "type": "article"
  },
  {
    "title": "Tree Edit Distance Cannot be Computed in Strongly Subcubic Time (Unless APSP Can)",
    "doi": "https://doi.org/10.1145/3381878",
    "publication_date": "2020-07-06",
    "publication_year": 2020,
    "authors": "Karl Bringmann; Paweł Gawrychowski; Shay Mozes; Oren Weimann",
    "corresponding_authors": "",
    "abstract": "The edit distance between two rooted ordered trees with n nodes labeled from an alphabet Ʃ is the minimum cost of transforming one tree into the other by a sequence of elementary operations consisting of deleting and relabeling existing nodes, as well as inserting new nodes. Tree edit distance is a well-known generalization of string edit distance. The fastest known algorithm for tree edit distance runs in cubic O ( n 3 ) time and is based on a similar dynamic programming solution as string edit distance. In this article, we show that a truly subcubic O ( n 3-ε ) time algorithm for tree edit distance is unlikely: For |Ʃ| = Ω ( n ), a truly subcubic algorithm for tree edit distance implies a truly subcubic algorithm for the all pairs shortest paths problem. For |Ʃ| = O (1), a truly subcubic algorithm for tree edit distance implies an O ( n k-ε ) algorithm for finding a maximum weight k -clique. Thus, while in terms of upper bounds string edit distance and tree edit distance are highly related, in terms of lower bounds string edit distance exhibits the hardness of the strong exponential time hypothesis (Backurs, Indyk STOC’15) whereas tree edit distance exhibits the hardness of all pairs shortest paths. Our result provides a matching conditional lower bound for one of the last remaining classic dynamic programming problems.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W3040166286",
    "type": "article"
  },
  {
    "title": "Polynomial-time Algorithm for Maximum Weight Independent Set on <i>P</i> <sub>6</sub> -free Graphs",
    "doi": "https://doi.org/10.1145/3414473",
    "publication_date": "2022-01-23",
    "publication_year": 2022,
    "authors": "Andrzej Grzesik; Tereza Klimošová; Marcin Pilipczuk; Michał Pilipczuk",
    "corresponding_authors": "",
    "abstract": "In the classic Maximum Weight Independent Set problem, we are given a graph G with a nonnegative weight function on its vertices, and the goal is to find an independent set in G of maximum possible weight. While the problem is NP-hard in general, we give a polynomial-time algorithm working on any P 6 -free graph, that is, a graph that has no path on 6 vertices as an induced subgraph. This improves the polynomial-time algorithm on P 5 -free graphs of Lokshtanov et al. [ 15 ] and the quasipolynomial-time algorithm on P 6 -free graphs of Lokshtanov et al. [ 14 ]. The main technical contribution leading to our main result is enumeration of a polynomial-size family ℱ of vertex subsets with the following property: For every maximal independent set I in the graph, ℱ contains all maximal cliques of some minimal chordal completion of G that does not add any edge incident to a vertex of I .",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W4226048850",
    "type": "article"
  },
  {
    "title": "Optimal Parameterized Algorithms for Planar Facility Location Problems Using Voronoi Diagrams",
    "doi": "https://doi.org/10.1145/3483425",
    "publication_date": "2022-03-30",
    "publication_year": 2022,
    "authors": "Dániel Marx; Michał Pilipczuk",
    "corresponding_authors": "",
    "abstract": "We study a general family of facility location problems defined on planar graphs and on the two-dimensional plane. In these problems, a subset of k objects has to be selected, satisfying certain packing (disjointness) and covering constraints. Our main result is showing that, for each of these problems, the n O (√ k ) time brute force algorithm of selecting k objects can be improved to n O (√ k ) time. The algorithm is based on an idea that was introduced recently in the design of geometric QPTASs, but was not yet used for exact algorithms and for planar graphs. We focus on the Voronoi diagram of a hypothetical solution of k objects, guess a balanced separator cycle of this Voronoi diagram to obtain a set that separates the solution in a balanced way, and then recurse on the resulting subproblems. The following list is an exemplary selection of concrete consequences of our main result. We can solve each of the following problems in time n O (√ k ), where n is the total size of the input: d -Scattered Set : find k vertices in an edge-weighted planar graph that pairwise are at distance at least d from each other ( d is part of the input). d -Dominating Set (or ( k,d )-Center): find k vertices in an edge-weighted planar graph such that every vertex of the graph is at distance at most d from at least one selected vertex ( d is part of the input). Given a set D of connected vertex sets in a planar graph G , find k disjoint vertex sets in D . Given a set D of disks in the plane (of possibly different radii), find k disjoint disks in D . Given a set D of simple polygons in the plane, find k disjoint polygons in D . Given a set D of disks in the plane (of possibly different radii) and a set P of points, find k disks in D that together cover the maximum number of points in P . Given a set D of axis-parallel squares in the plane (of possibly different sizes) and a set P of points, find k squares in D that together cover the maximum number of points in P . It is known from previous work that, assuming the Exponential Time Hypothesis (ETH), there is no f ( k ) n o (√ k ) time algorithm for any computable function f for any of these problems. Furthermore, we give evidence that packing problems have n O (√ k ) time algorithms for a much more general class of objects than covering problems have. For example, we show that, assuming ETH, the problem where a set D of axis-parallel rectangles and a set P of points are given, and the task is to select k rectangles that together cover the entire point set, does not admit an f ( k ) n o ( k ) time algorithm for any computable function f .",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2949765771",
    "type": "article"
  },
  {
    "title": "Peeling Close to the Orientability Threshold – Spatial Coupling in Hashing-Based Data Structures",
    "doi": "https://doi.org/10.1145/3711822",
    "publication_date": "2025-01-09",
    "publication_year": 2025,
    "authors": "Stefan Walzer",
    "corresponding_authors": "Stefan Walzer",
    "abstract": "In multiple-choice data structures each element \\(x\\) in a set \\(S\\) of \\(m\\) keys is associated with a random set \\(e(x) \\subseteq [n]\\) of buckets with capacity \\(\\ell\\geq 1\\) by hash functions. This setting is captured by the hypergraph \\(H=([n],\\{e(x)\\mid x \\in S\\})\\) . Accommodating each key in an associated bucket amounts to finding an \\(\\ell\\) -orientation of \\(H\\) assigning to each hyperedge an incident vertex such that each vertex is assigned at most \\(\\ell\\) hyperedges. If each subhypergraph of \\(H\\) has minimum degree at most \\(\\ell\\) , then an \\(\\ell\\) -orientation can be found greedily and \\(H\\) is called \\(\\ell\\) -peelable . Peelability has a central role in invertible Bloom lookup tables and can speed up the construction of retrieval data structures, perfect hash functions, and cuckoo hash tables. Many hypergraphs exhibit sharp density thresholds with respect to \\(\\ell\\) -orientability and \\(\\ell\\) -peelability, i.e., as the density \\(c=\\frac{m}{n}\\) grows past a critical value, the probability of these properties drops from almost \\(1\\) to almost \\(0\\) . In fully random \\(k\\) -uniform hypergraphs the thresholds \\(c_{\\smash{k,\\ell}}^{*}\\) for \\(\\ell\\) -orientability significantly exceed the thresholds for \\(\\ell\\) -peelability. In this article, for every \\(k\\geq 2\\) and \\(\\ell\\geq 1\\) with \\((k,\\ell)\\neq(2,1)\\) and every \\(z&gt;0\\) , we construct a new family of random \\(k\\) -uniform hypergraphs with i.i.d. random hyperedges such that both the \\(\\ell\\) -peelability and the \\(\\ell\\) -orientability thresholds approach \\(c_{\\smash{k,\\ell}}^{*}\\) as \\(z \\rightarrow \\infty \\) . In particular, we achieve \\(1\\) -peelability at densities arbitrarily close to \\(1\\) , extending the reach of greedy algorithms. Our construction is simple: The \\(n\\) vertices are linearly ordered and each hyperedge selects its \\(k\\) elements uniformly at random from a random range of \\(\\frac{n}{z+1}\\) consecutive vertices. We thus exploit the phenomenon of threshold saturation via spatial coupling discovered in the context of low-density parity-check codes. Once the connection to data structures is in plain sight, a framework by Kudekar, Richardson and Urbanke does the heavy lifting in our proof. We demonstrate the usefulness of our construction using our hypergraphs as a drop-in replacement in a retrieval data structure by Botelho et al. This reduces memory usage from \\(\\approx 1.23m\\) bits to \\(\\approx 1.12m\\) bits (for input size \\(m\\) ). Using \\(k&gt;3\\) attains, at small sacrifices in running time, further improvements to memory usage.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3003904644",
    "type": "article"
  },
  {
    "title": "Quasiconvex analysis of multivariate recurrence equations for backtracking algorithms",
    "doi": "https://doi.org/10.1145/1198513.1198515",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "David Eppstein",
    "corresponding_authors": "David Eppstein",
    "abstract": "We consider a class of multivariate recurrences frequently arising in the worst-case analysis of Davis-Putnam-style exponential-time backtracking algorithms for NP-hard problems. We describe a technique for proving asymptotic upper bounds on these recurrences, by using a suitable weight function to reduce the problem to that of solving univariate linear recurrences; show how to use quasiconvex programming to determine the weight function yielding the smallest upper bound; and prove that the resulting upper bounds are within a polynomial factor of the true asymptotics of the recurrence. We develop and implement a multiple-gradient descent algorithm for the resulting quasiconvex programs, using a real-number arithmetic package for guaranteed accuracy of the computed worst-case time bounds.",
    "cited_by_count": 55,
    "openalex_id": "https://openalex.org/W2014430206",
    "type": "article"
  },
  {
    "title": "Approximation algorithms for the capacitated minimum spanning tree problem and its variants in network design",
    "doi": "https://doi.org/10.1145/1103963.1103967",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Raja Jothi; Balaji Raghavachari",
    "corresponding_authors": "",
    "abstract": "Given an undirected graph G = ( V,E ) with nonnegative costs on its edges, a root node r V , a set of demands D V with demand v D wishing to route w(v) units of flow (weight) to r , and a positive number k , the Capacitated Minimum Steiner Tree (CMStT) problem asks for a minimum Steiner tree, rooted at r , spanning the vertices in D * &amp;lcub; r &amp;rcub;, in which the sum of the vertex weights in every subtree connected to r is at most k . When D &amp;equals; V , this problem is known as the Capacitated Minimum Spanning Tree (CMST) problem. Both CMsT and CMST problems are NP-hard. In this article, we present approximation algorithms for these problems and several of their variants in network design. Our main results are the following: ---We present a (³ Á ST + 2)-approximation algorithm for the CMStT problem, where ³ is the inverse Steiner ratio , and Á ST is the best achievable approximation ratio for the Steiner tree problem. Our ratio improves the current best ratio of 2Á ST + 2 for this problem. ---In particular, we obtain (³ + 2)-approximation ratio for the CMST problem, which is an improvement over the current best ratio of 4 for this problem. For points in Euclidean and rectilinear planes, our result translates into ratios of 3.1548 and 3.5, respectively. ---For instances in the plane, under the L p norm, with the vertices in D having uniform weights, we present a nontrivial (7/5Á ST + 3/2)-approximation algorithm for the CMStT problem. This translates into a ratio of 2.9 for the CMST problem with uniform vertex weights in the L p metric plane. Our ratio of 2.9 solves the long-standing open problem of obtaining any ratio better than 3 for this case. ---For the CMST problem, we show how to obtain a 2-approximation for graphs in metric spaces with unit vertex weights and k = 3,4. ---For the budgeted CMST problem, in which the weights of the subtrees connected to r could be up to ± k instead of k (± e 1), we obtain a ratio of ³ &amp;plus; 2/±.",
    "cited_by_count": 54,
    "openalex_id": "https://openalex.org/W2004240896",
    "type": "article"
  },
  {
    "title": "On the difficulty of some shortest path problems",
    "doi": "https://doi.org/10.1145/1186810.1186815",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "John Hershberger; Subhash Suri; Amit M. Bhosle",
    "corresponding_authors": "",
    "abstract": "We prove superlinear lower bounds for some shortest path problems in directed graphs, where no such bounds were previously known. The central problem in our study is the replacement paths problem: Given a directed graph G with non-negative edge weights, and a shortest path P = { e 1 , e 2 , …, e p } between two nodes s and t , compute the shortest path distances from s to t in each of the p graphs obtained from G by deleting one of the edges e i . We show that the replacement paths problem requires Ω( m √ n ) time in the worst case whenever m = O ( n √ n ). Our construction also implies a similar lower bound on the k shortest simple paths problem for a broad class of algorithms that includes all known algorithms for the problem. To put our lower bound in perspective, we note that both these problems (replacement paths and k shortest simple paths) can be solved in near-linear time for undirected graphs.",
    "cited_by_count": 50,
    "openalex_id": "https://openalex.org/W2075543862",
    "type": "article"
  },
  {
    "title": "Balanced parentheses strike back",
    "doi": "https://doi.org/10.1145/1367064.1367068",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Hsueh-I Lu; Chia-Chi Yeh",
    "corresponding_authors": "",
    "abstract": "An ordinal tree is an arbitrary rooted tree where the children of each node are ordered. Succinct representations for ordinal trees with efficient query support have been extensively studied. The best previously known result is due to Geary et al. [2004b, pages 1--10]. The number of bits required by their representation for an n -node ordinal tree T is 2 n + o ( n ), whose first-order term is information-theoretically optimal. Their representation supports a large set of O (1)-time queries on T . Based upon a balanced string of 2 n parentheses, we give an improved 2 n + o ( n )-bit representation for T . Our improvement is two-fold: First, the set of O (1)-time queries supported by our representation is a proper superset of that supported by the representation of Geary, Raman, and Raman. Second, it is also much easier for our representation to support new queries by simply adding new auxiliary strings.",
    "cited_by_count": 49,
    "openalex_id": "https://openalex.org/W2157963663",
    "type": "article"
  },
  {
    "title": "On the approximability of some network design problems",
    "doi": "https://doi.org/10.1145/1361192.1361200",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Julia Chuzhoy; Anupam Gupta; Joseph Naor; Amitabh Sinha",
    "corresponding_authors": "",
    "abstract": "Consider the following classical network design problem: a set of terminals T = { t i } wishes to send traffic to a root r in an n -node graph G = ( V , E ). Each terminal t i sends d i units of traffic and enough bandwidth has to be allocated on the edges to permit this. However, bandwidth on an edge e can only be allocated in integral multiples of some base capacity u e and hence provisioning k × u e bandwidth on edge e incurs a cost of ⌈k⌉ times the cost of that edge. The objective is a minimum-cost feasible solution. This is one of many network design problems widely studied where the bandwidth allocation is governed by side constraints: edges can only allow a subset of cables to be purchased on them or certain quality-of-service requirements may have to be met. In this work, we show that this problem and, in fact, several basic problems in this general network design framework cannot be approximated better than Ω(log log n ) unless NP ⊆ DTIME ( n O (log log log n ) ), where | V | = n . In particular, we show that this inapproximability threshold holds for (i) the Priority-Steiner Tree problem, (ii) the (single-sink) Cost-Distance problem, and (iii) the single-sink version of an even more fundamental problem, Fixed Charge Network Flow. Our results provide a further breakthrough in the understanding of the level of complexity of network design problems. These are the first nonconstant hardness results known for all these problems.",
    "cited_by_count": 47,
    "openalex_id": "https://openalex.org/W2166747457",
    "type": "article"
  },
  {
    "title": "Algorithms for capacitated rectangle stabbing and lot sizing with joint set-up costs",
    "doi": "https://doi.org/10.1145/1367064.1367074",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Guy Even; Retsef Levi; Dror Rawitz; Baruch Schieber; Shimon Shahar; Maxim Sviridenko",
    "corresponding_authors": "",
    "abstract": "In the rectangle stabbing problem, we are given a set of axis parallel rectangles and a set of horizontal and vertical lines, and our goal is to find a minimum size subset of lines that intersect all the rectangles. In this article, we study the capacitated version of this problem in which the input includes an integral capacity for each line. The capacity of a line bounds the number of rectangles that the line can cover. We consider two versions of this problem. In the first, one is allowed to use only a single copy of each line ( hard capacities ), and in the second, one is allowed to use multiple copies of every line, but the multiplicities are counted in the size (or weight) of the solution ( soft capacities ). We present an exact polynomial-time algorithm for the weighted one dimensional case with hard capacities that can be extended to the one dimensional weighted case with soft capacities. This algorithm is also extended to solve a certain capacitated multi-item lot-sizing inventory problem with joint set-up costs. For the case of d -dimensional rectangle stabbing with soft capacities, we present a 3 d -approximation algorithm for the unweighted case. For d -dimensional rectangle stabbing problem with hard capacities, we present a bi-criteria algorithm that computes 4 d -approximate solutions that use at most two copies of every line. Finally, we present hardness results for rectangle stabbing when the dimension is part of the input and for a two-dimensional weighted version with hard capacities.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W1970095041",
    "type": "article"
  },
  {
    "title": "Windows scheduling as a restricted version of bin packing",
    "doi": "https://doi.org/10.1145/1273340.1273344",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Amotz Bar-Noy; Richard E. Ladner; Tami Tamir",
    "corresponding_authors": "",
    "abstract": "Given is a sequence of n positive integers w 1 , w 2 ,…, w n that are associated with the items 1,2,… n , respectively. In the windows scheduling problem, the goal is to schedule all the items (equal-length information pages) on broadcasting channels such that the gap between two consecutive appearances of page i on any of the channels is at most w i slots (a slot is the transmission time of one page). In the unit-fractions bin packing problem, the goal is to pack all the items in bins of unit size where the size (width) of item i is 1/ w i . The optimization objective is to minimize the number of channels or bins. In the offline setting, the sequence is known in advance, whereas in the online setting, the items arrive in order and assignment decisions are irrevocable. Since a page requires at least 1/ w i of a channel's bandwidth, it follows that windows scheduling without migration (i.e., all broadcasts of a page must be from the same channel) is a restricted version of unit-fractions bin packing. Let H = ⌈Σ i ==1 n (1/ w i ) be the bandwidth lower bound on the required number of bins (channels). The best-known offline algorithm for the windows scheduling problem used H + O (ln H ) channels. This article presents an offline algorithm for the unit-fractions bin packing problem with at most H + 1 bins. In the online setting, this article presents algorithms for both problems with H + O (√ H ) channels or bins, where the one for the unit-fractions bin packing problem is simpler. On the other hand, this article shows that already for the unit-fractions bin packing problem, any online algorithm must use at least H +Ω(ln H ) bins. For instances in which the window sizes form a divisible sequence, an optimal online algorithm is presented. Finally, this article includes a new NP-hardness proof for the windows scheduling problem.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2098128029",
    "type": "article"
  },
  {
    "title": "Near-optimal algorithms for maximum constraint satisfaction problems",
    "doi": "https://doi.org/10.1145/1541885.1541893",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Moses Charikar; Konstantin Makarychev; Yury Makarychev",
    "corresponding_authors": "",
    "abstract": "In this article, we present two approximation algorithms for the maximum constraint satisfaction problem with k variables in each constraint (MAX k -CSP). Given a (1 − ε) satisfiable 2CSP our first algorithm finds an assignment of variables satisfying a 1 − O (√ε) fraction of all constraints. The best previously known result, due to Zwick, was 1 − O (ε 1/3 ). The second algorithm finds a ck /2 k approximation for the MAX k -CSP problem (where c &gt; 0.44 is an absolute constant). This result improves the previously best known algorithm by Hast, which had an approximation guarantee of Ω( k /(2 k log k )). Both results are optimal assuming the unique games conjecture and are based on rounding natural semidefinite programming relaxations. We also believe that our algorithms and their analysis are simpler than those previously known.",
    "cited_by_count": 44,
    "openalex_id": "https://openalex.org/W2621263703",
    "type": "article"
  },
  {
    "title": "An explicit universal cycle for the ( <i>n</i> -1)-permutations of an <i>n</i> -set",
    "doi": "https://doi.org/10.1145/1798596.1798598",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Frank Ruskey; Aaron Williams",
    "corresponding_authors": "",
    "abstract": "We show how to construct an explicit Hamilton cycle in the directed Cayley graph C → ({σ n , σ n -1 }: S n ), where σ k is the rotation (1 2 … k ). The existence of such cycles was shown by Jackson [1996] but the proof only shows that a certain directed graph is Eulerian, and Knuth [2005] asks for an explicit construction. We show that a simple recursion describes our Hamilton cycle and that the cycle can be generated by an iterative algorithm that uses O ( n ) space. Moreover, the algorithm produces each successive edge of the cycle in constant time; such algorithms are said to be loopless . Finally, our Hamilton cycle can be used to construct an explicit universal cycle for the ( n -1)-permutations of a n -set, or as the basis of an efficient algorithm for generating every n -permutation of an n -set within a circular array or linked list.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2012661148",
    "type": "article"
  },
  {
    "title": "Reasoning about online algorithms with weighted automata",
    "doi": "https://doi.org/10.1145/1721837.1721844",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Benjamin Aminof; Orna Kupferman; Robby Lampert",
    "corresponding_authors": "",
    "abstract": "We describe an automata-theoretic approach for the competitive analysis of online algorithms . Our approach is based on weighted automata , which assign to each input word a cost in R ≥0 . By relating the “unbounded look ahead” of optimal offline algorithms with nondeterminism, and relating the “no look ahead” of online algorithms with determinism, we are able to solve problems about the competitive ratio of online algorithms, and the memory they require, by reducing them to questions about determinization and approximated determinization of weighted automata.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2070937106",
    "type": "article"
  },
  {
    "title": "Lower-bounded facility location",
    "doi": "https://doi.org/10.1145/1824777.1824789",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Zoya Svitkina",
    "corresponding_authors": "Zoya Svitkina",
    "abstract": "We study the lower-bounded facility location problem which generalizes the classical uncapacitated facility location problem in that it comes with lower bound constraints for the number of clients assigned to a facility in the case that this facility is opened. This problem was introduced independently in the papers by Karger and Minkoff [2000] and by Guha et al. [2000], both of which give bicriteria approximation algorithms for it. These bicriteria algorithms come within a constant factor of the optimal solution cost, but they also violate the lower bound constraints by a constant factor. Our result in this article is the first true approximation algorithm for the lower-bounded facility location problem which respects the lower bound constraints and achieves a constant approximation ratio for the objective function. The main technical idea for the design of the algorithm is a reduction to the capacitated facility location problem, which has known constant-factor approximation algorithms.",
    "cited_by_count": 42,
    "openalex_id": "https://openalex.org/W2154044080",
    "type": "article"
  },
  {
    "title": "Optimizing throughput and energy in online deadline scheduling",
    "doi": "https://doi.org/10.1145/1644015.1644025",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Ho-Leung Chan; Joseph Chan; Tak‐Wah Lam; Lap–Kei Lee; Kin-Sum Mak; Prudence W. H. Wong",
    "corresponding_authors": "",
    "abstract": "This article extends the study of online algorithms for energy-efficient deadline scheduling to the overloaded setting. Specifically, we consider a processor that can vary its speed between 0 and a maximum speed T to minimize its energy usage (the rate is believed to be a cubic function of the speed). As the speed is upper bounded, the processor may be overloaded with jobs and no scheduling algorithms can guarantee to meet the deadlines of all jobs. An optimal schedule is expected to maximize the throughput, and furthermore, its energy usage should be the smallest among all schedules that achieve the maximum throughput. In designing a scheduling algorithm, one has to face the dilemma of selecting more jobs and being conservative in energy usage. If we ignore energy usage, the best possible online algorithm is 4-competitive on throughput [Koren and Shasha 1995]. On the other hand, existing work on energy-efficient scheduling focuses on a setting where the processor speed is unbounded and the concern is on minimizing the energy to complete all jobs; O (1)-competitive online algorithms with respect to energy usage have been known [Yao et al. 1995; Bansal et al. 2007a; Li et al. 2006]. This article presents the first online algorithm for the more realistic setting where processor speed is bounded and the system may be overloaded; the algorithm is O (1)-competitive on both throughput and energy usage. If the maximum speed of the online scheduler is relaxed slightly to (1+ϵ) T for some ϵ &gt; 0, we can improve the competitive ratio on throughput to arbitrarily close to one, while maintaining O (1)-competitiveness on energy usage.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2102094940",
    "type": "article"
  },
  {
    "title": "Optimization problems in multiple-interval graphs",
    "doi": "https://doi.org/10.1145/1721837.1721856",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Ayelet Butman; Danny Hermelin; Moshe Lewenstein; Dror Rawitz",
    "corresponding_authors": "",
    "abstract": "Multiple-interval graphs are a natural generalization of interval graphs where each vertex may have more then one interval associated with it. We initiate the study of optimization problems in multiple-interval graphs by considering three classical problems: Minimum Vertex Cover, Minimum Dominating Set, and Maximum Clique. We describe applications for each one of these problems, and then proceed to discuss approximation algorithms for them. Our results can be summarized as follows: Let t be the number of intervals associated with each vertex in a given multiple-interval graph. For Minimum Vertex Cover, we give a (2−1/ t )-approximation algorithm which also works when a t -interval representation of our given graph is absent. Following this, we give a t 2 -approximation algorithm for Minimum Dominating Set which adapts well to more general variants of the problem. We then proceed to prove that Maximum Clique is NP -hard already for 3-interval graphs, and provide a ( t 2 − t +1)/2-approximation algorithm for general values of t ≥ 2, using bounds proven for the so-called transversal number of t -interval families.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2106322572",
    "type": "article"
  },
  {
    "title": "Approximating the distance to monotonicity in high dimensions",
    "doi": "https://doi.org/10.1145/1798596.1798605",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Shahar Fattal; Dana Ron",
    "corresponding_authors": "",
    "abstract": "In this article we study the problem of approximating the distance of a function f : [ n ] d → R to monotonicity where [ n ] = {1,…, n } and R is some fully ordered range. Namely, we are interested in randomized sublinear algorithms that approximate the Hamming distance between a given function and the closest monotone function. We allow both an additive error, parameterized by δ, and a multiplicative error. Previous work on distance approximation to monotonicity focused on the one-dimensional case and the only explicit extension to higher dimensions was with a multiplicative approximation factor exponential in the dimension d . Building on Goldreich et al. [2000] and Dodis et al. [1999], in which there are better implicit results for the case n =2, we describe a reduction from the case of functions over the d -dimensional hypercube [ n ] d to the case of functions over the k -dimensional hypercube [ n ] k , where 1≤ k ≤ d . The quality of estimation that this reduction provides is linear in ⌈ d / k ⌉ and logarithmic in the size of the range | R | (if the range is infinite or just very large, then log | R | can be replaced by d log n ). Using this reduction and a known distance approximation algorithm for the one-dimensional case, we obtain a distance approximation algorithm for functions over the d -dimensional hypercube, with any range R , which has a multiplicative approximation factor of O ( d log | R |). For the case of a binary range, we present algorithms for distance approximation to monotonicity of functions over one dimension, two dimensions, and the k -dimensional hypercube (for any k ≥ 1). Applying these algorithms and the reduction described before, we obtain a variety of distance approximation algorithms for Boolean functions over the d -dimensional hypercube which suggest a trade-off between quality of estimation and efficiency of computation. In particular, the multiplicative error ranges between O ( d ) and O (1).",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W1992650621",
    "type": "article"
  },
  {
    "title": "Minimum cycle bases",
    "doi": "https://doi.org/10.1145/1644015.1644023",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Kurt Mehlhorn; Dimitrios Michail",
    "corresponding_authors": "",
    "abstract": "We consider the problem of computing exact or approximate minimum cycle bases of an undirected (or directed) graph G with m edges, n vertices and nonnegative edge weights. In this problem, a {0, 1} (−1,0,1}) incidence vector is associated with each cycle and the vector space over F 2 (Q) generated by these vectors is the cycle space of G . A set of cycles is called a cycle basis of G if it forms a basis for its cycle space. A cycle basis where the sum of the weights of the cycles is minimum is called a minimum cycle basis of G . Cycle bases of low weight are useful in a number of contexts, for example, the analysis of electrical networks, structural engineering, chemistry, and surface reconstruction. There exists a set of Θ( mn ) cycles which is guaranteed to contain a minimum cycle basis. A minimum basis can be extracted by Gaussian elimination. The resulting algorithm [Horton 1987] was the first polynomial-time algorithm. Faster and more complicated algorithms have been found since then. We present a very simple method for extracting a minimum cycle basis from the candidate set with running time O ( m 2 n ), which improves the running time for sparse graphs. Furthermore, in the undirected case by using bit-packing we improve the running time also in the case of dense graphs. For undirected graphs we derive an O ( m 2 n /log n + n 2 m ) algorithm. For directed graphs we get an O ( m 3 n ) deterministic and an O ( m 2 n ) randomized algorithm. Our results improve the running times of both exact and approximate algorithms. Finally, we derive a smaller candidate set with size in Ω( m ) ∩ O ( mn ).",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2095422835",
    "type": "article"
  },
  {
    "title": "Minimizing movement in mobile facility location problems",
    "doi": "https://doi.org/10.1145/1978782.1978783",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Zachary Friggstad; Mohammad R. Salavatipour",
    "corresponding_authors": "",
    "abstract": "In the mobile facility location problem, which is a variant of the classical facility location, each facility and client is assigned to a start location in a metric graph and our goal is to find a destination node for each client and facility such that every client is sent to a node which is the destination of some facility. The quality of a solution can be measured either by the total distance clients and facilities travel or by the maximum distance traveled by any client or facility. As we show in this article (by an approximation-preserving reduction), the problem of minimizing the total movement of facilities and clients generalizes the classical k -median problem. The class of movement problems was introduced by Demaine et al. [2007] where a simple 2-approximation was proposed for the minimum maximum movement mobile facility location problem while an approximation for the minimum total movement variant and hardness results for both were left as open problems. Our main result here is an 8-approximation algorithm for the minimum total movement mobile facility location problem. Our algorithm is obtained by rounding an LP relaxation in five phases. For the minimum maximum movement mobile facility location problem, we show that we cannot have a better than a 2-approximation for the problem, unless P = NP so the simple algorithm proposed by Demaine et al. [2007] is essentially best possible.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2125938788",
    "type": "article"
  },
  {
    "title": "Replacement paths and <i>k</i> simple shortest paths in unweighted directed graphs",
    "doi": "https://doi.org/10.1145/2344422.2344423",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Liam Roditty; Uri Zwick",
    "corresponding_authors": "",
    "abstract": "Let G = ( V,E ) be a directed graph and let P be a shortest path from s to t in G . In the replacement paths problem, we are required to find, for every edge e on P , a shortest path from s to t in G that avoids e . The only known algorithm for solving the problem, even for unweighted directed graphs, is the trivial algorithm in which each edge on the path, in its turn, is excluded from the graph and a shortest paths tree is computed from s . The running time is O ( mn + n 2 log n ). The replacement paths problem is strongly motivated by two different applications: (1) The fastest algorithm to compute the k simple shortest paths between s and t in directed graphs [Yen 1971; Lawler 1972] computes the replacement paths between s and t . Its running time is Õ ( mnk ). (2) The replacement paths problem is used to compute the Vickrey pricing of edges in a distributed network. It was raised as an open problem by Nisan and Ronen [2001] whether it is possible to compute the Vickrey pricing faster than n computations of a shortest paths tree. In this article we present the first nontrivial algorithm for computing replacement paths in unweighted directed graphs (and in graphs with small integer weights). Our algorithm is Monte-Carlo and its running time is Õ ( m √ n ). This result immediately improves the running time of the two applications mentioned above in a factor of √ n . We also show how to reduce the problem of computing k simple shortest paths between s and t to O ( k ) computations of a second simple shortest path from s to t each time in a different subgraph of G . The importance of this result is that computing a second simple shortest path may turn out to be an easier problem than computing the replacement paths, thus, we can focus our efforts to improve the k simple shortest paths algorithm in obtaining a faster algorithm for the second shortest path problem.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2073094163",
    "type": "article"
  },
  {
    "title": "A new upper bound 2.5545 on 2D Online Bin Packing",
    "doi": "https://doi.org/10.1145/2000807.2000818",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Xin Han; Francis Y. L. Chin; Hing‐Fung Ting; Guochuan Zhang; Yong Zhang",
    "corresponding_authors": "",
    "abstract": "The 2D Online Bin Packing is a fundamental problem in Computer Science and the determination of its asymptotic competitive ratio has research attention. In a long series of papers, the lower bound of this ratio has been improved from 1.808, 1.856 to 1.907 and its upper bound reduced from 3.25, 3.0625, 2.8596, 2.7834 to 2.66013. In this article, we rewrite the upper bound record to 2.5545. Our idea for the improvement is as follows. In 2002, Seiden and van Stee [Seiden and van Stee 2003] proposed an elegant algorithm called H ⊗ C , comprised of the Harmonic algorithm H and the Improved Harmonic algorithm C , for the two-dimensional online bin packing problem and proved that the algorithm has an asymptotic competitive ratio of at most 2.66013. Since the best known online algorithm for one-dimensional bin packing is the Super Harmonic algorithm [Seiden 2002], a natural question to ask is: could a better upper bound be achieved by using the Super Harmonic algorithm instead of the Improved Harmonic algorithm? However, as mentioned in Seiden and van Stee [2003], the previous analysis framework does not work. In this article, we give a positive answer for this question. A new upper bound of 2.5545 is obtained for 2-dimensional online bin packing. The main idea is to develop new weighting functions for the Super Harmonic algorithm and propose new techniques to bound the total weight in a rectangular bin.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2029125735",
    "type": "article"
  },
  {
    "title": "Dial a Ride from <i>k</i> -forest",
    "doi": "https://doi.org/10.1145/1721837.1721857",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Anupam Gupta; MohammadTaghi Hajiaghayi; Viswanath Nagarajan; R. Ravi",
    "corresponding_authors": "",
    "abstract": "The k-forest problem is a common generalization of both the k-MST and the dense-k-subgraph problems. Formally, given a metric space on n vertices V , with m demand pairs ⊆ V × V and a “target” k ≤ m , the goal is to find a minimum cost subgraph that connects at least k pairs. In this paper, we give an O (min{√ n ⋅log k ,√ k })-approximation algorithm for k -forest, improving on the previous best ratio of O (min { n 2/3 ,√ m }log n ) by Segev and Segev. We then apply our algsorithm for k -forest to obtain approximation algorithms for several Dial-a-Ride problems. The basic Dial-a-Ride problem is the following: given an n point metric space with m objects each with its own source and destination, and a vehicle capable of carrying at most k objects at any time, find the minimum length tour that uses this vehicle to move each object from its source to destination. We want that the tour be non-preemptive : that is, each object, once picked up at its source, is dropped only at its destination. We prove that an α-approximation algorithm for the k -forest problem implies an O (α⋅log 2 n )-approximation algorithm for Dial-a-Ride. Using our results for k -forest, we get an O (min{√ n ,√ k }⋅log 2 n )-approximation algorithm for Dial-a-Ride. The only previous result known for Dial-a-Ride was an O (√ k log n )-approximation by Charikar and Raghavachari; our results give a different proof of a similar approximation guarantee—in fact, when the vehicle capacity k is large, we give a slight improvement on their results. The reduction from Dial-a-Ride to the k -forest problem is fairly robust, and allows us to obtain approximation algorithms (with the same guarantee) for some interesting generalizations of Dial-a-Ride.",
    "cited_by_count": 38,
    "openalex_id": "https://openalex.org/W2109721451",
    "type": "article"
  },
  {
    "title": "An improved approximation algorithm for resource allocation",
    "doi": "https://doi.org/10.1145/2000807.2000816",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Gruiă Cälinescu; Amit Chakrabarti; Howard Karloff; Yuval Rabani",
    "corresponding_authors": "",
    "abstract": "We study the problem of finding a most profitable subset of n given tasks, each with a given start and finish time as well as profit and resource requirement, that at no time exceeds the quantity B of available resource. We show that this NP-hard Resource Allocation problem can be (1/2 − ε)-approximated in randomized polynomial time, which improves upon earlier approximation results.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W1996971123",
    "type": "article"
  },
  {
    "title": "Succinct ordinal trees based on tree covering",
    "doi": "https://doi.org/10.1145/2344422.2344432",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Meng He; J. Ian Munro; Srinivasa Rao Satti",
    "corresponding_authors": "",
    "abstract": "Various methods have been used to represent a tree on n nodes in essentially the information-theoretic minimum space while supporting various navigational operations in constant time, but different representations usually support different operations. Our main contribution is a succinct representation of ordinal trees, based on that of Geary et al. [2006], that supports all the navigational operations supported by various succinct tree representations while requiring only 2 n + o ( n ) bits. It also supports efficient level-order traversal, a useful ordering previously supported only with a very limited set of operations. Our second contribution expands on the notion of a single succinct representation supporting more than one traversal ordering, by showing that our method supports two other encoding schemes as abstract data types. In particular, it supports extracting a word ( O (lg n ) bits) of the balanced parenthesis sequence or depth first unary degree sequence in O ( f ( n )) time, using at most n / f ( n )+ o ( n ) additional bits, for any f ( n ) in O (lg n ) and Ω(1).",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2153294698",
    "type": "article"
  },
  {
    "title": "Node-Weighted Steiner Tree and Group Steiner Tree in Planar Graphs",
    "doi": "https://doi.org/10.1145/2601070",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Erik D. Demaine; MohammadTaghi Hajiaghayi; Philip N. Klein",
    "corresponding_authors": "",
    "abstract": "We improve the approximation ratios for two optimization problems in planar graphs. For node-weighted Steiner tree, a classical network-optimization problem, the best achievable approximation ratio in general graphs is Θ (log n ), and nothing better was previously known for planar graphs. We give a constant-factor approximation for planar graphs. Our algorithm generalizes to allow as input any nontrivial minor-closed graph family, and also generalizes to address other optimization problems such as Steiner forest, prize-collecting Steiner tree, and network-formation games. The second problem we address is group Steiner tree: given a graph with edge weights and a collection of groups (subsets of nodes), find a minimum-weight connected subgraph that includes at least one node from each group. The best approximation ratio known in general graphs is O (log 3 n ), or O (log 2 n ) when the host graph is a tree. We obtain an O (log n polyloglog n ) approximation algorithm for the special case where the graph is planar embedded and each group is the set of nodes on a face. We obtain the same approximation ratio for the minimum-weight tour that must visit each group.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2089847997",
    "type": "article"
  },
  {
    "title": "Bin Packing via Discrepancy of Permutations",
    "doi": "https://doi.org/10.1145/2483699.2483704",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Friedrich Eisenbrand; Dömötör Pálvölgyi; Thomas Rothvoß",
    "corresponding_authors": "",
    "abstract": "A well-studied special case of bin packing is the 3-partition problem , where n items of size &gt; 1/4 have to be packed in a minimum number of bins of capacity one. The famous Karmarkar-Karp algorithm transforms a fractional solution of a suitable LP relaxation for this problem into an integral solution that requires at most O (log n ) additional bins. The three-permutations-problem of Beck is the following. Given any three permutations on n symbols, color the symbols red and blue, such that in any interval of any of those permutations, the number of red and blue symbols is roughly the same. The necessary difference is called the discrepancy . We establish a surprising connection between bin packing and Beck’s problem: The additive integrality gap of the 3-partition linear programming relaxation can be bounded by the discrepancy of three permutations. This connection yields an alternative method to establish an O (log n ) bound on the additive integrality gap of the 3-partition. Conversely, making use of a recent example of three permutations, for which a discrepancy of Ω(log n ) is necessary, we prove the following: The O (log 2 n ) upper bound on the additive gap for bin packing with arbitrary item sizes cannot be improved by any technique that is based on rounding up items. This lower bound holds for a large class of algorithms including the Karmarkar-Karp procedure.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2083458896",
    "type": "article"
  },
  {
    "title": "Uniform Kernelization Complexity of Hitting Forbidden Minors",
    "doi": "https://doi.org/10.1145/3029051",
    "publication_date": "2017-03-20",
    "publication_year": 2017,
    "authors": "Archontia C. Giannopoulou; Bart M. P. Jansen; Daniel Lokshtanov; Saket Saurabh",
    "corresponding_authors": "",
    "abstract": "The F -M inor -F ree D eletion problem asks, for a fixed set F and an input consisting of a graph G and integer k , whether k vertices can be removed from G such that the resulting graph does not contain any member of F as a minor. At FOCS 2012, Fomin et al. showed that the special case when F contains at least one planar graph has a kernel of size f ( F ) ċ k g ( F ) for some functions f and g . They left open whether this P lanar F -M inor -F ree D eletion problem has kernels whose size is uniformly polynomial, of the form f ( F ) ċ k c for some universal constant c . We prove that some P lanar F -M inor -F ree D eletion problems do not have uniformly polynomial kernels (unless NP ⊆ coNP/poly), not even when parameterized by the vertex cover number. On the positive side, we consider the problem of determining whether k vertices can be removed to obtain a graph of treedepth at most η. We prove that this problem admits uniformly polynomial kernels with O ( k 6 ) vertices for every fixed η.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2140430392",
    "type": "article"
  },
  {
    "title": "A precise analysis of Cuckoo hashing",
    "doi": "https://doi.org/10.1145/2151171.2151174",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Michael Drmota; Reinhard Kutzelnigg",
    "corresponding_authors": "",
    "abstract": "Cuckoo hashing was introduced by Pagh and Rodler in 2001. Its main feature is that it provides constant worst-case search time. The aim of this article is to present a precise average case analysis of Cuckoo hashing. In particular, we determine the probability that Cuckoo hashing produces no conflicts and give an upper bound for the construction time, that is linear in the size of the table. The analysis rests on a generating function approach to the so called Cuckoo Graph, a random bipartite graph, and an application of a double saddle point method to obtain asymptotic expansions. Furthermore, we provide some results concerning the structure of these kinds of random graphs. Our results extend the analysis of Devroye and Morin [2003]. Additionally, we provide numerical results confirming the mathematical analysis.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2153091612",
    "type": "article"
  },
  {
    "title": "Deterministic Truncation of Linear Matroids",
    "doi": "https://doi.org/10.1145/3170444",
    "publication_date": "2018-03-12",
    "publication_year": 2018,
    "authors": "Daniel Lokshtanov; Pranabendu Misra; Fahad Panolan; Saket Saurabh",
    "corresponding_authors": "",
    "abstract": "Let M =( E , I ) be a matroid of rank n . A k - truncation of M is a matroid M ′ =( E , I ′ ) such that for any A ⊆ E , A ∈ ∈ I ′ if and only if | A |≤ k and A ∈ I . Given a linear representation, A , of M , we consider the problem of finding a linear representation, A k , of the k -truncation of M . A common way to compute A k is to multiply the matrix A with a random k × n matrix, yielding a simple randomized algorithm. Thus, a natural question is whether we can compute A k deterministically . In this article, we settle this question for matrices over any field in which the field operations can be done efficiently. This includes any finite field and the field of rational numbers (Q). Our algorithms are based on the properties of the classical Wronskian determinant, and the folded Wronskian determinant, which was recently introduced by Guruswami and Kopparty [23, 24] and Forbes and Shpilka [14]. Our main conceptual contribution in this article is to show that the Wronskian determinant can also be used to obtain a representation of the truncation of a linear matroid in deterministic polynomial time. An important application of our result is a deterministic algorithm to compute representative sets over linear matroids, which derandomizes a result of Fomin et al. [11, 12]. This result derandomizes several parameterized algorithms, including an algorithm for ℓ-M atroid P arity to which several problems, such as ℓ-M atroid I ntersection , can be reduced.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2964186470",
    "type": "article"
  },
  {
    "title": "The Minset-Poset Approach to Representations of Graph Connectivity",
    "doi": "https://doi.org/10.1145/2764909",
    "publication_date": "2016-02-12",
    "publication_year": 2016,
    "authors": "Harold N. Gabow",
    "corresponding_authors": "Harold N. Gabow",
    "abstract": "Various instances of the minimal-set poset (minset-poset for short) have been proposed in the literature, e.g., the representation of Picard and Queyranne for all st -minimum cuts of a flow network. We begin with an explanation of why this poset structure is common. We show any family of sets F that can be defined by a “labelling algorithm” (e.g., the Ford-Fulkerson labelling algorithm for maximum network flow) has an algorithm that constructs the minset poset for F . We implement this algorithm to efficiently find the nodes of the poset when F is the family of minimum edge cuts of an unweighted graph; we also give related algorithms to construct the entire poset for weighted graphs. The rest of the article discusses applications to edge- and vertex connectivity, both combinatorial and algorithmic, that we now describe. For digraphs, a natural interpretation of the minset poset represents all minimum edge cuts. In the special case of undirected graphs, the minset poset is proved to be a variant of the well-known cactus representation of all mincuts. We use the poset algorithms to construct the cactus representation for unweighted graphs in time O ( m +λ 2 n log (n/λ)) (λ is the edge connectivity) improving the previous bound O (λ n 2 ) for all but the densest graphs. We also construct the cactus representation for weighted graphs in time O ( nm log( n 2 / m )), the same bound as a previously known algorithm but in linear space O ( m ). The latter bound also holds for constructing the minset poset for any weighted digraph; the former bound also holds for constructing the nodes of that poset for any unweighted digraph. The poset is used in algorithms to increase the edge connectivity of a graph by adding the fewest edges possible. For directed and undirected graphs, weighted and unweighted, we achieve the time of the preceding two bounds, i.e., essentially the best-known bounds to compute the edge connectivity itself. Some constructions of minset posets for graph rigidity are also sketched. For vertex connectivity, the minset poset is proved to be a slight variant of the dominator tree. This leads to an algorithm to construct the dominator tree in time O ( m ) on a RAM. (The algorithm is included in the appendix, since other linear-time algorithms of similar simplicity have recently been presented.)",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2342702536",
    "type": "article"
  },
  {
    "title": "Robust and MaxMin Optimization under Matroid and Knapsack Uncertainty Sets",
    "doi": "https://doi.org/10.1145/2746226",
    "publication_date": "2015-11-16",
    "publication_year": 2015,
    "authors": "Anupam Gupta; Viswanath Nagarajan; R. Ravi",
    "corresponding_authors": "",
    "abstract": "Consider the following problem: given a set system ( U , Ω) and an edge-weighted graph G = ( U , E ) on the same universe U , find the set A ∈ Ω such that the Steiner tree cost with terminals A is as large as possible—“which set in Ω is the most difficult to connect up?” This is an example of a max-min problem : find the set A ∈ Ω such that the value of some minimization (covering) problem is as large as possible. In this article, we show that for certain covering problems that admit good deterministic online algorithms, we can give good algorithms for max-min optimization when the set system Ω is given by a p -system or knapsack constraints or both. This result is similar to results for constrained maximization of submodular functions. Although many natural covering problems are not even approximately submodular, we show that one can use properties of the online algorithm as a surrogate for submodularity. Moreover, we give stronger connections between max-min optimization and two-stage robust optimization, and hence give improved algorithms for robust versions of various covering problems, for cases where the uncertainty sets are given by p -systems and knapsack constraints.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W1526404960",
    "type": "article"
  },
  {
    "title": "Faster Spectral Sparsification and Numerical Algorithms for SDD Matrices",
    "doi": "https://doi.org/10.1145/2743021",
    "publication_date": "2015-12-08",
    "publication_year": 2015,
    "authors": "Ioannis Koutis; A. Levin; Richard Peng",
    "corresponding_authors": "",
    "abstract": "We study algorithms for spectral graph sparsification. The input is a graph G with n vertices and m edges, and the output is a sparse graph G˜ that approximates G in an algebraic sense. Concretely, for all vectors x and any ϵ &gt; 0, the graph G˜ satisfies (1-ϵ ) x T L G x ≤ x T L G˜ x ≤ (1+ϵ) x T L G x , where L G and G˜ are the Laplacians of G and G˜ respectively. The first contribution of this article applies to all existing sparsification algorithms that rely on solving solving linear systems on graph Laplacians. These algorithms are the fastest known to date. Specifically, we show that less precision is required in the solution of the linear systems, leading to speedups by an O (log n ) factor. We also present faster sparsification algorithms for slightly dense graphs: — An O ( m log n ) time algorithm that generates a sparsifier with O ( n log 3 n /ϵ 2 ) edges. — An O ( m log log n ) time algorithm for graphs with more than n log 5 n log log n edges. — An O ( m ) algorithm for graphs with more than n log 10 n edges. — An O ( m ) algorithm for unweighted graphs with more than n log 8 n edges. These bounds hold up to factors that are in O ( poly (log log n )) and are conjectured to be removable.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2135927639",
    "type": "article"
  },
  {
    "title": "Algebraic Algorithms for Linear Matroid Parity Problems",
    "doi": "https://doi.org/10.1145/2601066",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Ho Yee Cheung; Lap Chi Lau; Kai Man Leung",
    "corresponding_authors": "",
    "abstract": "We present fast and simple algebraic algorithms for the linear matroid parity problem and its applications. For the linear matroid parity problem, we obtain a simple randomized algorithm with running time O ( mr ω-1 ), where m and r are the number of columns and the number of rows, respectively, and ω ≈ 2.3727 is the matrix multiplication exponent. This improves the O ( mr ω )-time algorithm by Gabow and Stallmann and matches the running time of the algebraic algorithm for linear matroid intersection, answering a question of Harvey. We also present a very simple alternative algorithm with running time O ( mr 2 ), which does not need fast matrix multiplication. We further improve the algebraic algorithms for some specific graph problems of interest. For the Mader’s disjoint S -path problem, we present an O ( n ω )-time randomized algorithm where n is the number of vertices. This improves the running time of the existing results considerably and matches the running time of the algebraic algorithms for graph matching. For the graphic matroid parity problem, we give an O ( n 4 )-time randomized algorithm where n is the number of vertices, and an O ( n 3 )-time randomized algorithm for a special case useful in designing approximation algorithms. These algorithms are optimal in terms of n as the input size could be Ω ( n 4 ) and Ω ( n 3 ), respectively. The techniques are based on the algebraic algorithmic framework developed by Mucha and Sankowski, Harvey, and Sankowski. While linear matroid parity and Mader’s disjoint S -path are challenging generalizations for the design of combinatorial algorithms, our results show that both the algebraic algorithms for linear matroid intersection and graph matching can be extended nicely to more general settings. All algorithms are still faster than the existing algorithms even if fast matrix multiplication is not used. These provide simple algorithms that can be easily implemented in practice.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2170492169",
    "type": "article"
  },
  {
    "title": "Data Structures for Weighted Matching and Extensions to <i>b</i> -matching and <i>f</i> -factors",
    "doi": "https://doi.org/10.1145/3183369",
    "publication_date": "2018-06-22",
    "publication_year": 2018,
    "authors": "Harold N. Gabow",
    "corresponding_authors": "Harold N. Gabow",
    "abstract": "This article shows the weighted matching problem on general graphs can be solved in time O ( n ( m + n log n )) for n and m the number of vertices and edges, respectively. This was previously known only for bipartite graphs. The crux is a data structure for blossom creation. It uses a dynamic nearest-common-ancestor algorithm to simplify blossom steps, so they involve only back edges rather than arbitrary nontree edges. The rest of the article presents direct extensions of Edmonds’ blossom algorithm to weighted b -matching and f -factors. Again, the time bound is the one previously known for bipartite graphs: for b -matching the time is O (min { b ( V ), n log n }( m + n log n )), and for f -factors the time is O (min { f ( V ), m log n }( m + n log n )), where b ( V ) and f ( V ) both denote the sum of all degree constraints. Several immediate applications of the f -factor algorithm are given: The generalized shortest path structure of Reference [19], i.e., the analog of the shortest-paths tree for conservative undirected graphs, is shown to be a version of the blossom structure for f -factors. This structure is found in time O (| N |( m + n log n )) for N , the set of negative edges (0 &lt; | N | &lt; n ). A shortest T -join is found in time O ( n ( m + n log n )) or O (| T |( m + n log n )) when all costs are nonnegative. These bounds are all slight improvements of previously known ones, and are simply achieved by proper initialization of the f -factor algorithm.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2551688242",
    "type": "article"
  },
  {
    "title": "Sparse Sums of Positive Semidefinite Matrices",
    "doi": "https://doi.org/10.1145/2746241",
    "publication_date": "2015-12-09",
    "publication_year": 2015,
    "authors": "Marcel K. de Carli Silva; Nicholas J. A. Harvey; Cristiane M. Sato",
    "corresponding_authors": "",
    "abstract": "Many fast graph algorithms begin by preprocessing the graph to improve its sparsity. A common form of this is spectral sparsification, which involves removing and reweighting the edges of the graph while approximately preserving its spectral properties. This task has a more general linear algebraic formulation in terms of approximating sums of rank-one matrices. This article considers a more general task of approximating sums of symmetric, positive semidefinite matrices of arbitrary rank. We present two deterministic, polynomial time algorithms for solving this problem. The first algorithm applies the pessimistic estimators of Wigderson and Xiao, and the second involves an extension of the method of Batson, Spielman, and Srivastava. These algorithms have several applications, including sparsifiers of hypergraphs, sparse solutions to semidefinite programs, sparsifiers of unique games, and graph sparsifiers with various auxiliary constraints.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W3125317651",
    "type": "article"
  },
  {
    "title": "A Lottery Model for Center-Type Problems With Outliers",
    "doi": "https://doi.org/10.1145/3311953",
    "publication_date": "2019-06-12",
    "publication_year": 2019,
    "authors": "David G. Harris; Thomas Pensyl; Aravind Srinivasan; Khoa Trinh",
    "corresponding_authors": "",
    "abstract": "In this article, we give tight approximation algorithms for the k -center and matroid center problems with outliers. Unfairness arises naturally in this setting: certain clients could always be considered as outliers. To address this issue, we introduce a lottery model in which each client j is allowed to submit a parameter p j ∈ [0,1] and we look for a random solution that covers every client j with probability at least p j . Our techniques include a randomized rounding procedure to round a point inside a matroid intersection polytope to a basis plus at most one extra item such that all marginal probabilities are preserved and such that a certain linear function of the variables does not decrease in the process with probability one.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2951891729",
    "type": "article"
  },
  {
    "title": "Computing the Gromov-Hausdorff Distance for Metric Trees",
    "doi": "https://doi.org/10.1145/3185466",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Pankaj K. Agarwal; Kyle Fox; Abhinandan Nath; Anastasios Sidiropoulos; Yusu Wang",
    "corresponding_authors": "",
    "abstract": "The Gromov-Hausdorff (GH) distance is a natural way to measure distance between two metric spaces. We prove that it is NP-hard to approximate the GH distance better than a factor of 3 for geodesic metrics on a pair of trees. We complement this result by providing a polynomial time O (min n , √ rn )-approximation algorithm for computing the GH distance between a pair of metric trees, where r is the ratio of the longest edge length in both trees to the shortest edge length. For metric trees with unit length edges, this yields an O (√ n )-approximation algorithm 1 .",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2963526673",
    "type": "article"
  },
  {
    "title": "Sparse Dynamic Programming on DAGs with Small Width",
    "doi": "https://doi.org/10.1145/3301312",
    "publication_date": "2019-02-06",
    "publication_year": 2019,
    "authors": "Veli Mäkinen; Alexandru I. Tomescu; Anna Kuosmanen; Topi Paavilainen; Travis Gagie; Rayan Chikhi",
    "corresponding_authors": "",
    "abstract": "The minimum path cover problem asks us to find a minimum-cardinality set of paths that cover all the nodes of a directed acyclic graph (DAG). We study the case when the size k of a minimum path cover is small, that is, when the DAG has a small width . This case is motivated by applications in pan-genomics , where the genomic variation of a population is expressed as a DAG. We observe that classical alignment algorithms exploiting sparse dynamic programming can be extended to the sequence-against-DAG case by mimicking the algorithm for sequences on each path of a minimum path cover and handling an evaluation order anomaly with reachability queries . Namely, we introduce a general framework for DAG-extensions of sparse dynamic programming. This framework produces algorithms that are slower than their counterparts on sequences only by a factor k . We illustrate this on two classical problems extended to DAGs: longest increasing subsequence and longest common subsequence . For the former, we obtain an algorithm with running time O ( k | E |log | V |). This matches the optimal solution to the classical problem variant when the input sequence is modeled as a path. We obtain an analogous result for the longest common subsequence problem. We then apply this technique to the co-linear chaining problem, which is a generalization of the above two problems. The algorithm for this problem turns out to be more involved, needing further ingredients, such as an FM-index tailored for large alphabets and a two-dimensional range search tree modified to support range maximum queries. We also study a general sequence-to-DAG alignment formulation that allows affine gap costs in the sequence. The main ingredient of the proposed framework is a new algorithm for finding a minimum path cover of a DAG ( V , E ) in O ( k | E |log | V |) time, improving all known time-bounds when k is small and the DAG is not too dense. In addition to boosting the sparse dynamic programming framework, an immediate consequence of this new minimum path cover algorithm is an improved space/time tradeoff for reachability queries in arbitrary directed graphs.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2913934544",
    "type": "article"
  },
  {
    "title": "The Non-Uniform <i>k</i> -Center Problem",
    "doi": "https://doi.org/10.1145/3392720",
    "publication_date": "2020-06-21",
    "publication_year": 2020,
    "authors": "Deeparnab Chakrabarty; Prachi Goyal; Ravishankar Krishnaswamy",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce and study the Non-Uniform k -Center (NUkC) problem. Given a finite metric space ( X , d ) and a collection of balls of radii { r 1 ≥ … ≥ r k }, the NUkC problem is to find a placement of their centers in the metric space and find the minimum dilation α, such that the union of balls of radius α ⋅ r i around the i th center covers all the points in X . This problem naturally arises as a min-max vehicle routing problem with fleets of different speeds. The NUkC problem generalizes the classic k -center problem, wherein all the k radii are the same (which can be assumed to be 1 after scaling). It also generalizes the k -center with outliers (kCwO for short) problem, in which there are k balls of radius 1 and ℓ (number of outliers) balls of radius 0. Before this work, there was a 2-approximation and 3-approximation algorithm known for these problems, respectively; the former is best possible unless P=NP. We first observe that no O (1)-approximation to the optimal dilation is possible unless P=NP, implying that the NUkC problem is harder than the above two problems. Our main algorithmic result is an ( O (1), O (1))- bi-criteria approximation result: We give an O (1)-approximation to the optimal dilation; however, we may open Θ(1) centers of each radii. Our techniques also allow us to prove a simple (uni-criterion), optimal 2-approximation to the kCwO problem improving upon the long-standing 3-factor approximation for this problem. Our main technical contribution is a connection between the NUkC problem and the so-called firefighter problems on trees that have been studied recently in the TCS community. We show NUkC is at least as hard as the firefighter problem. While we do nt know whether the converse is true, we are able to adapt ideas from recent works [1, 3] in non-trivial ways to obtain our constant factor bi-criteria approximation.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2964242853",
    "type": "article"
  },
  {
    "title": "Randomized Contractions Meet Lean Decompositions",
    "doi": "https://doi.org/10.1145/3426738",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Marek Cygan; Paweł Komosa; Daniel Lokshtanov; Marcin Pilipczuk; Michał Pilipczuk; Saket Saurabh; Magnus Wahlström",
    "corresponding_authors": "",
    "abstract": "We show an algorithm that, given an n -vertex graph G and a parameter k , in time 2 O ( k log k ) n O (1) finds a tree decomposition of G with the following properties: — every adhesion of the tree decomposition is of size at most k , and — every bag of the tree decomposition is ( i , i )-unbreakable in G for every 1 ⩽ i ⩽ k . Here, a set X ⊆ V ( G ) is ( a , b )-unbreakable in G if for every separation ( A , B ) of order at most b in G , we have | A \\cap X | ⩽ a or | B ∩ X | ⩽ a . The resulting tree decomposition has arguably best possible adhesion size bounds and unbreakability guarantees. Furthermore, the parametric factor in the running time bound is significantly smaller than in previous similar constructions. These improvements allow us to present parameterized algorithms for M INIMUM B ISECTION , S TEINER C UT , and S TEINER M ULTICUT with improved parameteric factor in the running time bound. The main technical insight is to adapt the notion of lean decompositions of Thomas and the subsequent construction algorithm of Bellenbaum and Diestel to the parameterized setting.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W3113894442",
    "type": "article"
  },
  {
    "title": "A Learned Approach to Design Compressed Rank/Select Data Structures",
    "doi": "https://doi.org/10.1145/3524060",
    "publication_date": "2022-03-17",
    "publication_year": 2022,
    "authors": "Antonio Boffa; Paolo Ferragina; Giorgio Vinciguerra",
    "corresponding_authors": "",
    "abstract": "We address the problem of designing, implementing, and experimenting with compressed data structures that support rank and select queries over a dictionary of integers. We shine a new light on this classical problem by showing a connection between the input integers and the geometry of a set of points in a Cartesian plane suitably derived from them. We then build upon some results in computational geometry to introduce the first compressed rank/select dictionary based on the idea of “learning” the distribution of such points via proper linear approximations (LA). We therefore call this novel data structure the la_vector . We prove time and space complexities of the la_vector in several scenarios: in the worst case, in the case of input distributions with finite mean and variance, and taking into account the k th order entropy of some of its building blocks. We also discuss improved hybrid data structures, namely, ones that suitably orchestrate known compressed rank/select dictionaries with the la_vector . We corroborate our theoretical results with a large set of experiments over datasets originating from a variety of applications (Web search, DNA sequencing, information retrieval, and natural language processing) and show that our approach provides new interesting space-time tradeoffs with respect to many well-established compressed rank/select dictionary implementations. In particular, we show that our select is the fastest, and our rank is on the space-time Pareto frontier.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W4221058058",
    "type": "article"
  },
  {
    "title": "On network design problems: fixed cost flows and the covering steiner problem",
    "doi": "https://doi.org/10.1145/1077464.1077470",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Guy Even; Guy Kortsarz; Wolfgang Slany",
    "corresponding_authors": "",
    "abstract": "Network design problems, such as generalizations of the Steiner Tree Problem, can be cast as edge-cost-flow problems. An edge-cost flow problem is a min-cost flow problem in which the cost of the flow equals the sum of the costs of the edges carrying positive flow.We prove a hardness result for the Minimum Edge Cost Flow Problem (MECF). Using the one-round two-prover scenario, we prove that MECF does not admit a 2 log 1-ε n -ratio approximation, for every constant ε &gt; 0, unless NP ⊆ DTIME ( n polylogn ).A restricted version of MECF, called Infinite Capacity MECF (ICF), is defined. The ICF problem is defined as follows: (i) all edges have infinite capacity, (ii) there are multiple sources and sinks, where flow can be delivered from every source to every sink, (iii) each source and sink has a supply amount and demand amount, respectively, and (iv) the required total flow is given as part of the input. The goal is to find a minimum edge-cost flow that meets the required total flow while obeying the demands of the sinks and the supplies of the sources. This problem naturally arises in practical scheduling applications, and is equivalent to the special case of single source MECF, with all edges not touching the source or the sink having infinite capacity.The directed ICF generalizes the Covering Steiner Problem in directed and undirected graphs. The undirected version of ICF generalizes several network design problems, such as: Steiner Tree Problem, k -MST, Point-to-point Connection Problem, and the generalized Steiner Tree Problem.An O (log x )-approximation algorithm for undirected ICF is presented. We also present a bi-criteria approximation algorithm for directed ICF. The algorithm for directed ICF finds a flow that delivers half the required flow at a cost that is at most O ( n ε /ε 4 ) times bigger than the cost of an optimal flow. The running time of the algorithm is O ( x 2/ε ċ n 1+1/ε ), where x denotes the required total flow.Randomized approximation algorithms for the Covering Steiner Problem in directed and undirected graphs are presented. The algorithms are based on a randomized reduction to a problem called 1/2-Group Steiner. In undirected graphs, the approximation ratio matches the approximation ratio of Konjevod et al. [2002]. However, our algorithm is much simpler. In directed graphs, the algorithm is the first nontrivial approximation algorithm for the Covering Steiner Problem. Deterministic algorithms are obtained by derandomization.",
    "cited_by_count": 46,
    "openalex_id": "https://openalex.org/W2018511415",
    "type": "article"
  },
  {
    "title": "Faster algorithms for sorting by transpositions and sorting by block interchanges",
    "doi": "https://doi.org/10.1145/1273340.1273341",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Jianxing Feng; Daming Zhu",
    "corresponding_authors": "",
    "abstract": "In this article, we present a new data structure, called the permutation tree, to improve the running time of sorting permutation by transpositions and sorting permutation by block interchanges. The existing 1.5-approximation algorithm for sorting permutation by transpositions has time complexity O ( n 3/2 √ logn ). By means of the permutation tree, we can improve this algorithm to achieve time complexity O ( nlogn ). We can also improve the algorithm for sorting permutation by block interchanges to take its time complexity from O ( n 2 ) down to O ( nlogn ).",
    "cited_by_count": 43,
    "openalex_id": "https://openalex.org/W1989711785",
    "type": "article"
  },
  {
    "title": "Improved online algorithms for buffer management in QoS switches",
    "doi": "https://doi.org/10.1145/1290672.1290687",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Marek Chrobák; Wojciech Jawor; Jiřį́ Sgall; Tomáš Tichý",
    "corresponding_authors": "",
    "abstract": "We consider the following buffer management problem arising in QoS networks: Packets with specified weights and deadlines arrive at a network switch and need to be forwarded so that the total weight of forwarded packets is maximized. Packets not forwarded before their deadlines are lost. The main result of the article is an online 64/33 ≈ 1.939-competitive algorithm, the first deterministic algorithm for this problem with competitive ratio below 2. For the 2-uniform case we give an algorithm with ratio ≈ 1.377 and a matching lower bound.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2010459659",
    "type": "article"
  },
  {
    "title": "Approximate distance oracles for geometric spanners",
    "doi": "https://doi.org/10.1145/1328911.1328921",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Joachim Gudmundsson; Christos Levcopoulos; Giri Narasimhan; Michiel Smid",
    "corresponding_authors": "",
    "abstract": "Given an arbitrary real constant ε &gt; 0, and a geometric graph G in d -dimensional Euclidean space with n points, O ( n ) edges, and constant dilation, our main result is a data structure that answers (1 + ε)-approximate shortest-path-length queries in constant time. The data structure can be constructed in O ( n log n ) time using O ( n log n ) space. This represents the first data structure that answers (1 + ε)-approximate shortest-path queries in constant time, and hence functions as an approximate distance oracle. The data structure is also applied to several other problems. In particular, we also show that approximate shortest-path queries between vertices in a planar polygonal domain with “rounded” obstacles can be answered in constant time. Other applications include query versions of closest-pair problems, and the efficient computation of the approximate dilations of geometric graphs. Finally, we show how to extend the main result to answer (1 + ε)-approximate shortest-path-length queries in constant time for geometric spanner graphs with m = ω( n ) edges. The resulting data structure can be constructed in O ( m + n log n ) time using O ( n log n ) space.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2052373622",
    "type": "article"
  },
  {
    "title": "Bipartite roots of graphs",
    "doi": "https://doi.org/10.1145/1150334.1150337",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Lap Chi Lau",
    "corresponding_authors": "Lap Chi Lau",
    "abstract": "Graph H is a root of graph G if there exists a positive integer k such that x and y are adjacent in G if and only if their distance in H is at most k . Motwani and Sudan [1994] proved the NP-completeness of graph square recognition and conjectured that it is also NP-complete to recognize squares of bipartite graphs. The main result of this article is to show that squares of bipartite graphs can be recognized in polynomial time. In fact, we give a polynomial-time algorithm to count the number of different bipartite square roots of a graph, although this number could be exponential in the size of the input graph. By using the ideas developed, we are able to give a new and simpler linear-time algorithm to recognize squares of trees and a new algorithmic proof that tree square roots are unique up to isomorphism. Finally, we prove the NP-completeness of recognizing cubes of bipartite graphs.",
    "cited_by_count": 41,
    "openalex_id": "https://openalex.org/W2058105885",
    "type": "article"
  },
  {
    "title": "Minimizing weighted flow time",
    "doi": "https://doi.org/10.1145/1290672.1290676",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Nikhil Bansal; Kedar Dhamdhere",
    "corresponding_authors": "",
    "abstract": "We consider the problem of minimizing the total weighted flow time on a single machine with preemptions. We give an online algorithm that is O ( k )-competitive for k weight classes. This implies an O (log W )-competitive algorithm, where W is the maximum to minimum ratio of weights. This algorithm also implies an O (log n + log P )-approximation ratio for the problem, where P is the ratio of the maximum to minimum job size and n is the number of jobs. We also consider the nonclairvoyant setting where the size of a job is unknown upon its arrival and becomes known to the scheduler only when the job meets its service requirement. We consider the resource augmentation model, and give a (1 + ε)-speed, (1 +1/ε)-competitive online algorithm.",
    "cited_by_count": 40,
    "openalex_id": "https://openalex.org/W2134553994",
    "type": "article"
  },
  {
    "title": "Balanced families of perfect hash functions and their applications",
    "doi": "https://doi.org/10.1145/1798596.1798607",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Noga Alon; Shai Gutner",
    "corresponding_authors": "",
    "abstract": "The construction of perfect hash functions is a well-studied topic. In this article, this concept is generalized with the following definition. We say that a family of functions from [ n ] to [ k ] is a δ-balanced ( n,k )-family of perfect hash functions if for every S ⊆ [ n ], | S |= k , the number of functions that are 1-1 on S is between T /δ and δ T for some constant T &gt;0. The standard definition of a family of perfect hash functions requires that there will be at least one function that is 1-1 on S , for each S of size k . In the new notion of balanced families, we require the number of 1-1 functions to be almost the same (taking δ to be close to 1) for every such S . Our main result is that for any constant δ &gt; 1, a δ-balanced ( n,k )-family of perfect hash functions of size 2 O ( k log log k ) log n can be constructed in time 2 O ( k log log k ) n log n . Using the technique of color-coding we can apply our explicit constructions to devise approximation algorithms for various counting problems in graphs. In particular, we exhibit a deterministic polynomial-time algorithm for approximating both the number of simple paths of length k and the number of simple cycles of size k for any k ≤ O (log n /log log log n ) in a graph with n vertices. The approximation is up to any fixed desirable relative error.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W1980074516",
    "type": "article"
  },
  {
    "title": "Distributed weighted vertex cover via maximal matchings",
    "doi": "https://doi.org/10.1145/1435375.1435381",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Fabrizio Grandoni; Jochen Könemann; Alessandro Panconesi",
    "corresponding_authors": "",
    "abstract": "In this article, we consider the problem of computing a minimum-weight vertex-cover in an n -node, weighted, undirected graph G = ( V , E ). We present a fully distributed algorithm for computing vertex covers of weight at most twice the optimum, in the case of integer weights. Our algorithm runs in an expected number of O (log n + log Ŵ ) communication rounds, where Ŵ is the average vertex-weight. The previous best algorithm for this problem requires O (log n (log n + log Ŵ )) rounds and it is not fully distributed. For a maximal matching M in G , it is a well-known fact that any vertex-cover in G needs to have at least | M | vertices. Our algorithm is based on a generalization of this combinatorial lower-bound to the weighted setting.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2055000959",
    "type": "article"
  },
  {
    "title": "Kinetic and dynamic data structures for closest pair and all nearest neighbors",
    "doi": "https://doi.org/10.1145/1435375.1435379",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Pankaj K. Agarwal; Haim Kaplan; Micha Sharir",
    "corresponding_authors": "",
    "abstract": "We present simple, fully dynamic and kinetic data structures, which are variants of a dynamic two-dimensional range tree, for maintaining the closest pair and all nearest neighbors for a set of n moving points in the plane; insertions and deletions of points are also allowed. If no insertions or deletions take place, the structure for the closest pair uses O ( n log n ) space, and processes O ( n 2 β s +2 ( n )log n ) critical events, each in O (log 2 n ) time. Here s is the maximum number of times where the distances between any two specific pairs of points can become equal, β s ( q ) = λ s ( q )/ q , and λ s ( q ) is the maximum length of Davenport-Schinzel sequences of order s on q symbols. The dynamic version of the problem incurs a slight degradation in performance: If m ≥ n insertions and deletions are performed, the structure still uses O ( n log n ) space, and processes O ( mn β s +2( n )log 3 n ) events, each in O (log 3 n ) time. Our kinetic data structure for all nearest neighbors uses O ( n log 2 n ) space, and processes O ( n 2 β 2 s +2 ( n )log 3 n ) critical events. The expected time to process all events is O ( n 2 β s +2 2 ( n ) log 4 n ), though processing a single event may take Θ( n ) expected time in the worst case. If m ≥ n insertions and deletions are performed, then the expected number of events is O ( mn β 2 s +2 ( n ) log 3 n ) and processing them all takes O ( mn β 2 s +2 ( n ) log 4 n ). An insertion or deletion takes O ( n ) expected time.",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W2115704441",
    "type": "article"
  },
  {
    "title": "Labeling schemes for vertex connectivity",
    "doi": "https://doi.org/10.1145/1721837.1721855",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Amos Korman",
    "corresponding_authors": "Amos Korman",
    "abstract": "This article studies labeling schemes for the vertex connectivity function on general graphs. We consider the problem of assigning short labels to the nodes of any n -node graph is such a way that given the labels of any two nodes u and v , one can decide whether u and v are k -vertex connected in G , that is, whether there exist k vertex disjoint paths connecting u and v . This article establishes an upper bound of k 2 log n on the number of bits used in a label. The best previous upper bound for the label size of such a labeling scheme is 2 k log n .",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W2042604558",
    "type": "article"
  },
  {
    "title": "Embeddings of negative-type metrics and an improved approximation to generalized sparsest cut",
    "doi": "https://doi.org/10.1145/1361192.1361199",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Shuchi Chawla; Anupam Gupta; Harald Räcke",
    "corresponding_authors": "",
    "abstract": "In this article, we study metrics of negative type , which are metrics ( V , d) such that √d is an Euclidean metric; these metrics are thus also known as ℓ 2 -squared metrics. We show how to embed n -point negative-type metrics into Euclidean space ℓ 2 with distortion D = O (log 3/4 n ). This embedding result, in turn, implies an O (log 3/4 k )-approximation algorithm for the Sparsest Cut problem with nonuniform demands. Another corollary we obtain is that n -point subsets of ℓ 1 embed into ℓ 2 with distortion O (log 3/4 n ).",
    "cited_by_count": 36,
    "openalex_id": "https://openalex.org/W3137884736",
    "type": "article"
  },
  {
    "title": "Mechanism design for fractional scheduling on unrelated machines",
    "doi": "https://doi.org/10.1145/1721837.1721854",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "George Christodoulou; Ηλίας Κουτσουπιάς; Annamária Kovács",
    "corresponding_authors": "",
    "abstract": "Scheduling on unrelated machines is one of the most general and classical variants of the task scheduling problem. Fractional scheduling is the LP-relaxation of the problem, which is polynomially solvable in the nonstrategic setting, and is a useful tool to design deterministic and randomized approximation algorithms. The mechanism design version of the scheduling problem was introduced by Nisan and Ronen. In this article, we consider the mechanism design version of the fractional variant of this problem. We give lower bounds for any fractional truthful mechanism. Our lower bounds also hold for any (randomized) mechanism for the integral case. In the positive direction, we propose a truthful mechanism that achieves approximation 3/2 for 2 machines, matching the lower bound. This is the first new tight bound on the approximation ratio of this problem, after the tight bound of 2, for 2 machines, obtained by Nisan and Ronen. For n machines, our mechanism achieves an approximation ratio of n +1/2. Motivated by the fact that all the known deterministic and randomized mechanisms for the problem assign each task independently from the others, we focus on an interesting subclass of allocation algorithms, the task-independent algorithms. We give a lower bound of n +1/2, that holds for every (not only monotone) allocation algorithm that takes independent decisions. Under this consideration, our truthful independent mechanism is the best that we can hope from this family of algorithms.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2151792026",
    "type": "article"
  },
  {
    "title": "Finding heaviest <i>H</i> -subgraphs in real weighted graphs, with applications",
    "doi": "https://doi.org/10.1145/1798596.1798597",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Virginia Vassilevska; Ryan Williams; Raphael Yuster",
    "corresponding_authors": "",
    "abstract": "For a graph G with real weights assigned to the vertices (edges), the MAX H -SUBGRAPH problem is to find an H -subgraph of G with maximum total weight, if one exists. Our main results are new strongly polynomial algorithms for the MAX H -SUBGRAPH problem. Some of our algorithms are based, in part, on fast matrix multiplication. For vertex-weighted graphs with n vertices we solve a more general problem: the all pairs MAX H -SUBGRAPH problem, where the task is to find for every pair of vertices u,v, a maximum H -subgraph containing both u and v , if one exists. We obtain an O ( n t (ω, h )) -time algorithm for the all pairs MAX H -SUBGRAPH problem in the case where H is a fixed graph with h vertices and ω &lt; 2.376 is the exponent of matrix multiplication. The value of t (ω, h ) is determined by solving a small integer program. In particular, heaviest triangles for all pairs can be found in O ( n 2+1/(4-ω) ) ≤ o ( n 2.616 )-time. For h =4,5,8 the running time of our algorithm essentially matches that of the (unweighted) H -subgraph detection problem. Using rectangular matrix multiplication, the value of t ( ω,h ) can be improved; for example, the runtime for triangles becomes O ( n 2.575 ). We also present improved algorithms for the MAX H -SUBGRAPH problem in the edge-weighted case. In particular, we obtain an O ( m 2−1/ k log n )-time algorithm for the heaviest cycle of length 2 k or 2 k −1 in a graph with m edges and an O ( n 3 /log n )-time randomized algorithm for finding the heaviest cycle of any fixed length. Our methods also yield efficient algorithms for several related problems that are faster than any previously existing algorithms. For example, we show how to find chromatic H -subgraphs in edge-colored graphs, and how to compute the most significant bits of the distance product of two real matrices, in truly subcubic time.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2066367171",
    "type": "article"
  },
  {
    "title": "An approximation algorithm for the maximum leaf spanning arborescence problem",
    "doi": "https://doi.org/10.1145/1798596.1798599",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Matthew Drescher; Adrian Vetta",
    "corresponding_authors": "",
    "abstract": "We present an O (√opt)-approximation algorithm for the maximum leaf spanning arborescence problem, where opt is the number of leaves in an optimal spanning arborescence. The result is based upon an O (1)-approximation algorithm for a special class of directed graphs called willows. Incorporating the method for willow graphs as a subroutine in a local improvement algorithm gives the bound for general directed graphs.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2083082533",
    "type": "article"
  },
  {
    "title": "A local algorithm for finding dense subgraphs",
    "doi": "https://doi.org/10.1145/1824777.1824780",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Reid Andersen",
    "corresponding_authors": "Reid Andersen",
    "abstract": "We describe a local algorithm for finding subgraphs with high density, according to a measure of density introduced by Kannan and Vinay [1999]. The algorithm takes as input a bipartite graph G , a starting vertex v , and a parameter k , and outputs an induced subgraph of G . It is local in the sense that it does not examine the entire input graph; instead, it adaptively explores a region of the graph near the starting vertex. The running time of the algorithm is bounded by O (Δ k 2 ), which depends on the maximum degree Δ, but is otherwise independent of the graph. We prove the following approximation guarantee: for any subgraph S with k′ vertices and density θ, there exists a set S ′ ⊆ S for which the algorithm outputs a subgraph with density Ω(θ/log Δ) whenever v ∈ S ′ and k ≥ k ′. We prove that S ′ contains at least half of the edges in S .",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2620706275",
    "type": "article"
  },
  {
    "title": "Maximal biconnected subgraphs of random planar graphs",
    "doi": "https://doi.org/10.1145/1721837.1721847",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Κωνσταντίνος Παναγιώτου; Angelika Steger",
    "corresponding_authors": "",
    "abstract": "Let C be a class of labeled connected graphs, and let C n be a graph drawn uniformly at random from graphs in C that contain exactly n vertices. Denote by b (ℓ; C n ) the number of blocks (i.e., maximal biconnected subgraphs) of C n that contain exactly ℓ vertices, and let lb (C n ) be the number of vertices in a largest block of C n . We show that under certain general assumptions on C , C n belongs with high probability to one of the following categories: (1) lb (C n ) ∼ cn , for some explicitly given c = c ( C ), and the second largest block is of order n α , where 1 &gt; α = α( C ), or (2) lb (C n ) = O (log n ), that is, all blocks contain at most logarithmically many vertices. Moreover, in both cases we show that the quantity b (ℓ; C n ) is concentrated for all ℓ and we determine its expected value. As a corollary we obtain that the class of planar graphs belongs to category (1). In contrast to that, outerplanar and series-parallel graphs belong to category (2).",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2043083610",
    "type": "article"
  },
  {
    "title": "Online conflict-free coloring for halfplanes, congruent disks, and axis-parallel rectangles",
    "doi": "https://doi.org/10.1145/1497290.1497292",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Ke Chen; Haim Kaplan; Micha Sharir",
    "corresponding_authors": "",
    "abstract": "We present randomized algorithms for online conflict-free coloring (CF in short) of points in the plane, with respect to halfplanes, congruent disks, and nearly-equal axis-parallel rectangles. In all three cases, the coloring algorithms use O (log n ) colors, with high probability. We also present a deterministic algorithm for online CF coloring of points in the plane with respect to nearly-equal axis-parallel rectangles, using O (log 3 n ) colors. This is the first efficient (i.e, using polylog( n ) colors) deterministic online CF coloring algorithm for this problem.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2081118695",
    "type": "article"
  },
  {
    "title": "Three-coloring triangle-free planar graphs in linear time",
    "doi": "https://doi.org/10.1145/2000807.2000809",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Zdenĕk Dvořák; Ken‐ichi Kawarabayashi; Robin Thomas",
    "corresponding_authors": "",
    "abstract": "Grötzsch's theorem states that every triangle-free planar graph is 3-colorable, and several relatively simple proofs of this fact were provided by Thomassen and other authors. It is easy to convert these proofs into quadratic-time algorithms to find a 3-coloring, but it is not clear how to find such a coloring in linear time (Kowalik used a nontrivial data structure to construct an O ( n log n ) algorithm). We design a linear-time algorithm to find a 3-coloring of a given triangle-free planar graph. The algorithm avoids using any complex data structures, which makes it easy to implement. As a by-product, we give a yet simpler proof of Grötzsch's theorem.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2127059580",
    "type": "article"
  },
  {
    "title": "Fast computation of small cuts via cycle space sampling",
    "doi": "https://doi.org/10.1145/2000807.2000814",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "David Pritchard; Ramakrishna Thurimella",
    "corresponding_authors": "",
    "abstract": "We describe a new sampling-based method to determine cuts in an undirected graph. For a graph ( V , E ), its cycle space is the family of all subsets of E that have even degree at each vertex. We prove that with high probability, sampling the cycle space identifies the cuts of a graph. This leads to simple new linear-time sequential algorithms for finding all cut edges and cut pairs (a set of 2 edges that form a cut) of a graph. In the model of distributed computing in a graph G = ( V , E ) with O (log | V |)-bit messages, our approach yields faster algorithms for several problems. The diameter of G is denoted by D , and the maximum degree by Δ. We obtain simple O ( D )-time distributed algorithms to find all cut edges, 2-edge-connected components, and cut pairs, matching or improving upon previous time bounds. Under natural conditions these new algorithms are universally optimal—that is, a Ω( D )-time lower bound holds on every graph. We obtain a O ( D +Δ/log |V|)-time distributed algorithm for finding cut vertices; this is faster than the best previous algorithm when Δ, D = O (√| V |). A simple extension of our work yields the first distributed algorithm with sub-linear time for 3-edge-connected components. The basic distributed algorithms are Monte Carlo, but they can be made Las Vegas without increasing the asymptotic complexity. In the model of parallel computing on the EREW PRAM, our approach yields a simple algorithm with optimal time complexity O (log V ) for finding cut pairs and 3-edge-connected components.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2153507546",
    "type": "article"
  },
  {
    "title": "Range searching on uncertain data",
    "doi": "https://doi.org/10.1145/2344422.2344433",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Pankaj K. Agarwal; Siu-Wing Cheng; Ke Yi",
    "corresponding_authors": "",
    "abstract": "Querying uncertain data has emerged as an important problem in data management due to the imprecise nature of many measurement data. In this article, we study answering range queries over uncertain data. Specifically, we are given a collection P of n uncertain points in ℝ, each represented by its one-dimensional probability density function (pdf). The goal is to build a data structure on P such that, given a query interval I and a probability threshold τ, we can quickly report all points of P that lie in I with probability at least τ. We present various structures with linear or near-linear space and (poly)logarithmic query time. Our structures support pdf's that are either histograms or more complex ones such as Gaussian or piecewise algebraic.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2072729927",
    "type": "article"
  },
  {
    "title": "Polynomial-time algorithms for minimum energy scheduling",
    "doi": "https://doi.org/10.1145/2229163.2229170",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Philippe Baptiste; Marek Chrobák; Christoph Dürr",
    "corresponding_authors": "",
    "abstract": "The aim of power management policies is to reduce the amount of energy consumed by computer systems while maintaining a satisfactory level of performance. One common method for saving energy is to simply suspend the system during idle times. No energy is consumed in the suspend mode. However, the process of waking up the system itself requires a certain fixed amount of energy, and thus suspending the system is beneficial only if the idle time is long enough to compensate for this additional energy expenditure. In the specific problem studied in the article, we have a set of jobs with release times and deadlines that need to be executed on a single processor. Preemptions are allowed. The processor requires energy L to be woken up and, when it is on, it uses one unit of energy per one unit of time. It has been an open problem whether a schedule minimizing the overall energy consumption can be computed in polynomial time. We solve this problem in positive, by providing an O ( n 5 )-time algorithm. In addition we provide an O ( n 4 )-time algorithm for computing the minimum energy schedule when all jobs have unit length.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2116668770",
    "type": "article"
  },
  {
    "title": "A Bounded Budget Network Creation Game",
    "doi": "https://doi.org/10.1145/2701615",
    "publication_date": "2015-04-13",
    "publication_year": 2015,
    "authors": "Shayan Ehsani; Saber Shokat Fadaee; MohammadAmin Fazli; Abbas Mehrabian; Sina Sadeghian Sadeghabad; MohammadAli Safari; Morteza Saghafian",
    "corresponding_authors": "",
    "abstract": "We introduce a network creation game in which each player (vertex) has a fixed budget to establish links to other players. In this model, each link has a unit price, and each agent tries to minimize its cost, which is either its eccentricity or its total distance to other players in the underlying (undirected) graph of the created network. Two versions of the game are studied: In the MAX version, the cost incurred to a vertex is the maximum distance between the vertex and other vertices, and, in the SUM version, the cost incurred to a vertex is the sum of distances between the vertex and other vertices. We prove that in both versions pure Nash equilibria exist, but the problem of finding the best response of a vertex is NP-hard. We take the social cost of the created network to be its diameter, and next we study the maximum possible diameter of an equilibrium graph with n vertices in various cases. When the sum of players’ budgets is n − 1, the equilibrium graphs are always trees, and we prove that their maximum diameter is Θ( n ) and Θ(log n ) in MAX and SUM versions, respectively. When each vertex has a unit budget (i.e., can establish a link to just one vertex), the diameter of any equilibrium graph in either version is Θ(1). We give examples of equilibrium graphs in the MAX version, such that all vertices have positive budgets and yet the diameter is Ω(√log n ). This interesting (and perhaps counterintuitive) result shows that increasing the budgets may increase the diameter of equilibrium graphs and hence deteriorate the network structure. Then we prove that every equilibrium graph in the SUM version has diameter 2 O (√log n ) . Finally, we show that if the budget of each player is at least k , then every equilibrium graph in the SUM version is k -connected or has a diameter smaller than 4.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W3099896668",
    "type": "article"
  },
  {
    "title": "Approximating parameterized convex optimization problems",
    "doi": "https://doi.org/10.1145/2390176.2390186",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Joachim Giesen; Martin Jaggi; Sören Laue",
    "corresponding_authors": "",
    "abstract": "We consider parameterized convex optimization problems over the unit simplex, that depend on one parameter. We provide a simple and efficient scheme for maintaining an ϵ-approximate solution (and a corresponding ϵ-coreset) along the entire parameter path. We prove correctness and optimality of the method. Practically relevant instances of the abstract parameterized optimization problem are for example regularization paths of support vector machines, multiple kernel learning, and minimum enclosing balls of moving points.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2061810505",
    "type": "article"
  },
  {
    "title": "A compact routing scheme and approximate distance oracle for power-law graphs",
    "doi": "https://doi.org/10.1145/2390176.2390180",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Wei Chen; Christian Sommer; Shang‐Hua Teng; Yajun Wang",
    "corresponding_authors": "",
    "abstract": "Compact routing addresses the tradeoff between table sizes and stretch, which is the worst-case ratio between the length of the path a packet is routed through by the scheme and the length of an actual shortest path from source to destination. We adapt the compact routing scheme by Thorup and Zwick [2001] to optimize it for power-law graphs. We analyze our adapted routing scheme based on the theory of unweighted random power-law graphs with fixed expected degree sequence by Aiello et al. [2000]. Our result is the first analytical bound coupled to the parameter of the power-law graph model for a compact routing scheme. Let n denote the number of nodes in the network. We provide a labeled routing scheme that, after a stretch--5 handshaking step (similar to DNS lookup in TCP/IP), routes messages along stretch--3 paths. We prove that, instead of routing tables with Õ ( n 1/2 ) bits ( Õ suppresses factors logarithmic in n ) as in the general scheme by Thorup and Zwick, expected sizes of O ( n γ log n ) bits are sufficient, and that all the routing tables can be constructed at once in expected time O ( n 1+γ log n ), with γ = τ-22/τ-3 + ε, where τ∈(2,3) is the power-law exponent and ε 0 (which implies ε &lt; γ &lt; 1/3 + ε). Both bounds also hold with probability at least 1-1/ n (independent of ε). The routing scheme is a labeled scheme, requiring a stretch--5 handshaking step. The scheme uses addresses and message headers with O (log n log log n ) bits, with probability at least 1- o (1). We further demonstrate the effectiveness of our scheme by simulations on real-world graphs as well as synthetic power-law graphs. With the same techniques as for the compact routing scheme, we also adapt the approximate distance oracle by Thorup and Zwick [2001, 2005] for stretch-3 and we obtain a new upper bound of expected Õ ( n 1+γ ) for space and preprocessing for random power-law graphs. Our distance oracle is the first one optimized for power-law graphs. Furthermore, we provide a linear-space data structure that can answer 5--approximate distance queries in time at most Õ ( n 1/4+ε ) (similar to γ, the exponent actually depends on τ and lies between ε and 1/4 + ε).",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2152306920",
    "type": "article"
  },
  {
    "title": "Morphing orthogonal planar graph drawings",
    "doi": "https://doi.org/10.1145/2500118",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Thérèse Biedl; Anna Lubiw; Mark Petrick; Michael J. Spriggs",
    "corresponding_authors": "",
    "abstract": "We give an algorithm to morph between two planar orthogonal drawings of a graph, preserving planarity and orthogonality. The morph uses a quadratic number of steps, where each step is a linear morph (a linear interpolation between two drawings). This is the first algorithm to provide planarity-preserving morphs with well-behaved complexity for a significant class of graph drawings. Our method is to morph until each edge is represented by a sequence of segments, with corresponding segments parallel in the two drawings. Then, in a result of independent interest, we morph such parallel planar orthogonal drawings, preserving edge directions and planarity.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2624146531",
    "type": "article"
  },
  {
    "title": "Time vs. Information Tradeoffs for Leader Election in Anonymous Trees",
    "doi": "https://doi.org/10.1145/3039870",
    "publication_date": "2017-03-06",
    "publication_year": 2017,
    "authors": "Christian Glacet; Avery Miller; Andrzej Pelc",
    "corresponding_authors": "",
    "abstract": "Leader election is one of the fundamental problems in distributed computing. It calls for all nodes of a network to agree on a single node, called the leader . If the nodes of the network have distinct labels, then agreeing on a single node means that all nodes have to output the label of the elected leader. If the nodes of the network are anonymous, the task of leader election is formulated as follows: every node v of the network must output a simple path, which is coded as a sequence of port numbers, such that all these paths end at a common node, the leader. In this article, we study deterministic leader election in anonymous trees. Our aim is to establish tradeoffs between the allocated time τ and the amount of information that has to be given a priori to the nodes to enable leader election in time τ in all trees for which leader election in this time is at all possible. Following the framework of algorithms with advice , this information (a single binary string) is provided to all nodes at the start by an oracle knowing the entire tree. The length of this string is called the size of advice . For a given time τ allocated to leader election, we give upper and lower bounds on the minimum size of advice sufficient to perform leader election in time τ. For most values of τ, our upper and lower bounds are either tight up to multiplicative constants, or they differ only by a logarithmic factor. Let T be an n -node tree of diameter diam ⩽ D . While leader election in time diam can be performed without any advice, for time diam − 1 we give tight upper and lower bounds of Θ(log D ). For time diam − 2 we give tight upper and lower bounds of Θ(log D ) for even values of diam , and tight upper and lower bounds of Θ(log n ) for odd values of diam . Moving to shorter time, in the interval [β · diam , diam − 3] for constant β &gt; 1/2, we prove an upper bound of O ( n log n / D ) and a lower bound of Ω( n / D ), the latter being valid whenever diam is odd or when the time is at most diam − 4. Hence, with the exception of the special case when diam is even and time is exactly diam − 3, our bounds leave only a logarithmic gap in this time interval. Finally, for time α · diam for any constant α &lt; 1/2 (except for the case of very small diameters), we again give tight upper and lower bounds, this time Θ( n ).",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2619218210",
    "type": "article"
  },
  {
    "title": "Network Sparsification for Steiner Problems on Planar and Bounded-Genus Graphs",
    "doi": "https://doi.org/10.1145/3239560",
    "publication_date": "2018-09-17",
    "publication_year": 2018,
    "authors": "Marcin Pilipczuk; Michał Pilipczuk; Piotr Sankowski; Erik Jan van Leeuwen",
    "corresponding_authors": "",
    "abstract": "We propose polynomial-time algorithms that sparsify planar and bounded-genus graphs while preserving optimal or near-optimal solutions to Steiner problems. Our main contribution is a polynomial-time algorithm that, given an unweighted undirected graph G embedded on a surface of genus g and a designated face f bounded by a simple cycle of length k , uncovers a set F ⊆ E ( G ) of size polynomial in g and k that contains an optimal Steiner tree for any set of terminals that is a subset of the vertices of f . We apply this general theorem to prove that: — Given an unweighted graph G embedded on a surface of genus g and a terminal set S ⊆ V ( G ), one can in polynomial time find a set F ⊆ E ( G ) that contains an optimal Steiner tree T for S and that has size polynomial in g and | E ( T )|. — An analogous result holds for an optimal Steiner forest for a set S of terminal pairs. — Given an unweighted planar graph G and a terminal set S ⊆ V ( G ), one can in polynomial time find a set F ⊆ E ( G ) that contains an optimal (edge) multiway cut C separating S (i.e., a cutset that intersects any path with endpoints in different terminals from S ) and that has size polynomial in | C |. In the language of parameterized complexity, these results imply the first polynomial kernels for S teiner T ree and S teiner F orest on planar and bounded-genus graphs (parameterized by the size of the tree and forest, respectively) and for (E dge ) M ultiway C ut on planar graphs (parameterized by the size of the cutset). Additionally, we obtain a weighted variant of our main contribution: a polynomial-time algorithm that, given an undirected plane graph G with positive edge weights, a designated face f bounded by a simple cycle of weight w ( f ), and an accuracy parameter ε &gt; 0, uncovers a set F ⊆ E ( G ) of total weight at most poly(ε -1 ) w ( f ) that, for any set of terminal pairs that lie on f , contains a Steiner forest within additive error ε w ( f ) from the optimal Steiner forest.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2890355536",
    "type": "article"
  },
  {
    "title": "Socially desirable approximations for dodgson’s voting rule",
    "doi": "https://doi.org/10.1145/2556950",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Ioannis Caragiannis; Christos Kaklamanis; Nikos Karanikolas; Ariel D. Procaccia",
    "corresponding_authors": "",
    "abstract": "In 1876, Charles Lutwidge Dodgson suggested the intriguing voting rule that today bears his name. Although Dodgson’s rule is one of the most well-studied voting rules, it suffers from serious deficiencies, both from the computational point of view—it is NP-hard even to approximate the Dodgson score within sublogarithmic factors—and from the social choice point of view—it fails basic social choice desiderata such as monotonicity and homogeneity. However, this does not preclude the existence of approximation algorithms for Dodgson that are monotonic or homogeneous, and indeed it is natural to ask whether such algorithms exist. In this article, we give definitive answers to these questions. We design a monotonic exponential-time algorithm that yields a 2-approximation to the Dodgson score, while matching this result with a tight lower bound. We also present a monotonic polynomial-time O(log m )-approximation algorithm (where m is the number of alternatives); this result is tight as well due to a complexity-theoretic lower bound. Furthermore, we show that a slight variation on a known voting rule yields a monotonic, homogeneous, polynomial-time O( m log m )-approximation algorithm and establish that it is impossible to achieve a better approximation ratio even if one just asks for homogeneity. We complete the picture by studying several additional social choice properties; for these properties, we prove that algorithms with an approximation ratio that depends only on m do not exist.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2084807538",
    "type": "article"
  },
  {
    "title": "Geometric optimization and sums of algebraic functions",
    "doi": "https://doi.org/10.1145/2532647",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Antoine Vigneron",
    "corresponding_authors": "Antoine Vigneron",
    "abstract": "We present a new optimization technique that yields the first FPTAS for several geometric problems. These problems reduce to optimizing a sum of nonnegative, constant description complexity algebraic functions. We first give an FPTAS for optimizing such a sum of algebraic functions, and then we apply it to several geometric optimization problems. We obtain the first FPTAS for two fundamental geometric shape-matching problems in fixed dimension: maximizing the volume of overlap of two polyhedra under rigid motions and minimizing their symmetric difference. We obtain the first FPTAS for other problems in fixed dimension, such as computing an optimal ray in a weighted subdivision, finding the largest axially symmetric subset of a polyhedron, and computing minimum-area hulls.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2115785246",
    "type": "article"
  },
  {
    "title": "Lopsidependency in the Moser-Tardos Framework",
    "doi": "https://doi.org/10.1145/3015762",
    "publication_date": "2016-12-21",
    "publication_year": 2016,
    "authors": "David G. Harris",
    "corresponding_authors": "David G. Harris",
    "abstract": "The Lopsided Lovász Local Lemma (LLLL) is a powerful probabilistic principle that has been used in a variety of combinatorial constructions. While this principle began as a general statement about probability spaces, it has recently been transformed into a variety of polynomial-time algorithms. The resampling algorithm of Moser and Tardos [2010] is the most well-known example of this. A variety of criteria have been shown for the LLLL; the strongest possible criterion was shown by Shearer, and other criteria that are easier to use computationally have been shown by Bissacot et al. [2011], Pegden [2014], Kolipaka and Szegedy [2011], and Kolipaka et al. [2012]. We show a new criterion for the Moser-Tardos algorithm to converge. This criterion is stronger than the LLLL criterion, and, in fact, can yield better results even than the full Shearer criterion. This is possible because it does not apply in the same generality as the original LLLL; yet, it is strong enough to cover many applications of the LLLL in combinatorics. We show a variety of new bounds and algorithms. A noteworthy application is for k -SAT, with bounded occurrences of variables. As shown in Gebauer et al. [2011], a k -SAT instance in which every variable appears L ≤ 2/ k +1 e ( k +1) times, is satisfiable. Although this bound is asymptotically tight (in k ), we improve it to L ≤ 2/ k +1 (1 − 1/ k ) k k −1 − 2/ k , which can be significantly stronger when k is small. We introduce a new parallel algorithm for the LLLL. While Moser and Tardos described a simple parallel algorithm for the Lovász Local Lemma and described a simple sequential algorithm for a form of the Lopsided Lemma, they were not able to combine the two. Our new algorithm applies in nearly all settings in which the sequential algorithm works—this includes settings covered by our new, stronger LLLL criterion.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2198255326",
    "type": "article"
  },
  {
    "title": "Bloom Filters in Adversarial Environments",
    "doi": "https://doi.org/10.1145/3306193",
    "publication_date": "2019-06-07",
    "publication_year": 2019,
    "authors": "Moni Naor; Eylon Yogev",
    "corresponding_authors": "",
    "abstract": "Many efficient data structures use randomness, allowing them to improve upon deterministic ones. Usually, their efficiency and correctness are analyzed using probabilistic tools under the assumption that the inputs and queries are independent of the internal randomness of the data structure. In this work, we consider data structures in a more robust model, which we call the adversarial model . Roughly speaking, this model allows an adversary to choose inputs and queries adaptively according to previous responses. Specifically, we consider a data structure known as a “Bloom filter” and prove a tight connection between Bloom filters in this model and cryptography. A Bloom filter represents a set S of elements approximately by using fewer bits than a precise representation. The price for succinctness is allowing for some errors: For any x ∈ S , it should always answer Yes, and for any x ∉ S it should answer Yes only with small probability. In the adversarial model, we consider both efficient adversaries (that run in polynomial time) and computationally unbounded adversaries that are only bounded in the number of queries they can make. For computationally bounded adversaries, we show that non-trivial (memory-wise) Bloom filters exist if and only if one-way functions exist. For unbounded adversaries, we show that there exists a Bloom filter for sets of size n and error ε that is secure against t queries and uses only O ( n log 1/ε + t ) bits of memory. In comparison, n log 1/ε is the best possible under a non-adaptive adversary.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2952451113",
    "type": "article"
  },
  {
    "title": "Better Balance by Being Biased",
    "doi": "https://doi.org/10.1145/2907052",
    "publication_date": "2016-10-10",
    "publication_year": 2016,
    "authors": "Per Austrin; Siavosh Benabbas; Konstantinos Georgiou",
    "corresponding_authors": "",
    "abstract": "Recently, Raghavendra and Tan (SODA 2012) gave a 0.85-approximation algorithm for the M ax B isection problem. We improve their algorithm to a 0.8776-approximation. As M ax B isection is hard to approximate within α GW + ε ≈ 0.8786 under the Unique Games Conjecture (UGC), our algorithm is nearly optimal. We conjecture that M ax B isection is approximable within α GW − ε, that is, that the bisection constraint (essentially) does not make M ax C ut harder. We also obtain an optimal algorithm (assuming the UGC) for the analogous variant of M ax 2-S at . Our approximation ratio for this problem exactly matches the optimal approximation ratio for M ax 2-S at , that is, α LLZ + ε ≈ 0.9401, showing that the bisection constraint does not make M ax 2-S at harder. This improves on a 0.93-approximation for this problem from Raghavendra and Tan.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2127816126",
    "type": "article"
  },
  {
    "title": "Approximation Algorithms for Stochastic Submodular Set Cover with Applications to Boolean Function Evaluation and Min-Knapsack",
    "doi": "https://doi.org/10.1145/2876506",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Amol Deshpande; Lisa Hellerstein; Devorah Kletenik",
    "corresponding_authors": "",
    "abstract": "We present a new approximation algorithm for the stochastic submodular set cover (SSSC) problem called adaptive dual greedy . We use this algorithm to obtain a 3-approximation algorithm solving the stochastic Boolean function evaluation (SBFE) problem for linear threshold formulas (LTFs). We also obtain a 3-approximation algorithm for the closely related stochastic min-knapsack problem and a 2-approximation for a variant of that problem. We prove a new approximation bound for a previous algorithm for the SSSC problem, the adaptive greedy algorithm of Golovin and Krause. We also consider an approach to approximating SBFE problems using the adaptive greedy algorithm, which we call the Q -value approach. This approach easily yields a new result for evaluation of CDNF (conjunctive / disjunctive normal form) formulas, and we apply variants of it to simultaneous evaluation problems and a ranking problem. However, we show that the Q -value approach provably cannot be used to obtain a sublinear approximation factor for the SBFE problem for LTFs or read-once disjunctive normal form formulas.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2342745562",
    "type": "article"
  },
  {
    "title": "Linear-time String Indexing and Analysis in Small Space",
    "doi": "https://doi.org/10.1145/3381417",
    "publication_date": "2020-03-09",
    "publication_year": 2020,
    "authors": "Djamal Belazzougui; Fabio Cunial; Juha Kärkkäinen; Veli Mäkinen",
    "corresponding_authors": "",
    "abstract": "The field of succinct data structures has flourished over the past 16 years. Starting from the compressed suffix array by Grossi and Vitter (STOC 2000) and the FM-index by Ferragina and Manzini (FOCS 2000), a number of generalizations and applications of string indexes based on the Burrows-Wheeler transform (BWT) have been developed, all taking an amount of space that is close to the input size in bits. In many large-scale applications, the construction of the index and its usage need to be considered as one unit of computation. For example, one can compare two genomes by building a common index for their concatenation and by detecting common substructures by querying the index. Efficient string indexing and analysis in small space lies also at the core of a number of primitives in the data-intensive field of high-throughput DNA sequencing. We report the following advances in string indexing and analysis: We show that the BWT of a string T ∈ {1,…,σ} n can be built in deterministic O ( n ) time using just O ( n log σ) bits of space, where σ ≤ n . Deterministic linear time is achieved by exploiting a new partial rank data structure that supports queries in constant time and that might have independent interest. Within the same time and space budget, we can build an index based on the BWT that allows one to enumerate all the internal nodes of the suffix tree of T . Many fundamental string analysis problems, such as maximal repeats, maximal unique matches, and string kernels, can be mapped to such enumeration and can thus be solved in deterministic O ( n ) time and in O ( n log σ) bits of space from the input string by tailoring the enumeration algorithm to some problem-specific computations. We also show how to build many of the existing indexes based on the BWT, such as the compressed suffix array , the compressed suffix tree , and the bidirectional BWT index , in randomized O ( n ) time and in O ( n log σ) bits of space. The previously fastest construction algorithms for BWT, compressed suffix array and compressed suffix tree, which used O ( n log σ) bits of space, took O ( n log log σ) time for the first two structures and O ( n log ϵ n ) time for the third, where ϵ is any positive constant smaller than one. Alternatively, the BWT could be previously built in linear time if one was willing to spend O ( n log σ log log σ n ) bits of space. Contrary to the state-of-the-art, our bidirectional BWT index supports every operation in constant time per element in its output.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W3010768629",
    "type": "article"
  },
  {
    "title": "Distributed Edge Coloring and a Special Case of the Constructive Lovász Local Lemma",
    "doi": "https://doi.org/10.1145/3365004",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Yi‐Jun Chang; Qizheng He; Wenzheng Li; Seth Pettie; Jara Uitto",
    "corresponding_authors": "",
    "abstract": "The complexity of distributed edge coloring depends heavily on the palette size as a function of the maximum degree Δ. In this article, we explore the complexity of edge coloring in the LOCAL model in different palette size regimes. Our results are as follows. Lower Bounds: First, we simplify the round elimination technique of Brandt et al. [16] and prove that (2Δ −2)-edge coloring requires Ω (log Δ log n ) time with high probability and Ω (log Δ n ) time deterministically, even on trees . Second, we show that a natural approach to computing (Δ +1)-edge colorings (Vizing’s theorem), namely, extending an arbitrary partial coloring by iteratively recoloring subgraphs, requires Ω (Δ log n ) time. Upper Bounds on General Graphs: We give a randomized edge coloring algorithm that can use palette sizes as small as Δ + Õ(√Δ), which is a natural barrier for randomized approaches. The running time of our (1+ϵ)Δ-edge coloring algorithm is usually dominated by O (\\log ϵ −1 ) calls to a distributed Lovász local lemma (LLL) algorithm. For example, using the Chung-Pettie-Su LLL algorithm, we compute a (1+ϵ)Δ-edge coloring in O (log n ) time when ϵ ≥ (log 3 Δ) / √ Δ , or O (log Δ n ) + (log log n ) 3 + o (1) time when ϵ = Ω (1). When Δ is sublogarithmic in n the performance is improved with the Ghaffari-Harris-Kuhn LLL algorithm. Upper Bounds on Trees: We show that the Ω (log Δ log n ) lower bound can be nearly matched on trees. To establish this result, we develop a new distributed Lovász local lemma algorithm for tree-structured dependency graphs , which arise naturally from O (1)-round probabilistic algorithms run on trees. Specifically, our (1+ϵ)Δ-edge coloring algorithm for trees takes O (log (1 / ϵ)) ⋅ max { log log n \\ log log log n , log log Δ log n } time when ϵ ≥ (log 3 Δ) / √ Δ, or O (max { log log n \\ log log log n , log Δ log n }) time when ϵ = Ω (1).",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2983776960",
    "type": "article"
  },
  {
    "title": "On Coalescence Time in Graphs: When Is Coalescing as Fast as Meeting?",
    "doi": "https://doi.org/10.1145/3576900",
    "publication_date": "2023-01-17",
    "publication_year": 2023,
    "authors": "Varun Kanade; Frederik Mallmann-Trenn; Thomas Sauerwald",
    "corresponding_authors": "",
    "abstract": "Coalescing random walks is a fundamental distributed process, where a set of particles perform independent discrete-time random walks on an undirected graph. Whenever two or more particles meet at a given node, they merge and continue as a single random walk. The coalescence time is defined as the expected time until only one particle remains, starting from one particle at every node. Despite recent progress such as that of Cooper et al., the coalescence time for graphs, such as binary trees, d -dimensional tori, hypercubes, and, more generally, vertex-transitive graphs, remains unresolved. We provide a powerful toolkit that results in tight bounds for various topologies including the aforementioned ones. The meeting time is defined as the worst-case expected time required for two random walks to arrive at the same node at the same time. As a general result, we establish that for graphs whose meeting time is only marginally larger than the mixing time (a factor of log 2 n ), the coalescence time of n random walks equals the meeting time up to constant factors. This upper bound is complemented by the construction of a graph family demonstrating that this result is the best possible up to constant factors. Finally, we prove a tight worst-case bound for the coalescence time of O(n 3 ) . By duality, our results yield identical bounds on the voter model. Our techniques also yield a new bound on the hitting time and cover time of regular graphs, improving and tightening previous results by Broder and Karlin, as well as those by Aldous and Fill.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2556309115",
    "type": "article"
  },
  {
    "title": "Scalable High-Quality Hypergraph Partitioning",
    "doi": "https://doi.org/10.1145/3626527",
    "publication_date": "2023-10-09",
    "publication_year": 2023,
    "authors": "Lars Gottesbüren; Tobias Heuer; Nikolai Maas; Peter Sanders; Sebastian Schlag",
    "corresponding_authors": "",
    "abstract": "Balanced hypergraph partitioning is an NP-hard problem with many applications, e.g., optimizing communication in distributed data placement problems. The goal is to place all nodes across k different blocks of bounded size, such that hyperedges span as few parts as possible. This problem is well-studied in sequential and distributed settings, but not in shared-memory. We close this gap by devising efficient and scalable shared-memory algorithms for all components employed in the best sequential solvers without compromises with regards to solution quality. This work presents the scalable and high-quality hypergraph partitioning framework Mt-KaHyPar . Its most important components are parallel improvement algorithms based on the FM algorithm and maximum flows, as well as a parallel clustering algorithm for coarsening – which are used in a multilevel scheme with log (n) levels. As additional components, we parallelize the n -level partitioning scheme, devise a deterministic version of our algorithm, and present optimizations for plain graphs. We evaluate our solver on more than 800 graphs and hypergraphs, and compare it with 25 different algorithms from the literature. Our fastest configuration outperforms almost all existing hypergraph partitioners with regards to both solution quality and running time. Our highest-quality configuration achieves the same solution quality as the best sequential partitioner KaHyPar , while being an order of magnitude faster with ten threads. Thus, two of our configurations occupy all fronts of the Pareto curve for hypergraph partitioning. Furthermore, our solvers exhibit good speedups, e.g., 29.6x in the geometric mean on 64 cores (deterministic), 22.3x (log (n) -level), and 25.9x ( n -level).",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W4387461247",
    "type": "article"
  },
  {
    "title": "An improved algorithm for CIOQ switches",
    "doi": "https://doi.org/10.1145/1150334.1150342",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Yossi Azar; Yossi Richter",
    "corresponding_authors": "",
    "abstract": "The problem of maximizing the weighted throughput in various switching settings has been intensively studied recently through competitive analysis. To date, the most general model that has been investigated is the standard CIOQ (Combined Input and Output Queued) switch architecture with internal fabric speedup S ≥ 1. CIOQ switches, that comprise the backbone of packet routing networks, are N × N switches controlled by a switching policy that incorporates two components: Admission control and scheduling. An admission control strategy is essential to determine the packets stored in the FIFO queues in input and output ports, while the scheduling policy conducts the transfer of packets through the internal fabric, from input ports to output ports. The online problem of maximizing the total weighted throughput of CIOQ switches was recently investigated by Kesselman and Rosén [2003]. They presented two different online algorithms for the general problem that achieve non-constant competitive ratios (linear in either the speedup or the number of distinct values, or logarithmic in the value range). We introduce the first constant-competitive algorithm for the general case of the problem, with arbitrary speedup and packet values. Specifically, our algorithm is 8-competitive, and is also simple and easy to implement.",
    "cited_by_count": 39,
    "openalex_id": "https://openalex.org/W2078182186",
    "type": "article"
  },
  {
    "title": "SRPT optimally utilizes faster machines to minimize flow time",
    "doi": "https://doi.org/10.1145/1435375.1435376",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Eric Torng; Jason McCullough",
    "corresponding_authors": "",
    "abstract": "We analyze the shortest remaining processing time (SRPT) algorithm with respect to the problem of scheduling n jobs with release times on m identical machines to minimize total flow time. It is known that SRPT is optimal if m = 1 but that SRPT has a worst-case approximation ratio of Θ(min(log n/m , log Δ)) for this problem, where Δ is the ratio of the length of the longest job divided by the length of the shortest job. It has previously been shown that SRPT is able to use faster machines to produce a schedule as good as an optimal algorithm using slower machines. We now show that SRPT optimally uses these faster machines with respect to the worst-case approximation ratio. That is, if SRPT is given machines that are s ≥ 2 − 1/ m times as fast as those used by an optimal algorithm, SRPT's flow time is at least s times smaller than the flow time incurred by the optimal algorithm. Clearly, no algorithm can offer a better worst-case guarantee, and we show that existing algorithms with similar performance guarantees to SRPT without resource augmentation do not optimally use extra resources.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2036114217",
    "type": "article"
  },
  {
    "title": "A new approximation algorithm for the asymmetric TSP with triangle inequality",
    "doi": "https://doi.org/10.1145/1383369.1383378",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Markus Bläser",
    "corresponding_authors": "Markus Bläser",
    "abstract": "We present a polynomial time factor 0.999 ċ log n approximation algorithm for the asymmetric traveling salesperson problem with triangle inequality.",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2056179869",
    "type": "article"
  },
  {
    "title": "Improved algorithms for weakly chordal graphs",
    "doi": "https://doi.org/10.1145/1240233.1240237",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Ryan Hayward; Jeremy Spinrad; R. Sritharan",
    "corresponding_authors": "",
    "abstract": "We use a new structural theorem on the presence of two-pairs in weakly chordal graphs to develop improved algorithms. For the recognition problem, we reduce the time complexity from O( mn 2 ) to O( m 2 ) and the space complexity from O( n 3 ) to O( m + n ), and also produce a hole or antihole if the input graph is not weakly chordal. For the optimization problems, the complexity of the clique and coloring problems is reduced from O( mn 2 ) to O( n 3 ) and the complexity of the independent set and clique cover problems is improved from O( n 4 ) to O( mn ). The space complexity of our optimization algorithms is O( m + n ).",
    "cited_by_count": 35,
    "openalex_id": "https://openalex.org/W2099914933",
    "type": "article"
  },
  {
    "title": "Competitive buffer management for shared-memory switches",
    "doi": "https://doi.org/10.1145/1435375.1435378",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "William Aiello; Alex Kesselman; Yishay Mansour",
    "corresponding_authors": "",
    "abstract": "We consider buffer management policies for shared memory switches. We study the case of overloads resulting in packet loss, where the constraint is the limited shared memory capacity. The goal of the buffer management policy is that of maximizing the number of packets transmitted. The problem is online in nature, and thus we use competitive analysis to measure the performance of the buffer management policies. Our main result is to show that the well-known preemptive Longest Queue Drop ( LQD ) policy is at most 2-competitive and at least √2-competitive. We also demonstrate a general lower bound of 4/3 on the performance of any deterministic online policy. Finally, we consider some other popular non-preemptive policies including Complete Partition, Complete Sharing, Static Threshold and Dynamic Threshold and derive almost tight bounds on their performance.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2033661244",
    "type": "article"
  },
  {
    "title": "Alternation and redundancy analysis of the intersection problem",
    "doi": "https://doi.org/10.1145/1328911.1328915",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Jérémy Barbay; Claire Kenyon",
    "corresponding_authors": "",
    "abstract": "The intersection of sorted arrays problem has applications in search engines such as Google. Previous work has proposed and compared deterministic algorithms for this problem, in an adaptive analysis based on the encoding size of a certificate of the result (cost analysis). We define the alternation analysis , based on the nondeterministic complexity of an instance. In this analysis we prove that there is a deterministic algorithm asymptotically performing as well as any randomized algorithm in the comparison model. We define the redundancy analysis , based on a measure of the internal redundancy of the instance. In this analysis we prove that any algorithm optimal in the redundancy analysis is optimal in the alternation analysis, but that there is a randomized algorithm which performs strictly better than any deterministic algorithm in the comparison model. Finally, we describe how these results can be extended beyond the comparison model.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2100474856",
    "type": "article"
  },
  {
    "title": "Phase changes in random point quadtrees",
    "doi": "https://doi.org/10.1145/1240233.1240235",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Hua‐Huai Chern; Michael Fuchs; Hsien‐Kuei Hwang",
    "corresponding_authors": "",
    "abstract": "We show that a wide class of linear cost measures (such as the number of leaves) in random d -dimensional point quadtrees undergo a change in limit laws: If the dimension d = 1, …, 8, then the limit law is normal; if d ≥ 9 then there is no convergence to a fixed limit law. Stronger approximation results such as convergence rates and local limit theorems are also derived for the number of leaves, additional phase changes being unveiled. Our approach is new and very general, and also applicable to other classes of search trees. A brief discussion of Devroye's grid trees (covering m -ary search trees and quadtrees as special cases) is given. We also propose an efficient numerical procedure for computing the constants involved to high precision.",
    "cited_by_count": 34,
    "openalex_id": "https://openalex.org/W2165061849",
    "type": "article"
  },
  {
    "title": "Packing element-disjoint steiner trees",
    "doi": "https://doi.org/10.1145/1290672.1290684",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Joseph Cheriyan; Mohammad R. Salavatipour",
    "corresponding_authors": "",
    "abstract": "Given an undirected graph G ( V , E ) with terminal set T ⊆ V , the problem of packing element-disjoint Steiner trees is to find the maximum number of Steiner trees that are disjoint on the nonterminal nodes and on the edges. The problem is known to be NP-hard to approximate within a factor of Ω(log n ), where n denotes | V |. We present a randomized O (log n )-approximation algorithm for this problem, thus matching the hardness lower bound. Moreover, we show a tight upper bound of O (log n ) on the integrality ratio of a natural linear programming relaxation.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W1992520347",
    "type": "article"
  },
  {
    "title": "Finding a long directed cycle",
    "doi": "https://doi.org/10.1145/1328911.1328918",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Harold N. Gabow; Shuxin Nie",
    "corresponding_authors": "",
    "abstract": "Consider a digraph with n vertices. For any fixed value k , we present linear- and almost-linear-time algorithms to find a cycle of length ≥ k , if one exists. We also find a cycle that has length ≥ log n /log log n in polynomial time, if one exists. Under an appropriate complexity assumption it is known to be impossible to improve this guarantee by more than a log log n factor. Our approach is based on depth-first search.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2058198905",
    "type": "article"
  },
  {
    "title": "Edge-disjoint paths revisited",
    "doi": "https://doi.org/10.1145/1290672.1290683",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Chandra Chekuri; Sanjeev Khanna",
    "corresponding_authors": "",
    "abstract": "The approximability of the maximum edge-disjoint paths problem (EDP) in directed graphs was seemingly settled by an Ω( m 1/2 - ϵ)-hardness result of Guruswami et al. [2003], and an O (√ m ) approximation achievable via a natural multicommodity-flow-based LP relaxation as well as a greedy algorithm. Here m is the number of edges in the graph. We observe that the Ω( m 1/2 - ϵ)-hardness of approximation applies to sparse graphs, and hence when expressed as a function of n , that is, the number of vertices, only an Ω( n 1/2 - ϵ)-hardness follows. On the other hand, O (√ m )-approximation algorithms do not guarantee a sublinear (in terms of n ) approximation algorithm for dense graphs. We note that a similar gap exists in the known results on the integrality gap of the flow-based LP relaxation: an Ω(√ n ) lower bound and O (√ m ) upper bound. Motivated by this discrepancy in the upper and lower bounds, we study algorithms for EDP in directed and undirected graphs and obtain improved approximation ratios. We show that the greedy algorithm has an approximation ratio of O (min( n 2/3 , √ m )) in undirected graphs and a ratio of O (min( n 4/5 , √ m )) in directed graphs. For acyclic graphs we give an O (√ n ln n ) approximation via LP rounding. These are the first sublinear approximation ratios for EDP. The results also extend to EDP with weights and to the uniform-capacity unsplittable flow problem (UCUFP).",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W2080283527",
    "type": "article"
  },
  {
    "title": "Deterministic sampling and range counting in geometric data streams",
    "doi": "https://doi.org/10.1145/1240233.1240239",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Amitabha Bagchi; Amitabh Chaudhary; David Eppstein; Michael T. Goodrich",
    "corresponding_authors": "",
    "abstract": "We present memory-efficient deterministic algorithms for constructing ϵ-nets and ϵ-approximations of streams of geometric data. Unlike probabilistic approaches, these deterministic samples provide guaranteed bounds on their approximation factors. We show how our deterministic samples can be used to answer approximate online iceberg geometric queries on data streams. We use these techniques to approximate several robust statistics of geometric data streams, including Tukey depth, simplicial depth, regression depth, the Thiel-Sen estimator, and the least median of squares. Our algorithms use only a polylogarithmic amount of memory, provided the desired approximation factors are at least inverse-polylogarithmic. We also include a lower bound for noniceberg geometric queries.",
    "cited_by_count": 33,
    "openalex_id": "https://openalex.org/W3121225887",
    "type": "article"
  },
  {
    "title": "Enumeration of isolated cliques and pseudo-cliques",
    "doi": "https://doi.org/10.1145/1597036.1597044",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Hiro Ito; Kazuo Iwama",
    "corresponding_authors": "",
    "abstract": "In this article, we consider isolated cliques and isolated dense subgraphs. For a given graph G , a vertex subset S of size k (and also its induced subgraph G ( S )) is said to be c -isolated if G ( S ) is connected to its outside via less than ck edges. The number c is sometimes called the isolation factor . The subgraph appears more isolated if the isolation factor is smaller. The main result in this work shows that for a fixed constant c , we can enumerate all c -isolated maximal cliques (including a maximum one, if any) in linear time. In more detail, we show that, for a given graph G of n vertices and m edges, and a positive real number c , all c -isolated maximal cliques can be enumerated in time O ( c 4 2 2c m ). From this, we can see that: (1) if c is a constant, all c -isolated maximal cliques can be enumerated in linear time, and (2) if c = O (log n ), all c -isolated maximal cliques can be enumerated in polynomial time. Moreover, we show that these bounds are tight. That is, if f ( n ) is an increasing function not bounded by any constant, then there is a graph of n vertices and m edges for which the number of f ( n )-isolated maximal cliques is superlinear in n + m . Furthermore, if f ( n ) = ω(log n ), there is a graph of n vertices and m edges for which the number of f ( n )-isolated maximal cliques is superpolynomial in n + m . We next introduce the idea of pseudo-cliques. A pseudo-clique having an average degree α and a minimum degree β, denoted by PC (α,β), is a set V ′ ⊆ V such that the subgraph induced by V ′ has an average degree of at least α and a minimum degree of at least β. This article investigates these, and obtains some cases that can be solved in polynomial time and some other cases that have a superpolynomial number of solutions. Especially, we show the following results, where k is the number of vertices of the isolated pseudo-cliques: (1) For any ϵ &gt; 0 there is a graph of n vertices for which the number of 1-isolated PC ( k - (log k ) 1 + ϵ , k /(log k ) 1 + ϵ ) is superpolynomial, and (2) there is a polynomial-time algorithm which enumerates all c -isolated PC ( k - log k , k /log k ), for any constant c .",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2010504820",
    "type": "article"
  },
  {
    "title": "A linear-time algorithm to find a separator in a graph excluding a minor",
    "doi": "https://doi.org/10.1145/1597036.1597043",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Bruce Reed; David R. Wood",
    "corresponding_authors": "",
    "abstract": "Let G be an n -vertex m -edge graph with weighted vertices. A pair of vertex sets A , B ⊆ V ( G ) is a 2/3 -separation of order | A ∩ B | if A ∪ B = V ( G ), there is no edge between A − B and B − A , and both A − B and B − A have weight at most 2/3 the total weight of G . Let ℓ ∈ Z + be fixed. Alon et al. [1990] presented an algorithm that in O ( n 1/2 m ) time, outputs either a K ℓ -minor of G , or a separation of G of order O ( n 1/2 ). Whether there is a O ( n + m )-time algorithm for this theorem was left as an open problem. In this article, we obtain a O ( n + m )-time algorithm at the expense of a O ( n 2/3 ) separator. Moreover, our algorithm exhibits a trade-off between time complexity and the order of the separator. In particular, for any given ϵ ∈ [0,1/2], our algorithm outputs either a K ℓ -minor of G , or a separation of G with order O ( n (2−ϵ)/3 in O ( n 1 + ϵ + m ) time. As an application we give a fast approximation algorithm for finding an independent set in a graph with no K ℓ-minor.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2030012922",
    "type": "article"
  },
  {
    "title": "Compact dictionaries for variable-length keys and data with applications",
    "doi": "https://doi.org/10.1145/1361192.1361194",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Daniel K. Blandford; Guy E. Blelloch",
    "corresponding_authors": "",
    "abstract": "We consider the problem of maintaining a dynamic dictionary T of keys and associated data for which both the keys and data are bit strings that can vary in length from zero up to the length w of a machine word. We present a data structure for this variable-bit-length dictionary problem that supports constant time lookup and expected amortized constant-time insertion and deletion. It uses O ( m + 3 n − n log 2 n ) bits, where n is the number of elements in T , and m is the total number of bits across all strings in T (keys and data). Our dictionary uses an array A [1 … n ] in which locations store variable-bit-length strings. We present a data structure for this variable-bit-length array problem that supports worst-case constant-time lookups and updates and uses O ( m + n ) bits, where m is the total number of bits across all strings stored in A . The motivation for these structures is to support applications for which it is helpful to efficiently store short varying-length bit strings. We present several applications, including representations for semidynamic graphs, order queries on integers sets, cardinal trees with varying cardinality, and simplicial meshes of d dimensions. These results either generalize or simplify previous results.",
    "cited_by_count": 32,
    "openalex_id": "https://openalex.org/W2057529271",
    "type": "article"
  },
  {
    "title": "Trading off space for passes in graph streaming problems",
    "doi": "https://doi.org/10.1145/1644015.1644021",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Camil Demetrescu; Irene Finocchi; Andrea Ribichini",
    "corresponding_authors": "",
    "abstract": "Data stream processing has recently received increasing attention as a computational paradigm for dealing with massive data sets. Surprisingly, no algorithm with both sublinear space and passes is known for natural graph problems in classical read-only streaming. Motivated by technological factors of modern storage systems, some authors have recently started to investigate the computational power of less restrictive models where writing streams is allowed. In this article, we show that the use of intermediate temporary streams is powerful enough to provide effective space-passes tradeoffs for natural graph problems. In particular, for any space restriction of s bits, we show that single-source shortest paths in directed graphs with small positive integer edge weights can be solved in O (( n log 3/2 n )/√ s ) passes. The result can be generalized to deal with multiple sources within the same bounds. This is the first known streaming algorithm for shortest paths in directed graphs. For undirected connectivity, we devise an O (( n log n )/ s ) passes algorithm. Both problems require Ω( n / s ) passes under the restrictions we consider. We also show that the model where intermediate temporary streams are allowed can be strictly more powerful than classical streaming for some problems, while maintaining all of its hardness for others.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W1967521717",
    "type": "article"
  },
  {
    "title": "How to probe for an extreme value",
    "doi": "https://doi.org/10.1145/1868237.1868250",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Ashish Goel; Sudipto Guha; Kamesh Munagala",
    "corresponding_authors": "",
    "abstract": "In several systems applications, parameters such as load are known only with some associated uncertainty, which is specified, or modeled, as a distribution over values. The performance of the system optimization and monitoring schemes can be improved by spending resources such as time or bandwidth in observing or resolving the values of these parameters. In a resource-constrained situation, deciding which parameters to observe in order to best optimize the expected system performance (or in general, optimize the expected value of a certain objective function) itself becomes an interesting optimization problem. In this article, we initiate the study of such problems that we term “model-driven optimization”. In particular, we study the problem of optimizing the minimum value in the presence of observable distributions. We show that this problem is NP-Hard, and present greedy algorithms with good performance bounds. The proof of the performance bounds are via novel sub-modularity arguments and connections to covering integer programs.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2058632122",
    "type": "article"
  },
  {
    "title": "All maximal independent sets and dynamic dominance for sparse graphs",
    "doi": "https://doi.org/10.1145/1597036.1597042",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "David Eppstein",
    "corresponding_authors": "David Eppstein",
    "abstract": "We describe algorithms, based on Avis and Fukuda's reverse search paradigm, for listing all maximal independent sets in a sparse graph in polynomial time and delay per output. For bounded degree graphs, our algorithms take constant time per set generated; for minor-closed graph families, the time is O(n) per set, and for more general sparse graph families we achieve subquadratic time per set. We also describe new data structures for maintaining a dynamic vertex set S in a sparse or minor-closed graph family, and querying the number of vertices not dominated by S; for minor-closed graph families the time per update is constant, while it is sublinear for any sparse graph family. We can also maintain a dynamic vertex set in an arbitrary m-edge graph and test the independence of the maintained set in time O(sqrt m) per update. We use the domination data structures as part of our enumeration algorithms.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W3139242982",
    "type": "article"
  },
  {
    "title": "Real-Time Streaming String-Matching",
    "doi": "https://doi.org/10.1145/2635814",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Dany Breslauer; Zvi Galil",
    "corresponding_authors": "",
    "abstract": "This article presents a real-time randomized streaming string-matching algorithm that uses O (log m ) space. The algorithm only makes one-sided small probability false-positive errors, possibly reporting phantom occurrences of the pattern, but never missing an actual occurrence.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2064473870",
    "type": "article"
  },
  {
    "title": "The optimality of the online greedy algorithm in carpool and chairman assignment problems",
    "doi": "https://doi.org/10.1145/1978782.1978792",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Don Coppersmith; Tomasz Nowicki; Giuseppe Paleologo; Charles Tresser; Chai Wah Wu",
    "corresponding_authors": "",
    "abstract": "We study several classes of related scheduling problems including the carpool problem, its generalization to arbitrary inputs and the chairman assignment problem. We derive both lower and upper bounds for online algorithms solving these problems. We show that the greedy algorithm is optimal among online algorithms for the chairman assignment problem and the generalized carpool problem. We also consider geometric versions of these problems and show how the bounds adapt to these cases.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2083291396",
    "type": "article"
  },
  {
    "title": "Shortest vertex-disjoint two-face paths in planar graphs",
    "doi": "https://doi.org/10.1145/1921659.1921665",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Éric Colin de Verdière; Alexander Schrijver",
    "corresponding_authors": "",
    "abstract": "Let G be a directed planar graph of complexity n , each arc having a nonnegative length. Let s and t be two distinct faces of G let s 1 ,…, s k be vertices incident with s let t 1 ,…, t k be vertices incident with t . We give an algorithm to compute k pairwise vertex-disjoint paths connecting the pairs ( s i , t i ) in G , with minimal total length, in O ( kn log n ) time.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2111716715",
    "type": "article"
  },
  {
    "title": "The tree inclusion problem",
    "doi": "https://doi.org/10.1145/1978782.1978793",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Philip Bille; Inge Li Gørtz",
    "corresponding_authors": "",
    "abstract": "Given two rooted, ordered, and labeled trees P and T the tree inclusion problem is to determine if P can be obtained from T by deleting nodes in T . This problem has recently been recognized as an important query primitive in XML databases. Kilpeläinen and Mannila [1995] presented the first polynomial-time algorithm using quadratic time and space. Since then several improved results have been obtained for special cases when P and T have a small number of leaves or small depth. However, in the worst case these algorithms still use quadratic time and space. Let n S , l S , and d S denote the number of nodes, the number of leaves, and the depth of a tree S ∈ P , T . In this article we show that the tree inclusion problem can be solved in space O ( n T ) and time: O⎛⎝min⎧⎨⎩lPnTlPlT log log nT + nTnPnTlog nT+ nT log nT⎫⎬⎭⎞⎠. This improves or matches the best known time complexities while using only linear space instead of quadratic. This is particularly important in practical applications, such as XML databases, where the space is likely to be a bottleneck.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2150621286",
    "type": "article"
  },
  {
    "title": "For-All Sparse Recovery in Near-Optimal Time",
    "doi": "https://doi.org/10.1145/3039872",
    "publication_date": "2017-03-06",
    "publication_year": 2017,
    "authors": "Anna C. Gilbert; Yi Li; Ely Porat; Martin J. Strauss",
    "corresponding_authors": "",
    "abstract": "An approximate sparse recovery system in ℓ 1 norm consists of parameters k , ϵ, N ; an m -by- N measurement Φ; and a recovery algorithm R . Given a vector, x , the system approximates x by xˆ = R (Φ x ), which must satisfy ‖ xˆ- x ‖ 1 ≤ (1+ϵ)‖ x - x k ‖ 1 . We consider the “for all” model, in which a single matrix Φ, possibly “constructed” non-explicitly using the probabilistic method, is used for all signals x . The best existing sublinear algorithm by Porat and Strauss [2012] uses O (ϵ −3 k log ( N / k )) measurements and runs in time O ( k 1 − α N α ) for any constant α &gt; 0. In this article, we improve the number of measurements to O (ϵ − 2 k log ( N / k )), matching the best existing upper bound (attained by super-linear algorithms), and the runtime to O ( k 1+β poly(log N ,1/ϵ)), with a modest restriction that k ⩽ N 1 − α and ϵ ⩽ (log k /log N ) γ for any constants α, β, γ &gt; 0. When k ⩽ log c N for some c &gt; 0, the runtime is reduced to O ( k poly( N ,1/ϵ)). With no restrictions on ϵ, we have an approximation recovery system with m = O ( k /ϵlog ( N / k )((log N /log k ) γ + 1/ϵ)) measurements. The overall architecture of this algorithm is similar to that of Porat and Strauss [2012] in that we repeatedly use a weak recovery system (with varying parameters) to obtain a top-level recovery algorithm. The weak recovery system consists of a two-layer hashing procedure (or with two unbalanced expanders for a deterministic algorithm). The algorithmic innovation is a novel encoding procedure that is reminiscent of network coding and that reflects the structure of the hashing stages. The idea is to encode the signal position index i by associating it with a unique message m i , which will be encoded to a longer message m ′ i (in contrast to Porat and Strauss [2012] in which the encoding is simply the identity). Portions of the message m ′ i correspond to repetitions of the hashing, and we use a regular expander graph to encode the linkages among these portions. The decoding or recovery algorithm consists of recovering the portions of the longer messages m ′ i and then decoding to the original messages m i , all the while ensuring that corruptions can be detected and/or corrected. The recovery algorithm is similar to list recovery introduced in Indyk et al. [2010] and used in Gilbert et al. [2013]. In our algorithm, the messages { m i } are independent of the hashing, which enables us to obtain a better result.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W1491344380",
    "type": "article"
  },
  {
    "title": "Online scheduling of packets with agreeable deadlines",
    "doi": "https://doi.org/10.1145/2390176.2390181",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Łukasz Jeż; Fei Li; Jay Sethuraman; Clifford Stein",
    "corresponding_authors": "",
    "abstract": "This article concerns an online packet scheduling problem that arises as a natural model for buffer management at a network router. Packets arrive at a router at integer time steps, and are buffered upon arrival. Packets have non-negative weights and integer deadlines that are (weakly) increasing in their arrival times. In each integer time step, at most one packet can be sent. The objective is to maximize the sum of the weights of the packets that are sent by their deadlines. The main results include an optimal (ϕ := (1 + √ 5)/2 ≈ 1.618)-competitive deterministic online algorithm, a (4/3 ≈ 1.33)-competitive randomized online algorithm against an oblivious adversary, and a 2-speed 1-competitive deterministic online algorithm. The analysis does not use a potential function explicitly, but instead modifies the adversary's buffer and credits the adversary to account for these modifications.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2000013497",
    "type": "article"
  },
  {
    "title": "On the matrix berlekamp-massey algorithm",
    "doi": "https://doi.org/10.1145/2500122",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Erich Kaltofen; George Yuhasz",
    "corresponding_authors": "",
    "abstract": "We analyze the Matrix Berlekamp/Massey algorithm, which generalizes the Berlekamp/Massey algorithm [Massey 1969] for computing linear generators of scalar sequences. The Matrix Berlekamp/Massey algorithm computes a minimal matrix generator of a linearly generated matrix sequence and has been first introduced by Rissanen [1972a], Dickinson et al. [1974], and Coppersmith [1994]. Our version of the algorithm makes no restrictions on the rank and dimensions of the matrix sequence. We also give new proofs of correctness and complexity for the algorithm, which is based on self-contained loop invariants and includes an explicit termination criterion for a given determinantal degree bound of the minimal matrix generator.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2010027455",
    "type": "article"
  },
  {
    "title": "On Uniform Capacitated <i>k</i> -Median Beyond the Natural LP Relaxation",
    "doi": "https://doi.org/10.1145/2983633",
    "publication_date": "2017-01-14",
    "publication_year": 2017,
    "authors": "Shi Li",
    "corresponding_authors": "Shi Li",
    "abstract": "In this article, we study the uniform capacitated k -median (CKM) problem. In the problem, we are given a set F of potential facility locations, a set C of clients, a metric d over F ∪ C , an upper bound k on the number of facilities that we can open, and an upper bound u on the number of clients that each facility can serve. We need to open a subset S ⊆ F of k facilities and connect clients in C to facilities in S so that each facility is connected by at most u clients. The goal is to minimize the total connection cost over all clients. Obtaining a constant approximation algorithm for this problem is a notorious open problem; most previous works gave constant approximations by either violating the capacity constraints or the cardinality constraint. Notably, all of these algorithms are based on the natural LP relaxation for the problem. The LP relaxation has unbounded integrality gap, even when we are allowed to violate the capacity constraints or the cardinality constraint by a factor of 2 − ϵ. Our result is an exp ( O (1/ϵ 2 ))-approximation algorithm for the problem that violates the cardinality constraint by a factor of 1 + ϵ. In other words, we find a solution that opens at most (1 + ϵ) k facilities whose cost is at most exp ( O (1/ϵ 2 )) times the optimum solution when at most k facilities can be open. This is already beyond the capability of the natural LP relaxation, as it has unbounded integrality gap even if we are allowed to open (2 − ϵ) k facilities. Indeed, our result is based on a novel LP for this problem. It is our hope that this LP is the first step toward a constant approximation for CKM. The version that we described is the hard capacitated version of the problem, as we can only open one facility at each location. This is as opposed to the soft capacitated version, in which we are allowed to open more than one facility at each location. The hard capacitated version is more general, since one can convert a soft capacitated instance to a hard capacitated instance by making enough copies of each facility location. We give a simple proof that in the uniform capacitated case, the soft capacitated version and the hard capacitated version are actually equivalent, up to a small constant loss in the approximation ratio.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W3162123198",
    "type": "article"
  },
  {
    "title": "On the Performance of Smith’s Rule in Single-Machine Scheduling with Nonlinear Cost",
    "doi": "https://doi.org/10.1145/2629652",
    "publication_date": "2015-04-13",
    "publication_year": 2015,
    "authors": "Wiebke Höhn; Tobias Jacobs",
    "corresponding_authors": "",
    "abstract": "We consider a single-machine scheduling problem. Given some continuous, nondecreasing cost function, we aim to compute a schedule minimizing the weighted total cost, where the cost of each job is determined by the cost function value at its completion time. This problem is closely related to scheduling a single machine with nonuniform processing speed. We show that for piecewise linear cost functions it is strongly NP-hard. The main contribution of this article is a tight analysis of the approximation guarantee of Smith’s rule under any convex or concave cost function. More specifically, for these wide classes of cost functions we reduce the task of determining a worst-case problem instance to a continuous optimization problem, which can be solved by standard algebraic or numerical methods. For polynomial cost functions with positive coefficients, it turns out that the tight approximation ratio can be calculated as the root of a univariate polynomial. We show that this approximation ratio is asymptotically equal to k ( k − 1)/( k + 1) , denoting by k the degree of the cost function. To overcome unrealistic worst-case instances, we also give tight bounds for the case of integral processing times that are parameterized by the maximum and total processing time.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2044030708",
    "type": "article"
  },
  {
    "title": "Inapproximability of the Multilevel Uncapacitated Facility Location Problem",
    "doi": "https://doi.org/10.1145/2907050",
    "publication_date": "2016-09-21",
    "publication_year": 2016,
    "authors": "Ravishankar Krishnaswamy; Maxim Sviridenko",
    "corresponding_authors": "",
    "abstract": "In this article, we present improved inapproximability results for the k -level uncapacitated facility location problem. In particular, we show that there is no polynomial time approximation algorithm with performance guarantee better than 1.539 unless P = NP for the case when k = 2. For the case of general k (tending to infinity), we obtain a better hardness factor of 1.61. Interestingly, our results show that the two-level problem is computationally harder than the well-known uncapacitated facility location problem ( k = 1) since the best-known approximation guarantee for the latter problem is 1.488 due to Li [2013], and our inapproximability is a factor of 1.539 for the two-level problem. The only inapproximability result known before for this class of metric facility location problems is the bound of 1.463 due to Guha and Khuller [1999], which holds even for the case of k = 1.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2522951985",
    "type": "article"
  },
  {
    "title": "Incremental Exact Min-Cut in Polylogarithmic Amortized Update Time",
    "doi": "https://doi.org/10.1145/3174803",
    "publication_date": "2018-03-12",
    "publication_year": 2018,
    "authors": "Gramoz Goranci; Monika Henzinger; Mikkel Thorup",
    "corresponding_authors": "",
    "abstract": "We present a deterministic incremental algorithm for exactly maintaining the size of a minimum cut with O (log 3 n log log 2 n ) amortized time per edge insertion and O (1) query time. This result partially answers an open question posed by Thorup (2007). It also stays in sharp contrast to a polynomial conditional lower bound for the fully dynamic weighted minimum cut problem. Our algorithm is obtained by combining a sparsification technique of Kawarabayashi and Thorup (2015) or its recent improvement by Henzinger, Rao, and Wang (2017), and an exact incremental algorithm of Henzinger (1997). We also study space-efficient incremental algorithms for the minimum cut problem. Concretely, we show that there exists an O ( n log n /ε 2 ) space Monte Carlo algorithm that can process a stream of edge insertions starting from an empty graph, and with high probability, the algorithm maintains a (1+ε)-approximation to the minimum cut. The algorithm has O ((α ( n ) log 3 n )/ε 2 ) amortized update time and constant query time, where α ( n ) stands for the inverse of Ackermann function.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2538944508",
    "type": "article"
  },
  {
    "title": "Feedback Vertex Set Inspired Kernel for Chordal Vertex Deletion",
    "doi": "https://doi.org/10.1145/3284356",
    "publication_date": "2018-12-08",
    "publication_year": 2018,
    "authors": "Akanksha Agrawal; Daniel Lokshtanov; Pranabendu Misra; Saket Saurabh; Meirav Zehavi",
    "corresponding_authors": "",
    "abstract": "Given a graph G and a parameter k , the C hordal V ertex D eletion (CVD) problem asks whether there exists a subset U ⊆ V ( G ) of size at most k that hits all induced cycles of size at least 4. The existence of a polynomial kernel for CVD was a well-known open problem in the field of Parameterized Complexity. Recently, Jansen and Pilipczuk resolved this question affirmatively by designing a polynomial kernel for CVD of size O ( k 161 log 58 k ) and asked whether one can design a kernel of size O ( k 10 ) [Jansen an Pilipczuk, SODA 2017]. While we do not completely resolve this question, we design a significantly smaller kernel of size O ( k 12 log 10 k ), inspired by the O ( k 2 ) -size kernel for F eedback V ertex S et [Thomassé, TALG 2010]. Furthermore, we introduce the notion of the independence degree of a vertex, which is our main conceptual contribution.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2904185472",
    "type": "article"
  },
  {
    "title": "Label Cover Instances with Large Girth and the Hardness of Approximating Basic <i>k</i> -Spanner",
    "doi": "https://doi.org/10.1145/2818375",
    "publication_date": "2015-12-31",
    "publication_year": 2015,
    "authors": "Michael Dinitz; Guy Kortsarz; Ran Raz",
    "corresponding_authors": "",
    "abstract": "We study the well-known Label Cover problem under the additional requirement that problem instances have large girth. We show that if the girth is some k , the problem is roughly 2 log 1-ϵ n)/k hard to approximate for all constant ϵ &gt; 0. A similar theorem was claimed by Elkin and Peleg [2000] as part of an attempt to prove hardness for the basic k -spanner problem, but their proof was later found to have a fundamental error. Thus, we give both the first nontrivial lower bound for the problem of Label Cover with large girth as well as the first full proof of strong hardness for the basic k -spanner problem, which is both the simplest problem in graph spanners and one of the few for which super-logarithmic hardness was not known. Assuming NP ⊆ BPTIME (2 polylog(n) , we show (roughly) that for every k ⩾ 3 and every constant ϵ &gt; 0, it is hard to approximate the basic k -spanner problem within a factor better than 2 log 1-ϵ n)/k . This improves over the previous best lower bound of only Ω(log n )/ k from Kortsarz [2001]. Our main technique is subsampling the edges of 2-query probabilistically checkable proofs (PCPs), which allows us to reduce the degree of a PCP to be essentially equal to the soundness desired. This turns out to be enough to basically guarantee large girth.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1725039148",
    "type": "article"
  },
  {
    "title": "A Constant Factor Approximation Algorithm for Fault-Tolerant <i>k</i> -Median",
    "doi": "https://doi.org/10.1145/2854153",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "MohammadTaghi Hajiaghayi; Wei Hu; Jian Li; Shi Li; Barna Saha",
    "corresponding_authors": "",
    "abstract": "In this article, we consider the fault-tolerant k -median problem and give the first constant factor approximation algorithm for it. In the fault-tolerant generalization of the classical k -median problem, each client j needs to be assigned to at least r j ⩾ 1 distinct open facilities. The service cost of j is the sum of its distances to the r j facilities, and the k -median constraint restricts the number of open facilities to at most k . Previously, a constant factor was known only for the special case when all r j s are the same, and alogarithmic approximation ratio was known for the general case. In addition, we present the first polynomial time algorithm for the fault-tolerant k -median problem on a path or an HST by showing that the corresponding LP always has an integral optimal solution. We also consider the fault-tolerant facility location problem, in which the service cost of j can be a weighted sum of its distance to the r j facilities. We give a simple constant factor approximation algorithm, generalizing several previous results that work only for nonincreasing weight vectors.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1863013115",
    "type": "article"
  },
  {
    "title": "Sorting and Selection with Imprecise Comparisons",
    "doi": "https://doi.org/10.1145/2701427",
    "publication_date": "2015-11-17",
    "publication_year": 2015,
    "authors": "Miklós Ajtai; Vitaly Feldman; Avinatan Hassidim; Jelani Nelson",
    "corresponding_authors": "",
    "abstract": "We consider a simple model of imprecise comparisons: there exists some δ &gt; 0 such that when a subject is given two elements to compare, if the values of those elements (as perceived by the subject) differ by at least δ, then the comparison will be made correctly; when the two elements have values that are within δ, the outcome of the comparison is unpredictable. This model is inspired by both imprecision in human judgment of values and also by bounded but potentially adversarial errors in the outcomes of sporting tournaments. Our model is closely related to a number of models commonly considered in the psychophysics literature where δ corresponds to the Just Noticeable Difference (JND) unit or difference threshold . In experimental psychology, the method of paired comparisons was proposed as a means for ranking preferences among n elements of a human subject. The method requires performing all ( n 2 ) comparisons, then sorting elements according to the number of wins. The large number of comparisons is performed to counter the potentially faulty decision-making of the human subject, who acts as an imprecise comparator. We show that in our model the method of paired comparisons has optimal accuracy, minimizing the errors introduced by the imprecise comparisons. However, it is also wasteful because it requires all ( n 2 ). We show that the same optimal guarantees can be achieved using 4 n 3/2 comparisons, and we prove the optimality of our method. We then explore the general tradeoff between the guarantees on the error that can be made and number of comparisons for the problems of sorting, max-finding, and selection. Our results provide strong lower bounds and close-to-optimal solutions for each of these problems.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2111367393",
    "type": "article"
  },
  {
    "title": "Quasirandom Rumor Spreading",
    "doi": "https://doi.org/10.1145/2650185",
    "publication_date": "2014-10-30",
    "publication_year": 2014,
    "authors": "Benjamin Doerr; Tobias Friedrich; Thomas Sauerwald",
    "corresponding_authors": "",
    "abstract": "We propose and analyze a quasirandom analogue of the classical push model for disseminating information in networks (“randomized rumor spreading”). In the classical model, in each round, each informed vertex chooses a neighbor at random and informs it, if it was not informed before. It is known that this simple protocol succeeds in spreading a rumor from one vertex to all others within O (log n ) rounds on complete graphs, hypercubes, random regular graphs, Erdős-Rényi random graphs, and Ramanujan graphs with probability 1 − o (1). In the quasirandom model, we assume that each vertex has a (cyclic) list of its neighbors. Once informed, it starts at a random position on the list, but from then on informs its neighbors in the order of the list. Surprisingly, irrespective of the orders of the lists, the above-mentioned bounds still hold. In some cases, even better bounds than for the classical model can be shown.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2623400422",
    "type": "article"
  },
  {
    "title": "Distributed Dominating Set Approximations beyond Planar Graphs",
    "doi": "https://doi.org/10.1145/3326170",
    "publication_date": "2019-06-17",
    "publication_year": 2019,
    "authors": "Saeed Akhoondian Amiri; Stefan Schmid; Sebastian Siebertz",
    "corresponding_authors": "",
    "abstract": "The Minimum Dominating Set (MDS) problem is a fundamental and challenging problem in distributed computing. While it is well known that minimum dominating sets cannot be well approximated locally on general graphs, in recent years there has been much progress on computing good local approximations on sparse graphs and in particular on planar graphs. In this article, we study distributed and deterministic MDS approximation algorithms for graph classes beyond planar graphs. In particular, we show that existing approximation bounds for planar graphs can be lifted to bounded genus graphs and more general graphs, which we call locally embeddable graphs, and present (1) a local constant-time, constant-factor MDS approximation algorithm on locally embeddable graphs, and (2) a local O (log * n )-time (1+ϵ)-approximation scheme for any ϵ &gt; 0 on graphs of bounded genus. Our main technical contribution is a new analysis of a slightly modified variant of an existing algorithm by Lenzen et al. [21]. Interestingly, unlike existing proofs for planar graphs, our analysis does not rely on direct topological arguments but on combinatorial density arguments only.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2963948964",
    "type": "article"
  },
  {
    "title": "2-Edge Connectivity in Directed Graphs",
    "doi": "https://doi.org/10.1145/2968448",
    "publication_date": "2016-10-10",
    "publication_year": 2016,
    "authors": "Loukas Georgiadis; Giuseppe F. Italiano; Luigi Laura; Nikos Parotsidis",
    "corresponding_authors": "",
    "abstract": "Edge and vertex connectivity are fundamental concepts in graph theory. While they have been thoroughly studied in the case of undirected graphs, surprisingly, not much has been investigated for directed graphs. In this article, we study 2-edge connectivity problems in directed graphs and, in particular, we consider the computation of the following natural relation: We say that two vertices v and w are 2- edge-connected if there are two edge-disjoint paths from v to w and two edge-disjoint paths from w to v . This relation partitions the vertices into blocks such that all vertices in the same block are 2-edge-connected. Differently from the undirected case, those blocks do not correspond to the 2-edge-connected components of the graph. The main result of this article is an algorithm for computing the 2-edge-connected blocks of a directed graph in linear time. Besides being asymptotically optimal, our algorithm improves significantly over previous bounds. Once the 2-edge-connected blocks are available, we can test in constant time if two vertices are 2-edge-connected. Additionally, when two query vertices v and w are not 2-edge-connected, we can produce in constant time a “witness” of this property by exhibiting an edge that is contained in all paths from v to w or in all paths from w to v . We are also able to compute in linear time a sparse certificate for this relation, i.e., a subgraph of the input graph that has O ( n ) edges and maintains the same 2-edge-connected blocks as the input graph, where n is the number of vertices.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1880391707",
    "type": "article"
  },
  {
    "title": "Parameterized Hardness of Art Gallery Problems",
    "doi": "https://doi.org/10.1145/3398684",
    "publication_date": "2020-06-21",
    "publication_year": 2020,
    "authors": "Édouard Bonnet; Tillmann Miltzow",
    "corresponding_authors": "",
    "abstract": "Given a simple polygon P on n vertices, two points x , y in P are said to be visible to each other if the line segment between x and y is contained in P . The P oint G uard A rt G allery problem asks for a minimum set S such that every point in P is visible from a point in S . The V ertex G uard A rt G allery problem asks for such a set S subset of the vertices of P . A point in the set S is referred to as a guard. For both variants, we rule out any f ( k ) n o ( k / log k ) algorithm, where k := | S | is the number of guards, for any computable function f , unless the exponential time hypothesis fails. These lower bounds almost match the n O ( k ) algorithms that exist for both problems.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2546555264",
    "type": "article"
  },
  {
    "title": "Generalized Center Problems with Outliers",
    "doi": "https://doi.org/10.1145/3338513",
    "publication_date": "2019-07-08",
    "publication_year": 2019,
    "authors": "Deeparnab Chakrabarty; Maryam Negahbani",
    "corresponding_authors": "",
    "abstract": "We study the ℱ-center problem with outliers: Given a metric space ( X , d ), a general down-closed family ℱ of subsets of X , and a parameter m , we need to locate a subset S ∈ ℱ of centers such that the maximum distance among the closest m points in X to S is minimized. Our main result is a dichotomy theorem . Colloquially, we prove that there is an efficient 3-approximation for the ℱ-center problem with outliers if and only if we can efficiently optimize a poly-bounded linear function over ℱ subject to a partition constraint. One concrete upshot of our result is a polynomial time 3-approximation for the knapsack center problem with outliers for which no (true) approximation algorithm was known.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2959606821",
    "type": "article"
  },
  {
    "title": "Approximation Schemes for Low-rank Binary Matrix Approximation Problems",
    "doi": "https://doi.org/10.1145/3365653",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Fedor V. Fomin; Petr A. Golovach; Daniel Lokshtanov; Fahad Panolan; Saket Saurabh",
    "corresponding_authors": "",
    "abstract": "We provide a randomized linear time approximation scheme for a generic problem about clustering of binary vectors subject to additional constraints. The new constrained clustering problem generalizes a number of problems and by solving it, we obtain the first linear time-approximation schemes for a number of well-studied fundamental problems concerning clustering of binary vectors and low-rank approximation of binary matrices. Among the problems solvable by our approach are L ow GF(2)-R ank A pproximation , L ow B oolean -R ank A pproximation , and various versions of B inary C lustering . For example, for L ow GF(2)-R ank A pproximation problem, where for an m × n binary matrix A and integer r &gt; 0, we seek for a binary matrix B of GF(2) rank at most r such that the ℓ 0 -norm of matrix A−B is minimum, our algorithm, for any ϵ &gt; 0 in time f ( r ,ϵ)⋅ n ⋅ m , where f is some computable function, outputs a (1+ϵ)-approximate solution with probability at least (1−1\\ e ). This is the first linear time approximation scheme for these problems. We also give (deterministic) PTASes for these problems running in time n f ( r )1\\ϵ 2 log 1\\ϵ , where f is some function depending on the problem. Our algorithm for the constrained clustering problem is based on a novel sampling lemma, which is interesting on its own.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2986926078",
    "type": "article"
  },
  {
    "title": "Deterministic APSP, Orthogonal Vectors, and More",
    "doi": "https://doi.org/10.1145/3402926",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Timothy M. Chan; Ryan Williams",
    "corresponding_authors": "",
    "abstract": "We show how to solve all-pairs shortest paths on n nodes in deterministic n 3&gt; /2&gt; Ω ( √ log n ) time, and how to count the pairs of orthogonal vectors among n 0−1 vectors in d = c log n dimensions in deterministic n 2−1/ O (log c ) time. These running times essentially match the best known randomized algorithms of Williams [46] and Abboud, Williams, and Yu [8], respectively, and the ability to count was open even for randomized algorithms. By reductions, these two results yield faster deterministic algorithms for many other problems. Our techniques can also be used to deterministically count k -satisfiability ( k -SAT) assignments on n variable formulas in 2 n - n / O ( k ) time, roughly matching the best known running times for detecting satisfiability and resolving an open problem of Santhanam [24]. A key to our constructions is an efficient way to deterministically simulate certain probabilistic polynomials critical to the algorithms of prior work, carefully applying small-biased sets and modulus-amplifying polynomials.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W3115470548",
    "type": "article"
  },
  {
    "title": "<i>k</i> -apices of Minor-closed Graph Classes. II. Parameterized Algorithms",
    "doi": "https://doi.org/10.1145/3519028",
    "publication_date": "2022-03-07",
    "publication_year": 2022,
    "authors": "Ignasi Sau; Giannos Stamoulis; Dimitrios M. Thilikos",
    "corresponding_authors": "",
    "abstract": "Let 𝒢 be a minor-closed graph class. We say that a graph G is a k -apex of 𝒢 if G contains a set S of at most k vertices such that G\\S belongs to 𝒢 . We denote by 𝒜 k ( 𝒢 ) the set of all graphs that are k -apices of 𝒢 . In the first paper of this series, we obtained upper bounds on the size of the graphs in the minor-obstruction set of 𝒜 k ( 𝒢 ), i.e., the minor-minimal set of graphs not belonging to 𝒜 k ( 𝒢 ). In this article, we provide an algorithm that, given a graph G on n vertices, runs in time 2 poly (k) ⋅ n 3 and either returns a set S certifying that G ∈ 𝒜 k ( 𝒢 ), or reports that G ∉ 𝒜 k ( 𝒢 ). Here poly is a polynomial function whose degree depends on the maximum size of a minor-obstruction of 𝒢 . In the special case where 𝒢 excludes some apex graph as a minor, we give an alternative algorithm running in 2 poly (k) ⋅ n 2 -time.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3134554124",
    "type": "article"
  },
  {
    "title": "Scattering and Sparse Partitions, and their Applications",
    "doi": "https://doi.org/10.1145/3672562",
    "publication_date": "2024-06-12",
    "publication_year": 2024,
    "authors": "Arnold Filtser",
    "corresponding_authors": "Arnold Filtser",
    "abstract": "A partition \\(\\mathcal{P}\\) of a weighted graph \\(G\\) is \\((\\sigma,\\tau,\\Delta)\\) -sparse if every cluster has diameter at most \\(\\Delta\\) , and every ball of radius \\(\\Delta/\\sigma\\) intersects at most \\(\\tau\\) clusters. Similarly, \\(\\mathcal{P}\\) is \\((\\sigma,\\tau,\\Delta)\\) -scattering if instead for balls we require that every shortest path of length at most \\(\\Delta/\\sigma\\) intersects at most \\(\\tau\\) clusters. Given a graph \\(G\\) that admits a \\((\\sigma,\\tau,\\Delta)\\) -sparse partition for all \\(\\Delta \\gt 0\\) , Jia et al. [STOC05] constructed a solution for the Universal Steiner Tree problem (and also Universal TSP) with stretch \\(O(\\tau\\sigma^{2}\\log_{\\tau}n)\\) . Given a graph \\(G\\) that admits a \\((\\sigma,\\tau,\\Delta)\\) -scattering partition for all \\(\\Delta \\gt 0\\) , we construct a solution for the Steiner Point Removal problem with stretch \\(O(\\tau^{3}\\sigma^{3})\\) . We then construct sparse and scattering partitions for various different graph families, receiving many new results for the Universal Steiner Tree and Steiner Point Removal problems.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3000681379",
    "type": "article"
  },
  {
    "title": "Generic Non-recursive Suffix Array Construction",
    "doi": "https://doi.org/10.1145/3641854",
    "publication_date": "2024-02-08",
    "publication_year": 2024,
    "authors": "Jannik Olbrich; Enno Ohlebusch; Thomas Büchler",
    "corresponding_authors": "",
    "abstract": "The suffix array is arguably one of the most important data structures in sequence analysis and consequently there is a multitude of suffix sorting algorithms. However, to this date the GSACA algorithm introduced in 2015 is the only known non-recursive linear-time suffix array construction algorithm (SACA). Despite its interesting theoretical properties, there has been little effort in improving GSACA ’s non-competitive real-world performance. There is a super-linear algorithm DSH , which relies on the same sorting principle and is faster than DivSufSort , the fastest SACA for over a decade. The purpose of this article is twofold: We analyse the sorting principle used in GSACA and DSH and exploit its properties to give an optimised linear-time algorithm, and we show that it can be very elegantly used to compute both the original extended Burrows-Wheeler transform ( eBWT ) and a bijective version of the Burrows-Wheeler transform ( BBWT ) in linear time. We call the algorithm “generic,” since it can be used to compute the regular suffix array and the variants used for the BBWT and eBWT . Our suffix array construction algorithm is not only significantly faster than GSACA but also outperforms DivSufSort and DSH . Our BBWT -algorithm is faster than or competitive with all other tested BBWT construction implementations on large or repetitive data, and our eBWT -algorithm is faster than all other programs on data that is not extremely repetitive.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4391652638",
    "type": "article"
  },
  {
    "title": "Computing MEMs and Relatives on Repetitive Text Collections",
    "doi": "https://doi.org/10.1145/3701561",
    "publication_date": "2024-10-25",
    "publication_year": 2024,
    "authors": "Gonzalo Navarro",
    "corresponding_authors": "Gonzalo Navarro",
    "abstract": "We consider the problem of computing the Maximal Exact Matches (MEMs) of a given pattern \\(P[1\\mathinner{.. }m]\\) on a large repetitive text collection \\(T[1\\mathinner{.. }n]\\) over an alphabet of size \\(\\sigma\\) , which is represented as a (hopefully much smaller) run-length context-free grammar of size \\(g_{rl}\\) . We show that the problem can be solved in time \\(O(m^{2}\\log^{\\epsilon}n)\\) , for any constant \\(\\epsilon\\gt0\\) , on a data structure of size \\(O(g_{rl})\\) . Further, on a locally consistent grammar of size \\(O(\\delta\\log\\frac{n\\log\\sigma}{\\delta\\log n})\\) , the time decreases to \\(O(m\\log m(\\log m+\\log^{\\epsilon}n))\\) . The value \\(\\delta\\) is a function of the substring complexity of \\(T\\) and \\(\\Omega(\\delta\\log\\frac{n\\log\\sigma}{\\delta\\log n})\\) is a tight lower bound on the compressibility of repetitive texts \\(T\\) , so our structure has optimal size in terms of \\(n\\) , \\(\\sigma\\) , and \\(\\delta\\) . We extend our results to several related problems, such as finding \\(k\\) -MEMs, MUMs, rare MEMs, and applications. Categories and Subject Descriptors: E.1 [Data structures] ; E.2 [Data storage representations] ; E.4 [Coding and information theory]: Data compaction and compression; F.2.2 [Analysis of algorithms and problem complexity] : Nonnumerical algorithms and problems— Pattern matching, Computations on discrete structures, Sorting and searching",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4403761952",
    "type": "article"
  },
  {
    "title": "The greedy algorithm for the minimum common string partition problem",
    "doi": "https://doi.org/10.1145/1103963.1103971",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Marek Chrobák; Petr Kolman; Jiřį́ Sgall",
    "corresponding_authors": "",
    "abstract": "In the Minimum Common String Partition problem (MCSP), we are given two strings on input, and we wish to partition them into the same collection of substrings, minimizing the number of the substrings in the partition. This problem is NP-hard, even for a special case, denoted 2-MCSP, where each letter occurs at most twice in each input string. We study a greedy algorithm for MCSP that at each step extracts a longest common substring from the given strings. We show that the approximation ratio of this algorithm is between Ω( n 0.43 ) and O ( n 0.69 ). In the case of 2-MCSP, we show that the approximation ratio is equal to 3. For 4-MCSP, we give a lower bound of Ω(log n ).",
    "cited_by_count": 37,
    "openalex_id": "https://openalex.org/W1977957904",
    "type": "article"
  },
  {
    "title": "Oracles for bounded-length shortest paths in planar graphs",
    "doi": "https://doi.org/10.1145/1159892.1159895",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Łukasz Kowalik; Maciej Kurowski",
    "corresponding_authors": "",
    "abstract": "We present a new approach for answering short path queries in planar graphs. For any fixed constant k and a given unweighted planar graph G = ( V , E ), one can build in O(|V|) time a data structure, which allows to check in O(1) time whether two given vertices are at distance at most k in G and if so a shortest path between them is returned. Graph G can be undirected as well as directed.Our data structure works in fully dynamic environment. It can be updated in O(1) time after removing an edge or a vertex while updating after an edge insertion takes polylogarithmic amortized time. Besides deleting elements one can also disable ones for some time. It is motivated by a practical situation where nodes or links of a network may be temporarily out of service.Our results can be easily generalized to other wide classes of graphs---for instance we can take any minor-closed family of graphs.",
    "cited_by_count": 31,
    "openalex_id": "https://openalex.org/W2068243119",
    "type": "article"
  },
  {
    "title": "Fully dynamic algorithms for chordal graphs and split graphs",
    "doi": "https://doi.org/10.1145/1383369.1383371",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Louis Ibarra",
    "corresponding_authors": "Louis Ibarra",
    "abstract": "We present the first dynamic algorithm that maintains a clique tree representation of a chordal graph and supports the following operations: (1) query whether deleting or inserting an arbitrary edge preserves chordality; and (2) delete or insert an arbitrary edge, provided it preserves chordality. We give two implementations. In the first, each operation runs in O ( n ) time, where n is the number of vertices. In the second, an insertion query runs in O (log 2 n ) time, an insertion in O ( n ) time, a deletion query in O ( n ) time, and a deletion in O ( n log n ) time. We also present a data structure that allows a deletion query to run in O (√m) time in either implementation, where m is the current number of edges. Updating this data structure after a deletion or insertion requires O ( m ) time. We also present a very simple dynamic algorithm that supports each of the following operations in O (1) time on a general graph: (1) query whether the graph is split, and (2) delete or insert an arbitrary edge.",
    "cited_by_count": 30,
    "openalex_id": "https://openalex.org/W2055371600",
    "type": "article"
  },
  {
    "title": "Deterministic conflict-free coloring for intervals",
    "doi": "https://doi.org/10.1145/1383369.1383375",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Amotz Bar-Noy; Panagiotis Cheilaris; Shakhar Smorodinsky",
    "corresponding_authors": "",
    "abstract": "We investigate deterministic algorithms for a frequency assignment problem in cellular networks. The problem can be modeled as a special vertex coloring problem for hypergraphs: In every hyperedge there must exist a vertex with a color that occurs exactly once in the hyperedge (the conflict-free property). We concentrate on a special case of the problem, called conflict-free coloring for intervals. We introduce a hierarchy of four models for the aforesaid problem: (i) static, (ii) dynamic offline, (iii) dynamic online with absolute positions, and (iv) dynamic online with relative positions. In the dynamic offline model, we give a deterministic algorithm that uses at most log 3/2 n + 1 ≈ 1.71 log 2 n colors and show inputs that force any algorithm to use at least 3 log 5 n + 1 ≈ 1.29 log 2 n colors. For the online absolute-positions model, we give a deterministic algorithm that uses at most 3⌈log 3 n ⌉ ≈ 1.89 log 2 n colors. To the best of our knowledge, this is the first deterministic online algorithm using O (log n ) colors in a nontrivial online model. In the online relative-positions model, we resolve an open problem by showing a tight analysis on the number of colors used by the first-fit greedy online algorithm. We also consider conflict-free coloring only with respect to intervals that contain at least one of the two extreme points.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2004070233",
    "type": "article"
  },
  {
    "title": "Dissections, orientations, and trees with applications to optimal mesh encoding and random sampling",
    "doi": "https://doi.org/10.1145/1361192.1361196",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Éric Fusy; Gilles Schaeffer; Dominique Poulalhon",
    "corresponding_authors": "",
    "abstract": "We present a bijection between some quadrangular dissections of an hexagon and unrooted binary trees with interesting consequences for enumeration, mesh compression, and graph sampling. Our bijection yields an efficient uniform random sampler for 3-connected planar graphs, which turns out to be determinant for the quadratic complexity of the current best-known uniform random sampler for labelled planar graphs. It also provides an encoding for the set P ( n ) of n -edge 3-connected planar graphs that matches the entropy bound 1/ n log 2 | P ( n )| = 2 + o (1) bits per edge (bpe). This solves a theoretical problem recently raised in mesh compression as these graphs abstract the combinatorial part of meshes with spherical topology. We also achieve the optimal parametric rate 1/ n log 2 | P ( n , i , j )| bpe for graphs of P ( n ) with i vertices and j faces, matching in particular the optimal rate for triangulations. Our encoding relies on a linear time algorithm to compute an orientation associated with the minimal Schnyder wood of a 3-connected planar map. This algorithm is of independent interest, and it is, for instance, a key ingredient in a recent straight line drawing algorithm for 3-connected planar graphs.",
    "cited_by_count": 29,
    "openalex_id": "https://openalex.org/W2034983981",
    "type": "article"
  },
  {
    "title": "Approximating the minimum quadratic assignment problems",
    "doi": "https://doi.org/10.1145/1644015.1644033",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Refael Hassin; Asaf Levin; Maxim Sviridenko",
    "corresponding_authors": "",
    "abstract": "We consider the well-known minimum quadratic assignment problem. In this problem we are given two n × n nonnegative symmetric matrices A = ( a ij ) and B = ( b ij ). The objective is to compute a permutation π of V = {1,…, n } so that ∑ i , j ∈ V i ≠ j a π( i ),π( j ) b i , j is minimized. We assume that A is a 0/1 incidence matrix of a graph, and that B satisfies the triangle inequality. We analyze the approximability of this class of problems by providing polynomial bounded approximations for some special cases, and inapproximability results for other cases.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W1982810715",
    "type": "article"
  },
  {
    "title": "Strongly stable matchings in time <i>O</i> ( <i>nm</i> ) and extension to the hospitals-residents problem",
    "doi": "https://doi.org/10.1145/1240233.1240238",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Telikepalli Kavitha; Kurt Mehlhorn; Dimitrios Michail; Katarzyna Paluch",
    "corresponding_authors": "",
    "abstract": "An instance of the stable marriage problem is an undirected bipartite graph G = ( X ∪ W , E ) with linearly ordered adjacency lists with ties allowed in the ordering. A matching M is a set of edges, no two of which share an endpoint. An edge e = ( a , b ) ∈ E ∖ M is a blocking edge for M if a is either unmatched or strictly prefers b to its partner in M , and b is unmatched, strictly prefers a to its partner in M , or is indifferent between them. A matching is strongly stable if there is no blocking edge with respect to it. We give an O ( nm ) algorithm for computing strongly stable matchings, where n is the number of vertices and m the number of edges. The previous best algorithm had running time O ( m 2 ). We also study this problem in the hospitals-residents setting, which is a many-to-one extension of the aforementioned problem. We give an O ( m ∑ h∈H p h ) algorithm for computing a strongly stable matching in the hospitals-residents problem, where p h is the quota of a hospital h . The previous best algorithm had running time O ( m 2 ).",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2085383556",
    "type": "article"
  },
  {
    "title": "Retroactive data structures",
    "doi": "https://doi.org/10.1145/1240233.1240236",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Erik D. Demaine; John Iacono; Stefan Langerman",
    "corresponding_authors": "",
    "abstract": "We introduce a new data structuring paradigm in which operations can be performed on a data structure not only in the present, but also in the past. In this new paradigm, called retroactive data structures , the historical sequence of operations performed on the data structure is not fixed. The data structure allows arbitrary insertion and deletion of operations at arbitrary times, subject only to consistency requirements. We initiate the study of retroactive data structures by formally defining the model and its variants. We prove that, unlike persistence, efficient retroactivity is not always achievable. Thus, we present efficient retroactive data structures for queues, doubly ended queues, priority queues, union-find, and decomposable search structures.",
    "cited_by_count": 28,
    "openalex_id": "https://openalex.org/W2121573131",
    "type": "article"
  },
  {
    "title": "Thin heaps, thick heaps",
    "doi": "https://doi.org/10.1145/1328911.1328914",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Haim Kaplan; Robert E. Tarjan",
    "corresponding_authors": "",
    "abstract": "The Fibonacci heap was devised to provide an especially efficient implementation of Dijkstra's shortest path algorithm. Although asyptotically efficient, it is not as fast in practice as other heap implementations. Expanding on ideas of Høyer [1995], we describe three heap implementations (two versions of thin heaps and one of thick heaps ) that have the same amortized efficiency as Fibonacci heaps, but need less space and promise better practical performance. As part of our development, we fill in a gap in Høyer's analysis.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W1978960961",
    "type": "article"
  },
  {
    "title": "Improved approximate string matching and regular expression matching on Ziv-Lempel compressed texts",
    "doi": "https://doi.org/10.1145/1644015.1644018",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Philip Bille; Rolf Fagerberg; Inge Li Gørtz",
    "corresponding_authors": "",
    "abstract": "We study the approximate string matching and regular expression matching problem for the case when the text to be searched is compressed with the Ziv-Lempel adaptive dictionary compression schemes. We present a time-space trade-off that leads to algorithms improving the previously known complexities for both problems. In particular, we significantly improve the space bounds, which in practical applications are likely to be a bottleneck.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2119512879",
    "type": "article"
  },
  {
    "title": "Cake cutting really is not a piece of cake",
    "doi": "https://doi.org/10.1145/2000807.2000819",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Jeff Edmonds; Kirk Pruhs",
    "corresponding_authors": "",
    "abstract": "We consider the well-known cake cutting problem in which a protocol wants to divide a cake among n ≥ 2 players in such a way that each player believes that they got a fair share. The standard Robertson-Webb model allows the protocol to make two types of queries, Evaluation and Cut, to the players. A deterministic divide-and-conquer protocol with complexity O ( n log n ) is known. We provide the first a Ω( n log n ) lower bound on the complexity of any deterministic protocol in the standard model. This improves previous lower bounds, in that the protocol is allowed to assign to a player a piece that is a union of intervals and only guarantee approximate fairness. We accomplish this by lower bounding the complexity to find, for a single player, a piece of cake that is both rich in value, and thin in width. We then introduce a version of cake cutting in which the players are able to cut with only finite precision. In this case, we can extend the Ω( n log n ) lower bound to include randomized protocols.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2066369985",
    "type": "article"
  },
  {
    "title": "Approximation algorithms for the sex-equal stable marriage problem",
    "doi": "https://doi.org/10.1145/1868237.1868239",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Kazuo Iwama; Shuichi Miyazaki; Hiroki Yanagisawa",
    "corresponding_authors": "",
    "abstract": "The stable marriage problem is a classical matching problem introduced by Gale and Shapley. It is known that for any instance, there exists a solution, and there is a polynomial time algorithm to find one. However, the matching obtained by this algorithm is man-optimal, that is, the matching is favorable for men but unfavorable for women, (or, if we exchange the roles of men and women, the resulting matching is woman-optimal). The sex-equal stable marriage problem, posed by Gusfield and Irving, seeks a stable matching “fair” for both genders. Specifically it seeks a stable matching with the property that the sum of the men's scores is as close as possible to that of the women's. This problem is known to be strongly NP-hard. In this paper, we give a polynomial time algorithm for finding a near optimal solution for the sex-equal stable marriage problem. Furthermore, we consider the problem of optimizing an additional criterion: among stable matchings that are near optimal in terms of the sex-equality, find a minimum egalitarian stable matching. We show that this problem is strongly NP-hard, and give a polynomial time algorithm whose approximation ratio is less than two.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2154426512",
    "type": "article"
  },
  {
    "title": "The speed of convergence in congestion games under best-response dynamics",
    "doi": "https://doi.org/10.1145/2229163.2229169",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Angelo Fanelli; Michele Flammini; Luca Moscardelli",
    "corresponding_authors": "",
    "abstract": "We investigate the speed of convergence of best response dynamics to approximately optimal solutions in congestion games with linear delay functions. In Ackermann et al. [2008] it has been shown that the convergence time of such dynamics to Nash equilibrium may be exponential in the number of players n . Motivated by such a negative result, we focus on the study of the states (not necessarily being equilibria) reached after a limited number of players' selfish moves, and we show that Θ( n log log n ) best responses are necessary and sufficient to achieve states that approximate the optimal solution by a constant factor, under the assumption that every O ( n ) steps each player performs a constant (and nonnull) number of best responses. We show that such result is tight also for the simplest case of singleton congestion games.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W1980068415",
    "type": "article"
  },
  {
    "title": "On the hardness of losing weight",
    "doi": "https://doi.org/10.1145/2151171.2151182",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Andrei Krokhin; Dániel Marx",
    "corresponding_authors": "",
    "abstract": "We study the complexity of local search for the Boolean constraint satisfaction problem (CSP), in the following form: given a CSP instance, that is, a collection of constraints, and a solution to it, the question is whether there is a better (lighter, i.e., having strictly less Hamming weight) solution within a given distance from the initial solution. We classify the complexity, both classical and parameterized, of such problems by a Schaefer-style dichotomy result, that is, with a restricted set of allowed types of constraints. Our results show that there is a considerable amount of such problems that are NP-hard, but fixed-parameter tractable when parameterized by the distance.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2008809414",
    "type": "article"
  },
  {
    "title": "Routing (un-) splittable flow in games with player-specific affine latency functions",
    "doi": "https://doi.org/10.1145/1978782.1978786",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Martin Gairing; Burkhard Monien; Karsten Tiemann",
    "corresponding_authors": "",
    "abstract": "In this work we study weighted network congestion games with player-specific latency functions where selfish players wish to route their traffic through a shared network. We consider both the case of splittable and unsplittable traffic. Our main findings are as follows. For routing games on parallel links with linear latency functions, we introduce two new potential functions for unsplittable and for splittable traffic, respectively. We use these functions to derive results on the convergence to pure Nash equilibria and the computation of equilibria. For several generalizations of these routing games, we show that such potential functions do not exist. We prove tight upper and lower bounds on the price of anarchy for games with polynomial latency functions. All our results on the price of anarchy translate to general congestion games.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2090957813",
    "type": "article"
  },
  {
    "title": "Speed Scaling with an Arbitrary Power Function",
    "doi": "https://doi.org/10.1145/2438645.2438650",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Nikhil Bansal; Ho-Leung Chan; Kirk Pruhs",
    "corresponding_authors": "",
    "abstract": "This article initiates a theoretical investigation into online scheduling problems with speed scaling where the allowable speeds may be discrete, and the power function may be arbitrary, and develops algorithmic analysis techniques for this setting. We show that a natural algorithm, which uses Shortest Remaining Processing Time for scheduling and sets the power to be one more than the number of unfinished jobs, is 3-competitive for the objective of total flow time plus energy. We also show that another natural algorithm, which uses Highest Density First for scheduling and sets the power to be the fractional weight of the unfinished jobs, is a 2-competitive algorithm for the objective of fractional weighted flow time plus energy.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2097190088",
    "type": "article"
  },
  {
    "title": "Max-coloring and online coloring with bandwidths on interval graphs",
    "doi": "https://doi.org/10.1145/1978782.1978790",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Sriram V. Pemmaraju; Rajiv Raman; Kasturi Varadarajan",
    "corresponding_authors": "",
    "abstract": "Given a graph G = ( V, E ) and positive integral vertex weights w : V → N , the max-coloring problem seeks to find a proper vertex coloring of G whose color classes C 1 , C 2 , …, C k , minimize ∑ i =1 k max v ∈ C i w ( v ). This problem, restricted to interval graphs, arises whenever there is a need to design dedicated memory managers that provide better performance than the general-purpose memory management of the operating system. Though this problem seems similar to the dynamic storage allocation problem, there are fundamental differences. We make a connection between max-coloring and online graph coloring and use this to devise a simple 2-approximation algorithm for max-coloring on interval graphs. We also show that a simple first-fit strategy, that is a natural choice for this problem, yields an 8-approximation algorithm. We show this result by proving that the first-fit algorithm for online coloring an interval graph G uses no more than 8 ċ χ( G ) colors, significantly improving the bound of 26 ċ χ( G ) by Kierstead and Qin [1995]. We also show that the max-coloring problem is NP-hard. The problem of online coloring of intervals with bandwidths is a simultaneous generalization of online interval coloring and online bin packing. The input is a set I of intervals, each interval i ∈ I having an associated bandwidth b ( i ) ∈ (0, 1]. We seek an online algorithm that produces a coloring of the intervals such that for any color c and any real r , the sum of the bandwidths of intervals containing r and colored c is at most 1. Motivated by resource allocation problems, Adamy and Erlebach [2003] consider this problem and present an algorithm that uses at most 195 times the number of colors used by an optimal offline algorithm. Using the new analysis of first-fit coloring of interval graphs, we show that the Adamy-Erlebach algorithm is 35-competitive. Finally, we generalize the Adamy-Erlebach algorithm to a class of algorithms and show that a different instance from this class is 30-competitive.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1972620016",
    "type": "article"
  },
  {
    "title": "Competitive analysis of flash memory algorithms",
    "doi": "https://doi.org/10.1145/1921659.1921669",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Avraham Ben-Aroya; Sivan Toledo",
    "corresponding_authors": "",
    "abstract": "Flash memories are widely used in computer systems ranging from embedded systems to workstations and servers to digital cameras and mobile phones. The memory cells of flash devices can only endure a limited number of write cycles, usually between 10,000 and 1,000,000. Furthermore, cells containing data must be erased before they can store new data, and erasure operations erase large blocks of memory, not individual cells. To maximize the endurance of the device (the amount of useful data that can be written to it before one of its cells wears out), flash-based systems move data around in an attempt to reduce the total number of erasures and to level the wear of the different erase blocks. This data movement introduces an interesting online problem called the wear-leveling problem . Wear-leveling algorithms have been used at least since 1993, but they have never been mathematically analyzed. In this article we analyze the two main wear-leveling problems. We show that a simple randomized algorithm for one of them is essentially optimal both in the competitive sense and in the absolute sense (our competitive result relies on an analysis of a nearly-optimal offline algorithm). We show that deterministic algorithms cannot achieve comparable endurance. We also analyze a more difficult problem and show that offline algorithms for it can improve upon naive approaches, but that online algorithms essentially cannot.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2020088537",
    "type": "article"
  },
  {
    "title": "Assignment problem in content distribution networks",
    "doi": "https://doi.org/10.1145/2229163.2229164",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "MohammadHossein Bateni; MohammadTaghi Hajiaghayi",
    "corresponding_authors": "",
    "abstract": "In a Content Distribution Network (CDN) , there are m servers storing the data; each of them has a specific bandwidth. All the requests from a particular client should be assigned to one server because of the routing protocol used. The goal is to minimize the total cost of these assignments—cost of each is proportional to the distance between the client and the server as well as the request size—while the load on each server is kept below its bandwidth limit. When each server also has a setup cost, this is an unsplittable hard-capacitated facility location problem . As much attention as facility location problems have received, there has been no nontrivial approximation algorithm when we have hard capacities (i.e., there can only be one copy of each facility whose capacity cannot be violated) and demands are unsplittable (i.e., all the demand from a client has to be assigned to a single facility). We observe it is NP-hard to approximate the cost to within any bounded factor in this case. Thus, for an arbitrary constant ϵ&gt;0, we relax the capacities to a 1+ϵ factor. For the case where capacities are almost uniform , we give a bicriteria O (log n , 1+ϵ)-approximation algorithm for general metrics and a (1+ϵ, 1+ϵ)-approximation algorithm for tree metrics. A bicriteria (α,β)-approximation algorithm produces a solution of cost at most α times the optimum, while violating the capacities by no more than a β factor. We can get the same guarantees for nonuniform capacities if we allow quasipolynomial running time. In our algorithm, some clients guess the facility they are assigned to, and facilities decide the size of the clients they serve. A straightforward approach results in exponential running time. When costs do not satisfy metricity, we show that a 1.5 violation of capacities is necessary to obtain any approximation. It is worth noting that our results generalize bin packing (zero connection costs and facility costs equal to one), knapsack (single facility with all costs being zero), minimum makespan scheduling for related machines (all connection costs being zero), and some facility location problems.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2129486506",
    "type": "article"
  },
  {
    "title": "Rank-Balanced Trees",
    "doi": "https://doi.org/10.1145/2689412",
    "publication_date": "2015-06-02",
    "publication_year": 2015,
    "authors": "Bernhard Haeupler; Siddhartha Sen; Robert E. Tarjan",
    "corresponding_authors": "",
    "abstract": "Since the invention of AVL trees in 1962, many kinds of binary search trees have been proposed. Notable are red-black trees, in which bottom-up rebalancing after an insertion or deletion takes O(1) amortized time and O(1) rotations worst-case. But the design space of balanced trees has not been fully explored. We continue the exploration. Our contributions are three: We systematically study the use of ranks and rank differences to define height-based balance in binary trees. Different invariants on rank differences yield AVL trees, red-black trees, and other kinds of balanced trees. By relaxing AVL trees, we obtain a new kind of balanced binary tree, the weak AVL tree (wavl tree) , whose properties we develop. Bottom-up rebalancing after an insertion or deletion takes O(1) amortized time and at most two rotations, improving the three or more rotations per deletion needed in all other kinds of balanced trees of which we are aware. The height bound of a wavl tree degrades gracefully from that of an AVL tree as the number of deletions increases and is never worse than that of a red-black tree. Wavl trees also support top-down, fixed look-ahead rebalancing in O(1) amortized time. Finally, we use exponential potential functions to prove that in wavl trees rebalancing steps occur exponentially infrequently in rank. Thus, most of the rebalancing is at the bottom of the tree, which is crucial in concurrent applications and in those in which rotations take time that depends on the subtree size.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1958605991",
    "type": "article"
  },
  {
    "title": "Decision trees for entity identification",
    "doi": "https://doi.org/10.1145/1921659.1921661",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Venkatesan T. Chakaravarthy; Vinayaka Pandit; Sambuddha Roy; Pranjal Awasthi; Mukesh Mohania",
    "corresponding_authors": "",
    "abstract": "We consider the problem of constructing decision trees for entity identification from a given relational table. The input is a table containing information about a set of entities over a fixed set of attributes and a probability distribution over the set of entities that specifies the likelihood of the occurrence of each entity. The goal is to construct a decision tree that identifies each entity unambiguously by testing the attribute values such that the average number of tests is minimized. This classical problem finds such diverse applications as efficient fault detection, species identification in biology, and efficient diagnosis in the field of medicine. Prior work mainly deals with the special case where the input table is binary and the probability distribution over the set of entities is uniform. We study the general problem involving arbitrary input tables and arbitrary probability distributions over the set of entities. We consider a natural greedy algorithm and prove an approximation guarantee of O ( r K ⋅ log N ), where N is the number of entities and K is the maximum number of distinct values of an attribute. The value r K is a suitably defined Ramsey number, which is at most log K . We show that it is NP-hard to approximate the problem within a factor of Ω(log N ), even for binary tables (i.e., K =2). Thus, for the case of binary tables, our approximation algorithm is optimal up to constant factors (since r 2 =2). In addition, our analysis indicates a possible way of resolving a Ramsey-theoretic conjecture by Erdös.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W1983231745",
    "type": "article"
  },
  {
    "title": "Average Case and Distributional Analysis of Dual-Pivot Quicksort",
    "doi": "https://doi.org/10.1145/2629340",
    "publication_date": "2015-01-13",
    "publication_year": 2015,
    "authors": "Sebastian Wild; Markus E. Nebel; Ralph Neininger",
    "corresponding_authors": "",
    "abstract": "In 2009, Oracle replaced the long-serving sorting algorithm in its Java 7 runtime library by a new dual-pivot Quicksort variant due to Vladimir Yaroslavskiy. The decision was based on the strikingly good performance of Yaroslavskiy's implementation in running time experiments. At that time, no precise investigations of the algorithm were available to explain its superior performance—on the contrary: previous theoretical studies of other dual-pivot Quicksort variants even discouraged the use of two pivots. In 2012, two of the authors gave an average case analysis of a simplified version of Yaroslavskiy's algorithm, proving that savings in the number of comparisons are possible. However, Yaroslavskiy's algorithm needs more swaps, which renders the analysis inconclusive. To force the issue, we herein extend our analysis to the fully detailed style of Knuth: we determine the exact number of executed Java Bytecode instructions. Surprisingly, Yaroslavskiy's algorithm needs sightly more Bytecode instructions than a simple implementation of classic Quicksort—contradicting observed running times. As in Oracle's library implementation, we incorporate the use of Insertionsort on small subproblems and show that it indeed speeds up Yaroslavskiy's Quicksort in terms of Bytecodes; but even with optimal Insertionsort thresholds, the new Quicksort variant needs slightly more Bytecode instructions on average. Finally, we show that the (suitably normalized) costs of Yaroslavskiy's algorithm converge to a random variable whose distribution is characterized by a fixed-point equation. From that, we compute variances of costs and show that for large n , costs are concentrated around their mean.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2125378108",
    "type": "article"
  },
  {
    "title": "Computing Shortest Paths among Curved Obstacles in the Plane",
    "doi": "https://doi.org/10.1145/2660771",
    "publication_date": "2015-04-13",
    "publication_year": 2015,
    "authors": "Danny Z. Chen; Haitao Wang",
    "corresponding_authors": "",
    "abstract": "A fundamental problem in computational geometry is to compute an obstacle-avoiding Euclidean shortest path between two points in the plane. The case of this problem on polygonal obstacles is well studied. In this article, we consider the problem version on curved obstacles, which are commonly modeled as splinegons . A splinegon can be viewed as replacing each edge of a polygon by a convex curved edge (polygons are special splinegons), and the combinatorial complexity of each curved edge is assumed to be O (1). Given in the plane two points s and t and a set s of h pairwise disjoint splinegons with a total of n vertices, after a bounded degree decomposition of S is obtained, we compute a shortest s -to- t path avoiding the splinegons in O ( n + h log h + k ) time, where k is a parameter sensitive to the geometric structures of the input and is upper bounded by O ( h 2 ). The bounded degree decomposition of S , which is similar to the triangulation of the polygonal domains, can be computed in O ( n log n ) time or O ( n + h log 1 + ϵ h ) time for any ϵ &gt; 0. In particular, when all splinegons are convex, the decomposition can be computed in O ( n + h log h ) time and k is linear to the number of common tangents in the free space (called “free common tangents”) among the splinegons. Our techniques also improve several previous results: (1) For the polygon case (i.e., when all splinegons are polygons), the shortest path problem was previously solved in O ( n log n ) time, or in O ( n + h 2 log n ) time. Thus, our algorithm improves the O ( n + h 2 log n ) time result, and is faster than the O ( n log n ) time solution for sufficiently small h , for example, h = o (√ n ,log n . (2) Our techniques produce an optimal output-sensitive algorithm for a basic visibility problem of computing all free common tangents among h pairwise disjoint convex splinegons with a total of n vertices. Our algorithm runs in O ( n + h log h + k ) time and O ( n ) working space, where k is the number of all free common tangents. Note that k = O ( h 2 ). Even for the special case where all splinegons are convex polygons , the previously best algorithm for this visibility problem takes O ( n + h 2 log n ) time. (3) We improve the previous work for computing the shortest path between two points among convex pseudodisks of O (1) complexity each. In addition, a by-product of our techniques is an optimal O ( n + h log h ) time and O ( n ) space algorithm for computing the Voronoi diagram of a set of h pairwise disjoint convex splinegons with a total of n vertices.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2565603695",
    "type": "article"
  },
  {
    "title": "Generating Random Permutations by Coin Tossing",
    "doi": "https://doi.org/10.1145/3009909",
    "publication_date": "2017-02-07",
    "publication_year": 2017,
    "authors": "Axel Bacher; Olivier Bodini; Hsien‐Kuei Hwang; Tsung‐Hsi Tsai",
    "corresponding_authors": "",
    "abstract": "Several simple, classical, little-known algorithms in the statistics and computer science literature for generating random permutations by coin tossing are examined, analyzed, and implemented. These algorithms are either asymptotically optimal or close to being so in terms of the expected number of times the random bits are generated. In addition to asymptotic approximations to the expected complexity, we also clarify the corresponding variances, as well as the asymptotic distributions. A brief comparative discussion with numerical computations in a multicore system is also given.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2587429114",
    "type": "article"
  },
  {
    "title": "Exact Algorithms for Terrain Guarding",
    "doi": "https://doi.org/10.1145/3186897",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Pradeesha Ashok; Fedor V. Fomin; Sudeshna Kolay; Saket Saurabh; Meirav Zehavi",
    "corresponding_authors": "",
    "abstract": "Given a 1.5-dimensional terrain T , also known as an x -monotone polygonal chain, the T errain G uarding problem seeks a set of points of minimum size on T that guards all of the points on T . Here, we say that a point p guards a point q if no point of the line segment pq is strictly below T . The T errain G uarding problem has been extensively studied for over 20 years. In 2005 it was already established that this problem admits a constant-factor approximation algorithm (SODA 2005). However, only in 2010 King and Krohn (SODA 2010) finally showed that T errain G uarding is NP-hard. In spite of the remarkable developments in approximation algorithms for T errain G uarding , next to nothing is known about its parameterized complexity. In particular, the most intriguing open questions in this direction ask whether, if parameterized by the size k of a solution guard set, it admits a subexponential-time algorithm and whether it is fixed-parameter tractable. In this article, we answer the first question affirmatively by developing an n O (√ k ) -time algorithm for both D iscrete T errain G uarding and C ontinuous T errain G uarding . We also make non-trivial progress with respect to the second question: we show that D iscrete O rthogonal T errain G uarding , a well-studied special case of T errain G uarding , is fixed-parameter tractable.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2799900533",
    "type": "article"
  },
  {
    "title": "Fixed-Parameter Algorithms for Minimum-Cost Edge-Connectivity Augmentation",
    "doi": "https://doi.org/10.1145/2700210",
    "publication_date": "2015-04-13",
    "publication_year": 2015,
    "authors": "Dániel Marx; László A. Végh",
    "corresponding_authors": "",
    "abstract": "We consider connectivity-augmentation problems in a setting where each potential new edge has a non-negative cost associated with it, and the task is to achieve a certain connectivity target with at most p new edges of minimum total cost. The main result is that the minimum cost augmentation of edge-connectivity from k − 1 to k with at most p new edges is fixed-parameter tractable parameterized by p and admits a polynomial kernel. We also prove the fixed-parameter tractability of increasing edge connectivity from 0 to 2 and increasing node connectivity from 1 to 2.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W69311884",
    "type": "article"
  },
  {
    "title": "Annotations in Data Streams",
    "doi": "https://doi.org/10.1145/2636924",
    "publication_date": "2014-08-25",
    "publication_year": 2014,
    "authors": "Amit Chakrabarti; Graham Cormode; Andrew McGregor; Justin Thaler",
    "corresponding_authors": "",
    "abstract": "The central goal of data stream algorithms is to process massive streams of data using sublinear storage space. Motivated by work in the database community on outsourcing database and data stream processing, we ask whether the space usage of such algorithms can be further reduced by enlisting a more powerful “helper” that can annotate the stream as it is read. We do not wish to blindly trust the helper, so we require that the algorithm be convinced of having computed a correct answer. We show upper bounds that achieve a nontrivial tradeoff between the amount of annotation used and the space required to verify it. We also prove lower bounds on such tradeoffs, often nearly matching the upper bounds, via notions related to Merlin-Arthur communication complexity. Our results cover the classic data stream problems of selection, frequency moments, and fundamental graph problems such as triangle-freeness and connectivity. Our work is also part of a growing trend—including recent studies of multipass streaming, read/write streams, and randomly ordered streams—of asking more complexity-theoretic questions about data stream processing. It is a recognition that, in addition to practical relevance, the data stream model raises many interesting theoretical questions in its own right.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2128633442",
    "type": "article"
  },
  {
    "title": "Segmentation of Trajectories on Nonmonotone Criteria",
    "doi": "https://doi.org/10.1145/2660772",
    "publication_date": "2015-12-08",
    "publication_year": 2015,
    "authors": "Boris Aronov; Anne Driemel; Marc van Kreveld; Maarten Löffler; Frank Staals",
    "corresponding_authors": "",
    "abstract": "In the trajectory segmentation problem, we are given a polygonal trajectory with n vertices that we have to subdivide into a minimum number of disjoint segments (subtrajectories) that all satisfy a given criterion. The problem is known to be solvable efficiently for monotone criteria: criteria with the property that if they hold on a certain segment, they also hold on every subsegment of that segment. To the best of our knowledge, no theoretical results are known for nonmonotone criteria. We present a broader study of the segmentation problem, and suggest a general framework for solving it, based on the start-stop diagram: a 2-dimensional diagram that represents all valid and invalid segments of a given trajectory. This yields two subproblems: (1) computing the start-stop diagram, and (2) finding the optimal segmentation for a given diagram. We show that (2) is NP-hard in general. However, we identify properties of the start-stop diagram that make the problem tractable and give a polynomial-time algorithm for this case. We study two concrete nonmonotone criteria that arise in practical applications in more detail. Both are based on a given univariate attribute function f over the domain of the trajectory. We say a segment satisfies an outlier-tolerant criterion if the value of f lies within a certain range for at least a given percentage of the length of the segment. We say a segment satisfies a standard deviation criterion if the standard deviation of f over the length of the segment lies below a given threshold. We show that both criteria satisfy the properties that make the segmentation problem tractable. In particular, we compute an optimal segmentation of a trajectory based on the outlier-tolerant criterion in O(n2 log n + kn2) time and on the standard deviation criterion in O(kn2) time, where n is the number of vertices of the input trajectory and k is the number of segments in an optimal solution.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2270219430",
    "type": "article"
  },
  {
    "title": "Sparse Text Indexing in Small Space",
    "doi": "https://doi.org/10.1145/2836166",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Philip Bille; Johannes Fischer; Inge Li Gørtz; Tsvi Kopelowitz; Benjamin Sach; Hjalte Wedel Vildhøj",
    "corresponding_authors": "",
    "abstract": "In this work, we present efficient algorithms for constructing sparse suffix trees, sparse suffix arrays, and sparse position heaps for b arbitrary positions of a text T of length n while using only O(b) words of space during the construction. Attempts at breaking the naïve bound of Ω(nb) time for constructing sparse suffix trees in O(b) space can be traced back to the origins of string indexing in 1968. First results were not obtained until 1996, but only for the case in which the b suffixes were evenly spaced in T. In this article, there is no constraint on the locations of the suffixes. Our main contribution is to show that the sparse suffix tree (and array) can be constructed in O(nlog 2b) time. To achieve this, we develop a technique that allows one to efficiently answer b longest common prefix queries on suffixes of T, using only O(b) space. We expect that this technique will prove useful in many other applications in which space usage is a concern. Our first solution is Monte Carlo, and outputs the correct tree with high probability. We then give a Las Vegas algorithm, which also uses O(b) space and runs in the same time bounds with high probability when b = O(&sqrt; n). Additional trade-offs between space usage and construction time for the Monte Carlo algorithm are given. Finally, we show that, at the expense of slower pattern queries, it is possible to construct sparse position heaps in O(n + blog b) time and O(b) space.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2345228340",
    "type": "article"
  },
  {
    "title": "Submatrix Maximum Queries in Monge Matrices and Partial Monge Matrices, and Their Applications",
    "doi": "https://doi.org/10.1145/3039873",
    "publication_date": "2017-03-06",
    "publication_year": 2017,
    "authors": "Haim Kaplan; Shay Mozes; Yahav Nussbaum; Micha Sharir",
    "corresponding_authors": "",
    "abstract": "We describe a data structure for submatrix maximum queries in Monge matrices or partial Monge matrices, where a query seeks the maximum element in a contiguous submatrix of the given matrix. The structure, for an n × n Monge matrix, takes O ( n log n ) space and O ( n log n ) preprocessing time, and answers queries in O (log 2 n ) time. For partial Monge matrices, the space grows by α( n ), the preprocessing grows by α( n )log n (α( n ) is the inverse Ackermann function), and the query remains O (log 2 n ). Our design exploits an interpretation of the column maxima in a Monge (partial Monge, respectively) matrix as an upper envelope of pseudo-lines (pseudo-segments, respectively). We give two applications: (1) For a planar set of n points in an axis-parallel rectangle B , we build a data structure, in O ( n α( n )log 4 n ) time and O ( n α( n )log 3 n ) space, that returns, for a query point p , the largest-area empty axis-parallel rectangle contained in B and containing p , in O (log 4 n ) time. This improves substantially the nearly quadratic storage and preprocessing obtained by Augustine et al. [2010]. (2) Given an n -node arbitrarily weighted planar digraph, with possibly negative edge weights, we build, in O ( n log 2 n /log log n ) time, a linear-size data structure that supports edge-weight updates and graph-distance queries between arbitrary pairs of nodes in O ( n 2/3 log 5/3 n ) time per operation. This improves a previous algorithm of Fakcharoenphol and Rao [2006]. Our data structure has already been applied in a recent maximum flow algorithm for planar graphs in Borradaile et al. [2011].",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2592415985",
    "type": "article"
  },
  {
    "title": "Primal Dual Gives Almost Optimal Energy-Efficient Online Algorithms",
    "doi": "https://doi.org/10.1145/3155297",
    "publication_date": "2017-12-18",
    "publication_year": 2017,
    "authors": "Nikhil R. Devanur; Zhiyi Huang",
    "corresponding_authors": "",
    "abstract": "We consider the problem of online scheduling of jobs on unrelated machines with dynamic speed scaling to minimize the sum of energy and weighted flow-time. We give an algorithm with an almost optimal competitive ratio for arbitrary power functions. (No earlier results handled arbitrary power functions for unrelated machines.) For power functions of the form f ( s ) = s α for some constant α &gt; 1, we get a competitive ratio of O (α / log α), improving upon a previous competitive ratio of O (α 2 ) by Anand et al. (2012), along with a matching lower bound of Ω(α / log α). Further, in the resource augmentation model, with a 1+ ϵ speed up, we give a 2(1/ϵ + 1) competitive algorithm, with essentially the same techniques, improving the bound of 1 + O (1/ϵ 2 ) by Gupta et al. (2010) and matching the bound of Anand et al. (2012) for the special case of fixed speed unrelated machines. Unlike the previous results most of which used an amortized local competitiveness argument or dual fitting methods, we use a primal-dual method, which is useful not only to analyze the algorithms but also to design the algorithm itself.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2780261041",
    "type": "article"
  },
  {
    "title": "Linear Time Parameterized Algorithms for S <scp>ubset</scp> F <scp>eedback</scp> V <scp>ertex</scp> S <scp>et</scp>",
    "doi": "https://doi.org/10.1145/3155299",
    "publication_date": "2018-01-03",
    "publication_year": 2018,
    "authors": "Daniel Lokshtanov; M. S. Ramanujan; Saket Saurabh",
    "corresponding_authors": "",
    "abstract": "In the S ubset F eedback V ertex S et (S ubset FVS) problem, the input is a graph G on n vertices and m edges, a subset of vertices T , referred to as terminals, and an integer k . The objective is to determine whether there exists a set of at most k vertices intersecting every cycle that contains a terminal. The study of parameterized algorithms for this generalization of the F eedback V ertex S et problem has received significant attention over the past few years. In fact, the parameterized complexity of this problem was open until 2011, when two groups independently showed that the problem is fixed parameter tractable. Using tools from graph minors,, Kawarabayashi and Kobayashi obtained an algorithm for S ubset FVS running in time O ( f ( k )ċ n 2 m ) [SODA 2012, JCTB 2012]. Independently, Cygan et al. [ICALP 2011, SIDMA 2013] designed an algorithm for S ubset FVS running in time 2 O ( k log k ) ċ n O (1) . More recently, Wahlström obtained the first single exponential time algorithm for S ubset FVS, running in time 4 k ċ n O (1) [SODA 2014]. While the 2 O ( k ) dependence on the parameter k is optimal under the Exponential Time Hypothesis, the dependence of this algorithm as well as those preceding it, on the input size is at least quadratic. In this article, we design the first linear time parameterized algorithms for S ubset FVS. More precisely, we obtain the following new algorithms for S ubset FVS. — A randomized algorithm for S ubset FVS running in time O (25.6 k ċ ( n + m )). — A deterministic algorithm for S ubset FVS running in time 2 O ( k log k ) ċ ( n + m ). Since it is known that assuming the Exponential Time Hypothesis, S ubset FVS cannot have an algorithm running in time 2 o ( k ) n O (1) , our first algorithm obtains the best possible asymptotic dependence on both the parameter as well as the input size. Both of our algorithms are based on “cut centrality,” in the sense that solution vertices are likely to show up in minimum size cuts between vertices sampled from carefully chosen distributions.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2781748924",
    "type": "article"
  },
  {
    "title": "Streaming Algorithms for Estimating the Matching Size in Planar Graphs and Beyond",
    "doi": "https://doi.org/10.1145/3230819",
    "publication_date": "2018-08-28",
    "publication_year": 2018,
    "authors": "Hossein Esfandiari; MohammadTaghi Hajiaghayi; Vahid Liaghat; Morteza Monemizadeh; Krzysztof Onak",
    "corresponding_authors": "",
    "abstract": "We consider the problem of estimating the size of a maximum matching when the edges are revealed in a streaming fashion. When the input graph is planar, we present a simple and elegant streaming algorithm that, with high probability, estimates the size of a maximum matching within a constant factor using Õ( n 2/3 ) space, where n is the number of vertices. The approach generalizes to the family of graphs that have bounded arboricity, which include graphs with an excluded constant-size minor. To the best of our knowledge, this is the first result for estimating the size of a maximum matching in the adversarial-order streaming model (as opposed to the random-order streaming model) in o ( n ) space. We circumvent the barriers inherent in the adversarial-order model by exploiting several structural properties of planar graphs, and more generally, graphs with bounded arboricity. We further reduce the required memory size to Õ(√ n ) for three restricted settings: (i) when the input graph is a forest; (ii) when we have 2-passes and the input graph has bounded arboricity; and (iii) when the edges arrive in random order and the input graph has bounded arboricity. Finally, we design a reduction from the Boolean Hidden Matching Problem to show that there is no randomized streaming algorithm that estimates the size of the maximum matching to within a factor better than 3/2 and uses only o ( n 1/2 ) bits of space. Using the same reduction, we show that there is no deterministic algorithm that computes this kind of estimate in o ( n ) bits of space. The lower bounds hold even for graphs that are collections of paths of constant length.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2889287172",
    "type": "article"
  },
  {
    "title": "Exponential Separations in the Energy Complexity of Leader Election",
    "doi": "https://doi.org/10.1145/3341111",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "Yi‐Jun Chang; Tsvi Kopelowitz; Seth Pettie; Ruosong Wang; Wei Zhan",
    "corresponding_authors": "",
    "abstract": "Energy is often the most constrained resource for battery-powered wireless devices, and most of the energy is often spent on transceiver usage (i.e., transmitting and receiving packets) rather than computation. In this article, we study the energy complexity of fundamental problems in several models of wireless radio networks. It turns out that energy complexity is very sensitive to whether the devices can generate random bits and their ability to detect collisions . We consider four collision detection models: Strong-CD (in which transmitters and listeners detect collisions), Sender-CD (in which only transmitters detect collisions), Receiver-CD (in which only listeners detect collisions), and No-CD (in which no one detects collisions). The take-away message of our results is quite surprising. For randomized algorithms, there is an exponential gap between the energy complexity of Sender-CD and Receiver-CD: Randomized: No-CD = Sender-CD &gt; Receiver-CD = Strong-CD and for deterministic algorithms, there is another exponential gap in energy complexity, but in the reverse direction : Deterministic: No-CD = Receiver-CD &gt; Sender-CD = Strong-CD Precisely, the randomized energy complexity of Leader Election is Θ(log * n ) in Sender-CD but Θ(log(log * n )) in Receiver-CD, where n is the number of devices, which is unknown to the devices at the beginning; the deterministic complexity of Leader Election is Θ(log N ) in Receiver-CD but Θ(log log N ) in Sender-CD, where N is the size of the ID space. There is a tradeoff between time and energy. We provide a new upper bound on the time-energy tradeoff curve for randomized algorithms. A critical component of this algorithm is a new deterministic Leader Election algorithm for dense instances, when n = Θ( N ), with inverse Ackermann energy complexity.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2979827763",
    "type": "article"
  },
  {
    "title": "Envy-free pricing in multi-item markets",
    "doi": "https://doi.org/10.1145/2567923",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Ning Chen; Xiaotie Deng",
    "corresponding_authors": "",
    "abstract": "In this article, we study revenue maximizing envy-free pricing in multi-item markets: There are m indivisible items with unit supply each and n potential buyers where each buyer is interested in acquiring one item. The goal is to determine allocations (a matching between buyers and items) and prices of all items to maximize total revenue given that all buyers are envy-free. We give a polynomial time algorithm to compute a revenue maximizing envy-free pricing when every buyer evaluates at most two items at a positive valuation, by reducing it to an instance of weighted independent set in a perfect graph and applying the Strong Perfect Graph Theorem. We complement our result by showing that the problem becomes NP-hard if some buyers are interested in at least three items.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2029622310",
    "type": "article"
  },
  {
    "title": "Deterministic Network Exploration by Anonymous Silent Agents with Local Traffic Reports",
    "doi": "https://doi.org/10.1145/2594581",
    "publication_date": "2014-10-30",
    "publication_year": 2014,
    "authors": "Yoann Dieudonné; Andrzej Pelc",
    "corresponding_authors": "",
    "abstract": "A team consisting of an unknown number of mobile agents starting from different nodes of an unknown network, possibly at different times, have to explore the network: Every node must be visited by at least one agent, and all agents must eventually stop. Agents are anonymous (identical), execute the same deterministic algorithm, and move in synchronous rounds along links of the network. They are silent: They cannot send any messages to other agents or mark visited nodes in any way. In the absence of any additional information, exploration with termination of an arbitrary network in this model, devoid of any means of communication between agents, is impossible. Our aim is to solve the exploration problem by giving to agents very restricted local traffic reports . Specifically, an agent that is at a node v in a given round is provided with three bits of information answering the following questions: Am I alone at v ? Did any agent enter v in this round? Did any agent exit v in this round? We show that this small amount of information permits us to solve the exploration problem in arbitrary networks. More precisely, we give a deterministic terminating exploration algorithm working in arbitrary networks for all initial configurations that are not perfectly symmetric ; that is, in which there are agents with different views of the network. The algorithm works in polynomial time in the (unknown) size of the network. A deterministic terminating exploration algorithm working for all initial configurations in arbitrary networks does not exist.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2089187143",
    "type": "article"
  },
  {
    "title": "Fast Constructions of Lightweight Spanners for General Graphs",
    "doi": "https://doi.org/10.1145/2836167",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Michael Elkin; Shay Solomon",
    "corresponding_authors": "",
    "abstract": "It is long known that for every weighted undirected n -vertex m -edge graph G = ( V , E , ω), and every integer k ⩾ 1, there exists a ((2 k − 1) · (1 + ϵ))-spanner with O ( n 1 + 1/ k ) edges and weight O ( k · n 1/ k · ω( MST ( G )), for an arbitrarily small constant ϵ &gt; 0. (Here ω( MST ( G )) stands for the weight of the minimum spanning tree of G .) To our knowledge, the only algorithms for constructing sparse and lightweight spanners for general graphs admit high running times. Most notable in this context is the greedy algorithm of Althöfer et al. [1993], analyzed by Chandra et al. [1992], which requires O ( m · ( n 1 + 1/ k + n · log n )) time. In this article, we devise an efficient algorithm for constructing sparse and lightweight spanners. Specifically, our algorithm constructs ((2 k − 1) · (1 + ϵ))-spanners with O ( k · n 1 + 1/ k ) edges and weight O ( k · n 1/ k ) · ω( MST ( G )), where ϵ &gt; 0 is an arbitrarily small constant. The running time of our algorithm is O ( k · m + min { n · log n , m · α( n )}). Moreover, by slightly increasing the running time we can reduce the other parameters. These results address an open problem by Roditty and Zwick [2004].",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2401485379",
    "type": "article"
  },
  {
    "title": "Smoothed Analysis of the 2-Opt Algorithm for the General TSP",
    "doi": "https://doi.org/10.1145/2972953",
    "publication_date": "2016-09-14",
    "publication_year": 2016,
    "authors": "Matthias Englert; Heiko Röglin; Berthold Vöcking",
    "corresponding_authors": "",
    "abstract": "2-Opt is a simple local search heuristic for the traveling salesperson problem that performs very well in experiments with respect to both running time and solution quality. In contrast to this, there are instances on which 2-Opt may need an exponential number of steps to reach a local optimum. To understand why 2-Opt usually finds local optima quickly in experiments, we study its expected running time in the model of smoothed analysis, which can be considered as a less-pessimistic variant of worst-case analysis in which the adversarial input is subject to a small amount of random noise. In our probabilistic input model, an adversary chooses an arbitrary graph G and a probability density function for each edge according to which its length is chosen. We prove that in this model the expected number of local improvements is O (mnϕ ċ 16 √ln m )= m 1+ o (1) nϕ , where n and m denote the number of vertices and edges of G , respectively, and ϕ denotes an upper bound on the density functions.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2519455498",
    "type": "article"
  },
  {
    "title": "More Logarithmic-factor Speedups for 3SUM, (median,+)-convolution, and Some Geometric 3SUM-hard Problems",
    "doi": "https://doi.org/10.1145/3363541",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Timothy M. Chan",
    "corresponding_authors": "Timothy M. Chan",
    "abstract": "This article presents an algorithm that solves the 3SUM problem for n real numbers in O (( n 2 / log 2 n )(log log n ) O (1) ) time, improving previous solutions by about a logarithmic factor. Our framework for shaving off two logarithmic factors can be applied to other problems, such as (median,+)-convolution/matrix multiplication and algebraic generalizations of 3SUM. This work also obtains the first subquadratic results on some 3SUM-hard problems in computational geometry, for example, deciding whether (the interiors of) a constant number of simple polygons have a common intersection.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2987751358",
    "type": "article"
  },
  {
    "title": "Faster Replacement Paths and Distance Sensitivity Oracles",
    "doi": "https://doi.org/10.1145/3365835",
    "publication_date": "2019-12-05",
    "publication_year": 2019,
    "authors": "Fabrizio Grandoni; Virginia Vassilevska Williams",
    "corresponding_authors": "",
    "abstract": "Shortest paths computation is one of the most fundamental problems in computer science. An important variant of the problem is when edges can fail, and one needs to compute shortest paths that avoid a (failing) edge. More formally, given a source node s , a target node t , and an edge e , a replacement path for the triple ( s , t , e ) is a shortest s - t path avoiding edge e . Replacement paths computation can be seen either as a static problem or as a data structure problem. In the static setting, a typical goal is to compute for fixed s and t , for every possible failed edge e , the length of the best replacement path around e ( replacement paths problem ). In the data structure setting, a typical goal is to design a data structure ( distance sensitivity oracle ) that, after some preprocessing, quickly answers queries of the form: What is the length of the replacement path for the triple ( s , t , e )? In this article, we focus on n -node directed graphs with integer edge weights in [− M , M ], and present improved replacement paths algorithms and distance sensitivity oracles based on fast matrix multiplication. In more detail, we obtain the following main results: • We describe a replacement paths algorithm with runtime Õ( Mn ω ), where ω &lt; 2.373 is the fast matrix multiplication exponent. For a comparison, the previous fastest algorithms have runtime õ( Mn 1+2ω /3 ) [Weimann,Yuster—FOCS’10] and, in the unweighted case, õ( n 2.5 ) [Roditty, Zwick—ICALP’05]. Our result shows that, at least for small integer weights, the replacement paths problem in directed graphs may be easier than the related all-pairs shortest paths problem, as the current best runtime for the latter is õ( M 1\\4−ω n 2+1 \\ 4−ω ): this is Ω ( n 2.5 ) even if ω = 2. Our algorithm also implies that the k shortest simple s - t paths can be computed in õ( kMn ω ) time. • We consider the single-source generalization of the replacement paths problem, where only the source s is fixed. We show how to solve this problem in all-pairs shortest paths time, currently õ( M 1\\4−ω n 2+1\\4−ω ). Our runtime reduces to õ( Mn ω ) for positive weights, hence matching our mentioned result for the simpler replacement paths case (that, however, holds also for nonpositive weights). One of the ingredients that we use is an algorithm to compute the distances from a set s of source nodes to a set T of target nodes in õ( Mn ω +| S |ṡ | T |ṡ ( Mn ) 1\\4−ω ) time. This improves on a result in Yuster,Zwick—FOCS’05. • We present the first distance sensitivity oracle that achieves simultaneously subcubic preprocessing time and sublinear query time. More precisely, for a given parameter α ∈ [0,1], our oracle has preprocessing time Õ( Mn ω + 1\\ 2 + Mn ω + α (4−ω) ) and query time Õ( n 1−&amp;alpha ). The previous best oracle for small integer weights has Õ( Mn ω +1−α ) preprocessing time and (superlinear) Õ( n 1+α ) query time [Weimann,Yuster-FOCS’10]. From a technical point of view, an interesting and novel aspect of our oracle is that it exploits as a subroutine our single-source replacement paths algorithm. We also present an oracle with the same preprocessing time as in Weimann,Yuster—FOCS’10 and with smaller query time õ( n 1−1−α\\4−ω + n 2α ).",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2991878997",
    "type": "article"
  },
  {
    "title": "A Linear-Time Algorithm for Seeds Computation",
    "doi": "https://doi.org/10.1145/3386369",
    "publication_date": "2020-04-21",
    "publication_year": 2020,
    "authors": "Tomasz Kociumaka; Marcin Kubica; Jakub Radoszewski; Wojciech Rytter; Tomasz Waleń",
    "corresponding_authors": "",
    "abstract": "A seed in a word is a relaxed version of a period in which the occurrences of the repeating subword may overlap. Our first contribution is a linear-time algorithm computing a linear-size representation of all seeds of a word (the number of seeds might be quadratic). In particular, one can easily derive the shortest seed and the number of seeds from our representation. Thus, we solve an open problem stated in a survey by Smyth from 2000 and improve upon a previous O ( n log n )-time algorithm by Iliopoulos et al. from 1996. Our approach is based on combinatorial relations between seeds and subword complexity (used here for the first time in the context of seeds). In previous papers, compact representations of seeds consisted of two independent parts operating on the suffix tree of the input word and the suffix tree of its reverse, respectively. Our second contribution is a novel and significantly simpler representation of all seeds that avoids dealing with the suffix tree of the reversed word. This result is also of independent interest from a combinatorial point of view. A preliminary version of this work, with a much more complex algorithm constructing a representation of seeds on two suffix trees, was presented at the 23rd Annual ACM-SIAM Symposium on Discrete Algorithms (SODA’12).",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W3022427021",
    "type": "article"
  },
  {
    "title": "Sparse Fault-Tolerant BFS Structures",
    "doi": "https://doi.org/10.1145/2976741",
    "publication_date": "2016-10-10",
    "publication_year": 2016,
    "authors": "Merav Parter; David Peleg",
    "corresponding_authors": "",
    "abstract": "A fault-tolerant structure for a network is required for continued functioning following the failure of some of the network’s edges or vertices. This article considers breadth-first search (BFS) spanning trees and addresses the problem of designing a sparse fault-tolerant BFS structure (FT-BFS structure), namely, a sparse subgraph T of the given network G such that subsequent to the failure of a single edge or vertex, the surviving part T ′ of T still contains a BFS spanning tree for (the surviving part of) G . For a source node s , a target node t , and an edge e ∈ G , the shortest s − t path P s , t , e that does not go through e is known as a replacement path . Thus, our FT-BFS structure contains the collection of all replacement paths P s , t , e for every t ∈ V ( G ) and every failed edge e ∈ E ( G ). Our main results are as follows. We present an algorithm that for every n -vertex graph G and source node s constructs a (single edge failure) FT-BFS structure rooted at s with O ( n ċ min {Depth( s ), √n{) edges, where Depth( s ) is the depth of the BFS tree rooted at s . This result is complemented by a matching lower bound, showing that there exist n -vertex graphs with a source node s for which any edge (or vertex) FT-BFS structure rooted at s has Ω( n 3/2 ) edges. We then consider fault-tolerant multi-source BFS structures (FT-MBFS structures), aiming to provide (following a failure) a BFS tree rooted at each source s ∈ S for some subset of sources S ⊆ V . Again, tight bounds are provided, showing that there exists a poly-time algorithm that for every n -vertex graph and source set S ⊆ V of size σ constructs a (single failure) FT-MBFS structure T *( S ) from each source s i ∈ S , with O (√σ ċ n &lt;sup;&gt;3/2&lt;/sup;&gt;) edges, and, on the other hand, there exist n -vertex graphs with source sets S ⊆ V of cardinality σ, on which any FT-MBFS structure from S has Ω(√σ ċ n 3/2 ) edges. Finally, we propose an O (log n ) approximation algorithm for constructing FT-BFS and FT-MBFS structures. The latter is complemented by a hardness result stating that there exists no Ω(log n ) approximation algorithm for these problems under standard complexity assumptions. In comparison with previous constructions, our algorithm is deterministic and may improve the number of edges by a factor of up to √ n for some instances. All our algorithms can be extended to deal with one vertex failure as well, with the same performance.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2530362908",
    "type": "article"
  },
  {
    "title": "Nearest-Neighbor Searching Under Uncertainty II",
    "doi": "https://doi.org/10.1145/2955098",
    "publication_date": "2016-10-10",
    "publication_year": 2016,
    "authors": "Pankaj K. Agarwal; Boris Aronov; Sariel Har-Peled; Jeff M. Phillips; Ke Yi; Wuzhou Zhang",
    "corresponding_authors": "",
    "abstract": "Nearest-neighbor search, which returns the nearest neighbor of a query point in a set of points, is an important and widely studied problem in many fields, and it has a wide range of applications. In many of them, such as sensor databases, location-based services, face recognition, and mobile data, the location of data is imprecise. We therefore study nearest-neighbor queries in a probabilistic framework in which the location of each input point is specified as a probability distribution function. We present efficient algorithms for (i) computing all points that are nearest neighbors of a query point with nonzero probability and (ii) estimating the probability of a point being the nearest neighbor of a query point, either exactly or within a specified additive error.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2531454488",
    "type": "article"
  },
  {
    "title": "Online topological ordering",
    "doi": "https://doi.org/10.1145/1159892.1159896",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Irit Katriel; Hans L. Bodlaender",
    "corresponding_authors": "",
    "abstract": "It is shown that the problem of maintaining the topological order of the nodes of a directed acyclic graph while inserting m edges can be solved in O (min{ m 3/2 log n , m 3/2 + n 2 log n }) time, an improvement over the best known result of O ( mn ). In addition, we analyze the complexity of the same algorithm with respect to the treewidth k of the underlying undirected graph. We show that the algorithm runs in time O ( mk log 2 n ) for general k and that it can be implemented to run in O ( n log n ) time on trees, which is optimal. The algorithm also detects cycles in the input.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W2104685510",
    "type": "article"
  },
  {
    "title": "Tight bounds for worst-case equilibria",
    "doi": "https://doi.org/10.1145/1219944.1219949",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Artur Czumaj; Berthold Vöcking",
    "corresponding_authors": "",
    "abstract": "We study the problem of traffic routing in noncooperative networks. In such networks, users may follow selfish strategies to optimize their own performance measure and therefore, their behavior does not have to lead to optimal performance of the entire network. In this article we investigate the worst-case coordination ratio, which is a game-theoretic measure aiming to reflect the price of selfish routing.",
    "cited_by_count": 27,
    "openalex_id": "https://openalex.org/W4254172305",
    "type": "article"
  },
  {
    "title": "Algorithms for center and Tverberg points",
    "doi": "https://doi.org/10.1145/1435375.1435380",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Pankaj K. Agarwal; Micha Sharir; Emo Welzl",
    "corresponding_authors": "",
    "abstract": "Given a set S of n points in R 3 , a point x in R 3 is called center point of S if every closed halfspace whose bounding hyperplane passes through x contains at least ⌈ n /4⌉ points from S . We present a near-quadratic algorithm for computing the center region , that is the set of all center points, of a set of n points in R 3 . This is nearly tight in the worst case since the center region can have Ω( n 2 ) complexity. We then consider sets S of 3 n points in the plane which are the union of three disjoint sets consisting respectively of n red, n blue, and n green points. A point x in R 2 is called a colored Tverberg point of S if there is a partition of S into n triples with one point of each color, so that x lies in all triangles spanned by these triples. We present a first polynomial-time algorithm for recognizing whether a given point is a colored Tverberg point of such a 3-colored set S .",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2060889372",
    "type": "article"
  },
  {
    "title": "Improved algorithms for the minmax-regret 1-center and 1-median problems",
    "doi": "https://doi.org/10.1145/1367064.1367076",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Hung-I Yu; Tzu-Chin Lin; Biing-Feng Wang",
    "corresponding_authors": "",
    "abstract": "In this article, efficient algorithms are presented for the minmax-regret 1-center and 1-median problems on a general graph and a tree with uncertain vertex weights. For the minmax-regret 1-center problem on a general graph, we improve the previous upper bound from O ( mn 2 log n ) to O ( mn log n ). For the problem on a tree, we improve the upper bound from O ( n 2 ) to O ( n log 2 n ). For the minmax-regret 1-median problem on a general graph, we improve the upper bound from O ( mn 2 log n ) to O ( mn 2 + n 3 log n ). For the problem on a tree, we improve the upper bound from O ( n log 2 n ) to O ( n log n ).",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2066124676",
    "type": "article"
  },
  {
    "title": "A simple entropy-based algorithm for planar point location",
    "doi": "https://doi.org/10.1145/1240233.1240240",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Sunil Arya; Theocharis Malamatos; David M. Mount",
    "corresponding_authors": "",
    "abstract": "Given a planar polygonal subdivision S , point location involves preprocessing this subdivision into a data structure so that given any query point q , the cell of the subdivision containing q can be determined efficiently. Suppose that for each cell z in the subdivision, the probability p z that a query point lies within this cell is also given. The goal is to design the data structure to minimize the average search time. This problem has been considered before, but existing data structures are all quite complicated. It has long been known that the entropy H of the probability distribution is the dominant term in the lower bound on the average-case search time. In this article, we show that a very simple modification of a well-known randomized incremental algorithm can be applied to produce a data structure of expected linear size that can answer point-location queries in O ( H ) average time. We also present empirical evidence for the practical efficiency of this approach.",
    "cited_by_count": 26,
    "openalex_id": "https://openalex.org/W2133718007",
    "type": "article"
  },
  {
    "title": "The NP-completeness column",
    "doi": "https://doi.org/10.1145/1240233.1240247",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "David S. Johnson",
    "corresponding_authors": "David S. Johnson",
    "abstract": "This is the 26th edition of a column that covers new developments in the theory of NP-completeness. The presentation is modeled on that which M. R. Garey and I used in our book “Computers and Intractability: A Guide to the Theory of NP-Completeness,” W. H. Freeman &amp; Co., New York, 1979, hereinafter referred to as “[G&amp;J].” Previous columns, the first 23 of which appeared in J. Algorithms , will be referred to by a combination of their sequence number and year of appearance, e.g., “Column 1 [1981].” Full bibliographic details on the previous columns, as well as downloadable unofficial versions of them, can be found at http://www.research.att.com/~dsj/columns/. This column discusses the question of whether finding an object can be computationally difficult even when we know that the object exists.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2081548873",
    "type": "article"
  },
  {
    "title": "Improved bounds for scheduling conflicting jobs with minsum criteria",
    "doi": "https://doi.org/10.1145/1328911.1328922",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Rajiv Gandhi; Magnús M. Halldórsson; Guy Kortsarz; Hadas Shachnai",
    "corresponding_authors": "",
    "abstract": "We consider a general class of scheduling problems where a set of conflicting jobs needs to be scheduled (preemptively or nonpreemptively) on a set of machines so as to minimize the weighted sum of completion times. The conflicts among jobs are formed as an arbitrary conflict graph. Building on the framework of Queyranne and Sviridenko [2002b], we present a general technique for reducing the weighted sum of completion-times problem to the classical makespan minimization problem. Using this technique, we improve the best-known results for scheduling conflicting jobs with the min-sum objective, on several fundamental classes of graphs, including line graphs, ( k + 1)-claw-free graphs, and perfect graphs. In particular, we obtain the first constant-factor approximation ratio for nonpreemptive scheduling on interval graphs. We also improve the results of Kim [2003] for scheduling jobs on line graphs and for resource-constrained scheduling.",
    "cited_by_count": 25,
    "openalex_id": "https://openalex.org/W2139534004",
    "type": "article"
  },
  {
    "title": "Algorithms for distributional and adversarial pipelined filter ordering problems",
    "doi": "https://doi.org/10.1145/1497290.1497300",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Anne Condon; Amol Deshpande; Lisa Hellerstein; Ning Wu",
    "corresponding_authors": "",
    "abstract": "Pipelined filter ordering is a central problem in database query optimization. The problem is to determine the optimal order in which to apply a given set of commutative filters (predicates) to a set of elements (the tuples of a relation), so as to find, as efficiently as possible, the tuples that satisfy all of the filters. Optimization of pipelined filter ordering has recently received renewed attention in the context of environments such as the Web, continuous high-speed data streams, and sensor networks. Pipelined filter ordering problems are also studied in areas such as fault detection and machine learning under names such as learning with attribute costs, minimum-sum set cover, and satisficing search. We present algorithms for two natural extensions of the classical pipelined filter ordering problem: (1) a distributional-type problem where the filters run in parallel and the goal is to maximize throughput, and (2) an adversarial-type problem where the goal is to minimize the expected value of multiplicative regret . We present two related algorithms for solving (1), both running in time O ( n 2 ), which improve on the O ( n 3 log n ) algorithm of Kodialam. We use techniques from our algorithms for (1) to obtain an algorithm for (2).",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2160921566",
    "type": "article"
  },
  {
    "title": "Routing and scheduling in multihop wireless networks with time-varying channels",
    "doi": "https://doi.org/10.1145/1273340.1273349",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Matthew Andrews; Lisa Zhang",
    "corresponding_authors": "",
    "abstract": "We study routing and scheduling in multihop wireless networks . When data is transmitted from its source node to its destination node it may go through other wireless nodes as intermediate hops. The data transmission is node constrained , that is, every node can transmit data to at most one neighboring node per time step. The transmission rates are time varying as a result of changing wireless channel conditions. In this article, we assume that data arrivals and transmission rates are governed by an adversary . The power of the adversary is limited by an admissibility condition which forbids the adversary from overloading any wireless node a priori. The node-constrained transmission and time-varying nature of the transmission rates make our model different from and harder than the standard adversarial queueing model which relates to wireline networks. For the case in which the adversary specifies the paths that the data must follow, we design scheduling algorithms that ensure network stability. These algorithms try to give priority to the data that is closest to its source node. However, at each time step only a subset of the data queued at a node is eligible for scheduling. One of our algorithms is fully distributed . For the case in which the adversary does not dictate the data paths, we show how to route data so that the admissibility condition is satisfied. We can then schedule data along the chosen paths using our stable scheduling algorithms.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2166604552",
    "type": "article"
  },
  {
    "title": "Discounted deterministic Markov decision processes and discounted all-pairs shortest paths",
    "doi": "https://doi.org/10.1145/1721837.1721849",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Omid Madani; Mikkel Thorup; Uri Zwick",
    "corresponding_authors": "",
    "abstract": "We present algorithms for finding optimal strategies for discounted, infinite-horizon, Determinsitc Markov Decision Processes (DMDPs). Our fastest algorithm has a worst-case running time of O ( mn ), improving the recent bound of O ( mn 2 ) obtained by Andersson and Vorbyov [2006]. We also present a randomized O ( m 1/2 n 2 )-time algorithm for finding Discounted All-Pairs Shortest Paths (DAPSP), improving an O ( mn 2 )-time algorithm that can be obtained using ideas of Papadimitriou and Tsitsiklis [1987].",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2043871262",
    "type": "article"
  },
  {
    "title": "The relative worst order ratio applied to seat reservation",
    "doi": "https://doi.org/10.1145/1383369.1383379",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Joan Boyar; Paul Medvedev",
    "corresponding_authors": "",
    "abstract": "The seat reservation problem is the problem of assigning passengers to seats on a train with n seats and k stations enroute in an online manner. The performance of algorithms for this problem is studied using the relative worst order ratio, a fairly new measure for the quality of online algorithms, which allows for direct comparisons between algorithms. This study has yielded new separations between algorithms. For example, for both variants of the problem considered, using the relative worst order ratio, First-Fit and Best-Fit are shown to be better than Worst-Fit.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2072577896",
    "type": "article"
  },
  {
    "title": "The Knuth-Yao quadrangle-inequality speedup is a consequence of total monotonicity",
    "doi": "https://doi.org/10.1145/1644015.1644032",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Wolfgang Bein; Mordecai J. Golin; Lawrence L. Larmore; Yan Zhang",
    "corresponding_authors": "",
    "abstract": "There exist several general techniques in the literature for speeding up naive implementations of dynamic programming. Two of the best known are the Knuth-Yao quadrangle inequality speedup and the SMAWK algorithm for finding the row-minima of totally monotone matrices. Although both of these techniques use a quadrangle inequality and seem similar, they are actually quite different and have been used differently in the literature. In this article we show that the Knuth-Yao technique is actually a direct consequence of total monotonicity. As well as providing new derivations of the Knuth-Yao result, this also permits to solve the Knuth-Yao problem directly using the SMAWK algorithm. Another consequence of this approach is a method for solving online versions of problems with the Knuth-Yao property. The online algorithms given here are asymptotically as fast as the best previously known static ones. For example, the Knuth-Yao technique speeds up the standard dynamic program for finding the optimal binary search tree of n elements from Θ( n 3 ) down to O ( n 2 ), and the results in this article allow construction of an optimal binary search tree in an online fashion (adding a node to the left or the right of the current nodes at each step) in O ( n ) time per step.",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2622763161",
    "type": "article"
  },
  {
    "title": "Sublinear estimation of entropy and information distances",
    "doi": "https://doi.org/10.1145/1597036.1597038",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Sudipto Guha; Andrew McGregor; Suresh Venkatasubramanian",
    "corresponding_authors": "",
    "abstract": "In many data mining and machine learning problems, the data items that need to be clustered or classified are not arbitrary points in a high-dimensional space, but are distributions, that is, points on a high-dimensional simplex. For distributions, natural measures are not ℓ p distances, but information-theoretic measures such as the Kullback-Leibler and Hellinger divergences. Similarly, quantities such as the entropy of a distribution are more natural than frequency moments. Efficient estimation of these quantities is a key component in algorithms for manipulating distributions. Since the datasets involved are typically massive, these algorithms need to have only sublinear complexity in order to be feasible in practice. We present a range of sublinear-time algorithms in various oracle models in which the algorithm accesses the data via an oracle that supports various queries. In particular, we answer a question posed by Batu et al. on testing whether two distributions are close in an information-theoretic sense given independent samples. We then present optimal algorithms for estimating various information-divergences and entropy with a more powerful oracle called the combined oracle that was also considered by Batu et al. Finally, we consider sublinear-space algorithms for these quantities in the data-stream model. In the course of doing so, we explore the relationship between the aforementioned oracle models and the data-stream model. This continues work initiated by Feigenbaum et al. An important additional component to the study is considering data streams that are ordered randomly rather than just those which are ordered adversarially.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2043160138",
    "type": "article"
  },
  {
    "title": "Bootstrapping a hop-optimal network in the weak sensor model",
    "doi": "https://doi.org/10.1145/1597036.1597040",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Martı́n Farach-Colton; Rohan J. Fernandes; Miguel A. Mosteiro",
    "corresponding_authors": "",
    "abstract": "Sensor nodes are very weak computers that get distributed at random on a surface. Once deployed, they must wake up and form a radio network. Sensor network bootstrapping research thus has three parts: One must model the restrictions on sensor nodes; one must prove that the connectivity graph of the sensors has a subgraph that would make a good network; and one must give a distributed protocol for finding such a network subgraph that can be implemented on sensor nodes. Although many particular restrictions on sensor nodes are implicit or explicit in many papers, there remain many inconsistencies and ambiguities from paper to paper. The lack of a clear model means that solutions to the network bootstrapping problem in both the theory and systems literature all violate constraints on sensor nodes. For example, random geometric graph results on sensor networks predict the existence of subgraphs on the connectivity graph with good route-stretch, but these results do not address the degree of such a graph, and sensor networks must have constant degree. Furthermore, proposed protocols for actually finding such graphs require that nodes have too much memory, whereas others assume the existence of a contention-resolution mechanism. We present a formal Weak Sensor model that summarizes the literature on sensor node restrictions, taking the most restrictive choices when possible. We show that sensor connectivity graphs have low-degree subgraphs with good hop-stretch , as required by the Weak Sensor model. Finally, we give a Weak Sensor model-compatible protocol for finding such graphs. Ours is the first network initialization algorithm that is implementable on sensor nodes.",
    "cited_by_count": 21,
    "openalex_id": "https://openalex.org/W2032355069",
    "type": "article"
  },
  {
    "title": "Approximate shared-memory counting despite a strong adversary",
    "doi": "https://doi.org/10.1145/1721837.1721841",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "James Aspnes; Keren Censor",
    "corresponding_authors": "",
    "abstract": "A new randomized asynchronous shared-memory data structure is given for implementing an approximate counter that can be incremented once by each of n processes in a model that allows up to n -1 crash failures. For any fixed ϵ, the counter achieves a relative error of δ with high probability, at the cost of O (((1/δ) log n ) O (1/ϵ) ) register operations per increment and O ( n 4/5+ϵ ((1/δ) log n ) O (1/ϵ) ) register operations per read. The counter combines randomized sampling for estimating large values with an expander for estimating small values. This is the first counter implementation that is sublinear the number of processes and works despite a strong adversary scheduler that can observe internal states of processes. An application of the improved counter is an improved protocol for solving randomized shared-memory consensus, which reduces the best previously known individual work complexity from O ( n log n ) to an optimal O ( n ), resolving one of the last remaining open problems concerning consensus in this model.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2168550339",
    "type": "article"
  },
  {
    "title": "Cycle detection and correction",
    "doi": "https://doi.org/10.1145/2390176.2390189",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Amihood Amir; Estrella Eisenberg; Avivit Levy; Ely Porat; Natalie Shapira",
    "corresponding_authors": "",
    "abstract": "Assume that a natural cyclic phenomenon has been measured, but the data is corrupted by errors. The type of corruption is application-dependent and may be caused by measurements errors, or natural features of the phenomenon. We assume that an appropriate metric exists, which measures the amount of corruption experienced. This article studies the problem of recovering the correct cycle from data corrupted by various error models, formally defined as the period recovery problem . Specifically, we define a metric property which we call pseudolocality and study the period recovery problem under pseudolocal metrics. Examples of pseudolocal metrics are the Hamming distance, the swap distance, and the interchange (or Cayley) distance. We show that for pseudolocal metrics, periodicity is a powerful property allowing detecting the original cycle and correcting the data, under suitable conditions. Some surprising features of our algorithm are that we can efficiently identify the period in the corrupted data, up to a number of possibilities logarithmic in the length of the data string, even for metrics whose calculation is NP-hard . For the Hamming metric, we can reconstruct the corrupted data in near-linear time even for unbounded alphabets. This result is achieved using the property of separation in the self-convolution vector and Reed-Solomon codes. Finally, we employ our techniques beyond the scope of pseudo-local metrics and give a recovery algorithm for the non-pseudolocal Levenshtein edit metric.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2013125732",
    "type": "article"
  },
  {
    "title": "Nearly Optimal Deterministic Algorithm for Sparse Walsh-Hadamard Transform",
    "doi": "https://doi.org/10.1145/3029050",
    "publication_date": "2017-03-06",
    "publication_year": 2017,
    "authors": "Mahdi Cheraghchi; Piotr Indyk",
    "corresponding_authors": "",
    "abstract": "For every fixed constant α &gt; 0, we design an algorithm for computing the k -sparse Walsh-Hadamard transform (i.e., Discrete Fourier Transform over the Boolean cube) of an N -dimensional vector x ∈ R N in time k 1 + α (log N ) O (1) . Specifically, the algorithm is given query access to x and computes a k -sparse x˜ ∈ R N satisfying ‖ x˜ − xˆ ‖ 1 ≤ c ‖ xˆ − H k ( xˆ )‖‖‖‖‖‖‖‖ 1 for an absolute constant c &gt; 0, where xˆ is the transform of x and H k ( xˆ ) is its best k -sparse approximation. Our algorithm is fully deterministic and only uses nonadaptive queries to x (i.e., all queries are determined and performed in parallel when the algorithm starts). An important technical tool that we use is a construction of nearly optimal and linear lossless condensers, which is a careful instantiation of the GUV condenser (Guruswami et al. [2009]). Moreover, we design a deterministic and nonadaptive ℓ 1 /ℓ 1 compressed sensing scheme based on general lossless condensers that is equipped with a fast reconstruction algorithm running in time k 1 + α (log N ) O (1) (for the GUV-based condenser) and is of independent interest. Our scheme significantly simplifies and improves an earlier expander-based construction due to Berinde, Gilbert, Indyk, Karloff, and Strauss [Berinde et al. 2008]. Our methods use linear lossless condensers in a black box fashion; therefore, any future improvement on explicit constructions of such condensers would immediately translate to improved parameters in our framework (potentially leading to k (log N ) O (1) reconstruction time with a reduced exponent in the poly-logarithmic factor, and eliminating the extra parameter α). By allowing the algorithm to use randomness while still using nonadaptive queries, the runtime of the algorithm can be improved to õ ( k log 3 N ).",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2620883762",
    "type": "article"
  },
  {
    "title": "Graph Reconstruction and Verification",
    "doi": "https://doi.org/10.1145/3199606",
    "publication_date": "2018-08-09",
    "publication_year": 2018,
    "authors": "Sampath Kannan; Claire Mathieu; Hang Zhou",
    "corresponding_authors": "",
    "abstract": "How efficiently can we find an unknown graph using distance or shortest path queries between its vertices? We assume that the unknown graph G is connected, unweighted, and has bounded degree. In the reconstruction problem, the goal is to find the graph G . In the verification problem, we are given a hypothetical graph Ĝ and want to check whether G is equal to Ĝ . We provide a randomized algorithm for reconstruction using Õ( n 3/2 ) distance queries, based on Voronoi cell decomposition. Next, we analyze natural greedy algorithms for reconstruction using a shortest path oracle and also for verification using either oracle, and show that their query complexity is n 1+ o (1) . We further improve the query complexity when the graph is chordal or outerplanar. Finally, we show some lower bounds, and consider an approximate version of the reconstruction problem.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2885499996",
    "type": "article"
  },
  {
    "title": "Weighted popular matchings",
    "doi": "https://doi.org/10.1145/2556951",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Julián Mestre",
    "corresponding_authors": "Julián Mestre",
    "abstract": "We study the problem of assigning jobs to applicants. Each applicant has a weight and provides a preference list , which may contain ties, ranking a subset of the jobs. An applicant x may prefer one matching to another (or be indifferent between them, in case of a tie) based on the jobs x gets in the two matchings and x ’s personal preference. A matching M is popular if there is no other matching M ′ such that the weight of the applicants who prefer M ′ to M exceeds the weight of those who prefer M to M ′. We present algorithms to find a popular matching, or if none exists, to establish so. For instances with strict preference lists, we give an O ( n + m time algorithm. For preference lists with ties, we give a more involved algorithm that solves the problem in O (min ( k √ n ;, n ) m ) time, where k is the number of distinct weights the applicants are given.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1546314173",
    "type": "article"
  },
  {
    "title": "Approximating the Diameter of Planar Graphs in Near Linear Time",
    "doi": "https://doi.org/10.1145/2764910",
    "publication_date": "2015-11-16",
    "publication_year": 2015,
    "authors": "Oren Weimann; Raphael Yuster",
    "corresponding_authors": "",
    "abstract": "We present a (1 + ε)-approximation algorithm running in O ( f (ε) · n log 4 n ) time for finding the diameter of an undirected planar graph with n vertices and with nonnegative edge lengths.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1597730645",
    "type": "article"
  },
  {
    "title": "A Polynomial-Time Approximation Scheme for Euclidean Steiner Forest",
    "doi": "https://doi.org/10.1145/2629654",
    "publication_date": "2015-01-13",
    "publication_year": 2015,
    "authors": "Glencora Borradaile; Philip N. Klein; Claire Mathieu",
    "corresponding_authors": "",
    "abstract": "We give a randomized O ( n polylog n )-time approximation scheme for the Steiner forest problem in the Euclidean plane. For every fixed ϵ &gt; 0 and given n terminals in the plane with connection requests between some pairs of terminals, our scheme finds a (1 + ϵ) approximation to the minimum-length forest that connects every requested pair of terminals.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W1972906866",
    "type": "article"
  },
  {
    "title": "Geometric clustering",
    "doi": "https://doi.org/10.1145/2000807.2000811",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Sergio Cabello; Panos Giannopoulos; Christian Knauer; Dániel Marx; Günter Rote",
    "corresponding_authors": "",
    "abstract": "We study the parameterized complexity of the k -center problem on a given n -point set P in ℝ d , with the dimension d as the parameter. We show that the rectilinear 3-center problem is fixed-parameter tractable, by giving an algorithm that runs in O ( n log n ) time for any fixed dimension d . On the other hand, we show that this is unlikely to be the case with both the Euclidean and rectilinear k -center problems for any k ≥ 2 and k ≥ 4 respectively. In particular, we prove that deciding whether P can be covered by the union of 2 balls of given radius or by the union of 4 cubes of given side length is W[1]-hard with respect to d , and thus not fixed-parameter tractable unless FPT=W[1]. For the Euclidean case, we also show that even an n o ( d ) -time algorithm does not exist, unless there is a 2 o ( n ) -time algorithm for n -variable 3SAT, that is, the Exponential Time Hypothesis fails.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2127518109",
    "type": "article"
  },
  {
    "title": "Domination When the Stars Are Out",
    "doi": "https://doi.org/10.1145/3301445",
    "publication_date": "2019-04-22",
    "publication_year": 2019,
    "authors": "Danny Hermelin; Matthias Mnich; Erik Jan van Leeuwen; Gerhard J. Woeginger",
    "corresponding_authors": "",
    "abstract": "We algorithmize the structural characterization for claw-free graphs by Chudnovsky and Seymour. Building on this result, we show that D ominating S et on claw-free graphs is (i) fixed-parameter tractable and (ii) even possesses a polynomial kernel. To complement these results, we establish that D ominating S et is unlikely to be fixed-parameter tractable on the slightly larger class of graphs that exclude K 1,4 as an induced subgraph ( K 1,4 -free graphs). We show that our algorithmization can also be used to show that the related C onnected D ominating S et problem is fixed-parameter tractable on claw-free graphs. To complement that result, we show that C onnected D ominating S et is unlikely to have a polynomial kernel on claw-free graphs and is unlikely to be fixed-parameter tractable on K 1,4 -free graphs. Combined, our results provide a dichotomy for D ominating S et and C onnected D ominating S et on K 1,ℓ -free graphs and show that the problem is fixed-parameter tractable if and only if ℓ ≤ 3.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2942029771",
    "type": "article"
  },
  {
    "title": "Online Submodular Maximization with Preemption",
    "doi": "https://doi.org/10.1145/3309764",
    "publication_date": "2019-06-07",
    "publication_year": 2019,
    "authors": "Niv Buchbinder; Moran Feldman; Roy Schwartz",
    "corresponding_authors": "",
    "abstract": "Submodular function maximization has been studied extensively in recent years under various constraints and models. The problem plays a major role in various disciplines. We study a natural online variant of this problem in which elements arrive one by one and the algorithm has to maintain a solution obeying certain constraints at all times. Upon arrival of an element, the algorithm has to decide whether to accept the element into its solution and may preempt previously chosen elements. The goal is to maximize a submodular function over the set of elements in the solution. We study two special cases of this general problem and derive upper and lower bounds on the competitive ratio. Specifically, we design a 1/ e -competitive algorithm for the unconstrained case in which the algorithm may hold any subset of the elements, and constant competitive ratio algorithms for the case where the algorithm may hold at most k elements in its solution.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2950023069",
    "type": "article"
  },
  {
    "title": "Smoothed Analysis of Local Search for the Maximum-Cut Problem",
    "doi": "https://doi.org/10.1145/3011870",
    "publication_date": "2017-03-21",
    "publication_year": 2017,
    "authors": "Michael Etscheid; Heiko Röglin",
    "corresponding_authors": "",
    "abstract": "Even though local search heuristics are the method of choice in practice for many well-studied optimization problems, most of them behave poorly in the worst case. This is, in particular, the case for the Maximum-Cut Problem, for which local search can take an exponential number of steps to terminate and the problem of computing a local optimum is PLS-complete. To narrow the gap between theory and practice, we study local search for the Maximum-Cut Problem in the framework of smoothed analysis in which inputs are subject to a small amount of random noise. We show that the smoothed number of iterations is quasi-polynomial, that is, it is bounded from above by a polynomial in n log n and ϕ, where n denotes the number of nodes and ϕ denotes the perturbation parameter. This shows that worst-case instances are fragile, and it is a first step in explaining why they are rarely observed in practice.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3160805239",
    "type": "article"
  },
  {
    "title": "Quasi-Polynomial Local Search for Restricted Max-Min Fair Allocation",
    "doi": "https://doi.org/10.1145/2818695",
    "publication_date": "2015-11-17",
    "publication_year": 2015,
    "authors": "Lukáš Poláček; Ola Svensson",
    "corresponding_authors": "",
    "abstract": "The restricted max-min fair allocation problem (also known as the restricted Santa Claus problem) is one of few problems that enjoys the intriguing status of having a better estimation algorithm than approximation algorithm. Indeed, Asadpour et al. [2012] proved that a certain configuration LP can be used to estimate the optimal value within a factor of 1/(4 + ϵ), for any ϵ &gt; 0, but at the same time it is not known how to efficiently find a solution with a comparable performance guarantee. A natural question that arises from their work is if the difference between these guarantees is inherent or results from a lack of suitable techniques. We address this problem by giving a quasi-polynomial approximation algorithm with the mentioned performance guarantee. More specifically, we modify the local search of Asadpour et al. [2012] and provide a novel analysis that lets us significantly improve the bound on its running time: from 2 O ( n ) to n O (log n ) . Our techniques also have the interesting property that although we use the rather complex configuration LP in the analysis, we never actually solve it and therefore the resulting algorithm is purely combinatorial.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W1589729468",
    "type": "article"
  },
  {
    "title": "Faster Algorithms for Semi-Matching Problems",
    "doi": "https://doi.org/10.1145/2601071",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "Jittat Fakcharoenphol; Bundit Laekhanukit; Danupon Nanongkai",
    "corresponding_authors": "",
    "abstract": "We consider the problem of finding semi-matching in bipartite graphs, which is also extensively studied under various names in the scheduling literature. We give faster algorithms for both weighted and unweighted cases. For the weighted case, we give an O ( nm log n )-time algorithm, where n is the number of vertices and m is the number of edges, by exploiting the geometric structure of the problem. This improves the classical O ( n 3 )-time algorithms by Horn [1973] and Bruno et al. [1974b]. For the unweighted case, the bound can be improved even further. We give a simple divide-and-conquer algorithm that runs in O (√ nm log n ) time, improving two previous O ( nm )-time algorithms by Abraham [2003] and Harvey et al. [2003, 2006]. We also extend this algorithm to solve the Balanced Edge Cover problem in O (√ nm log n ) time, improving the previous O ( nm )-time algorithm by Harada et al. [2008].",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2033561606",
    "type": "article"
  },
  {
    "title": "A Linear-Size Logarithmic Stretch Path-Reporting Distance Oracle for General Graphs",
    "doi": "https://doi.org/10.1145/2888397",
    "publication_date": "2016-08-03",
    "publication_year": 2016,
    "authors": "Michael Elkin; Seth Pettie",
    "corresponding_authors": "",
    "abstract": "Thorup and Zwick [2001a] proposed a landmark distance oracle with the following properties. Given an n -vertex undirected graph G = ( V , E ) and a parameter k = 1, 2, …, their oracle has size O ( kn 1 + 1/ k ), and upon a query ( u , v ) it constructs a path Π between u and v of length δ( u , v ) such that d G ( u , v ) ⩽ δ( u , v ) ⩽ (2 k − 1) d G ( u , v ). The query time of the oracle from Thorup and Zwick [2001a] is O ( k ) (in addition to the length of the returned path), and it was subsequently improved to O (1) [Wulff-Nilsen 2012; Chechik 2014]. A major drawback of the oracle of Thorup and Zwick [2001a] is that its space is Ω( n · log n ). Mendel and Naor [2006] devised an oracle with space O ( n 1 + 1/ k ) and stretch O ( k ), but their oracle can only report distance estimates and not actual paths. In this article, we devise a path-reporting distance oracle with size O ( n 1 + 1/ k ), stretch O ( k ), and query time O ( n ϵ ), for an arbitrarily small constant ϵ &gt; 0. In particular, for k = log n , our oracle provides logarithmic stretch using linear size. Another variant of our oracle has size O ( n loglog n ), polylogarithmic stretch, and query time O (loglog n ). For unweighted graphs, we devise a distance oracle with multiplicative stretch O (1), additive stretch O (β( k )), for a function β(·), space O ( n 1 + 1/ k ), and query time O ( n ϵ ), for an arbitrarily small constant ϵ &gt; 0. The tradeoff between multiplicative stretch and size in these oracles is far below Erdős’s girth conjecture threshold (which is stretch 2 k − 1 and size O ( n 1 + 1/ k )). Breaking the girth conjecture tradeoff is achieved by exhibiting a tradeoff of different nature between additive stretch β( k ) and size O ( n 1 + 1/ k ). A similar type of tradeoff was exhibited by a construction of (1 + ϵ, β)-spanners due to Elkin and Peleg [2001]. However, so far (1 + ϵ, β)-spanners had no counterpart in the distance oracles’ world. An important novel tool that we develop on the way to these results is a distance-preserving path-reporting oracle. We believe that this oracle is of independent interest.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2211624051",
    "type": "article"
  },
  {
    "title": "Dominator Tree Certification and Divergent Spanning Trees",
    "doi": "https://doi.org/10.1145/2764913",
    "publication_date": "2015-11-16",
    "publication_year": 2015,
    "authors": "Loukas Georgiadis; Robert E. Tarjan",
    "corresponding_authors": "",
    "abstract": "How does one verify that the output of a complicated program is correct? One can formally prove that the program is correct, but this may be beyond the power of existing methods. Alternatively, one can check that the output produced for a particular input satisfies the desired input--output relation by running a checker on the input--output pair. Then one only needs to prove the correctness of the checker. For some problems, however, even such a checker may be too complicated to formally verify. There is a third alternative: augment the original program to produce not only an output but also a correctness certificate , with the property that a very simple program (whose correctness is easy to prove) can use the certificate to verify that the input--output pair satisfies the desired input--output relation. We consider the following important instance of this general question: How does one verify that the dominator tree of a flow graph is correct? Existing fast algorithms for finding dominators are complicated, and even verifying the correctness of a dominator tree in the absence of additional information seems complicated. We define a correctness certificate for a dominator tree, show how to use it to easily verify the correctness of the tree, and show how to augment fast dominator-finding algorithms so that they produce a correctness certificate. We also relate the dominator certificate problem to the problem of finding divergent spanning trees in a flow graph, and we develop algorithms to find such trees. All our algorithms run in linear time. Previous algorithms apply just to the special case of only trivial dominators, and they take at least quadratic time.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2242691822",
    "type": "article"
  },
  {
    "title": "Forbidden-Set Distance Labels for Graphs of Bounded Doubling Dimension",
    "doi": "https://doi.org/10.1145/2818694",
    "publication_date": "2016-02-12",
    "publication_year": 2016,
    "authors": "Ittai Abraham; Shiri Chechik; Cyril Gavoille; David Peleg",
    "corresponding_authors": "",
    "abstract": "This article proposes a forbidden-set labeling scheme for the family of unweighted graphs with doubling dimension bounded by α. For an n -vertex graph G in this family, and for any desired precision parameter ϵ &gt; 0, the labeling scheme stores an O (1 + ϵ − 1 ) 2α log 2 n -bit label at each vertex. Given the labels of two end-vertices s and t , and the labels of a set F of “forbidden” vertices and/or edges, our scheme can compute, in O (1 + ϵ − 1 ) 2α · | F | 2 log n time, a 1 + ϵ stretch approximation for the distance between s and t in the graph G ∖ F . The labeling scheme can be extended into a forbidden-set labeled routing scheme with stretch 1 + ϵ for graphs of bounded doubling dimension.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2343281498",
    "type": "article"
  },
  {
    "title": "Algorithmic and Enumerative Aspects of the Moser-Tardos Distribution",
    "doi": "https://doi.org/10.1145/3039869",
    "publication_date": "2017-03-06",
    "publication_year": 2017,
    "authors": "David G. Harris; Aravind Srinivasan",
    "corresponding_authors": "",
    "abstract": "Moser and Tardos have developed a powerful algorithmic approach (henceforth MT) to the Lovász Local Lemma (LLL); the basic operation done in MT and its variants is a search for “bad” events in a current configuration. In the initial stage of MT, the variables are set independently. We examine the distributions on these variables that arise during intermediate stages of MT. We show that these configurations have a more or less “random” form, building further on the MT-distribution concept of Haeupler et al. in understanding the (intermediate and) output distribution of MT. This has a variety of algorithmic applications; the most important is that bad events can be found relatively quickly, improving on MT across the complexity spectrum. It makes some polynomial-time algorithms sublinear (e.g., for Latin transversals, which are of basic combinatorial interest), gives lower-degree polynomial runtimes in some settings, transforms certain superpolynomial-time algorithms into polynomial-time algorithms, and leads to Las Vegas algorithms for some coloring problems for which only Monte Carlo algorithms were known. We show that, in certain conditions when the LLL condition is violated, a variant of the MT algorithm can still produce a distribution that avoids most of the bad events. We show in some cases that this MT variant can run faster than the original MT algorithm itself and develop the first-known criterion for the case of the asymmetric LLL. This can be used to find partial Latin transversals—improving on earlier bounds of Stein (1975)—among other applications. We furthermore give applications in enumeration, showing that most applications (for which we aim for all or most of the bad events to be avoided) have large solution sets. We do this by showing that the MT distribution has large Rényi entropy.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2623186112",
    "type": "article"
  },
  {
    "title": "Distributed Private Data Analysis",
    "doi": "https://doi.org/10.1145/3146549",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Elaine Shi; T-H. Hubert Chan; Eleanor Rieffel; Dawn Song",
    "corresponding_authors": "",
    "abstract": "We consider a distributed private data analysis setting, where multiple parties each hold some sensitive data and they wish to run a protocol to learn some aggregate statistics over the distributed dataset, while protecting each user’s privacy. As an initial effort, we consider a distributed summation problem. We first show a lower bound, that is, under information-theoretic differential privacy, any multi-party protocol with a small number of messages must have large additive error. We then show that by adopting a computational differential privacy notion, one can circumvent this lower bound and design practical protocols for the periodic distributed summation problem. Our construction has several desirable features. First, it works in the client-server model and requires no peer-to-peer communication among the clients. Second, our protocol is fault tolerant and can output meaningful statistics even when a subset of the participants fail to respond. Our constructions guarantee the privacy of honest parties even when a fraction of the participants may be compromised and colluding. In addition, we propose a new distributed noise addition mechanism that guarantees small total error.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2778211317",
    "type": "article"
  },
  {
    "title": "Conditional Lower Bounds for All-Pairs Max-Flow",
    "doi": "https://doi.org/10.1145/3212510",
    "publication_date": "2018-08-21",
    "publication_year": 2018,
    "authors": "Robert Krauthgamer; Ohad Trabelsi",
    "corresponding_authors": "",
    "abstract": "We provide evidence that computing the maximum flow value between every pair of nodes in a directed graph on n nodes, m edges, and capacities in the range [1‥ n ], which we call the All-Pairs Max-Flow problem, cannot be solved in time that is significantly faster (i.e., by a polynomial factor) than O ( n 3 ) even for sparse graphs, namely m = O ( n ); thus for general m , it cannot be solved significantly faster than O ( n 2 m ). Since a single maximum st -flow can be solved in time Õ( m √ n ) [Lee and Sidford, FOCS 2014], we conclude that the all-pairs version might require time equivalent to Ω ˜ ( n 3/2 ) computations of maximum st -flow, which strongly separates the directed case from the undirected one. Moreover, if maximum st -flow can be solved in time Õ( m ), then the runtime of Ω ˜ ( n 2 ) computations is needed. This is in contrast to a conjecture of Lacki, Nussbaum, Sankowski, and Wulff-Nilsen [FOCS 2012] that All-Pairs Max-Flow in general graphs can be solved faster than the time of O ( n 2 ) computations of maximum st -flow. Specifically, we show that in sparse graphs G = ( V , E , w ), if one can compute the maximum st -flow from every s in an input set of sources S ⊆ V to every t in an input set of sinks T ⊆ V in time O ((| S || T | m ) 1−ε ), for some | S |, | T | and a constant ε &gt; 0, then MAX-CNF-SAT (maximum satisfiability of conjunctive normal form formulas) with n ′ variables and m ′ clauses can be solved in time m ′ O (1) 2 (1−δ) n ′ for a constant δ(ε) &gt; 0, a problem for which not even 2 n ′ / poly ( n ′) algorithms are known. Such running time for MAX-CNF-SAT would in particular refute the Strong Exponential Time Hypothesis (SETH). Hence, we improve the lower bound of Abboud, Vassilevska-Williams, and Yu [STOC 2015], who showed that for every fixed ε &gt; 0 and | S | = | T | = O (√ n ), if the above problem can be solved in time O ( n 3/2−ε ), then some incomparable (and intuitively weaker) conjecture is false. Furthermore, a larger lower bound than ours implies strictly super-linear time for maximum st -flow problem, which would be an amazing breakthrough. In addition, we show that All-Pairs Max-Flow in uncapacitated networks with every edge-density m = m ( n ) cannot be computed in time significantly faster than O ( mn ), even for acyclic networks. The gap to the fastest known algorithm by Cheung, Lau, and Leung [FOCS 2011] is a factor of O ( m ω−1 / n ), and for acyclic networks it is O ( n ω−1 ), where ω is the matrix multiplication exponent. Finally, we extend our lower bounds to the version that asks only for the maximum-flow values below a given threshold (over all source-sink pairs).",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2962913759",
    "type": "article"
  },
  {
    "title": "The Complexity of Cake Cutting with Unequal Shares",
    "doi": "https://doi.org/10.1145/3380742",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Ágnes Cseh; Tamás Fleiner",
    "corresponding_authors": "",
    "abstract": "An unceasing problem of our prevailing society is the fair division of goods. The problem of proportional cake cutting focuses on dividing a heterogeneous and divisible resource, the cake, among n players who value pieces according to their own measure function. The goal is to assign each player a not necessarily connected part of the cake that the player evaluates at least as much as her proportional share. In this article, we investigate the problem of proportional division with unequal shares, where each player is entitled to receive a predetermined portion of the cake. Our main contribution is threefold. First we present a protocol for integer demands, which delivers a proportional solution in fewer queries than all known protocols. By giving a matching lower bound, we then show that our protocol is asymptotically the fastest possible. Finally, we turn to irrational demands and solve the proportional cake cutting problem by reducing it to the same problem with integer demands only. All results remain valid in a highly general cake cutting model, which can be of independent interest.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2963041995",
    "type": "article"
  },
  {
    "title": "Optimal Orthogonal Graph Drawing with Convex Bend Costs",
    "doi": "https://doi.org/10.1145/2838736",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Thomas Bläsius; Ignaz Rutter; Dorothea Wagner",
    "corresponding_authors": "",
    "abstract": "Traditionally, the quality of orthogonal planar drawings is quantified by the total number of bends or the maximum number of bends per edge. However, this neglects that, in typical applications, edges have varying importance. We consider the problem O ptimal F lex D raw that is defined as follows. Given a planar graph G on n vertices with maximum degree 4 ( 4-planar graph ) and for each edge e a cost function cost e : N 0 → R defining costs depending on the number of bends e has, compute a planar orthogonal drawing of G of minimum cost. In this generality O ptimal F lex D raw is NP-hard. We show that it can be solved efficiently if (1) the cost function of each edge is convex and (2) the first bend on each edge does not cause any cost. Our algorithm takes time O ( n , ⋅, T flow ( n ) and O ( n 2 , ⋅, T flow ( n )) for biconnected and connected graphs, respectively, where T flow ( n ) denotes the time to compute a minimum-cost flow in a planar network with multiple sources and sinks. Our result is the first polynomial-time bend-optimization algorithm for general 4-planar graphs optimizing over all embeddings. Previous work considers restricted graph classes and unit costs.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2110635609",
    "type": "article"
  },
  {
    "title": "Minimum Latency Submodular Cover",
    "doi": "https://doi.org/10.1145/2987751",
    "publication_date": "2016-11-15",
    "publication_year": 2016,
    "authors": "Sungjin Im; Viswanath Nagarajan; Ruben van der Zwaan",
    "corresponding_authors": "",
    "abstract": "We study the Minimum Latency Submodular Cover (MLSC) problem, which consists of a metric ( V , d ) with source r ∈ V and m monotone submodular functions f 1 , f 2 , …, f m : 2 V → [0, 1]. The goal is to find a path originating at r that minimizes the total “cover time” of all functions. This generalizes well-studied problems, such as Submodular Ranking [Azar and Gamzu 2011] and the Group Steiner Tree [Garg et al. 2000]. We give a polynomial time O (log 1/ϵ ċ log 2+δ |V|)-approximation algorithm for MLSC, where ϵ &gt; 0 is the smallest non-zero marginal increase of any { f i } m i = 1 and δ &gt; 0 is any constant. We also consider the Latency Covering Steiner Tree (LCST) problem, which is the special case of MLSC where the f i s are multi-coverage functions. This is a common generalization of the Latency Group Steiner Tree [Gupta et al. 2010; Chakrabarty and Swamy 2011] and Generalized Min-sum Set Cover [Azar et al. 2009; Bansal et al. 2010] problems. We obtain an O (log 2 | V |)-approximation algorithm for LCST. Finally, we study a natural stochastic extension of the Submodular Ranking problem and obtain an adaptive algorithm with an O (log 1/ϵ)-approximation ratio, which is best possible. This result also generalizes some previously studied stochastic optimization problems, such as Stochastic Set Cover [Goemans and Vondrák 2006] and Shared Filter Evaluation [Munagala et al. 2007; Liu et al. 2008].",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2148450486",
    "type": "article"
  },
  {
    "title": "On the <i>k</i> -Independence Required by Linear Probing and Minwise Independence",
    "doi": "https://doi.org/10.1145/2716317",
    "publication_date": "2015-11-16",
    "publication_year": 2015,
    "authors": "Mihai Pǎtraşcu; Mikkel Thorup",
    "corresponding_authors": "",
    "abstract": "We show that linear probing requires 5-independent hash functions for expected constant-time performance, matching an upper bound of Pagh et al. [2009]. More precisely, we construct a random 4-independent hash function yielding expected logarithmic search time for certain keys. For (1 + ε)-approximate minwise independence, we show that Ω(lg1 ε)-independent hash functions are required, matching an upper bound of Indyk [2001]. We also show that the very fast 2-independent multiply-shift scheme of Dietzfelbinger [1996] fails badly in both applications.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2245536463",
    "type": "article"
  },
  {
    "title": "How Good Is Multi-Pivot Quicksort?",
    "doi": "https://doi.org/10.1145/2963102",
    "publication_date": "2016-10-10",
    "publication_year": 2016,
    "authors": "Martin Aumüller; Martin Dietzfelbinger; Pascal Klaue",
    "corresponding_authors": "",
    "abstract": "Multi-Pivot Quicksort refers to variants of classical quicksort where in the partitioning step k pivots are used to split the input into k + 1 segments. For many years, multi-pivot quicksort was regarded as impractical, but in 2009 a two-pivot approach by Yaroslavskiy, Bentley, and Bloch was chosen as the standard sorting algorithm in Sun’s Java 7. In 2014 at ALENEX, Kushagra et al. introduced an even faster algorithm that uses three pivots. This article studies what possible advantages multi-pivot quicksort might offer in general. The contributions are as follows: Natural comparison-optimal algorithms for multi-pivot quicksort are devised and analyzed. The analysis shows that the benefits of using multiple pivots with respect to the average comparison count are marginal and these strategies are inferior to simpler strategies such as the well-known median-of-k approach. A substantial part of the partitioning cost is caused by rearranging elements. A rigorous analysis of an algorithm for rearranging elements in the partitioning step is carried out, observing mainly how often array cells are accessed during partitioning. The algorithm behaves best if three to five pivots are used. Experiments show that this translates into good cache behavior and is closest to predicting observed running times of multi-pivot quicksort algorithms. Finally, it is studied how choosing pivots from a sample affects sorting cost. The study is theoretical in the sense that although the findings motivate design recommendations for multipivot quicksort algorithms that lead to running-time improvements over known algorithms in an experimental setting, these improvements are small.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2276251922",
    "type": "article"
  },
  {
    "title": "Bypassing UGC from Some Optimal Geometric Inapproximability Results",
    "doi": "https://doi.org/10.1145/2737729",
    "publication_date": "2016-02-08",
    "publication_year": 2016,
    "authors": "Venkatesan Guruswami; Prasad Raghavendra; Rishi Saket; Yi Wu",
    "corresponding_authors": "",
    "abstract": "The Unique Games Conjecture (UGC) has emerged in recent years as the starting point for several optimal inapproximability results. While for none of these results a reverse reduction to Unique Games is known, the assumption of bijective projections in the Label Cover instance nevertheless seems critical in these proofs. In this work, we bypass the need for UGC assumption in inapproximability results for two geometric problems, obtaining a tight NP-hardness result in each case. The first problem, known as L p Subspace Approximation, is a generalization of the classic least squares regression problem. Here, the input consists of a set of points X = {α 1 , … , α m } ⊆ R n and a parameter k (possibly depending on n ). The goal is to find a subspace H of R n of dimension k that minimizes the ℓ p norm of the Euclidean distances to the points in X . For p = 2, k = n − 1, this reduces to the least squares regression problem, while for p = ∞, k = 0 it reduces to the problem of finding a ball of minimum radius enclosing all the points. We show that for any fixed p ∈ (2, ∞), and for k = n − 1, it is NP-hard to approximate this problem to within a factor of γ p − ϵ for constant ϵ &gt; 0, where γ p is the p th norm of a standard Gaussian random variable. This matches the γ p approximation algorithm obtained by Deshpande, Tulsiani, and Vishnoi who also showed the same hardness result under the UGC. The second problem we study is the related L p Quadratic Grothendieck Maximization Problem, considered by Kindler, Naor, and Schechtman. Here, the input is a multilinear quadratic form ∑ n i , j = 1 a ij x i x j and the goal is to maximize the quadratic form over the ℓ p unit ball, namely, all x with ∑ n i = 1 | x i | p ⩽ 1. The problem is polynomial time solvable for p = 2. We show that for any constant p ∈ (2, ∞), it is NP-hard to approximate the quadratic form to within a factor of γ 2 p − ϵ for any ϵ &gt; 0. The same hardness factor was shown under the UGC by Kindler et al. We also obtain a γ 2 p -approximation algorithm for the problem using the convex relaxation of the problem defined by Kindler et al. A γ 2 p approximation algorithm has also been independently obtained by Naor and Schechtman. These are the first approximation thresholds, proven under P ≠ NP, that involve the Gaussian random variable in a fundamental way. Note that the problem statements themselves do not explicitly involve the Gaussian distribution.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2397159611",
    "type": "article"
  },
  {
    "title": "Enumerating Minimal Dominating Sets in Kt-free Graphs and Variants",
    "doi": "https://doi.org/10.1145/3386686",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Marthe Bonamy; Oscar Defrain; Marc Heinrich; Michał Pilipczuk; Jean‐Florent Raymond",
    "corresponding_authors": "",
    "abstract": "It is a long-standing open problem whether the minimal dominating sets of a graph can be enumerated in output-polynomial time. In this article we investigate this problem in graph classes defined by forbidding an induced subgraph. In particular, we provide output-polynomial time algorithms for K t -free graphs and for several related graph classes. This answers a question of Kanté et al. about enumeration in bipartite graphs.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W3033151368",
    "type": "article"
  },
  {
    "title": "Efficient Shortest Paths in Scale-Free Networks with Underlying Hyperbolic Geometry",
    "doi": "https://doi.org/10.1145/3516483",
    "publication_date": "2022-02-11",
    "publication_year": 2022,
    "authors": "Thomas Bläsius; Cedric Freiberger; Tobias Friedrich; Maximilian Katzmann; Felix Montenegro-Retana; Marianne Thieffry",
    "corresponding_authors": "",
    "abstract": "A standard approach to accelerating shortest path algorithms on networks is the bidirectional search, which explores the graph from the start and the destination, simultaneously. In practice this strategy performs particularly well on scale-free real-world networks. Such networks typically have a heterogeneous degree distribution (e.g., a power-law distribution) and high clustering (i.e., vertices with a common neighbor are likely to be connected themselves). These two properties can be obtained by assuming an underlying hyperbolic geometry. To explain the observed behavior of the bidirectional search, we analyze its running time on hyperbolic random graphs and prove that it is Õ( n 2 - 1/α + n 1/(2α) + δ max ) with high probability, where α ∈ (1/2, 1) controls the power-law exponent of the degree distribution, and δ max is the maximum degree. This bound is sublinear, improving the obvious worst-case linear bound. Although our analysis depends on the underlying geometry, the algorithm itself is oblivious to it.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2802893379",
    "type": "article"
  },
  {
    "title": "Matching on the Line Admits no \\(o(\\sqrt {\\log n})\\) -Competitive Algorithm",
    "doi": "https://doi.org/10.1145/3594873",
    "publication_date": "2023-05-24",
    "publication_year": 2023,
    "authors": "Enoch Peserico; Michele Scquizzato",
    "corresponding_authors": "",
    "abstract": "We present a simple proof that no randomized online matching algorithm for the line can be \\((\\sqrt {\\log _2(n+1)}/15)\\) -competitive against an oblivious adversary for any n = 2 i - 1 : i ∈ ℕ. This is the first super-constant lower bound for the problem, and disproves as a corollary a recent conjecture on the topology-parametrized competitiveness achievable on generic spaces.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3122422288",
    "type": "article"
  },
  {
    "title": "Efficient constructions of the Prefer-same and Prefer-opposite de Bruijn sequences",
    "doi": "https://doi.org/10.1145/3679015",
    "publication_date": "2024-07-26",
    "publication_year": 2024,
    "authors": "Evan Sala; Joe Sawada; Abbas Alhakim",
    "corresponding_authors": "",
    "abstract": "The greedy Prefer-same de Bruijn sequence construction was first presented by Eldert, Gray, Gurk, and Rubinoff in 1958. As a greedy algorithm, it has one major downside: it requires an exponential amount of space to store the length \\(2^{n}\\) de Bruijn sequence. Though de Bruijn sequences have been heavily studied over the last 60 years, finding an efficient construction for the Prefer-same de Bruijn sequence has remained a tantalizing open problem. In this article, we unveil the underlying structure of the Prefer-same de Bruijn sequence and solve the open problem by presenting an efficient algorithm to construct it using \\(O(n)\\) time per bit and only \\(O(n)\\) space. Following a similar approach, we also present an efficient algorithm to construct the Prefer-opposite de Bruijn sequence.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3093330059",
    "type": "article"
  },
  {
    "title": "Improved results for data migration and open shop scheduling",
    "doi": "https://doi.org/10.1145/1125994.1126001",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Rajiv Gandhi; Magnús M. Halldórsson; Guy Kortsarz; Hadas Shachnai",
    "corresponding_authors": "",
    "abstract": "The data migration problem is to compute an efficient plan for moving data stored on devices in a network from one configuration to another. We consider this problem with the objective of minimizing the sum of completion times of all storage devices. It is modeled by a transfer graph, where vertices represent the storage devices, and the edges indicate the data transfers required between pairs of devices. Each vertex has a nonnegative weight, and each edge has a release time and a processing time. A vertex completes when all the edges incident on it complete; the constraint is that two edges incident on the same vertex cannot be processed simultaneously. The objective is to minimize the sum of weighted completion times of all vertices. Kim ( Journal of Algorithms, 55:42--57, 2005 ) gave a 9-approximation algorithm for the problem when edges have arbitrary processing times and are released at time zero. We improve Kim's result by giving a 5.06-approximation algorithm. We also address the open shop scheduling problem, O | r j | ∑ w j C j , and show that it is a special case of the data migration problem. Queyranne and Sviridenko ( Journal of Scheduling, 5:287-305, 2002 ) gave a 5.83-approximation algorithm for the nonpreemptive version of the open shop problem. They state as an obvious open question whether there exists an algorithm for open shop scheduling that gives a performance guarantee better than 5.83. Our 5.06 algorithm for data migration proves the existence of such an algorithm. Crucial to our improved result is a property of the linear programming relaxation for the problem. Similar linear programs have been used for various other scheduling problems. Our technique may be useful in obtaining improved results for these problems as well.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2014528617",
    "type": "article"
  },
  {
    "title": "Oblivious routing on node-capacitated and directed graphs",
    "doi": "https://doi.org/10.1145/1290672.1290688",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Mohammad Taghi Hajiaghayi; Robert Kleinberg; Harald Räcke; Tom Leighton",
    "corresponding_authors": "",
    "abstract": "Oblivious routing algorithms for general undirected networks were introduced by Räcke [2002], and this work has led to many subsequent improvements and applications. Comparatively little is known about oblivious routing in general directed networks, or even in undirected networks with node capacities. We present the first nontrivial upper bounds for both these cases, providing algorithms for k -commodity oblivious routing problems with competitive ratio O (√ k log( n )) for undirected node-capacitated graphs and O (√ k n 1/4 log( n )) for directed graphs. In the special case that all commodities have a common source or sink, our upper bound becomes O (√ n log( n )) in both cases, matching the lower bound up to a factor of log( n ). The lower bound (which first appeared in Azar et al. [2003]) is obtained on a graph with very high degree. We show that, in fact, the degree of a graph is a crucial parameter for node-capacitated oblivious routing in undirected graphs, by providing an O (Δ polylog( n ))-competitive oblivious routing scheme for graphs of degree Δ. For the directed case, however, we show that the lower bound of Ω(√ n ) still holds in low-degree graphs. Finally, we settle an open question about routing problems in which all commodities share a common source or sink. We show that even in this simplified scenario there are networks in which no oblivious routing algorithm can achieve a competitive ratio better than Ω(log n ).",
    "cited_by_count": 23,
    "openalex_id": "https://openalex.org/W2996539125",
    "type": "article"
  },
  {
    "title": "Randomized minimum spanning tree algorithms using exponentially fewer random bits",
    "doi": "https://doi.org/10.1145/1328911.1328916",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Seth Pettie; Vijaya Ramachandran",
    "corresponding_authors": "",
    "abstract": "For many fundamental problems there exist randomized algorithms that are asymptotically optimal and are superior to the best-known deterministic algorithm. Among these are the minimum spanning tree (MST) problem, the MST sensitivity analysis problem, the parallel connected components and parallel minimum spanning tree problems, and the local sorting and set maxima problems. (For the first two problems there are provably optimal deterministic algorithms with unknown, and possibly superlinear, running times.) One downside of the randomized methods for solving these problems is that they use a number of random bits linear in the size of input. In this article we develop some general methods for reducing exponentially the consumption of random bits in comparison-based algorithms. In some cases we are able to reduce the number of random bits from linear to nearly constant, without affecting the expected running time. Most of our results are obtained by adjusting or reorganizing existing randomized algorithms to work well with a pairwise or O (1)-wise independent sampler. The prominent exception, and the main focus of this article, is a linear-time randomized minimum spanning tree algorithm that is not derived from the well-known Karger-Klein-Tarjan algorithm. In many ways it resembles more closely the deterministic minimum spanning tree algorithms based on soft heaps. Further, using our algorithm as a guide, we present a unified view of the existing “nongreedy” minimum spanning tree algorithms. Concepts from the Karger-Klein-Tarjan algorithm, such as F -lightness, MST verification, and sampled graphs, are related to the concepts of edge corruption, subgraph contractibility, and soft heaps, which are the basis of the deterministic MST algorithms of Chazelle and Pettie-Ramachandran.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W1992273661",
    "type": "article"
  },
  {
    "title": "The string edit distance matching problem with moves",
    "doi": "https://doi.org/10.1145/1219944.1219947",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Graham Cormode; S. Muthukrishnan",
    "corresponding_authors": "",
    "abstract": "The edit distance between two strings S and R is defined to be the minimum number of character inserts, deletes, and changes needed to convert R to S. Given a text string t of length n, and a pattern string p of length m, informally, the string edit distance matching problem is to compute the smallest edit distance between p and substrings of t.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W4248804345",
    "type": "article"
  },
  {
    "title": "Ordinal embeddings of minimum relaxation",
    "doi": "https://doi.org/10.1145/1383369.1383377",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Noga Alon; Mihai Bâdoiu; Erik D. Demaine; Martı́n Farach-Colton; MohammadTaghi Hajiaghayi; Anastasios Sidiropoulos",
    "corresponding_authors": "",
    "abstract": "We introduce a new notion of embedding, called minimum-relaxation ordinal embedding , parallel to the standard notion of minimum-distortion (metric) embedding. In an ordinal embedding, it is the relative order between pairs of distances, and not the distances themselves, that must be preserved as much as possible. The (multiplicative) relaxation of an ordinal embedding is the maximum ratio between two distances whose relative order is inverted by the embedding. We develop several worst-case bounds and approximation algorithms on ordinal embedding. In particular, we establish that ordinal embedding has many qualitative differences from metric embedding, and we capture the ordinal behavior of ultrametrics and shortest-path metrics of unweighted trees.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2149726280",
    "type": "article"
  },
  {
    "title": "Polynomial constraint satisfaction problems, graph bisection, and the Ising partition function",
    "doi": "https://doi.org/10.1145/1597036.1597049",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Alex Scott; Gregory B. Sorkin",
    "corresponding_authors": "",
    "abstract": "We introduce a problem class we call Polynomial Constraint Satisfaction Problems, or PCSP. Where the usual CSPs from computer science and optimization have real-valued score functions, and partition functions from physics have monomials, PCSP has scores that are arbitrary multivariate formal polynomials, or indeed take values in an arbitrary ring. Although PCSP is much more general than CSP, remarkably, all (exact, exponential-time) algorithms we know of for 2-CSP (where each score depends on at most 2 variables) extend to 2-PCSP, at the expense of just a polynomial factor in running time. Specifically, we extend the reduction-based algorithm of Scott and Sorkin; the specialization of that approach to sparse random instances, where the algorithm runs in polynomial expected time; dynamic-programming algorithms based on tree decompositions; and the split-and-list matrix-multiplication algorithm of Williams. This gives the first polynomial-space exact algorithm more efficient than exhaustive enumeration for the well-studied problems of finding a minimum bisection of a graph, and calculating the partition function of an Ising model, and the most efficient algorithm known for certain instances of Maximum Independent Set. Furthermore, PCSP solves both optimization and counting versions of a wide range of problems, including all CSPs, and thus enables samplers including uniform sampling of optimal solutions and Gibbs sampling of all solutions.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2035135174",
    "type": "article"
  },
  {
    "title": "Improved online algorithms for the sorting buffer problem on line metrics",
    "doi": "https://doi.org/10.1145/1644015.1644030",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Iftah Gamzu; Danny Segev",
    "corresponding_authors": "",
    "abstract": "An instance of the sorting buffer problem consists of a metric space and a server, equipped with a finite-capacity buffer capable of holding a limited number of requests. An additional ingredient of the input is an online sequence of requests, each of which is characterized by a destination in the given metric space; whenever a request arrives, it must be stored in the sorting buffer. At any point in time, a currently pending request can be served by drawing it out of the buffer and moving the server to its corresponding destination. The objective is to serve all input requests in a way that minimizes the total distance traveled by the server. In this article, we focus our attention on instances of the problem in which the underlying metric is either an evenly-spaced line metric or a continuous line metric . Our main findings can be briefly summarized as follows. (1) We present a deterministic O (log n )-competitive algorithm for n -point evenly-spaced line metrics. This result improves on a randomized O (log 2 n )-competitive algorithm due to Khandekar and Pandit [2006b]. It also refutes their conjecture, stating that a deterministic strategy is unlikely to obtain a nontrivial competitive ratio. (2) We devise a deterministic O (log N log log N )-competitive algorithm for continuous line metrics, where N denotes the length of the input sequence. In this context, we introduce a novel discretization technique of independent interest. (3) We establish the first nontrivial lower bound for the evenly-spaced case, by proving that the competitive ratio of any deterministic algorithm is at least 2 + √3/√3 ≈ 2.154. This result settles, to some extent, an open question due to Khandekar and Pandit [2006b], who posed the task of attaining lower bounds on the achievable competitive ratio as a foundational objective for future research.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2052224952",
    "type": "article"
  },
  {
    "title": "Approximation algorithms for data placement on parallel disks",
    "doi": "https://doi.org/10.1145/1597036.1597037",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Leana Golubchik; Sanjeev Khanna; Samir Khuller; Ramakrishna Thurimella; An Zhu",
    "corresponding_authors": "",
    "abstract": "We study an optimization problem that arises in the context of data placement in a multimedia storage system. We are given a collection of M multimedia objects (data objects) that need to be assigned to a storage system consisting of N disks d 1 , d 2 …, d N . We are also given sets U 1 , U 2 ,…, U M such that U i is the set of clients seeking the i th data object. Each disk d j is characterized by two parameters, namely, its storage capacity C j which indicates the maximum number of data objects that may be assigned to it, and a load capacity L j which indicates the maximum number of clients that it can serve. The goal is to find a placement of data objects to disks and an assignment of clients to disks so as to maximize the total number of clients served, subject to the capacity constraints of the storage system. We study this data placement problem for two natural classes of storage systems, namely, homogeneous and uniform ratio . We show that an algorithm developed by Shachnai and Tamir [2000a] for data placement achieves the best possible absolute bound regarding the number of clients that can always be satisfied. We also show how to implement the algorithm so that it has a running time of O (( N + M ) log( N + M )). In addition, we design a polynomial-time approximation scheme, solving an open problem posed in the same paper.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2108111372",
    "type": "article"
  },
  {
    "title": "Finding equitable convex partitions of points in a polygon efficiently",
    "doi": "https://doi.org/10.1145/1824777.1824792",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "John Gunnar Carlsson; Benjamin Armbruster; Yinyu Ye",
    "corresponding_authors": "",
    "abstract": "Previous work has developed algorithms for finding an equitable convex partition that partitions the plane into n convex pieces each containing an equal number of red and blue points. Motivated by a vehicle routing heuristic, we look at a related problem where each piece must contain one point and an equal fraction of the area of some convex polygon. We first show how algorithms for solving the older problem lead to approximate solutions for this new equitable convex partition problem. Then we demonstrate a new algorithm that finds an exact solution to our problem in O ( N n log N ) time or operations, where n is the number of points, m the number of vertices or edges of the polygon, and N := n + m the sum.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2141807613",
    "type": "article"
  },
  {
    "title": "Finding shortest contractible and shortest separating cycles in embedded graphs",
    "doi": "https://doi.org/10.1145/1721837.1721840",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Sergio Cabello",
    "corresponding_authors": "Sergio Cabello",
    "abstract": "We give a polynomial-time algorithm to find a shortest contractible cycle (i.e., a closed walk without repeated vertices) in a graph embedded in a surface. This answers a question posed by Hutchinson. In contrast, we show that finding a shortest contractible cycle through a given vertex is NP-hard. We also show that finding a shortest separating cycle in an embedded graph is NP-hard. This answers a question posed by Mohar and Thomassen.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W2077970810",
    "type": "article"
  },
  {
    "title": "Dynamic pricing for impatient bidders",
    "doi": "https://doi.org/10.1145/1721837.1721851",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Nikhil Bansal; Ning Chen; Neva Cherniavsky; Atri Rurda; Baruch Schieber; Maxim Sviridenko",
    "corresponding_authors": "",
    "abstract": "We study the following problem related to pricing over time. Assume there is a collection of bidders, each of whom is interested in buying a copy of an item of which there is an unlimited supply. Every bidder is associated with a time interval over which the bidder will consider buying a copy of the item, and a maximum value the bidder is willing to pay for the item. On every time unit, the seller sets a price for the item. The seller's goal is to set the prices so as to maximize revenue from the sale of copies of items over the time period. In the first model considered, we assume that all bidders are impatient , that is, bidders buy the item at the first time unit within their bid interval that they can afford the price. To the best of our knowledge, this is the first work that considers this model. In the offline setting, we assume that the seller knows the bids of all the bidders in advance. In the online setting we assume that at each time unit the seller only knows the values of the bids that have arrived before or at that time unit. We give a polynomial time offline algorithm and prove upper and lower bounds on the competitiveness of deterministic and randomized online algorithms, compared with the optimal offline solution. The gap between the upper and lower bounds is quadratic. We also consider the envy-free model in which bidders are sold the item at the minimum price during their bid interval, as long as it is not over their limit value. We prove tight bounds on the competitiveness of deterministic online algorithms for this model, and upper and lower bounds on the competitiveness of randomized algorithms with quadratic gap. The lower bounds for the randomized case in both models use a novel general technique.",
    "cited_by_count": 18,
    "openalex_id": "https://openalex.org/W3136734724",
    "type": "article"
  },
  {
    "title": "Iterative Expansion and Color Coding",
    "doi": "https://doi.org/10.1145/2071379.2071385",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Jianer Chen; Yang Liu; Songjian Lu; Sing‐Hoi Sze; Fenghui Zhang",
    "corresponding_authors": "",
    "abstract": "The research in the parameterized 3d-matching problem has yielded a number of new algorithmic techniques and an impressive list of improved algorithms. In this article, a new deterministic algorithm for the problem is developed that integrates and improves a number of known techniques, including greedy localization, dynamic programming, and color coding. The new algorithm, which either constructs a matching of k triples in a given triple set or correctly reports that no such a matching exists, runs in time O * (2.80 3 k ), improving a long list of previous algorithms for the problem.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2010011156",
    "type": "article"
  },
  {
    "title": "Even Faster Exact Bandwidth",
    "doi": "https://doi.org/10.1145/2071379.2071387",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Marek Cygan; Marcin Pilipczuk",
    "corresponding_authors": "",
    "abstract": "We deal with exact algorithms for Bandwidth , a long studied NP-hard problem. For a long time nothing better than the trivial O * ( n !) 1 exhaustive search was known. In 2000, Feige and Kilian [Feige 2000] came up with a O * (10 n )-time and polynomial space algorithm. In this article we present a new algorithm that solves Bandwidth in O * (5 n ) time and O * (2 n ) space. Then, we take a closer look and introduce a major modification that makes it run in O (4.83 n ) time with a cost of a O * (4 n ) space complexity. This modification allowed us to perform the Measure &amp; Conquer analysis for the time complexity which was not used for graph layout problems before.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2015540687",
    "type": "article"
  },
  {
    "title": "An O(log n)-Approximation Algorithm for the Edge-Disjoint Paths Problem in Eulerian Planar Graphs",
    "doi": "https://doi.org/10.1145/2438645.2438648",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Ken‐ichi Kawarabayashi; Yusuke Kobayashi",
    "corresponding_authors": "",
    "abstract": "In this article, we study an approximation algorithm for the maximum edge-disjoint paths problem. In this problem, we are given a graph and a collection of pairs of vertices, and the objective is to find the maximum number of pairs that can be connected by edge-disjoint paths. We give an O (log n )-approximation algorithm for the maximum edge-disjoint paths problem when an input graph is either 4-edge-connected planar or Eulerian planar. This improves an O (log 2 n )-approximation algorithm given by Kleinberg [2005] for Eulerian planar graphs. Our result also generalizes the result by Chekuri et al. [2004, 2005] who gave an O (log n )-approximation algorithm for the maximum edge-disjoint paths problem with congestion two when an input graph is planar.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2035272561",
    "type": "article"
  },
  {
    "title": "Minimizing flow time in the wireless gathering problem",
    "doi": "https://doi.org/10.1145/1978782.1978788",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Vincenzo Bonifaci; Peter Korteweg; Alberto Marchetti-Spaccamela; Leen Stougie",
    "corresponding_authors": "",
    "abstract": "We address the problem of efficient data gathering in a wireless network through multi-hop communication. We focus on the objective of minimizing the maximum flow time of a data packet. We prove that no polynomial time algorithm for this problem can have approximation ratio less than $\\Omega(m^{1/3)$ when $m$ packets have to be transmitted, unless $P = NP$. We then use resource augmentation to assess the performance of a FIFO-like strategy. We prove that this strategy is 5-speed optimal, i.e., its cost remains within the optimal cost if we allow the algorithm to transmit data at a speed 5 times higher than that of the optimal solution we compare to.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2148438817",
    "type": "article"
  },
  {
    "title": "Clique-width III",
    "doi": "https://doi.org/10.1145/3280824",
    "publication_date": "2018-11-16",
    "publication_year": 2018,
    "authors": "Fedor V. Fomin; Petr A. Golovach; Daniel Lokshtanov; Saket Saurabh; Meirav Zehavi",
    "corresponding_authors": "",
    "abstract": "M AX -C UT , E DGE D OMINATING S ET , G RAPH C OLORING , and H AMILTONIAN C YCLE on graphs of bounded clique-width have received significant attention as they can be formulated in MSO 2 (and, therefore, have linear-time algorithms on bounded treewidth graphs by the celebrated Courcelle’s theorem), but cannot be formulated in MSO 1 (which would have yielded linear-time algorithms on bounded clique-width graphs by a well-known theorem of Courcelle, Makowsky, and Rotics). Each of these problems can be solved in time g ( k ) n f ( k ) on graphs of clique-width k . Fomin et al. (2010) showed that the running times cannot be improved to g ( k ) n O (1) assuming W[1]≠FPT. However, this does not rule out non-trivial improvements to the exponent f ( k ) in the running times. In a follow-up paper, Fomin et al. (2014) improved the running times for E DGE D OMINATING S ET and M AX -C UT to n O ( k ) , and proved that these problems cannot be solved in time g ( k ) n o ( k ) unless ETH fails. Thus, prior to this work, E DGE D OMINATING S ET and M AX -C UT were known to have tight n Θ ( k ) algorithmic upper and lower bounds. In this article, we provide lower bounds for H AMILTONIAN C YCLE and G RAPH C OLORING . For H AMILTONIAN C YCLE , our lower bound g ( k ) n o ( k ) matches asymptotically the recent upper bound n O ( k ) due to Bergougnoux, Kanté, and Kwon (2017). As opposed to the asymptotically tight n Θ( k ) bounds for E DGE D OMINATING S ET , M AX -C UT , and H AMILTONIAN C YCLE , the G RAPH C OLORING problem has an upper bound of n O (2 k ) and a lower bound of merely n o (√ [4] k ) (implicit from the W[1]-hardness proof). In this article, we close the gap for G RAPH C OLORING by proving a lower bound of n 2 o ( k ) . This shows that G RAPH C OLORING behaves qualitatively different from the other three problems. To the best of our knowledge, G RAPH C OLORING is the first natural problem known to require exponential dependence on the parameter in the exponent of n .",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2900958825",
    "type": "article"
  },
  {
    "title": "A 4/3-Approximation Algorithm for the Minimum 2-Edge Connected Subgraph Problem",
    "doi": "https://doi.org/10.1145/3341599",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "Christoph Hunkenschröder; Santosh Vempala; Adrian Vetta",
    "corresponding_authors": "",
    "abstract": "We present a factor 4/3 approximation algorithm for the problem of finding a minimum 2-edge connected spanning subgraph of a given undirected multigraph. The algorithm is based upon a reduction to a restricted class of graphs. In these graphs, the approximation algorithm constructs a 2-edge connected spanning subgraph by modifying the smallest 2-edge cover.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2979731478",
    "type": "article"
  },
  {
    "title": "Deciding the Confusability of Words under Tandem Repeats in Linear Time",
    "doi": "https://doi.org/10.1145/3338514",
    "publication_date": "2019-07-16",
    "publication_year": 2019,
    "authors": "Yeow Meng Chee; Johan Chrisnata; Han Mao Kiah; Tuan Thanh Nguyen",
    "corresponding_authors": "",
    "abstract": "Tandem duplication in DNA is the process of inserting a copy of a segment of DNA adjacent to the original position. Motivated by applications that store data in living organisms, Jain et al. (2016) proposed the study of codes that correct tandem duplications to improve the reliability of data storage. We investigate algorithms associated with the study of these codes. Two words are said to be ⩽-confusable if there exists a sequence of tandem duplications for each word, where each duplication is of length at most k , such that the resulting two words after duplications are equal. For k =3, we demonstrate that the problem of deciding whether two words is ⩽3-confusable is linear-time solvable through a characterisation that can be checked efficiently. Combining with previous results, the decision problem is linear-time solvable for k ⩽ 3. We conjecture that this problem is undecidable for k &gt; 3. Using insights gained from the algorithm, we study the size of tandem-duplication codes. We improve the previous known upper bound and then construct codes with larger sizes as compared to the previous constructions. We determine the sizes of optimal tandem-duplication codes for lengths up to 20, develop recursive methods to construct tandem-duplication codes for all word lengths, and compute explicit lower bounds for the size of optimal tandem-duplication codes for lengths from 21 to 30.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2998466234",
    "type": "article"
  },
  {
    "title": "Maximizing Symmetric Submodular Functions",
    "doi": "https://doi.org/10.1145/3070685",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Moran Feldman",
    "corresponding_authors": "Moran Feldman",
    "abstract": "Symmetric submodular functions are an important family of submodular functions capturing many interesting cases, including cut functions of graphs and hypergraphs. Maximization of such functions subject to various constraints receives little attention by current research, unlike similar minimization problems that have been widely studied. In this work, we identify a few submodular maximization problems for which one can get a better approximation for symmetric objectives than the state-of-the-art approximation for general submodular functions. We first consider the problem of maximizing a non-negative symmetric submodular function f :2 N → R + subject to a down-monotone solvable polytope P ⊆ [0, 1] N . For this problem, we describe an algorithm producing a fractional solution of value at least 0.432 ċ f ( OPT ), where OPT is the optimal integral solution. Our second result considers the problem max{ f ( S ): | S | = k } for a non-negative symmetric submodular function f :2 N → R + . For this problem, we give an approximation ratio that depends on the value k /| N | and is always at least 0.432. Our method can also be applied to non-negative non-symmetric submodular functions, in which case it produces 1/e − o (1) approximation, improving over the best-known result for this problem. For unconstrained maximization of a non-negative symmetric submodular function, we describe a deterministic linear-time 1/2-approximation algorithm. Finally, we give a [1 − (1 − 1/ k ) k − 1 ]-approximation algorithm for Submodular Welfare with k players having identical non-negative submodular utility functions and show that this is the best possible approximation ratio for the problem.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1601868537",
    "type": "article"
  },
  {
    "title": "Optimal Partitioning for Dual-Pivot Quicksort",
    "doi": "https://doi.org/10.1145/2743020",
    "publication_date": "2015-11-17",
    "publication_year": 2015,
    "authors": "Martin Aumüller; Martin Dietzfelbinger",
    "corresponding_authors": "",
    "abstract": "Dual-pivot quicksort refers to variants of classical quicksort where in the partitioning step two pivots are used to split the input into three segments. This can be done in different ways, giving rise to different algorithms. Recently, a dual-pivot algorithm due to Yaroslavskiy received much attention, because it replaced the well-engineered quicksort algorithm in Oracle’s Java 7 runtime library. Nebel and Wild (ESA 2012) analyzed this algorithm and showed that on average it uses 1.9 n ln n + O ( n ) comparisons to sort an input of size n , beating standard quicksort, which uses 2 n ln n + O ( n ) comparisons. We introduce a model that captures all dual-pivot algorithms, give a unified analysis, and identify new dual-pivot algorithms that minimize the average number of key comparisons among all possible algorithms up to a linear term. This minimum is 1.8 n ln n + O ( n ). For the case that the pivots are chosen from a small sample, we include a comparison of dual-pivot quicksort and classical quicksort. Specifically, we show that dual-pivot quicksort benefits from a skewed choice of pivots. We experimentally evaluate our algorithms and compare them to Yaroslavskiy’s algorithm and the recently described 3-pivot quicksort algorithm of Kushagra et al. (ALENEX 2014).",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1890752145",
    "type": "article"
  },
  {
    "title": "Kernels for (Connected) Dominating Set on Graphs with Excluded Topological Minors",
    "doi": "https://doi.org/10.1145/3155298",
    "publication_date": "2018-01-03",
    "publication_year": 2018,
    "authors": "Fedor V. Fomin; Daniel Lokshtanov; Saket Saurabh; Dimitrios M. Thilikos",
    "corresponding_authors": "",
    "abstract": "We give the first linear kernels for the D ominating S et and C onnected D ominating S et problems on graphs excluding a fixed graph H as a topological minor. In other words, we prove the existence of polynomial time algorithms that, for a given H -topological-minor-free graph G and a positive integer k , output an H -topological-minor-free graph G ′ on O ( k ) vertices such that G has a (connected) dominating set of size k if and only if G ′ has one. Our results extend the known classes of graphs on which the D ominating S et and C onnected D ominating S et problems admit linear kernels. Prior to our work, it was known that these problems admit linear kernels on graphs excluding a fixed apex graph H as a minor. Moreover, for D ominating S et , a kernel of size k c ( H ) , where c ( H ) is a constant depending on the size of H , follows from a more general result on the kernelization of D ominating S et on graphs of bounded degeneracy. Alon and Gutner explicitly asked whether one can obtain a linear kernel for D ominating S et on H -minor-free graphs. We answer this question in the affirmative and in fact prove a more general result. For C onnected D ominating S et no polynomial kernel even on H -minor-free graphs was known prior to our work. On the negative side, it is known that C onnected D ominating S et on 2-degenerated graphs does not admit a polynomial kernel unless coNP ⊆ NP/poly. Our kernelization algorithm is based on a non-trivial combination of the following ingredients • The structural theorem of Grohe and Marx [STOC 2012] for graphs excluding a fixed graph H as a topological minor; • A novel notion of protrusions, different than the one defined in [FOCS 2009]; • Our results are based on a generic reduction rule that produces an equivalent instance (in case the input graph is H -minor-free) of the problem, with treewidth O (√ k ). The application of this rule in a divide-and-conquer fashion, together with the new notion of protrusions, gives us the linear kernels. A protrusion in a graph [FOCS 2009] is a subgraph of constant treewidth which is separated from the rest of the graph by at most a constant number of vertices. In our variant of protrusions, instead of stipulating that the subgraph be of constant treewidth , we ask that it contains a constant number of vertices from a solution . We believe that this new take on protrusions would be useful for other graph problems and in different algorithmic settings.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2810074797",
    "type": "article"
  },
  {
    "title": "Subtree Isomorphism Revisited",
    "doi": "https://doi.org/10.1145/3093239",
    "publication_date": "2018-06-16",
    "publication_year": 2018,
    "authors": "Amir Abboud; Artūrs Bačkurs; Thomas Dueholm Hansen; Virginia Vassilevska Williams; Or Zamir",
    "corresponding_authors": "",
    "abstract": "The Subtree Isomorphism problem asks whether a given tree is contained in another given tree. The problem is of fundamental importance and has been studied since the 1960s. For some variants, e.g., ordered trees, near-linear time algorithms are known, but for the general case truly subquadratic algorithms remain elusive. Our first result is a reduction from the Orthogonal Vectors problem to Subtree Isomorphism, showing that a truly subquadratic algorithm for the latter refutes the Strong Exponential Time Hypothesis (SETH). In light of this conditional lower bound, we focus on natural special cases for which no truly subquadratic algorithms are known. We classify these cases against the quadratic barrier, showing in particular that: Even for binary, rooted trees, a truly subquadratic algorithm refutes SETH. Even for rooted trees of depth O(loglogn), where n is the total number of vertices, a truly subquadratic algorithm refutes SETH. For every constant d, there is a constant ϵd> 0 and a randomized, truly subquadratic algorithm for degree-d rooted trees of depth at most (1 + ϵ, d)logdn. In particular, there is an 0(min{2.85h, n2}) algorithm for binary trees of depth h. Our reductions utilize new \"tree gadgets\" that are likely useful for future SETH-based lower bounds for problems on trees. Our upper bounds apply a folklore result from randomized decision tree complexity.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2949518505",
    "type": "article"
  },
  {
    "title": "Discovering Archipelagos of Tractability for Constraint Satisfaction and Counting",
    "doi": "https://doi.org/10.1145/3014587",
    "publication_date": "2017-03-06",
    "publication_year": 2017,
    "authors": "Robert Ganian; M. S. Ramanujan; Stefan Szeider",
    "corresponding_authors": "",
    "abstract": "The Constraint Satisfaction Problem (CSP) is a central and generic computational problem which provides a common framework for many theoretical and practical applications. A central line of research is concerned with the identification of classes of instances for which CSP can be solved in polynomial time; such classes are often called “islands of tractability.” A prominent way of defining islands of tractability for CSP is to restrict the relations that may occur in the constraints to a fixed set, called a constraint language , whereas a constraint language is conservative if it contains all unary relations. Schaefer’s famous Dichotomy Theorem (STOC 1978) identifies all islands of tractability in terms of tractable constraint languages over a Boolean domain of values. Since then, many extensions and generalizations of this result have been obtained. Recently, Bulatov (TOCL 2011, JACM 2013) gave a full characterization of all islands of tractability for CSP and the counting version #CSP that are defined in terms of conservative constraint languages. This article addresses the general limit of the mentioned tractability results for CSP and #CSP, that they only apply to instances where all constraints belong to a single tractable language (in general, the union of two tractable languages is not tractable). We show that we can overcome this limitation as long as we keep some control of how constraints over the various considered tractable languages interact with each other. For this purpose, we utilize the notion of a strong backdoor of a CSP instance, as introduced by Williams et al. (IJCAI 2003), which is a set of variables that when instantiated, moves the instance to an island of tractability, that is, to a tractable class of instances. We consider strong backdoors into scattered classes , consisting of CSP instances where each connected component belongs entirely to some class from a list of tractable classes. Figuratively speaking, a scattered class constitutes an archipelago of tractability . The main difficulty lies in finding a strong backdoor of given size k ; once it is found, we can try all possible instantiations of the backdoor variables and apply the polynomial time algorithms associated with the islands of tractability on the list component-wise. Our main result is an algorithm that, given a CSP instance with n variables, finds in time f ( k ) n O (1) a strong backdoor into a scattered class (associated with a list of finite conservative constraint languages) of size k or correctly decides that there is not such a backdoor. This also gives the running time for solving (#)CSP, provided that (#)CSP is polynomial-time tractable for the considered constraint languages. Our result makes significant progress towards the main goal of the backdoor-based approach to CSPs—the identification of maximal base classes for which small backdoors can be detected efficiently.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2952150057",
    "type": "article"
  },
  {
    "title": "Ramsey Spanning Trees and Their Applications",
    "doi": "https://doi.org/10.1145/3371039",
    "publication_date": "2020-03-09",
    "publication_year": 2020,
    "authors": "Ittai Abraham; Shiri Chechik; Michael Elkin; Arnold Filtser; Ofer Neiman",
    "corresponding_authors": "",
    "abstract": "The metric Ramsey problem asks for the largest subset S of a metric space that can be embedded into an ultrametric (more generally into a Hilbert space) with a given distortion. Study of this problem was motivated as a non-linear version of Dvoretzky theorem. Mendel and Naor [29] devised the so-called Ramsey Partitions to address this problem, and showed the algorithmic applications of their techniques to approximate distance oracles and ranking problems. In this article, we study the natural extension of the metric Ramsey problem to graphs, and introduce the notion of Ramsey Spanning Trees . We ask for the largest subset S ⊆ V of a given graph G =( V , E ), such that there exists a spanning tree of G that has small stretch for S . Applied iteratively, this provides a small collection of spanning trees, such that each vertex has a tree providing low stretch paths to all other vertices . The union of these trees serves as a special type of spanner, a tree-padding spanner . We use this spanner to devise the first compact stateless routing scheme with O (1) routing decision time, and labels that are much shorter than in all currently existing schemes. We first revisit the metric Ramsey problem and provide a new deterministic construction. We prove that for every k , any n -point metric space has a subset S of size at least n 1−1/ k that embeds into an ultrametric with distortion 8 k . We use this result to obtain the state-of-the-art deterministic construction of a distance oracle. Building on this result, we prove that for every k , any n -vertex graph G =( V , E ) has a subset S of size at least n 1−1/ k , and a spanning tree of G , that has stretch O ( k log log n ) between any point in S and any point in V .",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3011280253",
    "type": "article"
  },
  {
    "title": "Improved Dynamic Graph Coloring",
    "doi": "https://doi.org/10.1145/3392724",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Shay Solomon; Nicole Wein",
    "corresponding_authors": "",
    "abstract": "This article studies the fundamental problem of graph coloring in fully dynamic graphs. Since the problem of computing an optimal coloring, or even approximating it to within n 1-ε for any ε &gt; 0, is NP-hard in static graphs, there is no hope to achieve any meaningful computational results for general graphs in the dynamic setting. It is therefore only natural to consider the combinatorial aspects of dynamic coloring or alternatively, study restricted families of graphs. Toward understanding the combinatorial aspects of this problem, one may assume a black-box access to a static algorithm for C -coloring any subgraph of the dynamic graph, and investigate the trade-off between the number of colors and the number of recolorings per update step. Optimizing the number of recolorings, sometimes referred to as the recourse bound, is important for various practical applications. In WADS ’17, Barba et al. devised two complementary algorithms: for any β &gt; 0, the first (respectively, second) maintains an O(Cβn 1/β ) (respectively, O(Cβ) -coloring while recoloring O(β) (respectively, O(β n 1/β )) vertices per update. Barba et al. also showed that the second trade-off appears to exhibit the right behavior, at least for β = O(1): any algorithm that maintains a C -coloring of an n -vertex dynamic forest must recolor Ω (n 2 C(C-1)) vertices per update, for any constant C ≥ 2. Our contribution is twofold: • We devise a new algorithm for general graphs that improves significantly upon the first trade-off in a wide range of parameters: for any β &gt; 0, we get a Ô (Cβlog 2 n)-coloring with O(β) recolorings per update, where the Ô notation suppresses polyloglog(n) factors. In particular, for β = O(1), we get constant recolorings with polylog(n) colors; not only is this an exponential improvement over the previous bound but also it unveils a rather surprising phenomenon: the trade-off between the number of colors and recolorings is highly non-symmetric. • For uniformly sparse graphs, we use low out-degree orientations to strengthen the preceding result by bounding the update time of the algorithm rather than the number of recolorings. Then, we further improve this result by introducing a new data structure that refines bounded out-degree edge orientations and is of independent interest. From this data structure, we get a deterministic algorithm for graphs of arboricity ɑ that maintains an O(ɑ log 2 n)-coloring in amortized O(1) time.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3033362299",
    "type": "article"
  },
  {
    "title": "Approximating Rooted Steiner Networks",
    "doi": "https://doi.org/10.1145/2650183",
    "publication_date": "2014-10-30",
    "publication_year": 2014,
    "authors": "Joseph Cheriyan; Bundit Laekhanukit; Guyslain Naves; Adrian Vetta",
    "corresponding_authors": "",
    "abstract": "The Directed Steiner Tree (DST) problem is a cornerstone problem in network design. We focus on the generalization of the problem with higher connectivity requirements. The problem with one root and two sinks is APX-hard. The problem with one root and many sinks is as hard to approximate as the directed Steiner forest problem, and the latter is well known to be as hard to approximate as the label cover problem. Utilizing previous techniques, we strengthen these results and extend them to undirected graphs. Specifically, we give an Ω( k ϵ ) hardness bound for the rooted k -connectivity problem in undirected graphs. As a consequence, we obtain an Ω( k ϵ ) hardness bound for the undirected subset k -connectivity problem. Additionally, we give a result on the integrality ratio of the natural linear programming relaxation of the directed rooted k -connectivity problem.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2141156487",
    "type": "article"
  },
  {
    "title": "Graph Sparsification for Derandomizing Massively Parallel Computation with Low Space",
    "doi": "https://doi.org/10.1145/3451992",
    "publication_date": "2021-04-30",
    "publication_year": 2021,
    "authors": "Artur Czumaj; Peter Maxwell Davies; Merav Parter",
    "corresponding_authors": "",
    "abstract": "The Massively Parallel Computation (MPC) model is an emerging model that distills core aspects of distributed and parallel computation, developed as a tool to solve combinatorial (typically graph) problems in systems of many machines with limited space. Recent work has focused on the regime in which machines have sublinear (in n , the number of nodes in the input graph) space, with randomized algorithms presented for the fundamental problems of Maximal Matching and Maximal Independent Set. However, there have been no prior corresponding deterministic algorithms. A major challenge underlying the sublinear space setting is that the local space of each machine might be too small to store all edges incident to a single node. This poses a considerable obstacle compared to classical models in which each node is assumed to know and have easy access to its incident edges. To overcome this barrier, we introduce a new graph sparsification technique that deterministically computes a low-degree subgraph, with the additional property that solving the problem on this subgraph provides significant progress towards solving the problem for the original input graph. Using this framework to derandomize the well-known algorithm of Luby [SICOMP’86], we obtain O (log Δ + log log n )-round deterministic MPC algorithms for solving the problems of Maximal Matching and Maximal Independent Set with O ( n ɛ ) space on each machine for any constant ɛ &gt; 0. These algorithms also run in O (log Δ) rounds in the closely related model of CONGESTED CLIQUE, improving upon the state-of-the-art bound of O (log 2 Δ) rounds by Censor-Hillel et al. [DISC’17].",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3167599539",
    "type": "article"
  },
  {
    "title": "Online Algorithms for Weighted Paging with Predictions",
    "doi": "https://doi.org/10.1145/3548774",
    "publication_date": "2022-08-12",
    "publication_year": 2022,
    "authors": "Zhihao Jiang; Debmalya Panigrahi; Kevin Sun",
    "corresponding_authors": "",
    "abstract": "In this article, we initiate the study of the weighted paging problem with predictions. This continues the recent line of work in online algorithms with predictions, particularly that of Lykouris and Vassilvitski (ICML 2018) and Rohatgi (SODA 2020) on unweighted paging with predictions. We show that unlike unweighted paging, neither a fixed lookahead nor a knowledge of the next request for every page is sufficient information for an algorithm to overcome the existing lower bounds in weighted paging. However, a combination of the two, which we call strong per request prediction (SPRP), suffices to give a 2-competitive algorithm. We also explore the question of gracefully degrading algorithms with increasing prediction error, and give both upper and lower bounds for a set of natural measures of prediction error.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3036588290",
    "type": "article"
  },
  {
    "title": "A PTAS for Capacitated Vehicle Routing on Trees",
    "doi": "https://doi.org/10.1145/3575799",
    "publication_date": "2022-12-14",
    "publication_year": 2022,
    "authors": "Claire Mathieu; Hang Zhou",
    "corresponding_authors": "",
    "abstract": "We give a polynomial time approximation scheme (PTAS) for the unit demand capacitated vehicle routing problem (CVRP) on trees, for the entire range of the tour capacity. The result extends to the splittable CVRP.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3211737054",
    "type": "article"
  },
  {
    "title": "Fréchet Distance for Uncertain Curves",
    "doi": "https://doi.org/10.1145/3597640",
    "publication_date": "2023-05-23",
    "publication_year": 2023,
    "authors": "Kevin Buchin; Chenglin Fan; Maarten Löffler; Aleksandr Popov; Benjamin Raichel; Marcel Roeloffzen",
    "corresponding_authors": "",
    "abstract": "In this article, we study a wide range of variants for computing the (discrete and continuous) Fréchet distance between uncertain curves. An uncertain curve is a sequence of uncertainty regions, where each region is a disk, a line segment, or a set of points. A realisation of a curve is a polyline connecting one point from each region. Given an uncertain curve and a second (certain or uncertain) curve, we seek to compute the lower and upper bound Fréchet distance, which are the minimum and maximum Fréchet distance for any realisations of the curves. We prove that both problems are NP-hard for the Fréchet distance in several uncertainty models, and that the upper bound problem remains hard for the discrete Fréchet distance. In contrast, the lower bound (discrete [ 5 ] and continuous) Fréchet distance can be computed in polynomial time in some models. Furthermore, we show that computing the expected (discrete and continuous) Fréchet distance is #P-hard in some models. On the positive side, we present an FPTAS in constant dimension for the lower bound problem when Δ/δ is polynomially bounded, where δ is the Fréchet distance and Δ bounds the diameter of the regions. We also show a near-linear-time 3-approximation for the decision problem on roughly δ-separated convex regions. Finally, we study the setting with Sakoe–Chiba time bands, where we restrict the alignment between the curves, and give polynomial-time algorithms for the upper bound and expected discrete and continuous Fréchet distance for uncertainty modelled as point sets.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3018982745",
    "type": "article"
  },
  {
    "title": "A Polynomial-Time Algorithm for 1/3-Approximate Nash Equilibria in Bimatrix Games",
    "doi": "https://doi.org/10.1145/3606697",
    "publication_date": "2023-07-08",
    "publication_year": 2023,
    "authors": "Argyrios Deligkas; Michail Fasoulakis; Evangelos Markakis",
    "corresponding_authors": "",
    "abstract": "Since the celebrated PPAD-completeness result for Nash equilibria in bimatrix games, a long line of research has focused on polynomial-time algorithms that compute ε-approximate Nash equilibria. Finding the best possible approximation guarantee that we can have in polynomial time has been a fundamental and non-trivial pursuit on settling the complexity of approximate equilibria. Despite a significant amount of effort, the algorithm of Tsaknakis and Spirakis [ 38 ], with an approximation guarantee of (0.3393+δ), remains the state of the art over the last 15 years. In this paper, we propose a new refinement of the Tsaknakis-Spirakis algorithm, resulting in a polynomial-time algorithm that computes a \\((\\frac{1}{3}+\\delta)\\) -Nash equilibrium, for any constant δ &gt; 0. The main idea of our approach is to go beyond the use of convex combinations of primal and dual strategies, as defined in the optimization framework of [ 38 ], and enrich the pool of strategies from which we build the strategy profiles that we output in certain bottleneck cases of the algorithm.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4383619660",
    "type": "article"
  },
  {
    "title": "Parameter estimation for Gibbs distributions",
    "doi": "https://doi.org/10.1145/3685676",
    "publication_date": "2024-07-30",
    "publication_year": 2024,
    "authors": "David G. Harris; Vladimir Kolmogorov",
    "corresponding_authors": "",
    "abstract": "A central problem in computational statistics is to convert a procedure for sampling combinatorial objects into a procedure for counting those objects, and vice versa. We consider sampling problems coming from Gibbs distributions , which are families of probability distributions over a discrete space \\(\\Omega\\) with probability mass function of the form \\(\\mu^{\\Omega}_{\\beta}(\\omega)\\propto e^{\\beta H(\\omega)}\\) for \\(\\beta\\) in an interval \\([\\beta_{\\min},\\beta_{\\max}]\\) and \\(H(\\omega)\\in\\{0\\}\\cup[1,n]\\) . Two important parameters are the partition function , which is the normalization factor \\(Z(\\beta)=\\sum_{\\omega\\in\\Omega}e^{\\beta H(\\omega)}\\) , and the vector of preimage counts \\(c_{x}=|H^{-1}(x)|\\) . We develop black-box sampling algorithms to estimate the counts using roughly \\(\\tilde{O}(\\frac{n^{2}}{\\varepsilon^{2}})\\) samples for integer-valued distributions and \\(\\tilde{O}(\\frac{q}{\\varepsilon^{2}})\\) samples for general distributions, where \\(q=\\log\\frac{Z(\\beta_{\\max})}{Z(\\beta_{\\min})}\\) (ignoring some second-order terms and parameters). We show this is optimal up to logarithmic factors. We illustrate with improved algorithms for counting connected subgraphs, independent sets, and perfect matchings. As a key subroutine, we estimate all values of the partition function using \\(\\tilde{O}(\\frac{n^{2}}{\\varepsilon^{2}})\\) samples for integer-valued distributions and \\(\\tilde{O}(\\frac{q}{\\varepsilon^{2}})\\) samples for general distributions. This improves over a prior algorithm of Huber (2015) which computes a single point estimate \\(Z(\\beta_{\\max})\\) and which uses a slightly larger amount of samples. We show matching lower bounds, demonstrating this complexity is optimal as a function of \\(n\\) and \\(q\\) up to logarithmic terms.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3043925259",
    "type": "article"
  },
  {
    "title": "Ultrasparse Ultrasparsifiers and Faster Laplacian System Solvers",
    "doi": "https://doi.org/10.1145/3593809",
    "publication_date": "2024-02-02",
    "publication_year": 2024,
    "authors": "Arun Jambulapati; Aaron Sidford",
    "corresponding_authors": "",
    "abstract": "In this paper we provide an O ( m loglog O (1) n log (1/ϵ))-expected time algorithm for solving Laplacian systems on n -node m -edge graphs, improving upon the previous best expected runtime of \\(O(m \\sqrt {\\log n} \\mathrm{log log}^{O(1)} n \\log (1/\\epsilon)) \\) achieved by (Cohen, Kyng, Miller, Pachocki, Peng, Rao, Xu 2014). To obtain this result we provide efficient constructions of low spectral stretch graph approximations with improved stretch and sparsity bounds. As motivation for this work, we show that for every set of vectors in \\(\\mathbb {R}^d \\) (not just those induced by graphs) and all integer k &gt; 1 there exist an ultra-sparsifier with d − 1 + O ( d / k ) re-weighted vectors of relative condition number at most k 2 . For small k , this improves upon the previous best known multiplicative factor of \\(k \\cdot \\tilde{O}(\\log d) \\) , which is only known for the graph case. Additionally, in the graph case we employ our low-stretch subgraph construction to obtain n − 1 + O ( n / k )-edge ultrasparsifiers of relative condition number k 1 + o (1) for k = ω (log δ n ) for any δ &gt; 0: this improves upon the previous work for k = o (exp (log 1/2 − δ n )).",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3115083469",
    "type": "article"
  },
  {
    "title": "A maiden analysis of longest wait first",
    "doi": "https://doi.org/10.1145/1077464.1077467",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Jeff Edmonds; Kirk Pruhs",
    "corresponding_authors": "",
    "abstract": "We consider server scheduling strategies to minimize average flow time in a multicast pull system where data items have uniform size. The algorithm Longest Wait First (LWF) always services the page where the aggregate waiting times of the outstanding requests for that page is maximized. We provide the first non-trivial analysis of the worst case performance of LWF. On the negative side, we show that LWF is not s -speed O (1)-competitive for s &lt; 1+√5/2. On the positive side, we show that LWF is 6-speed O (1)-competitive.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W1981710280",
    "type": "article"
  },
  {
    "title": "Analysis of linear combination algorithms in cryptography",
    "doi": "https://doi.org/10.1145/1077464.1077473",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Peter J. Grabner; Clemens Heuberger; Helmut Prodinger; Jörg Μ. Thuswaldner",
    "corresponding_authors": "",
    "abstract": "Several cryptosystems rely on fast calculations of linear combinations in groups. One way to achieve this is to use joint signed binary digit expansions of small “weight.” We study two algorithms, one based on nonadjacent forms of the coefficients of the linear combination, the other based on a certain joint sparse form specifically adapted to this problem. Both methods are sped up using the sliding windows approach combined with precomputed lookup tables. We give explicit and asymptotic results for the number of group operations needed, assuming uniform distribution of the coefficients. Expected values, variances and a central limit theorem are proved using generating functions.Furthermore, we provide a new algorithm that calculates the digits of an optimal expansion of pairs of integers from left to right. This avoids storing the whole expansion, which is needed with the previously known right-to-left methods, and allows an online computation.",
    "cited_by_count": 24,
    "openalex_id": "https://openalex.org/W2029653748",
    "type": "article"
  },
  {
    "title": "The minimum generalized vertex cover problem",
    "doi": "https://doi.org/10.1145/1125994.1125998",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Refael Hassin; Asaf Levin",
    "corresponding_authors": "",
    "abstract": "Let G = ( V , E ) be an undirected graph, with three numbers d 0 ( e ) ≥ d 1 ( e ) ≥ d 2 ( e ) ≥ 0 for each edge e ∈ E . A solution is a subset U ⊆ V and d i ( e ) represents the cost contributed to the solution by the edge e if exactly i of its endpoints are in the solution. The cost of including a vertex v in the solution is c ( v ). A solution has cost that is equal to the sum of the vertex costs and the edge costs. The minimum generalized vertex cover problem is to compute a minimum cost set of vertices. We study the complexity of the problem with the costs d 0 ( e ) = 1, d 1 ( e ) = α and d 2 ( e ) = 0 ∀ e ∈ E and c ( v ) = β∀ v ∈ V , for all possible values of α and β. We also provide 2-approximation algorithms for the general case.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2002809037",
    "type": "article"
  },
  {
    "title": "Individual displacements for linear probing hashing with different insertion policies",
    "doi": "https://doi.org/10.1145/1103963.1103964",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Svante Janson",
    "corresponding_authors": "Svante Janson",
    "abstract": "We study the distribution of the individual displacements in hashing with linear probing for three different versions: First Come, Last Come and Robin Hood. Asymptotic distributions and their moments are found when the the size of the hash table tends to infinity with the proportion of occupied cells converging to some α, 0 &lt; α &lt; 1. (In the case of Last Come, the results are more complicated and less complete than in the other cases.)We also show, using the diagonal Poisson transform studied by Poblete, Viola and Munro, that exact expressions for finite m and n can be obtained from the limits as m,n → ∞.We end with some results, conjectures and questions about the shape of the limit distributions. These have some relevance for computer applications.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2014367232",
    "type": "article"
  },
  {
    "title": "Exact distribution of individual displacements in linear probing hashing",
    "doi": "https://doi.org/10.1145/1103963.1103965",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Alfredo Viola",
    "corresponding_authors": "Alfredo Viola",
    "abstract": "This paper studies the distribution of individual displacements for the standard and the Robin Hood linear probing hashing algorithms. When the a table of size m has n elements, the distribution of the search cost of a random element is studied for both algorithms. Specifically, exact distributions for fixed m and n are found as well as when the table is α-full, and α strictly smaller than 1. Moreover, for full tables, limit laws for both algorithms are derived.",
    "cited_by_count": 22,
    "openalex_id": "https://openalex.org/W2081748540",
    "type": "article"
  },
  {
    "title": "Algorithmic aspects of bandwidth trading",
    "doi": "https://doi.org/10.1145/1186810.1186820",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Randeep Bhatia; Julia Chuzhoy; Ari Freund; Joseph Naor",
    "corresponding_authors": "",
    "abstract": "We study algorithmic problems that are motivated by bandwidth trading in next-generation networks. Typically, bandwidth trading involves sellers (e.g., network operators) interested in selling bandwidth pipes that offer to buyers a guaranteed level of service for a specified time interval. The buyers (e.g., bandwidth brokers) are looking to procure bandwidth pipes to satisfy the reservation requests of end-users (e.g., Internet subscribers). Depending on what is available in the bandwidth exchange, the goal of a buyer is to either spend the least amount of money so as to satisfy all the reservations made by its customers, or to maximize its revenue from whatever reservations can be satisfied. We model this as a real-time nonpreemptive scheduling problem in which machine types correspond to bandwidth pipes and jobs correspond to end-user reservation requests. Each job specifies a time interval during which it must be processed, and a set of machine types on which it can be executed. If necessary, multiple machines of a given type may be allocated, but each must be paid for. Finally, each job has associated with it a revenue, which is realized if the job is scheduled on some machine. There are two versions of the problem that we consider. In the cost minimization version, the goal is to minimize the total cost incurred for scheduling all jobs, and in the revenue maximization version the goal is to maximize the revenue of the jobs that are scheduled for processing on a given set of machines. We consider several variants of the problems that arise in practical scenarios, and provide constant factor approximations.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2047220011",
    "type": "article"
  },
  {
    "title": "This side up!",
    "doi": "https://doi.org/10.1145/1150334.1150339",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Leah Epstein; Rob van Stee",
    "corresponding_authors": "",
    "abstract": "We consider two- and three-dimensional bin-packing problems where 90° rotations are allowed. We improve all known asymptotic performance bounds for these problems. In particular, we show how to combine ideas from strip packing and two-dimensional bin packing to give a new algorithm for the three-dimensional strip packing problem where boxes can only be rotated sideways. We propose to call this problem “This side up”. Our algorithm has an asymptotic performance bound of 9/4.",
    "cited_by_count": 20,
    "openalex_id": "https://openalex.org/W2123783040",
    "type": "article"
  },
  {
    "title": "An asymptotic approximation scheme for multigraph edge coloring",
    "doi": "https://doi.org/10.1145/1361192.1361198",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Peter Sanders; David Steurer",
    "corresponding_authors": "",
    "abstract": "The edge coloring problem considers the assignment of colors from a minimum number of colors to edges of a graph such that no two edges with the same color are incident to the same node. We give polynomial time algorithms for approximate edge coloring of multigraphs, that is, parallel edges are allowed. The best previous algorithms achieve a fixed constant approximation factor plus a small additive offset. One of our algorithms achieves solution quality opt + √9opt/2 and has execution time polynomial in the number of nodes and the logarithm of the maximum edge multiplicity.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2159044866",
    "type": "article"
  },
  {
    "title": "Finding one tight cycle",
    "doi": "https://doi.org/10.1145/1824777.1824781",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Sergio Cabello; Matt DeVos; Jeff Erickson; Bojan Mohar",
    "corresponding_authors": "",
    "abstract": "A cycle on a combinatorial surface is tight if it as short as possible in its (free) homotopy class. We describe an algorithm to compute a single tight, noncontractible, essentially simple cycle on a given orientable combinatorial surface in O ( n log n ) time. The only method previously known for this problem was to compute the globally shortest noncontractible or nonseparating cycle in O (min{ g 3 , n }, n log n ) time, where g is the genus of the surface. As a consequence, we can compute the shortest cycle freely homotopic to a chosen boundary cycle in O ( n log n ) time, a tight octagonal decomposition in O ( gn log n ) time, and a shortest contractible cycle enclosing a nonempty set of faces in O ( n log 2 n ) time.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2147508044",
    "type": "article"
  },
  {
    "title": "On the minimum common integer partition problem",
    "doi": "https://doi.org/10.1145/1435375.1435387",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Xin Chen; Lan Liu; Zheng Liu; Tao Jiang",
    "corresponding_authors": "",
    "abstract": "We introduce a new combinatorial optimization problem in this article, called the minimum common integer partition (MCIP) problem, which was inspired by computational biology applications including ortholog assignment and DNA fingerprint assembly. A partition of a positive integer n is a multiset of positive integers that add up to exactly n , and an integer partition of a multiset S of integers is defined as the multiset union of partitions of integers in S . Given a sequence of multisets S 1 , S 2 , …, S k of integers, where k ≥ 2, we say that a multiset is a common integer partition if it is an integer partition of every multiset S i , 1 ≤ i ≤ k . The MCIP problem is thus defined as to find a common integer partition of S 1 , S 2 , …, S k with the minimum cardinality, denoted as MCIP( S 1 , S 2 , …, S k ). It is easy to see that the MCIP problem is NP-hard, since it generalizes the well-known subset sum problem. We can in fact show that it is APX-hard. We will also present a 5/4-approximation algorithm for the MCIP problem when k = 2, and a 3 k ( k −1)/3 k −2-approximation algorithm for k ≥ 3.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2152018213",
    "type": "article"
  },
  {
    "title": "Exponential time algorithms for the minimum dominating set problem on some graph classes",
    "doi": "https://doi.org/10.1145/1644015.1644024",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Serge Gaspers; Dieter Kratsch; Mathieu Liedloff; Ioan Todinca",
    "corresponding_authors": "",
    "abstract": "The minimum dominating set problem remains NP-hard when restricted to any of the following graph classes: c -dense graphs, chordal graphs, 4-chordal graphs, weakly chordal graphs, and circle graphs. Developing and using a general approach, for each of these graph classes we present an exponential time algorithm solving the minimum dominating set problem faster than the best known algorithm for general graphs. Our algorithms have the following running time: O (1.4124 n ) for chordal graphs, O (1.4776 n ) for weakly chordal graphs, O (1.4845 n ) for 4-chordal graphs, O (1.4887 n ) for circle graphs, and O (1.2273 (1+√1−2 c ) n ) for c -dense graphs.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2025756084",
    "type": "article"
  },
  {
    "title": "I/O-efficient batched union-find and its applications to terrain analysis",
    "doi": "https://doi.org/10.1145/1868237.1868249",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Pankaj K. Agarwal; Lars Arge; Ke Yi",
    "corresponding_authors": "",
    "abstract": "In this article we present an I/O-efficient algorithm for the batched (off-line) version of the union-find problem. Given any sequence of N union and find operations, where each union operation joins two distinct sets, our algorithm uses O (SORT( N )) = O ( N / B log M/B N / B ) I/Os, where M is the memory size and B is the disk block size. This bound is asymptotically optimal in the worst case. If there are union operations that join a set with itself, our algorithm uses O (SORT( N ) + MST( N )) I/Os, where MST( N ) is the number of I/Os needed to compute the minimum spanning tree of a graph with N edges. We also describe a simple and practical O (SORT( N ) log( N / M ))-I/O algorithm for this problem, which we have implemented. We are interested in the union-find problem because of its applications in terrain analysis. A terrain can be abstracted as a height function defined over R 2 , and many problems that deal with such functions require a union-find data structure. With the emergence of modern mapping technologies, huge amount of elevation data is being generated that is too large to fit in memory, thus I/O-efficient algorithms are needed to process this data efficiently. In this article, we study two terrain-analysis problems that benefit from a union-find data structure: (i) computing topological persistence and (ii) constructing the contour tree. We give the first O (SORT( N ))-I/O algorithms for these two problems, assuming that the input terrain is represented as a triangular mesh with N vertices.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2046183524",
    "type": "article"
  },
  {
    "title": "Testing bipartiteness of geometric intersection graphs",
    "doi": "https://doi.org/10.1145/1497290.1497291",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "David Eppstein",
    "corresponding_authors": "David Eppstein",
    "abstract": "We show how to test the bipartiteness of an intersection graph of n line segments or simple polygons in the plane, or of balls in R^d, in time O(n log n). More generally we find subquadratic algorithms for connectivity and bipartiteness testing of intersection graphs of a broad class of geometric objects. For unit balls in R^d, connectivity testing has equivalent randomized complexity to construction of Euclidean minimum spanning trees, and hence is unlikely to be solved as efficiently as bipartiteness testing. For line segments or planar disks, testing k-colorability of intersection graphs for k>2 is NP-complete.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W2052184512",
    "type": "article"
  },
  {
    "title": "Multidimensional online tracking",
    "doi": "https://doi.org/10.1145/2151171.2151175",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Ke Yi; Qin Zhang",
    "corresponding_authors": "",
    "abstract": "We propose and study a new class of online problems, which we call online tracking . Suppose an observer, say Alice, observes a multivalued function f : Z + → Z d over time in an online fashion, that is, she only sees f ( t ) for t≤t now where t now is the current time. She would like to keep a tracker, say Bob, informed of the current value of f at all times. Under this setting, Alice could send new values of f to Bob from time to time, so that the current value of f is always within a distance of Δ to the last value received by Bob. We give competitive online algorithms whose communication costs are compared with the optimal offline algorithm that knows the entire f in advance. We also consider variations of the problem where Alice is allowed to send predictions to Bob, to further reduce communication for well-behaved functions. These online tracking problems have a variety of application, ranging from sensor monitoring, location-based services, to publish/subscribe systems.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1999582613",
    "type": "article"
  },
  {
    "title": "The smoothed complexity of edit distance",
    "doi": "https://doi.org/10.1145/2344422.2344434",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Alexandr Andoni; Robert Krauthgamer",
    "corresponding_authors": "",
    "abstract": "We initiate the study of the smoothed complexity of sequence alignment, by proposing a semi-random model of edit distance between two input strings, generated as follows: First, an adversary chooses two binary strings of length d and a longest common subsequence A of them. Then, every character is perturbed independently with probability p , except that A is perturbed in exactly the same way inside the two strings. We design two efficient algorithms that compute the edit distance on smoothed instances up to a constant factor approximation. The first algorithm runs in near-linear time, namely d {1+ϵ} for any fixed ϵ &gt; 0. The second one runs in time sublinear in d , assuming the edit distance is not too small. These approximation and runtime guarantees are significantly better than the bounds that were known for worst-case inputs. Our technical contribution is twofold. First, we rely on finding matches between substrings in the two strings, where two substrings are considered a match if their edit distance is relatively small, a prevailing technique in commonly used heuristics, such as PatternHunter of Ma et al. [2002]. Second, we effectively reduce the smoothed edit distance to a simpler variant of (worst-case) edit distance, namely, edit distance on permutations (a.k.a. Ulam's metric). We are thus able to build on algorithms developed for the Ulam metric, whose much better algorithmic guarantees usually do not carry over to general edit distance.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2076238476",
    "type": "article"
  },
  {
    "title": "Facility location with hierarchical facility costs",
    "doi": "https://doi.org/10.1145/1721837.1721853",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Zoya Svitkina; Éva Tardos",
    "corresponding_authors": "",
    "abstract": "We introduce a facility location problem with submodular facility cost functions, and give an O (log n ) approximation algorithm for it. Then we focus on a special case of submodular costs, called hierarchical facility costs, and give a (4.237 + ϵ)-approximation algorithm using local search. The hierarchical facility costs model multilevel service installation. Shmoys et al. [2004] gave a constant factor approximation algorithm for a two-level version of the problem. Here we consider a multilevel problem, and give a constant factor approximation algorithm, independent of the number of levels, for the case of identical costs on all facilities.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2621840633",
    "type": "article"
  },
  {
    "title": "A near-linear-time algorithm for computing replacement paths in planar directed graphs",
    "doi": "https://doi.org/10.1145/1824777.1824784",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Yuval Emek; David Peleg; Liam Roditty",
    "corresponding_authors": "",
    "abstract": "Let ( G = ( V(G) , E(G) )) be a directed graph with nonnegative edge lengths and let P be a shortest path from s to t in G . In the replacement paths problem we are required to compute for every edge e in P , the length of a shortest path from s to t that avoids e . The fastest known algorithm for solving the problem in weighted directed graphs is the trivial one: each edge in P is removed from the graph in its turn and the distance from s to t in the modified graph is computed. The running time of this algorithm is O ( m n + n 2 log n ), where n = | V(G) | and m = | E(G) |. The replacement paths problem is strongly motivated by two different applications. First, the fastest algorithm to compute the k simple shortest paths from s to t in directed graphs [Yen 1971; Lawler 1972] repeatedly computes the replacement paths from s to t . Its running time is O ( kn ( m + n log n )). Second, the computation of Vickrey pricing of edges in distributed networks can be reduced to the replacement paths problem. An open question raised by Nisan and Ronen [2001] asks whether it is possible to compute the Vickrey pricing faster than the trivial algorithm described in the previous paragraph. In this article we present a near-linear time algorithm for computing replacement paths in weighted planar directed graphs. In particular, the algorithm computes the lengths of the replacement paths in O ( n log 3 n ) time (recall that in planar graphs m = O ( n )). This result immediately improves the running time of the two applications mentioned before by almost a linear factor. Our algorithm is obtained by combining several new ideas with a data structure of Klein [2005] that supports multisource shortest paths queries in planar directed graphs in logarithmic time. Our algorithm can be adapted to address the variant of the problem in which one is interested in the replacement path itself (rather than the length of the path). In that case the algorithm is executed in a preprocessing stage constructing a data structure that supports replacement path queries in time Õ ( h ), where h is the number of hops in the replacement path. In addition, we can handle the variant in which vertices should be avoided instead of edges.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2992182984",
    "type": "article"
  },
  {
    "title": "Entropy, triangulation, and point location in planar subdivisions",
    "doi": "https://doi.org/10.1145/2229163.2229173",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Sébastien Collette; Vida Dujmović; John Iacono; Stefan Langerman; Pat Morin",
    "corresponding_authors": "",
    "abstract": "A data structure is presented for point location in connected planar subdivisions when the distribution of queries is known in advance. The data structure has an expected query time that is within a constant factor of optimal. More specifically, an algorithm is presented that preprocesses a connected planar subdivision G of size n and a query distribution D to produce a point location data structure for G . The expected number of point-line comparisons performed by this data structure, when the queries are distributed according to D , is H˜ + O (H˜ 1/2 +1) where H˜=H˜( G,D ) is a lower bound on the expected number of point-line comparisons performed by any linear decision tree for point location in G under the query distribution D . The preprocessing algorithm runs in O ( n log n ) time and produces a data structure of size O ( n ). These results are obtained by creating a Steiner triangulation of G that has near-minimum entropy.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W3101679532",
    "type": "article"
  },
  {
    "title": "Partial convex recolorings of trees and galled networks",
    "doi": "https://doi.org/10.1145/2000807.2000810",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Shlomo Moran; Sagi Snir; Wing‐Kin Sung",
    "corresponding_authors": "",
    "abstract": "A coloring of a graph is convex if the vertices that pertain to any color induce a connected subgraph; a partial coloring (which assigns colors to a subset of the vertices) is convex if it can be completed to a convex (total) coloring. Convex coloring has applications in fields such as phylogenetics, communication or transportation networks, etc. When a coloring of a graph is not convex, a natural question is how far it is from a convex one. This problem is denoted as convex recoloring (CR). While the initial works on CR defined and studied the problem on trees, recent efforts aim at either generalizing the underlying graphs or specializing the input colorings. In this work, we extend the underlying graph and the input coloring to partially colored galled networks. We show that although determining whether a coloring is convex on an arbitrary network is hard, it can be found efficiently on galled networks. We present a fixed parameter tractable algorithm that finds the recoloring distance of such a network whose running time is quadratic in the network size and exponential in that distance. This complexity is achieved by amortized analysis that uses a novel technique for contracting colored graphs that seems to be of independent interest.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W1991473543",
    "type": "article"
  },
  {
    "title": "Reducing Curse of Dimensionality",
    "doi": "https://doi.org/10.1145/3158232",
    "publication_date": "2018-01-03",
    "publication_year": 2018,
    "authors": "T-H. Hubert Chan; Shaofeng H.-C. Jiang",
    "corresponding_authors": "",
    "abstract": "We consider the Traveling Salesman Problem with Neighborhoods (TSPN) in doubling metrics. The goal is to find the shortest tour that visits each of a given collection of subsets (regions or neighborhoods) in the underlying metric space. We give a randomized polynomial-time approximation scheme (PTAS) when the regions are fat weakly disjoint. This notion of regions was first defined when a QPTAS was given for the problem in SODA 2010 (Chan and Elbassioni 2010). The regions are partitioned into a constant number of groups, where in each group, regions should have a common upper bound on their diameters and each region designates one point within it such that these points are far away from one another. We combine the techniques in the previous work, together with the recent PTAS for TSP (STOC 2012: Bartal, Gottlieb, and Krauthgamer 2012) to achieve a PTAS for TSPN. However, several nontrivial technical hurdles need to be overcome for applying the PTAS framework to TSPN: (1) Heuristic to detect sparse instances. In the STOC 2012 paper, a minimum spanning tree heuristic is used to estimate the portion of an optimal tour within some ball. However, for TSPN, it is not known if an optimal tour would use points inside the ball to visit regions that intersect the ball. (2) Partially cut regions in the recursion. After a sparse ball is identified by the heuristic, the PTAS framework for TSP uses dynamic programming to solve the instance restricted to the sparse ball and recurse on the remaining instance. However, for TSPN, it is an important issue to decide whether each region partially intersecting the sparse ball should be solved in the sparse instance or considered in the remaining instance. Surprisingly, we show that both issues can be resolved by conservatively making the ball in question responsible for all intersecting regions. In particular, a sophisticated charging argument is needed to bound the cost of combining tours in the recursion. Moreover, more refined procedures are used to improve the dependence of the running time on the doubling dimension k from the previous exp[( O (1)) k 2 ] (even for just TSP) to exp[2 O ( k log k ) ].",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2781784381",
    "type": "article"
  },
  {
    "title": "Deterministic Graph Exploration with Advice",
    "doi": "https://doi.org/10.1145/3280823",
    "publication_date": "2018-11-16",
    "publication_year": 2018,
    "authors": "Barun Gorain; Andrzej Pelc",
    "corresponding_authors": "",
    "abstract": "We consider the fundamental task of graph exploration. An n -node graph has unlabeled nodes, and all ports at any node of degree d are arbitrarily numbered 0,…, d −1. A mobile agent, initially situated at some starting node v , has to visit all nodes and stop. The time of the exploration is the number of edge traversals. We consider the problem of how much knowledge the agent has to have a priori , to explore the graph in a given time, using a deterministic algorithm. Following the paradigm of algorithms with advice , this a priori information (advice) is provided to the agent by an oracle , in the form of a binary string, whose length is called the size of advice . We consider two types of oracles. The instance oracle knows the entire instance of the exploration problem, i.e., the port-numbered map of the graph and the starting node of the agent in this map. The map oracle knows the port-numbered map of the graph but does not know the starting node of the agent. What is the minimum size of advice that must be given to the agent by each of these oracles, so that the agent explores the graph in a given time? We first determine the minimum size of advice to achieve exploration in polynomial time. We prove that some advice of size log log log n − c , for any constant c , is sufficient for polynomial exploration, and that no advice of size log log log n −ϕ ( n ), where ϕ is any function diverging to infinity, can help to do this. These results hold both for the instance and for the map oracles. On the other side of the spectrum, when advice is large, there are two natural time thresholds: Θ ( n 2 ) for a map oracle, and Θ ( n ) for an instance oracle. This is because, in both cases, these time benchmarks can be achieved with sufficiently large advice (advice of size O ( n log n ) suffices). We show that, with a map oracle, time Θ ( n 2 ) cannot be improved in general, regardless of the size of advice. What is then the smallest advice to achieve time Θ ( n 2 ) with a map oracle? We show that this smallest size of advice is larger than n δ , for any δ &lt; 1/3. For large advice, the situation changes significantly when we allow an instance oracle instead of a map oracle. In this case, advice of size O ( n log n ) is enough to achieve time O ( n ). Is such a large advice needed to achieve linear time? We answer this question affirmatively. Indeed, we show more: with any advice of size o ( n log n ), the time of exploration must be at least n ϵ , for any ϵ &lt; 2, and with any advice of size O ( n ), the time must be Ω( n 2 ). We finally look at Hamiltonian graphs, as for them it is possible to achieve the absolutely optimal exploration time n −1, when sufficiently large advice (of size o ( n log n )) is given by an instance oracle. We show that a map oracle cannot achieve this: regardless of the size of advice, the time of exploration must be Ω( n 2 ), for some Hamiltonian graphs. However, even for the instance oracle, with advice of size o ( n log n ), optimal time n −1 cannot be achieved: Indeed, we show that the time of exploration with such advice must sometimes exceed the optimal time n −1 by a summand n ϵ , for any ϵ &lt; 1.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2900579929",
    "type": "article"
  },
  {
    "title": "Ascending-Price Algorithms for Unknown Markets",
    "doi": "https://doi.org/10.1145/3319394",
    "publication_date": "2019-06-07",
    "publication_year": 2019,
    "authors": "Xiaohui Bei; Jugal Garg; Martin Hoefer",
    "corresponding_authors": "",
    "abstract": "We design a simple ascending-price algorithm to compute a (1 + ε)-approximate equilibrium in Arrow-Debreu markets with weak gross substitute property. It applies to an unknown market setting without exact knowledge about the number of agents, their individual utilities, and endowments. Instead, our algorithm only uses price queries to a global demand oracle. This is the first polynomial-time algorithm for most of the known tractable classes of Arrow-Debreu markets, which computes such an equilibrium with a number of calls to the demand oracle that is polynomial in log 1/ε and avoids heavy machinery such as the ellipsoid method. Demands can be real-valued functions of prices, but the oracles only return demand values of bounded precision. Due to this more realistic assumption, precision and representation of prices and demands become a major technical challenge, and we develop new tools and insights that may be of independent interest. Furthermore, we give the first polynomial-time algorithm to compute an exact equilibrium for markets with spending constraint utilities. This resolves an open problem posed by Duan and Mehlhorn.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2953218668",
    "type": "article"
  },
  {
    "title": "Completeness for First-order Properties on Sparse Structures with Algorithmic Applications",
    "doi": "https://doi.org/10.1145/3196275",
    "publication_date": "2018-12-18",
    "publication_year": 2018,
    "authors": "Jiawei Gao; Russell Impagliazzo; Antonina Kolokolova; Ryan Williams",
    "corresponding_authors": "",
    "abstract": "Properties definable in first-order logic are algorithmically interesting for both theoretical and pragmatic reasons. Many of the most studied algorithmic problems, such as Hitting Set and Orthogonal Vectors, are first-order, and the first-order properties naturally arise as relational database queries. A relatively straightforward algorithm for evaluating a property with k +1 quantifiers takes time O ( m k ) and, assuming the Strong Exponential Time Hypothesis (SETH), some such properties require O ( m k −ϵ) time for any ϵ &gt; 0. (Here, &gt; m represents the size of the input structure, i.e., the number of tuples in all relations.) We give algorithms for every first-order property that improves this upper bound to m k /2 Θ (√ log n ) , i.e., an improvement by a factor more than any poly-log, but less than the polynomial required to refute SETH. Moreover, we show that further improvement is equivalent to improving algorithms for sparse instances of the well-studied Orthogonal Vectors problem. Surprisingly, both results are obtained by showing completeness of the Sparse Orthogonal Vectors problem for the class of first-order properties under fine-grained reductions. To obtain improved algorithms, we apply the fast Orthogonal Vectors algorithm of References [3, 16]. While fine-grained reductions (reductions that closely preserve the conjectured complexities of problems) have been used to relate the hardness of disparate specific problems both within P and beyond, this is the first such completeness result for a standard complexity class.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W4235156957",
    "type": "article"
  },
  {
    "title": "Mapping Simple Polygons",
    "doi": "https://doi.org/10.1145/2700223",
    "publication_date": "2015-04-13",
    "publication_year": 2015,
    "authors": "Jérémie Chalopin; Shantanu Das; Yann Disser; Matúš Mihaľák; Peter Widmayer",
    "corresponding_authors": "",
    "abstract": "We consider the exploration of a simple polygon P by a robot that moves from vertex to vertex along edges of the visibility graph of P . The visibility graph has a vertex for every vertex of P and an edge between two vertices if they see each other—that is, if the line segment connecting them lies inside P entirely. While located at a vertex, the robot is capable of ordering the vertices it sees in counterclockwise order as they appear on the boundary, and for every two such vertices, it can distinguish whether the angle between them is convex (⩽ π) or reflex ( &gt; π). Other than that, distant vertices are indistinguishable to the robot. We assume that an upper bound on the number of vertices is known. We obtain the general result that a robot exploring any locally oriented, arc-labeled graph G can always determine the base graph of G . Roughly speaking, this is the smallest graph that cannot be distinguished by a robot from G by its observations alone, no matter how it moves. Combining this result with various other techniques allows the ability to show that a robot exploring a polygon P with the preceding capabilities is always capable of reconstructing the visibility graph of P . We also show that multiple identical, indistinguishable, and deterministic robots of this kind can always solve the weak rendezvous problem in which they need to position themselves such that they mutually see each other—for instance, such that they form a clique in the visibility graph.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1970845672",
    "type": "article"
  },
  {
    "title": "Union-Find with Constant Time Deletions",
    "doi": "https://doi.org/10.1145/2636922",
    "publication_date": "2014-08-25",
    "publication_year": 2014,
    "authors": "Stephen Alstrup; Mikkel Thorup; Inge Li Gørtz; Theis Rauhe; Uri Zwick",
    "corresponding_authors": "",
    "abstract": "A union-find data structure maintains a collection of disjoint sets under the operations makeset, union, and find. Kaplan, Shafrir, and Tarjan [SODA 2002] designed data structures for an extension of the union-find problem in which items of the sets maintained may be deleted. The cost of a delete operation in their implementations is essentially the same as the cost of a find operation; namely, O (log n ) worst-case and O (α ⌈ M / N ⌉ ( n )) amortized, where n is the number of items in the set returned by the find operation, N is the total number of makeset operations performed, M is the total number of find operations performed, and α ⌈ M / N ⌉ ( n ) is a functional inverse of Ackermann’s function. They left open the question whether delete operations can be implemented more efficiently than find operations, for example, in o (log n ) worst-case time. We resolve this open problem by presenting a relatively simple modification of the classical union-find data structure that supports delete, as well as makeset and union operations, in constant worst-case time, while still supporting find operations in O (log n ) worst-case time and O (α ⌈ M/N⌉ ( n )) amortized time. Our analysis supplies, in particular, a very concise potential-based amortized analysis of the standard union-find data structure that yields an O (α ⌈ M / N ⌉ ( n )) amortized bound on the cost of find operations. All previous potential-based analyses yielded the weaker amortized bound of O (α ⌈ M / N ⌉ ( N )). Furthermore, our tighter analysis extends to one-path variants of the path compression technique such as path splitting .",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1974993532",
    "type": "article"
  },
  {
    "title": "Minimizing Movement: Fixed-Parameter Tractability",
    "doi": "https://doi.org/10.1145/2650247",
    "publication_date": "2014-10-30",
    "publication_year": 2014,
    "authors": "Erik D. Demaine; MohammadTaghi Hajiaghayi; Dániel Marx",
    "corresponding_authors": "",
    "abstract": "We study an extensive class of movement minimization problems that arise from many practical scenarios but so far have little theoretical study. In general, these problems involve planning the coordinated motion of a collection of agents (representing robots, people, map labels, network messages, etc.) to achieve a global property in the network while minimizing the maximum or average movement (expended energy). The only previous theoretical results about this class of problems are about approximation and are mainly negative: many movement problems of interest have polynomial inapproximability. Given that the number of mobile agents is typically much smaller than the complexity of the environment, we turn to fixed-parameter tractability. We characterize the boundary between tractable and intractable movement problems in a very general setup: it turns out the complexity of the problem fundamentally depends on the treewidth of the minimal configurations. Thus, the complexity of a particular problem can be determined by answering a purely combinatorial question. Using our general tools, we determine the complexity of several concrete problems and fortunately show that many movement problems of interest can be solved efficiently.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2086019191",
    "type": "article"
  },
  {
    "title": "Semi-Streaming Set Cover",
    "doi": "https://doi.org/10.1145/2957322",
    "publication_date": "2016-11-15",
    "publication_year": 2016,
    "authors": "Yuval Emek; Adi Rosén",
    "corresponding_authors": "",
    "abstract": "This article studies the set cover problem under the semi-streaming model. The underlying set system is formalized in terms of a hypergraph G = ( V , E ) whose edges arrive one by one, and the goal is to construct an edge cover F ⊆ E with the objective of minimizing the cardinality (or cost in the weighted case) of F . We further consider a parameterized relaxation of this problem, where, given some 0 ⩽ ϵ &lt; 1, the goal is to construct an edge (1 − ϵ)-cover, namely, a subset of edges incident to all but an ϵ-fraction of the vertices (or their benefit in the weighted case). The key limitation imposed on the algorithm is that its space is limited to (poly)logarithmically many bits per vertex. Our main result is an asymptotically tight tradeoff between ϵ and the approximation ratio: We design a semi-streaming algorithm that on input hypergraph G constructs a succinct data structure D such that for every 0 ⩽ ϵ &lt; 1, an edge (1 − ϵ)-cover that approximates the optimal edge (1-)cover within a factor of f (ϵ, n ) can be extracted from D (efficiently and with no additional space requirements), where f (ϵ, n ) = { O (1/ ϵ ), if ϵ &gt; 1/√ n O (√ n ), otherwise . In particular, for the traditional set cover problem, we obtain an O (√ n -approximation. This algorithm is proved to be best possible by establishing a family (parameterized by ϵ) of matching lower bounds.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W225368127",
    "type": "article"
  },
  {
    "title": "Exact and Asymptotic Solutions of a Divide-and-Conquer Recurrence Dividing at Half",
    "doi": "https://doi.org/10.1145/3127585",
    "publication_date": "2017-10-25",
    "publication_year": 2017,
    "authors": "Hsien‐Kuei Hwang; Svante Janson; Tsung‐Hsi Tsai",
    "corresponding_authors": "",
    "abstract": "Divide-and-conquer recurrences of the form f ( n ) = f (⌊ n/2⌋ ) + f ( ⌈ n/2⌉ ) + g ( n ) ( n ⩾ 2), with g ( n ) and f (1) given, appear very frequently in the analysis of computer algorithms and related areas. While most previous methods and results focus on simpler crude approximation to the solution, we show that the solution always satisfies the simple identity f ( n ) = n P (log 2 n ) − Q ( n ) under an optimum (iff) condition on g ( n ). This form is not only an identity but also an asymptotic expansion because Q ( n ) is of a smaller order than linearity. Explicit forms for the continuous periodic function P are provided. We show how our results can be easily applied to many dozens of concrete examples collected from the literature and how they can be extended in various directions. Our method of proof is surprisingly simple and elementary but leads to the strongest types of results for all examples to which our theory applies.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2765457434",
    "type": "article"
  },
  {
    "title": "Subquadratic Kernels for Implicit 3-H <scp>itting</scp> S <scp>et</scp> and 3-S <scp>et</scp> P <scp>acking</scp> Problems",
    "doi": "https://doi.org/10.1145/3293466",
    "publication_date": "2019-01-08",
    "publication_year": 2019,
    "authors": "Fedor V. Fomin; Tien-Nam Le; Daniel Lokshtanov; Saket Saurabh; Stéphan Thomassé; Meirav Zehavi",
    "corresponding_authors": "",
    "abstract": "We consider four well-studied NP-complete packing/covering problems on graphs: F eedback V ertex S et in T ournaments (FVST), C luster V ertex D eletion (CVD), T riangle P acking in T ournaments (TPT) and I nduced P 3 -P acking . For these four problems, kernels with O ( k 2 ) vertices have been known for a long time. In fact, such kernels can be obtained by interpreting these problems as finding either a packing of k pairwise disjoint sets of size 3 (3-S et P acking ) or a hitting set of size at most k for a family of sets of size at most 3 (3-H itting S et ). In this article, we give the first kernels for FVST, CVD, TPT, and I nduced P 3 -P acking with a subquadratic number of vertices. Specifically, we obtain the following results. • FVST admits a kernel with O ( k 3/2 ) vertices. • CVD admits a kernel with O ( k 5/3 ) vertices. • TPT admits a kernel with O ( k 3/2 ) vertices. • I nduced P 3 -P acking admits a kernel with O ( k 5/3 ) vertices. Our results resolve an open problem from WorKer 2010 on the existence of kernels with O( k 2−ϵ ) vertices for FVST and CVD. All of our results are based on novel uses of old and new “expansion lemmas” and a weak form of crown decomposition where (i) almost all of the head is used by the solution (as opposed to all ), (ii) almost none of the crown is used by the solution (as opposed to none ), and (iii) if H is removed from G , then there is almost no interaction between the head and the rest (as opposed to no interaction at all).",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2777065051",
    "type": "article"
  },
  {
    "title": "Tight Bounds for Online TSP on the Line",
    "doi": "https://doi.org/10.1145/3422362",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Antje Bjelde; Jan Hackfeld; Yann Disser; Christoph Hansknecht; Maarten Lipmann; Julie Meißner; Miriam Schlöter; Kevin Schewior; Leen Stougie",
    "corresponding_authors": "",
    "abstract": "We consider the online traveling salesperson problem (TSP), where requests appear online over time on the real line and need to be visited by a server initially located at the origin. We distinguish between closed and open online TSP, depending on whether the server eventually needs to return to the origin or not. While online TSP on the line is a very natural online problem that was introduced more than two decades ago, no tight competitive analysis was known to date. We settle this problem by providing tight bounds on the competitive ratios for both the closed and the open variant of the problem. In particular, for closed online TSP, we provide a 1.64-competitive algorithm, thus matching a known lower bound. For open online TSP, we give a new upper bound as well as a matching lower bound that establish the remarkable competitive ratio of 2.04. Additionally, we consider the online D IAL -A-R IDE problem on the line, where each request needs to be transported to a specified destination. We provide an improved non-preemptive lower bound of 1.75 for this setting, as well as an improved preemptive algorithm with competitive ratio 2.41. Finally, we generalize known and give new complexity results for the underlying offline problems. In particular, we give an algorithm with running time O ( n 2 ) for closed offline TSP on the line with release dates and show that both variants of offline D IAL -A-R IDE on the line are NP-hard for any capacity c ≥ 2 of the server.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W3115340459",
    "type": "article"
  },
  {
    "title": "Maximum Quadratic Assignment Problem",
    "doi": "https://doi.org/10.1145/2629672",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Konstantin Makarychev; Rajsekar Manokaran; Maxim Sviridenko",
    "corresponding_authors": "",
    "abstract": "We show that for every positive ε &gt; 0, unless NP ⊂ BPQP, it is impossible to approximate the maximum quadratic assignment problem within a factor better than 2 log 1-ε n by a reduction from the maximum label cover problem. Our result also implies that Approximate Graph Isomorphism is not robust and is, in fact, 1 - ε versus ε hard assuming the Unique Games Conjecture. Then, we present an O (√n)-approximation algorithm for the problem based on rounding of the linear programming relaxation often used in state-of-the-art exact algorithms.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1501441759",
    "type": "article"
  },
  {
    "title": "A New Approach to Online Scheduling",
    "doi": "https://doi.org/10.1145/2996800",
    "publication_date": "2016-12-21",
    "publication_year": 2016,
    "authors": "Elisabeth Lübbecke; Olaf Maurer; Nicole Megow; Andreas Wiese",
    "corresponding_authors": "",
    "abstract": "We propose a new approach to competitive analysis in online scheduling by introducing the novel concept of competitive-ratio approximation schemes. Such a scheme algorithmically constructs an online algorithm with a competitive ratio arbitrarily close to the best possible competitive ratio for any online algorithm. We study the problem of scheduling jobs online to minimize the weighted sum of completion times on parallel, related, and unrelated machines, and we derive both deterministic and randomized algorithms that are almost best possible among all online algorithms of the respective settings. We also generalize our techniques to arbitrary monomial cost functions and apply them to the makespan objective. Our method relies on an abstract characterization of online algorithms combined with various simplifications and transformations. We also contribute algorithmic means to compute the actual value of the best possible competitive ratio up to an arbitrary accuracy. This strongly contrasts with nearly all previous manually obtained competitiveness results, and, most importantly, it reduces the search for the optimal competitive ratio to a question that a computer can answer. We believe that our concept can also be applied to many other problems and yields a new perspective on online algorithms in general.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1623410360",
    "type": "article"
  },
  {
    "title": "Dynamic programming for graphs on surfaces",
    "doi": "https://doi.org/10.1145/2556952",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Juanjo Rué; Ignasi Sau; Dimitrios M. Thilikos",
    "corresponding_authors": "",
    "abstract": "We provide a framework for the design and analysis of dynamic programming algorithms for surface-embedded graphs on n vertices and branchwidth at most k . Our technique applies to general families of problems where standard dynamic programming runs in 2 O ( k ⋅log k ) ⋅ n steps. Our approach combines tools from topological graph theory and analytic combinatorics. In particular, we introduce a new type of branch decomposition called surface cut decomposition , generalizing sphere cut decompositions of planar graphs, which has nice combinatorial properties. Namely, the number of partial solutions that can be arranged on a surface cut decomposition can be upper-bounded by the number of noncrossing partitions on surfaces with boundary. It follows that partial solutions can be represented by a single-exponential (in the branchwidth k ) number of configurations. This proves that, when applied on surface cut decompositions, dynamic programming runs in 2 O ( k ) ⋅ n steps. That way, we considerably extend the class of problems that can be solved in running times with a single-exponential dependence on branchwidth and unify/improve most previous results in this direction.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1826939887",
    "type": "article"
  },
  {
    "title": "A logarithmic approximation for unsplittable flow on line graphs",
    "doi": "https://doi.org/10.1145/2532645",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "Nikhil Bansal; Zachary Friggstad; Rohit Khandekar; Mohammad R. Salavatipour",
    "corresponding_authors": "",
    "abstract": "We consider the unsplittable flow problem on a line. In this problem, we are given a set of n tasks, each specified by a start time s i , an end time t i , a demand d i &gt; 0, and a profit p i &gt; 0. A task, if accepted, requires d i units of “bandwidth” from time s i to t i and accrues a profit of p i . For every time t , we are also specified the available bandwidth c t , and the goal is to find a subset of tasks with maximum profit subject to the bandwidth constraints. We present the first polynomial time O (log n ) approximation algorithm for this problem. This significantly advances the state of the art, as no polynomial time o ( n ) approximation was known previously. Previous results for this problem were known only in more restrictive settings; in particular, either the instance satisfies the so-called “no-bottleneck” assumption: max i d i ≤ min t c t , or the ratio of both maximum to minimum demands and maximum to minimum capacities are polynomially (or quasi-polynomially) bounded in n . Our result, on the other hand, does not require these assumptions. Our algorithm is based on a combination of dynamic programming and rounding a natural linear programming relaxation for the problem. While there is an Ω( n ) integrality gap known for this LP relaxation, our key idea is to exploit certain structural properties of the problem to show that instances that are bad for the LP can in fact be handled using dynamic programming.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2126874118",
    "type": "article"
  },
  {
    "title": "SETH-based Lower Bounds for Subset Sum and Bicriteria Path",
    "doi": "https://doi.org/10.1145/3450524",
    "publication_date": "2022-01-23",
    "publication_year": 2022,
    "authors": "Amir Abboud; Karl Bringmann; Danny Hermelin; Dvir Shabtay",
    "corresponding_authors": "",
    "abstract": "Subset Sumand k -SAT are two of the most extensively studied problems in computer science, and conjectures about their hardness are among the cornerstones of fine-grained complexity. An important open problem in this area is to base the hardness of one of these problems on the other. Our main result is a tight reduction from k -SAT to Subset Sum on dense instances, proving that Bellman’s 1962 pseudo-polynomial O * ( T )-time algorithm for Subset Sum on n numbers and target T cannot be improved to time T 1-ε · 2 o(n) for any ε &gt; 0, unless the Strong Exponential Time Hypothesis (SETH) fails. As a corollary, we prove a “Direct-OR” theorem for Subset Sum under SETH, offering a new tool for proving conditional lower bounds: It is now possible to assume that deciding whether one out of N given instances of Subset Sum is a YES instance requires time ( N T ) 1-o(1) . As an application of this corollary, we prove a tight SETH-based lower bound for the classical Bicriteria s,t -Path problem, which is extensively studied in Operations Research. We separate its complexity from that of Subset Sum: On graphs with m edges and edge lengths bounded by L , we show that the O ( Lm ) pseudo-polynomial time algorithm by Joksch from 1966 cannot be improved to Õ( L + m ), in contrast to a recent improvement for Subset Sum (Bringmann, SODA 2017).",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W4207048092",
    "type": "article"
  },
  {
    "title": "On Two-Handed Planar Assembly Partitioning with Connectivity Constraints",
    "doi": "https://doi.org/10.1145/3711823",
    "publication_date": "2025-01-10",
    "publication_year": 2025,
    "authors": "Pankaj K. Agarwal; Boris Aronov; Tzvika Geft; Dan Halperin",
    "corresponding_authors": "",
    "abstract": "Assembly planning is a fundamental problem in robotics and automation, which involves designing a sequence of motions to bring the separate constituent parts of a product into their final placement in the product. Assembly planning is naturally cast as a disassembly problem, giving rise to the assembly partitioning subproblem: Given a set \\(A\\) of parts, find a subset \\(S\\subset A\\) , referred to as a subassembly, such that \\(S\\) can be rigidly translated to infinity along a prescribed direction without colliding with \\(A\\setminus S\\) . While assembly partitioning is efficiently solvable, it is further desirable for the parts of a subassembly to be easily held together. This motivates the problem that we study, called connected-assembly-partitioning , which additionally requires each of the two subassemblies, \\(S\\) and \\(A\\setminus S\\) , to be connected. We obtain the following results. We show that this problem is NP-complete, settling an open question posed by Wilson et al. (1995) a quarter of a century ago, even when \\(A\\) consists of unit-grid squares (i.e., \\(A\\) is polyomino-shaped). For assemblies composed of polygons, we also show that deciding whether complete (dis)assembly is possible by repeatedly applying connected-assembly-partitioning, is NP-complete. Towards these results, we prove the NP-hardness of a new Planar 3-SAT variant having an adjacency requirement for variables appearing in the same clause, which may be of independent interest. On the positive side, we give an \\(O(2^{k}n^{2})\\) -time fixed-parameter tractable algorithm (requiring low degree polynomial-time preprocessing) for an assembly \\(A\\) consisting of polygons in the plane, where \\(n=|A|\\) and \\(k=|S|\\) . We also describe a special case of unit-grid square assemblies, where a connected partition can always be found in \\(O(n)\\) -time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406242852",
    "type": "article"
  },
  {
    "title": "Online Lewis Weight Sampling",
    "doi": "https://doi.org/10.1145/3715127",
    "publication_date": "2025-01-28",
    "publication_year": 2025,
    "authors": "David P. Woodruff; Taisuke Yasuda",
    "corresponding_authors": "",
    "abstract": "The seminal work of Cohen and Peng [10] (STOC 2015) introduced Lewis weight sampling to the theoretical computer science community, which yields fast row sampling algorithms for approximating \\(d\\) -dimensional subspaces of \\(\\ell_{p}\\) up to \\((1+ \\varepsilon)\\) relative error. Prior works have extended this important primitive to other settings, such as the online coreset and sliding window models [4] (FOCS 2020). However, these results are only for \\(p\\in\\{1,2\\}\\) , and results for \\(p=1\\) require a suboptimal \\(\\tilde{O}(d^{2}/\\varepsilon^{2})\\) samples. In this work, we design the first nearly optimal \\(\\ell_{p}\\) subspace embeddings for all \\(p\\in(0,\\infty)\\) in the online coreset and sliding window models. In both models, our algorithms store \\(\\tilde{O}(d/\\varepsilon^{2})\\) rows for \\(p\\in(0,2)\\) and \\(\\tilde{O}(d^{p/2}/\\varepsilon^{2})\\) rows for \\(p\\in(2,\\infty)\\) . This answers a substantial generalization of the main open question of [4], gives the first results for all \\(p\\notin\\{1,2\\}\\) , and achieves nearly optimal sample complexities for all \\(p\\) . Towards our result, we give the first analysis of “one-shot” Lewis weight sampling of sampling rows proportionally to their Lewis weights, which gives a sample complexity of \\(\\tilde{O}(d^{p/2}/\\varepsilon^{2})\\) rows for \\(p&gt;2\\) . Previously, such a sampling scheme was only known to have a sample complexity of \\(\\tilde{O}(d^{p/2}/\\varepsilon^{5})\\) [10], whereas a bound of \\(\\tilde{O}(d^{p/2}/\\varepsilon^{2})\\) is known if a more sophisticated recursive sampling algorithm is used [20, 32]. Note that the recursive sampling strategy cannot be implemented in an online setting, thus necessitating an analysis of one-shot Lewis weight sampling. Perhaps surprisingly, our analysis crucially uses a novel connection to online numerical linear algebra, even for offline Lewis weight sampling . As an application, we obtain the first online coreset algorithms for \\((1+\\varepsilon)\\) approximation of important generalized linear models, such as logistic regression and \\(p\\) -probit regression. Our upper bounds are parameterized by a complexity parameter \\(\\mu\\) introduced by [31], and we also provide the first lower bounds showing that a linear dependence on \\(\\mu\\) is necessary.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406903580",
    "type": "article"
  },
  {
    "title": "Popular Arborescences and Their Matroid Generalization",
    "doi": "https://doi.org/10.1145/3715329",
    "publication_date": "2025-01-28",
    "publication_year": 2025,
    "authors": "Telikepalli Kavitha; Kazuhisa Makino; Ildikó Schlotter; Yu Yokoi",
    "corresponding_authors": "",
    "abstract": "Consider a directed, rooted graph \\(G=(V\\cup\\{r\\},E)\\) where each vertex in \\(V\\) has a partial order preference over its incoming edges. The preferences of a vertex naturally extend to preferences over arborescences rooted at \\(r\\) . We present a polynomial-time algorithm that decides whether a given input instance admits a popular arborescence, i.e., one for which there is no “more popular” arborescence. In fact, our algorithm solves the more general popular common base problem in the intersection of two matroids: we are given an arbitrary matroid \\(M=(E,\\mathcal{I})\\) and a partition matroid \\(M_{\\text{part}}\\) over \\(E\\) , where partition classes correspond to a set \\(V\\) of agents with \\(|V|={\\rm rank}(M)\\) and each agent has a partial order preference over its associated partition class; the problem asks for a common base of \\(M\\) and \\(M_{\\text{part}}\\) such that there is no “more popular” common base. Our algorithm is combinatorial, and can be regarded as a primal–dual algorithm. It searches for a solution along with its dual certificate, a chain of subsets of \\(E\\) , witnessing its popularity. Our generalized results, expressed in terms of matroids, demonstrate that the identification of agents with vertices of the graph in the popular arborescence problem is not essential. We also study the related popular common independent set problem. For the case with weak rankings, we formulate the popular common independent set polytope, and thus show that a minimum-cost popular common independent set can be computed efficiently. By contrast, we prove that it is \\(\\mathsf{NP}\\) -hard to compute a minimum-cost popular arborescence, even when rankings are strict.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406903828",
    "type": "article"
  },
  {
    "title": "Rerouting Planar Curves and Disjoint Paths",
    "doi": "https://doi.org/10.1145/3715694",
    "publication_date": "2025-01-29",
    "publication_year": 2025,
    "authors": "Takehiro Ito; Yuni Iwamasa; Naonori Kakimura; Yusuke Kobayashi; Shun‐ichi Maezawa; Yuta Nozaki; Yoshio Okamoto; Kenta Ozeki",
    "corresponding_authors": "",
    "abstract": "In this paper, we consider a transformation of \\(k\\) disjoint paths in a graph. For a graph and a pair of \\(k\\) disjoint paths \\(\\mathcal{P}\\) and \\(\\mathcal{Q}\\) connecting the same set of terminal pairs, we aim to determine whether \\(\\mathcal{P}\\) can be transformed to \\(\\mathcal{Q}\\) by repeatedly replacing one path with another path so that the intermediates are also \\(k\\) disjoint paths. The problem is called Disjoint Paths Reconfiguration . We first show that Disjoint Paths Reconfiguration is \\(\\mathsf{PSPACE}\\) -complete even when \\(k=2\\) . On the other hand, we prove that, when the graph is embedded on a plane and all paths in \\(\\mathcal{P}\\) and \\(\\mathcal{Q}\\) connect the boundaries of two faces, Disjoint Paths Reconfiguration can be solved in polynomial time. The algorithm is based on a topological characterization for rerouting curves on a plane using the algebraic intersection number. We also consider a transformation of disjoint \\(s\\) - \\(t\\) paths as a variant. We show that the disjoint \\(s\\) - \\(t\\) paths reconfiguration problem in planar graphs can be determined in polynomial time, while the problem is \\(\\mathsf{PSPACE}\\) -complete in general.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4406956707",
    "type": "article"
  },
  {
    "title": "Intersection Queries for Flat Semi-Algebraic Objects in Three Dimensions and Related Problems",
    "doi": "https://doi.org/10.1145/3721290",
    "publication_date": "2025-03-11",
    "publication_year": 2025,
    "authors": "Pankaj K. Agarwal; Boris Aronov; Esther Ezra; Matthew J. Katz; Micha Sharir",
    "corresponding_authors": "",
    "abstract": "Let \\(\\mathcal{T}\\) be a set of \\(n\\) flat (planar) semi-algebraic regions in \\(\\mathbb{R}^{3}\\) of constant complexity (e.g., triangles, disks), which we call plates . We wish to preprocess \\(\\mathcal{T}\\) into a data structure so that for a query object \\(\\gamma\\) , which is also a plate, we can quickly answer various intersection queries , such as detecting whether \\(\\gamma\\) intersects any plate of \\(\\mathcal{T}\\) , reporting all the plates intersected by \\(\\gamma\\) , or counting them. We also consider two simpler cases of this general setting: (i) the input objects are plates and the query objects are constant-degree parametrized algebraic arcs in \\(\\mathbb{R}^{3}\\) ( arcs , for short), or (ii) the input objects are arcs and the query objects are plates in \\(\\mathbb{R}^{3}\\) . Besides being interesting in their own right, the data structures for these two special cases form the building blocks for handling the general case. By combining the polynomial-partitioning technique with additional tools from real algebraic geometry, we present many different data structures for intersection queries, which also provide trade-offs between their size and query time. For example, if \\(\\mathcal{T}\\) is a set of plates and the query objects are algebraic arcs, we obtain a data structure that uses \\(O^{*}(n^{4/3})\\) storage (where the \\(O^{*}(\\cdot)\\) notation hides factors of the form \\(n^{\\varepsilon}\\) , for an arbitrarily small \\(\\varepsilon&gt;0\\) ) and answers an arc-intersection query in \\(O^{*}(n^{2/3})\\) time. This result is significant since the exponents do not depend on the specific shape of the input and query objects. We generalize and slightly improve this result: for a parameter \\(s\\in[n^{4/3},n^{t_{q}}]\\) , where \\({t_{q}}\\geq 3\\) is the number of real parameters needed to specify a query arc, the query time can be decreased to \\(O^{*}((n/s^{1/{t_{q}}})^{\\tfrac{2/3}{1-1/{t_{q}}}})\\) by increasing the storage to \\(O^{*}(s)\\) . Our approach can be extended to many additional intersection-searching problems in three dimensions, even when the input or query objects are not flat.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408327032",
    "type": "article"
  },
  {
    "title": "New Menger-Like Dualities in Digraphs and Applications to Half-Integral Linkages",
    "doi": "https://doi.org/10.1145/3724120",
    "publication_date": "2025-03-19",
    "publication_year": 2025,
    "authors": "Víctor Campos; Jonas Costa; Raul Lopes; Ignasi Sau",
    "corresponding_authors": "",
    "abstract": "We present new min-max relations in digraphs between the number of paths satisfying certain conditions and the order of the corresponding cuts. We define these objects in order to capture, in the context of solving the half-integral linkage problem, the essential properties needed for reaching a large bramble of constant congestion from the terminal set. This strategy has been used ad-hoc in several articles, usually with lengthy technical proofs, and our objective is to abstract it to make it applicable in a simpler and unified way. We provide two proofs of the min-max relations, one consisting in applying Menger’s Theorem on appropriately defined digraphs, and an alternative simpler one using matroids, however with worse polynomial running time. As an application, we manage to simplify and improve several results of Edwards et al. [ESA 2017] and of Giannopoulou et al. [SODA 2022] about finding half-integral linkages in digraphs. Concerning the former, besides being simpler, our proof provides an almost optimal bound on the strong connectivity of a digraph for it to be half-integrally feasible under the presence of a large bramble of congestion two (or equivalently, if the directed tree-width is large). Concerning the latter, our proof uses brambles as rerouting objects instead of cylindrical grids, hence yielding much better bounds and being somehow independent of a particular topology. We hope that our min-max relations will find further applications as, in our opinion, they are simple, robust, and versatile to be easily applicable to different types of routing problems in digraphs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408591186",
    "type": "article"
  },
  {
    "title": "Conditional Lower Bounds for Dynamic Geometric Measure Problems",
    "doi": "https://doi.org/10.1145/3727878",
    "publication_date": "2025-04-08",
    "publication_year": 2025,
    "authors": "Justin Dallant; John Iacono",
    "corresponding_authors": "",
    "abstract": "We give new polynomial lower bounds for a number of dynamic measure problems in computational geometry. These lower bounds hold in the Word-RAM model, conditioned on the hardness of either 3SUM, APSP, or the Online Matrix-Vector Multiplication problem [Henzinger et al., STOC 2015]. In particular we get lower bounds in the incremental and fully-dynamic settings for counting maximal or extremal points in \\(\\mathbb{R}^{3}\\) , different variants of Klee’s Measure Problem, problems related to finding the largest empty disk in a set of points, and querying the size of the \\(i\\) ’th convex layer in a planar set of points. We also answer a question of Chan et al. [SODA 2022] by giving a conditional lower bound for dynamic approximate square set cover. While many conditional lower bounds for dynamic data structures have been proven since the seminal work of Pătraşcu [STOC 2010], few of them relate to computational geometry problems. This is the first paper focusing on this topic. Most problems we consider can be solved in \\(O(n\\log n)\\) time in the static case and their dynamic versions have only been approached from the perspective of improving known upper bounds. One exception to this is Klee’s measure problem in \\(\\mathbb{R}^{2}\\) , for which Chan [CGTA 2010] gave an unconditional \\(\\Omega(\\sqrt{n})\\) lower bound on the worst-case update time in a variant of the Word RAM machine with large words. By a similar approach, we show that such a lower bound also holds for an important special case of Klee’s measure problem in \\(\\mathbb{R}^{3}\\) known as the Hypervolume Indicator problem, even for amortized runtime in the incremental setting.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409257253",
    "type": "article"
  },
  {
    "title": "Near-optimal Algorithms for Stochastic Online Bin Packing",
    "doi": "https://doi.org/10.1145/3728642",
    "publication_date": "2025-04-11",
    "publication_year": 2025,
    "authors": "Nikhil Ayyadevara; Rajni Dabas; Arindam Khan; Kidambi Sreenivas",
    "corresponding_authors": "",
    "abstract": "We study the online bin packing problem under two stochastic settings. In the bin packing problem, we are given \\(n\\) items with sizes in \\((0,1]\\) and the goal is to pack them into the minimum number of unit-sized bins. First, we study bin packing under the i.i.d. model, where item sizes are sampled independently and identically from a distribution in \\((0,1]\\) . Both the distribution and the total number of items are unknown. The items arrive one by one and their sizes are revealed upon their arrival and they must be packed immediately and irrevocably in bins of size \\(1\\) . We provide a simple meta-algorithm that takes an offline \\(\\alpha\\) -asymptotic approximation algorithm and provides a polynomial-time \\((\\alpha+\\epsilon)\\) -competitive algorithm for online bin packing under the i.i.d. model, where \\(\\epsilon{\\gt}0\\) is a small constant. Using the AFPTAS for offline bin packing, we thus provide a linear time \\((1+\\epsilon)\\) -competitive algorithm for online bin packing under i.i.d. model, thus settling the problem. We then study the random-order model, where an adversary chooses the instance, but the order of arrival of items in the instance is drawn uniformly at random from the set of all permutations of the items. Kenyon’s seminal result [SODA ’96] showed that the Best-Fit algorithm has a competitive ratio of at most \\(3/2\\) in the random-order model, and conjectured the ratio to be \\(\\approx 1.15\\) . However, it has been a long-standing open problem to break the barrier of \\(3/2\\) even for special cases. Recently, Albers et al. [Algorithmica ’21] showed an improvement by proving that in the special case when all the item sizes are greater than \\(1/3\\) , Best-Fit has a competitive ratio of at most \\(5/4\\) in the random-order model. In this work, we settle this special case by showing that Best-Fit has a competitive ratio of exactly \\(1\\) , i.e., Best-Fit performs almost optimally in this special case in the random-order model. We also make further progress by breaking the barrier of \\(3/2\\) for the 3-Partition problem, a notoriously hard special case of bin packing, where all item sizes lie in \\((1/4,1/2]\\) .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409359461",
    "type": "article"
  },
  {
    "title": "Tight Complexity Bounds for Counting Generalized Dominating Sets in Bounded-Treewidth Graphs",
    "doi": "https://doi.org/10.1145/3731452",
    "publication_date": "2025-04-21",
    "publication_year": 2025,
    "authors": "Jacob Focke; Dániel Marx; Fionn Mc Inerney; Daniel Neuen; Govind S. Sankar; Philipp Schepper; Philip Wellnitz",
    "corresponding_authors": "",
    "abstract": "We investigate how efficiently a well-studied family of domination-type problems can be solved on bounded-treewidth graphs. For sets \\(\\sigma,\\rho\\) of non-negative integers, a \\((\\sigma,\\rho)\\) -set of a graph \\(G\\) is a set \\(S\\) of vertices such that \\(|N(u)\\cap S|\\in\\sigma\\) for every \\(u\\in S\\) , and \\(|N(v)\\cap S|\\in\\rho\\) for every \\(v\\not\\in S\\) . The problem of finding a \\((\\sigma,\\rho)\\) -set (of a certain size) unifies standard problems such as Independent Set , Dominating Set , Independent Dominating Set , and many others. For all pairs of finite or cofinite sets \\((\\sigma,\\rho)\\) , we determine (under standard complexity assumptions) the best possible value \\(c_{\\sigma,\\rho}\\) such that there is an algorithm that counts \\((\\sigma,\\rho)\\) -sets in time \\(c_{\\sigma,\\rho}^{\\rm{tw}} \\cdot n^{O(1)}\\) (if a tree decomposition of width \\(\\rm{tw}\\) is given in the input). Let \\(s_{\\rm{top}}\\) denote the largest element of \\(\\sigma\\) if \\(\\sigma\\) is finite, or the largest missing integer \\(+1\\) if \\(\\sigma\\) is cofinite; \\(r_{\\rm{top}}\\) is defined analogously for \\(\\rho\\) . Surprisingly, \\(c_{\\sigma,\\rho}\\) is often significantly smaller than the natural bound \\(s_{\\rm{top}}+r_{\\rm{top}}+2\\) achieved by existing algorithms [van Rooij, 2020]. Toward defining \\(c_{\\sigma,\\rho}\\) , we say that \\((\\sigma,\\rho)\\) is m-structured if there is a pair \\((\\alpha,\\beta)\\) such that every integer in \\(\\sigma\\) equals \\(\\alpha\\) mod m, and every integer in \\(\\rho\\) equals \\(\\beta\\) mod m. Then, setting — \\(c_{\\sigma,\\rho}=s_{\\rm{top}}+r_{\\rm{top}}+2\\) if \\((\\sigma,\\rho)\\) is not m-structured for any \\(\\rm{m}\\geq 2\\) , — \\(c_{\\sigma,\\rho}=\\max\\{s_{\\rm{top}},r_{\\rm{top}}\\}+2\\) if \\((\\sigma,\\rho)\\) is 2-structured, but not \\(\\rm{m}\\) -structured for any \\(\\rm{m}\\geq 3\\) , and \\(s_{\\rm{top}}=r_{\\rm{top}}\\) is even, and — \\(c_{\\sigma,\\rho}=\\max\\{s_{\\rm{top}},r_{\\rm{top}}\\}+1\\) , otherwise, we provide algorithms counting \\((\\sigma,\\rho)\\) -sets in time \\(c_{\\sigma,\\rho}^{\\rm{tw}}\\cdot n^{O(1)}\\) . For example, for the Exact Independent Dominating Set problem (also known as Perfect Code ) corresponding to \\(\\sigma=\\{0\\}\\) and \\(\\rho=\\{1\\}\\) , this improves the \\(3^{\\rm{tw}}\\cdot n^{O(1)}\\) algorithm of van Rooij to \\(2^{\\rm{tw}}\\cdot n^{O(1)}\\) . Despite the unusually delicate definition of \\(c_{\\sigma,\\rho}\\) , an accompanying paper shows that our algorithms are most likely optimal, that is, for any pair \\((\\sigma,\\rho)\\) of finite or cofinite sets where the problem is non-trivial, and any \\(\\varepsilon&gt;0\\) , a \\((c_{\\sigma,\\rho}-\\varepsilon)^{\\rm{tw}}\\cdot n^{O(1)}\\) -algorithm counting the number of \\((\\sigma,\\rho)\\) -sets would violate the Counting Strong Exponential-Time Hypothesis (#SETH). For finite sets \\(\\sigma\\) and \\(\\rho\\) , these lower bounds also extend to the decision version, and hence, our algorithms are optimal in this setting as well. In contrast, for many cofinite sets, we show that further significant improvements for the decision and optimization versions are possible using the technique of representative sets.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4409643765",
    "type": "article"
  },
  {
    "title": "A <i>O</i> (log <i>k</i> )-Approximation for Directed Steiner Tree in Planar Graphs",
    "doi": "https://doi.org/10.1145/3734525",
    "publication_date": "2025-05-07",
    "publication_year": 2025,
    "authors": "Zachary Friggstad; Ramin Mousavi",
    "corresponding_authors": "",
    "abstract": "We present a \\(O(\\log k)\\) -approximation for both the edge-weighted and node-weighted versions of Directed Steiner Tree in planar graphs where \\(k\\) is the number of terminals. We extend our approach to Multi-Rooted Directed Steiner Tree 1 , in which we get a \\(O(R+\\log k)\\) -approximation for planar graphs for which \\(R\\) is the number of roots 2 .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410156455",
    "type": "article"
  },
  {
    "title": "Almost Consistent Systems of Linear Equations",
    "doi": "https://doi.org/10.1145/3733107",
    "publication_date": "2025-05-09",
    "publication_year": 2025,
    "authors": "Konrad K. Dabrowski; Peter Jönsson; Sebastian Ordyniak; Г. А. Осипов; Magnus Wahlström",
    "corresponding_authors": "",
    "abstract": "Checking whether a system of linear equations is consistent is a basic computational problem with ubiquitous applications. When dealing with inconsistent systems, one may seek an assignment that minimises the number of unsatisfied equations. This problem is NP -hard and UGC-hard to approximate within any constant even for two-variable equations over the two-element field. We study this problem from the point of view of parameterized complexity, with the parameter being the number of unsatisfied equations. We consider equations defined over a family of commutative domains (i.e. rings without zero divisors) with a particular Helly property. This set contains, for instance, finite and infinite fields, the ring of integers, and univariate polynomial rings with coefficients from a field; more generally, it contains the important class of Prüfer domains. We show that if every equation contains at most two variables, the problem is fixed-parameter tractable. This generalises many eminent graph separation problems such as Bipartization, Multiway Cut and Multicut parameterized by the size of the cutset. To complement this, we show that the problem is W [1]-hard when three or more variables are allowed in an equation, as well as for many commutative rings that are not covered by our fpt result. On the technical side, we introduce the notion of important balanced subgraphs, generalising the important separators of Marx [Theoretical Computer Science, 351:3, 2006] to the setting of biased graphs. Furthermore, we use recent results on parameterized MinCSP [Kim et al., SODA-2021] to efficiently solve a generalisation of Multicut with disjunctive cut requests.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410232740",
    "type": "article"
  },
  {
    "title": "Paging and the Address-Translation Problem",
    "doi": "https://doi.org/10.1145/3737700",
    "publication_date": "2025-06-04",
    "publication_year": 2025,
    "authors": "Michael A. Bender; Abhishek Bhattacharjee; Alex Conway; Martı́n Farach-Colton; Rob Johnson; Sudarsun Kannan; William Kuszmaul; Nirjhar Mukherjee; Donald E. Porter; Guido Tagliavini; Janet Vorobyeva; Evan West",
    "corresponding_authors": "",
    "abstract": "The classical paging problem, introduced by Sleator and Tarjan in 1985, formalizes the problem of caching pages in RAM in order to minimize IOs. Their online formulation ignores the cost of address translation: programs refer to data via virtual addresses, and these must be translated into physical locations in RAM. Although the cost of an individual address translation is much smaller than that of an IO, every memory access involves an address translation, whereas IOs can be infrequent. In practice, one can spend money to avoid paging by over-provisioning RAM; in contrast, address translation is effectively unavoidable. Thus address-translation costs can sometimes dominate paging costs, and systems must simultaneously optimize both. To mitigate the cost of address translation, all modern CPUs have translation lookaside buffers (TLBs), which are hardware caches of common address translations. What makes TLBs interesting is that a single TLB entry can potentially encode the address translation for many addresses. This is typically achieved via the use of huge pages, which translate runs of contiguous virtual addresses to runs of contiguous physical addresses. Huge pages reduce TLB misses at the cost of increasing the IOs needed to maintain contiguity in RAM. This tradeoff between TLB misses and IOs suggests that the classical paging problem does not tell the full story. This paper introduces the Address-Translation Problem, which formalizes the problem of maintaining a TLB, a page table, and RAM in order to minimize the total cost of both TLB misses and IOs. We present an algorithm that achieves the benefits of huge pages for TLB misses without the downsides of huge pages for IOs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411022900",
    "type": "article"
  },
  {
    "title": "Introduction: ACM-SIAM Symposium on Discrete Algorithms (SODA) 2023 Special Issue",
    "doi": "https://doi.org/10.1145/3742858",
    "publication_date": "2025-06-11",
    "publication_year": 2025,
    "authors": "Nikhil Bansal; Eun Jung Kim; Viswanath Nagarajan; Aaron Potechin; Lars Rohwedder",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411207295",
    "type": "article"
  },
  {
    "title": "Minimum Plane Bichromatic Spanning Trees",
    "doi": "https://doi.org/10.1145/3747591",
    "publication_date": "2025-07-11",
    "publication_year": 2025,
    "authors": "Hugo A. Akitaya; Ahmad Biniaz; Erik D. Demaine; Linda Kleist; Frederick Stock; Csaba D. Tóth",
    "corresponding_authors": "",
    "abstract": "For a set of red and blue points in the plane, a minimum bichromatic spanning tree (MinBST) is a shortest spanning tree of the points such that every edge has a red and a blue endpoint. A MinBST can be computed in \\(O(n\\log n)\\) time where \\(n\\) is the number of points. In contrast to the standard Euclidean MST, which is always plane (noncrossing), a MinBST may have edges that cross each other. However, we prove that a MinBST is quasi-plane, that is, it does not contain three pairwise crossing edges, and we determine the maximum number of crossings. Moreover, we study the problem of finding a minimum plane bichromatic spanning tree (MinPBST) which is a shortest bichromatic spanning tree with pairwise noncrossing edges. This problem is known to be NP-hard. The previous best approximation algorithm, due to Borgelt et al. (2009), has a ratio of \\(O(\\sqrt{n})\\) . It is also known that the optimum solution can be computed in polynomial time in some special cases, for instance, when the points are in convex position, collinear, semi-collinear, or when one color class has constant size. We present an \\(O(\\log n)\\) -factor approximation algorithm for the general case.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412202024",
    "type": "article"
  },
  {
    "title": "Parameterized Algorithms for Steiner Forest in Bounded Width Graphs",
    "doi": "https://doi.org/10.1145/3748724",
    "publication_date": "2025-07-16",
    "publication_year": 2025,
    "authors": "Andreas Emil Feldmann; Michael Lampis",
    "corresponding_authors": "",
    "abstract": "In this paper we reassess the parameterized complexity and approximability of the well-studied Steiner Forest problem in several graph classes of bounded width. The problem takes an edge-weighted graph and pairs of vertices as input, and the aim is to find a minimum cost subgraph in which each given vertex pair lies in the same connected component. It is known that this problem is APX-hard in general, and NP-hard on graphs of treewidth 3, treedepth 4, and feedback vertex set size 2. However, Bateni, Hajiaghayi and Marx [JACM, 2011] gave an approximation scheme with a runtime of \\(n^{O(k^{2}/\\epsilon)}\\) on graphs of treewidth \\(k\\) . Our main result is a much faster efficient parameterized approximation scheme (EPAS) with a runtime of \\(2^{O(\\frac{k^{2}}{\\epsilon}\\log\\frac{k}{\\epsilon})}\\cdot n^{O(1)}\\) . If \\(k\\) instead is the vertex cover number of the input graph, we show how to compute the optimum solution in \\(2^{O(k\\log k)}\\cdot n^{O(1)}\\) time, and we also prove that this runtime dependence on \\(k\\) is asymptotically best possible, under ETH. Furthermore, if \\(k\\) is the size of a feedback edge set, then we obtain a faster \\(2^{O(k)}\\cdot n^{O(1)}\\) time algorithm, which again cannot be improved under ETH.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412476242",
    "type": "article"
  },
  {
    "title": "Color Fault-Tolerant Spanners",
    "doi": "https://doi.org/10.1145/3750728",
    "publication_date": "2025-07-24",
    "publication_year": 2025,
    "authors": "Asaf Petruschka; Shay Sapir; Elad Tzalik",
    "corresponding_authors": "",
    "abstract": "We initiate the study of spanners in arbitrarily vertex- or edge-colored graphs (with no “legality” restrictions), that are resilient to failures of entire color classes . When a color fails, all vertices/edges of that color crash. An \\(f\\) -color fault-tolerant ( \\(f\\) -CFT) \\(t\\) -spanner of an \\(n\\) -vertex colored graph \\(G\\) is a subgraph \\(H\\) that preserves distances up to factor \\(t\\) , even in the presence of at most \\(f\\) color faults. This notion generalizes the well-studied \\(f\\) -vertex/edge fault-tolerant ( \\(f\\) -V/EFT) spanners. The size of an \\(f\\) -V/EFT spanner crucially depends on the number \\(f\\) of vertex/edge faults to be tolerated. In the colored variants, even a single color fault can correspond to an unbounded number of vertex/edge faults. The key conceptual contribution of this work is in showing that the size (number of edges) required by an \\(f\\) -CFT spanner is in fact comparable to its uncolored counterpart, with no dependency on the size of color classes. We provide optimal bounds on the size required by \\(f\\) -CFT \\((2k-1)\\) -spanners, as follows: When vertices have colors, we show an upper bound of \\(O(f^{1-1/k}n^{1+1/k})\\) edges. This precisely matches the (tight) bounds for \\((2k-1)\\) -spanners resilient to \\(f\\) individual vertex faults (Bodwin et al. [SODA 2018]; Bodwin and Patel [PODC 2019]). For colored edges, we show that \\(O(fn^{1+1/k})\\) edges are always sufficient. Further, we prove this is tight, i.e., we provide an \\(\\Omega(fn^{1+1/k})\\) (worst-case) lower bound. The state-of-the-art bounds known for the corresponding uncolored setting of edge faults are (roughly) \\(\\Theta(f^{1/2}n^{1+1/k})\\) (Bodwin et al. [SODA 2018]; Bodwin, Dinitz and Robelle [SODA 2022]). We also consider a mixed model where both vertices and edges are colored. In this case, we show tight \\(\\Theta(f^{2-1/k}n^{1+1/k})\\) bounds. Thus, CFT spanners exhibit an interesting phenomenon: while (individual) edge faults are “easier” than vertex faults, edge-color faults are “harder” than vertex-color faults. Our results further extend to the color lists model, where every edge/vertex is given a list of colors, and the failure of any color from the list makes the edge/vertex crash. Our upper bounds are based on a generalization of the blocking set technique of Bodwin and Patel [PODC 2019] for analyzing the (exponential-time) greedy algorithm for FT spanners. We complement them by providing efficient constructions of CFT spanners with similar size guarantees, based on the algorithm of Dinitz and Robelle [PODC 2020].",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412627853",
    "type": "article"
  },
  {
    "title": "Online Coalition Formation under Random Arrival or Coalition Dissolution",
    "doi": "https://doi.org/10.1145/3758324",
    "publication_date": "2025-08-06",
    "publication_year": 2025,
    "authors": "Martin Bullinger; René Romen",
    "corresponding_authors": "",
    "abstract": "Coalition formation explores how to partition a set of \\( n \\) agents into disjoint coalitions according to their preferences. We consider a cardinal utility model with an additively separable aggregation of preferences and study the online variant, where agents arrive in sequence. The goal is to achieve competitive social welfare. In the basic model, agents arrive in an arbitrary order and have to be assigned to coalitions immediately and irrevocably. There, the natural greedy algorithm is known to achieve an optimal competitive ratio, which heavily relies on the range of utilities. We complement this result by considering two related models. First, we study a model where agents arrive in a random order. We find that the competitive ratio of the greedy algorithm is \\(\\Theta\\left(\\frac{1}{n^{2}}\\right)\\) . In contrast, an alternative algorithm, which is based on alternating between waiting and greedy phases, can achieve a competitive ratio of \\(\\Theta\\left(\\frac{1}{n}\\right)\\) . Second, we relax the irrevocability of decisions by allowing the dissolution of coalitions into singleton coalitions. We achieve an asymptotically optimal competitive ratio of \\(\\Theta\\left(\\frac{1}{n}\\right)\\) by drawing a close connection to a general model of online matching. Hence, in both models, we obtain a competitive ratio that removes the unavoidable utility dependencies in the basic model and essentially matches the best possible approximation ratio by polynomial-time algorithms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413019887",
    "type": "article"
  },
  {
    "title": "Computing the 4-Edge-Connected Components of a Graph: An Experimental Study",
    "doi": "https://doi.org/10.1145/3757919",
    "publication_date": "2025-08-07",
    "publication_year": 2025,
    "authors": "Loukas Georgiadis; Giuseppe F. Italiano; Evangelos Kosinas",
    "corresponding_authors": "",
    "abstract": "The notions of edge-cuts and \\(k\\) -edge-connected components are fundamental in graph theory with numerous practical applications. Very recently, the first linear-time algorithms for computing all the \\(3\\) -edge cuts and the \\(4\\) -edge-connected components of a graph have been introduced. In this paper we present carefully engineered implementations of these algorithms and evaluate their efficiency in practice, by performing a thorough empirical study using both real-world graphs taken from a variety of application areas, as well as artificial graphs. To the best of our knowledge, this is the first experimental study for these problems, which highlights the merits and weaknesses of each technique. Furthermore, we present an improved algorithm for computing the \\(4\\) -edge-connected components of an undirected graph in linear time. The new algorithm uses only elementary data structures, and is implementable in the pointer machine model of computation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413134293",
    "type": "article"
  },
  {
    "title": "Node-Differentially Private Estimation of the Number of Connected Components",
    "doi": "https://doi.org/10.1145/3762664",
    "publication_date": "2025-08-25",
    "publication_year": 2025,
    "authors": "Iden Kalemaj; Sofya Raskhodnikova; Adam Smith; Charalampos E. Tsourakakis",
    "corresponding_authors": "",
    "abstract": "We design the first node-differentially private algorithm for approximating the number of connected components in a graph. Given a database representing an \\(n\\) -vertex graph \\(G\\) and a privacy parameter \\(\\epsilon\\) , our algorithm runs in polynomial time and, with probability \\(1-o(1)\\) , has additive error \\(\\widetilde{O}(\\frac{\\Delta^{*}\\ln\\ln n}{\\epsilon}),\\) where \\(\\Delta^{*}\\) is the smallest possible maximum degree of a spanning forest of \\(G.\\) Node-differentially private algorithms are known only for a small number of database analysis tasks. A major obstacle for designing such an algorithm for the number of connected components is that this graph statistic is not robust to adding one node with arbitrary connections (a change that node-differential privacy is designed to hide): every graph is a neighbor of a connected graph. We overcome this by designing a family of efficiently computable Lipschitz extensions of the number of connected components or, equivalently, the size of a spanning forest. The construction of the extensions, which is at the core of our algorithm, is based on the forest polytope of \\(G.\\) We prove several combinatorial facts about spanning forests, in particular, that a graph with no induced \\(\\Delta\\) -stars has a spanning forest of degree at most \\(\\Delta\\) . With this fact, we show that our Lipschitz extensions for the number of connected components equal the true value of the function for the largest possible monotone families of graphs. More generally, on all monotone sets of graphs, the \\(\\ell_{\\infty}\\) error of our Lipschitz extensions is nearly optimal.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413592037",
    "type": "article"
  },
  {
    "title": "Parameterized Approximation Schemes for Biclique-Free Max <i>k</i> -Weight SAT and Max Coverage",
    "doi": "https://doi.org/10.1145/3763238",
    "publication_date": "2025-08-26",
    "publication_year": 2025,
    "authors": "Pallavi Jain; Lawqueen Kanesh; Fahad Panolan; Souvik Saha; Abhishek Sahu; Saket Saurabh; Anannya Upasana",
    "corresponding_authors": "",
    "abstract": "Max-SAT with cardinality constraint ( CC-Max-Sat ) is one of the classical NP-complete problems, that generalizes Maximum Coverage , Partial Vertex Cover , Max-2-SAT with bisection constraints, and has been extensively studied across all algorithmic paradigms. In this problem, we are given a CNF-formula \\(\\Phi\\) , and a positive integer \\(k\\) , and the goal is to find an assignment \\(\\beta\\) with at most \\(k\\) variables set to true (also called a \\(k\\) -weight assignment) such that the number of clauses satisfied by \\(\\beta\\) is maximized. The problem is known to admit an approximation algorithm with factor \\(1-\\frac{1}{e}\\) , which is probably optimal. Furthermore, assuming Gap-Exponential Time Hypothesis (Gap-ETH), for any \\(\\epsilon&gt;0\\) and any function \\(h\\) , no \\(h(k)(n+m)^{o(k)}\\) time algorithm can approximate Maximum Coverage (a monotone version of CC-Max-Sat ) with \\(n\\) elements and \\(m\\) sets to within a factor \\((1-\\frac{1}{e}+\\epsilon)\\) , even with a promise that there exist \\(k\\) sets that fully cover the whole universe. In fact, the problem is hard to approximate within \\(0.929\\) , assuming Unique Games Conjecture, even when the input formula is \\(2\\) -CNF. These intractable results lead us to explore families of formula, where we can circumvent these barriers. Towards this, we consider \\(K_{d,d}\\) -free formulas (that is, the clause-variable incidence bipartite graph of the formula excludes \\(K_{d,d}\\) as an induced subgraph). We show that for every \\(\\epsilon&gt;0\\) , there exists an algorithm for CC-Max-Sat on \\(K_{d,d}\\) -free formulas with approximation ratio \\((1-\\epsilon)\\) and running in time \\(2^{\\mathcal{O}((\\frac{dk}{\\epsilon})^{d})}(n+m)^{\\mathcal{O}(1)}\\) (these algorithms are called FPT-AS). For Maximum Coverage on \\(K_{d,d}\\) -free set families, we obtain FPT-AS with running time \\((\\frac{dk}{\\epsilon})^{\\mathcal{O}(dk)}n^{\\mathcal{O}(1)}\\) . Our second result considers “optimizing \\(k\\) ”, with fixed covering constraint for the Maximum Coverage problem. To explain our result, we first recast the Maximum Coverage problem as the Max Red Blue Dominating Set with Covering Constraint problem. Here, the input is a bipartite graph \\(G=(A,B,E)\\) , a positive integer \\(t\\) , and the objective is to find a minimum sized subset \\(S\\subseteq A\\) , such that \\(|N(S)|\\) (the size of the set of neighbors of \\(S\\) ) is at least \\(t\\) . We design an additive approximation algorithm for Max Red Blue Dominating Set with Covering Constraint , on \\(K_{d,d}\\) -free bipartite graphs, running in FPT time. In particular, if \\(k\\) denotes the minimum size of \\(S\\subseteq A\\) , such that \\(|N(S)|\\geq t\\) , then our algorithm runs in time \\((kd)^{\\mathcal{O}(kd)}n^{\\mathcal{O}{(1)}}\\) and returns a set \\(S^{\\prime}\\) such that \\(|N(S^{\\prime})|\\geq t\\) and \\(|S^{\\prime}|\\leq k+1\\) . This is in sharp contrast to the fact that, even a special case of our problem, namely, the Partial Vertex Cover problem (or Max \\(k\\) -VC ) is W[1]-hard, parameterized by \\(k\\) . Thus, we get the best possible parameterized approximation algorithm for the Maximum Coverage problem on \\(K_{d,d}\\) -free bipartite graphs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413682919",
    "type": "article"
  },
  {
    "title": "Packing Short Cycles",
    "doi": "https://doi.org/10.1145/3765285",
    "publication_date": "2025-09-01",
    "publication_year": 2025,
    "authors": "Matthias Bentert; Fedor V. Fomin; Petr A. Golovach; Tuukka Korhonen; William Lochet; Fahad Panolan; R. Sridharan; Saket Saurabh; Kirill Simonov",
    "corresponding_authors": "",
    "abstract": "Cycle packing is a fundamental problem in optimization, graph theory, and algorithms. Motivated by recent advancements in finding vertex-disjoint paths between a specified set of vertices that either minimize the total length of the paths [Björklund, Husfeldt, ICALP 2014; Mari, Mukherjee, Pilipczuk, and Sankowski, SODA 2024] or request the paths to be shortest [Lochet, SODA 2021], we consider the following cycle packing problems: Min-Sum Cycle Packing and Shortest Cycle Packing . In Min-Sum Cycle Packing , we try to find, in a weighted undirected graph, \\(k\\) vertex-disjoint cycles of minimum total weight. Our first main result is an algorithm that, for any fixed \\(k\\) , solves the problem in polynomial time. We complement this result by establishing the W[1]-hardness of Min-Sum Cycle Packing parameterized by \\(k\\) . The same results hold for the version of the problem where the task is to find \\(k\\) edge disjoint cycles. Our second main result concerns Shortest Cycle Packing , which is a special case of Min-Sum Cycle Packing that asks to find a packing of \\(k\\) shortest cycles in a graph. We prove this problem to be fixed-parameter tractable (FPT) when parameterized by \\(k\\) on weighted planar graphs. We also obtain a polynomial kernel for the edge-disjoint variant of the problem on planar graphs. Whether Min-Sum Cycle Packing is FPT on planar graphs, or Shortest Cycle Packing on general graphs, remains open.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413893971",
    "type": "article"
  },
  {
    "title": "Long Plane Trees",
    "doi": "https://doi.org/10.1145/3765740",
    "publication_date": "2025-09-04",
    "publication_year": 2025,
    "authors": "Sergio Cabello; Michael M. Hoffmann; Katharina Klost; Wolfgang Mulzer; Josef Tkadlec",
    "corresponding_authors": "",
    "abstract": "In the longest plane spanning tree problem, we are given a finite planar point set \\(\\mathcal{P}\\) , and our task is to find a plane (i.e., noncrossing) spanning tree for \\(\\mathcal{P}\\) with maximum total Euclidean edge length. Despite more than two decades of research, it remains open whether this problem is NP-hard. Thus, previous results have focused on polynomial-time algorithms that produce plane trees whose total edge length approximates \\(\\mathrm{OPT}\\) , the maximum possible length. The approximate trees in these algorithms all have small unweighted diameter, typically two to four. It is natural to ask whether this is a common feature of longest plane spanning trees, or an artifact of the specific approximation algorithms. We provide three results to elucidate the interplay between the approximation guarantee and the unweighted diameter of the approximate trees. First, we describe a polynomial-time algorithm to construct a plane tree with diameter at most four and total edge length at least \\(0.546\\cdot\\mathrm{OPT}\\) . This constitutes a substantial improvement over the state of the art. Second, we show that a longest plane tree among those with diameter at most three can be found in polynomial time. Third, for any candidate diameter \\(d\\geq 3\\) , we provide upper bounds on the approximation factor that can be achieved by a longest plane tree with diameter at most \\(d\\) (compared to a longest plane tree without constraints).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413993572",
    "type": "article"
  },
  {
    "title": "Improved Learning-Augmented Algorithms and (Tight) Lower Bounds for Multi-Option Ski Rental Problem",
    "doi": "https://doi.org/10.1145/3763239",
    "publication_date": "2025-09-09",
    "publication_year": 2025,
    "authors": "Yong-Ho Shin; Changyeol Lee; Gukryeol Lee; Hyung-Chan An",
    "corresponding_authors": "",
    "abstract": "We present improved learning-augmented algorithms for the multi-option ski rental problem. Learning-augmented algorithms take machine learning (ML) predictions as an added part of the input and incorporate these predictions in solving the given problem. Due to their unique strength that combines the power of ML predictions with provable performance guarantees, they have been extensively studied in the context of online optimization problems. Whilst the multi-option ski rental problem provides a natural generalization of the classical rent-or-buy variant, only deterministic algorithms for this problem were previously known, with or without learning augmentation. In this paper, we first present that a very simple modification to a previously known algorithm suffices to give an improved deterministic learning-augmented algorithm. In fact, we prove that this algorithm has the best possible performance of a deterministic algorithm by giving a matching lower bound. Then we present the first randomized learning-augmented algorithm, which surpasses the lower bound of deterministic algorithms; this learning-augmented algorithm is based on a new best-possible randomized competitive algorithm. These results are complemented by lower bounds for randomized competitive/learning-augmented algorithms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414210803",
    "type": "article"
  },
  {
    "title": "Computing Tree Decompositions with Small Independence Number",
    "doi": "https://doi.org/10.1145/3767730",
    "publication_date": "2025-09-16",
    "publication_year": 2025,
    "authors": "Clément Dallard; Fedor V. Fomin; Petr A. Golovach; Tuukka Korhonen; Martin Milanič",
    "corresponding_authors": "",
    "abstract": "The independence number of a tree decomposition is the maximum of the independence numbers of the subgraphs induced by its bags. The tree-independence number of a graph is the minimum independence number of a tree decomposition of it. Several NP -hard graph problems, like maximum weight independent set, can be solved in time \\(n^{\\mathcal{O}(k)}\\) if the input \\(n\\) -vertex graph is given together with a tree decomposition of independence number \\(k\\) . Yolov, in [SODA 2018], gave an algorithm that, given an \\(n\\) -vertex graph \\(G\\) and an integer \\(k\\) , in time \\(n^{\\mathcal{O}(k^{3})}\\) either constructs a tree decomposition of \\(G\\) whose independence number is \\(\\mathcal{O}(k^{3})\\) or correctly reports that the tree-independence number of \\(G\\) is larger than \\(k\\) . In this paper, we first give an algorithm for computing the tree-independence number with a better approximation ratio and running time and then prove that our algorithm is, in some sense, the best one can hope for. More precisely, our algorithm runs in time \\(2^{\\mathcal{O}(k^{2})}n^{\\mathcal{O}(k)}\\) and either outputs a tree decomposition of \\(G\\) with independence number at most \\(8k\\) , or determines that the tree-independence number of \\(G\\) is larger than \\(k\\) . This implies \\(2^{\\mathcal{O}(k^{2})}n^{\\mathcal{O}(k)}\\) -time algorithms for various problems, like maximum weight independent set, parameterized by the tree-independence number \\(k\\) without needing the decomposition as an input. Assuming Gap-ETH, an \\(n^{\\Omega(k)}\\) factor in the running time is unavoidable for any approximation algorithm for the tree-independence number. Our second result is that the exact computation of the tree-independence number is para-NP -hard: We show that for every constant \\(k\\geq 4\\) it is NP -complete to decide if a given graph has the tree-independence number at most \\(k\\) .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414241953",
    "type": "article"
  },
  {
    "title": "Tree Containment Above Minimum Degree is FPT",
    "doi": "https://doi.org/10.1145/3768573",
    "publication_date": "2025-09-18",
    "publication_year": 2025,
    "authors": "Fedor V. Fomin; Petr A. Golovach; Danil Sagunov; Kirill Simonov",
    "corresponding_authors": "",
    "abstract": "According to the classic Chvátal's Lemma from 1977, a graph \\(G\\) of minimum degree \\(\\delta(G)\\) contains every tree on \\(\\delta(G)+1\\) vertices. Our main result is the following algorithmic “extension” of Chvátal's Lemma: For any \\(n\\) -vertex graph \\(G\\) , an integer \\(k\\) , and a tree \\(T\\) on at most \\(\\delta(G)+k\\) vertices, deciding whether \\(G\\) contains a subgraph isomorphic to \\(T\\) can be done in time \\(f(k)\\cdot n^{\\mathcal{O}(1)}\\) for some function \\(f\\) of \\(k\\) only. The proof is based on an intricate interplay between extremal graph theory and parameterized algorithms.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414321043",
    "type": "article"
  },
  {
    "title": "Maintaining an EDCS in General Graphs: Simpler, Density-Sensitive and with Worst-Case Time Bounds",
    "doi": "https://doi.org/10.1145/3765900",
    "publication_date": "2025-09-22",
    "publication_year": 2025,
    "authors": "Fabrizio Grandoni; Chris Schwiegelshohn; Shay Solomon; Amitai Uzrad",
    "corresponding_authors": "",
    "abstract": "In their breakthrough ICALP’15 paper, Bernstein and Stein presented an algorithm for maintaining a \\((3/2+\\epsilon)\\) -approximate maximum matching in fully dynamic bipartite graphs with a worst-case update time of \\(O_{\\epsilon}(m^{1/4})\\) ; we use the \\(O_{\\epsilon}\\) notation to suppress the \\(\\epsilon\\) -dependence. Their main technical contribution was in presenting a new type of bounded-degree subgraph, which they named an edge degree constrained subgraph (EDCS) , which contains a large matching — of size that is smaller than the maximum matching size of the entire graph by at most a \\(3/2+\\epsilon\\) factor. They demonstrate that the EDCS can be maintained with a worst-case update time of \\(O_{\\epsilon}(m^{1/4})\\) , and their main result follows as a direct corollary. In their followup SODA’16 paper, Bernstein and Stein generalized their result for general graphs, achieving the same update time of \\(O_{\\epsilon}(m^{1/4})\\) , albeit with an amortized rather than worst-case bound. To date, the best deterministic worst-case update time bound for any better-than-2 approximate matching is \\(O(\\sqrt{m})\\) [Neiman and Solomon, STOC’13], [Gupta and Peng, FOCS’13]; allowing randomization (against an oblivious adversary) one can achieve a much better (still polynomial) update time for approximation slightly below 2 [Behnezhad, Łacki and Mirrokni, SODA’20]. In this work we 1 simplify the approach of Bernstein and Stein for bipartite graphs, which allows us to generalize it to general graphs while maintaining the same \\(O_{\\epsilon}(m^{1/4})\\) bound on the worst-case update time. Moreover, our approach is density-sensitive : If the arboricity of the dynamic graph is always bounded by \\(\\alpha\\) , then the worst-case update time of the algorithm is \\(O_{\\epsilon}(\\sqrt{\\alpha})\\) .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414392145",
    "type": "article"
  },
  {
    "title": "Finding matchings in dense hypergraphs",
    "doi": "https://doi.org/10.1145/3768574",
    "publication_date": "2025-10-06",
    "publication_year": 2025,
    "authors": "Jie Han; Peter Keevash",
    "corresponding_authors": "",
    "abstract": "We consider the algorithmic decision problem that takes as input an \\(n\\) -vertex \\(k\\) -uniform hypergraph \\(H\\) with minimum codegree at least \\(m-c\\) and decides whether it has a matching of size \\(m\\) . We show that this decision problem is fixed parameter tractable with respect to \\(c\\) . Furthermore, our algorithm not only decides the problem, but actually either finds a matching of size \\(m\\) or a certificate that no such matching exists. In particular, when \\(m=n/k\\) and \\(c=O(\\log n)\\) , this gives a polynomial-time algorithm, that given any \\(n\\) -vertex \\(k\\) -uniform hypergraph \\(H\\) with minimum codegree at least \\(n/k-c\\) , finds either a perfect matching in \\(H\\) or a certificate that no perfect matching exists.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4414873373",
    "type": "article"
  },
  {
    "title": "Pattern matching for arc-annotated sequences",
    "doi": "https://doi.org/10.1145/1125994.1125997",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Jens Gramm; Jiong Guo; Rolf Niedermeier",
    "corresponding_authors": "",
    "abstract": "We study pattern matching for arc-annotated sequences. An O ( nm ) time algorithm is given for the problem to determine whether a length m sequence with nested arc annotation is an arc-preserving subsequence (aps) of a length n sequence with nested arc annotation, called APS(NESTED,NESTED). Arc-annotated sequences and, in particular, those with nested arc annotation are motivated by applications in RNA structure comparison. Our algorithm generalizes results for ordered tree inclusion problems and it is useful for recent fixed-parameter algorithms for LAPCS(NESTED,NESTED), which is the problem of computing a longest arc-preserving common subsequence of two sequences with nested arc annotations. In particular, the presented dynamic programming methodology implies a quadratic-time algorithm for an open problem posed by Vialette.",
    "cited_by_count": 19,
    "openalex_id": "https://openalex.org/W2018076990",
    "type": "article"
  },
  {
    "title": "An improved algorithm for radio broadcast",
    "doi": "https://doi.org/10.1145/1186810.1186818",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Michael Elkin; Guy Kortsarz",
    "corresponding_authors": "",
    "abstract": "We show that for every radio network G = ( V , E ) and source s ∈ V , there exists a radio broadcast schedule for G of length Rad ( G , s ) + O (√ Rad ( G , s ) ⋅log 2 n ) = O ( Rad ( G , s ) + log 4 n ), where Rad ( G , s ) is the radius of the radio network G with respect to the source s . This result improves the previously best-known upper bound of O ( Rad ( G , s ) + log 5 n ) due to Gaber and Mansour [1995]. For graphs with small genus, particularly for planar graphs, we provide an even better upper bound of Rad ( G , S ) + O (√ Rad ( G , s ) ⋅ log n + log 3 n ) = O ( Rad ( G , s ) + log 3 n ).",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2113759682",
    "type": "article"
  },
  {
    "title": "Throughput maximization of real-time scheduling with batching",
    "doi": "https://doi.org/10.1145/1497290.1497294",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Amotz Bar-Noy; Sudipto Guha; Yoav Katz; Joseph Naor; Baruch Schieber; Hadas Shachnai",
    "corresponding_authors": "",
    "abstract": "We consider the following scheduling with batching problem that has many applications, for example, in multimedia-on-demand and manufacturing of integrated circuits. The input to the problem consists of n jobs and k parallel machines. Each job is associated with a set of time intervals in which it can be scheduled (given either explicitly or nonexplicitly), a weight, and a family. Each family is associated with a processing time. Jobs that belong to the same family can be batched and executed together on the same machine. The processing time of each batch is the processing time of the family of jobs it contains. The goal is to find a nonpreemptive schedule with batching that maximizes the weight of the scheduled jobs. We give constant factor (4 or 4 + ε) approximation algorithms for two variants of the problem, depending on the precise representation of the input. When the batch size is unbounded and each job is associated with a time window in which it can be processed, these approximation ratios reduce to 2 and 2 + ε, respectively. We also give approximation algorithms for two special cases when all release times are the same.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W1996696855",
    "type": "article"
  },
  {
    "title": "Simultaneous source location",
    "doi": "https://doi.org/10.1145/1644015.1644031",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Konstantin Andreev; Charles Garrod; Daniel Golovin; Bruce M. Maggs; Adam Meyerson",
    "corresponding_authors": "",
    "abstract": "We consider the problem of simultaneous source location: selecting locations for sources in a capacitated graph such that a given set of demands can be satisfied simultaneously, with the goal of minimizing the number of locations chosen. For general directed and undirected graphs we give an O(log D)-approximation algorithm, where D is the sum of demands, and prove matching Ω(log D) hardness results assuming P ≠ NP. For undirected trees, we give an exact algorithm and show how this can be combined with a result of Räcke to give a solution that exceeds edge capacities by at most O(log2 n log log n), where n is the number of nodes. For undirected graphs of bounded treewidth we show that the problem is still NP-hard, but we are able to give a PTAS with at most (1 + ϵ) violation of the capacities for arbitrarily small ϵ, or a (k+1) approximation with exact capacities, where k is the treewidth.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2049354485",
    "type": "article"
  },
  {
    "title": "Approximation algorithms for a facility location problem with service capacities",
    "doi": "https://doi.org/10.1145/1383369.1383381",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Jens Maßberg; Jens Vygen",
    "corresponding_authors": "",
    "abstract": "We present the first constant-factor approximation algorithms for the following problem. Given a metric space ( V , c ), a finite set D ⊆ V of terminals/customers with demands d : D → R + , a facility opening cost f ∈ R + and a capacity u ∈R + , find a partition D = D 1 ⊍…⊍ D k and Steiner trees T i for D i ( i = 1, …, k ) with c ( E ( T i )) + d ( D i ) ≤ u for i = 1,…, k such that Σ i = 1 k c ( E ( T i )) + kf is minimum. This problem arises in VLSI design. It generalizes the bin-packing problem and the Steiner tree problem. In contrast to other network design and facility location problems, it has the additional feature of upper bounds on the service cost that each facility can handle. Among other results, we obtain a 4.1-approximation in polynomial time, a 4.5-approximation in cubic time, and a 5-approximation as fast as computing a minimum spanning tree on ( D , c ).",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2171134634",
    "type": "article"
  },
  {
    "title": "Approximating connectivity augmentation problems",
    "doi": "https://doi.org/10.1145/1644015.1644020",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Zeev Nutov",
    "corresponding_authors": "Zeev Nutov",
    "abstract": "Let G = ( V , E ) be an undirected graph and let S ⊆ V . The S-connectivity λ S G ( u , v ) of a node pair ( u , v ) in G is the maximum number of uv -paths that no two of them have an edge or a node in S - { u , v } in common. The corresponding Connectivity Augmentation (CA) problem is: given a graph G = ( V , E ), a node subset S ⊆ V , and a nonnegative integer requirement function r ( u , v ) on V × V , add a minimum size set F of new edges to G so that λ S G + F ( u , v ) ≥ r ( u , v ) for all ( u , v ) ∈ V × V . Three extensively studied particular cases are: the Edge-CA ( S = ∅), the Node-CA ( S = V ), and the Element-CA ( r ( u , v )= 0 whenever u ∈ S or v ∈ S ). A polynomial-time algorithm for Edge-CA was developed by Frank. In this article we consider the Element-CA and the Node-CA, that are NP-hard even for r ( u , v ) ∈ {0,2}. The best known ratios for these problems were: 2 for Element-CA and O ( r max ṡ ln n ) for Node-CA, where r max = max u , v ∈ V r ( u , v ) and n = | V |. Our main result is a 7/4-approximation algorithm for the Element-CA, improving the previously best known 2-approximation. For Element-CA with r ( u , v ) ∈ {0,1,2} we give a 3/2-approximation algorithm. These approximation ratios are based on a new splitting-off theorem, which implies an improved lower bound on the number of edges needed to cover a skew-supermodular set function. For Node-CA we establish the following approximation threshold: Node-CA with r ( u , v ) ∈ {0, k } cannot be approximated within O (2 log 1-ϵ n ) for any fixed ϵ &gt; 0, unless NP ⊆ DTIME( n polylog( n ) ).",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2621727216",
    "type": "article"
  },
  {
    "title": "Nondecreasing paths in a weighted graph or",
    "doi": "https://doi.org/10.1145/1824777.1824790",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Virginia Vassilevska Williams",
    "corresponding_authors": "Virginia Vassilevska Williams",
    "abstract": "A travel booking office has timetables giving arrival and departure times for all scheduled trains, including their origins and destinations. A customer presents a starting station and demands a route with perhaps several train connections taking him to his destination as early as possible. The booking office must find the best route for its customers. This problem was first considered in the theory of algorithms by Minty [1958], who reduced it to a problem on directed edge-weighted graphs: find a path from a given source to a given target such that the consecutive weights on the path are nondecreasing and the last weight on the path is minimized. Minty gave the first algorithm for the single-source version of the problem, in which one finds minimum last weight nondecreasing paths from the source to every other vertex. In this article we give the first linear -time algorithm for this problem in the word-RAM model of computation. We also define an all-pairs version for the problem and give a strongly polynomial truly subcubic algorithm for it. Finally, we discuss an extension of the problem in which one also has prices on trip segments and one wishes to find a cheapest valid itinerary.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1978868826",
    "type": "article"
  },
  {
    "title": "Smoothed analysis of left-to-right maxima with applications",
    "doi": "https://doi.org/10.1145/2229163.2229174",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Valentina Damerow; Bodo Manthey; Friedhelm Meyer auf der Heide; Harald Räcke; Christian Scheideler; Christian Sohler; Till Tantau",
    "corresponding_authors": "",
    "abstract": "A left-to-right maximum in a sequence of n numbers s 1 , …, s n is a number that is strictly larger than all preceding numbers. In this article we present a smoothed analysis of the number of left-to-right maxima in the presence of additive random noise. We show that for every sequence of n numbers s i ∈ [0,1] that are perturbed by uniform noise from the interval [-ϵ,ϵ], the expected number of left-to-right maxima is Θ(√ n /ϵ + log n ) for ϵ&gt;1/ n . For Gaussian noise with standard deviation σ we obtain a bound of O ((log 3/2 n )/σ + log n ). We apply our results to the analysis of the smoothed height of binary search trees and the smoothed number of comparisons in the quicksort algorithm and prove bounds of Θ(√ n /ϵ + log n ) and Θ( n /ϵ+1√ n /ϵ + n log n ), respectively, for uniform random noise from the interval [-ϵ,ϵ]. Our results can also be applied to bound the smoothed number of points on a convex hull of points in the two-dimensional plane and to smoothed motion complexity, a concept we describe in this article. We bound how often one needs to update a data structure storing the smallest axis-aligned box enclosing a set of points moving in d -dimensional space.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2029151602",
    "type": "article"
  },
  {
    "title": "Counting occurrences for a finite set of words",
    "doi": "https://doi.org/10.1145/2229163.2229175",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Frédérique Bassino; Julien Clément; Pierre Nicodème",
    "corresponding_authors": "",
    "abstract": "In this article, we provide the multivariate generating function counting texts according to their length and to the number of occurrences of words from a finite set. The application of the inclusion-exclusion principle to word counting due to Goulden and Jackson [1979, 1983] is used to derive the result. Unlike some other techniques which suppose that the set of words is reduced (i.e., where no two words are factor of one another), the finite set can be chosen arbitrarily. Noonan and Zeilberger [1999] already provided a Maple package treating the nonreduced case, without giving an expression of the generating function or a detailed proof. We provide a complete proof validating the use of the inclusion-exclusion principle. Some formulæ for expected values, variance, and covariance for number of occurrences when considering two arbitrary sets of finite words are given as an application of our methodology.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2070539158",
    "type": "article"
  },
  {
    "title": "Broadcast scheduling",
    "doi": "https://doi.org/10.1145/2000807.2000815",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Jessica Chang; Thomas Erlebach; Renars Gailis; Samir Khuller",
    "corresponding_authors": "",
    "abstract": "Broadcast Scheduling is a popular method for disseminating information in response to client requests. There are n pages of information, and clients request pages at different times. However, multiple clients can have their requests satisfied by a single broadcast of the requested page. In this article, we consider several related broadcast scheduling problems. One central problem we study simply asks to minimize the maximum response time (over all requests). Another related problem we consider is the version in which every request has a release time and a deadline, and the goal is to maximize the number of requests that meet their deadlines. While approximation algorithms for both these problems were proposed several years back, it was not known if they were NP-complete. One of our main results is that both these problems are NP-complete. In addition, we use the same unified approach to give a simple NP-completeness proof for minimizing the sum of response times. A very complicated proof was known for this version. Furthermore, we give a proof that FIFO is a 2-competitive online algorithm for minimizing the maximum response time (this result had been claimed earlier with no proof) and that there is no better deterministic online algorithm (this result was claimed earlier as well, but with an incorrect proof).",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2127274846",
    "type": "article"
  },
  {
    "title": "Online Submodular Maximization with Free Disposal",
    "doi": "https://doi.org/10.1145/3242770",
    "publication_date": "2018-09-17",
    "publication_year": 2018,
    "authors": "T-H. Hubert Chan; Zhiyi Huang; Shaofeng H.-C. Jiang; Ning Kang; Zhihao Gavin Tang",
    "corresponding_authors": "",
    "abstract": "We study the online submodular maximization problem with free disposal under a matroid constraint. Elements from some ground set arrive one by one in rounds, and the algorithm maintains a feasible set that is independent in the underlying matroid. In each round when a new element arrives, the algorithm may accept the new element into its feasible set and possibly remove elements from it, provided that the resulting set is still independent. The goal is to maximize the value of the final feasible set under some monotone submodular function, to which the algorithm has oracle access. For k -uniform matroids, we give a deterministic algorithm with competitive ratio at least 0.2959, and the ratio approaches 1/α ∞ ≈ 0.3178 as k approaches infinity, improving the previous best ratio of 0.25 by Chakrabarti and Kale (IPCO 2014), Buchbinder et al. (SODA 2015), and Chekuri et al. (ICALP 2015). We also show that our algorithm is optimal among a class of deterministic monotone algorithms that accept a new arriving element only if the objective is strictly increased. Further, we prove that no deterministic monotone algorithm can be strictly better than 0.25-competitive even for partition matroids, the most modest generalization of k -uniform matroids, matching the competitive ratio by Chakrabarti and Kale (IPCO 2014) and Chekuri et al. (ICALP 2015). Interestingly, we show that randomized algorithms are strictly more powerful by giving a (non-monotone) randomized algorithm for partition matroids with ratio 1/α ∞ ≈ 0.3178.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2890692662",
    "type": "article"
  },
  {
    "title": "An Optimal Algorithm for ℓ <sub>1</sub> -Heavy Hitters in Insertion Streams and Related Problems",
    "doi": "https://doi.org/10.1145/3264427",
    "publication_date": "2018-10-22",
    "publication_year": 2018,
    "authors": "Arnab Bhattacharyya; Palash Dey; David P. Woodruff",
    "corresponding_authors": "",
    "abstract": "We give the first optimal bounds for returning the ℓ 1 -heavy hitters in a data stream of insertions, together with their approximate frequencies, closing a long line of work on this problem. For a stream of m items in { 1, 2, … , n } and parameters 0 &lt; ε &lt; φ ⩽ 1, let f i denote the frequency of item i , i.e., the number of times item i occurs in the stream. With arbitrarily large constant probability, our algorithm returns all items i for which f i ⩾ φ m , returns no items j for which f j ⩽ (φ −ε) m , and returns approximations f˜ i with | f˜ i − f i | ⩽ ε m for each item i that it returns. Our algorithm uses O (ε −1 log φ −1 + φ −1 log n + log log m ) bits of space, processes each stream update in O (1) worst-case time, and can report its output in time linear in the output size. We also prove a lower bound, which implies that our algorithm is optimal up to a constant factor in its space complexity. A modification of our algorithm can be used to estimate the maximum frequency up to an additive ε m error in the above amount of space, resolving Question 3 in the IITK 2006 Workshop on Algorithms for Data Streams for the case of ℓ 1 -heavy hitters. We also introduce several variants of the heavy hitters and maximum frequency problems, inspired by rank aggregation and voting schemes, and show how our techniques can be applied in such settings. Unlike the traditional heavy hitters problem, some of these variants look at comparisons between items rather than numerical values to determine the frequency of an item.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2898069179",
    "type": "article"
  },
  {
    "title": "The Simplex Algorithm Is NP-Mighty",
    "doi": "https://doi.org/10.1145/3280847",
    "publication_date": "2018-11-16",
    "publication_year": 2018,
    "authors": "Yann Disser; Martin Skutella",
    "corresponding_authors": "",
    "abstract": "We show that the Simplex Method, the Network Simplex Method—both with Dantzig’s original pivot rule—and the Successive Shortest Path Algorithm are NP-mighty . That is, each of these algorithms can be used to solve, with polynomial overhead, any problem in NP implicitly during the algorithm’s execution. This result casts a more favorable light on these algorithms’ exponential worst-case running times. Furthermore, as a consequence of our approach, we obtain several novel hardness results. For example, for a given input to the Simplex Algorithm, deciding whether a given variable ever enters the basis during the algorithm’s execution and determining the number of iterations needed are both NP-hard problems. Finally, we close a long-standing open problem in the area of network flows over time by showing that earliest arrival flows are NP-hard to obtain.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2996397717",
    "type": "article"
  },
  {
    "title": "On the query complexity of testing orientations for being Eulerian",
    "doi": "https://doi.org/10.1145/2151171.2151178",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Eldar Fischer; Oded Lachish; Arie Matsliah; Ilan Newman; Orly Yahalom",
    "corresponding_authors": "",
    "abstract": "We consider testing directed graphs Eulerianity in the orientation model introduced in Halevy et al. [2005]. Despite the local nature of the Eulerian property, it turns out to be significantly harder to test than other properties studied in the orientation model. We show a nonconstant lower bound on the query complexity of 2-sided tests and a linear lower bound on the query complexity of 1-sided tests for this property. On the positive side, we give several 1-sided and 2-sided tests, including a sublinear query complexity 2-sided test, for general graphs. For special classes of graphs, including bounded-degree graphs and expander graphs, we provide improved results. In particular, we give a 2-sided test with constant query complexity for dense graphs, as well as for expander graphs with a constant expansion parameter.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2153563062",
    "type": "article"
  },
  {
    "title": "Combinatiorial algorithms for wireless information flow",
    "doi": "https://doi.org/10.1145/2390176.2390184",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Javad B. Ebrahimi; Christina Fragouli",
    "corresponding_authors": "",
    "abstract": "A long-standing open question in information theory is to characterize the unicast capacity of a wireless relay network. The difficulty arises due to the complex signal interactions induced in the network, since the wireless channel inherently broadcasts the signals and there is interference among transmissions. Recently, Avestimehr et al. [2007b] proposed a linear deterministic model that takes into account the shared nature of wireless channels, focusing on the signal interactions rather than the background noise. They generalized the min-cut max-flow theorem for graphs to networks of deterministic channels and proved that the capacity can be achieved using information theoretical tools. They showed that the value of the minimum cut is in this case the minimum rank of all the adjacency matrices describing source-destination cuts. In this article, we develop a polynomial-time algorithm that discovers the relay encoding strategy to achieve the min-cut value in linear deterministic (wireless) networks, for the case of a unicast connection. Our algorithm crucially uses a notion of linear independence between channels to calculate the capacity in polynomial time. Moreover, we can achieve the capacity by using very simple one-symbol processing at the intermediate nodes, thereby constructively yielding finite-length strategies that achieve the unicast capacity of the linear deterministic (wireless) relay network.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2170580421",
    "type": "article"
  },
  {
    "title": "Fine-grained Complexity Analysis of Two Classic TSP Variants",
    "doi": "https://doi.org/10.1145/3414845",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Mark de Berg; Kevin Buchin; Bart M. P. Jansen; Gerhard J. Woeginger",
    "corresponding_authors": "",
    "abstract": "We analyze two classic variants of the T RAVELING S ALESMAN P ROBLEM ( TSP ) using the toolkit of fine-grained complexity. Our first set of results is motivated by the B ITONIC TSP problem: given a set of n points in the plane, compute a shortest tour consisting of two monotone chains. It is a classic dynamic-programming exercise to solve this problem in O ( n 2 ) time. While the near-quadratic dependency of similar dynamic programs for L ONGEST C OMMON S UBSEQUENCE and D ISCRETE F réchet D istance has recently been proven to be essentially optimal under the Strong Exponential Time Hypothesis, we show that bitonic tours can be found in subquadratic time. More precisely, we present an algorithm that solves bitonic TSP in O ( n log 2 n ) time and its bottleneck version in O ( n log 3 n ) time. In the more general pyramidal TSP problem, the points to be visited are labeled 1,… , n and the sequence of labels in the solution is required to have at most one local maximum. Our algorithms for the bitonic (bottleneck) TSP problem also work for the pyramidal TSP problem in the plane. Our second set of results concerns the popular k - OPT heuristic for TSP in the graph setting. More precisely, we study the k - OPT decision problem, which asks whether a given tour can be improved by a k - OPT move that replaces k edges in the tour by k new edges. A simple algorithm solves k - OPT in O ( n k ) time for fixed k . For 2- OPT , this is easily seen to be optimal. For k =3, we prove that an algorithm with a runtime of the form Õ( n 3−ɛ ) exists if and only if A LL -P AIRS S HORTEST P ATHS in weighted digraphs has such an algorithm. For general k - OPT , it is known that a runtime of f ( k ) · n o ( k / log k ) would contradict the Exponential Time Hypothesis. The results for k =2,3 may suggest that the actual time complexity of k - OPT is Θ ( n k ). We show that this is not the case, by presenting an algorithm that finds the best k -move in O ( n ⌊ 2 k /3 ⌋+1 ) time for fixed k ≥ 3. This implies that 4- OPT can be solved in O ( n 3 ) time, matching the best-known algorithm for 3- OPT . Finally, we show how to beat the quadratic barrier for k =2 in two important settings, namely, for points in the plane and when we want to solve 2- OPT repeatedly.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2486127132",
    "type": "article"
  },
  {
    "title": "Fault-Tolerant Approximate BFS Structures",
    "doi": "https://doi.org/10.1145/3022730",
    "publication_date": "2018-01-22",
    "publication_year": 2018,
    "authors": "Merav Parter; David Peleg",
    "corresponding_authors": "",
    "abstract": "A fault-tolerant structure for a network is required to continue functioning following the failure of some of the network’s edges or vertices. This article addresses the problem of designing a fault-tolerant (α , β) approximate BFS structure (or FT-ABFS structure for short), namely, a subgraph H of the network G such that subsequent to the failure of some subset F of edges or vertices, the surviving part of H (namely, H \\ F ) still contains an approximate BFS spanning tree for (the surviving part of) G , satisfying dist( s,v,H \\ F ) ≤ α ċ dist( s,v,G \\ F )+ β for every v isin V . Our first result is an algorithm that given an n -vertex unweighted undirected graph G and a source s constructs a multiplicative (3,0) FT-ABFS structure rooted at s resilient to a failure of a single edge with at most 4 n edges (improving by an O (log n ) factor on the near-tight result of Baswana and Khanna (2010) for the special case of edge failures). This was recently improved to 2n edges by Bilò et al. (2014). Next, we consider the multiple edge faults case, for a constant integer f &gt;1, we prove that there exists a (polynomial-time constructible) (3 f , f log n ) FT-ABFS structure with O ( f n ) edges that is resilient against f faults. We also show the existence of a (3 f +1,0) FT-ABFS structure with O ( f log f n ċ n ) edges. We then consider additive (1, β ) FT-ABFS structures and demonstrate an interesting dichotomy between multiplicative and additive spanners. In contrast to the linear size of ( α ,0) FT-ABFS structures, we show that for every n , there exist δ , ε &gt;0, and n -vertex graphs G with a source s for which any (1, n δ ) FT-ABFS structure rooted at s has Ω ( n 7/6 −ε) edges. For the case of additive stretch 3, we show that (1,3) FT-ABFS structures admit a lower bound of Ω ( n 5/4 ) edges.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2784432858",
    "type": "article"
  },
  {
    "title": "Packing Groups of Items into Multiple Knapsacks",
    "doi": "https://doi.org/10.1145/3233524",
    "publication_date": "2018-08-21",
    "publication_year": 2018,
    "authors": "Lin Chen; Guochuan Zhang",
    "corresponding_authors": "",
    "abstract": "We consider a natural generalization of the classical multiple knapsack problem in which instead of packing single items we are packing groups of items. In this problem, we have multiple knapsacks and a set of items partitioned into groups. Each item has an individual weight, while the profit is associated with groups rather than items. The profit of a group can be attained if and only if every item of this group is packed. Such a general model finds applications in various practical problems, e.g., delivering bundles of goods. The tractability of this problem relies heavily on how large a group could be. Deciding if a group of items of total weight 2 could be packed into two knapsacks of unit capacity is already NP -hard and it thus rules out a constant-approximation algorithm for this problem in general. We then focus on the parameterized version where the total weight of items in each group is bounded by a factor δ of the total capacity of all knapsacks. Both approximation and inapproximability results with respect to δ are derived. We also show that, depending on whether the number of knapsacks is a constant or part of the input, the approximation ratio for the problem, as a function on δ, changes substantially, which has a clear difference from the classical multiple knapsack problem.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2888289200",
    "type": "article"
  },
  {
    "title": "Approximation Schemes for Machine Scheduling with Resource (In-)dependent Processing Times",
    "doi": "https://doi.org/10.1145/3302250",
    "publication_date": "2019-05-07",
    "publication_year": 2019,
    "authors": "Klaus Jansen; Marten Maack; Malin Rau",
    "corresponding_authors": "",
    "abstract": "We consider two related scheduling problems: single resource-constrained scheduling on identical parallel machines and a generalization with resource-dependent processing times. In both problems, jobs require a certain amount of an additional resource and have to be scheduled on machines minimizing the makespan, while at every point in time a given resource capacity is not exceeded. In the first variant of the problem, the processing times and resource amounts are fixed, while in the second the former depends on the latter. Both problems contain bin packing with cardinality constraint as a special case, and, therefore, these problems are strongly NP-complete even for a constant number of machines larger than three, which can be proven by a reduction from 3-Partition. Furthermore, if the number of machines is part of the input, then we cannot hope for an approximation algorithm with absolute approximation ratio smaller than 3/2. We present asymptotic fully polynomial time approximation schemes (AFPTAS) for the problems: For any ε &gt; 0, a schedule of length at most (1+ε) times the optimum plus an additive term of O ( p max log (1/ε)/ε) is provided, and the running time is polynomially bounded in 1/ε and the input length. Up to now, only approximation algorithms with absolute approximation ratios were known. Furthermore, the AFPTAS for resource-constrained scheduling on identical parallel machines directly improves the additive term of the best AFPTAS for bin packing with cardinality constraint so far.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2944073560",
    "type": "article"
  },
  {
    "title": "Tight Analysis of Parallel Randomized Greedy MIS",
    "doi": "https://doi.org/10.1145/3326165",
    "publication_date": "2019-12-05",
    "publication_year": 2019,
    "authors": "Manuela Fischer; Andreas Noever",
    "corresponding_authors": "",
    "abstract": "We provide a tight analysis that settles the round complexity of the well-studied parallel randomized greedy MIS algorithm, thus answering the main open question of Blelloch, Fineman, and Shun [SPAA’12]. The parallel/distributed randomized greedy Maximal Independent Set (MIS) algorithm works as follows. An order of the vertices is chosen uniformly at random. Then, in each round, all vertices that appear before their neighbors in the order are added to the independent set and removed from the graph along with their neighbors. The main question of interest is the number of rounds it takes until the graph is empty. This algorithm has been studied since 1987, initiated by Coppersmith, Raghavan, and Tompa [FOCS’87], and the previously best known bounds were O (log n ) rounds in expectation for Erdős-Rényi random graphs by Calkin and Frieze [Random Struc. Alg.’90] and O (log 2 n ) rounds with high probability for general graphs by Blelloch, Fineman, and Shun [SPAA’12]. We prove a high probability upper bound of O (log n ) on the round complexity of this algorithm in general graphs and that this bound is tight. This also shows that parallel randomized greedy MIS is as fast as the celebrated algorithm of Luby [STOC’85, JALG’86].",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2993198966",
    "type": "article"
  },
  {
    "title": "An Improved Isomorphism Test for Bounded-tree-width Graphs",
    "doi": "https://doi.org/10.1145/3382082",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Martin Grohe; Daniel Neuen; Pascal Schweitzer; Daniel Wiebking",
    "corresponding_authors": "",
    "abstract": "We give a new FPT algorithm testing isomorphism of n -vertex graphs of tree-width k in time 2 kpolylog(k) n 3 , improving the FPT algorithm due to Lokshtanov, Pilipczuk, Pilipczuk, and Saurabh (FOCS 2014), which runs in time 2 O(k5 log k) n 5 . Based on an improved version of the isomorphism-invariant graph decomposition technique introduced by Lokshtanov et al., we prove restrictions on the structure of the automorphism groups of graphs of tree-width k . Our algorithm then makes heavy use of the group theoretic techniques introduced by Luks (JCSS 1982) in his isomorphism test for bounded degree graphs and Babai (STOC 2016) in his quasipolynomial isomorphism test. In fact, we even use Babai’s algorithm as a black box in one place. We also give a second algorithm that, at the price of a slightly worse running time 2 O(k2 log k) n 3 , avoids the use of Babai’s algorithm and, more importantly, has the additional benefit that it can also be used as a canonization algorithm.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3033022049",
    "type": "article"
  },
  {
    "title": "Edge Estimation with Independent Set Oracles",
    "doi": "https://doi.org/10.1145/3404867",
    "publication_date": "2020-09-16",
    "publication_year": 2020,
    "authors": "Paul Beame; Sariel Har-Peled; Sivaramakrishnan Natarajan Ramamoorthy; Cyrus Rashtchian; Makrand Sinha",
    "corresponding_authors": "",
    "abstract": "We study the task of estimating the number of edges in a graph, where the access to the graph is provided via an independent set oracle. Independent set queries draw motivation from group testing and have applications to the complexity of decision versus counting problems. We give two algorithms to estimate the number of edges in an n -vertex graph, using (i) polylog( n ) bipartite independent set queries or (ii) n 2/3 polylog( n ) independent set queries.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3087345281",
    "type": "article"
  },
  {
    "title": "Dynamic Facility Location via Exponential Clocks",
    "doi": "https://doi.org/10.1145/2928272",
    "publication_date": "2017-02-07",
    "publication_year": 2017,
    "authors": "Hyung-Chan An; Ashkan Norouzi-Fard; Ola Svensson",
    "corresponding_authors": "",
    "abstract": "The dynamic facility location problem is a generalization of the classic facility location problem proposed by Eisenstat, Mathieu, and Schabanel to model the dynamics of evolving social/infrastructure networks. The generalization lies in that the distance metric between clients and facilities changes over time. This leads to a trade-off between optimizing the classic objective function and the “stability” of the solution: There is a switching cost charged every time a client changes the facility to which it is connected. While the standard linear program (LP) relaxation for the classic problem naturally extends to this problem, traditional LP-rounding techniques do not, as they are often sensitive to small changes in the metric resulting in frequent switches. We present a new LP-rounding algorithm for facility location problems, which yields the first constant approximation algorithm for the dynamic facility location problem. Our algorithm installs competing exponential clocks on the clients and facilities and connects every client by the path that repeatedly follows the smallest clock in the neighborhood. The use of exponential clocks gives rise to several properties that distinguish our approach from previous LP roundings for facility location problems. In particular, we use no clustering and we allow clients to connect through paths of arbitrary lengths . In fact, the clustering-free nature of our algorithm is crucial for applying our LP-rounding approach to the dynamic problem.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3161451740",
    "type": "article"
  },
  {
    "title": "Near-Optimal Light Spanners",
    "doi": "https://doi.org/10.1145/3199607",
    "publication_date": "2018-06-22",
    "publication_year": 2018,
    "authors": "Shiri Chechik; Christian Wulff‐Nilsen",
    "corresponding_authors": "",
    "abstract": "A spanner H of a weighted undirected graph G is a “sparse” subgraph that approximately preserves distances between every pair of vertices in G . We refer to H as a δ-spanner of G for some parameter δ ≥ 1 if the distance in H between every vertex pair is at most a factor δ bigger than in G . In this case, we say that H has stretch δ. Two main measures of the sparseness of a spanner are the size (number of edges) and the total weight (the sum of weights of the edges in the spanner). It is well-known that for any positive integer k , one can efficiently construct a (2 k − 1)-spanner of G with O ( n 1+1/ k ) edges where n is the number of vertices [2]. This size-stretch tradeoff is conjectured to be optimal based on a girth conjecture of Erdős [17]. However, the current state of the art for the second measure is not yet optimal. Recently Elkin, Neiman and Solomon [ICALP 14] presented an improved analysis of the greedy algorithm, proving that the greedy algorithm admits (2 k − 1) · (1 + ϵ) stretch and total edge weight of O ϵ (( k / log k ) · ω ( MST ( G )) · n 1/ k ), where ω( MST ( G )) is the weight of a MST of G . The previous analysis by Chandra et al. [SOCG 92] admitted (2 k − 1) · (1 + ϵ) stretch and total edge weight of O ϵ ( k ω( MST ( G )) n 1/ k ). Hence, Elkin et al. improved the weight of the spanner by a log k factor. In this article, we completely remove the k factor from the weight, presenting a spanner with (2 k − 1) · (1 + ϵ) stretch, O ϵ (ω( MST ( G )) n 1/ k ) total weight, and O ( n 1+1/ k ) edges. Up to a (1 + ϵ) factor in the stretch this matches the girth conjecture of Erdős [17].",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W3163127969",
    "type": "article"
  },
  {
    "title": "Compressed Cache-Oblivious String B-Tree",
    "doi": "https://doi.org/10.1145/2903141",
    "publication_date": "2016-08-03",
    "publication_year": 2016,
    "authors": "Paolo Ferragina; Rossano Venturini",
    "corresponding_authors": "",
    "abstract": "In this article, we study three variants of the well-known prefix-search problem for strings, and we design solutions for the cache-oblivious model which improve the best known results. Among these contributions, we close (asymptotically) the classic problem, which asks for the detection of the set of strings that share the longest common prefix with a queried pattern by providing an I/O-optimal solution that matches the space lower bound for tries up to a constant multiplicative factor of the form (1 + ϵ), for ϵ &gt; 0. Our solutions hinge upon a novel compressed storage scheme that adds the ability to decompress prefixes of the stored strings I/O-optimally to the elegant locality-preserving front coding (Bender et al. 2006) still preserving its space bounds.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2479292667",
    "type": "article"
  },
  {
    "title": "On the Tradeoff between Stability and Fit",
    "doi": "https://doi.org/10.1145/2963103",
    "publication_date": "2016-09-21",
    "publication_year": 2016,
    "authors": "Edith Cohen; Graham Cormode; Nick Duffield; Carsten Lund",
    "corresponding_authors": "",
    "abstract": "In computing, as in many aspects of life, changes incur cost. Many optimization problems are formulated as a one-time instance starting from scratch. However, a common case that arises is when we already have a set of prior assignments and must decide how to respond to a new set of constraints, given that each change from the current assignment comes at a price. That is, we would like to maximize the fitness or efficiency of our system, but we need to balance it with the changeout cost from the previous state. We provide a precise formulation for this tradeoff and analyze the resulting stable extensions of some fundamental problems in measurement and analytics. Our main technical contribution is a stable extension of Probability Proportional to Size (PPS) weighted random sampling, with applications to monitoring and anomaly detection problems. We also provide a general framework that applies to top- k , minimum spanning tree, and assignment. In both cases, we are able to provide exact solutions and discuss efficient incremental algorithms that can find new solutions as the input changes.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1570406128",
    "type": "article"
  },
  {
    "title": "A Faster Algorithm for Computing Straight Skeletons",
    "doi": "https://doi.org/10.1145/2898961",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Siu-Wing Cheng; Liam Mencel; Antoine Vigneron",
    "corresponding_authors": "",
    "abstract": "We present a new algorithm for computing the straight skeleton of a polygon. For a polygon with n vertices, among which r are reflex vertices, we give a deterministic algorithm that reduces the straight skeleton computation to a motorcycle graph computation in O ( n (log n )log r ) time. It improves on the previously best known algorithm for this reduction, which is randomized, and runs in expected O ( n sqrt h + 1 log 2 n ) time for a polygon with h holes. Using known motorcycle graph algorithms, our result yields improved time bounds for computing straight skeletons. In particular, we can compute the straight skeleton of a nondegenerate polygon in O ( n (log n )log r + r 4/3 + ε ) time for any ε &gt; 0. On degenerate input, our time bound increases to O ( n (log n )log r + r 17/11 + ε ).",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W73899363",
    "type": "article"
  },
  {
    "title": "Sticky Brownian Rounding and its Applications to Constraint Satisfaction Problems",
    "doi": "https://doi.org/10.1145/3459096",
    "publication_date": "2022-02-11",
    "publication_year": 2022,
    "authors": "Sepehr Abbasi-Zadeh; Nikhil Bansal; Guru Guruganesh; Aleksandar Nikolov; Roy Schwartz; Mohit Singh",
    "corresponding_authors": "",
    "abstract": "Semidefinite programming is a powerful tool in the design and analysis of approximation algorithms for combinatorial optimization problems. In particular, the random hyperplane rounding method of Goemans and Williamson [ 31 ] has been extensively studied for more than two decades, resulting in various extensions to the original technique and beautiful algorithms for a wide range of applications. Despite the fact that this approach yields tight approximation guarantees for some problems, e.g., Max-Cut , for many others, e.g., Max-SAT and Max-DiCut , the tight approximation ratio is still unknown. One of the main reasons for this is the fact that very few techniques for rounding semi-definite relaxations are known. In this work, we present a new general and simple method for rounding semi-definite programs, based on Brownian motion. Our approach is inspired by recent results in algorithmic discrepancy theory. We develop and present tools for analyzing our new rounding algorithms, utilizing mathematical machinery from the theory of Brownian motion, complex analysis, and partial differential equations. Focusing on constraint satisfaction problems, we apply our method to several classical problems, including Max-Cut , Max-2SAT , and Max-DiCut , and derive new algorithms that are competitive with the best known results. To illustrate the versatility and general applicability of our approach, we give new approximation algorithms for the Max-Cut problem with side constraints that crucially utilizes measure concentration results for the Sticky Brownian Motion, a feature missing from hyperplane rounding and its generalizations.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2903710486",
    "type": "article"
  },
  {
    "title": "Subcubic Equivalences between Graph Centrality Problems, APSP, and Diameter",
    "doi": "https://doi.org/10.1145/3563393",
    "publication_date": "2022-09-16",
    "publication_year": 2022,
    "authors": "Amir Abboud; Fabrizio Grandoni; Virginia Vassilevska Williams",
    "corresponding_authors": "",
    "abstract": "Measuring the importance of a node in a network is a major goal in the analysis of social networks, biological systems, transportation networks, and so forth. Different centrality measures have been proposed to capture the notion of node importance. For example, the center of a graph is a node that minimizes the maximum distance to any other node (the latter distance is the radius of the graph). The median of a graph is a node that minimizes the sum of the distances to all other nodes. Informally, the betweenness centrality of a node w measures the fraction of shortest paths that have w as an intermediate node. Finally, the reach centrality of a node w is the smallest distance r such that any s - t shortest path passing through w has either s or t in the ball of radius r around w . The fastest known algorithms to compute the center and the median of a graph and to compute the betweenness or reach centrality even of a single node take roughly cubic time in the number n of nodes in the input graph. It is open whether these problems admit truly subcubic algorithms, i.e., algorithms with running time Õ(n 3-δ ) for some constant δ &gt; 0. 1 We relate the complexity of the mentioned centrality problems to two classical problems for which no truly subcubic algorithm is known, namely All Pairs Shortest Paths (APSP) and Diameter. We show that Radius, Median, and Betweenness Centrality are equivalent under subcubic reductions to APSP, i.e., that a truly subcubic algorithm for any of these problems implies a truly subcubic algorithm for all of them. We then show that Reach Centrality is equivalent to Diameter under subcubic reductions. The same holds for the problem of approximating Betweenness Centrality within any finite factor. Thus, the latter two centrality problems could potentially be solved in truly subcubic time, even if APSP required essentially cubic time. On the positive side, our reductions for Reach Centrality imply an improved Õ(Mn ω )-time algorithm for this problem in case of non-negative integer weights upper bounded by M , where ω is a fast matrix multiplication exponent.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W4296270819",
    "type": "article"
  },
  {
    "title": "Load Thresholds for Cuckoo Hashing with Overlapping Blocks",
    "doi": "https://doi.org/10.1145/3589558",
    "publication_date": "2023-03-31",
    "publication_year": 2023,
    "authors": "Stefan Walzer",
    "corresponding_authors": "Stefan Walzer",
    "abstract": "We consider a natural variation of cuckoo hashing proposed by Lehman and Panigrahy (2009). Each of cn objects is assigned k = 2 intervals of size ℓ in a linear hash table of size n and both starting points are chosen independently and uniformly at random. Each object must be placed into a table cell within its intervals, but each cell can only hold one object. Experiments suggested that this scheme outperforms the variant with blocks in which intervals are aligned at multiples of ℓ. In particular, the load threshold is higher, i.e., the load c that can be achieved with high probability. For instance, Lehman and Panigrahy (2009) empirically observed the threshold for ℓ = 2 to be around 96.5% as compared to roughly 89.7% using blocks. They pinned down the asymptotics of the thresholds for large ℓ, but the precise values resisted rigorous analysis. We establish a method to determine these load thresholds for all ℓ ≥ 2, and, in fact, for general k ≥ 2. For instance, for k = ℓ = 2, we get ≈ 96.4995%. We employ a theorem due to Leconte, Lelarge, and Massoulié (2013), which adapts methods from statistical physics to the world of hypergraph orientability. In effect, the orientability thresholds for our graph families are determined by belief propagation equations for certain graph limits. As a side note, we provide experimental evidence suggesting that placements can be constructed in linear time using an adapted version of an algorithm by Khosla (2013).",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2737172134",
    "type": "article"
  },
  {
    "title": "Towards Optimal Moment Estimation in Streaming and Distributed Models",
    "doi": "https://doi.org/10.1145/3596494",
    "publication_date": "2023-05-10",
    "publication_year": 2023,
    "authors": "Rajesh Jayaram; David P. Woodruff",
    "corresponding_authors": "",
    "abstract": "One of the oldest problems in the data stream model is to approximate the p th moment \\(\\Vert \\mathbf {X}\\Vert _p^p = \\sum _{i=1}^n \\mathbf {X}_i^p\\) of an underlying non-negative vector \\(\\mathbf {X}\\in \\mathbb {R}^n\\) , which is presented as a sequence of \\(\\mathrm{poly}(n)\\) updates to its coordinates. Of particular interest is when \\(p \\in (0,2]\\) . Although a tight space bound of \\(\\Theta (\\epsilon ^{-2} \\log n)\\) bits is known for this problem when both positive and negative updates are allowed, surprisingly, there is still a gap in the space complexity of this problem when all updates are positive. Specifically, the upper bound is \\(O(\\epsilon ^{-2} \\log n)\\) bits, while the lower bound is only \\(\\Omega (\\epsilon ^{-2} + \\log n)\\) bits. Recently, an upper bound of \\(\\tilde{O}(\\epsilon ^{-2} + \\log n)\\) bits was obtained under the assumption that the updates arrive in a random order . We show that for \\(p \\in (0, 1]\\) , the random order assumption is not needed. Namely, we give an upper bound for worst-case streams of \\(\\tilde{O}(\\epsilon ^{-2} + \\log n)\\) bits for estimating \\(\\Vert \\mathbf {X}\\Vert _p^p\\) . Our techniques also give new upper bounds for estimating the empirical entropy in a stream. However, we show that for \\(p \\in (1,2]\\) , in the natural coordinator and blackboard distributed communication topologies, there is an \\(\\tilde{O}(\\epsilon ^{-2})\\) bit max-communication upper bound based on a randomized rounding scheme. Our protocols also give rise to protocols for heavy hitters and approximate matrix product. We generalize our results to arbitrary communication topologies G , obtaining an \\(\\tilde{O}(\\epsilon ^{2} \\log d)\\) max-communication upper bound, where d is the diameter of G . Interestingly, our upper bound rules out natural communication complexity-based approaches for proving an \\(\\Omega (\\epsilon ^{-2} \\log n)\\) bit lower bound for \\(p \\in (1,2]\\) for streaming algorithms. In particular, any such lower bound must come from a topology with large diameter.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2979234330",
    "type": "article"
  },
  {
    "title": "Polynomial Formulations as a Barrier for Reduction-based Hardness Proofs",
    "doi": "https://doi.org/10.1145/3721134",
    "publication_date": "2025-03-04",
    "publication_year": 2025,
    "authors": "Tatiana Belova; Alexander Golovnev; Alexander S. Kulikov; Ivan Mihajlin; Denil Sharipov",
    "corresponding_authors": "",
    "abstract": "The Strong Exponential Time Hypothesis (SETH) asserts that for every \\(\\varepsilon&gt;0\\) there exists \\(k\\) such that \\(k\\) -SAT requires time \\((2-\\varepsilon)^{n}\\) . The field of fine-grained complexity has leveraged SETH to prove quite tight conditional lower bounds for dozens of problems in various domains and complexity classes, including Edit Distance, Graph Diameter, Hitting Set, Independent Set, and Orthogonal Vectors. Yet, it has been repeatedly asked in the literature whether SETH-hardness results can be proven for other fundamental problems such as Hamiltonian Path, Independent Set, Chromatic Number, MAX- \\(k\\) -SAT, and Set Cover. In this paper, we show that fine-grained reductions implying even \\(\\lambda^{n}\\) -hardness of these problems from SETH for any \\(\\lambda&gt;1\\) , would imply new circuit lower bounds: super-linear lower bounds for Boolean series-parallel circuits or polynomial lower bounds for arithmetic circuits (each of which is a four-decade open question). We also extend this barrier result to the class of parameterized problems. Namely, for every \\(\\lambda&gt;1\\) we conditionally rule out fine-grained reductions implying SETH-based lower bounds of \\(\\lambda^{k}\\) for a number of problems parameterized by the solution size \\(k\\) . Our main technical tool is a new concept called polynomial formulations. In particular, we show that many problems can be represented by relatively succinct low-degree polynomials, and that any problem with such a representation cannot be proven SETH-hard (without proving new circuit lower bounds).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4408150749",
    "type": "article"
  },
  {
    "title": "Tight Approximation Algorithms for Two-dimensional Guillotine Strip Packing",
    "doi": "https://doi.org/10.1145/3736723",
    "publication_date": "2025-05-22",
    "publication_year": 2025,
    "authors": "Arindam Khan; Aditya Lonkar; Arnab Maiti; Amatya Sharma; Andreas Wiese",
    "corresponding_authors": "",
    "abstract": "In the Strip Packing (SP) problem, we are given a vertical half-strip \\([0,W]\\times[0,\\infty)\\) and a set of \\( n \\) axis-aligned rectangles of width at most \\( W \\) . The goal is to find a non-overlapping packing of all rectangles into the strip such that the height of the packing is minimized. A well-studied and frequently used practical constraint is to allow only those packings that are guillotine separable, i.e., every rectangle in the packing can be obtained by recursively applying a sequence of edge-to-edge axis-parallel cuts (guillotine cuts) that do not intersect any item of the solution. In this article, we study approximation algorithms for the Guillotine Strip Packing (GSP) problem, i.e., the SP problem where we require additionally that the packing needs to be guillotine separable. This problem generalizes the classical Bin Packing problem and also makespan minimization on identical machines, and thus it is already strongly \\(\\mathsf{NP}\\) -hard. Moreover, due to a reduction from the Partition problem, it is \\(\\mathsf{NP}\\) -hard to obtain a polynomial-time \\((3/2-\\varepsilon)\\) -approximation algorithm for GSP for any \\(\\varepsilon &gt; 0\\) (exactly as SP ). We provide a matching polynomial time \\((3/2+\\varepsilon)\\) -approximation algorithm for GSP. Furthermore, we present a pseudo-polynomial time \\((1+\\varepsilon)\\) -approximation algorithm for GSP. This is surprising as it is \\(\\mathsf{NP}\\) -hard to obtain a \\((5/4-\\varepsilon)\\) -approximation algorithm for (general) SP in pseudo-polynomial time. Thus, our results essentially settle the approximability of GSP for both the polynomial and the pseudo-polynomial settings.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410610052",
    "type": "article"
  },
  {
    "title": "Short Synchronizing Words for Random Automata",
    "doi": "https://doi.org/10.1145/3736722",
    "publication_date": "2025-05-23",
    "publication_year": 2025,
    "authors": "Guillaume Chapuy; Guillem Perarnau",
    "corresponding_authors": "",
    "abstract": "We prove that a uniformly random automaton with \\(n\\) states on a 2-letter alphabet has a synchronizing word of length \\(O(n^{1/2}\\log n)\\) with high probability (w.h.p.). That is to say, w.h.p. there exists a word \\(\\omega\\) of such length, and a state \\(v_{0}\\) , such that \\(\\omega\\) sends all states to \\(v_{0}\\) . Prior to this work, the best upper bound was the quasilinear bound \\(O(n\\log^{3}n)\\) due to Nicaud [26]. The correct scaling exponent had been subject to various estimates by other authors between \\(0.5\\) and \\(0.56\\) based on numerical simulations, and our result confirms that the smallest one indeed gives a valid upper bound (with a log factor). Our proof introduces the concept of \\(w\\) -trees, for a word \\(w\\) , that is, automata in which the \\(w\\) -transitions induce a (loop-rooted) tree. We prove a strong structure result that says that, w.h.p., a random automaton on \\(n\\) states is a \\(w\\) -tree for some word \\(w\\) of length at most \\((1+\\epsilon)\\log_{2}(n)\\) , for any \\(\\epsilon&gt;0\\) . The existence of the (random) word \\(w\\) is proved by the probabilistic method. This structure result is key to proving that a short synchronizing word exists.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410635565",
    "type": "article"
  },
  {
    "title": "Local Distributed Rounding: Generalized to MIS, Matching, Set Cover, and Beyond",
    "doi": "https://doi.org/10.1145/3742476",
    "publication_date": "2025-06-03",
    "publication_year": 2025,
    "authors": "Salwa Faour; Mohsen Ghaffari; Christoph Grunau; Fabian Kühn; Václav Rozhoň",
    "corresponding_authors": "",
    "abstract": "We develop a general deterministic distributed method for locally rounding fractional solutions of graph problems for which the analysis can be broken down into analyzing pairs of vertices. Roughly speaking, the method can transform fractional/probabilistic label assignments of the vertices into integral/deterministic label assignments for the vertices, while approximately preserving a potential function that is a linear combination of functions, each of which depends on at most two vertices (subject to some conditions usually satisfied in pairwise analyses). The method unifies and significantly generalizes prior work on deterministic local rounding techniques [Ghaffari, Kuhn FOCS’21; Harris FOCS’19; Fischer, Ghaffari, Kuhn FOCS’17; Fischer DISC’17] to obtain polylogarithmic-time deterministic distributed solutions for combinatorial graph problems. Our general rounding result enables us to locally and efficiently derandomize a range of distributed algorithms for local graph problems, including maximal independent set (MIS), maximum-weight independent set approximation, and minimum-cost set cover approximation. As highlights, we in particular obtain the following results. — We obtain a deterministic \\(O(\\log^{2}\\Delta\\cdot\\log n)\\) -round algorithm for computing an MIS in the \\(\\mathsf{LOCAL}\\) model and an almost as efficient \\(O(\\log^{2}\\Delta\\cdot\\log\\log\\Delta\\cdot\\log n)\\) -round deterministic MIS algorithm in the \\(\\mathsf{CONGEST}\\) model. As a result, the best known deterministic distributed time complexity of the four most widely studied distributed symmetry breaking problems (MIS, maximal matching, \\((\\Delta+1)\\) -vertex coloring, and \\((2\\Delta-1)\\) -edge coloring) is now \\(O(\\log^{2}\\Delta\\cdot\\log n)\\) . Our new MIS algorithm is also the first direct polylogarithmic-time deterministic distributed MIS algorithm, which is not based on network decomposition. — We obtain efficient deterministic distributed algorithms for rounding fractional solutions for maximum (weighted) independent set and minimum (weighted) set cover. In particular, for any constant \\(\\varepsilon&gt;0\\) , we give a deterministic \\(O(\\log^{2}\\Delta+\\log^{*}n)\\) -round algorithm for computing an independent set of size \\((1/2-\\varepsilon)\\cdot n/\\deg_{\\mathrm{avg}}\\) , and we give deterministic \\(O(\\log^{2}(\\Delta W)+\\log^{*}n)\\) -round algorithms for computing a \\((1-\\varepsilon)/\\Delta\\) -approximation of maximum weight independent set, and for computing a \\((1-\\varepsilon)/r\\) -approximation of maximum weight matching in hypergraphs of rank \\(r\\) . For minimum set cover instances with sets of size at most \\(s\\) and where each element is contained in at most \\(t\\) sets, we show that an \\(O(\\log s)\\) -approximation can be computed in time \\(O(\\log s\\cdot\\log^{2}t+\\log^{*}n)\\) .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4410976087",
    "type": "article"
  },
  {
    "title": "Introduction: ACM-SIAM Symposium on Discrete Algorithms (SODA) 2021 Special Issue",
    "doi": "https://doi.org/10.1145/3744924",
    "publication_date": "2025-06-27",
    "publication_year": 2025,
    "authors": "Alina Ene; Troy Lee; Piotr Micek; Sushant Sachdeva",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4411712687",
    "type": "article"
  },
  {
    "title": "A simpler and parallelizable \\(O(\\sqrt{\\log n})\\) -approximation algorithm for <scp>Sparsest Cut</scp>",
    "doi": "https://doi.org/10.1145/3748723",
    "publication_date": "2025-07-16",
    "publication_year": 2025,
    "authors": "Vladimir Kolmogorov",
    "corresponding_authors": "Vladimir Kolmogorov",
    "abstract": "Currently, the best known tradeoff between approximation ratio and complexity for the Sparsest Cut problem is achieved by the algorithm in [Sherman, FOCS 2009]: it computes \\(O(\\sqrt{(\\log n)/\\varepsilon})\\) -approximation using \\(O(n^{\\varepsilon}\\log^{O(1)}n)\\) maxflows for any \\(\\varepsilon\\in[\\Theta(1/\\log n),\\Theta(1)]\\) . It works by solving the SDP relaxation of [Arora-Rao-Vazirani, STOC 2004] using the Multiplicative Weights Update algorithm (MW) of [Arora-Kale, JACM 2016]. To implement one MW step, Sherman approximately solves a multicommodity flow problem using another application of MW. Nested MW steps are solved via a certain “chaining” algorithm that combines results of multiple calls to the maxflow algorithm. We present an alternative approach that avoids solving the multicommodity flow problem and instead computes “violating paths”. This simplifies Sherman's algorithm by removing a need for a nested application of MW, and also allows parallelization: we show how to compute \\(O(\\sqrt{(\\log n)/\\varepsilon})\\) -approximation via \\(O(\\log^{O(1)}n)\\) maxflows using \\(O(n^{\\varepsilon})\\) processors. We also revisit Sherman's chaining algorithm, and present a simpler version together with a new analysis.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4412476103",
    "type": "article"
  },
  {
    "title": "Fast and Small Subsampled R-indexes",
    "doi": "https://doi.org/10.1145/3750729",
    "publication_date": "2025-08-18",
    "publication_year": 2025,
    "authors": "Dustin Cobas; Travis Gagie; Gonzalo Navarro",
    "corresponding_authors": "",
    "abstract": "The r -index (Gagie et al., JACM 2020) represented a breakthrough in compressed indexing of repetitive text collections, outperforming its alternatives by orders of magnitude in query time. Its space usage, \\(\\mathcal{O}(r)\\) where \\( r \\) is the number of runs in the Burrows–Wheeler Transform of the text, is however higher than Lempel–Ziv and grammar-based indexes and makes it uninteresting in various real-life scenarios of milder repetitiveness. In this article, we introduce the sr -index , a variant that limits a large fraction of the space to \\({\\mathcal{O}}(\\min(r,n/s))\\) for a text of length \\( n \\) and a given parameter \\( s \\) , at the expense of multiplying by \\( s \\) the time per occurrence reported. The sr -index is obtained by carefully subsampling the text positions indexed by the r -index , in a way that we prove is still able to support pattern matching with guaranteed performance. Our experiments demonstrate that the theoretical analysis falls short in describing the practical advantages of the sr -index , because it performs much better on real texts than on synthetic ones: the sr -index retains the performance of the r -index while using 1.5–4.0 times less space, sharply outperforming virtually every other compressed index on repetitive texts in both time and space. Only a particular Lempel–Ziv-based index uses less space—about half—than the sr -index , but it is an order of magnitude slower. Our second contribution are the r -csa and sr -csa indexes. Just like the r -index adapts the well-known FM-Index to repetitive texts, the r -csa adapts Sadakane’s Compressed Suffix Array (CSA) to this case. We show that the principles used on the r -index turn out to fit naturally and efficiently in the CSA framework. The sr -csa is the corresponding subsampled version of the r -csa . While the CSA performs better than the FM-Index on classic texts with alphabets larger than DNA, our experiments show that the sr -csa outperforms the sr -index on repetitive texts not only over those larger alphabets, but on some DNA texts as well. Overall, our new subsampled indexes sweep the table of the existing indexes for highly repetitive text collection, by combining the exceptional speed of the r -index with drastically reduced storage use.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4413279381",
    "type": "article"
  },
  {
    "title": "Robust subgraphs for trees and paths",
    "doi": "https://doi.org/10.1145/1150334.1150341",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Refael Hassin; Danny Segev",
    "corresponding_authors": "",
    "abstract": "Consider a graph problem which is associated with a parameter, for example, that of finding a longest tour spanning k vertices. The following question is natural: Is there a small subgraph that contains an optimal or near optimal solution for every possible value of the given parameter? Such a subgraph is said to be robust . In this article we consider the problems of finding heavy paths and heavy trees of k edges. In these two cases, we prove surprising bounds on the size of a robust subgraph for a variety of approximation ratios. For both problems, we show that in every complete weighted graph on n vertices there exists a subgraph with approximately α/1−α 2 n edges that contains an α-approximate solution for every k = 1,…, n − 1. In the analysis of the tree problem, we also describe a new result regarding balanced decomposition of trees. In addition, we consider variants in which the subgraph itself is restricted to be a path or a tree. For these problems, we describe polynomial time algorithms and corresponding proofs of negative results.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2029846150",
    "type": "article"
  },
  {
    "title": "Generating rooted and free plane trees",
    "doi": "https://doi.org/10.1145/1125994.1125995",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Joe Sawada",
    "corresponding_authors": "Joe Sawada",
    "abstract": "This article has two main results. First, we develop a simple algorithm to list all nonisomorphic rooted plane trees in lexicographic order using a level sequence representation. Then, by selecting a unique centroid to act as the root of a free plane tree, we apply the rooted plane tree algorithm to develop an algorithm to list all nonisomorphic free plane trees. The latter algorithm also uses a level sequence representation and lists all free plane trees with a unique centroid first followed by all free plane trees with two centroids. Both algorithms are proved to run in constant amortized time using straightforward bounding methods.",
    "cited_by_count": 17,
    "openalex_id": "https://openalex.org/W2082869103",
    "type": "article"
  },
  {
    "title": "Approximate majorization and fair online load balancing",
    "doi": "https://doi.org/10.1145/1103963.1103970",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Ashish Goel; Adam Meyerson; Serge Plotkin",
    "corresponding_authors": "",
    "abstract": "This article relates the notion of fairness in online routing and load balancing to vector majorization as developed by Hardy et al. [1929]. We define α -supermajorization as an approximate form of vector majorization, and show that this definition generalizes and strengthens the prefix measure proposed by Kleinberg et al. [2001] as well as the popular notion of max-min fairness .The article revisits the problem of online load-balancing for unrelated 1-∞ machines from the viewpoint of fairness. We prove that a greedy approach is O (log n )-supermajorized by all other allocations, where n is the number of jobs. This means the greedy approach is globally O (log n )- fair . This may be contrasted with polynomial lower bounds presented by Goel et al. [2001] for fair online routing.We also define a machine-centric view of fairness using the related concept of submajorization . We prove that the greedy online algorithm is globally O (log m )- balanced , where m is the number of machines.",
    "cited_by_count": 16,
    "openalex_id": "https://openalex.org/W1976665334",
    "type": "article"
  },
  {
    "title": "Writing-all deterministically and optimally using a nontrivial number of asynchronous processors",
    "doi": "https://doi.org/10.1145/1367064.1367073",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Dariusz R. Kowalski; Alexander A. Shvartsman",
    "corresponding_authors": "",
    "abstract": "The problem of performing n tasks on p asynchronous or undependable processors is a basic problem in distributed computing. This article considers an abstraction of this problem called Write-All: using p processors write 1's into all locations of an array of size n . In this problem writing 1 abstracts the notion of performing a simple task. Despite substantial research, there is a dearth of efficient deterministic asynchronous algorithms for Write-All/ . Efficiency of algorithms is measured in terms of work that accounts for all local steps performed by the processors in solving the problem. Thus, an optimal algorithm would have work Θ( n ), however it is known that optimality cannot be achieved when p = Ω( n ). The quest then is to obtain work-optimal solutions for this problem using a nontrivial, compared to n , number of processors p . The algorithm presented in this article has work complexity of O ( n + p 2 + ϵ ), and it achieves work optimality for p = O ( n 1/(2 + ε) ) for any ε &gt; 0, while the previous best result achieved optimality for p ≤4√ n /log n . Additionally, the new result uses only the atomic read/write memory, without resorting to using the test-and-set primitive that was necessary in the previous solution.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2036862097",
    "type": "article"
  },
  {
    "title": "Combinatorial dominance guarantees for problems with infeasible solutions",
    "doi": "https://doi.org/10.1145/1435375.1435383",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Daniel Berend; Steven Skiena; Yochai Twitto",
    "corresponding_authors": "",
    "abstract": "The design and analysis of approximation algorithms for NP -hard problems is perhaps the most active research area in the theory of combinatorial algorithms. In this article, we study the notion of a combinatorial dominance guarantee as a way for assessing the performance of a given approximation algorithm. An f ( n ) dominance bound is a guarantee that the heuristic always returns a solution not worse than at least f ( n ) solutions. We give tight analysis of many heuristics, and establish novel and interesting dominance guarantees even for certain inapproximable problems and heuristic search algorithms. For example, we show that the maximal matching heuristic of VERTEX COVER offers a combinatorial dominance guarantee of 2 n − (1.839 + o (1)) n . We also give inapproximability results for most of the problems we discuss.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W1978936478",
    "type": "article"
  },
  {
    "title": "Randomized fast design of short DNA words",
    "doi": "https://doi.org/10.1145/1597036.1597047",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Ming‐Yang Kao; Manan Sanghi; Robert Schweller",
    "corresponding_authors": "",
    "abstract": "We consider the problem of efficiently designing sets (codes) of equal-length DNA strings (words) that satisfy certain combinatorial constraints. This problem has numerous motivations including DNA self-assembly and DNA computing. Previous work has extended results from coding theory to obtain bounds on code size for new biologically motivated constraints and has applied heuristic local search and genetic algorithm techniques for code design. This article proposes a natural optimization formulation of the DNA code design problem in which the goal is to design n strings that satisfy a given set of constraints while minimizing the length of the strings. For multiple sets of constraints, we provide simple randomized algorithms that run in time polynomial in n and any given constraint parameters, and output strings of length within a constant factor of the optimal with high probability. To the best of our knowledge, this work is the first to consider this type of optimization problem in the context of DNA code design.",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2087947565",
    "type": "article"
  },
  {
    "title": "Compacting cuts",
    "doi": "https://doi.org/10.1145/1541885.1541888",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Robert D. Carr; Goran Konjevod; Greg Little; Venkatesh Natarajan; Ojas Parekh",
    "corresponding_authors": "",
    "abstract": "For a graph ( V , E ), existing compact linear formulations for the minimum cut problem require Θ(| V || E |) variables and constraints and can be interpreted as a composition of | V | − 1 polyhedra for minimum s - t cuts in much the same way as early approaches to finding globally minimum cuts relied on | V | − 1 calls to a minimum s - t cut algorithm. We present the first formulation to beat this bound, one that uses O (| V | 2 ) variables and O (| V | 3 ) constraints. An immediate consequence of our result is a compact linear relaxation with O (| V | 2 ) constraints and O (| V | 3 ) variables for enforcing global connectivity constraints. This relaxation is as strong as standard cut-based relaxations and has applications in solving traveling salesman problems by integer programming as well as finding approximate solutions for survivable network design problems using Jain's iterative rounding method. Another application is a polynomial-time verifiable certificate of size n for for the NP-complete problem of l 1 -embeddability of a rational metric on an n -set (as opposed to a certificate of size n 2 known previously).",
    "cited_by_count": 13,
    "openalex_id": "https://openalex.org/W2150361102",
    "type": "article"
  },
  {
    "title": "Adaptive sampling strategies for quickselects",
    "doi": "https://doi.org/10.1145/1798596.1798606",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Conrado Martı́nez; Daniel Panario; Alfredo Viola",
    "corresponding_authors": "",
    "abstract": "Quickselect with median-of-3 is largely used in practice and its behavior is fairly well understood. However, the following natural adaptive variant, which we call proportion-from-3 , had not been previously analyzed: “choose as pivot the smallest of the sample if the relative rank of the sought element is below 1/3, the largest if the relative rank is above 2/3, and the median if the relative rank is between 1/3 and 2/3.” We first analyze the average number of comparisons made when using proportion-from-2 and then for proportion-from-3. We also analyze ν-find, a generalization of proportion-from-3 with interval breakpoints at ν and 1-ν. We show that there exists an optimal value of ν and we also provide the range of values of ν where ν-find outperforms median-of-3. Then, we consider the average total cost of these strategies, which takes into account the cost of both comparisons and exchanges. Our results strongly suggest that a suitable implementation of ν-find could be the method of choice in a practical setting. We also study the behavior of proportion-from- s with s &gt;3 and in particular we show that proportion-from- s -like strategies are optimal when s →∞.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2024781872",
    "type": "article"
  },
  {
    "title": "Computing large matchings fast",
    "doi": "https://doi.org/10.1145/1868237.1868238",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Ignaz Rutter; Alexander Wolff",
    "corresponding_authors": "",
    "abstract": "In this article we present algorithms for computing large matchings in 3-regular graphs, graphs with maximum degree 3, and 3-connected planar graphs. The algorithms give a guarantee on the size of the computed matching and take linear or slightly superlinear time. Thus they are faster than the best-known algorithm for computing maximum matchings in general graphs, which runs in O (√ nm ) time, where n denotes the number of vertices and m the number of edges of the given graph. For the classes of 3-regular graphs and graphs with maximum degree 3, the bounds we achieve are known to be best possible. We also investigate graphs with block trees of bounded degree, where the d -block tree is the adjacency graph of the d -connected components of the given graph. In 3-regular graphs and 3-connected planar graphs with bounded-degree 2- and 4-block trees, respectively, we show how to compute maximum matchings in slightly superlinear time.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2620994567",
    "type": "article"
  },
  {
    "title": "Distributed error confinement",
    "doi": "https://doi.org/10.1145/1798596.1798601",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Yossi Azar; Shay Kutten; Boaz Patt-Shamir",
    "corresponding_authors": "",
    "abstract": "We study error confinement in distributed applications, which can be viewed as an extreme case of various fault locality notions studied in the past. Error confinement means that to the external observer, only nodes that were directly hit by a fault may deviate from their specified correct behavior, and only temporarily. The externally observable behavior of all other nodes must remain impeccable, even though their internal state may be affected. Error confinement is impossible if an adversary is allowed to inflict arbitrary transient faults on the system, since the faults might completely wipe out input values. We introduce a new fault-tolerance measure we call agility , which quantifies the fault tolerance of an algorithm that disseminates information against state corrupting faults. We then propose broadcast algorithms that guarantee error confinement with optimal agility to within a constant factor in synchronous networks. These algorithms can serve as building blocks in more general reactive systems. Previous results in exploring locality in reactive systems were not error confined, or allowed a wide range of behaviors to be considered correct. Our results also include a new technique that can be used to analyze the “cow path” problem.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1994131773",
    "type": "article"
  },
  {
    "title": "All-pairs shortest paths with a sublinear additive error",
    "doi": "https://doi.org/10.1145/2000807.2000813",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Liam Roditty; A. Shapira",
    "corresponding_authors": "",
    "abstract": "We show that, for every 0 ≤ p ≤ 1, there is an O ( n 2.575− p /(7.4−2.3 p ) )-time algorithm that given a directed graph with small positive integer weights, estimates the length of the shortest path between every pair of vertices u , v in the graph to within an additive error δ p ( u , v ), where δ( u , v ) is the exact length of the shortest path between u and v . This algorithm runs faster than the fastest algorithm for computing exact shortest paths for any 0 &lt; p ≤ 1. Previously the only way to “beat” the running time of the exact shortest path algorithms was by applying an algorithm of Zwick [2002] that approximates the shortest path distances within a multiplicative error of (1 + ϵ). Our algorithm thus gives a smooth qualitative and quantitative transition between the fastest exact shortest paths algorithm, and the fastest approximation algorithm with a linear additive error. In fact, the main ingredient we need in order to obtain the above result, which is also interesting in its own right, is an algorithm for computing (1 + ϵ) multiplicative approximations for the shortest paths, whose running time is faster than the running time of Zwick's approximation algorithm when ϵ ≪ 1 and the graph has small integer weights.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1994717376",
    "type": "article"
  },
  {
    "title": "Parallel pipelined filter ordering with precedence constraints",
    "doi": "https://doi.org/10.1145/2344422.2344431",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Amol Deshpande; Lisa Hellerstein",
    "corresponding_authors": "",
    "abstract": "In the parallel pipelined filter ordering problem, we are given a set of n filters that run in parallel. The filters need to be applied to a stream of elements, to determine which elements pass all filters. Each filter has a rate limit r i on the number of elements it can process per unit time, and a selectivity p i , which is the probability that a random element will pass the filter. The goal is to maximize throughput. This problem appears naturally in a variety of settings, including parallel query optimization in databases and query processing over Web services. We present an O ( n 3 ) algorithm for this problem, given tree-structured precedence constraints on the filters. This extends work of Condon et al. [2009] and Kodialam [2001], who presented algorithms for solving the problem without precedence constraints. Our algorithm is combinatorial and produces a sparse solution. Motivated by join operators in database queries, we also give algorithms for versions of the problem in which “filter” selectivities may be greater than or equal to 1. We prove a strong connection between the more classical problem of minimizing total work in sequential filter ordering (A), and the parallel pipelined filter ordering problem (B). More precisely, we prove that A is solvable in polynomial time for a given class of precedence constraints if and only if B is as well. This equivalence allows us to show that B is NP-Hard in the presence of arbitrary precedence constraints (since A is known to be NP-Hard in that setting).",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2010712525",
    "type": "article"
  },
  {
    "title": "A fast algorithm to generate open meandric systems and meanders",
    "doi": "https://doi.org/10.1145/1721837.1721858",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Bruce Bobier; Joe Sawada",
    "corresponding_authors": "",
    "abstract": "An open meandric system is a planar configuration of acyclic curves crossing an infinite horizontal line in the plane such that the curves may extend in both horizontal directions. We present a fast, recursive algorithm to exhaustively generate open meandric systems with n crossings. We then illustrate how to modify the algorithm to generate unidirectional open meandric systems (the curves extend only to the right) and nonisomorphic open meandric systems where equivalence is taken under horizontal reflection. Each algorithm can be modified to generate systems with exactly k curves. In the unidirectional case when k = 1, we can apply a minor modification along with some additional optimization steps to yield the first fast and simple algorithm to generate open meanders.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2027273244",
    "type": "article"
  },
  {
    "title": "S-T connectivity on digraphs with a known stationary distribution",
    "doi": "https://doi.org/10.1145/1978782.1978785",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Kai-Min Chung; Omer Reingold; Salil Vadhan",
    "corresponding_authors": "",
    "abstract": "We present a deterministic logspace algorithm for solving S-T Connectivity on directed graphs if: (i) we are given a stationary distribution of the random walk on the graph in which both of the input vertices s and t have nonnegligible probability mass and (ii) the random walk which starts at the source vertex s has polynomial mixing time. This result generalizes the recent deterministic logspace algorithm for S-T Connectivity on undirected graphs [Reingold, 2008]. It identifies knowledge of the stationary distribution as the gap between the S-T Connectivity problems we know how to solve in logspace ( L ) and those that capture all of randomized logspace ( RL ).",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2055100233",
    "type": "article"
  },
  {
    "title": "An Efficient Algorithm for Computing High-Quality Paths amid Polygonal Obstacles",
    "doi": "https://doi.org/10.1145/3230650",
    "publication_date": "2018-08-21",
    "publication_year": 2018,
    "authors": "Pankaj K. Agarwal; Kyle Fox; Oren Salzman",
    "corresponding_authors": "",
    "abstract": "We study a path-planning problem amid a set O of obstacles in R 2 , in which we wish to compute a short path between two points while also maintaining a high clearance from O; the clearance of a point is its distance from a nearest obstacle in O. Specifically, the problem asks for a path minimizing the reciprocal of the clearance integrated over the length of the path. We present the first polynomial-time approximation scheme for this problem. Let n be the total number of obstacle vertices and let ε ∈ (0, 1]. Our algorithm computes in time O ( n 2 /ε 2 log n /ε) a path of total cost at most (1 + ε) times the cost of the optimal path.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2888446832",
    "type": "article"
  },
  {
    "title": "An Optimal <i>O</i> ( <i>nm</i> ) Algorithm for Enumerating All Walks Common to All Closed Edge-covering Walks of a Graph",
    "doi": "https://doi.org/10.1145/3341731",
    "publication_date": "2019-07-29",
    "publication_year": 2019,
    "authors": "Massimo Cairo; Paul Medvedev; Nidia Obscura Acosta; Roméo Rizzi; Alexandru I. Tomescu",
    "corresponding_authors": "",
    "abstract": "In this article, we consider the following problem. Given a directed graph G , output all walks of G that are sub-walks of all closed edge-covering walks of G . This problem was first considered by Tomescu and Medvedev (RECOMB 2016), who characterized these walks through the notion of omnitig . Omnitigs were shown to be relevant for the genome assembly problem from bioinformatics, where a genome sequence must be assembled from a set of reads from a sequencing experiment. Tomescu and Medvedev (RECOMB 2016) also proposed an algorithm for listing all maximal omnitigs, by launching an exhaustive visit from every edge. In this article, we prove new insights about the structure of omnitigs and solve several open questions about them. We combine these to achieve an O ( nm )-time algorithm for outputting all the maximal omnitigs of a graph (with n nodes and m edges). This is also optimal, as we show families of graphs whose total omnitig length is Ω( nm ). We implement this algorithm and show that it is 9--12 times faster in practice than the one of Tomescu and Medvedev (RECOMB 2016).",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2965565043",
    "type": "article"
  },
  {
    "title": "Beating Approximation Factor Two for Weighted Tree Augmentation with Bounded Costs",
    "doi": "https://doi.org/10.1145/3182395",
    "publication_date": "2018-12-07",
    "publication_year": 2018,
    "authors": "David Adjiashvili",
    "corresponding_authors": "David Adjiashvili",
    "abstract": "The Weighted Tree Augmentation Problem (WTAP) is a fundamental well-studied problem in the field of network design. Given an undirected tree G =( V , E ), an additional set of edges L ⊑ V × V disjoint from E called links and a cost vector c ∈ R ≥ 0 L , WTAP asks to find a minimum-cost set F ⊑ L with the property that ( V , E ∪ F ) is 2-edge connected. The special case where c ℓ = 1 for all ℓ ∈ L is called the Tree Augmentation Problem (TAP). For the class of bounded cost vectors, we present the first improved approximation algorithm for WTAP in more than three decades. Concretely, for any M ∈ R ≥ 1 and ε &gt; 0, we present an LP based (μ +ϵ)-approximation for WTAP restricted to cost vectors c in [1, M ] L for μ ≈ 1.96417. More generally, our result is a (μ +ϵ)-approximation algorithm with running time n r O (1) , where r = c max / c min is the ratio between the largest and the smallest cost of any link. For the special case of TAP, we improve this factor to 5/3+ϵ. Our results rely on several new ideas, including a new LP relaxation of WTAP and a two-phase rounding algorithm. In the first phase, the algorithm uses the fractional LP solution to guide a simple decomposition method that breaks the tree into well-structured trees and equips each with a part of the fraction LP solution. In the second phase, the fractional solution in each part of the decomposition is rounded to an integral solution with two rounding procedures and the best outcome is included in the solution. One rounding procedure exploits the constraints in the new LP, while the other one exploits a connection to the Edge Cover Problem. We show that both procedures cannot have a bad approximation guarantee simultaneously to obtain the claimed approximation factor.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W3163298847",
    "type": "article"
  },
  {
    "title": "On the Integrality Gap of Degree-4 Sum of Squares for Planted Clique",
    "doi": "https://doi.org/10.1145/3178538",
    "publication_date": "2018-06-16",
    "publication_year": 2018,
    "authors": "Samuel B. Hopkins; Pravesh K. Kothari; Aaron Potechin; Prasad Raghavendra; Tselil Schramm",
    "corresponding_authors": "",
    "abstract": "The problem of finding large cliques in random graphs and its “planted” variant, where one wants to recover a clique of size ω &gt; log ( n ) added to an Erdős-Rényi graph G ∼ G ( n ,1/2), have been intensely studied. Nevertheless, existing polynomial time algorithms can only recover planted cliques of size ω = Ω (√ n ). By contrast, information theoretically, one can recover planted cliques so long as ω &gt; log ( n ). In this work, we continue the investigation of algorithms from the Sum of Squares hierarchy for solving the planted clique problem begun by Meka, Potechin, and Wigderson [2] and Deshpande and Montanari [25]. Our main result is that degree four SoS does not recover the planted clique unless ω &gt; √ n / polylog n , improving on the bound ω &gt; n 1/3 due to Reference [25]. An argument of Kelner shows that the this result cannot be proved using the same certificate as prior works. Rather, our proof involves constructing and analyzing a new certificate that yields the nearly tight lower bound by “correcting” the certificate of References [2, 25, 27].",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W4251683043",
    "type": "article"
  },
  {
    "title": "The Discrete and Semicontinuous Fréchet Distance with Shortcuts via Approximate Distance Counting and Selection",
    "doi": "https://doi.org/10.1145/2700222",
    "publication_date": "2015-04-13",
    "publication_year": 2015,
    "authors": "Rinat Ben Avraham; Omrit Filtser; Haim Kaplan; Matthew J. Katz; Micha Sharir",
    "corresponding_authors": "",
    "abstract": "The Fréchet distance is a well-studied similarity measure between curves. The discrete Fréchet distance is an analogous similarity measure, defined for two sequences of m and n points, where the points are usually sampled from input curves. We consider a variant, called the discrete Fréchet distance with shortcuts , which captures the similarity between (sampled) curves in the presence of outliers. When shortcuts are allowed only in one noise-containing curve, we give a randomized algorithm that runs in O (( m + n ) 6/5 + ε ) expected time, for any ε &gt; 0. When shortcuts are allowed in both curves, we give an O (( m 2/3 n 2/3 + m + n )log 3 ( m + n ))-time deterministic algorithm. We also consider the semicontinuous Fréchet distance with one-sided shortcuts, where we have a sequence of m points and a polygonal curve of n edges, and shortcuts are allowed only in the sequence. We show that this problem can be solved in randomized expected time O (( m + n ) 2/3 m 2/3 n 1/3 log ( m + n )). Our techniques are novel and may find further applications. One of the main new technical results is: Given two sets of points A and B in the plane and an interval I , we develop an algorithm that decides whether the number of pairs ( x , y ) ∈ A × B whose distance dist( x , y ) is in I is less than some given threshold L . The running time of this algorithm decreases as L increases. In case there are more than L pairs of points whose distance is in I , we can get a small sample of pairs that contain a pair at approximate median distance (i.e., we can approximately “bisect” I ). We combine this procedure with additional ideas to search, with a small overhead, for the optimal one-sided Fréchet distance with shortcuts, using a very fast decision procedure. We also show how to apply this technique for approximating distance selection (with respect to rank), and a somewhat more involved variant of this technique is used in the solution of the semicontinuous Fréchet distance with one-sided shortcuts. In general, the new technique can be applied to optimization problems for which the decision procedure is very fast but standard techniques like parametric search makes the optimization algorithm substantially slower.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W1967985699",
    "type": "article"
  },
  {
    "title": "Rate vs. buffer size--greedy information gathering on the line",
    "doi": "https://doi.org/10.1145/1978782.1978787",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Adi Rosén; Gabriel Scalosub",
    "corresponding_authors": "",
    "abstract": "We consider packet networks with limited buffer space at the nodes, and are interested in the question of maximizing the number of packets that arrive to destination rather than being dropped due to full buffers. We initiate a more refined analysis of the throughput competitive ratio of admission and scheduling policies in the Competitive Network Throughput model [Aiello et al. 2005], taking into account not only the network size but also the buffer size and the injection rate of the traffic. We specifically consider the problem of information gathering on the line, with limited buffer space, under adversarial traffic. We examine how the buffer size and the injection rate of the traffic affect the performance of the greedy protocol for this problem. We establish upper bounds on the competitive ratio of the greedy protocol in terms of the network size, the buffer size, and the adversary's rate, and present lower bounds which are tight up to constant factors. These results show, for example, that provisioning the network with sufficiently large buffers may substantially improve the performance of the greedy protocol in some cases, whereas for some high-rate adversaries, using larger buffers does not have any effect on the competitive ratio of the protocol.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2079815698",
    "type": "article"
  },
  {
    "title": "Randomized rendezvous with limited memory",
    "doi": "https://doi.org/10.1145/1978782.1978789",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Evangelos Kranakis; Danny Kriz̧anc; Pat Morin",
    "corresponding_authors": "",
    "abstract": "We present a trade-off between the expected time for two identical agents to rendezvous on a synchronous, anonymous, oriented ring and the memory requirements of the agents. In particular, we show there exists a 2 t state agent which can achieve rendezvous on an n -node ring in expected time O ( n 2 /2 t + 2 t ) and that any t /2 state agent requires expected time Ω( n 2 /2 t ). As a corollary we observe that Θ(log log n ) bits of memory are necessary and sufficient to achieve rendezvous in linear time.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2086702855",
    "type": "article"
  },
  {
    "title": "An online scalable algorithm for average flow time in broadcast scheduling",
    "doi": "https://doi.org/10.1145/2344422.2344429",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "Sungjin Im; Benjamin Moseley",
    "corresponding_authors": "",
    "abstract": "In this article, the online pull-based broadcast model is considered. In this model, there are n pages of data stored at a server and requests arrive for pages online. When the server broadcasts page p , all outstanding requests for the same page p are simultaneously satisfied. We consider the problem of minimizing average (total) flow time online where all pages are unit-sized. For this problem, there has been a decade-long search for an online algorithm which is scalable, that is, (1 + ϵ)-speed O (1)-competitive for any fixed ϵ &gt; 0. In this article, we give the first analysis of an online scalable algorithm.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2096036254",
    "type": "article"
  },
  {
    "title": "Distributed algorithms for multicommodity flow problems via approximate steepest descent framework",
    "doi": "https://doi.org/10.1145/2390176.2390179",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Baruch Awerbuch; Rohit Khandekar; Satish Rao",
    "corresponding_authors": "",
    "abstract": "We consider solutions for distributed multicommodity flow problems, which are solved by multiple agents operating in a cooperative but uncoordinated manner. We show first distributed solutions that allow (1 + ϵ) approximation and whose convergence time is essentially linear in the maximal path length, and is independent of the number of commodities and the size of the graph. Our algorithms use a very natural approximate steepest descent framework, combined with a blocking flow technique to speed up the convergence in distributed and parallel environment. Previously known solutions that achieved comparable convergence time and approximation ratio required exponential computational and space overhead per agent.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2100001654",
    "type": "article"
  },
  {
    "title": "Approximating the Girth",
    "doi": "https://doi.org/10.1145/2438645.2438647",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Liam Roditty; Roei Tov",
    "corresponding_authors": "",
    "abstract": "This article considers the problem of computing a minimum weight cycle in weighted undirected graphs. Given a weighted undirected graph G = ( V , E , w ), let C be a minimum weight cycle of G , let w ( C ) be the weight of C , and let w max ( C ) be the weight of the maximum edge of C . We obtain three new approximation algorithms for the minimum weight cycle problem: (1) for integral weights from the range [1, M ], an algorithm that reports a cycle of weight at most 4 3 w ( C ) in O ( n 2 log n (log n + log M )) time; (2) For integral weights from the range [1, M ], an algorithm that reports a cycle of weight at most w ( C ) + w max ( C ) in O ( n 2 log n (log n + log M )) time; (3) For nonnegative real edge weights, an algorithm that for any ε &gt; 0 reports a cycle of weight at most (4 3 + ε ) w ( C ) in O (1 ε n 2 log n (log log n )) time. In a recent breakthrough, Williams and Williams [2010] showed that a subcubic algorithm, that computes the exact minimum weight cycle in undirected graphs with integral weights from the range [1, M ], implies a subcubic algorithm for computing all-pairs shortest paths in directed graphs with integral weights from the range [− M , M ]. This implies that in order to get a subcubic algorithm for computing a minimum weight cycle, we have to relax the problem and to consider an approximated solution. Lingas and Lundell [2009] were the first to consider approximation in the context of minimum weight cycle in weighted graphs. They presented a 2-approximation algorithm for integral weights with O ( n 2 log n (log n + log M )) running time. They also posed, as an open problem, the question whether it is possible to obtain a subcubic algorithm with a c -approximation, where c &lt; 2. The current article answers this question in the affirmative, by presenting an algorithm with 4/3-approximation and the same running time. Surprisingly, the approximation factor of 4/3 is not accidental. We show, using the new result of Williams and Williams [2010], that a subcubic combinatorial algorithm with (4/3 − ε )-approximation, where 0 &lt; ε ≤ 1/3, implies a subcubic combinatorial algorithm for multiplying two boolean matrices.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2156306627",
    "type": "article"
  },
  {
    "title": "Ordered Level Planarity and Its Relationship to Geodesic Planarity, Bi-Monotonicity, and Variations of Level Planarity",
    "doi": "https://doi.org/10.1145/3359587",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "Boris Klemz; Günter Rote",
    "corresponding_authors": "",
    "abstract": "We introduce and study the problem Ordered Level Planarity, which asks for a planar drawing of a graph such that vertices are placed at prescribed positions in the plane and such that every edge is realized as a y -monotone curve. This can be interpreted as a variant of Level Planarity in which the vertices on each level appear in a prescribed total order. We establish a complexity dichotomy with respect to both the maximum degree and the level-width, that is, the maximum number of vertices that share a level. Our study of Ordered Level Planarity is motivated by connections to several other graph drawing problems. Geodesic Planarity asks for a planar drawing of a graph such that vertices are placed at prescribed positions in the plane and such that every edge e is realized as a polygonal path p composed of line segments with two adjacent directions from a given set S of directions that is symmetric with respect to the origin. Our results on Ordered Level Planarity imply NP -hardness for any S with ∣S∣ ≥ 4, even if the given graph is a matching. Manhattan Geodesic Planarity is the special case where S contains precisely the horizontal and vertical directions. Katz, Krug, Rutter, and Wolff claimed that Manhattan Geodesic Planarity can be solved in polynomial time for the special case of matchings [GD’09]. Our results imply that this is incorrect unless P = NP . Our reduction extends to settle the complexity of the Bi-Monotonicity problem, which was proposed by Fulek, Pelsmajer, Schaefer, and Štefankovič. Ordered Level Planarity turns out to be a special case of T-Level Planarity, Clustered Level Planarity, and Constrained Level Planarity. Thus, our results strengthen previous hardness results. In particular, our reduction to Clustered Level Planarity generates instances with only two non-trivial clusters. This answers a question posed by Angelini, Da Lozzo, Di Battista, Frati, and Roselli.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2745320730",
    "type": "article"
  },
  {
    "title": "Parallel Algorithms and Concentration Bounds for the Lovász Local Lemma via Witness DAGs",
    "doi": "https://doi.org/10.1145/3147211",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Bernhard Haeupler; David G. Harris",
    "corresponding_authors": "",
    "abstract": "The Lovász Local Lemma (LLL) is a cornerstone principle in the probabilistic method of combinatorics, and a seminal algorithm of Moser and Tardos (2010) provides an efficient randomized algorithm to implement it. This can be parallelized to give an algorithm that uses polynomially many processors and runs in O (log 3 n ) time on an EREW PRAM, stemming from O (log n ) adaptive computations of a maximal independent set (MIS). Chung et al. (2014) developed faster local and parallel algorithms, potentially running in time O (log 2 n ), but these algorithms require more stringent conditions than the LLL. We give a new parallel algorithm that works under essentially the same conditions as the original algorithm of Moser and Tardos but uses only a single MIS computation, thus running in O (log 2 n ) time on an EREW PRAM. This can be derandomized to give an NC algorithm running in time O (log 2 n ) as well, speeding up a previous NC LLL algorithm of Chandrasekaran et al. (2013). We also provide improved and tighter bounds on the runtimes of the sequential and parallel resampling-based algorithms originally developed by Moser and Tardos. These apply to any problem instance in which the tighter Shearer LLL criterion is satisfied.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2772781679",
    "type": "article"
  },
  {
    "title": "Independence and Efficient Domination on <i>P</i> <sub>6</sub> -free Graphs",
    "doi": "https://doi.org/10.1145/3147214",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "Daniel Lokshtanov; Marcin Pilipczuk; Erik Jan van Leeuwen",
    "corresponding_authors": "",
    "abstract": "In the M aximum W eight I ndependent S et problem, the input is a graph G , every vertex has a non-negative integer weight, and the task is to find a set S of pairwise nonadjacent vertices, maximizing the total weight of the vertices in S . We give an n O (log 2 n ) time algorithm for this problem on graphs excluding the path P 6 on 6 vertices as an induced subgraph. Currently, there is no constant k known for which M aximum W eight I ndependent S et on P k -free graphs becomes NP-hard, and our result implies that if such a k exists, then k &gt; 6 unless all problems in NP can be decided in quasi-polynomial time. Using the combinatorial tools that we develop for this algorithm, we also give a polynomial-time algorithm for M aximum W eight E fficient D ominating S et on P 6 -free graphs. In this problem, the input is a graph G , every vertex has an integer weight, and the objective is to find a set S of maximum weight such that every vertex in G has exactly one vertex in S in its closed neighborhood or to determine that no such set exists. Prior to our work, the class of P 6 -free graphs was the only class of graphs defined by a single forbidden induced subgraph on which the computational complexity of M aximum W eight E fficient D ominating S et was unknown.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2773660891",
    "type": "article"
  },
  {
    "title": "<i>k</i> -center Clustering under Perturbation Resilience",
    "doi": "https://doi.org/10.1145/3381424",
    "publication_date": "2020-03-09",
    "publication_year": 2020,
    "authors": "Maria-Florina Balcan; Nika Haghtalab; Colin White",
    "corresponding_authors": "",
    "abstract": "The k -center problem is a canonical and long-studied facility location and clustering problem with many applications in both its symmetric and asymmetric forms. Both versions of the problem have tight approximation factors on worst case instances: a 2-approximation for symmetric k -center and an O (log * ( k ))-approximation for the asymmetric version. Therefore, to improve on these ratios, one must go beyond the worst case. In this work, we take this approach and provide strong positive results both for the asymmetric and symmetric k -center problems under a natural input stability (promise) condition called α-perturbation resilience [15], which states that the optimal solution does not change under any α-factor perturbation to the input distances. We provide algorithms that give strong guarantees simultaneously for stable and non-stable instances: Our algorithms always inherit the worst-case guarantees of clustering approximation algorithms and output the optimal solution if the input is 2-perturbation resilient. In particular, we show that if the input is only perturbation resilient on part of the data, our algorithm will return the optimal clusters from the region of the data that is perturbation resilient while achieving the best worst-case approximation guarantee on the remainder of the data. Furthermore, we prove that our result is tight by showing symmetric k -center under (2 − ϵ)-perturbation resilience is hard unless NP = RP . The impact of our results is multifaceted. First, to our knowledge, asymmetric k -center is the first problem that is hard to approximate to any constant factor in the worst case, yet can be optimally solved in polynomial time under perturbation resilience for a constant value of α. This is also the first tight result for any problem under perturbation resilience, i.e., this is the first time the exact value of α for which the problem switches from being NP-hard to efficiently computable has been found. Furthermore, our results illustrate a surprising relationship between symmetric and asymmetric k -center instances under perturbation resilience. Unlike approximation ratio, for which symmetric k -center is easily solved to a factor of 2 but asymmetric k -center cannot be approximated to any constant factor, both symmetric and asymmetric k -center can be solved optimally under resilience to 2-perturbations. Finally, our guarantees in the setting where only part of the data satisfies perturbation resilience make these algorithms more applicable to real-life instances.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3011209672",
    "type": "article"
  },
  {
    "title": "Time- and Space-optimal Algorithm for the Many-visits TSP",
    "doi": "https://doi.org/10.1145/3382038",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "André Berger; László Kozma; Matthias Mnich; Roland Vincze",
    "corresponding_authors": "",
    "abstract": "The many-visits traveling salesperson problem (MV-TSP) asks for an optimal tour of n cities that visits each city c a prescribed number k c of times. Travel costs may be asymmetric, and visiting a city twice in a row may incur a non-zero cost. The MV-TSP problem finds applications in scheduling, geometric approximation, and Hamiltonicity of certain graph families. The fastest known algorithm for MV-TSP is due to Cosmadakis and Papadimitriou (SICOMP, 1984). It runs in time n O(n) + O(n 3 log ∑ c k c ) and requires n ᶿ(n) space. An interesting feature of the Cosmadakis-Papadimitriou algorithm is its logarithmic dependence on the total length ∑ c k c of the tour, allowing the algorithm to handle instances with very long tours. The superexponential dependence on the number of cities in both the time and space complexity, however, renders the algorithm impractical for all but the narrowest range of this parameter. In this article, we improve upon the Cosmadakis-Papadimitriou algorithm, giving an MV-TSP algorithm that runs in time 2 O(n) , i.e., single-exponential in the number of cities, using polynomial space. The space requirement of our algorithm is (essentially) the size of the output, and assuming the Exponential-Time Hypothesis (ETH), the problem cannot be solved in time 2 o(n) . Our algorithm is deterministic, and arguably both simpler and easier to analyze than the original approach of Cosmadakis and Papadimitriou. It involves an optimization over directed spanning trees and a recursive, centroid-based decomposition of trees.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3033696807",
    "type": "article"
  },
  {
    "title": "Deterministic Sparse Suffix Sorting in the Restore Model",
    "doi": "https://doi.org/10.1145/3398681",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Johannes Fischer; I Tomohiro; Dominik Köppl",
    "corresponding_authors": "",
    "abstract": "Given a text T of length n , we propose a deterministic online algorithm computing the sparse suffix array and the sparse longest common prefix array of T in O( c √ lg n + m lg m lg n lg * n ) time with O( m ) words of space under the premise that the space of T is rewritable, where m ≤ n is the number of suffixes to be sorted (provided online and arbitrarily), and c is the number of characters with m ≤ c ≤ n that must be compared for distinguishing the designated suffixes.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3040814014",
    "type": "article"
  },
  {
    "title": "Zeros of Holant Problems",
    "doi": "https://doi.org/10.1145/3418056",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Heng Guo; Chao Liao; Pinyan Lu; Chihao Zhang",
    "corresponding_authors": "",
    "abstract": "We present fully polynomial-time (deterministic or randomised) approximation schemes for Holant problems, defined by a non-negative constraint function satisfying a generalised second-order recurrence modulo in a couple of exceptional cases. As a consequence, any non-negative Holant problem on cubic graphs has an efficient approximation algorithm unless the problem is equivalent to approximately counting perfect matchings, a central open problem in the area. This is in sharp contrast to the computational phase transition shown by two-state spin systems on cubic graphs. Our main technique is the recently established connection between zeros of graph polynomials and approximate counting.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3113819057",
    "type": "article"
  },
  {
    "title": "Parameterized Approximation Algorithms for Bidirected Steiner Network Problems",
    "doi": "https://doi.org/10.1145/3447584",
    "publication_date": "2021-04-19",
    "publication_year": 2021,
    "authors": "Rajesh Chitnis; Andreas Emil Feldmann; Pasin Manurangsi",
    "corresponding_authors": "",
    "abstract": "The D irected S teiner N etwork (DSN) problem takes as input a directed graph G =( V , E ) with non-negative edge-weights and a set D ⊆ V × V of k demand pairs. The aim is to compute the cheapest network N⊆ G for which there is an s\\rightarrow t path for each ( s , t )∈ D. It is known that this problem is notoriously hard, as there is no k 1/4− o (1) -approximation algorithm under Gap-ETH, even when parametrizing the runtime by k [Dinur &amp; Manurangsi, ITCS 2018]. In light of this, we systematically study several special cases of DSN and determine their parameterized approximability for the parameter k . For the bi -DSNP lanar problem, the aim is to compute a solution N⊆ G whose cost is at most that of an optimum planar solution in a bidirected graph G , i.e., for every edge uv of G the reverse edge vu exists and has the same weight. This problem is a generalization of several well-studied special cases. Our main result is that this problem admits a parameterized approximation scheme (PAS) for k . We also prove that our result is tight in the sense that (a) the runtime of our PAS cannot be significantly improved, and (b) no PAS exists for any generalization of bi-DSNP lanar , under standard complexity assumptions. The techniques we use also imply a polynomial-sized approximate kernelization scheme (PSAKS). Additionally, we study several generalizations of bi -DSNP lanar and obtain upper and lower bounds on obtainable runtimes parameterized by k . One important special case of DSN is the S trongly C onnected S teiner S ubgraph (SCSS) problem, for which the solution network N⊆ G needs to strongly connect a given set of k terminals. It has been observed before that for SCSS a parameterized 2-approximation exists for parameter k [Chitnis et al., IPEC 2013]. We give a tight inapproximability result by showing that for k no parameterized (2 − ε)-approximation algorithm exists under Gap-ETH. Additionally, we show that when restricting the input of SCSS to bidirected graphs, the problem remains NP-hard but becomes FPT for k .",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3155138594",
    "type": "article"
  },
  {
    "title": "Fast Zeta Transforms for Lattices with Few Irreducibles",
    "doi": "https://doi.org/10.1145/2629429",
    "publication_date": "2015-12-31",
    "publication_year": 2015,
    "authors": "Andreas Björklund; Thore Husfeldt; Petteri Kaski; Mikko Koivisto; Jesper Nederlof; Pekka Parviainen",
    "corresponding_authors": "",
    "abstract": "We investigate fast algorithms for changing between the standard basis and an orthogonal basis of idempotents for Möbius algebras of finite lattices. We show that every lattice with v elements, n of which are nonzero and join-irreducible (or, by a dual result, nonzero and meet-irreducible), has arithmetic circuits of size O ( vn ) for computing the zeta transform and its inverse, thus enabling fast multiplication in the Möbius algebra. Furthermore, the circuit construction in fact gives optimal (up to constants) monotone circuits for several lattices of combinatorial and algebraic relevance, such as the lattice of subsets of a finite set, the lattice of set partitions of a finite set, the lattice of vector subspaces of a finite vector space, and the lattice of positive divisors of a positive integer.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W3160627641",
    "type": "article"
  },
  {
    "title": "All-Or-Nothing Generalized Assignment with Application to Scheduling Advertising Campaigns",
    "doi": "https://doi.org/10.1145/2843944",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Ron Adany; Moran Feldman; Elad Haramaty; Rohit Khandekar; Baruch Schieber; Roy Schwartz; Hadas Shachnai; Tami Tamir",
    "corresponding_authors": "",
    "abstract": "We study a variant of the generalized assignment problem ( gap ), which we label all-or-nothing gap ( agap ). We are given a set of items, partitioned into n groups, and a set of m bins. Each item ℓ has size s ℓ &gt; 0, and utility a ℓ j ⩾ 0 if packed in bin j . Each bin can accommodate at most one item from each group; the total size of the items in a bin cannot exceed its capacity. A group of items is satisfied if all of its items are packed. The goal is to find a feasible packing of a subset of the items in the bins such that the total utility from satisfied groups is maximized. We motivate the study of agap by pointing out a central application in scheduling advertising campaigns. Our main result is an O (1)-approximation algorithm for agap instances arising in practice, in which each group consists of at most m /2 items. Our algorithm uses a novel reduction of agap to maximizing submodular function subject to a matroid constraint. For agap instances with a fixed number of bins, we develop a randomized polynomial time approximation scheme (PTAS) , relying on a nontrivial LP relaxation of the problem. We present a (3 + ε)-approximation as well as PTASs for other special cases of agap , where the utility of any item does not depend on the bin in which it is packed. Finally, we derive hardness results for the different variants of agap studied in this paper.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2343846702",
    "type": "article"
  },
  {
    "title": "Counting List Homomorphisms from Graphs of Bounded Treewidth: Tight Complexity Bounds",
    "doi": "https://doi.org/10.1145/3640814",
    "publication_date": "2024-01-16",
    "publication_year": 2024,
    "authors": "Jacob Focke; Dániel Marx; Paweł Rzążewski",
    "corresponding_authors": "",
    "abstract": "The goal of this work is to give precise bounds on the counting complexity of a family of generalized coloring problems (list homomorphisms) on bounded-treewidth graphs. Given graphs G , H , and lists L (v) ⊆ V(H) for every v ∈ V(G) , a f:V(G) → V(H) that preserves the edges (i.e., uv ∈ E(G) implies f(u)f(v) ∈ E(H) ) and respects the lists (i.e., f(v) ∈ L(v) ). Standard techniques show that if G is given with a tree decomposition of width t , then the number of list homomorphisms can be counted in time |V(H)| t ⋅ n 𝒪(1) . Our main result is determining, for every fixed graph H , how much the base |V(H)| in the running time can be improved. For a connected graph H , we define irr( H ) in the following way: if H has a loop or is nonbipartite, then irr( H ) is the maximum size of a set S⊆ V(H) where any two vertices have different neighborhoods; if H is bipartite, then irr( H ) is the maximum size of such a set that is fully in one of the bipartition classes. For disconnected H , we define irr( H ) as the maximum of irr( C ) over every connected component C of H . It follows from earlier results that if irr( H )=1, then the problem of counting list homomorphisms to H is polynomial-time solvable, and otherwise it is #P-hard. We show that, for every fixed graph H , the number of list homomorphisms from (G,L) to H — can be counted in time \\(\\operatorname{irr}(H)^t\\cdot n^{\\mathcal {O}(1)}\\) if a tree decomposition of G having width at most t is given in the input, and, — given that \\(\\operatorname{irr}(H)\\ge 2\\) , cannot be counted in time \\((\\operatorname{irr}(H)-\\varepsilon)^t\\cdot n^{\\mathcal {O}(1)}\\) for any \\(\\varepsilon \\gt 0\\) , even if a tree decomposition of G having width at most t is given in the input, unless the Counting Strong Exponential-Time Hypothesis (#SETH) fails. Thereby, we give a precise and complete complexity classification featuring matching upper and lower bounds for all target graphs with or without loops.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4390918625",
    "type": "article"
  },
  {
    "title": "Flow-augmentation II: Undirected Graphs",
    "doi": "https://doi.org/10.1145/3641105",
    "publication_date": "2024-01-19",
    "publication_year": 2024,
    "authors": "Eun Jung Kim; Stefan Kratsch; Marcin Pilipczuk; Magnus Wahlström",
    "corresponding_authors": "",
    "abstract": "We present an undirected version of the recently introduced flow-augmentation technique: Given an undirected multigraph G with distinguished vertices s,t ∈ V(G) and an integer k , one can in randomized k 𝒪(1) ⋅ (|V(G)| + |E(G)|) time sample a set A ⊆ \\(\\binom{V(G)}{2}\\) such that the following holds: for every inclusion-wise minimal st -cut Z in G of cardinality at most k , Z becomes a minimum-cardinality cut between s and t in G+A (i.e., in the multigraph G with all edges of A added) with probability 2 -𝒪( k log k ). Compared to the version for directed graphs [STOC 2022], the version presented here has improved success probability (2 -𝒪( k log k ) instead of 2 -𝒪( k 4 log k ) ), linear dependency on the graph size in the running time bound, and an arguably simpler proof. An immediate corollary is that the Bi-objective st -Cut problem can be solved in randomized FPT time 2 𝒪( k log k ) (|V(G)|+|E(G)|) on undirected graphs.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4391026304",
    "type": "article"
  },
  {
    "title": "True Contraction Decomposition and Almost ETH-Tight Bipartization for Unit-Disk Graphs",
    "doi": "https://doi.org/10.1145/3656042",
    "publication_date": "2024-07-03",
    "publication_year": 2024,
    "authors": "Sayan Bandyapadhyay; William Lochet; Daniel Lokshtanov; Saket Saurabh; Jie Xue",
    "corresponding_authors": "",
    "abstract": "We prove a structural theorem for unit-disk graphs, which (roughly) states that given a set \\(\\mathcal{D}\\) of \\(n\\) unit disks inducing a unit-disk graph \\(G_{\\mathcal{D}}\\) and a number \\(p\\in[n]\\) , one can partition \\(\\mathcal{D}\\) into \\(p\\) subsets \\(\\mathcal{D}_{1},\\dots,\\mathcal{D}_{p}\\) such that for every \\(i\\in[p]\\) and every \\(\\mathcal{D}^{\\prime}\\subseteq\\mathcal{D}_{i}\\) , the graph obtained from \\(G_{\\mathcal{D}}\\) by contracting all edges between the vertices in \\(\\mathcal{D}_{i}\\backslash\\mathcal{D}^{\\prime}\\) admits a tree decomposition in which each bag consists of \\(O(p+|\\mathcal{D}^{\\prime}|)\\) cliques. Our theorem can be viewed as an analog for unit-disk graphs of the structural theorems for planar graphs and almost-embeddable graphs proved recently by Marx et al. [SODA ’22] and Bandyapadhyay et al. [SODA ’22]. By applying our structural theorem, we give several new combinatorial and algorithmic results for unit-disk graphs. On the combinatorial side, we obtain the first Contraction Decomposition Theorem for unit-disk graphs, resolving an open question in the work by Panolan et al. [SODA ’19]. On the algorithmic side, we obtain a new algorithm for bipartization (also known as odd cycle transversal) on unit-disk graphs, which runs in \\(2^{O(\\sqrt{k}\\log k)}\\cdot n^{O(1)}\\) time, where \\(k\\) denotes the solution size. Our algorithm significantly improves the previous slightly subexponential-time algorithm given by Lokshtanov et al. [SODA ’22] which runs in \\(2^{O(k^{27/28})}\\cdot n^{O(1)}\\) time. We also show that the problem cannot be solved in \\(2^{o(\\sqrt{k})}\\cdot n^{O(1)}\\) time assuming the Exponential Time Hypothesis, which implies that our algorithm is almost optimal.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4394618918",
    "type": "article"
  },
  {
    "title": "Efficient decoding up to a constant fraction of the code length for asymptotically good quantum codes",
    "doi": "https://doi.org/10.1145/3663763",
    "publication_date": "2024-05-07",
    "publication_year": 2024,
    "authors": "Anthony Leverrier; Gilles Zémor",
    "corresponding_authors": "",
    "abstract": "We introduce and analyse an efficient decoder for quantum Tanner codes that can correct adversarial errors of linear weight. Previous decoders for quantum low-density parity-check codes could only handle adversarial errors of weight \\(O(\\sqrt{n\\log n})\\) . We also work on the link between quantum Tanner codes and the Lifted Product codes of Panteleev and Kalachev, and show that our decoder can be adapted to the latter. The decoding algorithm alternates between sequential and parallel procedures and converges in linear time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4396708890",
    "type": "article"
  },
  {
    "title": "On the complexity of symmetric vs. functional PCSPs",
    "doi": "https://doi.org/10.1145/3673655",
    "publication_date": "2024-06-18",
    "publication_year": 2024,
    "authors": "Tamio-Vesa Nakajima; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "The complexity of the promise constraint satisfaction problem \\(\\operatorname{PCSP}(\\mathbf{A},\\mathbf{B})\\) is largely unknown, even for symmetric \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) , except for the case when \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) are Boolean. First, we establish a dichotomy for \\(\\operatorname{PCSP}(\\mathbf{A},\\mathbf{B})\\) where \\(\\mathbf{A},\\mathbf{B}\\) are symmetric, \\(\\mathbf{B}\\) is functional (i.e. any \\(r-1\\) elements of an \\(r\\) -ary tuple uniquely determines the last one), and \\((\\mathbf{A},\\mathbf{B})\\) satisfies technical conditions we introduce called dependency and additivity . This result implies a dichotomy for \\(\\operatorname{PCSP}(\\mathbf{A},\\mathbf{B})\\) with \\(\\mathbf{A},\\mathbf{B}\\) symmetric and \\(\\mathbf{B}\\) functional if (i) \\(\\mathbf{A}\\) is Boolean, or (ii) \\(\\mathbf{A}\\) is a hypergraph of a small uniformity, or (iii) \\(\\mathbf{A}\\) has a relation \\(R^{\\mathbf{A}}\\) of arity at least 3 such that the hypergraph diameter of \\((A,R^{\\mathbf{A}})\\) is at most 1. Second, we show that for \\(\\operatorname{PCSP}(\\mathbf{A},\\mathbf{B})\\) , where \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) contain a single relation, \\(\\mathbf{A}\\) satisfies a technical condition called balancedness , and \\(\\mathbf{B}\\) is arbitrary, the combined basic linear programming relaxation ( \\(\\operatorname{BLP}\\) ) and the affine integer programming relaxation ( \\(\\operatorname{AIP}\\) ) is no more powerful than the (in general strictly weaker) \\(\\operatorname{AIP}\\) relaxation. Balanced \\(\\mathbf{A}\\) include symmetric \\(\\mathbf{A}\\) or, more generally, \\(\\mathbf{A}\\) preserved by a transitive permutation group.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4399783013",
    "type": "article"
  },
  {
    "title": "The NP-completeness column",
    "doi": "https://doi.org/10.1145/1159892.1159901",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "David S. Johnson",
    "corresponding_authors": "David S. Johnson",
    "abstract": "This is the 25th edition of a column that covers new developments in the theory of NP-completeness. The presentation is modeled on that which M. R. Garey and I used in our book Computers and Intractability: A Guide to the Theory of NP-Completeness , W. H. Freeman &amp; Co., New York, 1979, hereinafter referred to as “[G&amp;J].” Previous columns, the first 23 of which appeared in Journal of Algorithms , will be referred to by a combination of their sequence number and year of appearance, for example, [Col 1, 1981]. Full bibliographic details on the previous columns as well as downloadable unofficial versions of them can be found at http://www.reseach.att.com/~dsj/columns/. This edition of the column discusses the wide range of lower bounds on approximation guarantees for NP-hard optimization problems both in their functional forms and in the hypotheses on which they depend.",
    "cited_by_count": 15,
    "openalex_id": "https://openalex.org/W2018451329",
    "type": "article"
  },
  {
    "title": "A loopless Gray code for rooted trees",
    "doi": "https://doi.org/10.1145/1150334.1150335",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "James F. Korsh; Paul S. LaFollette",
    "corresponding_authors": "",
    "abstract": "Beyer and Hedetniemi [1980] gave the first constant average-time algorithm for the generation of all rooted trees with n nodes. This article presents the first combinatorial Gray code for these trees and a loopless algorithm for its generation.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2022419565",
    "type": "article"
  },
  {
    "title": "Black box for constant-time insertion in priority queues (note)",
    "doi": "https://doi.org/10.1145/1077464.1077471",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Stephen Alstrup; Thore Husfeldt; Theis Rauhe; Mikkel Thorup",
    "corresponding_authors": "",
    "abstract": "We present a simple black box that takes a priority queue Q which supports find-min, insert, and delete in x-time at most t . Here x-time may be worst-case, expected, or amortized. The black-box transforms Q into a priority queue Q * that supports find-min in constant time, insert in constant x-time, and delete in x-time O ( t ). Moreover, if Q supports dec-key in constant time, then so does Q *.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2070213718",
    "type": "article"
  },
  {
    "title": "The register function for <i>t</i> -ary trees",
    "doi": "https://doi.org/10.1145/1159892.1159894",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Michael Drmota; Helmut Prodinger",
    "corresponding_authors": "",
    "abstract": "For the register function for t -ary trees, recently introduced by Auber et al., we prove that the average is log 4 n + O (1), if all such trees with n internal nodes are considered to be equally likely.This result remains true for rooted trees where the set of possible out-degrees is finite. Furthermore we obtain exponential tail estimates for the distribution of the register function. Thus, the distribution is highly concentrated around the mean value.",
    "cited_by_count": 14,
    "openalex_id": "https://openalex.org/W2104498389",
    "type": "article"
  },
  {
    "title": "A faster and simpler fully dynamic transitive closure",
    "doi": "https://doi.org/10.1145/1328911.1328917",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Liam Roditty",
    "corresponding_authors": "Liam Roditty",
    "abstract": "We obtain a new fully dynamic algorithm for maintaining the transitive closure of a directed graph. Our algorithm maintains the transitive closure matrix in a total running time of O ( mn + ( ins + del ) · n 2 ), where ins ( del ) is the number of insert (delete) operations performed. Here n is the number of vertices in the graph and m is the initial number of edges in the graph. Obviously, reachability queries can be answered in constant time. The algorithm uses only O ( n 2 ) time which is essentially optimal for maintaining the transitive closure matrix. Our algorithm can also support path queries. If v is reachable from u , the algorithm can produce a path from u to v in time proportional to the length of the path. The best previously known algorithm for the problem is due to Demetrescu and Italiano [2000]. Their algorithm has a total running time of O ( n 3 + ( ins + del ) · n 2 ). The query time is also constant. In addition, we also present a simple algorithm for directed acyclic graphs (DAGs) with a total running time of O ( mn + ins · n 2 + del ). Our algorithms are obtained by combining some new ideas with techniques of Italiano [1986, 1988], King [1999], King and Thorup [2001] and Frigioni et al. [2001]. We also note that our algorithms are extremely simple and can be easily implemented.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W1997898455",
    "type": "article"
  },
  {
    "title": "Guessing secrets efficiently via list decoding",
    "doi": "https://doi.org/10.1145/1290672.1290679",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Noga Alon; Venkatesan Guruswami; Tali Kaufman; Madhu Sudan",
    "corresponding_authors": "",
    "abstract": "We consider the guessing secrets problem defined by Chung et al. [2001]. This is a variant of the standard 20 questions game where the player has a set of k &gt; 1 secrets from a universe of N possible secrets. The player is asked Boolean questions about the secret. For each question, the player picks one of the k secrets adversarially, and answers according to this secret. We present an explicit set of O (log N ) questions together with an efficient (i.e., poly(log N ) time) algorithm to solve the guessing secrets problem for the case of 2 secrets. This answers the main algorithmic question left unanswered by Chung et al. [2001]. The main techniques we use are small ϵ-biased spaces and the notion of list decoding . We also establish bounds on the number of questions needed to solve the k -secrets game for k &gt; 2, and discuss how list decoding can be used to get partial information about the secrets, specifically to find a small core of secrets that must intersect the actual set of k secrets.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2137164140",
    "type": "article"
  },
  {
    "title": "Primal-dual approach for directed vertex connectivity augmentation and generalizations",
    "doi": "https://doi.org/10.1145/1361192.1361197",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "László A. Végh; András A. Benczúr",
    "corresponding_authors": "",
    "abstract": "In their seminal paper, Frank and Jordán [1995] show that a large class of optimization problems, including certain directed graph augmentation, fall into the class of covering supermodular functions over pairs of sets. They also give an algorithm for such problems, however, it relies on the ellipsoid method. Prior to our result, combinatorial algorithms existed only for the 0--1 valued problem. Our key result is a combinatorial algorithm for the general problem that includes directed vertex or S − T connectivity augmentation. The algorithm is based on Benczúr's previous algorithm for the 0--1 valued case [Benczúr 2003]. Our algorithm uses a primal-dual scheme for finding covers of partially ordered sets that satisfy natural abstract properties as in Frank and Jordán. For an initial (possibly greedy) cover, the algorithm searches for witnesses for the necessity of each element in the cover. If no two (weighted) witnesses have a common cover, the solution is optimal. As long as this is not the case, the witnesses are gradually exchanged for smaller ones. Each witness change defines an appropriate change in the solution; these changes are finally unwound in a shortest-path manner to obtain a solution of size one less.",
    "cited_by_count": 12,
    "openalex_id": "https://openalex.org/W2165498664",
    "type": "article"
  },
  {
    "title": "Path decomposition under a new cost measure with applications to optical network design",
    "doi": "https://doi.org/10.1145/1328911.1328926",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Elliot Anshelevich; Lisa Zhang",
    "corresponding_authors": "",
    "abstract": "We introduce a problem directly inspired by its application to DWDM ( dense wavelength division multiplexing ) network design. We are given a set of demands to be carried over a network. Our goal is to choose a route for each demand and to decompose the network into a collection of edge-disjoint simple paths. These paths are called optical line systems . The cost of routing one unit of demand is the number of line systems with which the demand route overlaps; our design objective is to minimize the total cost over all demands. This cost metric is motivated by the need to minimize O-E-O ( optical-electrical-optical ) conversions in optical transmission. For given line systems, it is easy to find the optimal demand routes. On the other hand, for given demand routes designing the optimal line systems can be NP-hard. We first present a 2-approximation for general network topologies. As optical networks often have low node degrees, we offer an algorithm that finds the optimal solution for the special case in which the node degree is at most 3. Our solution is based on a local greedy approach. If neither demand routes nor line systems are fixed, the situation becomes much harder. Even for a restricted scenario on a 3-regular Hamiltonian network, no efficient algorithm can guarantee a constant approximation better than 2. For general topologies, we offer a simple algorithm with an O (log K )- and an O (log n )-approximation, where K is the number of demands and n the number of nodes. This approximation ratio is almost tight. For rings, a common special topology, we offer a more complex 3/2-approximation algorithm.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1984292362",
    "type": "article"
  },
  {
    "title": "No sorting? better searching!",
    "doi": "https://doi.org/10.1145/1328911.1328913",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Gianni Franceschini; Roberto Grossi",
    "corresponding_authors": "",
    "abstract": "Questions about order versus disorder in systems and models have been fascinating scientists over the years. In computer science, order is intimately related to sorting, commonly meant as the task of arranging keys in increasing or decreasing order with respect to an underlying total order relation. The sorted organization is amenable for searching a set of n keys, since each search requires Θ(log n ) comparisons in the worst case, which is optimal if the cost of a single comparison can be considered a constant. Nevertheless, we prove that disorder implicitly provides more information than order does. For the general case of searching an array of multidimensional keys whose comparison cost is proportional to their length (and hence which cannot be considered a constant), we demonstrate that “suitable” disorder gives better bounds than those derivable by using the natural lexicographic order. We start from previous work done by Andersson et al. [2001], who proved that Θ( k log log n /log log(4 + k log log n /log n ) + k + log n ) character comparisons (or probes) comprise the tight complexity for searching a plain sorted array of n keys, each of length k , arranged in lexicographic order. We describe a novel permutation of the n keys that is different from the sorted order. When keys are kept “unsorted” in the array according to this permutation, the complexity of searching drops to Θ( k + log n ) character comparisons (or probes) in the worst case, which is optimal among all possible permutations, up to a constant factor. Consequently, disorder carries more information than does order; this fact was not observable before, since the latter two bounds are Θ(log n ) when k = O (1). More implications are discussed in the article, including searching in the bit-probe model.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2057316598",
    "type": "article"
  },
  {
    "title": "Optimality of an algorithm solving the Bottleneck Tower of Hanoi problem",
    "doi": "https://doi.org/10.1145/1367064.1367065",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Yefim Dinitz; Shay Solomon",
    "corresponding_authors": "",
    "abstract": "We study the Bottleneck Tower of Hanoi puzzle posed by D. Wood in 1981. There, a relaxed placement rule allows a larger disk to be placed higher than a smaller one if their size difference is less than a pregiven value k . A shortest sequence of moves (optimal algorithm) transferring all the disks placed on some peg in decreasing order of size, to another peg in the same order is in question. In 1992, D. Poole suggested a natural disk-moving strategy for this problem, and computed the length of the shortest move sequence under its framework. However, other strategies were overlooked, so the lower bound/optimality question remained open. In 1998, Benditkis, Berend, and Safro proved the optimality of Poole's algorithm for the first nontrivial case k = 2. We prove Poole's algorithm to be optimal in the general case.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W2058956491",
    "type": "article"
  },
  {
    "title": "Clustering lines in high-dimensional space",
    "doi": "https://doi.org/10.1145/1868237.1868246",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Jie Gao; Michael Langberg; Leonard J. Schulman",
    "corresponding_authors": "",
    "abstract": "A set of k balls B 1 , …, B k in a Euclidean space is said to cover a collection of lines if every line intersects some ball. We consider the k - center problem for lines in high-dimensional space: Given a set of n lines l = { l 1 ,…, l n in R d , find k balls of minimum radius which cover l . We present a 2-approximation algorithm for the cases k = 2, 3 of this problem, having running time quasi-linear in the number of lines and the dimension of the ambient space. Our result for 3-clustering is strongly based on a new result in discrete geometry that may be of independent interest: a Helly-type theorem for collections of axis-parallel “crosses” in the plane. The family of crosses does not have finite Helly number in the usual sense. Our Helly theorem is of a new type: it depends on ε-contracting the sets. In statistical practice, data is often incompletely specified; we consider lines as the most elementary case of incompletely specified data points. Clustering of data is a key primitive in nonparametric statistics. Our results provide a way of performing this primitive on incomplete data, as well as imputing the missing values.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2052979560",
    "type": "article"
  },
  {
    "title": "Instability of FIFO in the permanent sessions model at arbitrarily small network loads",
    "doi": "https://doi.org/10.1145/1541885.1541894",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Matthew Andrews",
    "corresponding_authors": "Matthew Andrews",
    "abstract": "We show that for any r &gt; 0, there is a network of First-In-First-Out servers and a fixed set of sessions such that: —The network load is r with respect to the permanent sessions model with bounded arrivals. —The network can be made unstable.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2123582246",
    "type": "article"
  },
  {
    "title": "Faster Algorithms for Computing Plurality Points",
    "doi": "https://doi.org/10.1145/3186990",
    "publication_date": "2018-06-16",
    "publication_year": 2018,
    "authors": "Mark de Berg; Joachim Gudmundsson; Mehran Mehr",
    "corresponding_authors": "",
    "abstract": "Let V be a set of n points in R d , which we call voters. A point p ∈ R d is preferred over another point p ′ ∈ R d by a voter υ ∈ V if dist(υ, p ) &lt; dist(υ, p ′). A point p is called a plurality point if it is preferred by at least as many voters as any other point p ′. We present an algorithm that decides in O ( n log n ) time whether V admits a plurality point in the L 2 norm and, if so, finds the (unique) plurality point. We also give efficient algorithms to compute a minimum-cost subset W ⊂ V such that V \\ W admits a plurality point, and to compute a so-called minimum-radius plurality ball. Finally, we consider the problem in the personalized L 1 norm, where each point υ ∈ V has a preference vector 〈 w 1 (υ),…, w d (υ)〉 and the distance from υ to any point p ∈ R d is given by ∑ i =1 d w i (υ)· | x i (υ)− x i ( p )|. For this case we can compute in O ( n d −1 ) time the set of all plurality points of V . When all preference vectors are equal, the running time improves to O ( n ).",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2469837900",
    "type": "article"
  },
  {
    "title": "Memoryless facility location in one pass",
    "doi": "https://doi.org/10.1145/2000807.2000817",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Dimitris Fotakis",
    "corresponding_authors": "Dimitris Fotakis",
    "abstract": "We present the first one-pass memoryless algorithm for metric Facility Location that maintains a set of facilities approximating the optimal facility configuration within a constant factor. The algorithm is randomized and very simple to state and implement. It processes the demand points one-by-one as they arrive, and keeps in memory only the facility locations currently open. We prove that its competitive ratio is less than 14 in the special case of uniform facility costs, and less than 49 in the general case of nonuniform facility costs.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W1994429514",
    "type": "article"
  },
  {
    "title": "On approximating multicriteria TSP",
    "doi": "https://doi.org/10.1145/2151171.2151180",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Bodo Manthey",
    "corresponding_authors": "Bodo Manthey",
    "abstract": "We present approximation algorithms for almost all variants of the multicriteria traveling salesman problem (TSP). First, we devise randomized approximation algorithms for multicriteria maximum traveling salesman problems (Max-TSP). For multicriteria Max-STSP where the edge weights have to be symmetric, we devise an algorithm with an approximation ratio of 2/3 - ε. For multicriteria Max-ATSP where the edge weights may be asymmetric, we present an algorithm with a ratio of 1/2 - ε. Our algorithms work for any fixed number k of objectives. Furthermore, we present a deterministic algorithm for bicriteria Max-STSP that achieves an approximation ratio of 7/27. Finally, we present a randomized approximation algorithm for the asymmetric multicriteria minimum TSP with triangle inequality (Min-ATSP). This algorithm achieves a ratio of log n + ε.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2141596881",
    "type": "article"
  },
  {
    "title": "A Data Structure for Nearest Common Ancestors with Linking",
    "doi": "https://doi.org/10.1145/3108240",
    "publication_date": "2017-09-19",
    "publication_year": 2017,
    "authors": "Harold N. Gabow",
    "corresponding_authors": "Harold N. Gabow",
    "abstract": "Consider a forest that evolves via link operations that make the root of one tree the child of a node in another tree. Intermixed with link operations are nca operations, which return the nearest common ancestor of two given nodes when such exists. This article shows that a sequence of m such nca and link operations on a forest of n nodes can be processed online in time O ( m α ( m , n )+ n ). This was previously known only for a restricted type of link operation. The special case where a link only extends a tree by adding a new leaf occurs in Edmonds’ algorithm for finding a maximum weight matching on a general graph. Incorporating our algorithm into the implementation of Edmonds’ algorithm in [9] achieves time O ( n ( m + n log n )) for weighted matching, an arguably optimum asymptotic bound ( n and m are the number of vertices and edges, respectively). Our data structure also provides a simple alternative implementation of the incremental-tree set merging algorithm of Gabow and Tarjan [11].",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2550952896",
    "type": "article"
  },
  {
    "title": "Asymptotically Optimal Encodings of Range Data Structures for Selection and Top- <i>k</i> Queries",
    "doi": "https://doi.org/10.1145/3012939",
    "publication_date": "2017-03-06",
    "publication_year": 2017,
    "authors": "Roberto Grossi; John Iacono; Gonzalo Navarro; Rajeev Raman; Srinivasa Rao Satti",
    "corresponding_authors": "",
    "abstract": "Given an array A [1, n ] of elements with a total order, we consider the problem of building a data structure that solves two queries: ( a ) selection queries receive a range [ i , j ] and an integer k and return the position of the k th largest element in A [ i , j ]; ( b ) top- k queries receive [ i , j ] and k and return the positions of the k largest elements in A [ i , j ]. These problems can be solved in optimal time, O (1+lg k /lg lg n ) and O ( k ), respectively, using linear-space data structures. We provide the first study of the encoding data structures for the above problems, where A cannot be accessed at query time. Several applications are interested in the relative order of the entries of A , and their positions, rather their actual values, and thus we do not need to keep A at query time. In those cases, encodings save storage space: we first show that any encoding answering such queries requires n lg k - O ( n + k lg k ) bits of space; then, we design encodings using O ( n lg k ) bits, that is, asymptotically optimal up to constant factors, while preserving optimal query time.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2592486490",
    "type": "article"
  },
  {
    "title": "Hollow Heaps",
    "doi": "https://doi.org/10.1145/3093240",
    "publication_date": "2017-07-27",
    "publication_year": 2017,
    "authors": "Thomas Dueholm Hansen; Haim Kaplan; Robert E. Tarjan; Uri Zwick",
    "corresponding_authors": "",
    "abstract": "We introduce the hollow heap, a very simple data structure with the same amortized efficiency as the classical Fibonacci heap. All heap operations except delete and delete-min take O(1) time, worst case as well as amortized; delete and delete-min take O(logn) amortized time on a heap of n items. Hollow heaps are the simplest structure to achieve these bounds. Hollow heaps combine two novel ideas: the use of lazy deletion and re-insertion to do decrease-key operations and the use of a dag (directed acyclic graph) instead of a tree or set of trees to represent a heap. Lazy deletion produces hollow nodes (nodes without items), giving the data structure its name.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2752947237",
    "type": "article"
  },
  {
    "title": "Separate, Measure and Conquer",
    "doi": "https://doi.org/10.1145/3111499",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Serge Gaspers; Gregory B. Sorkin",
    "corresponding_authors": "",
    "abstract": "We show a method resulting in the improvement of several polynomial-space, exponential-time algorithms. The method capitalizes on the existence of small balanced separators for sparse graphs, which can be exploited for branching to disconnect an instance into independent components. For this algorithm design paradigm, the challenge to date has been to obtain improvements in worst-case analyses of algorithms, compared with algorithms that are analyzed with advanced methods, notably Measure and Conquer. Our contribution is the design of a general method to integrate the advantage from the separator-branching into Measure and Conquer, for a more precise and improved running time analysis. We illustrate the method with improved algorithms for M ax ( r ,2)-C sp and #D ominating S et . An instance of the problem M ax ( r ,2)-C SP , or simply M ax 2-CSP, is parameterized by the domain size r (often 2), the number of variables n (vertices in the constraint graph G ), and the number of constraints m (edges in G ). When G is cubic, and omitting sub-exponential terms here for clarity, we give an algorithm running in time r (1/5) n = r (2/15) m the previous best was r (1/4) n = r (1/6) m . By known results, this improvement for the cubic case results in an algorithm running in time r (9/50) m for general instances; the previous best was r (19/100) m . We show that the analysis of the earlier algorithm was tight: our improvement is in the algorithm, not just the analysis. The same running time improvements hold for M ax C ut , an important special case of M ax 2-CSP, and for Polynomial and Ring CSP, generalizations encompassing graph bisection, the Ising model, and counting. We also give faster algorithms for #D ominating S et , counting the dominating sets of every cardinality 0, … , n for a graph G of order n . For cubic graphs, our algorithm runs in time 3 (1/5) n the previous best was 2 (1/2) n . For general graphs, we give an unrelated algorithm running in time 1.5183 n the previous best was 1.5673 n . The previous best algorithms for these problems all used local transformations and were analyzed by the Measure and Conquer method. Our new algorithms capitalize on the existence of small balanced separators for cubic graphs—a non-local property—and the ability to tailor the local algorithms always to “pivot” on a vertex in the separator. The new algorithms perform much as the old ones until the separator is empty, at which point they gain because the remaining vertices are split into two independent problem instances that can be solved recursively. It is likely that such algorithms can be effective for other problems too, and we present their design and analysis in a general framework.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2774159520",
    "type": "article"
  },
  {
    "title": "Analyzing Node-Weighted Oblivious Matching Problem via Continuous LP with Jump Discontinuity",
    "doi": "https://doi.org/10.1145/3168008",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "T-H. Hubert Chan; Fei Chen; Xiaowei Wu",
    "corresponding_authors": "",
    "abstract": "We prove the first non-trivial performance ratio strictly above 0.5 for the weighted Ranking algorithm on the oblivious matching problem where nodes in a general graph can have arbitrary weights. We have discovered a new structural property of the ranking algorithm: if a node has two unmatched neighbors, then it will still be matched even when its rank is demoted to the bottom. This property allows us to form LP constraints for both the weighted and the unweighted versions of the problem. Using a new class of continuous linear programming (LP), we prove that the ratio for the weighted case is at least 0.501512, and we improve the ratio for the unweighted case to 0.526823 (from the previous best 0.523166 in SODA 2014). Unlike previous continuous LP, in which the primal solution must be continuous everywhere, our new continuous LP framework allows the monotone component of the primal function to have jump discontinuities, and the other primal components to take non-conventional forms, such as the Dirac δ function.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2802497182",
    "type": "article"
  },
  {
    "title": "Distributed Online and Stochastic Queueing on a Multiple Access Channel",
    "doi": "https://doi.org/10.1145/3182396",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Marcin Bieńkowski; Tomasz Jurdziński; Miroslaw Korzeniowski; Dariusz R. Kowalski",
    "corresponding_authors": "",
    "abstract": "We consider the problems of online and stochastic packet queueing in a distributed system of n nodes with queues, where the communication between the nodes is done via a multiple access channel. In the online setting, in each round, an arbitrary number of packets can be injected to nodes’ queues. Two measures of performance are considered: the total number of packets in all queues, called the total load , and the maximum queue size, called the maximum load . We develop a deterministic distributed algorithm that is asymptotically optimal with respect to both complexity measures, in a competitive way. More precisely, the total load of our algorithm is bigger than the total load of any other algorithm, including centralized online solutions, by only an additive term of O ( n 2 ), whereas the maximum queue size of our algorithm is at most n times bigger than the maximum queue size of any other algorithm, with an extra additive O ( n ). The optimality for both measures is justified by proving the corresponding lower bounds, which also separates nearly exponentially distributed solutions from the centralized ones. Next, we show that our algorithm is also stochastically stable for any expected injection rate smaller or equal to 1. This is the first solution to the stochastic queueing problem on a multiple access channel that achieves such stability for the (highest possible) rate equal to 1.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2804372445",
    "type": "article"
  },
  {
    "title": "Solving the Sigma-Tau Problem",
    "doi": "https://doi.org/10.1145/3359589",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Joe Sawada; Aaron Williams",
    "corresponding_authors": "",
    "abstract": "Knuth assigned the following open problem a difficulty rating of 48/50 in The Art of Computer Programming Volume 4A : For odd n ≥ 3, can the permutations of { 1,2,… , n } be ordered in a cyclic list so that each permutation is transformed into the next by applying either the operation σ, a rotation to the left, or τ, a transposition of the first two symbols? The Sigma-Tau problem is equivalent to finding a Hamilton cycle in the directed Cayley graph generated by σ = (1 2 ⋅ n ) and τ = (1 2). In this article, we solve the Sigma-Tau problem by providing a simple O ( n )-time successor rule to generate successive permutations of a Hamilton cycle in the aforementioned Cayley graph.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2987306417",
    "type": "article"
  },
  {
    "title": "Optimal Streaming and Tracking Distinct Elements with High Probability",
    "doi": "https://doi.org/10.1145/3309193",
    "publication_date": "2019-12-05",
    "publication_year": 2019,
    "authors": "Jarosław Błasiok",
    "corresponding_authors": "Jarosław Błasiok",
    "abstract": "The distinct elements problem is one of the fundamental problems in streaming algorithms—given a stream of integers in the range { 1,… , n }, we wish to provide a (1+ε) approximation to the number of distinct elements in the input. After a long line of research an optimal solution for this problem with constant probability of success, using O (1/ε 2 +lg n ) bits of space, was given by Kane, Nelson, and Woodruff in 2010. The standard approach used to achieve low failure probability δ is to take the median of lg δ −1 parallel repetitions of the original algorithm. We show that such a multiplicative space blow-up is unnecessary: We provide an optimal algorithm using O (lg δ −1 /ε 2 + lg n ) bits of space—matching known lower bounds for this problem. That is, the lg δ −1 ; factor does not multiply the lg n term. This settles completely the space complexity of the distinct elements problem with respect to all standard parameters. We consider also the strong tracking (or continuous monitoring ) variant of the distinct elements problem, where we want an algorithm that provides an approximation of the number of distinct elements seen so far, at all times of the stream. We show that this variant can be solved using O (lg lg n + lg δ −1 /ε 2 + lg n ) bits of space, which we show to be optimal.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2993415324",
    "type": "article"
  },
  {
    "title": "Holant Clones and the Approximability of Conservative Holant Problems",
    "doi": "https://doi.org/10.1145/3381425",
    "publication_date": "2020-03-09",
    "publication_year": 2020,
    "authors": "Miriam Backens; Leslie Ann Goldberg",
    "corresponding_authors": "",
    "abstract": "We construct a theory of holant clones to capture the notion of expressibility in the holant framework. Their role is analogous to the role played by functional clones in the study of weighted counting Constraint Satisfaction Problems. We explore the landscape of conservative holant clones and determine the situations in which a set F of functions is “universal in the conservative case,” which means that all functions are contained in the holant clone generated by F together with all unary functions. When F is not universal in the conservative case, we give concise generating sets for the clone. We demonstrate the usefulness of the holant clone theory by using it to give a complete complexity-theory classification for the problem of approximating the solution to conservative holant problems. We show that approximation is intractable exactly when F is universal in the conservative case.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3010665772",
    "type": "article"
  },
  {
    "title": "Symmetry Exploitation for Online Machine Covering with Bounded Migration",
    "doi": "https://doi.org/10.1145/3397535",
    "publication_date": "2020-07-06",
    "publication_year": 2020,
    "authors": "Waldo Gálvez; José A. Soto; José Verschae",
    "corresponding_authors": "",
    "abstract": "Online models that allow recourse can be highly effective in situations where classical online models are too pessimistic. One such problem is the online machine covering problem on identical machines. In this setting, jobs arrive one by one and must be assigned to machines with the objective of maximizing the minimum machine load. When a job arrives, we are allowed to reassign some jobs as long as their total size is (at most) proportional to the processing time of the arriving job. The proportionality constant is called the migration factor of the algorithm. Using a rounding procedure with useful structural properties for online packing and covering problems, we design first a simple (1.7 + ε)-competitive algorithm using a migration factor of O(1/ε), which maintains at every arrival a locally optimal solution with respect to the Jump neighborhood. After that, we present as our main contribution a more involved (4/3+ε)-competitive algorithm using a migration factor of Ō (1/ε 3 ). At every arrival, we run an adaptation of the Largest Processing Time first (LPT) algorithm. Since the new job can cause a complete change of the assignment of smaller jobs in both cases, a low migration factor is achieved by carefully exploiting the highly symmetric structure obtained by the rounding procedure.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3040022793",
    "type": "article"
  },
  {
    "title": "Polylogarithmic Approximation Algorithms for Weighted-ℱ-deletion Problems",
    "doi": "https://doi.org/10.1145/3389338",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "Akanksha Agrawal; Daniel Lokshtanov; Pranabendu Misra; Saket Saurabh; Meirav Zehavi",
    "corresponding_authors": "",
    "abstract": "For a family of graphs ℱ, the W&lt;scp;&gt;eighted&lt;/scp;&gt; ℱ V&lt;scp;&gt;ertex&lt;/scp;&gt; D&lt;scp;&gt;eletion&lt;/scp;&gt; problem, is defined as follows: given an n -vertex undirected graph G and a weight function w : V ( G )࢐ ℝ, find a minimum weight subset S ⊆ V ( G ) such that G - S belongs to ℱ. We devise a recursive scheme to obtain O(log O(1) n )-approximation algorithms for such problems, building upon the classical technique of finding balanced separators . We obtain the first O(log O(1) n )-approximation algorithms for the following problems. • Let F be a finite set of graphs containing a planar graph, and ℱ= G ( F ) be the maximal family of graphs such that every graph H ∈ G ( F ) excludes all graphs in F as minors. The vertex deletion problem corresponding to ℱ= G ( F ) is the W eighted P lanar F -M inor -F ree D eletion (WP F -MFD) problem. We give a randomized and a deterministic approximation algorithms for WP F -MFD with ratios O(log 1.5 n ) and O(log 2 n ), respectively. Prior to our work, a randomized constant factor approximation algorithm for the unweighted version was known [FOCS 2012]. After our work, a deterministic constant factor approximation algorithm for the unweighted version was also obtained [SODA 2019]. • We give an O(log 2 n )-factor approximation algorithm for W eighted C hordal V ertex D eletion , the vertex deletion problem to the family of chordal graphs. On the way to this algorithm, we also obtain a constant factor approximation algorithm for M ulticut on chordal graphs. • We give an O(log 3 n )-factor approximation algorithm for W eighted D istance H ereditary V ertex D eletion . We believe that our recursive scheme can be applied to obtain O(log O(1) n )-approximation algorithms for many other problems as well.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3042150117",
    "type": "article"
  },
  {
    "title": "Querying a Matrix through Matrix-Vector Products",
    "doi": "https://doi.org/10.1145/3470566",
    "publication_date": "2021-10-04",
    "publication_year": 2021,
    "authors": "Xiaoming Sun; David P. Woodruff; Guang Yang; Jialin Zhang",
    "corresponding_authors": "",
    "abstract": "We consider algorithms with access to an unknown matrix M ε F n×d via matrix-vector products , namely, the algorithm chooses vectors v 1 , ⃛ , v q , and observes Mv 1 , ⃛ , Mv q . Here the v i can be randomized as well as chosen adaptively as a function of Mv 1 , ⃛ , Mv i-1 . Motivated by applications of sketching in distributed computation, linear algebra, and streaming models, as well as connections to areas such as communication complexity and property testing, we initiate the study of the number q of queries needed to solve various fundamental problems. We study problems in three broad categories, including linear algebra, statistics problems, and graph problems. For example, we consider the number of queries required to approximate the rank, trace, maximum eigenvalue, and norms of a matrix M; to compute the AND/OR/Parity of each column or row of M, to decide whether there are identical columns or rows in M or whether M is symmetric, diagonal, or unitary; or to compute whether a graph defined by M is connected or triangle-free. We also show separations for algorithms that are allowed to obtain matrix-vector products only by querying vectors on the right, versus algorithms that can query vectors on both the left and the right. We also show separations depending on the underlying field the matrix-vector product occurs in. For graph problems, we show separations depending on the form of the matrix (bipartite adjacency versus signed edge-vertex incidence matrix) to represent the graph. Surprisingly, very few works discuss this fundamental model, and we believe a thorough investigation of problems in this model would be beneficial to a number of different application areas.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W3204296272",
    "type": "article"
  },
  {
    "title": "Principles of Robust Medium Access and an Application to Leader Election",
    "doi": "https://doi.org/10.1145/2635818",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Baruch Awerbuch; Andréa W. Richa; Christian Scheideler; Stefan Schmid; Jin Zhang",
    "corresponding_authors": "",
    "abstract": "This article studies the design of medium access control (MAC) protocols for wireless networks that are provably robust against arbitrary and unpredictable disruptions (e.g., due to unintentional external interference from co-existing networks or due to jamming). We consider a wireless network consisting of a set of n honest and reliable nodes within transmission (and interference) range of each other, and we model the external disruptions with a powerful adaptive adversary. This adversary may know the protocol and its entire history and can use this knowledge to jam the wireless channel at will at any time. It is allowed to jam a (1-ϵ)-fraction of the timesteps, for an arbitrary constant ϵ &gt; 0 unknown to the nodes. The nodes cannot distinguish between the adversarial jamming or a collision of two or more messages that are sent at the same time. We demonstrate, for the first time, that there is a local-control MAC protocol requiring only very limited knowledge about the adversary and the network that achieves a constant (asymptotically optimal) throughput for the nonjammed time periods under any of the aforementioned adversarial strategies. The derived principles are also useful to build robust applications on top of the MAC layer, and we present an exemplary study for leader election, one of the most fundamental tasks in distributed computing.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2063044716",
    "type": "article"
  },
  {
    "title": "Improved Approximation Algorithms for Relay Placement",
    "doi": "https://doi.org/10.1145/2814938",
    "publication_date": "2015-12-31",
    "publication_year": 2015,
    "authors": "Alon Efrat; Sándor P. Fekete; Joseph S. B. Mitchell; Valentin Polishchuk; Jukka Suomela",
    "corresponding_authors": "",
    "abstract": "In the relay placement problem, the input is a set of sensors and a number r ⩾ 1, the communication range of a relay. In the one-tier version of the problem, the objective is to place a minimum number of relays so that between every pair of sensors there is a path through sensors and/or relays such that the consecutive vertices of the path are within distance r if both vertices are relays and within distance 1 otherwise. The two-tier version adds the restrictions that the path must go through relays, and not through sensors . We present a 3.11-approximation algorithm for the one-tier version and a polynomial-time approximation scheme (PTAS) for the two-tier version. We also show that the one-tier version admits no PTAS, assuming P ≠ NP.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2167108103",
    "type": "article"
  },
  {
    "title": "Deletion Without Rebalancing in Binary Search Trees",
    "doi": "https://doi.org/10.1145/2903142",
    "publication_date": "2016-09-02",
    "publication_year": 2016,
    "authors": "Siddhartha Sen; Robert E. Tarjan; David Hong Kyun Kim",
    "corresponding_authors": "",
    "abstract": "We address the vexing issue of deletions in balanced trees. Rebalancing after a deletion is generally more complicated than rebalancing after an insertion. Textbooks neglect deletion rebalancing, and many B-tree--based database systems do not do it. We describe a relaxation of AVL trees in which rebalancing is done after insertions but not after deletions, yet worst-case access time remains logarithmic in the number of insertions. For any application of balanced trees in which the number of updates is polynomial in the tree size, our structure offers performance competitive with that of classical balanced trees. With the addition of periodic rebuilding, the performance of our structure is theoretically superior to that of many, if not all, classic balanced tree structures. Our structure needs lg lg m + 1 bits of balance information per node, where m is the number of insertions and lg is the base-two logarithm, or lg lg n + O(1) with periodic rebuilding, where n is the number of nodes. An insertion takes up to two rotations and O(1) amortized time, not counting the time to find the insertion position. This is the same as in standard AVL trees. Using an analysis that relies on an exponential potential function, we show that rebalancing steps occur with a frequency that is exponentially small in the height of the affected node. Our techniques apply to other types of balanced trees, notably B-trees, as we show in a companion article, and particularly red-black trees, which can be viewed as a special case of B-trees.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2510324744",
    "type": "article"
  },
  {
    "title": "Data Structures for Path Queries",
    "doi": "https://doi.org/10.1145/2905368",
    "publication_date": "2016-08-16",
    "publication_year": 2016,
    "authors": "Meng He; J. Ian Munro; Gelin Zhou",
    "corresponding_authors": "",
    "abstract": "Consider a tree T on n nodes, each having a weight drawn from [1‥σ]. In this article, we study the problem of supporting various path queries over the tree T . The path counting query asks for the number of the nodes on a query path whose weights are in a query range, while the path reporting query requires to report these nodes. The path median query asks for the median weight on a path between two given nodes, and the path selection query returns the k -th smallest weight. We design succinct data structures to encode T using n nH ( W T ) + 2 n + o ( n lg σ) bits of space, such that we can support path counting queries in O (lg σ/lg lg n + 1)) time, path reporting queries in O (( occ +1)(lg σ / lg lg n + 1)) time, and path median and path selection queries in O (lg σ / lg lg σ) time, where H ( W T ) is the entropy of the multiset of the weights of the nodes in T and occ is the size of the output. Our results not only greatly improve the best known data structures [Chazelle 1987; Krizanc et al. 2005], but also match the lower bounds for path counting, median, and selection queries [Pătraşcu 2007, 2011; Jørgensen and Larsen 2011] when σ = Ω( n /polylog( n )).",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2513395528",
    "type": "article"
  },
  {
    "title": "Hypergraph Isomorphism for Groups with Restricted Composition Factors",
    "doi": "https://doi.org/10.1145/3527667",
    "publication_date": "2022-04-21",
    "publication_year": 2022,
    "authors": "Daniel Neuen",
    "corresponding_authors": "Daniel Neuen",
    "abstract": "We consider the isomorphism problem for hypergraphs taking as input two hypergraphs over the same set of vertices $V$ and a permutation group $\\Gamma$ over domain $V$, and asking whether there is a permutation $\\gamma \\in \\Gamma$ that proves the two hypergraphs to be isomorphic. We show that for input groups, all of whose composition factors are isomorphic to a subgroup of the symmetric group on $d$ points, this problem can be solved in time $(n+m)^{O((\\log d)^{c})}$ for some absolute constant $c$ where $n$ denotes the number of vertices and $m$ the number of hyperedges. In particular, this gives the currently fastest isomorphism test for hypergraphs in general. The previous best algorithm for this problem due to Schweitzer and Wiebking (STOC 2019) runs in time $n^{O(d)}m^{O(1)}$. As an application of this result, we obtain, for example, an algorithm testing isomorphism of graphs excluding $K_{3,h}$ ($h \\geq 3$) as a minor in time $n^{O((\\log h)^{c})}$. In particular, this gives an isomorphism test for graphs of Euler genus at most $g$ running in time $n^{O((\\log g)^{c})}$.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3005681358",
    "type": "article"
  },
  {
    "title": "Approximation Schemes for Capacitated Vehicle Routing on Graphs of Bounded Treewidth, Bounded Doubling, or Highway Dimension",
    "doi": "https://doi.org/10.1145/3582500",
    "publication_date": "2023-02-01",
    "publication_year": 2023,
    "authors": "Aditya Jayaprakash; Mohammad R. Salavatipour",
    "corresponding_authors": "",
    "abstract": "In this article, we present Approximation Schemes for Capacitated Vehicle Routing Problem (CVRP) on several classes of graphs. In CVRP, introduced by Dantzig and Ramser in 1959 [ 14 ], we are given a graph G=(V,E) with metric edges costs, a depot r ∈ V , and a vehicle of bounded capacity Q . The goal is to find a minimum cost collection of tours for the vehicle that returns to the depot, each visiting at most Q nodes, such that they cover all the nodes. This generalizes classic TSP and has been studied extensively. In the more general setting, each node v has a demand d v and the total demand of each tour must be no more than Q . Either the demand of each node must be served by one tour (unsplittable) or can be served by multiple tours (splittable). The best-known approximation algorithm for general graphs has ratio α +2(1-ε) (for the unsplittable) and α +1-ε (for the splittable) for some fixed \\(&amp;#x03B5; \\gt \\frac{1}{3000}\\) , where α is the best approximation for TSP. Even for the case of trees, the best approximation ratio is 4/3 [ 5 ] and it has been an open question if there is an approximation scheme for this simple class of graphs. Das and Mathieu [ 15 ] presented an approximation scheme with time n log O(1/ε) n for Euclidean plane ℝ 2 . No other approximation scheme is known for any other class of metrics (without further restrictions on Q ). In this article, we make significant progress on this classic problem by presenting Quasi-Polynomial Time Approximation Schemes (QPTAS) for graphs of bounded treewidth, graphs of bounded highway dimensions, and graphs of bounded doubling dimensions. For comparison, our result implies an approximation scheme for the Euclidean plane with run time n O(log 6 n/ε 5 ) .",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4318820632",
    "type": "article"
  },
  {
    "title": "Fast and Perfect Sampling of Subgraphs and Polymer Systems",
    "doi": "https://doi.org/10.1145/3632294",
    "publication_date": "2023-11-10",
    "publication_year": 2023,
    "authors": "Antonio Blanca; Sarah Cannon; Will Perkins",
    "corresponding_authors": "",
    "abstract": "We give an efficient perfect sampling algorithm for weighted, connected induced subgraphs (or graphlets ) of rooted, bounded degree graphs. Our algorithm utilizes a vertex-percolation process with a carefully chosen rejection filter and works under a percolation subcriticality condition. We show that this condition is optimal in the sense that the task of (approximately) sampling weighted rooted graphlets becomes impossible in finite expected time for infinite graphs and intractable for finite graphs when the condition does not hold. We apply our sampling algorithm as a subroutine to give near linear-time perfect sampling algorithms for polymer models and weighted non-rooted graphlets in finite graphs, two widely studied yet very different problems. This new perfect sampling algorithm for polymer models gives improved sampling algorithms for spin systems at low temperatures on expander graphs and unbalanced bipartite graphs, among other applications.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4388574679",
    "type": "article"
  },
  {
    "title": "A data structure for a sequence of string accesses in external memory",
    "doi": "https://doi.org/10.1145/1186810.1186816",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Valentina Ciriani; Paolo Ferragina; Fabrizio Luccio; S. Muthukrishnan",
    "corresponding_authors": "",
    "abstract": "We introduce a new paradigm for querying strings in external memory, suited to the execution of sequences of operations. Formally, given a dictionary of n strings S 1 , …, S n , we aim at supporting a search sequence for m not necessarily distinct strings T 1 , T 2 , …, T m , as well as inserting and deleting individual strings. The dictionary is stored on disk, where each access to a disk page fetches B items, the cost of an operation is the number of pages accessed (I/Os), and efficiency must be attained on entire sequences of string operations rather than on individual ones. Our approach relies on a novel and conceptually simple self-adjusting data structure (SASL) based on skip lists, that is also interesting per se . The search for the whole sequence T 1 , T 2 , …, T m can be done in an expected number of I/Os: O (∑ j =1 m | T j |/ B + ∑ i =1 n n ( n i log B m / n i )), where each T j may or may not be present in the dictionary, and n i is the number of times S i is queried (i.e., the number of T j s equal to S i ). Moreover, inserting or deleting a string S i takes an expected amortized number O (| S i |/ B + log B n ) of I/Os. The term ∑ j =1 m | T j |/ B in the search formula is a lower bound for reading the input, and the term ∑ i =1 n n i log B m / n i (entropy of the query sequence) is a standard information-theoretic lower bound. We regard this result as the static optimality theorem for external-memory string access , as compared to Sleator and Tarjan's classical theorem for numerical dictionaries [Sleator and Tarjan 1985]. Finally, we reformulate the search bound if a cache is available, taking advantage of common prefixes among the strings examined in the search.",
    "cited_by_count": 11,
    "openalex_id": "https://openalex.org/W1976193123",
    "type": "article"
  },
  {
    "title": "Dynamic routing schemes for graphs with low local density",
    "doi": "https://doi.org/10.1145/1383369.1383372",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Amos Korman; David Peleg",
    "corresponding_authors": "",
    "abstract": "This article studies approximate distributed routing schemes on dynamic communication networks. The work focuses on dynamic weighted general graphs where the vertices of the graph are fixed, but the weights of the edges may change. Our main contribution concerns bounding the cost of adapting to dynamic changes. The update efficiency of a routing scheme is measured by the time needed in order to update the routing scheme following a weight change. A naive dynamic routing scheme, which updates all vertices following a weight change, requires Ω( Diam ) time in order to perform the updates after every weight change, where Diam is the diameter of the underlying graph. In contrast, this article presents approximate dynamic routing schemes with average time complexity Θ˜( D ) per topological change, where D is the local density parameter of the underlying graph. Following a weight change, our scheme never incurs more than Diam time; thus, our scheme is particularly efficient on graphs which have low local density and large diameter. The article also establishes upper and lower bounds on the size of the databases required by the scheme at each site.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2010216648",
    "type": "article"
  },
  {
    "title": "Online nonpreemptive scheduling of equal-length jobs on two identical machines",
    "doi": "https://doi.org/10.1145/1435375.1435377",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Michael H. Goldwasser; Mark Pedigo",
    "corresponding_authors": "",
    "abstract": "We consider the nonpreemptive scheduling of two identical machines for jobs with equal processing times yet arbitrary release dates and deadlines. Our objective is to maximize the number of jobs completed by their deadlines. Using standard nomenclature, this problem is denoted as P 2 | p j = p , r j | Σ Ū j . The problem is known to be polynomially solvable in an offline setting. In an online variant of the problem, a job's existence and parameters are revealed to the scheduler only upon that job's release date. We present an online deterministic algorithm for the problem and prove that it is 3/2-competitive. A simple lower bound shows that this is the optimal deterministic competitiveness.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2041516682",
    "type": "article"
  },
  {
    "title": "A polynomial-time approximation scheme for embedding hypergraph in a cycle",
    "doi": "https://doi.org/10.1145/1497290.1497296",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Guojun Li; Xiaotie Deng; Ying Xu",
    "corresponding_authors": "",
    "abstract": "We consider the problem of embedding hyperedges of a hypergraph as paths in a cycle such that the maximum congestion, namely the maximum number of paths that use any single edge in a cycle, is minimized. The minimum congestion hypergraph embedding in a cycle problem is known to be NP-hard and its graph version, the minimum congestion graph embedding in a cycle , is solvable in polynomial-time. Furthermore, for the graph problem, a polynomial-time approximation scheme for the weighted version is known. For the hypergraph model, several approximation algorithms with a ratio of two have been previously published. A recent paper reduced the approximation ratio to 1.5. We present a polynomial-time approximation scheme in this article, settling the debate regarding whether the problem is polynomial-time approximable.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2058787824",
    "type": "article"
  },
  {
    "title": "Making deterministic signatures quickly",
    "doi": "https://doi.org/10.1145/1541885.1541887",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Milan Ružić",
    "corresponding_authors": "Milan Ružić",
    "abstract": "We present a new technique of universe reduction. Primary applications are the dictionary problem and the predecessor problem. We give several new results on static dictionaries in different computational models: the word RAM, the practical RAM, and the cache-oblivious model. All algorithms and data structures are deterministic and use linear space. Representative results are: a dictionary with a lookup time of O (log log n ) and construction time of O ( n ) on sorted input on a word RAM, and a static predecessor structure for variable- and unbounded length binary strings that in the cache-oblivious model has a query performance of O (| s |/ B + log | s |) I/Os, for query argument s .",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2149213038",
    "type": "article"
  },
  {
    "title": "Approximation Algorithms for the Bottleneck Asymmetric Traveling Salesman Problem",
    "doi": "https://doi.org/10.1145/3478537",
    "publication_date": "2021-10-04",
    "publication_year": 2021,
    "authors": "Hyung-Chan An; Robert Kleinberg; David B. Shmoys",
    "corresponding_authors": "",
    "abstract": "We present the first nontrivial approximation algorithm for the bottleneck asymmetric traveling salesman problem . Given an asymmetric metric cost between n vertices, the problem is to find a Hamiltonian cycle that minimizes its bottleneck (or maximum-length edge) cost. We achieve an O (log n / log log n ) approximation performance guarantee by giving a novel algorithmic technique to shortcut Eulerian circuits while bounding the lengths of the shortcuts needed. This allows us to build on a related result of Asadpour, Goemans, Mądry, Oveis Gharan, and Saberi to obtain this guarantee. Furthermore, we show how our technique yields stronger approximation bounds in some cases, such as the bounded orientable genus case studied by Oveis Gharan and Saberi. We also explore the possibility of further improvement upon our main result through a comparison to the symmetric counterpart of the problem.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1563055883",
    "type": "article"
  },
  {
    "title": "Succinct geometric indexes supporting point location queries",
    "doi": "https://doi.org/10.1145/2151171.2151173",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Prosenjit Bose; Eric Chen; Meng He; Anil Maheshwari; Pat Morin",
    "corresponding_authors": "",
    "abstract": "We propose designing data structures called succinct geometric indexes of negligible space (more precisely, o ( n ) bits) that support geometric queries in optimal time, by taking advantage of the n points in the dataset permuted and stored elsewhere as a sequence. Our first and main result is a succinct geometric index that can answer point location queries, a fundamental problem in computational geometry, on planar triangulations in O (lg n ) time. We also design three variants of this index. The first supports point location using lg n + 2√lg n + O (lg 1/4 n ) point-line comparisons. The second supports point location in o (lg n ) time when the coordinates are integers bounded by U . The last variant can answer point location queries in O ( H + 1) expected time, where H is the entropy of the query distribution. These results match the query efficiency of previous point location structures that occupy O ( n ) words or O(n lg n ) bits, while saving drastic amounts of space. We generalize our succinct geometric index to planar subdivisions, and design indexes for other types of queries. Finally, we apply our techniques to design the first implicit data structures that support point location in O (lg 2 n ) time.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2114804538",
    "type": "article"
  },
  {
    "title": "Batched Point Location in SINR Diagrams via Algebraic Tools",
    "doi": "https://doi.org/10.1145/3209678",
    "publication_date": "2018-08-09",
    "publication_year": 2018,
    "authors": "Boris Aronov; Matthew J. Katz",
    "corresponding_authors": "",
    "abstract": "The SINR (Signal to Interference plus Noise Ratio) model for the quality of wireless connections has been the subject of extensive recent study. It attempts to predict whether a particular transmitter is heard at a specific location, in a setting consisting of n simultaneous transmitters and background noise. The SINR model gives rise to a natural geometric object, the SINR diagram , which partitions the space into n regions where each of the transmitters can be heard and the remaining space where no transmitter can be heard. Efficient point location in the SINR diagram, i.e., being able to build a data structure that facilitates determining, for a query point, whether any transmitter is heard there, and if so, which one, has been recently investigated in several articles. These planar data structures are constructed in time at least quadratic in n and support logarithmic-time approximate queries. Moreover, the performance of some of the proposed structures depends strongly not only on the number n of transmitters and on the approximation parameter ε , but also on some geometric parameters that cannot be bounded a priori as a function of n or ε . In this article, we address the question of batched point location queries, i.e., answering many queries simultaneously. Specifically, in one dimension, we can answer n queries exactly in amortized polylogarithmic time per query, while in the plane we can do it approximately. In another result, we show how to answer n 2 queries exactly in amortized polylogarithmic time per query, assuming the queries are located on a possibly non-uniform n × n grid. All these results can handle arbitrary power assignments to the transmitters. Moreover, the amortized query time in these results depends only on n and ε . We also show how to speed up the preprocessing in a previously proposed point-location structure in SINR diagram for uniform-power sites, by almost a full order of magnitude. For this, we obtain results on the sensitivity of the reception regions to slight changes in the reception threshold, which are of independent interest. Finally, these results demonstrate the (so far underutilized) power of combining algebraic tools with those of computational geometry and other fields.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2962913133",
    "type": "article"
  },
  {
    "title": "Randomized Embeddings with Slack and High-Dimensional Approximate Nearest Neighbor",
    "doi": "https://doi.org/10.1145/3178540",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Evangelos Anagnostopoulos; Ioannis Z. Emiris; Ioannis Psarros",
    "corresponding_authors": "",
    "abstract": "Approximate nearest neighbor search (ϵ-ANN) in high dimensions has been mainly addressed by Locality Sensitive Hashing (LSH), which has complexity with polynomial dependence in dimension, sublinear query time, but subquadratic space requirement. We introduce a new “low-quality” embedding for metric spaces requiring that, for some query, there exists an approximate nearest neighbor among the pre-images of its k &gt; 1 approximate nearest neighbors in the target space. In Euclidean spaces, we employ random projections to a dimension inversely proportional to k . Our approach extends to the decision problem with witness of checking whether there exists an approximate near neighbor; this also implies a solution for ϵ-ANN. After dimension reduction, we store points in a uniform grid of side length ϵ /√ d ′ , where d ′ is the reduced dimension. Given a query, we explore cells intersecting the unit ball around the query. This data structure requires linear space and query time in O ( d n ρ ), ρ ≈ 1-ϵ 2 i&gt;/log(1ϵ), where n denotes input cardinality and d space dimension. Bounds are improved for doubling subsets via r -nets. We present our implementation for ϵ-ANN in C++ and experiments for d ≤ 960, n ≤ 10 6 , using synthetic and real datasets, which confirm the theoretical analysis and, typically, yield better practical performance. We compare to FALCONN, the state-of-the-art implementation of multi-probe LSH: our prototype software is essentially comparable in terms of preprocessing, query time, and storage usage.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2963710502",
    "type": "article"
  },
  {
    "title": "Subexponential Parameterized Algorithm for I <scp>nterval</scp> C <scp>ompletion</scp>",
    "doi": "https://doi.org/10.1145/3186896",
    "publication_date": "2018-06-27",
    "publication_year": 2018,
    "authors": "Ivan Bliznets; Fedor V. Fomin; Marcin Pilipczuk; Michał Pilipczuk",
    "corresponding_authors": "",
    "abstract": "In the I nterval C ompletion problem we are given an n -vertex graph G and an integer k , and the task is to transform G by making use of at most k edge additions into an interval graph. This is a fundamental graph modification problem with applications in sparse matrix multiplication and molecular biology. The question about fixed-parameter tractability of I nterval C ompletion was asked by Kaplan et al. [FOCS 1994; SIAM J. Comput. 1999] and was answered affirmatively more than a decade later by Villanger et al. [STOC 2007; SIAM J. Comput. 2009], who presented an algorithm with running time O ( k 2 k n 3 m ). We give the first subexponential parameterized algorithm solving I nterval C ompletion in time k O (√ k ) n O (1) . This adds I nterval C ompletion to a very small list of parameterized graph modification problems solvable in subexponential time.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3000706835",
    "type": "article"
  },
  {
    "title": "Covering Small Independent Sets and Separators with Applications to Parameterized Algorithms",
    "doi": "https://doi.org/10.1145/3379698",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Daniel Lokshtanov; Fahad Panolan; Saket Saurabh; Roohani Sharma; Meirav Zehavi",
    "corresponding_authors": "",
    "abstract": "We present two new combinatorial tools for the design of parameterized algorithms. The first is a simple linear time randomized algorithm that given as input a d -degenerate graph G and an integer k , outputs an independent set Y , such that for every independent set X in G of size at most k , the probability that X is a subset of Y is at least (( (d+1)k k ) . k (d+1)) -1 . The second is a new (deterministic) polynomial time graph sparsification procedure that given a graph G , a set T = {s_1, t_1} , {s_2, t_2}, …. , {s_ℓ , t_ℓ} of terminal pairs, and an integer k , returns an induced subgraph G* of G that maintains all the inclusion minimal multicuts of G of size at most k and does not contain any ( k +2)-vertex connected set of size 2 O(k) . In particular, G* excludes a clique of size 2 O(k) as a topological minor. Put together, our new tools yield new randomized fixed parameter tractable (FPT) algorithms for S TABLE s-t S EPARATOR , S TABLE O DD C YCLE T RANSVERSAL , and S TABLE M ULTICUT on general graphs, and for S TABLE D IRECTED F EEDBACK V ERTEX S ET on d -degenerate graphs, resolving two problems left open by Marx et al. [ ACM Transactions on Algorithms, 2013{. All of our algorithms can be derandomized at the cost of a small overhead in the running time.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3033379983",
    "type": "article"
  },
  {
    "title": "Dynamic Parameterized Problems and Algorithms",
    "doi": "https://doi.org/10.1145/3395037",
    "publication_date": "2020-07-06",
    "publication_year": 2020,
    "authors": "Josh Alman; Matthias Mnich; Virginia Vassilevska Williams",
    "corresponding_authors": "",
    "abstract": "Fixed-parameter algorithms and kernelization are two powerful methods to solve NP-hard problems. Yet so far those algorithms have been largely restricted to static inputs. In this article, we provide fixed-parameter algorithms and kernelizations for fundamental NP-hard problems with dynamic inputs. We consider a variety of parameterized graph and hitting set problems that are known to have f ( k ) n 1+o(1) time algorithms on inputs of size n , and we consider the question of whether there is a data structure that supports small updates (such as edge/vertex/set/element insertions and deletions) with an update time of g ( k ) n o(1) ; such an update time would be essentially optimal. Update and query times independent of n are particularly desirable. Among many other results, we show that F EEDBACK V ERTEX S ET and k -P ATH admit dynamic algorithms with f ( k )log O(1) update and query times for some function f depending on the solution size k only. We complement our positive results by several conditional and unconditional lower bounds. For example, we show that unlike their undirected counterparts, D IRECTED F EEDBACK V ERTEX S ET and D IRECTED k -P ATH do not admit dynamic algorithms with n o(1) update and query times even for constant solution sizes k ≤ 3 , assuming popular hardness hypotheses. We also show that unconditionally, in the cell probe model, D IRECTED F EEDBACK V ERTEX S ET cannot be solved with update time that is purely a function of k .",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3085566810",
    "type": "article"
  },
  {
    "title": "A Simple Algorithm for Optimal Search Trees with Two-way Comparisons",
    "doi": "https://doi.org/10.1145/3477910",
    "publication_date": "2021-12-02",
    "publication_year": 2021,
    "authors": "Marek Chrobák; Mordecai J. Golin; J. Ian Munro; Neal E. Young",
    "corresponding_authors": "",
    "abstract": "We present a simple O(n 4 ) -time algorithm for computing optimal search trees with two-way comparisons. The only previous solution to this problem, by Anderson et al., has the same running time but is significantly more complicated and is restricted to the variant where only successful queries are allowed. Our algorithm extends directly to solve the standard full variant of the problem, which also allows unsuccessful queries and for which no polynomial-time algorithm was previously known. The correctness proof of our algorithm relies on a new structural theorem for two-way-comparison search trees.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3134377377",
    "type": "article"
  },
  {
    "title": "Property Testing on Product Distributions",
    "doi": "https://doi.org/10.1145/3039241",
    "publication_date": "2017-03-10",
    "publication_year": 2017,
    "authors": "Deeparnab Chakrabarty; Kashyap Dixit; Madhav Jha; C. Seshadhri",
    "corresponding_authors": "",
    "abstract": "The primary problem in property testing is to decide whether a given function satisfies a certain property or is far from any function satisfying it. This crucially requires a notion of distance between functions. The most prevalent notion is the Hamming distance over the uniform distribution on the domain. This restriction to uniformity is rather limiting, and it is important to investigate distances induced by more general distributions. In this article, we provide simple and optimal testers for bounded derivative properties over arbitrary product distributions . Bounded derivative properties include fundamental properties, such as monotonicity and Lipschitz continuity. Our results subsume almost all known results (upper and lower bounds) on monotonicity and Lipschitz testing over arbitrary ranges. We prove an intimate connection between bounded derivative property testing and binary search trees (BSTs). We exhibit a tester whose query complexity is the sum of expected depths of optimal BSTs for each marginal. Furthermore, we show that this sum-of-depths is also a lower bound. A technical contribution of our work is an optimal dimension reduction theorem for all bounded derivative properties that relates the distance of a function from the property to the distance of restrictions of the function to random lines. Such a theorem has been elusive even for monotonicity, and our theorem is an exponential improvement to the previous best-known result.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3163847447",
    "type": "article"
  },
  {
    "title": "A Deamortization Approach for Dynamic Spanner and Dynamic Maximal Matching",
    "doi": "https://doi.org/10.1145/3469833",
    "publication_date": "2021-10-04",
    "publication_year": 2021,
    "authors": "Aaron Bernstein; Sebastian Forster; Monika Henzinger",
    "corresponding_authors": "",
    "abstract": "Many dynamic graph algorithms have an amortized update time, rather than a stronger worst-case guarantee. But amortized data structures are not suitable for real-time systems, where each individual operation has to be executed quickly. For this reason, there exist many recent randomized results that aim to provide a guarantee stronger than amortized expected. The strongest possible guarantee for a randomized algorithm is that it is always correct (Las Vegas) and has high-probability worst-case update time, which gives a bound on the time for each individual operation that holds with high probability. In this article, we present the first polylogarithmic high-probability worst-case time bounds for the dynamic spanner and the dynamic maximal matching problem. (1) For dynamic spanner, the only known o ( n ) worst-case bounds were O ( n 3/4 ) high-probability worst-case update time for maintaining a 3-spanner and O ( n 5/9 ) for maintaining a 5-spanner. We give a O (1) k log 3 ( n ) high-probability worst-case time bound for maintaining a ( 2k-1 )-spanner, which yields the first worst-case polylog update time for all constant k . (All the results above maintain the optimal tradeoff of stretch 2k-1 and Õ( n 1+1/k ) edges.) (2) For dynamic maximal matching, or dynamic 2-approximate maximum matching, no algorithm with o(n) worst-case time bound was known and we present an algorithm with O (log 5 ( n )) high-probability worst-case time; similar worst-case bounds existed only for maintaining a matching that was (2+ϵ)-approximate, and hence not maximal. Our results are achieved using a new approach for converting amortized guarantees to worst-case ones for randomized data structures by going through a third type of guarantee, which is a middle ground between the two above: An algorithm is said to have worst-case expected update time ɑ if for every update σ, the expected time to process σ is at most ɑ. Although stronger than amortized expected, the worst-case expected guarantee does not resolve the fundamental problem of amortization: A worst-case expected update time of O(1) still allows for the possibility that every 1/ f(n) updates requires ϴ ( f(n) ) time to process, for arbitrarily high f(n) . In this article, we present a black-box reduction that converts any data structure with worst-case expected update time into one with a high-probability worst-case update time: The query time remains the same, while the update time increases by a factor of O (log 2(n) ). Thus, we achieve our results in two steps: (1) First, we show how to convert existing dynamic graph algorithms with amortized expected polylogarithmic running times into algorithms with worst-case expected polylogarithmic running times. (2) Then, we use our black-box reduction to achieve the polylogarithmic high-probability worst-case time bound. All our algorithms are Las-Vegas-type algorithms.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W3202772786",
    "type": "article"
  },
  {
    "title": "Better Scalable Algorithms for Broadcast Scheduling",
    "doi": "https://doi.org/10.1145/2636916",
    "publication_date": "2014-08-25",
    "publication_year": 2014,
    "authors": "Nikhil Bansal; Ravishankar Krishnaswamy; Viswanath Nagarajan",
    "corresponding_authors": "",
    "abstract": "In the classical broadcast scheduling problem , there are n pages stored at a server, and requests for these pages arrive over time. Whenever a page is broadcast, it satisfies all outstanding requests for that page. The objective is to minimize average flow time of the requests. For any ϵ &gt; 0, we give a (1+ϵ)-speed O (1/ϵ 3 )-competitive online algorithm for broadcast scheduling. This improves over the recent breakthrough result of Im and Moseley [2010], where they obtained a (1+ϵ)-speed O (1/ϵ 11 )-competitive algorithm. Our algorithm and analysis are considerably simpler than Im and Moseley [2010]. More importantly, our techniques also extend to the general setting of nonuniform page sizes and dependent requests . This is the first scalable algorithm for broadcast scheduling with varying size pages and resolves the main open question from Im and Moseley [2010].",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2108248067",
    "type": "article"
  },
  {
    "title": "Adaptive and Approximate Orthogonal Range Counting",
    "doi": "https://doi.org/10.1145/2830567",
    "publication_date": "2016-09-02",
    "publication_year": 2016,
    "authors": "Timothy M. Chan; Bryan T. Wilkinson",
    "corresponding_authors": "",
    "abstract": "We present three new results on one of the most basic problems in geometric data structures, 2-D orthogonal range counting. All the results are in the w-bit word RAM model. -It is well known that there are linear-space data structures for 2-D orthogonal range counting with worstcase optimal query time O(log n/ log log n). We give an O(nlog log n)-space adaptive data structure that improves the query time to O(log log n+ log k/ log log n), where k is the output count. When k = O(1), our bounds match the state of the art for the 2-D orthogonal range emptiness problem [Chan et al., 2011]. -We give an O(nlog log n)-space data structure for approximate 2-D orthogonal range counting that can compute a (1+d)-factor approximation to the count in O(log log n) time for any fixed constant d > 0. Again, our bounds match the state of the art for the 2-D orthogonal range emptiness problem. -Last, we consider the 1-D range selection problem, where a query in an array involves finding the kth least element in a given subarray. This problem is closely related to 2-D 3-sided orthogonal range counting. Recently, Jørgensen and Larsen [2011] presented a linear-space adaptive data structure with query time O(log log n+ log k/ log log n). We give a new linear-space structure that improves the query time to O(1 + log k/ log log n), exactly matching the lower bound proved by Jørgensen and Larsen.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2295356180",
    "type": "article"
  },
  {
    "title": "Distributed Selfish Load Balancing on Networks",
    "doi": "https://doi.org/10.1145/2629671",
    "publication_date": "2014-08-11",
    "publication_year": 2014,
    "authors": "Petra Berenbrink; Martin Hoefer; Thomas Sauerwald",
    "corresponding_authors": "",
    "abstract": "We study distributed load balancing in networks with selfish agents. In the simplest model considered here, there are n identical machines represented by vertices in a network and m &gt; n selfish agents that unilaterally decide to move from one vertex to another if this improves their experienced load. We present several protocols for concurrent migration that satisfy desirable properties such as being based only on local information and computation and the absence of global coordination or cooperation of agents. Our main contribution is to show rapid convergence of the resulting migration process to states that satisfy different stability or balance criteria. In particular, the convergence time to a Nash equilibrium is only logarithmic in m and polynomial in n , where the polynomial depends on the graph structure. In addition, we show reduced convergence times to approximate Nash equilibria. Finally, we extend our results to networks of machines with different speeds or to agents that have different weights and show similar results for convergence to approximate and exact Nash equilibria.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2622743094",
    "type": "article"
  },
  {
    "title": "Waste Makes Haste",
    "doi": "https://doi.org/10.1145/2988232",
    "publication_date": "2016-11-19",
    "publication_year": 2016,
    "authors": "Erel Segal-Halevi; Avinatan Hassidim; Yonatan Aumann",
    "corresponding_authors": "",
    "abstract": "We consider the classic problem of envy-free division of a heterogeneous good (“cake”) among several agents. It is known that, when the allotted pieces must be connected, the problem cannot be solved by a finite algorithm for three or more agents. The impossibility result, however, assumes that the entire cake must be allocated. In this article, we replace the entire-allocation requirement with a weaker partial-proportionality requirement: the piece given to each agent must be worth for it at least a certain positive fraction of the entire cake value. We prove that this version of the problem is solvable in bounded time even when the pieces must be connected. We present simple, bounded-time envy-free cake-cutting algorithms for (1) giving each of n agents a connected piece with a positive value; (2) giving each of three agents a connected piece worth at least 1/3; (3) giving each of four agents a connected piece worth at least 1/7; (4) giving each of four agents a disconnected piece worth at least 1/4; and (5) giving each of n agents a disconnected piece worth at least (1 − ϵ)/ n for any positive ϵ.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4300664602",
    "type": "article"
  },
  {
    "title": "Approximation Algorithms and Hardness of the <i>k</i> -Route Cut Problem",
    "doi": "https://doi.org/10.1145/2644814",
    "publication_date": "2015-12-31",
    "publication_year": 2015,
    "authors": "Julia Chuzhoy; Yury Makarychev; Aravindan Vijayaraghavan; Yuan Zhou",
    "corresponding_authors": "",
    "abstract": "We study the k -route cut problem: given an undirected edge-weighted graph G = ( V , E ), a collection {( s 1 , t 1 ), ( s 2 , t 2 ), …, ( s r , t r )} of source-sink pairs, and an integer connectivity requirement k , the goal is to find a minimum-weight subset E ′ of edges to remove, such that the connectivity of every pair ( s i , t i ) falls below k . Specifically, in the edge-connectivity version, EC-kRC, the requirement is that there are at most ( k − 1) edge-disjoint paths connecting s i to t i in G ∖ E ′, while in the vertex-connectivity version, VC-kRC, the same requirement is for vertex-disjoint paths. Prior to our work, poly-logarithmic approximation algorithms have been known for the special case where k ⩽ 3, but no non-trivial approximation algorithms were known for any value k &gt; 3, except in the single-source setting. We show an O ( k log 3/2 r )-approximation algorithm for EC-kRC with uniform edge weights, and several polylogarithmic bi-criteria approximation algorithms for EC-kRC and VC-kRC, where the connectivity requirement k is violated by a constant factor. We complement these upper bounds by proving that VC-kRC is hard to approximate to within a factor of k ϵ for some fixed ϵ &gt; 0. We then turn to study a simpler version of VC-kRC, where only one source-sink pair is present. We give a simple bi-criteria approximation algorithm for this case, and show evidence that even this restricted version of the problem may be hard to approximate. For example, we prove that the single source-sink pair version of VC-kRC has no constant-factor approximation, assuming Feige’s Random κ-AND assumption.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4302769223",
    "type": "article"
  },
  {
    "title": "Network Design for <i>s</i> - <i>t</i> Effective Resistance",
    "doi": "https://doi.org/10.1145/3522588",
    "publication_date": "2022-03-17",
    "publication_year": 2022,
    "authors": "Pak Hay Chan; Lap Chi Lau; Aaron Schild; Sam Chiu-wai Wong; Hong Zhou",
    "corresponding_authors": "",
    "abstract": "We consider a new problem of designing a network with small s - t effective resistance. In this problem, we are given an undirected graph G = (V,E) , two designated vertices s,t ∈ V , and a budget k . The goal is to choose a subgraph of G with at most k edges to minimize the s - t effective resistance. This problem is an interpolation between the shortest path problem and the minimum cost flow problem and has applications in electrical network design. We present several algorithmic and hardness results for this problem and its variants. On the hardness side, we show that the problem is NP-hard, and the weighted version is hard to approximate within a factor smaller than two assuming the small-set expansion conjecture. On the algorithmic side, we analyze a convex programming relaxation of the problem and design a constant factor approximation algorithm. The key of the rounding algorithm is a randomized path-rounding procedure based on the optimality conditions and a flow decomposition of the fractional solution. We also use dynamic programming to obtain a fully polynomial time approximation scheme when the input graph is a series-parallel graph, with better approximation ratio than the integrality gap of the convex program for these graphs.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2925520559",
    "type": "article"
  },
  {
    "title": "Approximating Pathwidth for Graphs of Small Treewidth",
    "doi": "https://doi.org/10.1145/3576044",
    "publication_date": "2022-12-13",
    "publication_year": 2022,
    "authors": "Carla Groenland; Gwenaël Joret; Wojciech Nadara; Bartosz Walczak",
    "corresponding_authors": "",
    "abstract": "We describe a polynomial-time algorithm which, given a graph $G$ with treewidth $t$, approximates the pathwidth of $G$ to within a ratio of $O(t\\sqrt{\\log t})$. This is the first algorithm to achieve an $f(t)$-approximation for some function $f$. Our approach builds on the following key insight: every graph with large pathwidth has large treewidth or contains a subdivision of a large complete binary tree. Specifically, we show that every graph with pathwidth at least $th+2$ has treewidth at least $t$ or contains a subdivision of a complete binary tree of height $h+1$. The bound $th+2$ is best possible up to a multiplicative constant. This result was motivated by, and implies (with $c=2$), the following conjecture of Kawarabayashi and Rossman (SODA'18): there exists a universal constant $c$ such that every graph with pathwidth $\\Omega(k^c)$ has treewidth at least $k$ or contains a subdivision of a complete binary tree of height $k$. Our main technical algorithm takes a graph $G$ and some (not necessarily optimal) tree decomposition of $G$ of width $t'$ in the input, and it computes in polynomial time an integer $h$, a certificate that $G$ has pathwidth at least $h$, and a path decomposition of $G$ of width at most $(t'+1)h+1$. The certificate is closely related to (and implies) the existence of a subdivision of a complete binary tree of height $h$. The approximation algorithm for pathwidth is then obtained by combining this algorithm with the approximation algorithm of Feige, Hajiaghayi, and Lee (STOC'05) for treewidth.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3046743316",
    "type": "article"
  },
  {
    "title": "Constant-time Dynamic (Δ +1)-Coloring",
    "doi": "https://doi.org/10.1145/3501403",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Monika Henzinger; Pan Peng",
    "corresponding_authors": "",
    "abstract": "We give a fully dynamic (Las-Vegas style) algorithm with constant expected amortized time per update that maintains a proper (Δ +1)-vertex coloring of a graph with maximum degree at most Δ. This improves upon the previous O (log Δ)-time algorithm by Bhattacharya et al. (SODA 2018). Our algorithm uses an approach based on assigning random ranks to vertices and does not need to maintain a hierarchical graph decomposition. We show that our result does not only have optimal running time but is also optimal in the sense that already deciding whether a Δ-coloring exists in a dynamically changing graph with maximum degree at most Δ takes Ω (log n ) time per operation.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W4214882646",
    "type": "article"
  },
  {
    "title": "Efficient algorithms for bichromatic separability",
    "doi": "https://doi.org/10.1145/1150334.1150338",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Pankaj K. Agarwal; Boris Aronov; Vladlen Koltun",
    "corresponding_authors": "",
    "abstract": "A closed solid body separates one point set from another if it contains the former and the closure of its complement contains the latter. We present a near-linear algorithm for deciding whether two sets of n points in ℝ 3 can be separated by a prism, near-quadratic algorithms for separating by a slab or a wedge, and a near-cubic algorithm for separating by a double wedge. The latter three algorithms improve the previous best known results by an order of magnitude, while the prism separability algorithm constitutes an improvement of two orders of magnitude.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2027237344",
    "type": "article"
  },
  {
    "title": "The collective memory of amnesic processes",
    "doi": "https://doi.org/10.1145/1328911.1328923",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Rachid Guerraoui; Ron R. Levy; Bastian Pochon; Jim Pugh",
    "corresponding_authors": "",
    "abstract": "This article considers the problem of robustly emulating a shared atomic memory over a distributed message-passing system where processes can fail by crashing and possibly recover. We revisit the notion of atomicity in the crash-recovery context and introduce a generic algorithm that emulates an atomic memory. The algorithm is instantiated for various settings according to whether processes have access to local stable storage, and whether, in every execution of the algorithm, a sufficient number of processes are assumed not to crash. We establish the optimality of specific instances of our algorithm in terms of resilience , log complexity (number of stable storage accesses needed in every read or write operation), as well as time complexity (number of communication steps needed in every read or write operation). The article also discusses the impact of considering a multiwriter versus a single-writer memory, as well as the impact of weakening the consistency of the memory by providing safe or regular semantics instead of atomicity.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2034692508",
    "type": "article"
  },
  {
    "title": "Constructing pairwise disjoint paths with few links",
    "doi": "https://doi.org/10.1145/1273340.1273342",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Himanshu Gupta; Rephael Wenger",
    "corresponding_authors": "",
    "abstract": "Let P be a simple polygon and let {( u 1 , u ′ 1 ), ( u 2 , u ′ 2 ),…,( u m , u ′ m )} be a set of m pairs of distinct vertices of P , where for every distinct i , j ≤ m , there exist pairwise disjoint (nonintersecting) paths connecting u i to u ′ i and u j to u ′ j . We wish to construct m pairwise disjoint paths in the interior of P connecting u i to u ′ i for i = 1, …, m , with a minimal total number of line segments. We give an approximation algorithm that constructs such a set of paths using O ( M ) line segments in O ( n log m + M log m ) time, where M is the number of line segments in the optimal solution and n is the size of the polygon.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2088485107",
    "type": "article"
  },
  {
    "title": "An <i>O</i> ( <i>n</i> <sup>2.75</sup> ) algorithm for incremental topological ordering",
    "doi": "https://doi.org/10.1145/1383369.1383370",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Deepak Ajwani; Tobias Friedrich; Ulrich Meyer",
    "corresponding_authors": "",
    "abstract": "We present a simple algorithm which maintains the topological order of a directed acyclic graph (DAG) with n nodes, under an online edge insertion sequence, in O ( n 2.75 ) time, independent of the number m of edges inserted. For dense DAGs, this is an improvement over the previous best result of O (min{ m 3/2 log n , m 3/2 + n 2 log n }) by Katriel and Bodlaender [2006]. We also provide an empirical comparison of our algorithm with other algorithms for incremental topological sorting.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2156167308",
    "type": "article"
  },
  {
    "title": "Determining plurality",
    "doi": "https://doi.org/10.1145/1367064.1367066",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Laurent Alonso; Edward M. Reingold",
    "corresponding_authors": "",
    "abstract": "Given a set of n elements, each of which is colored one of c colors, we must determine an element of the plurality (most frequently occurring) color by pairwise equal/unequal color comparisons of elements. We prove that ( c − 1)( n − c )/2 color comparisons are necessary in the worst case to determine the plurality color and give an algorithm requiring (0.775 c + 5.9) n + O ( c 2 ) color comparisons for c ≥ 9.",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2293538051",
    "type": "article"
  },
  {
    "title": "A faster algorithm for computing the girth of planar and bounded genus graphs",
    "doi": "https://doi.org/10.1145/1868237.1868240",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Hristo Djidjev",
    "corresponding_authors": "Hristo Djidjev",
    "abstract": "The girth of a graph G is the length of a shortest cycle of G . In this article we design an O ( n 5/4 log n ) algorithm for finding the girth of an undirected n -vertex planar graph, the first o ( n 2 ) algorithm for this problem. We also extend our results for the class of graphs embedded into an orientable surface of small genus. Our approach uses several techniques such as graph partitioning, hammock decomposition, graph covering, and dynamic shortest-path computation. We discuss extensions and generalizations of our result.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W1990428898",
    "type": "article"
  },
  {
    "title": "Geodesic delaunay triangulations in bounded planar domains",
    "doi": "https://doi.org/10.1145/1824777.1824787",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Steve Oudot; Leonidas Guibas; Jie Gao; Yue Wang",
    "corresponding_authors": "",
    "abstract": "We introduce a new feature size for bounded domains in the plane endowed with an intrinsic metric. Given a point x in a domain X , the systolic feature size of X at x measures half the length of the shortest loop through x that is not null-homotopic in X . The resort to an intrinsic metric makes the systolic feature size rather insensitive to the local geometry of the domain, in contrast with its predecessors (local feature size, weak feature size, homology feature size). This reduces the number of samples required to capture the topology of X , provided that a reliable approximation to the intrinsic metric of X is available. Under sufficient sampling conditions involving the systolic feature size, we show that the geodesic Delaunay triangulation D x ( L ) of a finite sampling L is homotopy equivalent to X . Under similar conditions, D x ( L ) is sandwiched between the geodesic witness complex C W X ( L ) and a relaxed version C W X,ν ( L ). In the conference version of the article, we took advantage of this fact and proved that the homology of D x ( L ) (and hence the one of X ) can be retrieved by computing the persistent homology between C W X ( L ) and C W X,ν ( L ). Here, we investigate further and show that the homology of X can also be recovered from the persistent homology associated with inclusions of type C W X,ν ( L )↪ C W X,ν′ ( L ), under some conditions on the parameters ν≤ν′. Similar results are obtained for Vietoris-Rips complexes in the intrinsic metric. The proofs draw some connections with recent advances on the front of homology inference from point cloud data, but also with several well-known concepts of Riemannian (and even metric) geometry. On the algorithmic front, we propose algorithms for estimating the systolic feature size of a bounded planar domain X , selecting a landmark set of sufficient density, and computing the homology of X using geodesic witness complexes or Rips complexes.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2061212063",
    "type": "article"
  },
  {
    "title": "The directed circular arrangement problem",
    "doi": "https://doi.org/10.1145/1798596.1798600",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Joseph Naor; Roy Schwartz",
    "corresponding_authors": "",
    "abstract": "We consider the problem of embedding a directed graph onto evenly spaced points on a circle while minimizing the total weighted edge length. We present the first poly-logarithmic approximation factor algorithm for this problem which yields an approximation factor of O (log n log log n ), thus improving the previous Õ (√ n ) approximation factor. In order to achieve this, we introduce a new problem which we call the directed penalized linear arrangement . This problem generalizes both the directed feedback edge set problem and the directed linear arrangement problem. We present an O (log n log log n )-approximation factor algorithm for this newly defined problem. Our solution uses two distinct directed metrics (“right” and “left”) which together yield a lower bound on the value of an optimal solution. In addition, we define a sequence of new directed spreading metrics that are used for applying the algorithm recursively on smaller subgraphs. The new spreading metrics allow us to define an asymmetric region growing procedure that accounts simultaneously for both incoming and outgoing edges. To the best of our knowledge, this is the first time that a region growing procedure is defined in directed graphs that allows for such an accounting.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2078739601",
    "type": "article"
  },
  {
    "title": "Admission control to minimize rejections and online set cover with repetitions",
    "doi": "https://doi.org/10.1145/1644015.1644026",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Noga Alon; Yossi Azar; Shai Gutner",
    "corresponding_authors": "",
    "abstract": "We study the admission control problem in general networks. Communication requests arrive over time, and the online algorithm accepts or rejects each request while maintaining the capacity limitations of the network. The admission control problem has been usually analyzed as a benefit problem, where the goal is to devise an online algorithm that accepts the maximum number of requests possible. The problem with this objective function is that even algorithms with optimal competitive ratios may reject almost all of the requests, when it would have been possible to reject only a few. This could be inappropriate for settings in which rejections are intended to be rare events. In this article, we consider preemptive online algorithms whose goal is to minimize the number of rejected requests. Each request arrives together with the path it should be routed on. We show an O (log 2 ( mc ))-competitive randomized algorithm for the weighted case, where m is the number of edges in the graph and c is the maximum edge capacity. For the unweighted case, we give an O (log m log c )-competitive randomized algorithm. This settles an open question of Blum et al. [2001]. We note that allowing preemption and handling requests with given paths are essential for avoiding trivial lower bounds. The admission control problem is a generalization of the online set cover with repetitions problem, whose input is a family of m subsets of a ground set of n elements. Elements of the ground set are given to the online algorithm one by one, possibly requesting each element a multiple number of times. (If each element arrives at most once, this corresponds to the online set cover problem.) The algorithm must cover each element by different subsets, according to the number of times it has been requested. We give an O (log m log n )-competitive randomized algorithm for the online set cover with repetitions problem. This matches a recent lower bound of Ω(log m log n ) given by Korman [2005] (based on Feige [1998]) for the competitive ratio of any randomized polynomial time algorithm, under the BPP ≠ NP assumption. Given any constant ϵ &gt; 0, an O (log m log n )-competitive deterministic bicriteria algorithm is shown that covers each element by at least (1 - ϵ) k sets, where k is the number of times the element is covered by the optimal solution.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2084729404",
    "type": "article"
  },
  {
    "title": "Perfect matchings via uniform sampling in regular bipartite graphs",
    "doi": "https://doi.org/10.1145/1721837.1721843",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Ashish Goel; Michael Kapralov; Sanjeev Khanna",
    "corresponding_authors": "",
    "abstract": "In this article we further investigate the well-studied problem of finding a perfect matching in a regular bipartite graph. The first nontrivial algorithm, with running time O ( mn ), dates back to König's work in 1916 (here m = nd is the number of edges in the graph, 2 n is the number of vertices, and d is the degree of each node). The currently most efficient algorithm takes time O(m) , and is due to Cole et al. [2001]. We improve this running time to O (min{ m , n 2.5 ln n / d }); this minimum can never be larger than O ( n 1.75 √ln n ). We obtain this improvement by proving a uniform sampling theorem: if we sample each edge in a d -regular bipartite graph independently with a probability p = O ( n ln n / d 2 ) then the resulting graph has a perfect matching with high probability. The proof involves a decomposition of the graph into pieces which are guaranteed to have many perfect matchings but do not have any small cuts. We then establish a correspondence between potential witnesses to nonexistence of a matching (after sampling) in any piece and cuts of comparable size in that same piece. Karger's sampling theorem [1994a, 1994b] for preserving cuts in a graph can now be adapted to prove our uniform sampling theorem for preserving perfect matchings. Using the O ( m √ n ) algorithm (due to Hopcroft and Karp [1973]) for finding maximum matchings in bipartite graphs on the sampled graph then yields the stated running time. We also provide an infinite family of instances to show that our uniform sampling result is tight up to polylogarithmic factors (in fact, up to ln 2 n ).",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2151348756",
    "type": "article"
  },
  {
    "title": "Hausdorff distance under translation for points and balls",
    "doi": "https://doi.org/10.1145/1824777.1824791",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Pankaj K. Agarwal; Sariel Har-Peled; Micha Sharir; Yusu Wang",
    "corresponding_authors": "",
    "abstract": "We study the shape matching problem under the Hausdorff distance and its variants. In the first part of the article, we consider two sets A,B of balls in R d , d =2,3, and wish to find a translation t that minimizes the Hausdorff distance between A+t , the set of all balls in A shifted by t , and B . We consider several variants of this problem. First, we extend the notion of Hausdorff distance from sets of points to sets of balls, so that each ball has to be matched with the nearest ball in the other set. We also consider the problem in the standard setting, by computing the Hausdorff distance between the unions of the two sets (as point sets). Second, we consider either all possible translations t (as is the standard approach), or consider only translations that keep the balls of A+t disjoint from those of B . We propose several exact and approximation algorithms for these problems. In the second part of the article, we note that the Hausdorff distance is sensitive to outliers, and thus consider two variants that are more robust: the root-mean-square (rms) and the summed Hausdorff distance. We propose efficient approximation algorithms for computing the minimum rms and the minimum summed Hausdorff distances under translation, between two point sets in R d . In order to obtain a fast algorithm for the summed Hausdorff distance, we propose a deterministic efficient dynamic data structure for maintaining an ϵ-approximation of the 1-median of a set of points in R d , under insertions and deletions.",
    "cited_by_count": 8,
    "openalex_id": "https://openalex.org/W2158866691",
    "type": "article"
  },
  {
    "title": "Data structures for mergeable trees",
    "doi": "https://doi.org/10.1145/1921659.1921660",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Loukas Georgiadis; Haim Kaplan; Nira Shafrir; Robert E. Tarjan; Renato F. Werneck",
    "corresponding_authors": "",
    "abstract": "Motivated by an application in computational geometry, we consider a novel variant of the problem of efficiently maintaining a forest of dynamic rooted trees. This variant includes an operation that merges two tree paths. In contrast to the standard problem, in which a single operation can only add or delete one arc, one merge can add and delete up to a linear number of arcs. In spite of this, we develop three different methods that need only polylogarithmic time per operation. The first method extends a solution of Farach and Thorup [1998] for the special case of paths. Each merge takes O (log 2 n ) amortized time on an n -node forest and each standard dynamic tree operation takes O (log n ) time; the latter bound is amortized, worst case, or randomized depending on the underlying data structure. For the special case that occurs in the motivating application, in which arbitrary arc deletions (cuts) do not occur, we give a method that takes O (log n ) time per operation, including merging. This is best possible in a model of computation with an Ω( n log n ) lower bound for sorting n numbers, since such sorting can be done in O ( n ) tree operations. For the even-more-special case in which there are no cuts and no parent queries, we give a method that uses standard dynamic trees as a black box: each mergeable tree operation becomes a constant number of standard dynamic tree operations. This third method can also be used in the motivating application, but only by changing the algorithm in the application. Each of our three methods needs different analytical tools and reveals different properties of dynamic trees.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W1973784010",
    "type": "article"
  },
  {
    "title": "I/O-efficient shortest path algorithms for undirected graphs with random or bounded edge lengths",
    "doi": "https://doi.org/10.1145/2229163.2229166",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Ulrich Meyer; Norbert Zeh",
    "corresponding_authors": "",
    "abstract": "We present I/O-efficient single-source shortest path algorithms for undirected graphs. Our main result is an algorithm with I/O complexity O(√( nm log L )/ B +MST( n, m )) on graphs with n vertices, m edges, and arbitrary edge lengths between 1 and L ; MST( n, m denotes the I/O complexity of computing a minimum spanning tree; B denotes the disk block size. If the edge lengths are drawn uniformly at random from (0,1], the expected I/O complexity of the algorithm is O(√ nm/B + ( m/B )log B + MST( n, m )). A simpler algorithm has expected I/O complexity O(√( nm log B )/ B + MST( n, m )) for uniformly random edge lengths.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2011204371",
    "type": "article"
  },
  {
    "title": "Optimal lower bounds for projective list update algorithms",
    "doi": "https://doi.org/10.1145/2500120",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Christoph Ambühl; Bernd Gärtner; Bernhard von Stengel",
    "corresponding_authors": "",
    "abstract": "The list update problem is a classical online problem, with an optimal competitive ratio that is still open, known to be somewhere between 1.5 and 1.6. An algorithm with competitive ratio 1.6, the smallest known to date, is COMB, a randomized combination of BIT and the TIMESTAMP algorithm TS. This and almost all other list update algorithms, like MTF, are projective in the sense that they can be defined by looking only at any pair of list items at a time. Projectivity (also known as “list factoring”) simplifies both the description of the algorithm and its analysis, and so far seems to be the only way to define a good online algorithm for lists of arbitrary length. In this article, we characterize all projective list update algorithms and show that their competitive ratio is never smaller than 1.6 in the partial cost model. Therefore, COMB is a best possible projective algorithm in this model.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2046103177",
    "type": "article"
  },
  {
    "title": "Sparse Euclidean Spanners with Tiny Diameter",
    "doi": "https://doi.org/10.1145/2483699.2483708",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Shay Solomon",
    "corresponding_authors": "Shay Solomon",
    "abstract": "In STOC’95, Arya et al. [1995] showed that for any set of n points in R d , a (1 + ε )-spanner with diameter at most 2 (respectively, 3) and O ( n log n ) edges (respectively, O ( n log log n ) edges) can be built in O ( n log n ) time. Moreover, it was shown in Arya et al. [1995] and Narasimhan and Smid [2007] that for any k ≥ 4, one can build in O ( n (log n )2 k α k ( n )) time a (1 + ε )-spanner with diameter at most 2 k and O ( n 2 k α k ( n )) edges. The function α k is the inverse of a certain function at the k /2 th level of the primitive recursive hierarchy, where α 0 ( n ) = n /2 , α 1 ( n ) = √ n , α 2 ( n ) = log n , α 3 ( n ) = log log n , α 4 ( n ) = log* n , α 5 ( n ) = 12 log* n , ..., etc. It is also known [Narasimhan and Smid 2007] that if one allows quadratic time, then these bounds can be improved. Specifically, for any k ≥ 4, a (1 + ε )-spanner with diameter at most k and O ( nkα k ( n )) edges can be constructed in O ( n 2 ) time [Narasimhan and Smid 2007]. A major open question in this area is whether one can construct within time O ( n log n + nkα k ( n )) a (1 + ε )-spanner with diameter at most k and O ( nkα k ( n )) edges. In this article, we answer this question in the affirmative. Moreover, in fact, we provide a stronger result. Specifically, we show that for any k ≥ 4, a (1 + ε )-spanner with diameter at most k and O ( nα k ( n )) edges can be built in optimal time O ( n log n ).",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2063900329",
    "type": "article"
  },
  {
    "title": "Computing 2-Walks in Polynomial Time",
    "doi": "https://doi.org/10.1145/3183368",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Andreas Schmid; Jens M. Schmidt",
    "corresponding_authors": "",
    "abstract": "A 2-walk of a graph is a walk visiting every vertex at least once and at most twice. By generalizing decompositions of Tutte and Thomassen, Gao, Richter, and Yu proved that every 3-connected planar graph contains a closed 2-walk such that all vertices visited twice are contained in 3-separators. This seminal result generalizes Tutte’s theorem that every 4-connected planar graph is Hamiltonian, as well as Barnette’s theorem that every 3-connected planar graph has a spanning tree with maximum degree at most 3. The algorithmic challenge of finding such a closed 2-walk is to overcome big overlapping subgraphs in the decomposition, which are also inherent in Tutte’s and Thomassen’s decompositions. We solve this problem by extending the decomposition of Gao, Richter, and Yu in such a way that all pieces into which the graph is decomposed are edge-disjoint. This implies the first polynomial-time algorithm that computes the closed 2-walk just mentioned. Its running time is O ( n 3 ).",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2801537393",
    "type": "article"
  },
  {
    "title": "Stream Sampling Framework and Application for Frequency Cap Statistics",
    "doi": "https://doi.org/10.1145/3234338",
    "publication_date": "2018-09-24",
    "publication_year": 2018,
    "authors": "Edith Cohen",
    "corresponding_authors": "Edith Cohen",
    "abstract": "Unaggregated data, in a streamed or distributed form, are prevalent and come from diverse sources such as interactions of users with web services and IP traffic. Data elements have keys (cookies, users, queries), and elements with different keys interleave. Analytics on such data typically utilizes statistics expressed as a sum over keys in a specified segment of a function f applied to the frequency (the total number of occurrences) of the key. In particular, Distinct is the number of active keys in the segment, Sum is the sum of their frequencies, and both are special cases of frequency cap statistics, which cap the frequency by a parameter T . Random samples can be very effective for quick and efficient estimation of statistics at query time. Ideally, to estimate statistics for a given function f , our sample would include a key with frequency w with probability roughly proportional to f ( w ). The challenge is that while such “gold-standard” samples can be easily computed after aggregating the data (computing the set of key-frequency pairs), this aggregation is costly: It requires structure of size that is proportional to the number of active keys, which can be very large. We present a sampling framework for unaggregated data that uses a single pass (for streams) or two passes (for distributed data) and structure size proportional to the desired sample size. Our design unifies classic solutions for Distinct and Sum. Specifically, our ℓ-capped samples provide nonnegative unbiased estimates of any monotone non-decreasing frequency statistics and statistical guarantees on quality that are close to gold standard for cap statistics with T =Θ (ℓ). Furthermore, our multi-objective samples provide these statistical guarantees on quality for all concave sub-linear statistics (the nonnegative span of cap functions) while incurring only a logarithmic overhead on sample size.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2893034441",
    "type": "article"
  },
  {
    "title": "Recognizing Weak Embeddings of Graphs",
    "doi": "https://doi.org/10.1145/3344549",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "Hugo A. Akitaya; Radoslav Fulek; Csaba D. Tóth",
    "corresponding_authors": "",
    "abstract": "We present an efficient algorithm for a problem in the interface between clustering and graph embeddings. An embedding φ : G → M of a graph G into a 2-manifold M maps the vertices in V ( G ) to distinct points and the edges in E ( G ) to interior-disjoint Jordan arcs between the corresponding vertices. In applications in clustering, cartography, and visualization, nearby vertices and edges are often bundled to the same point or overlapping arcs due to data compression or low resolution. This raises the computational problem of deciding whether a given map φ : G → M comes from an embedding. A map φ : G → M is a weak embedding if it can be perturbed into an embedding ψ ε : G → M with ‖ φ − ψ ε ‖ &lt; ε for every ε &gt; 0, where ‖.‖ is the unform norm. A polynomial-time algorithm for recognizing weak embeddings has recently been found by Fulek and Kynčl. It reduces the problem to solving a system of linear equations over Z 2 . It runs in O ( n 2ω )≤ O ( n 4.75 ) time, where ω ∈ [2,2.373) is the matrix multiplication exponent and n is the number of vertices and edges of G . We improve the running time to O ( n log n ). Our algorithm is also conceptually simpler: We perform a sequence of local operations that gradually “untangles” the image φ( G ) into an embedding ψ( G ) or reports that φ is not a weak embedding. It combines local constraints on the orientation of subgraphs directly, thereby eliminating the need for solving large systems of linear equations.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2979847601",
    "type": "article"
  },
  {
    "title": "A Faster Algorithm for Minimum-cost Bipartite Perfect Matching in Planar Graphs",
    "doi": "https://doi.org/10.1145/3365006",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Mudabir Kabir Asathulla; Sanjeev Khanna; Nathaniel Lahn; Sharath Raghvendra",
    "corresponding_authors": "",
    "abstract": "Given a weighted planar bipartite graph G ( A ∪ B , E ) where each edge has an integer edge cost, we give an Õ( n 4/3 log nC ) time algorithm to compute minimum-cost perfect matching; here C is the maximum edge cost in the graph. The previous best-known planarity exploiting algorithm has a running time of O ( n 3/2 log n ) and is achieved by using planar separators (Lipton and Tarjan ’80). Our algorithm is based on the bit-scaling paradigm (Gabow and Tarjan ’89). For each scale, our algorithm first executes O ( n 1/3 ) iterations of Gabow and Tarjan’s algorithm in O ( n 4/3 ) time leaving only O ( n 2/3 ) vertices unmatched. Next, it constructs a compressed residual graph H with O ( n 2/3 ) vertices and O ( n ) edges. This is achieved by using an r -division of the planar graph G with r = n 2/3 . For each partition of the r -division, there is an edge between two vertices of H if and only if they are connected by a directed path inside the partition. Using existing efficient shortest-path data structures, the remaining O ( n 2/3 ) vertices are matched by iteratively computing a minimum-cost augmenting path, each taking Õ( n 2/3 ) time. Augmentation changes the residual graph, so the algorithm updates the compressed representation for each partition affected by the change in Õ( n 2/3 ) time. We bound the total number of affected partitions over all the augmenting paths by O ( n 2/3 log n ). Therefore, the total time taken by the algorithm is Õ( n 4/3 ).",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2986113791",
    "type": "article"
  },
  {
    "title": "Randomized Memoryless Algorithms for the Weighted and the Generalized <i>k</i> -server Problems",
    "doi": "https://doi.org/10.1145/3365002",
    "publication_date": "2019-12-05",
    "publication_year": 2019,
    "authors": "Ashish Chiplunkar; Sundar Vishwanathan",
    "corresponding_authors": "",
    "abstract": "The weighted k -server problem is a generalization of the k -server problem wherein the cost of moving a server of weight β i through a distance d is β i ⋅ d . On uniform metric spaces, this models caching with caches having different page replacement costs. A memoryless algorithm is an online algorithm whose behavior is independent of the history given the positions of its k servers. In this article, we develop a framework to analyze the competitiveness of randomized memoryless algorithms. The key technical contribution is a method for working with potential functions defined implicitly as the solution of a linear system. Using this, we establish tight bounds on the competitive ratio achievable by randomized memoryless algorithms for the weighted k -server problem on uniform metrics. We first prove that there is an α k -competitive memoryless algorithm for this problem, where α k =α k − 1 2 + 3α k − 1 +1; α 1 = 1. We complement this result by proving that no randomized memoryless algorithm can have a competitive ratio less than α k . Finally, we prove that the above bounds also hold for the generalized k -server problem on weighted uniform metrics.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2994446698",
    "type": "article"
  },
  {
    "title": "Doubly Balanced Connected Graph Partitioning",
    "doi": "https://doi.org/10.1145/3381419",
    "publication_date": "2020-03-09",
    "publication_year": 2020,
    "authors": "Saleh Soltan; Mihalis Yannakakis; Gil Zussman",
    "corresponding_authors": "",
    "abstract": "We introduce and study the doubly balanced connected graph partitioning problem: Let G =( V , E ) be a connected graph with a weight (supply/demand) function p : V → {−1, +1} satisfying p ( V )=∑ j &amp;isin V p ( j ) = 0. The objective is to partition G into ( V 1 , V 2 ) such that G [ V 1 ] and G [ V 2 ] are connected, ∣ p ( V 1 )∣,∣ p ( V 2 )∣≤ c p , and max{ ∣ V 1 / V 2 ∣,∣ V 2 / V 1 ∣} ≤ c s , for some constants c p and c s . When G is 2-connected, we show that a solution with c p =1 and c s =2 always exists and can be found in randomized polynomial time. Moreover, when G is 3-connected, we show that there is always a “perfect” solution (a partition with p ( V 1 )= p ( V 2 )=0 and ∣ V 1 ∣=∣ V 2 ∣, if ∣ V ∣≡ 0 (mod 4)), and it can be found in randomized polynomial time. Our techniques can be extended, with similar results, to the case in which the weights are arbitrary (not necessarily ±1), and to the case that p ( V )≠ 0 and the excess supply/demand should be split evenly. They also apply to the problem of partitioning a graph with two types of nodes into two large connected subgraphs that preserve approximately the proportion of the two types.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3012413036",
    "type": "article"
  },
  {
    "title": "Testing Bounded Arboricity",
    "doi": "https://doi.org/10.1145/3381418",
    "publication_date": "2020-03-09",
    "publication_year": 2020,
    "authors": "Talya Eden; Reut Levi; Dana Ron",
    "corresponding_authors": "",
    "abstract": "In this article, we consider the problem of testing whether a graph has bounded arboricity. The class of graphs with bounded arboricity includes many important graph families (e.g., planar graphs and randomly generated preferential attachment graphs). Graphs with bounded arboricity have been studied extensively in the past, particularly because for many problems, they allow for much more efficient algorithms and/or better approximation ratios. We present a tolerant tester in the general-graphs model. The general-graphs model allows access to degree and neighbor queries, and the distance is defined with respect to the actual number of edges. Namely, we say that a graph G is ϵ-close to having arboricity α if by removing at most an ϵ-fraction of its edges, we can obtain a graph G ′ that has arboricity α, and otherwise we say that G is ϵ-far. Our algorithm distinguishes between graphs that are ϵ-close to having arboricity α and graphs that are c ṡ ϵ-far from having arboricity 3α, where c is an absolute small constant. The query complexity and running time of the algorithm are Õ ( n / ϵ√ m ) + (1 / ϵ) O (log(1/ϵ)) , where n denotes the number of vertices and m denotes the number of edges (we use the notation Õ to hide poly-logarithmic factors in n ). In terms of the dependence on n and m , this bound is optimal up to poly-logarithmic factors since Ω( n / √ m ) queries are necessary.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3012533071",
    "type": "article"
  },
  {
    "title": "Improved Deterministic Algorithms for Linear Programming in Low Dimensions",
    "doi": "https://doi.org/10.1145/3155312",
    "publication_date": "2018-06-16",
    "publication_year": 2018,
    "authors": "Timothy M. Chan",
    "corresponding_authors": "Timothy M. Chan",
    "abstract": "Chazelle and Matoušek [ J. Algorithms , 1996] presented a derandomization of Clarkson’s sampling-based algorithm [ J. ACM , 1995] for solving linear programs with n constraints and d variables in d (7+ o (1)) d n deterministic time. The time bound can be improved to d (5+ o (1)) d n with subsequent work by Brönnimann, Chazelle, and Matoušek [ SIAM J. Comput. , 1999]. We first point out a much simpler derandomization of Clarkson’s algorithm that avoids ε-approximations and runs in d (3+ o (1)) d n time. We then describe a few additional ideas that eventually improve the deterministic time bound to d (1/2+ o (1)) d n .",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4243587444",
    "type": "article"
  },
  {
    "title": "Windrose Planarity",
    "doi": "https://doi.org/10.1145/3239561",
    "publication_date": "2018-09-17",
    "publication_year": 2018,
    "authors": "Patrizio Angelini; Giordano Da Lozzo; Giuseppe Di Battista; Valentino Di Donato; Philipp Kindermann; Günter Rote; Ignaz Rutter",
    "corresponding_authors": "",
    "abstract": "Given a planar graph G and a partition of the neighbors of each vertex v in four sets v ↗ , v ↖ , v ↙ , and v ↘ , the problem W indrose P lanarity asks to decide whether G admits a windrose-planar drawing , that is, a planar drawing in which (i) each neighbor u ∈ v ↗ v is above and to the right of v , (ii) each neighbor u ∈ v ↖ is above and to the left of v , (iii) each neighbor u ∈ v ↙ is below and to the left of v , (iv) each neighbor u ∈ v ↘ is below and to the right of v , and (v) edges are represented by curves that are monotone with respect to each axis. By exploiting both the horizontal and the vertical relationship among vertices, windrose-planar drawings allow us to simultaneously visualize two partial orders defined by means of the edges of the graph. Although the problem is NP -hard in the general case, we give a polynomial-time algorithm for testing whether there exists a windrose-planar drawing that respects a given combinatorial embedding. This algorithm is based on a characterization of the plane triangulations admitting a windrose-planar drawing. Furthermore, for any embedded graph with n vertices that has a windrose-planar drawing, we can construct one with at most one bend per edge and with at most 2 n −5 bends in total, which lies on the 3 n × 3 n grid. The latter result contrasts with the fact that straight-line windrose-planar drawings may require exponential area.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4289389740",
    "type": "article"
  },
  {
    "title": "The Two-Edge Connectivity Survivable-Network Design Problem in Planar Graphs",
    "doi": "https://doi.org/10.1145/2831235",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Glencora Borradaile; Philip N. Klein",
    "corresponding_authors": "",
    "abstract": "Consider the following problem: given a graph with edge costs and a subset Q of vertices, find a minimum-cost subgraph in which there are two edge-disjoint paths connecting every pair of vertices in Q . The problem is a failure-resilient analog of the Steiner tree problem arising, for example, in telecommunications applications. We study a more general mixed-connectivity formulation, also employed in telecommunications optimization. Given a number (or requirement ) r ( v ) ∈ {0, 1, 2} for each vertex v in the graph, find a minimum-cost subgraph in which there are min { r ( u ), r ( v )} edge-disjoint u -to- v paths for every pair u , v of vertices. We address the problem in planar graphs, considering a popular relaxation in which the solution is allowed to use multiple copies of the input-graph edges (paying separately for each copy). The problem is max SNP-hard in general graphs and strongly NP-hard in planar graphs. We give the first polynomial-time approximation scheme in planar graphs. The running time is O ( n log n ). Under the additional restriction that the requirements are only non-zero for vertices on the boundary of a single face of a planar graph, we give a polynomial-time algorithm to find the optimal solution.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2144241285",
    "type": "article"
  },
  {
    "title": "Testing Properties of Sparse Images",
    "doi": "https://doi.org/10.1145/2635806",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "Dana Ron; Gilad Tsur",
    "corresponding_authors": "",
    "abstract": "We initiate the study of testing properties of images that correspond to sparse 0/1-valued matrices of size n × n . Our study is related to but different from the study initiated by Raskhodnikova ( Proceedings of RANDOM, 2003 ), where the images correspond to dense 0/1-valued matrices. Specifically, in the model studied by Raskhodnikova, the distance that an image has to a specific property is the number of entries that should be modified in the corresponding matrix so that the property can be obtained, divided by the total number of entries: n 2 . In the model we consider, the distance is the number of entries that should be modified divided by the actual number of 1’s in the matrix, which may be much smaller than n 2 . We study several natural properties: connectivity, convexity, monotonicity, and being a line. In all cases, we give testing algorithms with sublinear complexity, and, in some of the cases, we also provide corresponding lower bounds.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2153773146",
    "type": "article"
  },
  {
    "title": "Algorithms for Hub Label Optimization",
    "doi": "https://doi.org/10.1145/2996593",
    "publication_date": "2016-11-15",
    "publication_year": 2016,
    "authors": "Maxim A. Babenko; Andrew V. Goldberg; Anupam Gupta; Viswanath Nagarajan",
    "corresponding_authors": "",
    "abstract": "We consider the hub label optimization problem, which arises in designing fast preprocessing-based shortest-path algorithms. We give O (log n )-approximation algorithms for the objectives of minimizing the maximum label size (ℓ ∞ -norm) and simultaneously minimizing a constant number of ℓ p -norms. Prior to this, an O (log n )-approximation algorithm was known [Cohen et al. 2003] only for minimizing the total label size (ℓ 1 -norm).",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2556123342",
    "type": "article"
  },
  {
    "title": "Approximating Nash Social Welfare under Submodular Valuations through (Un)Matchings",
    "doi": "https://doi.org/10.1145/3613452",
    "publication_date": "2023-08-16",
    "publication_year": 2023,
    "authors": "Jugal Garg; Pooja Kulkarni; Rucha Kulkarni",
    "corresponding_authors": "",
    "abstract": "We study the problem of approximating maximum Nash social welfare (NSW) when allocating m indivisible items among n asymmetric agents with submodular valuations. The NSW is a well-established notion of fairness and efficiency, defined as the weighted geometric mean of agents’ valuations. For special cases of the problem with symmetric agents and additive(-like) valuation functions, approximation algorithms have been designed using approaches customized for these specific settings, and they fail to extend to more general settings. Hence, no approximation algorithm with a factor independent of m was known either for asymmetric agents with additive valuations or for symmetric agents beyond additive(-like) valuations before this work. In this article, we extend our understanding of the NSW problem to far more general settings. Our main contribution is two approximation algorithms for asymmetric agents with additive and submodular valuations. Both algorithms are simple to understand and involve non-trivial modifications of a greedy repeated matchings approach. Allocations of high-valued items are done separately by un-matching certain items and re-matching them by different processes in both algorithms. We show that these approaches achieve approximation factors of O ( n ) and O ( n log n ) for additive and submodular cases, independent of the number of items. For additive valuations, our algorithm outputs an allocation that also achieves the fairness property of envy-free up to one item ( EF1 ). Furthermore, we show that the NSW problem under submodular valuations is strictly harder than all currently known settings with an \\(\\frac{\\mathrm{e}}{\\mathrm{e}-1}\\) factor of the hardness of approximation, even for constantly many agents. For this case, we provide a different approximation algorithm that achieves a factor of \\(\\frac{\\mathrm{e}}{\\mathrm{e}-1}\\) , hence resolving it completely.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2996923187",
    "type": "article"
  },
  {
    "title": "Pricing multicasting in more flexible network models",
    "doi": "https://doi.org/10.1145/1077464.1077469",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Micah Adler; Dan Rubenstein",
    "corresponding_authors": "",
    "abstract": "The problem of designing efficient algorithms for sharing the cost of multicasting has recently received considerable attention. In this article, we examine the effect on the complexity of pricing when two flexibility-enhancing mechanisms are incorporated into the network model. In particular, we study a model where the session is offered at a number of different rates of transmission, and where there is a cost for enabling multicasting at each node of the network. We consider two techniques that have been used in practice to provide multiple rates: using a layered transmission scheme (called the layered paradigm ) and using different multicast groups for each possible rate (called the split session paradigm ). We demonstrate that the difference between these two paradigms has a significant impact on the complexity of pricing multicasting.For the layered paradigm, we provide a distributed algorithm for computing pricing efficiently in terms of local computation and message complexity. For the split session paradigm, on the other hand, we demonstrate that this problem can be solved in polynomial time if the number of possible rates is fixed, but if the number of rates is part of the input, then the problem becomes NP-Hard even to approximate. We also examine the effect of delivering the transmissions for the various rates from different locations within the network. We show that, in this case, the pricing problem becomes NP-Hard for the split session paradigm even for a fixed constant number of possible rates but if layering is used, then it can be solved in polynomial time by formulating the problem as a totally unimodular integer program.",
    "cited_by_count": 10,
    "openalex_id": "https://openalex.org/W2151353987",
    "type": "article"
  },
  {
    "title": "The cyclic multi-peg Tower of Hanoi",
    "doi": "https://doi.org/10.1145/1159892.1159893",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "Daniel Berend; Amir Sapir",
    "corresponding_authors": "",
    "abstract": "Variants of the classical Tower of Hanoi problem evolved in various directions. Allowing more than 3 pegs, and imposing limitations on the possible moves among the pegs, are two of these. Here, we deal with the case of h ≥3 pegs arranged on a circle, where moves are allowed only from a peg to the next peg (in the clockwise direction). Unlike the multi-peg problem without restrictions on moves between pegs, the complexity of this variant as a function of the number of disks is exponential. We find explicit lower and upper bounds for its complexity for any h , and show how this complexity can be estimated arbitrarily well for any specific h .",
    "cited_by_count": 9,
    "openalex_id": "https://openalex.org/W2051684267",
    "type": "article"
  },
  {
    "title": "Average-case analysis of some plurality algorithms",
    "doi": "https://doi.org/10.1145/1497290.1497293",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Laurent Alonso; Edward M. Reingold",
    "corresponding_authors": "",
    "abstract": "Given a set of n elements, each of which is colored one of c colors, we must determine an element of the plurality (most frequently occurring) color by pairwise equal/unequal color comparisons of elements. We focus on the expected number of color comparisons when the c n colorings are equally probable. We analyze an obvious algorithm, showing that its expected performance is c 2 + c − 2/2 c n − O ( c 2 ), with variance Θ( c 2 n ). We present and analyze an algorithm for the case c = 3 colors whose average complexity on the 3 n equally probable inputs is 7083/5425 n + O (√ n ) = 1.3056… n + O (√ n ), substantially better than the expected complexity 5/3 n + O (1) = 1.6666… n + O (1) of the obvious algorithm. We describe a similar algorithm for c =4 colors whose average complexity on the 4 n equally probable inputs is 761311/402850 n + O (log n ) = 1.8898… n + O (log n ), substantially better than the expected complexity 9/4 n + O (1) = 2.25 n + O (1) of the obvious algorithm.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2079994531",
    "type": "article"
  },
  {
    "title": "Approximating Geometric Knapsack via L-packings",
    "doi": "https://doi.org/10.1145/3473713",
    "publication_date": "2021-10-04",
    "publication_year": 2021,
    "authors": "Waldo Gálvez; Fabrizio Grandoni; Salvatore Ingala; Sandy Heydrich; Arindam Khan; Andreas Wiese",
    "corresponding_authors": "",
    "abstract": "We study the two-dimensional geometric knapsack problem, in which we are given a set of n axis-aligned rectangular items, each one with an associated profit, and an axis-aligned square knapsack. The goal is to find a (non-overlapping) packing of a maximum profit subset of items inside the knapsack (without rotating items). The best-known polynomial-time approximation factor for this problem (even just in the cardinality case) is 2+ε [Jansen and Zhang, SODA 2004]. In this article we present a polynomial-time 17/9+ε &lt; 1.89-approximation, which improves to 558/325+ε &lt; 1.72 in the cardinality case. Prior results pack items into a constant number of rectangular containers that are filled via greedy strategies. We deviate from this setting and show that there exists a large profit solution where items are packed into a constant number of containers plus one L-shaped region at the boundary of the knapsack containing narrow-high items and thin-wide items. These items may interact in complex manners at the corner of the L. The best-known approximation ratio for the subproblem in the L-shaped region is 2+ε (via a trivial reduction to one-dimensional knapsack); hence, as a second major result we present a PTAS for this case that we believe might be of broader utility. We also consider the variant with rotations, where items can be rotated by 90 degrees. Again, the best-known polynomial-time approximation factor (even for the cardinality case) is 2+ε [Jansen and Zhang, SODA 2004]. We present a polynomial-time (3/2+ε)-approximation for this setting, which improves to 4/3+ε in the cardinality case.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3203979862",
    "type": "article"
  },
  {
    "title": "Smaller Cuts, Higher Lower Bounds",
    "doi": "https://doi.org/10.1145/3469834",
    "publication_date": "2021-10-04",
    "publication_year": 2021,
    "authors": "Amir Abboud; Keren Censor-Hillel; Seri Khoury; Ami Paz",
    "corresponding_authors": "",
    "abstract": "This article proves strong lower bounds for distributed computing in the congest model, by presenting the bit-gadget : a new technique for constructing graphs with small cuts. The contribution of bit-gadgets is twofold. First, developing careful sparse graph constructions with small cuts extends known techniques to show a near-linear lower bound for computing the diameter, a result previously known only for dense graphs. Moreover, the sparseness of the construction plays a crucial role in applying it to approximations of various distance computation problems, drastically improving over what can be obtained when using dense graphs. Second, small cuts are essential for proving super-linear lower bounds, none of which were known prior to this work. In fact, they allow us to show near-quadratic lower bounds for several problems, such as exact minimum vertex cover or maximum independent set, as well as for coloring a graph with its chromatic number. Such strong lower bounds are not limited to NP-hard problems, as given by two simple graph problems in P, which are shown to require a quadratic and near-quadratic number of rounds. All of the above are optimal up to logarithmic factors. In addition, in this context, the complexity of the all-pairs-shortest-paths problem is discussed. Finally, it is shown that graph constructions for congest lower bounds translate to lower bounds for the semi-streaming model, despite being very different in its nature.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W3204294665",
    "type": "article"
  },
  {
    "title": "Spider Covers for Prize-Collecting Network Activation Problem",
    "doi": "https://doi.org/10.1145/3132742",
    "publication_date": "2017-10-25",
    "publication_year": 2017,
    "authors": "Takuro Fukunaga",
    "corresponding_authors": "Takuro Fukunaga",
    "abstract": "In the network activation problem, each edge in a graph is associated with an activation function that decides whether the edge is activated from weights assigned to its end nodes. The feasible solutions of the problem are node weights such that the activated edges form graphs of required connectivity, and the objective is to find a feasible solution minimizing its total weight. In this article, we consider a prize-collecting version of the network activation problem and present the first nontrivial approximation algorithms. Our algorithms are based on a new linear programming relaxation of the problem. They round optimal solutions for the relaxation by repeatedly computing node weights activating subgraphs, called spiders, which are known to be useful for approximating the network activation problem. For the problem with node-connectivity requirements, we also present a new potential function on uncrossable biset families and use it to analyze our algorithms.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1675942548",
    "type": "article"
  },
  {
    "title": "Linear-Time Parameterized Algorithms via Skew-Symmetric Multicuts",
    "doi": "https://doi.org/10.1145/3128600",
    "publication_date": "2017-09-19",
    "publication_year": 2017,
    "authors": "M. S. Ramanujan; Saket Saurabh",
    "corresponding_authors": "",
    "abstract": "A skew-symmetric graph ( D =( V , A ),σ) is a directed graph D with an involution σ on the set of vertices and arcs. Flows on skew-symmetric graphs have been used to generalize maximum flow and maximum matching problems on graphs, initially by Tutte and later by Goldberg and Karzanov. In this article, we introduce a separation problem, d -S kew -S ymmetric M ulticut , where we are given a skew-symmetric graph D , a family τ of d -size subsets of vertices, and an integer k . The objective is to decide whether there is a set X ⊑ A of k arcs such that every set J in the family has a vertex υ such that υ and σ(υ) are in different strongly connected components of D ′=( V ,A \\ ( X ∪ σ( X )). In this work, we give an algorithm for d -S kew -S ymmetric M ulticut that runs in time O ((4 d ) k ( m + n +ℓ)), where m is the number of arcs in the graph, n is the number of vertices, and ℓ is the length of the family given in the input. This problem, apart from being independently interesting, also captures the main combinatorial difficulty of numerous classical problems. Our algorithm for d -S kew -S ymmetric M ulticut paves the way for the first linear-time parameterized algorithms for several problems. We demonstrate its utility by obtaining the following linear-time parameterized algorithms: — We show that A lmost 2-SAT is a special case of 1-S kew -S ymmetric M ulticut , resulting in an algorithm for A lmost 2-SAT that runs in time O (4 k k 4 ℓ), where k is the size of the solution and ℓ is the length of the input formula. Then, using linear-time parameter-preserving reductions to A lmost 2-SAT, we obtain algorithms for O dd C ycle T ransversal and E dge B ipartization that run in time O (4 k k 4 ( m + n )) and O (4 k k 5 ( m + n )), respectively, where k is the size of the solution, and m and n are the number of edges and vertices respectively. This resolves an open problem posed by Reed et al. and improves on the earlier almost-linear-time algorithm of Kawarabayashi and Reed. — We show that D eletion q-Horn B ackdoor S et D etection is a special case of 3-S kew -S ymmetric M ulticut , giving us an algorithm for D eletion q-Horn B ackdoor S et D etection that runs in time O (12 k k 5 ℓ), where k is the size of the solution and ℓ is the length of the input formula. This gives the first fixed-parameter tractable algorithm for this problem answering a question posed in a work by Narayanaswamy et al. Using this result, we get an algorithm for S atisfiability that runs in time O (12 k k 5 ℓ), where k is the size of the smallest q-Horn deletion backdoor set, with ℓ being the length of the input formula.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1955711040",
    "type": "article"
  },
  {
    "title": "How to trim a MST",
    "doi": "https://doi.org/10.1145/2151171.2151179",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Toshihiro Fujito",
    "corresponding_authors": "Toshihiro Fujito",
    "abstract": "The minimum cost-tree cover problem is to compute a minimum cost-tree T in a given connected graph G with costs on the edges, such that the vertices spanned by T form a vertex cover for G . The problem is supposed to occur in applications of vertex cover and in edge-dominating sets when additional connectivity is required for solutions. Whereas a linear-time 2 -approximation algorithm for the unweighted case has been known for quite a while, the best approximation ratio known for the weighted case is 3 . Moreover, the 3 -approximation algorithms for such cases are far from practical due to their inefficiency. In this article we present a fast, purely combinatorial 2 -approximation algorithm for the minimum cost-tree cover problem. It constructs a good approximate solution by trimming some leaves within a minimum spanning tree (MST); and, to determine which leaves to trim, it uses both the primal-dual schema and an instance layering technique adapted from the local ratio method.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1974759992",
    "type": "article"
  },
  {
    "title": "Tight bounds and a fast FPT algorithm for directed Max-Leaf Spanning Tree",
    "doi": "https://doi.org/10.1145/2000807.2000812",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Paul Bonsma; Frederic Dorn",
    "corresponding_authors": "",
    "abstract": "An out-tree T of a directed graph D is a rooted tree subgraph with all arcs directed outwards from the root. An out-branching is a spanning out-tree. By ℓ( D ) and ℓ s ( D ), we denote the maximum number of leaves over all out-trees and out-branchings of D , respectively. We give fixed parameter tractable algorithms for deciding whether ℓ s ( D ) ≥ k and whether ℓ( D ) ≥ k for a digraph D on n vertices, both with time complexity 2 O ( k log k ) · n O (1) . This answers an open question whether the problem for out-branchings is in FPT, and improves on the previous complexity of 2 O ( k log 2 k ) · n O (1) in the case of out-trees. To obtain the complexity bound in the case of out-branchings, we prove that when all arcs of D are part of at least one out-branching, ℓ s ( D ) ≥ ℓ( D )/3. The second bound we prove in this article states that for strongly connected digraphs D with minimum in-degree 3, ℓ s ( D ) ≥ Θ(√ n ), where previously ℓ s ( D ) ≥ Θ(3√ n ) was the best known bound. This bound is tight, and also holds for the larger class of digraphs with minimum in-degree 3 in which every arc is part of at least one out-branching.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1993219112",
    "type": "article"
  },
  {
    "title": "How well can primal-dual and local-ratio algorithms perform?",
    "doi": "https://doi.org/10.1145/1978782.1978784",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Allan Borodin; David Cashman; Avner Magen",
    "corresponding_authors": "",
    "abstract": "We define an algorithmic paradigm, the stack model, that captures many primal-dual and local-ratio algorithms for approximating covering and packing problems. The stack model is defined syntactically and without any complexity limitations and hence our approximation bounds are independent of the P versus NP question. Using the stack model, we bound the performance of a broad class of primal-dual and local-ratio algorithms and supply a (log n +1)/2 inapproximability result for set cover, a 4/3 inapproximability for min Steiner tree, and a 0.913 inapproximability for interval scheduling on two machines.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2003388935",
    "type": "article"
  },
  {
    "title": "An FPTAS for the minimum total weighted tardiness problem with a fixed number of distinct due dates",
    "doi": "https://doi.org/10.1145/2344422.2344430",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "George Karakostas; Stavros G. Kolliopoulos; Jing Wang",
    "corresponding_authors": "",
    "abstract": "Given a sequencing of jobs on a single machine, each one with a weight, processing time, and a due date, the tardiness of a job is the time needed for its completion beyond its due date. We present an FPTAS for the basic scheduling problem of minimizing the total weighted tardiness when the number of distinct due dates is fixed. Previously, an FPTAS was known only for the case where all jobs have a common due date.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2090543144",
    "type": "article"
  },
  {
    "title": "Improved Approximation Algorithm for Steiner <i>k</i> -Forest with Nearly Uniform Weights",
    "doi": "https://doi.org/10.1145/3077581",
    "publication_date": "2017-07-13",
    "publication_year": 2017,
    "authors": "Michael Dinitz; Guy Kortsarz; Zeev Nutov",
    "corresponding_authors": "",
    "abstract": "In the Steiner k -Forest problem, we are given an edge weighted graph, a collection D of node pairs, and an integer k ⩽ | D |. The goal is to find a min-weight subgraph that connects at least k pairs. The best known ratio for this problem is min { O (√ n ), O (√ k )} [Gupta et al. 2010]. In Gupta et al. [2010], it is also shown that ratio ρ for Steiner k -Forest implies ratio O (ρ · log 2 n ) for the related Dial-a-Ride problem. The only other algorithm known for Dial-a-Ride, besides the one resulting from Gupta et al. [2010], has ratio O (√ n ) [Charikar and Raghavachari 1998]. We obtain approximation ratio n 0.448 for Steiner k -Forest and Dial-a-Ride with unit weights, breaking the O (√ n ) approximation barrier for this natural case. We also show that if the maximum edge-weight is O ( n ϵ ), then one can achieve ratio O ( n (1 + ϵ) · 0.448 ), which is less than √ n if ϵ is small enough. The improvement for Dial-a-Ride is the first progress for this problem in 15 years. To prove our main result, we consider the following generalization of the Minimum k -Edge Subgraph (M k -ES) problem, which we call Min-Cost ℓ-Edge-Profit Subgraph (MCℓ-EPS): Given a graph G = ( V , E ) with edge-profits p = { p e : e ∈ E } and node-costs c = { c v : v ∈ V }, and a lower profit bound ℓ, find a minimum node-cost subgraph of G of edge-profit at least ℓ. The M k -ES problem is a special case of MCℓ-EPS with unit node costs and unit edge profits. The currently best known ratio for M k -ES is n 3-2√2 + ϵ [Chlamtac et al. 2012]. We extend this ratio to MCℓ-EPS for general node costs and profits bounded by a polynomial in n , which may be of independent interest.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2734543612",
    "type": "article"
  },
  {
    "title": "Counting Thin Subgraphs via Packings Faster than Meet-in-the-Middle Time",
    "doi": "https://doi.org/10.1145/3125500",
    "publication_date": "2017-09-19",
    "publication_year": 2017,
    "authors": "Andreas Björklund; Petteri Kaski; Łukasz Kowalik",
    "corresponding_authors": "",
    "abstract": "Vassilevska and Williams (STOC’09) showed how to count simple paths on k vertices and matchings on k /2 edges in an n -vertex graph in time n k /2+ O (1) . In the same year, two different algorithms with the same runtime were given by Koutis and Williams (ICALP’09), and Björklund et al. (ESA’09), via n st /2+ O (1) -time algorithms for counting t -tuples of pairwise disjoint sets drawn from a given family of s -sized subsets of an n -element universe. Shortly afterwards, Alon and Gutner (TALG’10) showed that these problems have Ω( n ⌊ st /2⌋ ) and Ω( n ⌊ k /2⌋ ) lower bounds when counting by color coding. Here, we show that one can do better—we show that the “meet-in-the-middle” exponent st /2 can be beaten and give an algorithm that counts in time n 0.45470382 st + O (1) for t a multiple of three. This implies algorithms for counting occurrences of a fixed subgraph on k vertices and pathwidth p ≪ k in an n -vertex graph in n 0.45470382 k +2 p + O (1) time, improving on the three mentioned algorithms for paths and matchings, and circumventing the color-coding lower bound. We also give improved bounds for counting t -tuples of disjoint s -sets for s = 2,3,4. Our algorithms use fast matrix multiplication. We show an argument that this is necessary to go below the meet-in-the-middle barrier.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2963965405",
    "type": "article"
  },
  {
    "title": "Minimum Makespan Multi-Vehicle Dial-a-Ride",
    "doi": "https://doi.org/10.1145/2629653",
    "publication_date": "2015-01-13",
    "publication_year": 2015,
    "authors": "Inge Li Gørtz; Viswanath Nagarajan; R. Ravi",
    "corresponding_authors": "",
    "abstract": "Dial-a-Ride problems consist of a set V of n vertices in a metric space (denoting travel time between vertices) and a set of m objects represented as source-destination pairs {(s(i), t(i))}(i-1)(m), where each object requires to be moved from its source to destination vertex. In the multi-vehicle Dial-a-Ride problem, there are q vehicles, each having capacity k and where each vehicle j epsilon [q] has its own depot-vertex r(j) epsilon V. A feasible schedule consists of a capacitated route for each vehicle (where vehicle j originates and ends at its depot r(j)) that together move all objects from their sources to destinations. The objective is to find a feasible schedule that minimizes the maximum completion time (i.e., makespan) of vehicles, where the completion time of vehicle j is the time when it returns to its depot r(j) at the end of its route. We study the preemptive version of multi-vehicle Dial-a-Ride, in which an object may be left at intermediate vertices and transported by more than one vehicle, while being moved from source to destination. Our main results are an O(log(3) n)-approximation algorithm for preemptive multi-vehicle Dial-a-Ride, and an improved O(log t)-approximation for its special case when there is no capacity constraint (here t",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1561031615",
    "type": "article"
  },
  {
    "title": "Approximating Semi-matchings in Streaming and in Two-Party Communication",
    "doi": "https://doi.org/10.1145/2898960",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Christian Konrad; Adi Rosén",
    "corresponding_authors": "",
    "abstract": "We study the streaming complexity and communication complexity of approximating unweighted semi-matchings. A semi-matching in a bipartite graph G = ( A , B , E ) with n = | A | is a subset of edges S ⊆ E that matches all A vertices to B vertices with the goal usually being to do this as fairly as possible. While the term semi-matching was coined in 2003 by Harvey et al. [2003], the problem had already previously been studied in the scheduling literature under different names. We present a deterministic one-pass streaming algorithm that for any 0 ⩽ ϵ ⩽ 1 uses space Õ( n 1+ϵ and computes an O( n (1−ϵ)/2 )-approximation to the semi-matching problem. Furthermore, with O(log n ) passes it is possible to compute an O(log n )-approximation with space Õ( n ). In the one-way two-party communication setting, we show that for every ϵ &gt; 0, deterministic communication protocols for computing an O( n 1/(1+ϵ) c +1) -approximation require a message of size more than cn bits. We present two deterministic protocols communicating n and 2 n edges that compute an O√ n and an O(n 1/3 )-approximation, respectively. Finally, we improve on the results of Harvey et al. [2003] and prove new links between semi-matchings and matchings. While it was known that an optimal semi-matching contains a maximum matching, we show that there is a hierarchical decomposition of an optimal semi-matching into maximum matchings. A similar result holds for semi-matchings that do not admit length-two degree-minimizing paths.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1831744648",
    "type": "article"
  },
  {
    "title": "Space-Constrained Interval Selection",
    "doi": "https://doi.org/10.1145/2886102",
    "publication_date": "2016-09-02",
    "publication_year": 2016,
    "authors": "Yuval Emek; Magnús M. Halldórsson; Adi Rosén",
    "corresponding_authors": "",
    "abstract": "We study streaming algorithms for the interval selection problem: finding a maximum cardinality subset of disjoint intervals on the line. A deterministic 2-approximation streaming algorithm for this problem is developed, together with an algorithm for the special case of proper intervals, achieving improved approximation ratio of 3/2. We complement these upper bounds by proving that they are essentially the best possible in the streaming setting: It is shown that an approximation ratio of 2 − ϵ (or 3/2 − ϵ for proper intervals) cannot be achieved unless the space is linear in the input size. In passing, we also answer an open question of Adler and Azar (J. Scheduling 2003) regarding the space complexity of constant-competitive randomized preemptive online algorithms for the same problem.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1900356479",
    "type": "article"
  },
  {
    "title": "Fast Convergence for Consensus in Dynamic Networks",
    "doi": "https://doi.org/10.1145/2601072",
    "publication_date": "2014-05-01",
    "publication_year": 2014,
    "authors": "T-H. Hubert Chan; Ning Li",
    "corresponding_authors": "",
    "abstract": "In this article, we study the convergence time required to achieve consensus in dynamic networks. In each timestep, a node's value is updated to some weighted average of its neighbors and its old values. We study the case when the underlying network is dynamic and investigate different averaging models. Both our analysis and experiments show that dynamic networks exhibit fast convergence behavior, even under very mild connectivity assumptions.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W1973153469",
    "type": "article"
  },
  {
    "title": "Two-Dimensional Parameterized Matching",
    "doi": "https://doi.org/10.1145/2650220",
    "publication_date": "2014-10-30",
    "publication_year": 2014,
    "authors": "Richard Cole; Carmit Hazay; Moshe Lewenstein; Dekel Tsur",
    "corresponding_authors": "",
    "abstract": "Two equal-length strings, or two equal-sized two-dimensional texts, parameterize match ( p-match ) if there is a one-one mapping (relative to the alphabet) of their characters. Two-dimensional parameterized matching is the task of finding all m × m substrings of an n × n text that p-match an m × m pattern. This models searching for color images with changing of color maps, for example. We present two algorithms that solve the two-dimensional parameterized matching problem. The time complexities of our algorithms are O ( n 2 log 2 m ) and O ( n 2 + m 2.5 polylog( m )). Our algorithms are faster than the O ( n 2 m log 2 m log log m ) time algorithm for this problem of Amir et al. [2006]. A key step in both of our algorithms is to count the number of distinct characters in every m × m substring of an n × n string. We show how to solve this problem in O ( n 2 ) time. This result may be of independent interest.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2164090479",
    "type": "article"
  },
  {
    "title": "On the Expected Complexity of Voronoi Diagrams on Terrains",
    "doi": "https://doi.org/10.1145/2846099",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Anne Driemel; Sariel Har-Peled; Benjamin Raichel",
    "corresponding_authors": "",
    "abstract": "We investigate the combinatorial complexity of geodesic Voronoi diagrams on polyhedral terrains using a probabilistic analysis. Aronov et al. [2008] prove that, if one makes certain realistic input assumptions on the terrain, this complexity is Θ( n + m √ n ) in the worst case, where n denotes the number of triangles that define the terrain and m denotes the number of Voronoi sites. We prove that, under a relaxed set of assumptions, the Voronoi diagram has expected complexity O ( n + m ), given that the sites are sampled uniformly at random from the domain of the terrain (or the surface of the terrain). Furthermore, we present a construction of a terrain that implies a lower bound of Ω( nm 2/3 ) on the expected worst-case complexity if these assumptions on the terrain are dropped. As an additional result, we show that the expected fatness of a cell in a random planar Voronoi diagram is bounded by a constant.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2569453482",
    "type": "article"
  },
  {
    "title": "A Faster Algorithm for Finding Tarski Fixed Points",
    "doi": "https://doi.org/10.1145/3524044",
    "publication_date": "2022-03-17",
    "publication_year": 2022,
    "authors": "John Fearnley; Dömötör Pálvölgyi; Rahul Savani",
    "corresponding_authors": "",
    "abstract": "Dang et al. have given an algorithm that can find a Tarski fixed point in a k -dimensional lattice of width n using O (log k n ) queries [ 2 ]. Multiple authors have conjectured that this algorithm is optimal [ 2 , 7 ], and indeed this has been proven for two-dimensional instances [ 7 ]. We show that these conjectures are false in dimension three or higher by giving an O (log 2 n ) query algorithm for the three-dimensional Tarski problem. We also give a new decomposition theorem for k -dimensional Tarski problems which, in combination with our new algorithm for three dimensions, gives an O (log 2 ⌈k/3⌉ n ) query algorithm for the k -dimensional problem.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3092556900",
    "type": "article"
  },
  {
    "title": "Detecting Feedback Vertex Sets of Size <i>k</i> in <i>O</i> <sup>⋆</sup> (2.7 <i>k</i> ) Time",
    "doi": "https://doi.org/10.1145/3504027",
    "publication_date": "2022-02-14",
    "publication_year": 2022,
    "authors": "Jason Li; Jesper Nederlof",
    "corresponding_authors": "",
    "abstract": "In the Feedback Vertex Set (FVS) problem, one is given an undirected graph G and an integer k , and one needs to determine whether there exists a set of k vertices that intersects all cycles of G (a so-called feedback vertex set). Feedback Vertex Set is one of the most central problems in parameterized complexity: It served as an excellent testbed for many important algorithmic techniques in the field such as Iterative Compression [Guo et al. (JCSS’06)], Randomized Branching [Becker et al. (J. Artif. Intell. Res’00)] and Cut&amp;Count [Cygan et al. (FOCS’11)]. In particular, there has been a long race for the smallest dependence f(k) in run times of the type O ⋆ (f(k)) , where the O ⋆ notation omits factors polynomial in n . This race seemed to have reached a conclusion in 2011, when a randomized O ⋆ (3 k ) time algorithm based on Cut&amp;Count was introduced. In this work, we show the contrary and give a O ⋆ (2.7 k ) time randomized algorithm. Our algorithm combines all mentioned techniques with substantial new ideas: First, we show that, given a feedback vertex set of size k of bounded average degree, a tree decomposition of width (1-Ω (1))k can be found in polynomial time. Second, we give a randomized branching strategy inspired by the one from [Becker et al. (J. Artif. Intell. Res’00)] to reduce to the aforementioned bounded average degree setting. Third, we obtain significant run time improvements by employing fast matrix multiplication.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4212964627",
    "type": "article"
  },
  {
    "title": "Fully Dynamic (Δ +1)-Coloring in <i>O</i> (1) Update Time",
    "doi": "https://doi.org/10.1145/3494539",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Sayan Bhattacharya; Fabrizio Grandoni; Janardhan Kulkarni; Quanquan C. Liu; Shay Solomon",
    "corresponding_authors": "",
    "abstract": "The problem of (Δ +1)-vertex coloring a graph of maximum degree Δ has been extremely well studied over the years in various settings and models. Surprisingly, for the dynamic setting, almost nothing was known until recently. In SODA’18, Bhattacharya, Chakrabarty, Henzinger and Nanongkai devised a randomized algorithm for maintaining a (Δ +1)-coloring with O (log Δ) expected amortized update time. In this article, we present an improved randomized algorithm for (Δ +1)-coloring that achieves O (1) amortized update time and show that this bound holds not only in expectation but also with high probability. Our starting point is the state-of-the-art randomized algorithm for maintaining a maximal matching (Solomon, FOCS’16). We carefully build on the approach of Solomon, but, due to inherent differences between the maximal matching and (Δ +1)-coloring problems, we need to deviate significantly from it in several crucial and highly nontrivial points. 1",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W4214847522",
    "type": "article"
  },
  {
    "title": "Recognizing <i>k</i> -Leaf Powers in Polynomial Time, for Constant <i>k</i>",
    "doi": "https://doi.org/10.1145/3614094",
    "publication_date": "2023-08-08",
    "publication_year": 2023,
    "authors": "Manuel Lafond",
    "corresponding_authors": "Manuel Lafond",
    "abstract": "A graph G is a k -leaf power if there exists a tree T whose leaf set is V ( G ), and such that uv ∈ E ( G ) if and only if the distance between u and v in T is at most k (and u ≠ v ). The graph classes of k -leaf powers have several applications in computational biology, but recognizing them has remained a challenging algorithmic problem for the past two decades. The best known result is that 6-leaf powers can be recognized in polynomial time. In this article, we present an algorithm that decides whether a graph G is a k -leaf power in time O ( n f(k) for some function f that depends only on k (but has the growth rate of a power tower function). Our techniques are based on the fact that either a k -leaf power has a corresponding tree of low maximum degree, in which case finding it is easy, or every corresponding tree has large maximum degree. In the latter case, large-degree vertices in the tree imply that G has redundant substructures which can be pruned from the graph. In addition to solving a long-standing open problem, it is our hope that the structural results presented in this work can lead to further results on k -leaf powers and related classes.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3210535977",
    "type": "article"
  },
  {
    "title": "Entropy-based bounds for online algorithms",
    "doi": "https://doi.org/10.1145/1186810.1186817",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Gopal Pandurangan; Eli Upfal",
    "corresponding_authors": "",
    "abstract": "We focus in this work on an aspect of online computation that is not addressed by standard competitive analysis, namely, identifying request sequences for which nontrivial online algorithms are useful versus request sequences for which all algorithms perform equally poorly. The motivations for this work are advanced system and architecture designs which allow the operating system to dynamically allocate resources to online protocols such as prefetching and caching. To utilize these features, the operating system needs to identify data streams that can benefit from more resources. Our approach in this work is based on the relation between entropy, compression, and gambling, extensively studied in information theory. It has been shown that in some settings, entropy can either fully or at least partially characterize the expected outcome of an iterative gambling game. Our goal is to study the extent to which the entropy of the input characterizes the expected performance of online algorithms for problems that arise in computer applications. We study bounds based on entropy for three classical online problems---list accessing, prefetching, and caching. Our bounds relate the performance of the best online algorithm to the entropy , a parameter intrinsic to characteristics of the request sequence. This is in contrast to the competitive ratio parameter of competitive analysis, which quantifies the performance of the online algorithm with respect to an optimal offline algorithm. For the prefetching problem, we give explicit upper and lower bounds for the performance of the best prefetching algorithm in terms of the entropy of the request sequence. In contrast, we show that the entropy of the request sequence alone does not fully capture the performance of online list accessing and caching algorithms.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2073523085",
    "type": "article"
  },
  {
    "title": "Frugal path mechanisms",
    "doi": "https://doi.org/10.1145/1219944.1219948",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Aaron Archer; Éva Tardos",
    "corresponding_authors": "",
    "abstract": "We consider the problem of selecting a low-cost s - t path in a graph where the edge costs are a secret, known only to the various economic agents who own them. To solve this problem, Nisan and Ronen applied the celebrated Vickrey-Clarke-Groves (VCG) mechanism, which pays a premium to induce the edges so as to reveal their costs truthfully. We observe that this premium can be unacceptably high. There are simple instances where the mechanism pays Θ(n) times the actual cost of the path, even if there is an alternate path available that costs only (1 + ϵ) times as much. This inspires the frugal path problem, which is to design a mechanism that selects a path and induces truthful cost revelation, without paying such a high premium.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W4242166714",
    "type": "article"
  },
  {
    "title": "Testing Euclidean minimum spanning trees in the plane",
    "doi": "https://doi.org/10.1145/1367064.1367071",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Artur Czumaj; Christian Sohler",
    "corresponding_authors": "",
    "abstract": "Given a Euclidean graph G over a set P of n points in the plane, we are interested in verifying whether G is a Euclidean minimum spanning tree (EMST) of P or G differs from it in more than ϵ n edges. We assume that G is given in adjacency list representation and the point/vertex set P is given in an array. We present a property testing algorithm that accepts graph G if it is an EMST of P and that rejects with probability at least 2/3 if G differs from every EMST of P in more than ϵ, n edges. Our algorithm runs in O(√ n /ϵ ⋅ log 2 ( n /ϵ)) time and has a query complexity of O(√ n /ϵ ⋅ log ( n /ϵ)).",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1965045148",
    "type": "article"
  },
  {
    "title": "On hard instances of approximate vertex cover",
    "doi": "https://doi.org/10.1145/1435375.1435382",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Sundar Vishwanathan",
    "corresponding_authors": "Sundar Vishwanathan",
    "abstract": "We show that if there is a 2 - ϵ approximation algorithm for vertex cover on graphs with vector chromatic number at most 2 + δ, then there is a 2 - f (ϵ, δ) approximation algorithm for vertex cover for all graphs.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1996249628",
    "type": "article"
  },
  {
    "title": "Jitter regulation for multiple streams",
    "doi": "https://doi.org/10.1145/1644015.1644027",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "David Hay; Gabriel Scalosub",
    "corresponding_authors": "",
    "abstract": "For widely used interactive communication, it is essential that traffic is kept as smooth as possible; the smoothness of the traffic is typically captured by its delay jitter , that is, the difference between the maximal and minimal end-to-end delays. The task of minimizing the jitter is done by jitter regulators that use a limited-size buffer in order to shape the traffic. In many real-life situations regulators must handle multiple streams simultaneously and provide low jitter on each of them separately. Moreover, communication links have limited capacity, and these may pose further restrictions on the choices made by the regulator. This article investigates the problem of minimizing jitter in such an environment, using a fixed-size buffer. We show that the offline version of the problem can be solved in polynomial time, by introducing an efficient offline algorithm that finds a release schedule with optimal jitter. When regulating M streams in the online setting, we take a competitive analysis point of view and note that, in the upcapacitated case, previous results in Mansour and Patt-Shamir [2001] can be extended to an online algorithm that uses a buffer of size 2⋅ M ⋅ B and obtains the optimal jitter possible with a buffer of size B (and an offline algorithm). The question arises whether such a resource augmentation is essential. We answer this question in the affirmative, by proving a lower bound that is tight up to a factor of 2, thus showing that jitter regulation does not scale well as the number of streams increases unless the buffer is sized-up proportionally.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2101287718",
    "type": "article"
  },
  {
    "title": "Selection and Sorting in the “Restore” Model",
    "doi": "https://doi.org/10.1145/3168005",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Timothy M. Chan; J. Ian Munro; Venkatesh Raman",
    "corresponding_authors": "",
    "abstract": "We consider the classical selection and sorting problems in a model where the initial permutation of the input has to be restored after completing thecomputation. Such algorithms are useful for designing space-efficient algorithms, when one encounters subproblems that have to be solved by subroutines. It is important that these subroutines leave the array in its original state after they finish so that the computation can be properly resumed. Algorithms in this model can also be relevant for saving communication time, in case the data is distributed among several machines and would need to be copied to further machines for execution of the subroutine. Although the requirement of the restoration is stringent compared to the classicalversions of the problems, this model is more relaxed than a read-only memory where the input elements are not allowed to be moved within the input array. We first show that for a sequence of n integers, selection (finding the median or more generally the k -th smallest element for a given k ) can be done in O ( n ) time using O (lg n ) words 1 of extra space in this model. In contrast, no linear-time selection algorithm is known that uses polylogarithmic space in the read-only memory model. For sorting n integers in this model, we first present an O ( n lg n )-time algorithm using O (lg n ) words of extra space that outputs (in a write only tape) the given sequence in sorted order while restoring the order of the original input in the input tape. When the universe size U is polynomial in n , we give a faster O ( n )-time algorithm (analogous to radix sort) that uses O ( n ε ) words of extra space for an arbitrarily small constant ε &gt; 0. More generally, we show how to match the time bound of any word-RAM integer sorting algorithms using O ( n ε ) words of extra space. In sharp contrast, there is an Ω ( n 2 / S )-time lower bound for integer sorting using O ( S ) bits of space in the read-only memory model. Extension of our results to arbitrary input types beyond integers is not possible: for “indivisible” input elements, we can prove the same Ω ( n 2 / S ) lower bound for sorting in our model. We also describe space-efficient algorithms to count the number of inversions in a given sequence in this model. En route, we develop linear-time in-place algorithms to extract leading bits of the input array and to compress and decompress strings with low entropy; these techniques may be of independent interest.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2799530285",
    "type": "article"
  },
  {
    "title": "The Dependent Doors Problem",
    "doi": "https://doi.org/10.1145/3218819",
    "publication_date": "2018-08-21",
    "publication_year": 2018,
    "authors": "Amos Korman; Yoav Rodeh",
    "corresponding_authors": "",
    "abstract": "We introduce the dependent doors problem as an abstraction for situations in which one must perform a sequence of dependent decisions, without receiving feedback information on the effectiveness of previously made actions. Informally, the problem considers a set of d doors that are initially closed, and the aim is to open all of them as fast as possible. To open a door, the algorithm knocks on it, and it might open or not according to some probability distribution. This distribution may depend on which other doors are currently open, as well as on which other doors were open during each of the previous knocks on that door. The algorithm aims to minimize the expected time until all doors open. Crucially, it must act at any time without knowing whether or which other doors have already opened. In this work, we focus on scenarios where dependencies between doors are both positively correlated and acyclic. The fundamental distribution of a door describes the probability it opens in the best of conditions (with respect to other doors being open or closed). We show that if in two configurations of d doors corresponding doors share the same fundamental distribution, then these configurations have the same optimal running time up to a universal constant, no matter what the dependencies between doors and what the distributions. We also identify algorithms that are optimal up to a universal constant factor. For the case in which all doors share the same fundamental distribution, we additionally provide a simpler algorithm and a formula to calculate its running time. We furthermore analyse the price of lacking feedback for several configurations governed by standard fundamental distributions. In particular, we show that the price is logarithmic in d for memoryless doors but can potentially grow to be linear in d for other distributions. We then turn our attention to investigate precise bounds. Even for the case of two doors, identifying the optimal sequence is an intriguing combinatorial question. Here, we study the case of two cascading memoryless doors. That is, the first door opens on each knock independently with probability p 1 . The second door can only open if the first door is open, in which case it will open on each knock independently with probability p 2 . We solve this problem almost completely by identifying algorithms that are optimal up to an additive term of 1.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2888081897",
    "type": "article"
  },
  {
    "title": "An <i>O</i> (log <i>k</i> )-Competitive Algorithm for Generalized Caching",
    "doi": "https://doi.org/10.1145/3280826",
    "publication_date": "2018-11-16",
    "publication_year": 2018,
    "authors": "Anna Adamaszek; Artur Czumaj; Matthias Englert; Harald Räcke",
    "corresponding_authors": "",
    "abstract": "In the generalized caching problem, we have a set of pages and a cache of size k . Each page p has a size w p ≥ 1 and fetching cost c p for loading the page into the cache. At any point in time, the sum of the sizes of the pages stored in the cache cannot exceed k . The input consists of a sequence of page requests. If a page is not present in the cache at the time it is requested, it has to be loaded into the cache, incurring a cost of c p . We give a randomized O (log k )-competitive online algorithm for the generalized caching problem, improving the previous bound of O (log 2 k ) by Bansal, Buchbinder, and Naor (STOC’08). This improved bound is tight and of the same order as the known bounds for the classic paging problem with uniform weights and sizes. We use the same LP-based techniques as Bansal et al. but provide improved and slightly simplified methods for rounding fractional solutions online.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2900830292",
    "type": "article"
  },
  {
    "title": "Faster Approximation Schemes for the Two-Dimensional Knapsack Problem",
    "doi": "https://doi.org/10.1145/3338512",
    "publication_date": "2019-08-08",
    "publication_year": 2019,
    "authors": "Sandy Heydrich; Andreas Wiese",
    "corresponding_authors": "",
    "abstract": "For geometric optimization problems we often understand the computational complexity on a rough scale, but not very well on a finer scale. One example is the two-dimensional knapsack problem for squares. There is a polynomial time (1+ε)-approximation algorithm for it (i.e., a PTAS) but the running time of this algorithm is triple exponential in 1/ε, i.e., Ω ( n 2 2 1/ε ). A double or triple exponential dependence on 1/ε is inherent in how this and other algorithms for other geometric problems work. In this article, we present an efficient PTAS (EPTAS) for knapsack for squares, i.e., a (1+ε)-approximation algorithm with a running time of O ε (1)⋅ n O (1) . In particular, the exponent of n in the running time does not depend on ε at all! Since there can be no fully polynomial time approximation scheme (FPTAS) for the problem (unless P = NP), this is the best kind of approximation scheme we can hope for. To achieve this improvement, we introduce two new key ideas: We present a fast method to guess the Ω (2 2 1/ε ) relatively large squares of a suitable near-optimal packing instead of using brute-force enumeration. Secondly, we introduce an indirect guessing framework to define sizes of cells for the remaining squares. In the previous PTAS, each of these steps needs a running time of Ω ( n 2 2 1/ε ) and we improve both to O ε (1)⋅ n O (1) . We complete our result by giving an algorithm for two-dimensional knapsack for rectangles under (1+ε)-resource augmentation. We improve the previous double-exponential PTAS to an EPTAS and compute even a solution with optimal weight, while the previous PTAS computes only an approximation.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2968986948",
    "type": "article"
  },
  {
    "title": "Improving TSP Tours Using Dynamic Programming over Tree Decompositions",
    "doi": "https://doi.org/10.1145/3341730",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "Marek Cygan; Łukasz Kowalik; Arkadiusz Socała",
    "corresponding_authors": "",
    "abstract": "Given a traveling salesman problem (TSP) tour H in graph G , a k -move is an operation that removes k edges from H and adds k edges of G so that a new tour H ′ is formed. The popular k -OPT heuristic for TSP finds a local optimum by starting from an arbitrary tour H and then improving it by a sequence of k -moves. Until 2016, the only known algorithm to find an improving k -move for a given tour was the naive solution in time O ( n k ). At ICALP’16, de Berg, Buchin, Jansen, and Woeginger showed an O ( n ⌊2 k /3⌋+1 )-time algorithm. We show an algorithm that runs in O ( n (1/4+ϵ k ) k ) time, where lim k → ∞ ϵ k = 0. It improves over the state of the art for every k ≥ 5. For the most practically relevant case k = 5, we provide a slightly refined algorithm running in O ( n 3.4 ) time. We also show that for the k = 4 case, improving over the O ( n 3 )-time algorithm of de Berg et al. would be a major breakthrough: An O ( n 3−ϵ )-time algorithm for any ϵ &gt; 0 would imply an O ( n 3−δ )-time algorithm for the A ll P airs S hortest P aths problem, for some δ &gt; 0.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2980171939",
    "type": "article"
  },
  {
    "title": "Scheduling When You Do Not Know the Number of Machines",
    "doi": "https://doi.org/10.1145/3340320",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Clifford Stein; Mingxian Zhong",
    "corresponding_authors": "",
    "abstract": "Often in a scheduling problem, there is uncertainty about the jobs to be processed. The issue of uncertainty regarding the machines has been much less studied. In this article, we study a scheduling environment in which jobs first need to be grouped into some sets before the number of machines is known, and then the sets need to be scheduled on machines without being separated. To evaluate algorithms in such an environment, we introduce the idea of an α-robust algorithm, one that is guaranteed to return a schedule on any number m of machines that is within an α factor of the optimal schedule on m machine, where the optimum is not subject to the restriction that the sets cannot be separated. Under such environment, we give a (5\\3+ϵ)-robust algorithm for scheduling on parallel machines to minimize makespan and show a lower bound 4\\3. For the special case when the jobs are infinitesimal, we give a 1.233-robust algorithm with an asymptotic lower bound of 1.207. We also study a case of fair allocation, where the objective is to minimize the difference between the maximum and minimum machine load.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2988836825",
    "type": "article"
  },
  {
    "title": "Random Walks on Small World Networks",
    "doi": "https://doi.org/10.1145/3382208",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Martin Dyer; Andreas Galanis; Leslie Ann Goldberg; Mark Jerrum; Eric Vigoda",
    "corresponding_authors": "",
    "abstract": "We study the mixing time of random walks on small-world networks modelled as follows: starting with the 2-dimensional periodic grid, each pair of vertices {u,v} with distance d&gt; 1 is added as a “long-range” edge with probability proportional to d -r , where r≥ 0 is a parameter of the model. Kleinberg [33{ studied a close variant of this network model and proved that the (decentralised) routing time is O((log n ) 2 ) when r =2 and n Ω (1) when r≠ 2. Here, we prove that the random walk also undergoes a phase transition at r=2 , but in this case, the phase transition is of a different form. We establish that the mixing time is ϴ (log n) for r&lt; 2, O((log n ) 4 ) for r =2, and n Ω (1) for r&gt; 2.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3033587075",
    "type": "article"
  },
  {
    "title": "Polynomial Kernels and Wideness Properties of Nowhere Dense Graph Classes",
    "doi": "https://doi.org/10.1145/3274652",
    "publication_date": "2018-11-16",
    "publication_year": 2018,
    "authors": "Stephan Kreutzer; Roman Rabinovich; Sebastian Siebertz",
    "corresponding_authors": "",
    "abstract": "Nowhere dense classes of graphs [21, 22] are very general classes of uniformly sparse graphs with several seemingly unrelated characterisations. From an algorithmic perspective, a characterisation of these classes in terms of uniform quasi-wideness , a concept originating in finite model theory, has proved to be particularly useful. Uniform quasi-wideness is used in many fpt-algorithms on nowhere dense classes. However, the existing constructions showing the equivalence of nowhere denseness and uniform quasi-wideness imply a non-elementary blow up in the parameter dependence of the fpt-algorithms, making them infeasible in practice. As a first main result of this article, we use tools from logic, in particular from a sub-field of model theory known as stability theory, to establish polynomial bounds for the equivalence of nowhere denseness and uniform quasi-wideness. A powerful method in parameterized complexity theory is to compute a problem kernel in a pre-computation step, that is, to reduce the input instance in polynomial time to a sub-instance of size bounded in the parameter only (independently of the input graph size). Our new tools allow us to obtain for every fixed radius r ∈ N a polynomial kernel for the distance- r dominating set problem on nowhere dense classes of graphs. This result is particularly interesting, as it implies that for every class C of graphs that is closed under taking subgraphs, the distance- r dominating set problem admits a kernel on C for every value of r if, and only if, it already admits a polynomial kernel for every value of r (under the standard assumption of parameterized complexity theory that FPT ≠ W[2]).",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3160089363",
    "type": "article"
  },
  {
    "title": "Approximate Counting of <i>k</i> -Paths: Simpler, Deterministic, and in Polynomial Space",
    "doi": "https://doi.org/10.1145/3461477",
    "publication_date": "2021-07-15",
    "publication_year": 2021,
    "authors": "Daniel Lokshtanov; Andreas Björklund; Saket Saurabh; Meirav Zehavi",
    "corresponding_authors": "",
    "abstract": "Recently, Brand et al. [STOC 2018] gave a randomized mathcal O(4 k m ε -2 -time exponential-space algorithm to approximately compute the number of paths on k vertices in a graph G up to a multiplicative error of 1 ± ε based on exterior algebra. Prior to our work, this has been the state-of-the-art. In this article, we revisit the algorithm by Alon and Gutner [IWPEC 2009, TALG 2010], and obtain the following results: • We present a deterministic 4 k + O (√ k (log k +log 2 ε -1 )) m -time polynomial-space algorithm. This matches the running time of the best known deterministic polynomial-space algorithm for deciding whether a given graph G has a path on k vertices. • Additionally, we present a randomized 4 k +mathcal O(log k (log k +logε -1 )) m -time polynomial-space algorithm. Our algorithm is simple—we only make elementary use of the probabilistic method. Here, n and m are the number of vertices and the number of edges, respectively. Additionally, our approach extends to approximate counting of other patterns of small size (such as q -dimensional p -matchings).",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3183157744",
    "type": "article"
  },
  {
    "title": "Discrete Fréchet Distance under Translation",
    "doi": "https://doi.org/10.1145/3460656",
    "publication_date": "2021-07-15",
    "publication_year": 2021,
    "authors": "Karl Bringmann; Marvin Künnemann; André Nusser",
    "corresponding_authors": "",
    "abstract": "The discrete Fréchet distance is a popular measure for comparing polygonal curves. An important variant is the discrete Fréchet distance under translation, which enables detection of similar movement patterns in different spatial domains. For polygonal curves of length n in the plane, the fastest known algorithm runs in time Õ( n 5 ) [12]. This is achieved by constructing an arrangement of disks of size Õ( n 4 ), and then traversing its faces while updating reachability in a directed grid graph of size N := Õ( n 5 ), which can be done in time Õ(√ N ) per update [27]. The contribution of this article is two-fold. First, although it is an open problem to solve dynamic reachability in directed grid graphs faster than Õ(√ N ), we improve this part of the algorithm: We observe that an offline variant of dynamic s - t -reachability in directed grid graphs suffices, and we solve this variant in amortized time Õ( N 1/3 ) per update, resulting in an improved running time of Õ( N 4.66 ) for the discrete Fréchet distance under translation. Second, we provide evidence that constructing the arrangement of size Õ( N 4 ) is necessary in the worst case by proving a conditional lower bound of n 4 - o(1) on the running time for the discrete Fréchet distance under translation, assuming the Strong Exponential Time Hypothesis.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3184650363",
    "type": "article"
  },
  {
    "title": "The Quest for Strong Inapproximability Results with Perfect Completeness",
    "doi": "https://doi.org/10.1145/3459668",
    "publication_date": "2021-07-15",
    "publication_year": 2021,
    "authors": "Joshua Brakensiek; Venkatesan Guruswami",
    "corresponding_authors": "",
    "abstract": "The Unique Games Conjecture has pinned down the approximability of all constraint satisfaction problems (CSPs), showing that a natural semidefinite programming relaxation offers the optimal worst-case approximation ratio for any CSP. This elegant picture, however, does not apply for CSP instances that are perfectly satisfiable, due to the imperfect completeness inherent in the Unique Games Conjecture. This work is motivated by the pursuit of a better understanding of the approximability of perfectly satisfiable instances of CSPs. We prove that an “almost Unique” version of Label Cover can be approximated within a constant factor on satisfiable instances. Our main conceptual contribution is the formulation of a (hypergraph) version of Label Cover that we call V Label Cover . Assuming a conjecture concerning the inapproximability of V Label Cover on perfectly satisfiable instances, we prove the following implications: • There is an absolute constant c 0 such that for k ≥ 3, given a satisfiable instance of Boolean k -CSP, it is hard to find an assignment satisfying more than c 0 k 2 /2 k fraction of the constraints. • Given a k -uniform hypergraph, k ≥ 2, for all ε &gt; 0, it is hard to tell if it is q -strongly colorable or has no independent set with an ε fraction of vertices, where q =⌈ k +√ k -1/2⌉. • Given a k -uniform hypergraph, k ≥ 3, for all ε &gt; 0, it is hard to tell if it is ( k -1)-rainbow colorable or has no independent set with an ε fraction of vertices.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3185022466",
    "type": "article"
  },
  {
    "title": "Zip Trees",
    "doi": "https://doi.org/10.1145/3476830",
    "publication_date": "2021-10-04",
    "publication_year": 2021,
    "authors": "Robert E. Tarjan; Caleb Levy; Stephen Timmel",
    "corresponding_authors": "",
    "abstract": "We introduce the zip tree, a form of randomized binary search tree that integrates previous ideas into one practical, performant, and pleasant-to-implement package. A zip tree is a binary search tree in which each node has a numeric rank and the tree is (max)-heap-ordered with respect to ranks, with rank ties broken in favor of smaller keys. Zip trees are essentially treaps (Seidel and Aragon 1996), except that ranks are drawn from a geometric distribution instead of a uniform distribution, and we allow rank ties. These changes enable us to use fewer random bits per node. We perform insertions and deletions by unmerging and merging paths (\"unzipping\" and \"zipping\") rather than by doing rotations, which avoids some pointer changes and improves efficiency. The methods of zipping and unzipping take inspiration from previous top-down approaches to insertion and deletion (Stephenson 1980; Mart\\'inez and Roura 1998; Sprugnoli 1980). From a theoretical standpoint, this work provides two main results. First, zip trees require only $O(\\log \\log n)$ bits (with high probability) to represent the largest rank in an $n$-node binary search tree; previous data structures require $O(\\log n)$ bits for the largest rank. Second, zip trees are naturally isomorphic to skip lists (Pugh 1990), and simplify the mapping of (Dean and Jones 2007) between skip lists and binary search trees.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W3204759753",
    "type": "article"
  },
  {
    "title": "Prize-collecting steiner network problems",
    "doi": "https://doi.org/10.1145/2390176.2390178",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "MohammadTaghi Hajiaghayi; Rohit Khandekar; Guy Kortsarz; Zeev Nutov",
    "corresponding_authors": "",
    "abstract": "In the Steiner Network problem, we are given a graph G with edge-costs and connectivity requirements r uv between node pairs u,v . The goal is to find a minimum-cost subgraph H of G that contains r uv edge-disjoint paths for all u,v ∈ V . In Prize-Collecting Steiner Network problems, we do not need to satisfy all requirements, but are given a penalty function for violating the connectivity requirements, and the goal is to find a subgraph H that minimizes the cost plus the penalty. The case when r uv ∈ {0,1} is the classic Prize-Collecting Steiner Forest problem. In this article, we present a novel linear programming relaxation for the Prize-Collecting Steiner Network problem, and by rounding it, obtain the first constant-factor approximation algorithm for submodular and monotone nondecreasing penalty functions. In particular, our setting includes all-or-nothing penalty functions, which charge the penalty even if the connectivity requirement is slightly violated; this resolves an open question posed by Nagarajan et al. [2008]. We further generalize our results for element-connectivity and node-connectivity.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2083716230",
    "type": "article"
  },
  {
    "title": "Finding witnesses by peeling",
    "doi": "https://doi.org/10.1145/1921659.1921670",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Yonatan Aumann; Moshe Lewenstein; Noa Lewenstein; Dekel Tsur",
    "corresponding_authors": "",
    "abstract": "In the k -matches problem, we are given a pattern and a text, and for each text location, the desired output consists of all aligned matching characters if there are k or fewer of them, and any k aligned matching characters if there are more than k of them. This problem is one of several string matching problems that seek not only to find where the pattern matches the text under different “match” definitions, but also to provide witnesses to the match. Other such problems include k -aligned ones, k -witnesses, and k -mismatches. In addition, the solutions to several other string matching problems rely on the efficient solutions of the witness finding problems. In this article we provide a general method for solving such witness finding problems efficiently. We do so by casting the problem as a generalization of group testing, which we then solve by a process we call peeling . Using this general framework we obtain improved results for all of the problems mentioned. We also show that our method also solves a couple of problems outside the pattern matching domain.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2085888776",
    "type": "article"
  },
  {
    "title": "Algorithms and complexity for periodic real-time scheduling",
    "doi": "https://doi.org/10.1145/2390176.2390182",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "Vincenzo Bonifaci; Ho-Leung Chan; Alberto Marchetti-Spaccamela; Nicole Megow",
    "corresponding_authors": "",
    "abstract": "We investigate the preemptive scheduling of periodic tasks with hard deadlines. We show that, even in the uniprocessor case, no pseudopolynomial-time algorithm can test the feasibility of a task system within a constant speedup bound, unless P = NP. This result contrasts with recent results for sporadic task systems. For two special cases, synchronous task systems and systems with a constant number of different task types, we provide the first polynomial-time constant-speedup feasibility tests for multiprocessor platforms. Furthermore, we show that the problem of testing feasibility is coNP-hard for synchronous multiprocessor task systems. The complexity of some of these problems has been open for a long time. We also propose a weight maximization variant of the feasibility problem, where every task has a nonnegative weight, and the goal is to find a subset of tasks that can be scheduled feasibly and has maximum weight. We give the first constant-speed, constant-approximation algorithm for the case of synchronous task systems, together with related hardness results.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2124435847",
    "type": "article"
  },
  {
    "title": "Cost-Oblivious Storage Reallocation",
    "doi": "https://doi.org/10.1145/3070693",
    "publication_date": "2017-05-26",
    "publication_year": 2017,
    "authors": "Michael A. Bender; Martı́n Farach-Colton; Sándor P. Fekete; Jeremy T. Fineman; Seth Gilbert",
    "corresponding_authors": "",
    "abstract": "Databases allocate and free blocks of storage on disk. Freed blocks introduce holes where no data is stored. Allocation systems attempt to reuse such deallocated regions in order to minimize the footprint on disk. When previously allocated blocks cannot be moved, this problem is called the memory allocation problem. The competitive ratio for this problem has matching upper and lower bounds that are logarithmic in the number of requests and in the ratio of the largest to smallest requests. This article defines the storage reallocation problem, where previously allocated blocks can be moved, or reallocated , but at some cost. This cost is determined by the allocation/reallocation cost function . The objective is to minimize the storage footprint, that is, the largest memory address containing an allocated object, while simultaneously minimizing the reallocation costs. This article gives asymptotically optimal algorithms for storage reallocation, in which the storage footprint is at most (1+ ϵ) times optimal, and the reallocation cost is O ((1/ϵ)log (1/ϵ)) times the original allocation cost, that is, it is within a constant factor of optimal when ϵ is a constant. The algorithms are cost oblivious , which means they achieve these bounds with no knowledge of the allocation/reallocation cost function, as long as the cost function is subadditive.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2616949295",
    "type": "article"
  },
  {
    "title": "Anarchy Is Free in Network Creation",
    "doi": "https://doi.org/10.1145/2729978",
    "publication_date": "2016-02-12",
    "publication_year": 2016,
    "authors": "Ronald Graham; Linus Hamilton; Ariel Levavi; Po‐Shen Loh",
    "corresponding_authors": "",
    "abstract": "The Internet has emerged as perhaps the most important network in modern computing, but rather miraculously, it was created through the individual actions of a multitude of agents rather than by a central planning authority. This motivates the game-theoretic study of network formation, and our article considers one of the most well-studied models, originally proposed by Fabrikant et al. In the model, each of n agents corresponds to a vertex, which can create edges to other vertices at a cost of α each, for some parameter α. Every edge can be freely used by every vertex, regardless of who paid the creation cost. To reflect the desire to be close to other vertices, each agent’s cost function is further augmented by the sum total of all (graph-theoretic) distances to all other vertices. Previous research proved that for many regimes of the (α, n ) parameter space, the total social cost (sum of all agents’ costs) of every Nash equilibrium is bounded by at most a constant multiple of the optimal social cost. In algorithmic game-theoretic nomenclature, this approximation ratio is called the price of anarchy. In our article, we significantly sharpen some of those results, proving that for all constant nonintegral α &gt; 2, the price of anarchy is in fact 1 + o (1); that is, not only is it bounded by a constant, but also it tends to 1 as n → ∞. For constant integral α ⩾ 2, we show that the price of anarchy is bounded away from 1. We provide quantitative estimates on the rates of convergence for both results.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1703835995",
    "type": "article"
  },
  {
    "title": "Families with Infants",
    "doi": "https://doi.org/10.1145/2847419",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "Alexander Golovnev; Alexander S. Kulikov; Ivan Mihajlin",
    "corresponding_authors": "",
    "abstract": "Assume that a group of n people is going to an excursion and our task is to seat them into buses with several constraints each saying that a pair of people does not want to see each other in the same bus. This is a well-known graph coloring problem (with n being the number of vertices) and it can be solved in O *(2 n ) time by the inclusion-exclusion principle as shown by Björklund, Husfeldt, and Koivisto in 2009. Another approach to solve this problem in O *(2 n ) time is to use the Fast Fourier Transform (FFT). For this, given a graph G one constructs a polynomial P G ( x ) of degree O *(2 n ) with the following property: G is k -colorable if and only if the coefficient of x m (for some particular value of m ) in the k -th power of P ( x ) is nonzero. Then, it remains to compute this coefficient using FFT. Assume now that we have additional constraints: the group of people contains several infants and these infants should be accompanied by their relatives in a bus. We show that if the number of infants is linear, then the problem can be solved in O *((2 − ε) n ) time, where ε is a positive constant independent of n . We use this approach to improve known bounds for several NP-hard problems (the traveling salesman problem, the graph coloring problem, the problem of counting perfect matchings) on graphs of bounded average degree, as well as to simplify the proofs of several known results.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1747610753",
    "type": "article"
  },
  {
    "title": "Approximation Algorithms for Movement Repairmen",
    "doi": "https://doi.org/10.1145/2908737",
    "publication_date": "2016-08-03",
    "publication_year": 2016,
    "authors": "Mohammad Taghi Hajiaghayi; Rohit Khandekar; Mohammad Reza Khani; Guy Kortsarz",
    "corresponding_authors": "",
    "abstract": "In the Movement Repairmen (MR) problem, we are given a metric space ( V , d ) along with a set R of k repairmen r 1 , r 2 , …, r k with their start depots s 1 , s 2 , …, s k ∈ V and speeds v 1 , v 2 , …, v k ⩾ 0, respectively, and a set C of m clients c 1 , c 2 , …, c m having start locations s ′ 1 , s ′ 2 , …, s ′ m ∈ V and speeds v ′ 1 , v ′ 2 , …, v ′ m ⩾ 0, respectively. If t is the earliest time a client c j is collocated with any repairman (say, r i ) at a node u , we say that the client is served by r i at u and that its latency is t . The objective in the (S um -MR) problem is to plan the movements for all repairmen and clients to minimize the sum (average) of the clients’ latencies. The motivation for this problem comes, for example, from Amazon Locker Delivery [Amazon 2010] and USPS gopost [Service 2010]. We give the first O (log n )-approximation algorithm for the S um -MR problem. In order to approximate S um -MR, we formulate an LP for the problem and bound its integrality gap. Our LP has exponentially many variables; therefore, we need a separation oracle for the dual LP. This separation oracle is an instance of the Neighborhood Prize Collecting Steiner Tree (NPCST) problem in which we want to find a tree with weight at most L collecting the maximum profit from the clients by visiting at least one node from their neighborhoods. The NPCST problem, even with the possibility to violate both the tree weight and neighborhood radii, is still very hard to approximate. We deal with this difficulty by using LP with geometrically increasing segments of the timeline, and by giving a tricriteria approximation for the problem. The rounding needs a relatively involved analysis. We give a constant approximation algorithm for S um -MR in Euclidean Space where the speed of the clients differs by a constant factor. We also give a constant approximation for the makespan variant.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1809214845",
    "type": "article"
  },
  {
    "title": "Editorial to the Special Issue on SODA'12",
    "doi": "https://doi.org/10.1145/2846001",
    "publication_date": "2016-02-08",
    "publication_year": 2016,
    "authors": "Yuval Rabani; Andréa W. Richa; Jared Saia; David P. Woodruff",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2320187540",
    "type": "article"
  },
  {
    "title": "Melding priority queues",
    "doi": "https://doi.org/10.1145/1198513.1198517",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Ran Mendelson; Robert E. Tarjan; Mikkel Thorup; Uri Zwick",
    "corresponding_authors": "",
    "abstract": "We show that any priority queue data structure that supports insert , delete , and find-min operations in pq ( n ) amortized time, where n is an upper bound on the number of elements in the priority queue, can be converted into a priority queue data structure that also supports fast meld operations with essentially no increase in the amortized cost of the other operations. More specifically, the new data structure supports insert , meld and find-min operations in O (1) amortized time, and delete operations in O ( pq ( n ) + α( n )) amortized time, where α( n ) is a functional inverse of the Ackermann function, and where n this time is the total number of operations performed on all the priority queues. The construction is very simple. The meldable priority queues are obtained by placing a nonmeldable priority queues at each node of a union-find data structure. We also show that when all keys are integers in the range [1, N ], we can replace n in the bound stated previously by min{ n , N }.Applying this result to the nonmeldable priority queue data structures obtained recently by Thorup [2002b] and by Han and Thorup [2002] we obtain meldable RAM priority queues with O (log log n ) amortized time per operation, or O (√log log n ) expected amortized time per operation, respectively. As a by-product, we obtain improved algorithms for the minimum directed spanning tree problem on graphs with integer edge weights, namely, a deterministic O ( m log log n )-time algorithm and a randomized O ( m √log log n )-time algorithm. For sparse enough graphs, these bounds improve on the O ( m + n log n ) running time of an algorithm by Gabow et al. [1986] that works for arbitrary edge weights.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2018895114",
    "type": "article"
  },
  {
    "title": "Minimizing total completion time on uniform machines with deadline constraints",
    "doi": "https://doi.org/10.1145/1125994.1126000",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Teofilo F. Gonzalez; Joseph Y.‐T. Leung; Michael Pinedo",
    "corresponding_authors": "",
    "abstract": "Consider n independent jobs and m uniform machines in parallel. Each job has a processing requirement and a deadline. All jobs are available for processing at time t = 0. Job j must complete its processing before or at its deadline and preemptions are allowed. A set of jobs is said to be feasible if there exists a schedule that meets all the deadlines. We present a polynomial-time algorithm that given a feasible set of jobs, constructs a schedule that minimizes the total completion time Σ C j . In the classical α | β | γ scheduling notation, this problem is referred to as Qm | prmt , d¯ j | Σ C j . It is well known that a generalization of this problem with regard to its machine environment results in an NP-hard problem.",
    "cited_by_count": 7,
    "openalex_id": "https://openalex.org/W2077533566",
    "type": "article"
  },
  {
    "title": "Querying priced information in databases",
    "doi": "https://doi.org/10.1145/1186810.1186819",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Renato Carmo; Tomás Feder; Yoshiharu Kohayakawa; Eduardo Sany Laber; Rajeev Motwani; Liadan O'Callaghan; Rina Panigrahy‎; Dilys Thomas",
    "corresponding_authors": "",
    "abstract": "Query optimization that involves expensive predicates has received considerable attention in the database community. Typically, the output to a database query is a set of tuples that satisfy certain conditions, and, with expensive predicates, these conditions may be computationally costly to verify. In the simplest case, when the query looks for the set of tuples that simultaneously satisfy k expensive predicates, the problem reduces to ordering the evaluation of the predicates so as to minimize the time to output the set of tuples comprising the answer to the query. We study different cases of the problem: the sequential case , in which a single processor is available to evaluate the predicates, and the distributed case , in which there are k processors available, each dedicated to a different attribute (column) of the database, and there is no communication cost between the processors. For the sequential case, we give a simple and fast deterministic k -approximation algorithm, and prove that k is the best possible approximation ratio for a deterministic algorithm, even if exponential time algorithms are allowed. We also propose a randomized, polynomial time algorithm with expected approximation ratio 1 + √2/2 ≈ 1.707 for k = 2, and prove that 3/2 is the best possible expected approximation ratio for randomized algorithms. We also show that given 0 ≤ ε ≤ 1, no randomized algorithm achieves approximation ratio smaller than 1 + ε with probability larger than (1 + ε)/2. For the distributed case, we consider two different models: the preemptive model , in which a processor is allowed to interrupt the evaluation of a predicate, and the nonpreemptive model , in which the evaluation of a predicate must be completed once started. We show that k is the best possible approximation ratio for a deterministic algorithm, even if exponential time algorithms are allowed. For the preemptive model, we introduce a polynomial time k -approximation algorithm. For the nonpreemptive model, we introduce a polynomial time O ( k log 2 k )-approximation algorithm.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W1990245857",
    "type": "article"
  },
  {
    "title": "An algorithm for deciding zero equivalence of nested polynomially recurrent sequences",
    "doi": "https://doi.org/10.1145/1240233.1240241",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Manuel Kauers",
    "corresponding_authors": "Manuel Kauers",
    "abstract": "We introduce the class of nested polynomially recurrent sequences which includes a large number of sequences that are of combinatorial interest. We present an algorithm for deciding zero equivalence of these sequences, thereby providing a new algorithm for proving identities among combinatorial sequences: In order to prove an identity, decide by the algorithm whether the difference of lefthand-side and righthand-side is identically zero. This algorithm is able to treat mathematical objects which are not covered by any other known symbolic method for proving combinatorial identities. Despite its theoretical flavor and high complexity, an implementation of the algorithm can be successfully applied to nontrivial examples.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2065374506",
    "type": "article"
  },
  {
    "title": "Computing rank-convolutions with a mask",
    "doi": "https://doi.org/10.1145/1644015.1644035",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "László Babai; Pedro F. Felzenszwalb",
    "corresponding_authors": "",
    "abstract": "Rank-convolutions have important applications in a variety of areas such as signal processing and computer vision. We define a mask as a function taking only values zero and infinity. Rank-convolutions with masks are of special interest to image processing. We show how to compute the rank- k convolution of a function over an interval of length n with an arbitrary mask of length m in O ( n √ m log m ) time. The result generalizes to the d -dimensional case. Previously no algorithm performing significantly better than the brute-force O ( nm ) bound was known. Our algorithm seems to perform well in practice. We describe an implementation, illustrating its application to a problem in image processing. Already on relatively small images, our experiments show a signficant speedup compared to brute force.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2057286960",
    "type": "article"
  },
  {
    "title": "A Mazing 2+ε Approximation for Unsplittable Flow on a Path",
    "doi": "https://doi.org/10.1145/3242769",
    "publication_date": "2018-09-17",
    "publication_year": 2018,
    "authors": "Aris Anagnostopoulos; Fabrizio Grandoni; Stefano Leonardi; Andreas Wiese",
    "corresponding_authors": "",
    "abstract": "We study the problem of unsplittable flow on a path (UFP), which arises naturally in many applications such as bandwidth allocation, job scheduling, and caching. Here we are given a path with nonnegative edge capacities and a set of tasks, which are characterized by a subpath, a demand, and a profit. The goal is to find the most profitable subset of tasks whose total demand does not violate the edge capacities. Not surprisingly, this problem has received a lot of attention in the research community. If the demand of each task is at most a small-enough fraction δ of the capacity along its subpath (δ- small tasks ), then it has been known for a long time [Chekuri et al., ICALP 2003] how to compute a solution of value arbitrarily close to the optimum via LP rounding. However, much remains unknown for the complementary case, that is, when the demand of each task is at least some fraction δ &gt; 0 of the smallest capacity of its subpath (δ- large tasks ). For this setting, a constant factor approximation is known, improving on an earlier logarithmic approximation [Bonsma et al., FOCS 2011]. In this article, we present a polynomial-time approximation scheme (PTAS) for δ-large tasks, for any constant δ &gt; 0. Key to this result is a complex geometrically inspired dynamic program. Each task is represented as a segment underneath the capacity curve, and we identify a proper maze-like structure so that each corridor of the maze is crossed by only O (1) tasks in the optimal solution. The maze has a tree topology, which guides our dynamic program. Our result implies a 2+ε approximation for UFP, for any constant ε &gt; 0, improving on the previously best 7+ε approximation by Bonsma et al. We remark that our improved approximation algorithm matches the best known approximation ratio for the considerably easier special case of uniform edge capacities.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2891839364",
    "type": "article"
  },
  {
    "title": "Entropy and Optimal Compression of Some General Plane Trees",
    "doi": "https://doi.org/10.1145/3275444",
    "publication_date": "2018-10-01",
    "publication_year": 2018,
    "authors": "Zbigniew Gołębiewski; Abram Magner; Wojciech Szpankowski",
    "corresponding_authors": "",
    "abstract": "We continue developing the information theory of structured data. In this article, we study models generating d -ary trees ( d ≥ 2) and trees with unrestricted degree. We first compute the entropy which gives us the fundamental lower bound on compression of such trees. Then we present efficient compression algorithms based on arithmetic encoding that achieve the entropy within a constant number of bits. A naïve implementation of these algorithms has a prohibitive time complexity of O ( n d ) elementary arithmetic operations (each corresponding to a number f ( n , d ) of bit operations), but our efficient algorithms run in O ( n 2 ) of these operations, where n is the number of nodes. It turns out that extending source coding (i.e., compression) from sequences to advanced data structures such as degree-unconstrained trees is mathematically quite challenging and leads to recurrences that find ample applications in the information theory of general structures (e.g., to analyze the information content of degree-unconstrained non-plane trees).",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2895506925",
    "type": "article"
  },
  {
    "title": "A (2+ϵ)-Approximation for Maximum Weight Matching in the Semi-streaming Model",
    "doi": "https://doi.org/10.1145/3274668",
    "publication_date": "2018-12-07",
    "publication_year": 2018,
    "authors": "Ami Paz; Gregory Schwartzman",
    "corresponding_authors": "",
    "abstract": "We present a simple deterministic single-pass (2+ϵ)-approximation algorithm for the maximum weight matching problem in the semi-streaming model. This improves on the currently best known approximation ratio of (4+ϵ). Our algorithm uses O ( n log 2 n ) bits of space for constant values of ϵ. It relies on a variation of the local-ratio theorem, which may be of use for other algorithms in the semi-streaming model as well.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2904319175",
    "type": "article"
  },
  {
    "title": "Firefighting on Trees Beyond Integrality Gaps",
    "doi": "https://doi.org/10.1145/3173046",
    "publication_date": "2018-12-07",
    "publication_year": 2018,
    "authors": "David Adjiashvili; Andrea Baggio; Rico Zenklusen",
    "corresponding_authors": "",
    "abstract": "The Firefighter problem and a variant of it, known as Resource Minimization for Fire Containment (RMFC), are natural models for optimal inhibition of harmful spreading processes. Despite considerable progress on several fronts, the approximability of these problems is still badly understood. This is the case even when the underlying graph is a tree, which is one of the most-studied graph structures in this context and the focus of this article. In their simplest version, a fire spreads from one fixed vertex step by step from burning to adjacent non-burning vertices, and at each time step B many non-burning vertices can be protected from catching fire. The Firefighter problem asks, for a given B , to maximize the number of vertices that will not catch fire, whereas RMFC (on a tree) asks to find the smallest B that allows for saving all leaves of the tree. Prior to this work, the best known approximation ratios were an O (1)-approximation for the Firefighter problem and an O (log * n )-approximation for RMFC, both being LP-based and essentially matching the integrality gaps of two natural LP relaxations. We improve on both approximations by presenting a PTAS for the Firefighter problem and an O (1)-approximation for RMFC, both qualitatively matching the known hardness results. Our results are obtained through a combination of the known LPs with several new techniques, which allow for efficiently enumerating over super-constant size sets of constraints to strengthen the natural LPs.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2905516683",
    "type": "article"
  },
  {
    "title": "Derandomized Concentration Bounds for Polynomials, and Hypergraph Maximal Independent Set",
    "doi": "https://doi.org/10.1145/3326171",
    "publication_date": "2019-07-16",
    "publication_year": 2019,
    "authors": "David G. Harris",
    "corresponding_authors": "David G. Harris",
    "abstract": "A parallel algorithm for maximal independent set (MIS) in hypergraphs has been a long-standing algorithmic challenge, dating back nearly 30 years to a survey of Karp and Ramachandran (1990). The best randomized parallel algorithm for hypergraphs of fixed rank r was developed by Beame and Luby (1990) and Kelsen (1992), running in time roughly (log n ) r ! . We improve the randomized algorithm of Kelsen, reducing the runtime to roughly (log n ) 2 r and simplifying the analysis through the use of more-modern concentration inequalities. We also give a method for derandomizing concentration bounds for low-degree polynomials, which are the key technical tool used to analyze that algorithm. This leads to a deterministic PRAM algorithm also running in (log n ) 2 r +3 time and poly ( m , n ) processors. This is the first deterministic algorithm with sub-polynomial runtime for hypergraphs of rank r &gt; 3. Our analysis can also apply when r is slowly growing; using this in conjunction with a strategy of Bercea et al. (2015) gives a deterministic MIS algorithm running in time exp ( O ( log ( mn ) / log log ( mn )).",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2960354271",
    "type": "article"
  },
  {
    "title": "Nearly ETH-tight Algorithms for Planar Steiner Tree with Terminals on Few Faces",
    "doi": "https://doi.org/10.1145/3371389",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "‪Sándor Kisfaludi-Bak; Jesper Nederlof; Erik Jan van Leeuwen",
    "corresponding_authors": "",
    "abstract": "The S TEINER T REE problem is one of the most fundamental NP-complete problems, as it models many network design problems. Recall that an instance of this problem consists of a graph with edge weights and a subset of vertices (often called terminals); the goal is to find a subtree of the graph of minimum total weight that connects all terminals. A seminal paper by Erickson et al. [Math. Oper. Res., 1987{ considers instances where the underlying graph is planar and all terminals can be covered by the boundary of k faces. Erickson et al. show that the problem can be solved by an algorithm using n O(k) time and n O(k) space, where n denotes the number of vertices of the input graph. In the past 30 years there has been no significant improvement of this algorithm, despite several efforts. In this work, we give an algorithm for P LANAR S TEINER T REE with running time 2 O(k) n O(√k) with the above parameterization, using only polynomial space. Furthermore, we show that the running time of our algorithm is almost tight: We prove that there is no f ( k ) n o(√k) algorithm for P LANAR S TEINER T REE for any computable function f , unless the Exponential Time Hypothesis fails.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2963277542",
    "type": "article"
  },
  {
    "title": "Efficient Computation of Middle Levels Gray Codes",
    "doi": "https://doi.org/10.1145/3170443",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Torsten Mütze; Jerri Nummenpalo",
    "corresponding_authors": "",
    "abstract": "For any integer n ≥ 1, a middle levels Gray code is a cyclic listing of all bitstrings of length 2 n +1 that have either n or n +1 entries equal to 1 such that any two consecutive bitstrings in the list differ in exactly one bit. The question whether such a Gray code exists for every n ≥ 1 has been the subject of intensive research during the past 30 years and has been answered affirmatively only recently [T. Mütze. Proof of the middle levels conjecture. Proc. London Math. Soc. , 112(4):677--713, 2016]. In this work, we provide the first efficient algorithm to compute a middle levels Gray code. For a given bitstring, our algorithm computes the next ℓ bitstrings in the Gray code in time O ( n ℓ (1+ n /ℓ)), which is O ( n ) on average per bitstring provided that ℓ = Ω ( n ).",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2963283269",
    "type": "article"
  },
  {
    "title": "A Time- and Message-Optimal Distributed Algorithm for Minimum Spanning Trees",
    "doi": "https://doi.org/10.1145/3365005",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Gopal Pandurangan; Peter Robinson; Michele Scquizzato",
    "corresponding_authors": "",
    "abstract": "This article presents a randomized (Las Vegas) distributed algorithm that constructs a minimum spanning tree (MST) in weighted networks with optimal (up to polylogarithmic factors) time and message complexity. This algorithm runs in Õ( D + √ n ) time and exchanges Õ( m ) messages (both with high probability), where n is the number of nodes of the network, D is the hop-diameter, and m is the number of edges. This is the first distributed MST algorithm that matches simultaneously the time lower bound of Ω ˜ ( D + √ n ) [10] and the message lower bound of Ω ( m ) [31], which both apply to randomized Monte Carlo algorithms. The prior time and message lower bounds are derived using two completely different graph constructions; the existing lower-bound construction that shows one lower bound does not work for the other. To complement our algorithm, we present a new lower-bound graph construction for which any distributed MST algorithm requires both Ω ˜ ( D + √ n ) rounds and Ω ( m ) messages.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2985210774",
    "type": "article"
  },
  {
    "title": "Subexponential Algorithms for Rectilinear Steiner Tree and Arborescence Problems",
    "doi": "https://doi.org/10.1145/3381420",
    "publication_date": "2020-03-09",
    "publication_year": 2020,
    "authors": "Fedor V. Fomin; Daniel Lokshtanov; Sudeshna Kolay; Fahad Panolan; Saket Saurabh",
    "corresponding_authors": "",
    "abstract": "A rectilinear Steiner tree for a set K of points in the plane is a tree that connects k using horizontal and vertical lines. In the R ectilinear S teiner T ree problem, the input is a set K ={ z 1 , z 2 ,…, z n } of n points in the Euclidean plane (R 2 ), and the goal is to find a rectilinear Steiner tree for k of smallest possible total length. A rectilinear Steiner arborescence for a set k of points and a root r ∈ K is a rectilinear Steiner tree T for K such that the path in T from r to any point z ∈ K is a shortest path. In the R ectilinear S teiner A rborescence problem, the input is a set K of n points in R 2 , and a root r ∈ K , and the task is to find a rectilinear Steiner arborescence for K , rooted at r of smallest possible total length. In this article, we design deterministic algorithms for these problems that run in 2 O (√ n log n ) time.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3010770967",
    "type": "article"
  },
  {
    "title": "A Unified PTAS for Prize Collecting TSP and Steiner Tree Problem in Doubling Metrics",
    "doi": "https://doi.org/10.1145/3378571",
    "publication_date": "2020-03-09",
    "publication_year": 2020,
    "authors": "T-H. Hubert Chan; Haotian Jiang; Shaofeng H.-C. Jiang",
    "corresponding_authors": "",
    "abstract": "We present a unified (randomized) polynomial-time approximation scheme (PTAS) for the prize collecting traveling salesman problem (PCTSP) and the prize collecting Steiner tree problem (PCSTP) in doubling metrics. Given a metric space and a penalty function on a subset of points known as terminals, a solution is a subgraph on points in the metric space whose cost is the weight of its edges plus the penalty due to terminals not covered by the subgraph. Under our unified framework, the solution subgraph needs to be Eulerian for PCTSP, while it needs to be a tree for PCSTP. Before our work, even a QPTAS for the problems in doubling metrics is not known. Our unified PTAS is based on the previous dynamic programming frameworks proposed in Talwar (STOC 2004) and Bartal, Gottlieb, Krauthgamer (STOC 2012). However, since it is unknown which part of the optimal cost is due to edge lengths and which part is due to penalties of uncovered terminals, we need to develop new techniques to apply previous divide-and-conquer strategies and sparse instance decompositions.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3011328295",
    "type": "article"
  },
  {
    "title": "Maximum Matching in the Online Batch-arrival Model",
    "doi": "https://doi.org/10.1145/3399676",
    "publication_date": "2020-07-20",
    "publication_year": 2020,
    "authors": "Euiwoong Lee; Sahil Singla",
    "corresponding_authors": "",
    "abstract": "Consider a two-stage matching problem, where edges of an input graph are revealed in two stages (batches) and in each stage we have to immediately and irrevocably extend our matching using the edges from that stage. The natural greedy algorithm is half competitive. Even though there is a huge literature on online matching in adversarial vertex arrival model , no positive results were previously known in adversarial edge arrival model . For two-stage bipartite matching problem, we show that the optimal competitive ratio is exactly 2/3 in both the fractional and the randomized-integral models. Furthermore, our algorithm for fractional bipartite matching is instance optimal , i.e., it achieves the best competitive ratio for any given first stage graph. We also study natural extensions of this problem to general graphs and to s stages and present randomized-integral algorithms with competitive ratio ½ + 2− O(s) . Our algorithms use a novel Instance-Optimal-LP and combine graph decomposition techniques with online primal-dual analysis.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3044919769",
    "type": "article"
  },
  {
    "title": "A Colored Path Problem and Its Applications",
    "doi": "https://doi.org/10.1145/3396573",
    "publication_date": "2020-06-21",
    "publication_year": 2020,
    "authors": "Eduard Eiben; Iyad Kanj",
    "corresponding_authors": "",
    "abstract": "Given a set of obstacles and two points in the plane, is there a path between the two points that does not cross more than k different obstacles? Equivalently, can we remove k obstacles so that there is an obstacle-free path between the two designated points? This is a fundamental NP-hard problem that has undergone a tremendous amount of research work. The problem can be formulated and generalized into the following graph problem: Given a planar graph G whose vertices are colored by color sets, two designated vertices s , t ∈ V ( G ), and k ∈ N, is there an s - t path in G that uses at most k colors? If each obstacle is connected, then the resulting graph satisfies the color-connectivity property, namely that each color induces a connected subgraph. We study the complexity and design algorithms for the above graph problem with an eye on its geometric applications. We prove a set of hardness results, including a result showing that the color-connectivity property is crucial for any hope for fixed-parameter tractable (FPT) algorithms. We also show that our hardness results translate to the geometric instances of the problem. We then focus on graphs satisfying the color-connectivity property. We design an FPT algorithm for this problem parameterized by both k and the treewidth of the graph and extend this result further to obtain an FPT algorithm for the parameterization by both k and the length of the path. The latter result implies and explains previous FPT results for various obstacle shapes.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3048679163",
    "type": "article"
  },
  {
    "title": "A Faster Subquadratic Algorithm for Finding Outlier Correlations",
    "doi": "https://doi.org/10.1145/3174804",
    "publication_date": "2018-06-16",
    "publication_year": 2018,
    "authors": "Matti Karppa; Petteri Kaski; Jukka Kohonen",
    "corresponding_authors": "",
    "abstract": "We study the problem of detecting outlier pairs of strongly correlated variables among a collection of n variables with otherwise weak pairwise correlations. After normalization, this task amounts to the geometric task where we are given as input a set of n vectors with unit Euclidean norm and dimension d , and for some constants 0&lt;τ &lt; ρ &lt; 1, we are asked to find all the outlier pairs of vectors whose inner product is at least ρ in absolute value, subject to the promise that all but at most q pairs of vectors have inner product at most τ in absolute value. Improving on an algorithm of Valiant [FOCS 2012; J. ACM 2015], we present a randomized algorithm that for Boolean inputs ({ −1,1}-valued data normalized to unit Euclidean length) runs in time Õ(( n max,{ 1−γ + M (Δ γ ,γ), M (1−γ ,2 Δ γ)} + qdn 2γ ), where 0&lt;γ &lt; 1 is a constant tradeoff parameter and M (μ, ν) is the exponent to multiply an ⌊ n μ ⌋ × ⌊ n ν ⌋ matrix with an ⌊ n ν ⌋ × ⌊ n μ ⌋ matrix and Δ =1/(1−log τ ρ). As corollaries we obtain randomized algorithms that run in time Õ( ( n 2/ω 3−log τ ρ + qdn 2/(1−log τ ρ)3=log ττ ρ ) and in time õ( ( n 4 / 2+α (1−log τ ρ) + qdn 2/α (1−log τ ρ)2+α (1−log τ ρ) &gt;), where 2≤ ω &lt;2.38 is the exponent for square matrix multiplication and 0.3&lt;α ≤ 1 is the exponent for rectangular matrix multiplication. The notation Õ(ṡ) hides polylogarithmic factors in n and d whose degree may depend on ρ and τ. We present further corollaries for the light bulb problem and for learning sparse Boolean functions.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3163661117",
    "type": "article"
  },
  {
    "title": "Approximation Algorithms for Min-Max Generalization Problems",
    "doi": "https://doi.org/10.1145/2636920",
    "publication_date": "2014-08-25",
    "publication_year": 2014,
    "authors": "Piotr Berman; Sofya Raskhodnikova",
    "corresponding_authors": "",
    "abstract": "We provide improved approximation algorithms for the min-max generalization problems considered by Du, Eppstein, Goodrich, and Lueker [Du et al. 2009]. Generalization is widely used in privacy-preserving data mining and can also be viewed as a natural way of compressing a dataset. In min-max generalization problems, the input consists of data items with weights and a lower bound w lb , and the goal is to partition individual items into groups of weight at least w lb while minimizing the maximum weight of a group. The rules of legal partitioning are specific to a problem. Du et al. consider several problems in this vein: (1) partitioning a graph into connected subgraphs, (2) partitioning unstructured data into arbitrary classes, and (3) partitioning a two-dimensional array into contiguous rectangles (subarrays) that satisfy these weight requirements. We significantly improve approximation ratios for all the problems considered by Du et al. and provide additional motivation for these problems. Moreover, for the first problem, whereas Du et al. give approximation algorithms for specific graph families, namely, 3-connected and 4-connected planar graphs, no approximation algorithm that works for all graphs was known prior to this work.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2032415540",
    "type": "article"
  },
  {
    "title": "Approximation Algorithms for a Minimization Variant of the Order-Preserving Submatrices and for Biclustering Problems",
    "doi": "https://doi.org/10.1145/2438645.2438651",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "Dorit S. Hochbaum; Asaf Levin",
    "corresponding_authors": "",
    "abstract": "Finding a largest Order-Preserving SubMatrix, OPSM, is an important problem arising in the discovery of patterns in gene expression. Ben-Dor et al. formulated the problem in Ben-Dor et al. [2003]. They further showed that the problem is NP-complete and provided a greedy heuristic for the problem. The complement of the OPSM problem, called MinOPSM, is to delete the least number of entries in the matrix so that the remaining submatrix is order preserving. We devise a 5-approximation algorithm for the MinOPSM based on a formulation of the problem as a quadratic, nonseparable set cover problem. An alternative formulation combined with a primal-dual algorithm improves the approximation factor to 3. The complexity of both algorithms for a matrix of size m × n is O ( m 2 n ). We further comment on the related biclustering problem.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2035261709",
    "type": "article"
  },
  {
    "title": "An Improved Competitive Algorithm for Reordering Buffer Management",
    "doi": "https://doi.org/10.1145/2663347",
    "publication_date": "2015-06-23",
    "publication_year": 2015,
    "authors": "Noa Avigdor-Elgrabli; Yuval Rabani",
    "corresponding_authors": "",
    "abstract": "We design and analyze an online reordering buffer management algorithm with improved O (log k /log log k ) competitive ratio for nonuniform costs, where k is the buffer size. This improves on the best previous result (even for uniform costs) of Englert and Westermann (2005) giving O (log k ) competitive ratio, which was also the best (offline) polynomial time approximation guarantee for this problem. Our analysis is based on an intricate dual fitting argument using a linear programming relaxation for the problem that we introduce in this article.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2624545553",
    "type": "article"
  },
  {
    "title": "Tight Bounds for ℓ <sub>1</sub> Oblivious Subspace Embeddings",
    "doi": "https://doi.org/10.1145/3477537",
    "publication_date": "2022-01-24",
    "publication_year": 2022,
    "authors": "Ruosong Wang; David P. Woodruff",
    "corresponding_authors": "",
    "abstract": "An \\ell _p oblivious subspace embedding is a distribution over r \\times n matrices \\Pi such that for any fixed n \\times d matrix A , \\[ \\Pr _{\\Pi }[\\textrm {for all }x, \\ \\Vert Ax\\Vert _p \\le \\Vert \\Pi Ax\\Vert _p \\le \\kappa \\Vert Ax\\Vert _p] \\ge 9/10, \\] where r is the dimension of the embedding, \\kappa is the distortion of the embedding, and for an n -dimensional vector y , \\Vert y\\Vert _p = (\\sum _{i=1}^n |y_i|^p)^{1/p} is the \\ell _p -norm. Another important property is the sparsity of \\Pi , that is, the maximum number of non-zero entries per column, as this determines the running time of computing \\Pi A . While for p = 2 there are nearly optimal tradeoffs in terms of the dimension, distortion, and sparsity, for the important case of 1 \\le p \\lt 2 , much less was known. In this article, we obtain nearly optimal tradeoffs for \\ell _1 oblivious subspace embeddings, as well as new tradeoffs for 1 \\lt p \\lt 2 . Our main results are as follows: (1) We show for every 1 \\le p \\lt 2 , any oblivious subspace embedding with dimension r has distortion \\[ \\kappa = \\Omega \\left(\\frac{1}{\\left(\\frac{1}{d}\\right)^{1 / p} \\log ^{2 / p}r + \\left(\\frac{r}{n}\\right)^{1 / p - 1 / 2}}\\right). \\] When r = {\\operatorname{poly}}(d) \\ll n in applications, this gives a \\kappa = \\Omega (d^{1/p}\\log ^{-2/p} d) lower bound, and shows the oblivious subspace embedding of Sohler and Woodruff (STOC, 2011) for p = 1 is optimal up to {\\operatorname{poly}}(\\log (d)) factors. (2) We give sparse oblivious subspace embeddings for every 1 \\le p \\lt 2 . Importantly, for p = 1 , we achieve r = O(d \\log d) , \\kappa = O(d \\log d) and s = O(\\log d) non-zero entries per column. The best previous construction with s \\le {\\operatorname{poly}}(\\log d) is due to Woodruff and Zhang (COLT, 2013), giving \\kappa = \\Omega (d^2 {\\operatorname{poly}}(\\log d)) or \\kappa = \\Omega (d^{3/2} \\sqrt {\\log n} \\cdot {\\operatorname{poly}}(\\log d)) and r \\ge d \\cdot {\\operatorname{poly}}(\\log d) ; in contrast our r = O(d \\log d) and \\kappa = O(d \\log d) are optimal up to {\\operatorname{poly}}(\\log (d)) factors even for dense matrices. We also give (1) \\ell _p oblivious subspace embeddings with an expected 1+\\varepsilon number of non-zero entries per column for arbitrarily small \\varepsilon \\gt 0 , and (2) the first oblivious subspace embeddings for 1 \\le p \\lt 2 with O(1) -distortion and dimension independent of n . Oblivious subspace embeddings are crucial for distributed and streaming environments, as well as entrywise \\ell _p low-rank approximation. Our results give improved algorithms for these applications.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4207064254",
    "type": "article"
  },
  {
    "title": "Adaptive Shivers Sort: An Alternative Sorting Algorithm",
    "doi": "https://doi.org/10.1145/3664195",
    "publication_date": "2024-05-22",
    "publication_year": 2024,
    "authors": "Vincent Jugé",
    "corresponding_authors": "Vincent Jugé",
    "abstract": "We present a new sorting algorithm, called adaptive ShiversSort, that exploits the existence of monotonic runs for sorting efficiently partially sorted data. This algorithm is a variant of the well-known algorithm TimSort, which is the sorting algorithm used in standard libraries of programming languages such as Python or Java (for non-primitive types). More precisely, adaptive ShiversSort is a so-called \\(k\\) -aware merge-sort algorithm, a class that captures “TimSort-like” algorithms and that was introduced by Buss and Knop. In this article, we prove that, although adaptive ShiversSort is simple to implement and differs only slightly from TimSort, its computational cost, in number of comparisons performed, is optimal within the class of natural merge-sort algorithms, up to a small additive linear term. This makes adaptive ShiversSort the first \\(k\\) -aware algorithm to benefit from this property, which is also a 33% improvement over TimSort’s worst-case. This suggests that adaptive ShiversSort could be a strong contender for being used instead of TimSort. Then, we investigate the optimality of \\(k\\) -aware algorithms. We give lower and upper bounds on the best approximation factors of such algorithms, compared to optimal stable natural merge-sort algorithms. In particular, we design generalisations of adaptive ShiversSort whose computational costs are optimal up to arbitrarily small multiplicative factors.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2891219599",
    "type": "article"
  },
  {
    "title": "A face cover perspective to \\(\\ell_{1}\\) embeddings of planar graphs",
    "doi": "https://doi.org/10.1145/3686800",
    "publication_date": "2024-08-05",
    "publication_year": 2024,
    "authors": "Arnold Filtser",
    "corresponding_authors": "Arnold Filtser",
    "abstract": "It was conjectured by Gupta et al. that every planar graph can be embedded into \\(\\ell_{1}\\) with constant distortion. However, given an \\(n\\) -vertex weighted planar graph, the best upper bound on the distortion is only \\(O(\\sqrt{\\log n})\\) , by Rao. In this article, we study the case where there is a set \\(K\\) of terminals, and the goal is to embed only the terminals into \\(\\ell_{1}\\) with low distortion. In a seminal article, Okamura and Seymour showed that if all the terminals lie on a single face, they can be embedded isometrically into \\(\\ell_{1}\\) . The more general case, where the set of terminals can be covered by \\(\\gamma\\) faces, was studied by Lee and Sidiropoulos and Chekuri et al. The state of the art is an upper bound of \\(O(\\log\\gamma)\\) by Krauthgamer, Lee and Rika. Our contribution is a further improvement on the upper bound to \\(O(\\sqrt{\\log\\gamma})\\) . Since every planar graph has at most \\(O(n)\\) faces, any further improvement on this result will be a major breakthrough, directly improving upon Rao's long standing upper bound. Moreover, it is well known that the flow-cut gap equals to the distortion of the best embedding into \\(\\ell_{1}\\) . Therefore, our result provides a polynomial time \\(O(\\sqrt{\\log\\gamma})\\) -approximation to the sparsest cut problem on planar graphs, for the case where all the demand pairs can be covered by \\(\\gamma\\) faces.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2921536139",
    "type": "article"
  },
  {
    "title": "Streaming Algorithms for Geometric Steiner Forest",
    "doi": "https://doi.org/10.1145/3663666",
    "publication_date": "2024-05-07",
    "publication_year": 2024,
    "authors": "Artur Czumaj; Shaofeng H.-C. Jiang; Robert Krauthgamer; Pavel Veselý",
    "corresponding_authors": "",
    "abstract": "We consider a generalization of the Steiner tree problem, the Steiner forest problem , in the Euclidean plane: the input is a multiset \\(X\\subseteq{\\mathbb{R}}^{2}\\) , partitioned into \\(k\\) color classes \\(C_{1},\\ldots,C_{k}\\subseteq X\\) . The goal is to find a minimum-cost Euclidean graph \\(G\\) such that every color class \\(C_{i}\\) is connected in \\(G\\) . We study this Steiner forest problem in the streaming setting, where the stream consists of insertions and deletions of points to \\(X\\) . Each input point \\(x\\in X\\) arrives with its color \\(\\mathsf{color}(x)\\in[k]\\) , and as usual for dynamic geometric streams, the input is restricted to the discrete grid \\(\\{1,\\ldots,\\Delta\\}^{2}\\) . We design a single-pass streaming algorithm that uses \\(\\operatorname{poly}(k\\cdot\\log\\Delta)\\) space and time, and estimates the cost of an optimal Steiner forest solution within ratio arbitrarily close to the famous Euclidean Steiner ratio \\(\\alpha_{2}\\) (currently \\(1.1547\\leq\\alpha_{2}\\leq 1.214\\) ). This approximation guarantee matches the state-of-the-art bound for streaming Steiner tree, i.e., when \\(k=1\\) , and it is a major open question to improve the ratio to \\(1+\\varepsilon\\) even for this special case. Our approach relies on a novel combination of streaming techniques, like sampling and linear sketching, with the classical Arora-style dynamic-programming framework for geometric optimization problems, which usually requires large memory and so far has not been applied in the streaming setting. We complement our streaming algorithm for the Steiner forest problem with simple arguments showing that any finite multiplicative approximation requires \\(\\Omega(k)\\) bits of space.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3103329032",
    "type": "article"
  },
  {
    "title": "Better Sum Estimation via Weighted Sampling",
    "doi": "https://doi.org/10.1145/3650030",
    "publication_date": "2024-03-30",
    "publication_year": 2024,
    "authors": "Lorenzo Beretta; Jakub Tětek",
    "corresponding_authors": "",
    "abstract": "Given a large set U where each item α ∈ U has weight w(α), we want to estimate the total weight W = Σ α ∈ U w(α) to within factor of 1± ϵ with some constant probability > 1/2. Since n=|U| is large, we want to do this without looking at the entire set U. In the traditional setting in which we are allowed to sample elements from U uniformly, sampling ω (n) items is necessary to provide any non-trivial guarantee on the estimate. Therefore, we investigate this problem in different settings: in the proportional setting we can sample items with probabilities proportional to their weights, and in the hybrid setting we can sample both proportionally and uniformly. These settings have applications, for example, in sublinear-time algorithms and distribution testing. Sum estimation in the proportional and hybrid setting has been considered before by Motwani, Panigrahy, and Xu [ICALP, 2007]. In their article, they give both upper and lower bounds in terms of n. Their bounds are near-matching in terms of n, but not in terms of ϵ. In this article, we improve both their upper and lower bounds. Our bounds are matching up to constant factors in both settings, in terms of both n and ϵ. No lower bounds with dependency on ϵ were known previously. In the proportional setting, we improve their Õ(√n/ϵ7/2) algorithm to O(√n/ϵ). In the hybrid setting, we improve to Õ Õ (3√n/ϵ9/2) to O(3√n/ϵ4/3). Our algorithms are also significantly simpler and do not have large constant factors. We then investigate the previously unexplored scenario in which n is not known to the algorithm. In this case, we obtain a O(√n/ϵ+log n/ϵ2) algorithm for the proportional setting, and a O(√n/ϵ)algorithm for the hybrid setting. This means that in the proportional setting, we may remove the need for advice without greatly increasing the complexity of the problem, while there is a major difference in the hybrid setting. We prove that this difference in the hybrid setting is necessary, by showing a matching lower bound. Our algorithms have applications in the area of sublinear-time graph algorithms. Consider a large graph G=(V, E) and the task of (1 ± ϵ)-approximating |E|. We consider the (standard) settings where we can sample uniformly from E or from both E and V. This relates to sum estimation as follows: we set U = V and the weights to be equal to the degrees. Uniform sampling then corresponds to sampling vertices uniformly. Proportional sampling can be simulated by taking a random edge and picking one of its endpoints at random. If we can only sample uniformly from E, then our results immediately give a O(√\\V\\/ϵ) algorithm. When we may sample both from E and V, our results imply an algorithm with complexity O(3√|V|/ϵ4/3). Surprisingly, one of our subroutines provides an (1 ± ϵ)-approximation of |E| Õ(d/ϵ2) using expected samples, where d is the average degree, under the mild assumption that at least a constant fraction of vertices are non-isolated. This subroutine works in the setting where we can sample uniformly from both V and E. We find this remarkable since it is O(1/ϵ2) for sparse graphs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3210340672",
    "type": "article"
  },
  {
    "title": "Competitive Data-Structure Dynamization",
    "doi": "https://doi.org/10.1145/3672614",
    "publication_date": "2024-06-28",
    "publication_year": 2024,
    "authors": "Claire Mathieu; Rajmohan Rajaraman; Neal E. Young; Arman Yousefi",
    "corresponding_authors": "",
    "abstract": "Data-structure dynamization is a general approach for making static data structures dynamic. It is used extensively in geometric settings and in the guise of so-called merge (or compaction) policies in big-data databases such as LevelDB and Google Bigtable. Previous theoretical work is based on worst-case analyses for uniform inputs—insertions of one item at a time and non-varying read rate. In practice, merge policies must not only handle batch insertions and varying read/write ratios, they can take advantage of such non-uniformity to reduce cost on a per-input basis. To model this, we initiate the study of data-structure dynamization through the lens of competitive analysis via two new online set-cover problems. For each, the input is a sequence of disjoint sets of weighted items. The sets are revealed one at a time. The algorithm must respond to each with a set cover that covers all items revealed so far. It obtains the cover incrementally from the previous cover by adding one or more sets and optionally removing existing sets. For each new set the algorithm incurs build cost equal to the weight of the items in the set. In the first problem the objective is to minimize total build cost plus total query cost , where the algorithm incurs a query cost at each time \\(t\\) equal to the current cover size. In the second problem, the objective is to minimize the build cost while keeping the query cost from exceeding \\(k\\) (a given parameter) at any time. We give deterministic online algorithms for both variants, with competitive ratios of \\(\\Theta(\\log^{*}n)\\) and \\(k\\) , respectively. The latter ratio is optimal for the second variant.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4226283575",
    "type": "article"
  },
  {
    "title": "Map Matching Queries on Realistic Input Graphs Under the Fréchet Distance",
    "doi": "https://doi.org/10.1145/3643683",
    "publication_date": "2024-01-30",
    "publication_year": 2024,
    "authors": "Joachim Gudmundsson; Martin P. Seybold; Sampson Wong",
    "corresponding_authors": "",
    "abstract": "Map matching is a common preprocessing step for analysing vehicle trajectories. In the theory community, the most popular approach for map matching is to compute a path on the road network that is the most spatially similar to the trajectory, where spatial similarity is measured using the Fréchet distance. A shortcoming of existing map matching algorithms under the Fréchet distance is that every time a trajectory is matched, the entire road network needs to be reprocessed from scratch. An open problem is whether one can preprocess the road network into a data structure, so that map matching queries can be answered in sublinear time.In this article, we investigate map matching queries under the Fréchet distance. We provide a negative result for geometric planar graphs. We show that, unless SETH fails, there is no data structure that can be constructed in polynomial time that answers map matching queries in O((pq)1-δ) query time for any δ> 0, where p and q are the complexities of the geometric planar graph and the query trajectory, respectively. We provide a positive result for realistic input graphs, which we regard as the main result of this article. We show that for c-packed graphs, one can construct a data structure of size that can answer (1+ϵ)-approximate map matching queries in time, where hides lower-order factors and dependence on ϵ.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4391360827",
    "type": "article"
  },
  {
    "title": "Contraction Decomposition in Unit Disk Graphs and Algorithmic Applications in Parameterized Complexity",
    "doi": "https://doi.org/10.1145/3648594",
    "publication_date": "2024-02-15",
    "publication_year": 2024,
    "authors": "Fahad Panolan; Saket Saurabh; Meirav Zehavi",
    "corresponding_authors": "",
    "abstract": "We give a new decomposition theorem in unit disk graphs (UDGs) and demonstrate its applicability in the fields of Structural Graph Theory and Parameterized Complexity. First, our new decomposition theorem shows that the class of UDGs admits an “almost” Contraction Decomposition Theorem. Prior studies on this topic exhibited that the classes of planar graphs [Klein, SICOMP, 2008], graphs of bounded genus [Demaine, Hajiaghayi and Mohar, Combinatorica 2010], and H -minor free graphs [Demaine, Hajiaghayi and Kawarabayashi, STOC 2011] admit a Contraction Decomposition Theorem. Even bounded-degree UDGs can contain arbitrarily large cliques as minors, and therefore our result is a significant advance in the study of contraction decompositions. Additionally, this result answers an open question posed by Hajiaghayi ( www.youtube.com/watch?v=2Bq2gy1N01w ) regarding the existence of contraction decompositions for classes of graphs beyond H -minor free graphs though under a relaxation of the original formulation. Second, we present a “parameteric version” of our new decomposition theorem. We prove that there is an algorithm that, given a UDG G and a positive integer k , runs in polynomial time and outputs a collection of \\(\\mathcal {O}(k)\\) tree decompositions of G with the following properties. Each bag in any of these tree decompositions can be partitioned into \\(\\mathcal {O}(k)\\) connected pieces (we call this measure the chunkiness of the tree decomposition). Moreover, for any subset S of at most k edges in G , there is a tree decomposition in the collection such that S is well preserved in the decomposition in the following sense. For any bag in the tree decomposition and any edge in S with both endpoints in the bag, either its endpoints lie in different pieces or they lie in a piece that is a clique. Having this decomposition at hand, we show that the design of parameterized algorithms for some cut problems becomes elementary. In particular, our algorithmic applications include single-exponential (or slightly super-exponential) algorithms for well-studied problems such as Min Bisection , Steiner Cut , s -Way Cut , and Edge Multiway Cut-Uncut on UDGs; these algorithms are substantially faster than the best-known algorithms for these problems on general graphs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4391843512",
    "type": "article"
  },
  {
    "title": "Isomorphism Testing for Graphs Excluding Small Topological Subgraphs",
    "doi": "https://doi.org/10.1145/3651986",
    "publication_date": "2024-03-13",
    "publication_year": 2024,
    "authors": "Daniel Neuen",
    "corresponding_authors": "Daniel Neuen",
    "abstract": "We give an isomorphism test that runs in time n polylog( h ) on all n -vertex graphs excluding some h -vertex graph as a topological subgraph. Previous results state that isomorphism for such graphs can be tested in time n polylog( h ) (Babai, STOC 2016) and n {f(h) for some function f (Grohe and Marx, SIAM J. Comp., 2015). Our result also unifies and extends previous isomorphism tests for graphs of maximum degree d running in time n polylog( d ) (SIAM J. Comp., 2023) and for graphs of Hadwiger number h running in time n polylog( h ) (SIAM J. Comp., 2023).",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4392750080",
    "type": "article"
  },
  {
    "title": "The Fine-Grained Complexity of Graph Homomorphism Parameterized by Clique-Width",
    "doi": "https://doi.org/10.1145/3652514",
    "publication_date": "2024-03-25",
    "publication_year": 2024,
    "authors": "Robert Ganian; Thekla Hamm; Viktoriia Korchemna; Karolina Okrasa; Kirill Simonov",
    "corresponding_authors": "",
    "abstract": "The generic homomorphism problem, which asks whether an input graph \\(G\\) admits a homomorphism into a fixed target graph \\(H\\) , has been widely studied in the literature. In this article, we provide a fine-grained complexity classification of the running time of the homomorphism problem with respect to the clique-width of \\(G\\) (denoted \\({\\operatorname{cw}}\\) ) for virtually all choices of \\(H\\) under the Strong Exponential Time Hypothesis. In particular, we identify a property of \\(H\\) called the signature number \\(s(H)\\) and show that for each \\(H\\) , the homomorphism problem can be solved in time \\(\\mathcal{O^{*}}(s(H)^{{\\operatorname{cw}}})\\) . Crucially, we then show that this algorithm can be used to obtain essentially tight upper bounds. Specifically, we provide a reduction that yields matching lower bounds for each \\(H\\) that is either a projective core or a graph admitting a factorization with additional properties—allowing us to cover all possible target graphs under long-standing conjectures.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4393143766",
    "type": "article"
  },
  {
    "title": "Introduction: ACM-SIAM Symposium on Discrete Algorithms (SODA) 2022 Special Issue",
    "doi": "https://doi.org/10.1145/3655622",
    "publication_date": "2024-05-09",
    "publication_year": 2024,
    "authors": "Daniel Dadush; Martin Milanič; Tami Tamir",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4396781224",
    "type": "article"
  },
  {
    "title": "Fully Dynamic Submodular Maximization over Matroids",
    "doi": "https://doi.org/10.1145/3698397",
    "publication_date": "2024-10-10",
    "publication_year": 2024,
    "authors": "Paul Dütting; Federico Fusco; Silvio Lattanzi; Ashkan Norouzi-Fard; Morteza Zadimoghaddam",
    "corresponding_authors": "",
    "abstract": "Maximizing monotone submodular functions under a matroid constraint is a classic algorithmic problem with multiple applications in data mining and machine learning. We study this significant problem in the fully dynamic setting, where elements can be both inserted and deleted in real-time. Our main result is a randomized algorithm that maintains an efficient data structure with an \\({\\tilde{O}({k^{2}}{\\varepsilon})}\\) amortized update time (in the number of insertions and deletions) and yields a \\({(4+O(\\varepsilon))}\\) -approximate solution with respect to the dynamic optimum, where \\(k\\) is the rank of the matroid.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4403456809",
    "type": "article"
  },
  {
    "title": "Strict Fibonacci Heaps",
    "doi": "https://doi.org/10.1145/3707692",
    "publication_date": "2024-12-10",
    "publication_year": 2024,
    "authors": "Gerth Stølting Brodal; George Lagogiannis; Robert E. Tarjan",
    "corresponding_authors": "",
    "abstract": "We present the strict Fibonacci heap , the first pointer-based heap implementation with time bounds matching those of Fibonacci heaps in the worst case. Strict Fibonacci heaps support make-heap, insert, find-min, meld and decrease-key in worst-case \\(O(1)\\) time, and delete and delete-min in worst-case \\(O(\\lg n)\\) time, where \\(n\\) is the size of the heap. The data structure uses linear space. A previous solution achieving the same time bounds in the RAM model made essential use of arrays and extensive use of redundant counter schemes to maintain balance. Our solution uses neither. Our key simplification is to discard the structure of the smaller heap when doing a meld, and to use the pigeonhole principle in place of the redundant counter mechanism to maintain balance.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405208398",
    "type": "article"
  },
  {
    "title": "Efficiency of Self-Adjusting Heaps",
    "doi": "https://doi.org/10.1145/3708989",
    "publication_date": "2024-12-23",
    "publication_year": 2024,
    "authors": "Corwin Sinnamon; Robert E. Tarjan",
    "corresponding_authors": "",
    "abstract": "Since the invention of the pairing heap by Fredman, Sedgewick, Sleator, and Tarjan [8], it has been an open question whether this or any other simple “self-adjusting” heap supports decrease-key operations in \\(\\mathrm{O}(\\log\\log n)\\) time, where \\(n\\) is the number of heap items. Using powerful new techniques, we answer this question in the affirmative. We prove that both slim and smooth heaps, recently introduced self-adjusting heaps, support heap operations in the following amortized time bounds: \\(\\mathrm{O}(\\log n)\\) for delete-min and delete, \\(\\mathrm{O}(\\log\\log n)\\) for decrease-key, and \\(\\mathrm{O}(1)\\) for all other heap operations, including insert and meld, where \\(n\\) is the number of heap items that are eventually deleted: Items inserted but never deleted do not count in the bounds. We also analyze the multipass pairing heap, a variant of pairing heaps. For this heap implementation, we obtain the same bounds except for decrease-key, for which our bound is \\(\\mathrm{O}(\\log\\log n\\cdot\\log\\log\\log n)\\) , where again items that are never deleted do not count in \\(n\\) . Our bounds significantly improve the best previously known bounds for all three data structures. For slim and smooth heaps our bounds are tight, since they match lower bounds of Iacono and Özkan [13].",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4405705692",
    "type": "article"
  },
  {
    "title": "Minimizing mean flow time for UET tasks",
    "doi": "https://doi.org/10.1145/1150334.1150340",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "Yumei Huo; Joseph Y.‐T. Leung",
    "corresponding_authors": "",
    "abstract": "We consider the problem of scheduling a set of n unit-execution-time (UET) tasks, with precedence constraints, on m ≥ 1 parallel and identical processors so as to minimize the mean flow time. For two processors, the Coffman--Graham algorithm gives a schedule that simultaneously minimizes the mean flow time and the makespan. The problem becomes strongly NP-hard for an arbitrary number of processors, although the complexity is not known for each fixed m ≥ 3. For arbitrary precedence constraints, we show that the Coffman--Graham algorithm gives a schedule with a worst-case bound no more than 2, and we give examples showing that the bound is tight. For intrees, the problem can be solved in polynomial time for each fixed m ≥ 1, although the complexity is not known for an arbitrary number of processors. We show that Hu's algorithm (which is optimal for the makespan objective) yields a schedule with a worst-case bound no more than 1.5, and we give examples showing that the ratio can approach 1.308999.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2086519761",
    "type": "article"
  },
  {
    "title": "An <i>O</i> ( <i>VE</i> ) algorithm for ear decompositions of matching-covered graphs",
    "doi": "https://doi.org/10.1145/1103963.1103969",
    "publication_date": "2005-10-01",
    "publication_year": 2005,
    "authors": "Marcelo H. de Carvalho; Joseph Cheriyan",
    "corresponding_authors": "",
    "abstract": "Our main result is an O(nm) -time (deterministic) algorithm for constructing an ear decomposition of a matching-covered graph, where n and m denote the number of nodes and edges. The improvement in the running time comes from new structural results that give a sharpened version of Lovász and Plummer's Two-Ear Theorem. Our algorithm is based on O(nm) -time algorithms for two other fundamental problems in matching theory, namely, finding all the allowed edges of a graph, and finding the canonical partition of an elementary graph. To the best of our knowledge, no faster deterministic algorithms are known for these two fundamental problems.",
    "cited_by_count": 6,
    "openalex_id": "https://openalex.org/W2170132163",
    "type": "article"
  },
  {
    "title": "Average-case lower bounds for the plurality problem",
    "doi": "https://doi.org/10.1145/1367064.1367067",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Laurent Alonso; Edward M. Reingold",
    "corresponding_authors": "",
    "abstract": "Given a set of n elements, each of which is colored one of c ≥ 2 colors, we have to determine an element of the plurality (most frequently occurring) color by pairwise equal/unequal color comparisons of elements. We derive lower bounds for the expected number of color comparisons when the c n colorings are equally probable. We prove a general lower bound of c /3 n − O (√ n ) for c ≥ 2; we prove the stronger particular bounds of 7/6 n − O (√ n ) for c = 3, 54/35 n − O (√ n ) for c = 4, 607/315 n − O (√ n ) for c = 5, 1592/693 n − O (√ n ) for c = 6, 7985/3003 n − O (√ n ) for c = 7, and 19402/6435 n − O (√ n ) for c = 8.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2000986517",
    "type": "article"
  },
  {
    "title": "Optimal parallel selection",
    "doi": "https://doi.org/10.1145/1290672.1290675",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Yijie Han",
    "corresponding_authors": "Yijie Han",
    "abstract": "We present an optimal parallel selection algorithm on the EREW PRAM. This algorithm runs in O (log n ) time with n /log n processors. This complexity matches the known lower bound for parallel selection on the EREW PRAM model. We therefore close this problem which has been open for more than a decade.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2068078228",
    "type": "article"
  },
  {
    "title": "Clustering, community partition and disjoint spanning trees",
    "doi": "https://doi.org/10.1145/1367064.1367075",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "Cun‐Quan Zhang; Yongbin Ou",
    "corresponding_authors": "",
    "abstract": "Clustering method is one of the most important tools in statistics. In a graph theory model, clustering is the process of finding all dense subgraphs. A mathematically well-defined measure for graph density is introduced in this article as follows. Let G = ( V , E ) be a graph (or multi-graph) and H be a subgraph of G . The dynamic density of H is the greatest integer k such that min ∀ P {| E ( H / P )|/| V ( H / P )| − 1} &gt; k where the minimum is taken over all possible partitions P of the vertex set of H , and H / P is the graph obtained from H by contracting each part of P into a single vertex. A subgraph H of G is a level- k community if H is a maximal subgraph of G with dynamic density at least k . An algorithm is designed in this paper to detect all level- h communities of an input multi-graph G . The worst-case complexity of this algorithm is upper bounded by O (| V ( G )| 2 h 2 ). This new method is one of few available clustering methods that are mathematically well-defined, supported by rigorous mathematical proof and able to achieve the optimization goal with polynomial complexity. As a byproduct, this algorithm also can be applied for finding edge-disjoint spanning trees of a multi-graph. The worst-case complexity is lower than all known algorithms for multi-graphs.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2074167246",
    "type": "article"
  },
  {
    "title": "Sharing the cost more efficiently",
    "doi": "https://doi.org/10.1145/1240233.1240246",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "Luca Becchetti; Jochen Könemann; Stefano Leonardi; M. Páal",
    "corresponding_authors": "",
    "abstract": "In the multicommodity rent-or-buy (MROB) network design problems, we are given a network together with a set of k terminal pairs ( s 1 , t 1 ), …, ( s k , t k . The goal is to provision the network so that a given amount of flow can be shipped between s i and t i for all 1 ≤ i ≤ k simultaneously. In order to provision the network, one can either rent capacity on edges at some cost per unit of flow, or buy them at some larger fixed cost. Bought edges have no incremental, flow-dependent cost. The overall objective is to minimize the total provisioning cost. Recently, Gupta et al. [2003a] presented a 12-approximation for the MROB problem. Their algroithm chooses a subset of the terminal pairs in the graph at random and then buys the edges of an approximate Steiner forest for these pairs. This technique had previously been introduced [Gupta et al. 2003b] for the single-sink rent-or-buy network design problem. In this article we give a 6.828-approximation for the MROB problem by refining the algorithm of Gupta et al. and simplifying their analysis. The improvement in our article is based on a more careful adaptation and simplified analysis of the primal-dual algorithm for the Steiner forest problem due to Agrawal et al. [1995]. Our result significantly reduces the gap between the single-sink and multisink case.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W2624136382",
    "type": "article"
  },
  {
    "title": "The Complexity of the Ideal Membership Problem for Constrained Problems Over the Boolean Domain",
    "doi": "https://doi.org/10.1145/3449350",
    "publication_date": "2021-10-04",
    "publication_year": 2021,
    "authors": "Monaldo Mastrolilli",
    "corresponding_authors": "Monaldo Mastrolilli",
    "abstract": "Given an ideal I and a polynomial f the Ideal Membership Problem (IMP) is to test if f ϵ I . This problem is a fundamental algorithmic problem with important applications and notoriously intractable. We study the complexity of the IMP for combinatorial ideals that arise from constrained problems over the Boolean domain. As our main result, we identify the borderline of tractability. By using Gröbner bases techniques, we extend Schaefer’s dichotomy theorem [STOC, 1978] which classifies all Constraint Satisfaction Problems (CSPs) over the Boolean domain to be either in P or NP-hard. Moreover, our result implies necessary and sufficient conditions for the efficient computation of Theta Body Semi-Definite Programming (SDP) relaxations, identifying therefore the borderline of tractability for constraint language problems. This article is motivated by the pursuit of understanding the recently raised issue of bit complexity of Sum-of-Squares (SoS) proofs [O’Donnell, ITCS, 2017]. Raghavendra and Weitz [ICALP, 2017] show how the IMP tractability for combinatorial ideals implies bounded coefficients in SoS proofs.",
    "cited_by_count": 5,
    "openalex_id": "https://openalex.org/W3203099067",
    "type": "article"
  },
  {
    "title": "Periodicity testing with sublinear samples and space",
    "doi": "https://doi.org/10.1145/1721837.1721859",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Funda Ergün; S. Muthukrishnan; Cenk Sahinalp",
    "corresponding_authors": "",
    "abstract": "In this work, we are interested in periodic trends in long data streams in the presence of computational constraints. To this end; we present algorithms for discovering periodic trends in the combinatorial property testing model in a data stream S of length n using o ( n ) samples and space. In accordance with the property testing model, we first explore the notion of being “close” to periodic by defining three different notions of self-distance through relaxing different notions of exact periodicity. An input S is then called approximately periodic if it exhibits a small self-distance (with respect to any one self-distance defined). We show that even though the different definitions of exact periodicity are equivalent, the resulting definitions of self-distance and approximate periodicity are not; we also show that these self-distances are constant approximations of each other. Afterwards, we present algorithms which distinguish between the two cases where S is exactly periodic and S is far from periodic with only a constant probability of error. Our algorithms sample only O (√ n log 2 n ) (or O (√ n log 4 n ), depending on the self-distance) positions and use as much space. They can also find, using o ( n ) samples and space, the largest/smallest period, and/or all of the approximate periods of S . These algorithms can also be viewed as working on streaming inputs where each data item is seen once and in order, storing only a sublinear ( O (√ n log 2 n ) or O (√ n log 4 n )) size sample from which periodicities are identified.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W1973767581",
    "type": "article"
  },
  {
    "title": "Updating relaxed <i>K</i> -d trees",
    "doi": "https://doi.org/10.1145/1644015.1644019",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Amalia Duch; Conrado Martı́nez",
    "corresponding_authors": "",
    "abstract": "In this work we present an in-depth study of randomized relaxed K -d trees. It covers two fundamental aspects: the randomized algorithms that allow to preserve the random properties of relaxed K -d trees and the mathematical analysis of the expected performance of these algorithms. In particular, we describe randomized update algorithms for K -d trees based on the split and join algorithms of Duch et al. [1998]. We carry out an analysis of the expected cost of all these algorithms, using analytic combinatorics techniques. We show that the average cost of split and join is of the form ζ( K ) ⋅ n ϕ( K ) + o ( n ϕ( K ) ), with 1 ≤ ϕ( K ) &lt; 1.561552813, and we give explicit formulæ for both ζ( K ) and ϕ( K ). These results on the average performance of split and join imply that the expected cost of an insertion or a deletion is Θ( n ϕ( K )−1 ) when K &gt; 2 and Θ(log n ) for K = 2.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2044340625",
    "type": "article"
  },
  {
    "title": "Competitive weighted throughput analysis of greedy protocols on DAGs",
    "doi": "https://doi.org/10.1145/1798596.1798603",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Eyal Gordon; Adi Rosén",
    "corresponding_authors": "",
    "abstract": "The combination of the buffer sizes of routers deployed in the Internet, and the Internet traffic itself, leads routinely to the dropping of packets. Motivated by this, we are interested in the problem of maximizing the throughput of protocols that control packet networks. Moreover, we are interested in a setting where different packets have different priorities (or weights), thus taking into account Quality-of-Service considerations. We first extend the Competitive Network Throughput (CNT) model introduced by Aiello et al. [2003] to the weighted packets case. We analyze the performance of online, local-control protocols by their competitive ratio, in the face of arbitrary traffic, using as a measure the total weight of the packets that arrive to their destinations, rather than being dropped en-route. We prove that on Directed Acyclic Graphs (DAGs), any greedy protocol is competitive, with competitive ratio independent of the weights of the packets. Here we mean by a “greedy protocol” a protocol that not only does not leave a resource idle unnecessarily, but also prefers packets with higher weight over those with lower weight. We give two independent upper bounds on the competitive ratio of general greedy protocols on DAGs. We further give lower bounds that show that our upper bounds cannot be improved (other than constant factors) in the general case. Both our upper and lower bounds apply also to the unweighted case, and they improve the results given in Aiello et al. [2003] for that case. We thus give tight (up to constant factors) upper and lower bounds for both the unweighted and weighted cases. In the course of proving our upper bounds we prove a lemma that gives upper bounds on the delivery times of packets by any greedy protocol on general DAGs (without buffer size considerations). We believe that this lemma may be of independent interest and may find additional applications.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2090278743",
    "type": "article"
  },
  {
    "title": "Linear time 3-approximation for the MAST problem",
    "doi": "https://doi.org/10.1145/1497290.1497299",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Vincent Berry; Christophe Paul; Sylvain Guillemot; François Nicolas",
    "corresponding_authors": "",
    "abstract": "Given a set of leaf-labeled trees with identical leaf sets, the well-known Maximum Agreement SubTree (MAST) problem consists in finding a subtree homeomorphically included in all input trees and with the largest number of leaves. MAST and its variant called Maximum Compatible Tree (MCT) are of particular interest in computational biology. This article presents a linear-time approximation algorithm to solve the complement version of MAST, namely identifying the smallest set of leaves to remove from input trees to obtain isomorphic trees. We also present an O ( n 2 + kn ) algorithm to solve the complement version of MCT. For both problems, we thus achieve significantly lower running times than previously known algorithms. Fast running times are especially important in phylogenetics where large collections of trees are routinely produced by resampling procedures, such as the nonparametric bootstrap or Bayesian MCMC methods.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2138780502",
    "type": "article"
  },
  {
    "title": "On the bichromatic <i>k</i> -set problem",
    "doi": "https://doi.org/10.1145/1824777.1824782",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Timothy M. Chan",
    "corresponding_authors": "Timothy M. Chan",
    "abstract": "We study a bichromatic version of the well-known k-set problem : given two sets R and B of points of total size n and an integer k , how many subsets of the form (R ∩ h ) ∪ ( B ∖ h ) can have size exactly k over all halfspaces h ? In the dual, the problem is asymptotically equivalent to determining the worst-case combinatorial complexity of the k-level in an arrangement of n halfspaces . Disproving an earlier conjecture by Linhart [1993], we present the first nontrivial upper bound for all k ≪ n in two dimensions: O ( nk 1/3 + n 5/6−ϵ k 2/3+2 ϵ + k 2 ) for any fixed ϵ&lt;0. In three dimensions, we obtain the bound O ( nk 3/2 + n 0.5034 k 2.4932 + k 3 ). Incidentally, this also implies a new upper bound for the original k -set problem in four dimensions: O ( n 2 k 3/2 + n 1.5034 k 2.4932 + n k 3 ), which improves the best previous result for all k ≪ n 0.923 . Extensions to other cases, such as arrangements of disks, are also discussed.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2148015778",
    "type": "article"
  },
  {
    "title": "Sublinear-Time Maintenance of Breadth-First Spanning Trees in Partially Dynamic Networks",
    "doi": "https://doi.org/10.1145/3146550",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Monika Henzinger; Sebastian Krinninger; Danupon Nanongkai",
    "corresponding_authors": "",
    "abstract": "We study the problem of maintaining a breadth-first spanning tree (BFS tree) in partially dynamic distributed networks modeling a sequence of either failures or additions of communication links (but not both). We present deterministic (1+ϵ)-approximation algorithms whose amortized time (over some number of link changes) is sublinear in D , the maximum diameter of the network. Our technique also leads to a deterministic (1+ϵ)-approximate incremental algorithm for single-source shortest paths in the sequential (usual RAM) model. Prior to our work, the state of the art was the classic exact algorithm of Even and Shiloach (1981), which is optimal under some assumptions (Roditty and Zwick 2011; Henzinger et al. 2015). Our result is the first to show that, in the incremental setting, this bound can be beaten in certain cases if some approximation is allowed.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W24636605",
    "type": "article"
  },
  {
    "title": "Toward Optimal Self-Adjusting Heaps",
    "doi": "https://doi.org/10.1145/3147138",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Amr Elmasry",
    "corresponding_authors": "Amr Elmasry",
    "abstract": "We give a variant of the pairing heaps that achieves the following amortized costs: O (1) per find-min and insert , O (log log n ) per decrease-key and meld , O (log n ) per delete-min ; where n is the number of elements in the resulting heap on which the operation is performed. These bounds are the best known for any self-adjusting heap and match two lower bounds, one established by Fredman and the other by Iacono and Özkan, for a family of self-adjusting heaps that generalizes the pairing heaps but do not include our variant. We further show how to reduce the amortized cost for meld to be paid by the other operations, on the expense of increasing that of delete-min to O (log n + log log N ), where N is the total number of elements in the collection of heaps of the data structure (not just the heap under consideration by the operation).",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2769587183",
    "type": "article"
  },
  {
    "title": "Binary Adder Circuits of Asymptotically Minimum Depth, Linear Size, and Fan-Out Two",
    "doi": "https://doi.org/10.1145/3147215",
    "publication_date": "2017-12-14",
    "publication_year": 2017,
    "authors": "Stephan Held; Sophie Spirkl",
    "corresponding_authors": "",
    "abstract": "We consider the problem of constructing fast and small binary adder circuits. Among widely used adders, the Kogge-Stone adder is often considered the fastest, because it computes the carry bits for two n -bit numbers (where n is a power of two) with a depth of 2 log 2 n logic gates, size 4 n log 2 n , and all fan-outs bounded by two. Fan-outs of more than two are disadvantageous in practice, because they lead to the insertion of repeaters for repowering the signal and additional depth in the physical implementation. However, the depth bound of the Kogge-Stone adder is off by a factor of two from the lower bound of log 2 n . Two separate constructions by Brent and Krapchenko achieve this lower bound asymptotically. Brent’s construction gives neither a bound on the fan-out nor the size, while Krapchenko’s adder has linear size, but can have up to linear fan-out. With a fan-out bound of two, neither construction achieves a depth of less than 2 log 2 n . In a further approach, Brent and Kung proposed an adder with linear size and fan-out two but twice the depth of the Kogge-Stone adder. These results are 33–43 years old and no substantial theoretical improvement for has been made since then. In this article, we integrate the individual advantages of all previous adder circuits into a new family of full adders, the first to improve on the depth bound of 2 log 2 n while maintaining a fan-out bound of two. Our adders achieve an asymptotically optimum logic gate depth of log 2 n + o (log 2 n ) and linear size O ( n ).",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2963891047",
    "type": "article"
  },
  {
    "title": "The Parametric Closure Problem",
    "doi": "https://doi.org/10.1145/3147212",
    "publication_date": "2017-12-06",
    "publication_year": 2017,
    "authors": "David Eppstein",
    "corresponding_authors": "David Eppstein",
    "abstract": "We define the parametric closure problem, in which the input is a partially ordered set whose elements have linearly varying weights and the goal is to compute the sequence of minimum-weight lower sets of the partial order as the weights vary. We give polynomial time solutions to many important special cases of this problem including semiorders, reachability orders of bounded-treewidth graphs, partial orders of bounded width, and series-parallel partial orders. Our result for series-parallel orders provides a significant generalization of a previous result of Carlson and Eppstein on bicriterion subtree problems.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3121954179",
    "type": "article"
  },
  {
    "title": "Squarepants in a tree",
    "doi": "https://doi.org/10.1145/1541885.1541890",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "David Eppstein",
    "corresponding_authors": "David Eppstein",
    "abstract": "We provide efficient constant factor approximation algorithms for the problems of finding a hierarchical clustering of a point set in any metric space, minimizing the sum of minimimum spanning tree lengths within each cluster, and in the hyperbolic or Euclidean planes, minimizing the sum of cluster perimeters. Our algorithms for the hyperbolic and Euclidean planes can also be used to provide a pants decomposition, that is, a set of disjoint simple closed curves partitioning the plane minus the input points into subsets with exactly three boundary components, with approximately minimum total length. In the Euclidean case, these curves are squares; in the hyperbolic case, they combine our Euclidean square pants decomposition with our tree clustering method for general metric spaces.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4300193727",
    "type": "article"
  },
  {
    "title": "Maximizing the Minimum Load for Random Processing Times",
    "doi": "https://doi.org/10.1145/2651421",
    "publication_date": "2015-01-13",
    "publication_year": 2015,
    "authors": "Stefanie Gerke; Κωνσταντίνος Παναγιώτου; Justus Schwartz; Angelika Steger",
    "corresponding_authors": "",
    "abstract": "In this article, we consider a stochastic variant of the so-called Santa Claus problem. The Santa Claus problem is equivalent to the problem of scheduling a set of n jobs on m parallel machines without preemption, so as to maximize the minimum load. We consider the identical machine version of this scheduling problem with the additional restriction that the scheduler has only a guess of the processing times; that is, the processing time of a job is a random variable . We show that there is a critical value ρ ( n,m ) such that if the duration of the jobs is exponentially distributed and the expected values deviate by less than a multiplicative factor of ρ ( n,m ) from each other, then a greedy algorithm has an expected competitive ratio arbitrarily close to one; that is, it performs in expectation almost as good as an algorithm that knows the actual values in advance . On the other hand, if the expected values deviate by more than a multiplicative factor of ρ ( n,m ), then the expected performance is arbitrarily bad for all algorithms.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2005075659",
    "type": "article"
  },
  {
    "title": "Time Complexity of Link Reversal Routing",
    "doi": "https://doi.org/10.1145/2644815",
    "publication_date": "2015-01-13",
    "publication_year": 2015,
    "authors": "Bernadette Charron-Bost; Matthias Függer; Jennifer L. Welch; Josef Widder",
    "corresponding_authors": "",
    "abstract": "Link reversal is a versatile algorithm design paradigm, originally proposed by Gafni and Bertsekas in 1981 for routing and subsequently applied to other problems including mutual exclusion, leader election, and resource allocation. Although these algorithms are well known, until now there have been only preliminary results on time complexity, even for the simplest link reversal algorithm for routing, called Full Reversal. In Full Reversal, a sink reverses all its incident links, whereas in other link reversal algorithms (e.g., Partial Reversal), a sink reverses only some of its incident links. Charron-Bost et al. introduced a generalization, called LR, that includes Full and Partial Reversal as special cases. In this article, we present an exact expression for the time complexity of LR. The expression is stated in terms of simple properties of the initial graph. The result specializes to exact formulas for the time complexity of any node in any initial acyclic directed graph for both Full and Partial Reversal. Having the exact formulas provides insight into the behavior of Full and Partial Reversal on specific graph families. Our first technical insight is to describe the behavior of Full Reversal as a dynamical system and to observe that this system is linear in min-plus algebra. Our second technical insight is to overcome the difficulty posed by the fact that LR is not linear by transforming every execution of LR from an initial graph into an execution of Full Reversal from a different initial graph while maintaining the execution's work and time complexity.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2031202715",
    "type": "article"
  },
  {
    "title": "Dynamic Ray Stabbing",
    "doi": "https://doi.org/10.1145/2559153",
    "publication_date": "2014-10-30",
    "publication_year": 2014,
    "authors": "Yufei Tao",
    "corresponding_authors": "Yufei Tao",
    "abstract": "We consider maintaining a dynamic set S of N horizontal segments in ℝ 2 such that, given a vertical ray Q in ℝ 2 , the segments in S intersecting Q can be reported efficiently. In the external memory model, we give a structure that consumes O ( N / B ) space, answers a query in O (log B N + K / B ) time (where K is the number of reported segments), and can be updated in O (log B N ) amortized time per insertion and deletion. With B set to a constant, the structure also works in internal memory, consuming space O ( N ), answering a query in O (log N + K ) time, and supporting an update in O (log N ) amortized time.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2079685181",
    "type": "article"
  },
  {
    "title": "Price-based protocols for fair resource allocation",
    "doi": "https://doi.org/10.1145/2556949",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "Ashish Goel; Hamid Nazerzadeh",
    "corresponding_authors": "",
    "abstract": "We analyze several distributed, continuous time protocols for a fair allocation of bandwidths to flows in a network (or resources to agents). Our protocols converge to an allocation that is a logarithmic approximation, simultaneously, to all canonical social welfare functions (i.e., functions that are symmetric, concave, and nondecreasing). These protocols can be started in an arbitrary state. Although a similar protocol was known before, it only applied to the simple bandwidth allocation problem, and its stability and convergence time were not understood. In contrast, our protocols also apply to the more general case of Leontief utilities, where each user may place a different requirement on each resource. Furthermore, we prove that our protocols converge in polynomial time. The best convergence time we prove is O ( n log nc MAX a MAX / c MIN a MIN ), where n is the number of agents in the network, c MAX and c MIN are the maximum and minimum capacity of the links, and a max , a min are respectively the largest and smallest Leontief coefficients. This time is achieved by a simple Multiplicative Increase, Multiplicative Decrease (MIMD) protocol that had not been studied before in this setting. We also identify combinatorial properties of these protocols that may be useful in proving stronger convergence bounds. The final allocations by our protocols are supported by usage-sensitive dual prices that are fair in the sense that they shield light users of a resource from the impact of heavy users. Thus, our protocols can also be thought of as efficient distributed schemes for computing fair prices.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2098772063",
    "type": "article"
  },
  {
    "title": "Scale-Free Compact Routing Schemes in Networks of Low Doubling Dimension",
    "doi": "https://doi.org/10.1145/2876055",
    "publication_date": "2016-06-15",
    "publication_year": 2016,
    "authors": "Goran Konjevod; Andréa W. Richa; Donglin Xia",
    "corresponding_authors": "",
    "abstract": "We consider compact routing schemes in networks of low doubling dimension, where the doubling dimension is the least value α such that any ball in the network can be covered by at most 2 α balls of half radius. There are two variants of routing-scheme design: (i) labeled (name-dependent) routing, in which the designer is allowed to rename the nodes so that the names (labels) can contain additional routing information, for example, topological information; and (ii) name-independent routing, which works on top of the arbitrary original node names in the network, that is, the node names are independent of the routing scheme. In this article, given any constant ϵ ∈ (0, 1) and an n -node edge-weighted network of doubling dimension α ∈ O (loglog n ), we present —a (1 + ϵ)-stretch labeled compact routing scheme with ⌈log n ⌉-bit routing labels, O (log 2 n /loglog n )-bit packet headers, and ((1/ϵ) O (α) log 3 n )-bit routing information at each node; —a (9 + ϵ)-stretch name-independent compact routing scheme with O (log 2 n /loglog n )-bit packet headers, and ((1/ϵ) O (α) log 3 n )-bit routing information at each node. In addition, we prove a lower bound: any name-independent routing scheme with o ( n (ϵ/60) 2 ) bits of storage at each node has stretch no less than 9 − ϵ for any ϵ ∈ (0, 8). Therefore, our name-independent routing scheme achieves asymptotically optimal stretch with polylogarithmic storage at each node and packet headers. Note that both schemes are scale-free in the sense that their space requirements do not depend on the normalized diameter Δ of the network. We also present a simpler nonscale-free (9 + ϵ)-stretch name-independent compact routing scheme with improved space requirements if Δ is polynomial in n .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2621619537",
    "type": "article"
  },
  {
    "title": "Computing the Distance between Piecewise-Linear Bivariate Functions",
    "doi": "https://doi.org/10.1145/2847257",
    "publication_date": "2016-02-08",
    "publication_year": 2016,
    "authors": "Guillaume Moroz; Boris Aronov",
    "corresponding_authors": "",
    "abstract": "We consider the problem of computing the distance between two piecewise-linear bivariate functions f and g defined over a common domain M , induced by the L 2 norm—that is, ‖ f - g ‖2 = √∫ M ( f - g ) 2 . If f is defined by linear interpolation over a triangulation of M with n triangles and g is defined over another such triangulation, the obvious naive algorithm requires Θ( n 2 ) arithmetic operations to compute this distance. We show that it is possible to compute it in O ( n log 4 n log log n ) arithmetic operations by reducing the problem to multipoint evaluation of a certain type of polynomials. We also present several generalizations and an application to terrain matching.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3162131094",
    "type": "article"
  },
  {
    "title": "Popular Matchings with One-Sided Bias",
    "doi": "https://doi.org/10.1145/3638764",
    "publication_date": "2023-12-27",
    "publication_year": 2023,
    "authors": "Telikepalli Kavitha",
    "corresponding_authors": "Telikepalli Kavitha",
    "abstract": "Let G = (A ∪ B, E) be a bipartite graph where the set A consists of agents or main players and the set B consists of jobs or secondary players. Every vertex in A ∪ B has a strict ranking of its neighbors. A matching M is popular if for any matching N , the number of vertices that prefer M to N is at least the number that prefer N to M . Popular matchings always exist in G since every stable matching is popular. A matching M is A -popular if for any matching N , the number of agents (i.e., vertices in A ) that prefer M to N is at least the number of agents that prefer N to M . Unlike popular matchings, A -popular matchings need not exist in a given instance G and there is a simple linear time algorithm to decide if G admits an A -popular matching and compute one, if so. We consider the problem of deciding if G admits a matching that is both popular and A -popular and finding one, if so. We call such matchings fully popular . A fully popular matching is useful when A is the more important side—so along with overall popularity, we would like to maintain “popularity within the set A ”. A fully popular matching is not necessarily a min-size/max-size popular matching and all known polynomial-time algorithms for popular matching problems compute either min-size or max-size popular matchings. Here we show a linear time algorithm for the fully popular matching problem, thus our result shows a new tractable subclass of popular matchings.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3038030638",
    "type": "article"
  },
  {
    "title": "Synchronized Planarity with Applications to Constrained Planarity Problems",
    "doi": "https://doi.org/10.1145/3607474",
    "publication_date": "2023-08-03",
    "publication_year": 2023,
    "authors": "Thomas Bläsius; Simon D. Fink; Ignaz Rutter",
    "corresponding_authors": "",
    "abstract": "We introduce the problem S ynchronized P lanarity . Roughly speaking, its input is a loop-free multi-graph together with synchronization constraints that, e.g., match pairs of vertices of equal degree by providing a bijection between their edges. S ynchronized P lanarity then asks whether the graph admits a crossing-free embedding into the plane such that the orders of edges around synchronized vertices are consistent. We show, on the one hand, that S ynchronized P lanarity can be solved in quadratic time, and, on the other hand, that it serves as a powerful modeling language that lets us easily formulate several constrained planarity problems as instances of S ynchronized P lanarity . In particular, this lets us solve C lustered P lanarity in quadratic time, where the most efficient previously known algorithm has an upper bound of O ( n 8 ).",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3045874352",
    "type": "article"
  },
  {
    "title": "Genome Assembly, from Practice to Theory: Safe, Complete and <i>Linear-Time</i>",
    "doi": "https://doi.org/10.1145/3632176",
    "publication_date": "2023-11-08",
    "publication_year": 2023,
    "authors": "Massimo Cairo; Roméo Rizzi; Alexandru I. Tomescu; Elia C. Zirondelli",
    "corresponding_authors": "",
    "abstract": "Genome assembly asks to reconstruct an unknown string from many shorter substrings of it. Even though it is one of the key problems in Bioinformatics, it is generally lacking major theoretical advances. Its hardness stems both from practical issues (size and errors of real data), and from the fact that problem formulations inherently admit multiple solutions. Given these, at their core, most state-of-the-art assemblers are based on finding non-branching paths ( unitigs ) in an assembly graph. While such paths constitute only partial assemblies, they are likely to be correct. More precisely, if one defines a genome assembly solution as a closed arc-covering walk of the graph, then unitigs appear in all solutions, being thus safe partial solutions. Until recently, it was open what are all the safe walks of an assembly graph. Tomescu and Medvedev (RECOMB 2016) characterized all such safe walks ( omnitigs ), thus giving the first safe and complete genome assembly algorithm. Even though maximal omnitig finding was later improved to quadratic time by Cairo et al. (ACM Trans. Algorithms 2019), it remained open whether the crucial linear-time feature of finding unitigs can be attained with omnitigs. We answer this question affirmatively, by describing a surprising O(m) -time algorithm to identify all maximal omnitigs of a graph with n nodes and m arcs, notwithstanding the existence of families of graphs with Θ (mn) total maximal omnitig size. This is based on the discovery of a family of walks ( macrotigs ) with the property that all the non-trivial omnitigs are univocal extensions of subwalks of a macrotig. This has two consequences: (1) A linear-time output-sensitive algorithm enumerating all maximal omnitigs. (2) A compact O(m) representation of all maximal omnitigs, which allows, e.g., for O(m) -time computation of various statistics on them. Our results close a long-standing theoretical question inspired by practical genome assemblers, originating with the use of unitigs in 1995. We envision our results to be at the core of a reverse transfer from theory to practical and complete genome assembly programs, as has been the case for other key Bioinformatics problems.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3104459592",
    "type": "article"
  },
  {
    "title": "An Improved Algorithm for The <i>k</i> -Dyck Edit Distance Problem",
    "doi": "https://doi.org/10.1145/3627539",
    "publication_date": "2023-10-19",
    "publication_year": 2023,
    "authors": "Dvir Fried; Shay Golan; Tomasz Kociumaka; Tsvi Kopelowitz; Ely Porat; Tatiana Starikovskaya",
    "corresponding_authors": "",
    "abstract": "A Dyck sequence is a sequence of opening and closing parentheses (of various types) that is balanced. The Dyck edit distance of a given sequence of parentheses S is the smallest number of edit operations (insertions, deletions, and substitutions) needed to transform S into a Dyck sequence. We consider the threshold Dyck edit distance problem, where the input is a sequence of parentheses S and a positive integer k , and the goal is to compute the Dyck edit distance of S only if the distance is at most k , and otherwise report that the distance is larger than k . Backurs and Onak [PODS’16] showed that the threshold Dyck edit distance problem can be solved in O ( n + k 16 ) time. In this work, we design new algorithms for the threshold Dyck edit distance problem which costs O ( n + k 4.544184 ) time with high probability or O ( n + k 4.853059 ) deterministically. Our algorithms combine several new structural properties of the Dyck edit distance problem, a refined algorithm for fast (min, +) matrix product, and a careful modification of ideas used in Valiant’s parsing algorithm.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3208093996",
    "type": "article"
  },
  {
    "title": "Almost-Optimal Deterministic Treasure Hunt in Unweighted Graphs",
    "doi": "https://doi.org/10.1145/3588437",
    "publication_date": "2023-03-18",
    "publication_year": 2023,
    "authors": "Sébastien Bouchard; Yoann Dieudonné; Arnaud Labourel; Andrzej Pelc",
    "corresponding_authors": "",
    "abstract": "A mobile agent navigating along edges of a simple connected unweighted graph, either finite or countably infinite, has to find an inert target (treasure) hidden in one of the nodes. This task is known as treasure hunt. The agent has no a priori knowledge of the graph, of the location of the treasure, or of the initial distance to it. The cost of a treasure hunt algorithm is the worst-case number of edge traversals performed by the agent until finding the treasure. Awerbuch et al. [ 3 ] considered graph exploration and treasure hunt for finite graphs in a restricted model where the agent has a fuel tank that can be replenished only at the starting node s . The size of the tank is B = 2 (1+α) r , for some positive real constant α, where r , called the radius of the graph, is the maximum distance from s to any other node. The tank of size B allows the agent to make at most ⌊ B ⌋ edge traversals between two consecutive visits at node s . Let e(d) be the number of edges whose at least one endpoint is at distance less than d from s . Awerbuch et al. [ 3 ] conjectured that it is impossible to find a treasure hidden in a node at distance at most d at cost nearly linear in e(d) . We first design a deterministic treasure hunt algorithm working in the model without any restrictions on the moves of the agent at cost 𝒪(e(d) log d ) and then show how to modify this algorithm to work in the model from Awerbuch et al. [ 3 ] with the same complexity. Thus, we refute the preceding 20-year-old conjecture. We observe that no treasure hunt algorithm can beat cost Θ ( e(d) ) for all graphs, and thus our algorithms are also almost optimal.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4327814720",
    "type": "article"
  },
  {
    "title": "Hopcroft’s Problem, Log* Shaving, Two-dimensional Fractional Cascading, and Decision Trees",
    "doi": "https://doi.org/10.1145/3591357",
    "publication_date": "2023-04-11",
    "publication_year": 2023,
    "authors": "Timothy M. Chan; Da Wei Zheng",
    "corresponding_authors": "",
    "abstract": "We revisit Hopcroft’s problem and related fundamental problems about geometric range searching. Given n points and n lines in the plane, we show how to count the number of point-line incidence pairs or the number of point-above-line pairs in O ( n 4/3 ) time, which matches the conjectured lower bound and improves the best previous time bound of \\(n^{4/3}2^{O(\\log ^*n)}\\) obtained almost 30 years ago by Matoušek [ 58 ]. We describe two interesting and different ways to achieve the result: The first is randomized and uses a new two-dimensional version of fractional cascading for arrangements of lines; the second is deterministic and uses decision trees in a manner inspired by the sorting technique of Fredman [42]. The second approach extends to any constant dimension. Many consequences follow from these new ideas: For example, we obtain an O ( n 4/3 )-time algorithm for line segment intersection counting in the plane, O ( n 4/3 )-time randomized algorithms for distance selection in the plane and bichromatic closest pair and Euclidean minimum spanning tree in three or four dimensions, and a randomized data structure for halfplane range counting in the plane with O ( n 4/3 ) preprocessing time and space and \\(O(n^{1/3})\\) query time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4364361917",
    "type": "article"
  },
  {
    "title": "Near-Optimal Time–Energy Tradeoffs for Deterministic Leader Election",
    "doi": "https://doi.org/10.1145/3614429",
    "publication_date": "2023-08-10",
    "publication_year": 2023,
    "authors": "Yi‐Jun Chang; Ran Duan; Shunhua Jiang",
    "corresponding_authors": "",
    "abstract": "We consider the energy complexity of the leader election problem in the single-hop radio network model, where each device v has a unique identifier ID ( v ) ∈{ 1, 2, ⋖ , N } . Energy is a scarce resource for small battery-powered devices. For such devices, most of the energy is often spent on communication, not on computation. To approximate the actual energy cost, the energy complexity of an algorithm is defined as the maximum over all devices of the number of time slots where the device transmits or listens. Much progress has been made in understanding the energy complexity of leader election in radio networks, but very little is known about the tradeoff between time and energy. Chang et al. [STOC 2017] showed that the optimal deterministic energy complexity of leader election is Θ (log log N ) if each device can simultaneously transmit and listen but still leaving the problem of determining the optimal time complexity under any given energy constraint. Time–energy tradeoff: For any k ≥ log log N , we show that a leader among at most n devices can be elected deterministically in O ( k ċ n 1+ε ) + O ( k ċ N 1/k ) time and O ( k ) energy if each device can simultaneously transmit and listen, where ε &gt; 0 is any small constant. This improves upon the previous O ( N )-time O (log log N )-energy algorithm by Chang et al. [STOC 2017]. We provide lower bounds to show that the time–energy tradeoff of our algorithm is near-optimal. Dense instances: For the dense instances where the number of devices is n = Θ ( N ), we design a deterministic leader election algorithm using only O (1) energy. This improves upon the O (log* N )-energy algorithm by Jurdziński, Kutyłowski, and Zatopiański [PODC 2002] and the O (α ( N ))-energy algorithm by Chang et al. [STOC 2017]. More specifically, we show that the optimal deterministic energy complexity of leader election is \\(\\Theta (\\max \\lbrace 1, \\log \\tfrac{N}{n}\\rbrace)\\) if each device cannot simultaneously transmit and listen, and it is \\(&amp;#x0398; (\\max \\lbrace 1, \\log \\log \\tfrac{N}{n}\\rbrace)\\) if each device can simultaneously transmit and listen.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4385720197",
    "type": "article"
  },
  {
    "title": "A Cubic Algorithm for Computing the Hermite Normal Form of a Nonsingular Integer Matrix",
    "doi": "https://doi.org/10.1145/3617996",
    "publication_date": "2023-08-31",
    "publication_year": 2023,
    "authors": "Stavros Birmpilis; George Labahn; Arne Storjohann",
    "corresponding_authors": "",
    "abstract": "A Las Vegas randomized algorithm is given to compute the Hermite normal form of a nonsingular integer matrix A of dimension n . The algorithm uses quadratic integer multiplication and cubic matrix multiplication and has running time bounded by O(n 3 (log n + log ||A||) 2 (log n ) 2 ) bit operations, where || A ||= max ij | A ij | denotes the largest entry of A in absolute value. A variant of the algorithm that uses pseudo-linear integer multiplication is given that has running time (n 3 log || A ||) 1+ o (1) bit operations, where the exponent “ + o (1)” captures additional factors c 1 (log n ) c2 (loglog|| A ||) c3 for positive real constants c 1 ,c 2 ,c 3 .",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4386326626",
    "type": "article"
  },
  {
    "title": "On the External Validity of Average-Case Analyses of Graph Algorithms",
    "doi": "https://doi.org/10.1145/3633778",
    "publication_date": "2023-11-23",
    "publication_year": 2023,
    "authors": "Thomas Bläsius; Philipp Fischbeck",
    "corresponding_authors": "",
    "abstract": "The number one criticism of average-case analysis is that we do not actually know the probability distribution of real-world inputs. Thus, analyzing an algorithm on some random model has no implications for practical performance. At its core, this criticism doubts the existence of external validity , i.e., it assumes that algorithmic behavior on the somewhat simple and clean models does not translate beyond the models to practical performance real-world input. With this paper, we provide a first step towards studying the question of external validity systematically. To this end, we evaluate the performance of six graph algorithms on a collection of 2740 sparse real-world networks depending on two properties; the heterogeneity (variance in the degree distribution) and locality (tendency of edges to connect vertices that are already close). We compare this with the performance on generated networks with varying locality and heterogeneity. We find that the performance in the idealized setting of network models translates surprisingly well to real-world networks. Moreover, heterogeneity and locality appear to be the core properties impacting the performance of many graph algorithms.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4388941623",
    "type": "article"
  },
  {
    "title": "On an infinite family of solvable Hanoi graphs",
    "doi": "https://doi.org/10.1145/1435375.1435388",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "Dany Azriel; Noam Solomon; Shay Solomon",
    "corresponding_authors": "",
    "abstract": "The Tower of Hanoi problem is generalized by placing pegs on the vertices of a given directed graph G with two distinguished vertices, S and D , and allowing moves only along arcs of this graph. An optimal solution for such a graph G is an algorithm that completes the task of moving a tower of any given number of disks from S to D in a minimal number of disk moves. In this article we present an algorithm which solves the problem for two infinite families of graphs, and prove its optimality. To the best of our knowledge, this is the first optimality proof for an infinite family of graphs. Furthermore, we present a unified algorithm that solves the problem for a wider family of graphs and conjecture its optimality.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2105476091",
    "type": "article"
  },
  {
    "title": "Improved algorithms for optimal embeddings",
    "doi": "https://doi.org/10.1145/1383369.1383376",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Nishanth Chandran; Ryan Moriarty; Rafail Ostrovsky; Omkant Pandey; Mohammad Ali Safari; Amit Sahai",
    "corresponding_authors": "",
    "abstract": "In the last decade, the notion of metric embeddings with small distortion has received wide attention in the literature, with applications in combinatorial optimization, discrete mathematics, and bio-informatics. The notion of embedding is, given two metric spaces on the same number of points, to find a bijection that minimizes maximum Lipschitz and bi-Lipschitz constants. One reason for the popularity of the notion is that algorithms designed for one metric space can be applied to a different one, given an embedding with small distortion. The better distortion, the better the effectiveness of the original algorithm applied to a new metric space. The goal recently studied by Kenyon et al. [2004] is to consider all possible embeddings between two finite metric spaces and to find the best possible one; that is, consider a single objective function over the space of all possible embeddings that minimizes the distortion. In this article we continue this important direction. In particular, using a theorem of Albert and Atkinson [2005], we are able to provide an algorithm to find the optimal bijection between two line metrics, provided that the optimal distortion is smaller than 13.602. This improves the previous bound of 3 + 2√2, solving an open question posed by Kenyon et al. [2004]. Further, we show an inherent limitation of algorithms using the “forbidden pattern” based dynamic programming approach, in that they cannot find optimal mapping if the optimal distortion is more than 7 + 4√3 (≃ 13.928). Thus, our results are almost optimal for this method. We also show that previous techniques for general embeddings apply to a (slightly) more general class of metrics.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2169779606",
    "type": "article"
  },
  {
    "title": "Tight Space Bounds for Two-Dimensional Approximate Range Counting",
    "doi": "https://doi.org/10.1145/3205454",
    "publication_date": "2018-04-30",
    "publication_year": 2018,
    "authors": "Zhewei Wei; Ke Yi",
    "corresponding_authors": "",
    "abstract": "We study the problem of two-dimensional orthogonal range counting with additive error. Given a set P of n points drawn from an n × n grid and an error parameter ε, the goal is to build a data structure, such that for any orthogonal range R , it can return the number of points in P ∩ R with additive error ε n . A well-known solution for this problem is obtained by using ε-approximation , which is a subset A ⊆ P that can estimate the number of points in P ∩ R with the number of points in A ∩ R . It is known that an ε-approximation of size O (1/ε log 2.5 1/ε) exists for any P with respect to orthogonal ranges, and the best lower bound is Ω(1/ε log 1/ε). The ε-approximation is a rather restricted data structure, as we are not allowed to store any information other than the coordinates of the points. In this article, we explore what can be achieved without any restriction on the data structure. We first describe a simple data structure that uses O (1/ε(log 2 1/ε + log n )) bits and answers queries with error ε n . We then prove a lower bound that any data structure that answers queries with error ε n will have to use Ω(1/ε (log 2 1/ε + log n )) bits. Our lower bound is information-theoretic: We show that there is a collection of 2 Ω ( n log n ) point sets with large union combinatorial discrepancy and thus are hard to distinguish unless we use Ω( n log n ) bits.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2806847441",
    "type": "article"
  },
  {
    "title": "Improved Analysis of Deterministic Load-Balancing Schemes",
    "doi": "https://doi.org/10.1145/3282435",
    "publication_date": "2018-11-16",
    "publication_year": 2018,
    "authors": "Petra Berenbrink; Ralf Klasing; Adrian Kosowski; Frederik Mallmann-Trenn; Przemysław Uznański",
    "corresponding_authors": "",
    "abstract": "We consider the problem of deterministic load balancing of tokens in the discrete model. A set of n processors is connected into a d -regular undirected network. In every timestep, each processor exchanges some of its tokens with each of its neighbors in the network. The goal is to minimize the discrepancy between the number of tokens on the most-loaded and the least-loaded processor as quickly as possible. In this work, we identify some natural conditions on deterministic load-balancing algorithms to improve upon the long-standing results of Rabani et al. (1998). Specifically, we introduce the notion of cumulatively fair load-balancing algorithms where in any interval of consecutive timesteps, the total number of tokens sent out over an edge by a node is the same (up to constants) for all adjacent edges. We prove that algorithms that are cumulatively fair and where every node retains a sufficient part of its load in each step, achieve a discrepancy of O ( d min { √ log n /μ,√ n }) in time O ( T ), where μ is the spectral gap of the transition matrix of the graph. We also show that, in general, neither of these assumptions may be omitted without increasing discrepancy. We then show, by a combinatorial potential reduction argument, that any cumulatively fair scheme satisfying some additional assumptions achieves a discrepancy of O ( d ) almost as quickly as the continuous diffusion process. This positive result applies to some of the simplest and most natural discrete load balancing schemes.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2901559723",
    "type": "article"
  },
  {
    "title": "Even Delta-Matroids and the Complexity of Planar Boolean CSPs",
    "doi": "https://doi.org/10.1145/3230649",
    "publication_date": "2018-12-07",
    "publication_year": 2018,
    "authors": "Alexandr Kazda; Vladimir Kolmogorov; Michal Rolínek",
    "corresponding_authors": "",
    "abstract": "The main result of this article is a generalization of the classical blossom algorithm for finding perfect matchings. Our algorithm can efficiently solve Boolean CSPs where each variable appears in exactly two constraints (we call it edge CSP) and all constraints are even Δ-matroid relations (represented by lists of tuples). As a consequence of this, we settle the complexity classification of planar Boolean CSPs started by Dvořák and Kupec. Using a reduction to even Δ-matroids, we then extend the tractability result to larger classes of Δ-matroids that we call efficiently coverable . It properly includes classes that were known to be tractable before, namely, co-independent , compact , local , linear , and binary , with the following caveat: We represent Δ-matroids by lists of tuples, while the last two use a representation by matrices. Since an n × n matrix can represent exponentially many tuples, our tractability result is not strictly stronger than the known algorithm for linear and binary Δ-matroids.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2904289608",
    "type": "article"
  },
  {
    "title": "Sparse Approximation via Generating Point Sets",
    "doi": "https://doi.org/10.1145/3302249",
    "publication_date": "2019-06-12",
    "publication_year": 2019,
    "authors": "Avrim Blum; Sariel Har-Peled; Benjamin Raichel",
    "corresponding_authors": "",
    "abstract": "For a set P of n points in the unit ball b⊆ R d , consider the problem of finding a small subset T ⊆ P such that its convex-hull ε-approximates the convex-hull of the original set. Specifically, the Hausdorff distance between the convex hull of T and the convex hull of P should be at most ε. We present an efficient algorithm to compute such an ε′-approximation of size k alg , where ε ′ is a function of ε and k alg is a function of the minimum size k opt of such an ε-approximation. Surprisingly, there is no dependence on the dimension d in either of the bounds. Furthermore, every point of P can be ε-approximated by a convex-combination of points of T that is O (1/ε 2 )-sparse. Our result can be viewed as a method for sparse, convex autoencoding: approximately representing the data in a compact way using sparse combinations of a small subset T of the original data. The new algorithm can be kernelized, and it preserves sparsity in the original input.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2953276104",
    "type": "article"
  },
  {
    "title": "Exploring the Complexity of Layout Parameters in Tournaments and Semicomplete Digraphs",
    "doi": "https://doi.org/10.1145/3196276",
    "publication_date": "2018-06-27",
    "publication_year": 2018,
    "authors": "Florian Barbero; Christophe Paul; Michał Pilipczuk",
    "corresponding_authors": "",
    "abstract": "A simple digraph is semicomplete if for any two of its vertices u and v , at least one of the arcs ( u , v ) and ( v , u ) is present. We study the complexity of computing two layout parameters of semicomplete digraphs: cutwidth and optimal linear arrangement (O la ). We prove the following: • Both parameters are NP-hard to compute and the known exact and parameterized algorithms for them have essentially optimal running times, assuming the Exponential Time Hypothesis. • The cutwidth parameter admits a quadratic Turing kernel, whereas it does not admit any polynomial kernel unless NP ⊆ coNP/poly. By contrast, O la admits a linear kernel. These results essentially complete the complexity analysis of computing cutwidth and O la on semicomplete digraphs (with respect to standard parameters). Our techniques also can be used to analyze the sizes of minimal obstructions for having a small cutwidth under the induced subdigraph relation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2963055638",
    "type": "article"
  },
  {
    "title": "Spanning Circuits in Regular Matroids",
    "doi": "https://doi.org/10.1145/3355629",
    "publication_date": "2019-10-04",
    "publication_year": 2019,
    "authors": "Fedor V. Fomin; Petr A. Golovach; Daniel Lokshtanov; Saket Saurabh",
    "corresponding_authors": "",
    "abstract": "We consider the fundamental Matroid Theory problem of finding a circuit in a matroid containing a set T of given terminal elements. For graphic matroids, this corresponds to the problem of finding a simple cycle passing through a set of given terminal edges in a graph. The algorithmic study of the problem on regular matroids, a superclass of graphic matroids, was initiated by Gavenčiak, Král’, and Oum [ICALP’12], who proved that the case of the problem with ∣T∣ = 2 is fixed-parameter tractable (FPT) when parameterized by the length of the circuit. We extend the result of Gavenčiak, Král’, and Oum by showing that for regular matroids • the M inimum S panning C ircuit problem, deciding whether there is a circuit with at most ℓ elements containing T , is FPT parameterized by k = ℓ − ∣T∣ • the S panning C ircuit problem, deciding whether there is a circuit containing ∣T∣, is FPT parameterized by ∣T∣. We note that extending our algorithmic findings to binary matroids, a superclass of regular matroids, is highly unlikely: M inimum S panning C ircuit parameterized by ℓ is W[1]-hard on binary matroids even when ∣T∣ = 1. We also show a limit to how far our results can be strengthened by considering a smaller parameter. More precisely, we prove that M inimum S panning C ircuit parameterized by ∣T∣ is W[1]-hard even on cographic matroids, a proper subclass of regular matroids.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2979548720",
    "type": "article"
  },
  {
    "title": "Algorithms to Approximate Column-sparse Packing Problems",
    "doi": "https://doi.org/10.1145/3355400",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Brian Brubach; Karthik Abinav Sankararaman; Aravind Srinivasan; Pan Xu",
    "corresponding_authors": "",
    "abstract": "Column-sparse packing problems arise in several contexts in both deterministic and stochastic discrete optimization. We present two unifying ideas, (non-uniform) attenuation and multiple-chance algorithms , to obtain improved approximation algorithms for some well-known families of such problems. As three main examples, we attain the integrality gap, up to lower-order terms, for known LP relaxations for k -column-sparse packing integer programs (Bansal et al., Theory of Computing , 2012) and stochastic k -set packing (Bansal et al., Algorithmica , 2012), and go “half the remaining distance” to optimal for a major integrality-gap conjecture of Füredi, Kahn, and Seymour on hypergraph matching ( Combinatorica , 1993).",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2986071419",
    "type": "article"
  },
  {
    "title": "Lower Bounds for the Parameterized Complexity of Minimum Fill-in and Other Completion Problems",
    "doi": "https://doi.org/10.1145/3381426",
    "publication_date": "2020-03-11",
    "publication_year": 2020,
    "authors": "Ivan Bliznets; Marek Cygan; Paweł Komosa; Michał Pilipczuk; Lukáš Mach",
    "corresponding_authors": "",
    "abstract": "In this work, we focus on several completion problems for subclasses of chordal graphs: M INIMUM F ILL -I N , I NTERVAL C OMPLETION , P ROPER I NTERVAL C OMPLETION , T RIVIALLY P ERFECT C OMPLETION , and T HRESHOLD C OMPLETION . In these problems, the task is to add at most k edges to a given graph to obtain a chordal, interval, proper interval, threshold, or trivially perfect graph, respectively. We prove the following lower bounds for all these problems, as well as for the related C HAIN C OMPLETION problem: • Assuming the Exponential Time Hypothesis, none of these problems can be solved in time 2 O ( n 1/2 /log c n ) or 2 O ( k 1/4 /log c k )· n O (1) , for some integer c . • Assuming the non-existence of a subexponential-time approximation scheme for M IN B ISECTION on d -regular graphs, for some constant d , none of these problems can be solved in time 2 o ( n ) or 2 o √k) }· n O (1) . For all the aforementioned completion problems, apart from P ROPER I NTERVAL C OMPLETION , FPT algorithms with running time of the form 2 O (√ k log k ) · n O (1) are known. Thus, the second result proves that a significant improvement of any of these algorithms would lead to a surprising breakthrough in the design of approximation algorithms for M IN B ISECTION . To prove our results, we use a reduction methodology based on combining the classic approach of starting with a sparse instance of 3-S AT , prepared using the Sparsification Lemma, with the existence of almost linear-size Probabilistically Checkable Proofs. Apart from our main results, we also obtain lower bounds excluding the existence of subexponential algorithms for the O PTIMUM L INEAR A RRANGEMENT problem, as well as improved, yet still not tight, lower bounds for F EEDBACK A RC S ET IN T OURNAMENTS .",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3011735201",
    "type": "article"
  },
  {
    "title": "A PTAS for Euclidean TSP with Hyperplane Neighborhoods",
    "doi": "https://doi.org/10.1145/3383466",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Antonios Antoniadis; Krzysztof Fleszar; Ruben Hoeksma; Kevin Schewior",
    "corresponding_authors": "",
    "abstract": "In the Traveling Salesperson Problem with Neighborhoods (TSPN), we are given a collection of geometric regions in some space. The goal is to output a tour of minimum length that visits at least one point in each region. Even in the Euclidean plane, TSPN is known to be APX-hard [27{, which gives rise to studying more tractable special cases of the problem. In this article, we focus on the fundamental special case of regions that are hyperplanes in the d -dimensional Euclidean space. This case contrasts the much-better understood case of so-called fat regions [20, 40{. While for d = 2, an exact algorithm with a running time of O(n 5 ) is known [34{, settling the exact approximability of the problem for d = 3 has been repeatedly posed as an open question [29, 30, 40, 47{. To date, only an approximation algorithm with guarantee exponential in d is known [30{, and NP-hardness remains open. For arbitrary fixed d , we develop a Polynomial Time Approximation Scheme (PTAS) that works for both the tour and path version of the problem. Our algorithm is based on approximating the convex hull of an optimal tour by a convex polytope of bounded complexity. After enumerating a number of structural properties of these polytopes, a linear program finds one of them that minimizes the length of the tour. As the approximation guarantee approaches 1, our scheme adjusts the complexity of the considered polytopes accordingly. In the analysis of our approximation scheme, we show that our search space includes a sufficiently good approximation of the optimum. To do so, we develop a novel and general sparsification technique that transforms an arbitrary convex polytope into one with a constant number of vertices, and, subsequently, into one of bounded complexity in the above sense. We show that this transformation does not increase the tour length by too much, while the transformed tour visits any hyperplane that it visited before the transformation.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3033574327",
    "type": "article"
  },
  {
    "title": "Approximating Spanners and Directed Steiner Forest",
    "doi": "https://doi.org/10.1145/3381451",
    "publication_date": "2020-06-12",
    "publication_year": 2020,
    "authors": "Eden Chlamtáč; Michael Dinitz; Guy Kortsarz; Bundit Laekhanukit",
    "corresponding_authors": "",
    "abstract": "It was recently found that there are very close connections between the existence of additive spanners (subgraphs where all distances are preserved up to an additive stretch), distance preservers (subgraphs in which demand pairs have their distance preserved exactly), and pairwise spanners (subgraphs in which demand pairs have their distance preserved up to a multiplicative or additive stretch) [Abboud-Bodwin SODA’16 8 J.ACM’17, Bodwin-Williams SODA’16]. We study these problems from an optimization point of view, where rather than studying the existence of extremal instances, we are given an instance and are asked to find the sparsest possible spanner/preserver. We give an O ( n 3/5 + ε )-approximation for distance preservers and pairwise spanners (for arbitrary constant ε &gt; 0). This is the first nontrivial upper bound for either problem, both of which are known to be as hard to approximate as Label Cover. We also prove Label Cover hardness for approximating additive spanners, even for the cases of additive 1 stretch (where one might expect a polylogarithmic approximation, since the related multiplicative 2-spanner problem admits an O (log n )-approximation) and additive polylogarithmic stretch (where the related multiplicative spanner problem has an O (1)-approximation). Interestingly, the techniques we use in our approximation algorithm extend beyond distance-based problem to pure connectivity network design problems. In particular, our techniques allow us to give an O ( n 3/5 + ε )-approximation for the Directed Steiner Forest problem (for arbitrary constant ε &gt; 0) when all edges have uniform costs, improving the previous best O ( n 2/3 + ε )-approximation due to Berman et al. [ICALP’11] (which holds for general edge costs).",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3035713054",
    "type": "article"
  },
  {
    "title": "Optimal Substring Equality Queries with Applications to Sparse Text Indexing",
    "doi": "https://doi.org/10.1145/3426870",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Nicola Prezza",
    "corresponding_authors": "Nicola Prezza",
    "abstract": "We consider the problem of encoding a string of length n from an integer alphabet of size σ so access , substring equality , and Longest Common Extension (LCE) queries can be answered efficiently. We describe a new space-optimal data structure supporting logarithmic-time queries. Access and substring equality query times can furthermore be improved to the optimal O (1) if O (log n ) additional precomputed words are allowed in the total space. Additionally, we provide in-place algorithms for converting between the string and our data structure. Using this new string representation, we obtain the first in-place subquadratic algorithms for several string-processing problems in the restore model: The input string is rewritable and must be restored before the computation terminates. In particular, we describe the first in-place subquadratic Monte Carlo solutions to the sparse suffix sorting, sparse LCP array construction, and suffix selection problems. With the sole exception of suffix selection, our algorithms are also the first running in sublinear time for small enough sets of input suffixes. Combining these solutions, we obtain the first sublinear-time Monte Carlo algorithm for building the sparse suffix tree in compact space. We also show how to build a correct version of our data structure using small working space. This leads to the first Las Vegas in-place algorithm computing the full LCP array in O ( n log n ) time w.h.p. and to the first Las Vegas in-place algorithms solving the sparse suffix sorting and sparse LCP array construction problems in O ( n 1.5 √ log σ) time w.h.p.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3116090636",
    "type": "article"
  },
  {
    "title": "Perfect Phylogenies via Branchings in Acyclic Digraphs and a Generalization of Dilworth’s Theorem",
    "doi": "https://doi.org/10.1145/3182178",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Ademir Hujdurović; Edin Husić; Martin Milanič; Roméo Rizzi; Alexandru I. Tomescu",
    "corresponding_authors": "",
    "abstract": "Motivated by applications in cancer genomics and following the work of Hajirasouliha and Raphael (WABI 2014), Hujdurović et al. (IEEE TCBB, 2018) introduced the minimum conflict-free row split (MCRS) problem: split each row of a given binary matrix into a bitwise OR of a set of rows so that the resulting matrix corresponds to a perfect phylogeny and has the minimum possible number of rows among all matrices with this property. Hajirasouliha and Raphael also proposed the study of a similar problem, in which the task is to minimize the number of distinct rows of the resulting matrix. Hujdurović et al. proved that both problems are NP-hard, gave a related characterization of transitively orientable graphs, and proposed a polynomial-time heuristic algorithm for the MCRS problem based on coloring cocomparability graphs. We give new, more transparent formulations of the two problems, showing that the problems are equivalent to two optimization problems on branchings in a derived directed acyclic graph. Building on these formulations, we obtain new results on the two problems, including (1) a strengthening of the heuristic by Hujdurović et al. via a new min-max result in digraphs generalizing Dilworth’s theorem, which may be of independent interest; (2) APX-hardness results for both problems; (3) approximation algorithms; and (4) exponential-time algorithms solving the two problems to optimality faster than the naïve brute-force approach. Our work relates to several well-studied notions in combinatorial optimization: chain partitions in partially ordered sets, laminar hypergraphs, and (classical and weighted) colorings of graphs.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3123103866",
    "type": "article"
  },
  {
    "title": "An improved algorithm for radio broadcast",
    "doi": "https://doi.org/10.1145/1219944.1219954",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Michael Elkin; Guy Kortsarz",
    "corresponding_authors": "",
    "abstract": "We show that for every radio network G = (V, E) and source s ∈ V, there exists a radio broadcast schedule for G of length Rad(G, s) + O(√Rad(G, s) ⋅log2 n) = O(Rad(G, s) + log4 n), where Rad(G, s) is the radius of the radio network G with respect to the source s. This result improves the previously best-known upper bound of O(Rad(G, s) + log5 n) due to Gaber and Mansour [1995].",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W4238190226",
    "type": "article"
  },
  {
    "title": "Tight approximation algorithms for scheduling with fixed jobs and nonavailability",
    "doi": "https://doi.org/10.1145/2229163.2229171",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Florian Diedrich; Klaus Jansen; Lars Prädel; Ulrich M. Schwarz; Ola Svensson",
    "corresponding_authors": "",
    "abstract": "We study two closely related problems in nonpreemptive scheduling of jobs on identical parallel machines. In these two settings there are either fixed jobs or nonavailability intervals during which the machines are not available; in both cases, the objective is to minimize the makespan. Both formulations have different applications, for example, in turnaround scheduling or overlay computing. For both problems we contribute approximation algorithms with an improved ratio of 3/2. For scheduling with fixed jobs, a lower bound of 3/2 on the approximation ratio has been obtained by Scharbrodt et al. [1999]; for scheduling with nonavailability we provide the same lower bound. We use dual approximation, creation of a gap structure, and a PTAS for the multiple subset sum problem, combined with a postprocessing step to assign large jobs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2015796751",
    "type": "article"
  },
  {
    "title": "Dotted interval graphs",
    "doi": "https://doi.org/10.1145/2151171.2151172",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "Yonatan Aumann; Moshe Lewenstein; Oren Melamud; Ron Y. Pinter; Zohar Yakhini",
    "corresponding_authors": "",
    "abstract": "We introduce a generalization of interval graphs, which we call Dotted Interval Graphs (DIG). A dotted interval graph is an intersection graph of arithmetic progressions (dotted intervals). Coloring of dotted interval graphs naturally arises in the context of high throughput genotyping. We study the properties of dotted interval graphs, with a focus on coloring. We show that any graph is a DIG, but that DIG d graphs, that is, DIGs in which the arithmetic progressions have a jump of at most d , form a strict hierarchy. We show that coloring DIG d graphs is NP-complete even for d = 2. For any fixed d , we provide a 5/6 d + o ( d ) approximation for the coloring of DIG d graphs. Finally, we show that finding the maximal clique in DIG d graphs is fixed parameter tractable in d .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2042686731",
    "type": "article"
  },
  {
    "title": "Sum edge coloring of multigraphs via configuration LP",
    "doi": "https://doi.org/10.1145/1921659.1921668",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Magnús M. Halldórsson; Guy Kortsarz; Maxim Sviridenko",
    "corresponding_authors": "",
    "abstract": "We consider the scheduling of biprocessor jobs under sum objective (BPSMSM). Given a collection of unit-length jobs where each job requires the use of two processors, find a schedule such that no two jobs involving the same processor run concurrently. The objective is to minimize the sum of the completion times of the jobs. Equivalently, we would like to find a sum edge coloring of a given multigraph, that is, a partition of its edge set into matchings M 1 ,…, M t minimizing Σ i =1 t i | M i |. This problem is APX-hard, even in the case of bipartite graphs [Marx 2009]. This special case is closely related to the classic open shop scheduling problem. We give a 1.8298-approximation algorithm for BPSMSM improving the previously best ratio known of 2 [Bar-Noy et al. 1998]. The algorithm combines a configuration LP with greedy methods, using nonstandard randomized rounding on the LP fractions. We also give an efficient combinatorial 1.8886-approximation algorithm for the case of simple graphs, which gives an improved 1.79568 + O (log d¯/d¯)-approximation in graphs of large average degree d¯.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2075580456",
    "type": "article"
  },
  {
    "title": "Improved Fixed-Parameter Algorithms for Minimum-Flip Consensus Trees",
    "doi": "https://doi.org/10.1145/2071379.2071386",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "Sebastian Böcker; Quang Bao Anh Bui; Anke Truß",
    "corresponding_authors": "",
    "abstract": "In computational phylogenetics, the problem of constructing a consensus tree for a given set of rooted input trees has frequently been addressed. In this article we study the Minimum-Flip Problem : the input trees are transformed into a binary matrix, and we want to find a perfect phylogeny for this matrix using a minimum number of flips, that is, corrections of single entries in the matrix. The graph-theoretical formulation of the problem is as follows: Given a bipartite graph G = ( Vt ∪ Vc , E ), the task is to find a minimum set of edge modifications such that the resulting graph has no induced path with four edges that starts and ends in Vt , where Vt corresponds to the taxa set and Vc corresponds to the character set. We present two fixed-parameter algorithms for the Minimum-Flip Problem , one with running time O (4.83 k + poly ( m , n )) and another one with running time O (4.42 k + poly ( m , n )) for n taxa, m characters, k flips, and poly ( m , n ) denotes a polynomial function in m and n . Additionally, we discuss several heuristic improvements. We also report computational results on phylogenetic data.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2089357212",
    "type": "article"
  },
  {
    "title": "Finding a Shortest Odd Hole",
    "doi": "https://doi.org/10.1145/3447869",
    "publication_date": "2021-04-19",
    "publication_year": 2021,
    "authors": "Maria Chudnovsky; Alex Scott; Paul Seymour",
    "corresponding_authors": "",
    "abstract": "An odd hole in a graph is an induced cycle with odd length greater than 3. In an earlier paper (with Sophie Spirkl), solving a longstanding open problem, we gave a polynomial-time algorithm to test if a graph has an odd hole. We subsequently showed that, for every t , there is a polynomial-time algorithm to test whether a graph contains an odd hole of length at least t . In this article, we give an algorithm that finds a shortest odd hole, if one exists.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3156929411",
    "type": "article"
  },
  {
    "title": "Navigating in Trees with Permanently Noisy Advice",
    "doi": "https://doi.org/10.1145/3448305",
    "publication_date": "2021-04-30",
    "publication_year": 2021,
    "authors": "Lucas Boczkowski; Uriel Feige; Amos Korman; Yoav Rodeh",
    "corresponding_authors": "",
    "abstract": "We consider a search problem on trees in which an agent starts at the root of a tree and aims to locate an adversarially placed treasure, by moving along the edges, while relying on local, partial information. Specifically, each node in the tree holds a pointer to one of its neighbors, termed advice . A node is faulty with probability q . The advice at a non-faulty node points to the neighbor that is closer to the treasure, and the advice at a faulty node points to a uniformly random neighbor. Crucially, the advice is permanent , in the sense that querying the same node again would yield the same answer. Let Δ denote the maximum degree. For the expected number of moves (edge traversals) until finding the treasure, we show that a phase transition occurs when the noise parameter q is roughly 1 √Δ. Below the threshold, there exists an algorithm with expected number of moves O ( D √Δ), where D is the depth of the treasure, whereas above the threshold, every search algorithm has an expected number of moves, which is both exponential in D and polynomial in the number of nodes n . In contrast, if we require to find the treasure with probability at least 1 − δ, then for every fixed ɛ &gt; 0, if q &lt; 1/Δ ɛ , then there exists a search strategy that with probability 1 − δ finds the treasure using (Δ −1 D ) O (1/ε) moves. Moreover, we show that (Δ −1 D ) Ω(1/ε) moves are necessary.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3168067270",
    "type": "article"
  },
  {
    "title": "Improving the Smoothed Complexity of FLIP for Max Cut Problems",
    "doi": "https://doi.org/10.1145/3454125",
    "publication_date": "2021-07-15",
    "publication_year": 2021,
    "authors": "Ali Bibak; Charles Carlson; Karthekeyan Chandrasekaran",
    "corresponding_authors": "",
    "abstract": "Finding locally optimal solutions for MAX-CUT and MAX- k -CUT are well-known PLS-complete problems. An instinctive approach to finding such a locally optimum solution is the FLIP method. Even though FLIP requires exponential time in worst-case instances, it tends to terminate quickly in practical instances. To explain this discrepancy, the run-time of FLIP has been studied in the smoothed complexity framework. Etscheid and Röglin (ACM Transactions on Algorithms, 2017) showed that the smoothed complexity of FLIP for max-cut in arbitrary graphs is quasi-polynomial. Angel, Bubeck, Peres, and Wei (STOC, 2017) showed that the smoothed complexity of FLIP for max-cut in complete graphs is ( O Φ 5 n 15.1 ), where Φ is an upper bound on the random edge-weight density and Φ is the number of vertices in the input graph. While Angel, Bubeck, Peres, and Wei’s result showed the first polynomial smoothed complexity, they also conjectured that their run-time bound is far from optimal. In this work, we make substantial progress toward improving the run-time bound. We prove that the smoothed complexity of FLIP for max-cut in complete graphs is O (Φ n 7.83 ). Our results are based on a carefully chosen matrix whose rank captures the run-time of the method along with improved rank bounds for this matrix and an improved union bound based on this matrix. In addition, our techniques provide a general framework for analyzing FLIP in the smoothed framework. We illustrate this general framework by showing that the smoothed complexity of FLIP for MAX-3-CUT in complete graphs is polynomial and for MAX - k - CUT in arbitrary graphs is quasi-polynomial. We believe that our techniques should also be of interest toward showing smoothed polynomial complexity of FLIP for MAX - k - CUT in complete graphs for larger constants k .",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W3185749561",
    "type": "article"
  },
  {
    "title": "Approximating corridors and tours via restriction and relaxation techniques",
    "doi": "https://doi.org/10.1145/1798596.1798609",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "Arturo González-Gutiérrez; Teofilo F. Gonzalez",
    "corresponding_authors": "",
    "abstract": "Given a rectangular boundary partitioned into rectangles, the Minimum-Length Corridor (MLC-R) problem consists of finding a corridor of least total length. A corridor is a set of connected line segments, each of which must lie along the line segments that form the rectangular boundary and/or the boundary of the rectangles, and must include at least one point from the boundary of every rectangle and from the rectangular boundary. The MLC-R problem is known to be NP-hard. We present the first polynomial-time constant ratio approximation algorithm for the MLC-R and MLC k problems. The MLC k problem is a generalization of the MLC-R problem where the rectangles are rectilinear c -gons, for c ≤ k and k is a constant. We also present the first polynomial-time constant ratio approximation algorithm for the Group Traveling Salesperson Problem (GTSP) for a rectangular boundary partitioned into rectilinear c -gons as in the MLC k problem. Our algorithms are based on the restriction and relaxation approximation techniques.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1978064083",
    "type": "article"
  },
  {
    "title": "Quantum algorithms for Simon's problem over nonabelian groups",
    "doi": "https://doi.org/10.1145/1644015.1644034",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Gorjan Alagic; Cristopher Moore; Alexander Russell",
    "corresponding_authors": "",
    "abstract": "Daniel Simon's 1994 discovery of an efficient quantum algorithm for finding “hidden shifts” of Z 2 n provided the first algebraic problem for which quantum computers are exponentially faster than their classical counterparts. In this article, we study the generalization of Simon's problem to arbitrary groups. Fixing a finite group G , this is the problem of recovering an involution m = ( m 1 ,…, m n ) ∈ G n from an oracle f with the property that f ( x ⋅ y ) = f ( x ) ⇔ y ∈ {1, m }. In the current parlance, this is the hidden subgroup problem (HSP) over groups of the form G n , where G is a nonabelian group of constant size, and where the hidden subgroup is either trivial or has order two. Although groups of the form G n have a simple product structure, they share important representation--theoretic properties with the symmetric groups S n , where a solution to the HSP would yield a quantum algorithm for Graph Isomorphism. In particular, solving their HSP with the so-called “standard method” requires highly entangled measurements on the tensor product of many coset states. In this article, we provide quantum algorithms with time complexity 2 O (√ n ) that recover hidden involutions m = ( m 1 ,… m n ) ∈ G n where, as in Simon's problem, each m i is either the identity or the conjugate of a known element m which satisfies κ( m ) = −κ(1) for some κ ∈ Ĝ . Our approach combines the general idea behind Kuperberg's sieve for dihedral groups with the “missing harmonic” approach of Moore and Russell. These are the first nontrivial HSP algorithms for group families that require highly entangled multiregister Fourier sampling.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1987091447",
    "type": "article"
  },
  {
    "title": "A generalized minimum cost <i>k</i> -clustering",
    "doi": "https://doi.org/10.1145/1597036.1597039",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Asaf Levin",
    "corresponding_authors": "Asaf Levin",
    "abstract": "We consider the problems of set partitioning into k clusters with minimum total cost and minimum of the maximum cost of a cluster. The cost function is given by an oracle, and we assume that it satisfies some natural structural constraints. That is, we assume that the cost function is monotone, the cost of a singleton is zero, and we assume that for all S ∩ S′ ≠ ∅ the following holds c ( S ) + c ( S ′) ≥ c ( S ∪ S ′). For the problem of minimizing the maximum cost of a cluster we present a (2 k − 1)-approximation algorithm for k ≥ 3, a 2-approximation algorithm for k = 2, and we also show a lower bound of k on the performance guarantee of any polynomial-time algorithm. For the problem of minimizing the total cost of all the clusters, we present a 2-approximation algorithm for the case where k is a fixed constant, a (4 k − 3)-approximation where k is unbounded, and we show a lower bound of 2 on the approximation ratio of any polynomial-time algorithm. Our lower bounds do not depend on the common assumption that P ≠ NP .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W1989610002",
    "type": "article"
  },
  {
    "title": "Efficient algorithms for the 2-gathering problem",
    "doi": "https://doi.org/10.1145/1721837.1721850",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Alon Shalita; Uri Zwick",
    "corresponding_authors": "",
    "abstract": "Pebbles are placed on some vertices of a directed graph. Is it possible to move each pebble along at most one edge of the graph so that in the final configuration no pebble is left on its own? We give an O ( mn )-time algorithm for solving this problem, which we call the 2-gathering problem, where n is the number of vertices and m is the number of edges of the graph. If such a 2-gathering is not possible, the algorithm finds a solution that minimizes the number of solitary pebbles. The 2-gathering problem forms a nontrivial generalization of the nonbipartite matching problem and it is solved by extending the augmenting paths technique used to solve matching problems.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2074392665",
    "type": "article"
  },
  {
    "title": "Inverse auctions",
    "doi": "https://doi.org/10.1145/1644015.1644036",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "F. Thomas Bruss; Guy Louchard; Mark Daniel Ward",
    "corresponding_authors": "",
    "abstract": "We consider auctions in which the winning bid is the smallest bid that is unique. Only the upper-price limit is given. Neither the number of participants nor the distribution of the offers are known, so that the problem of placing a bid to win with maximum probability looks, a priori, ill-posed. Indeed, the essence of the problem is to inject a (final) minimum into a random subset (of unique offers) of a larger random set. We will see, however, that here no more than two external (and almost compelling) arguments make the problem meaningful. By appropriately modeling the relationship between the number of participants and the distribution of the bids, we can then maximize our chances of winning the auction and propose a computable algorithm for placing our bid.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2090173294",
    "type": "article"
  },
  {
    "title": "Tolerant Testers of Image Properties",
    "doi": "https://doi.org/10.1145/3531527",
    "publication_date": "2022-05-10",
    "publication_year": 2022,
    "authors": "Piotr Berman; Meiram Murzabulatov; Sofya Raskhodnikova",
    "corresponding_authors": "",
    "abstract": "We initiate a systematic study of tolerant testers of image properties or, equivalently, algorithms that approximate the distance from a given image to the desired property. Image processing is a particularly compelling area of applications for sublinear-time algorithms and, specifically, property testing. However, for testing algorithms to reach their full potential in image processing, they have to be tolerant, which allows them to be resilient to noise. We design efficient approximation algorithms for the following fundamental questions: What fraction of pixels have to be changed in an image so it becomes a half-plane? A representation of a convex object? A representation of a connected object? More precisely, our algorithms approximate the distance to three basic properties (being a half-plane, convexity, and connectedness) within a small additive error ε, after reading poly (1/ε) pixels, independent of the image size. We also design an efficient agnostic proper PAC learner of convex sets (continuous and discrete) in two dimensions under the uniform distribution. Our algorithms require very simple access to the input: uniform random samples for the half-plane property and convexity, and samples from uniformly random blocks for connectedness. However, the analysis of the algorithms, especially for convexity, requires many geometric and combinatorial insights. For example, in the analysis of the algorithm for convexity, we define a set of reference polygons P ε such that (1) every convex image has a nearby polygon in P ε and (2) one can use dynamic programming to quickly compute the smallest empirical distance to a polygon in P ε .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2515390721",
    "type": "article"
  },
  {
    "title": "A Fast and Simple Surface Reconstruction Algorithm",
    "doi": "https://doi.org/10.1145/3039242",
    "publication_date": "2017-03-10",
    "publication_year": 2017,
    "authors": "Siu-Wing Cheng; Jiongxin Jin; Man-Kit Lau",
    "corresponding_authors": "",
    "abstract": "We present an algorithm for surface reconstruction from a point cloud. It runs in O ( n log n ) time, where n is the number of sample points, and this is optimal in the pointer machine model. The only existing O ( n log n )-time algorithm is due to Funke and Ramos, and it uses some sophisticated data structures. The key task is to extract a locally uniform subsample from the input points. Our algorithm is much simpler and it is based on a variant of the standard octree. We built a prototype that runs an implementation of our algorithm to extract a locally uniform subsample, invokes Cocone to reconstruct a surface from the subsample, and adds back the sample points absent from the subsample via edge flips. In our experiments with some nonuniform samples, the subsample extraction step is fast and effective, and the prototype gives a 51% to 68% speedup over using Cocone alone. The prototype also runs faster on locally uniform samples.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2596145574",
    "type": "article"
  },
  {
    "title": "Tight Bounds on Vertex Connectivity Under Sampling",
    "doi": "https://doi.org/10.1145/3086465",
    "publication_date": "2017-04-30",
    "publication_year": 2017,
    "authors": "Keren Censor-Hillel; Mohsen Ghaffari; George Giakkoupis; Bernhard Haeupler; Fabian Kühn",
    "corresponding_authors": "",
    "abstract": "A fundamental result by Karger [10] states that for any λ-edge-connected graph with n nodes, independently sampling each edge with probability p = Ω(log ( n )/λ) results in a graph that has edge connectivity Ω(λ p ), with high probability. This article proves the analogous result for vertex connectivity, when either vertices or edges are sampled. We show that for any k -vertex-connected graph G with n nodes, if each node is independently sampled with probability p =Ω(√log( n )/ k ), then the subgraph induced by the sampled nodes has vertex connectivity Ω( kp 2 ), with high probability. If edges are sampled with probability p = Ω(log ( n )/ k ), then the sampled subgraph has vertex connectivity Ω( kp ), with high probability. Both bounds are existentially optimal.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2619418495",
    "type": "article"
  },
  {
    "title": "Competitive Algorithms for Generalized <i>k</i> -Server in Uniform Metrics",
    "doi": "https://doi.org/10.1145/3568677",
    "publication_date": "2022-12-13",
    "publication_year": 2022,
    "authors": "Nikhil Bansal; Marek Eliáš; Grigorios Koumoutsos; Jesper Nederlof",
    "corresponding_authors": "",
    "abstract": "The generalized k -server problem is a far-reaching extension of the k -server problem with several applications. Here, each server s i lies in its own metric space M i . A request is a k -tuple r = ( r 1 , r 2 ,… , r k , which is served by moving some server s i to the point r i ∈ M i , and the goal is to minimize the total distance traveled by the servers. Despite much work, no f ( k )-competitive algorithm is known for the problem for k &gt; 2 servers, even for special cases such as uniform metrics and lines. Here, we consider the problem in uniform metrics and give the first f ( k )-competitive algorithms for general k . In particular, we obtain deterministic and randomized algorithms with competitive ratio k · 2 k and O ( k 3 log k ), respectively. Our deterministic bound is based on a novel application of the polynomial method to online algorithms, and essentially matches the long-known lower bound of 2 k -1. We also give a 2 2 O(k) -competitive deterministic algorithm for weighted uniform metrics, which also essentially matches the recent doubly exponential lower bound for the problem.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2735399061",
    "type": "article"
  },
  {
    "title": "Exact Distance Oracles for Planar Graphs with Failing Vertices",
    "doi": "https://doi.org/10.1145/3511541",
    "publication_date": "2022-02-08",
    "publication_year": 2022,
    "authors": "Panagiotis Charalampopoulos; Shay Mozes; Benjamin Tebeka",
    "corresponding_authors": "",
    "abstract": "We consider exact distance oracles for directed weighted planar graphs in the presence of failing vertices. Given a source vertex u , a target vertex v and a set X of k failed vertices, such an oracle returns the length of a shortest u -to- v path that avoids all vertices in X . We propose oracles that can handle any number k of failures. We show several tradeoffs between space, query time, and preprocessing time. In particular, for a directed weighted planar graph with n vertices and any constant k , we show an Õ( n )-size, Õ(√ n )-query-time oracle. 1 We then present a space vs. query time tradeoff: for any q ε [ 1,√ n ], we propose an oracle of size n k+1+o(1) / q 2k that answers queries in Õ( q ) time. For single vertex failures ( k = 1), our n 2+o(1) / q 2 -size, Õ( q )-query-time oracle improves over the previously best known tradeoff of Baswana et al. SODA 2012 by polynomial factors for q ≥ n t , for any t ∈ (0,1/2]. For multiple failures, no planarity exploiting results were previously known.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2952546397",
    "type": "article"
  },
  {
    "title": "Faster and Simpler Sketches of Valuation Functions",
    "doi": "https://doi.org/10.1145/3039871",
    "publication_date": "2017-03-06",
    "publication_year": 2017,
    "authors": "Keren Cohavi; Shahar Dobzinski",
    "corresponding_authors": "",
    "abstract": "We present fast algorithms for sketching valuation functions. Let N (| N | = n ) be some ground set and v :2 N → R be a function. We say that v˜:2 N → R is an α-sketch of v if for every set S we have that v ( S )/α ≤ v˜( S ) ≤ v ( S ) and v˜ can be described in poly ( n ) bits. Goemans et al. [SODA’09] showed that if v is submodular then there exists an õ (√ n )-sketch that can be constructed using polynomially many value queries (this is essentially the best possible, as Balcan and Harvey [STOC’11] show that no submodular function admits an n 1/3 - ϵ -sketch). Based on their work, Balcan et al. [COLT’12] and Badanidiyuru et al. [SODA’12] show that if v is subadditive, then there exists an õ (√ n )-sketch that can be constructed using polynomially many demand queries. All previous sketches are based on complicated geometric constructions. The first step in their constructions is proving the existence of a good sketch by finding an ellipsoid that “approximates” v well (this is done by applying John’s theorem to ensure the existence of an ellipsoid that is “close” to the polymatroid that is associated with v ). The second step is to show that this ellipsoid can be found efficiently, and this is done by repeatedly solving a certain convex program to obtain better approximations of John’s ellipsoid. In this article, we give a significantly simpler, nongeometric proof for the existence of good sketches and utilize the proof to obtain much faster algorithms that match the previously obtained approximation bounds. Specifically, we provide an algorithm that finds õ (√ n )-sketch of a submodular function with only õ ( n 3/2 value queries, and we provide an algorithm that finds õ (√ n )-sketch of a subadditive function with O ( n ) demand and value queries.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2963004163",
    "type": "article"
  },
  {
    "title": "Time Dependent Biased Random Walks",
    "doi": "https://doi.org/10.1145/3498848",
    "publication_date": "2022-03-15",
    "publication_year": 2022,
    "authors": "John Haslegrave; Thomas Sauerwald; John Sylvester",
    "corresponding_authors": "",
    "abstract": "We study the biased random walk where at each step of a random walk a “controller” can, with a certain small probability, move the walk to an arbitrary neighbour. This model was introduced by Azar et al. [STOC’1992]; we extend their work to the time dependent setting and consider cover times of this walk. We obtain new bounds on the cover and hitting times. Azar et al. conjectured that the controller can increase the stationary probability of a vertex from p to p 1-ε ; while this conjecture is not true in full generality, we propose a best-possible amended version of this conjecture and confirm it for a broad class of graphs. We also consider the problem of computing an optimal strategy for the controller to minimise the cover time and show that for directed graphs determining the cover time is PSPACE -complete.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3034084724",
    "type": "article"
  },
  {
    "title": "PTAS for Sparse General-valued CSPs",
    "doi": "https://doi.org/10.1145/3569956",
    "publication_date": "2022-12-13",
    "publication_year": 2022,
    "authors": "Balázs F. Mezei; Marcin Wrochna; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "We study polynomial-time approximation schemes (PTASes) for constraint satisfaction problems (CSPs) such as Maximum Independent Set or Minimum Vertex Cover on sparse graph classes. Baker's approach gives a PTAS on planar graphs, excluded-minor classes, and beyond. For Max-CSPs, and even more generally, maximisation finite-valued CSPs (where constraints are arbitrary non-negative functions), Romero, Wrochna, and \\v{Z}ivn\\'y [SODA'21] showed that the Sherali-Adams LP relaxation gives a simple PTAS for all fractionally-treewidth-fragile classes, which is the most general \"sparsity\" condition for which a PTAS is known. We extend these results to general-valued CSPs, which include \"crisp\" (or \"strict\") constraints that have to be satisfied by every feasible assignment. The only condition on the crisp constraints is that their domain contains an element which is at least as feasible as all the others (but possibly less valuable). For minimisation general-valued CSPs with crisp constraints, we present a PTAS for all Baker graph classes -- a definition by Dvo\\v{r}\\'ak [SODA'20] which encompasses all classes where Baker's technique is known to work, except possibly for fractionally-treewidth-fragile classes. While this is standard for problems satisfying a certain monotonicity condition on crisp constraints, we show this can be relaxed to diagonalisability -- a property of relational structures connected to logics, statistical physics, and random CSPs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3114199807",
    "type": "article"
  },
  {
    "title": "Universal Algorithms for Clustering Problems",
    "doi": "https://doi.org/10.1145/3572840",
    "publication_date": "2022-12-13",
    "publication_year": 2022,
    "authors": "Arun Ganesh; Bruce M. Maggs; Debmalya Panigrahi",
    "corresponding_authors": "",
    "abstract": "This article presents universal algorithms for clustering problems, including the widely studied k -median, k -means, and k -center objectives. The input is a metric space containing all potential client locations. The algorithm must select k cluster centers such that they are a good solution for any subset of clients that actually realize. Specifically, we aim for low regret , defined as the maximum over all subsets of the difference between the cost of the algorithm’s solution and that of an optimal solution. A universal algorithm’s solution Sol for a clustering problem is said to be an α , β-approximation if for all subsets of clients C ′ , it satisfies sol ( C ′ ) ≤ α ċ opt ( C ′) + β ċ mr , where opt ( C ′ is the cost of the optimal solution for clients ( C ′) and mr is the minimum regret achievable by any solution. Our main results are universal algorithms for the standard clustering objectives of k -median, k -means, and k -center that achieve ( O (1), O (1))-approximations. These results are obtained via a novel framework for universal algorithms using linear programming (LP) relaxations. These results generalize to other ℓ p -objectives and the setting where some subset of the clients are fixed . We also give hardness results showing that (α, β)-approximation is NP-hard if α or β is at most a certain constant, even for the widely studied special case of Euclidean metric spaces. This shows that in some sense, ( O (1), O (1))-approximation is the strongest type of guarantee obtainable for universal clustering.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3178347017",
    "type": "article"
  },
  {
    "title": "I/O-Efficient Algorithms for Topological Sort and Related Problems",
    "doi": "https://doi.org/10.1145/3418356",
    "publication_date": "2022-01-23",
    "publication_year": 2022,
    "authors": "Nairen Cao; Jeremy T. Fineman; Katina Russell; Eugene Yang",
    "corresponding_authors": "",
    "abstract": "This article presents I/O-efficient algorithms for topologically sorting a directed acyclic graph and for the more general problem identifying and topologically sorting the strongly connected components of a directed graph G = ( V, E ). Both algorithms are randomized and have I/O-costs O ( sort ( E ) · poly(log V)), with high probability, where sort ( E ) = O( E / B log M / B ( E/B )) is the I/O cost of sorting an | E |-element array on a machine with size- B blocks and size- M cache/internal memory. These are the first algorithms for these problems that do not incur at least one I/O per vertex, and as such these are the first I/O-efficient algorithms for sparse graphs. By applying the technique of time-forward processing, these algorithms also imply I/O-efficient algorithms for most problems on directed acyclic graphs, such as shortest paths, as well as the single-source reachability problem on arbitrary directed graphs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4225242249",
    "type": "article"
  },
  {
    "title": "Polynomial-time trace reconstruction in the smoothed complexity model",
    "doi": "https://doi.org/10.1145/3560819",
    "publication_date": "2022-08-31",
    "publication_year": 2022,
    "authors": "Xi Chen; Anindya De; Chin Ho Lee; Rocco A. Servedio; Sandip Sinha",
    "corresponding_authors": "",
    "abstract": "In the trace reconstruction problem , an unknown source string x ∈ {0, 1} n is sent through a probabilistic deletion channel which independently deletes each bit with probability δ and concatenates the surviving bits, yielding a trace of x . The problem is to reconstruct x given independent traces. This problem has received much attention in recent years both in the worst-case setting where x may be an arbitrary string in {0, 1} n [DOS19, NP17, HHP18, HL20, Cha21a, Cha21b] and in the average-case setting where x is drawn uniformly at random from {0, 1} n [PZ17, HPP18, HL20, Cha21a, Cha21b]. This paper studies trace reconstruction in the smoothed analysis setting, in which a “worst-case” string x worst is chosen arbitrarily from {0, 1} n , and then a perturbed version x of x worst is formed by independently replacing each coordinate by a uniform random bit with probability σ . The problem is to reconstruct x given independent traces from it. Our main result is an algorithm which, for any constant perturbation rate 0 &lt; σ &lt; 1 and any constant deletion rate 0 &lt; δ &lt; 1, uses poly( n ) running time and traces and succeeds with high probability in reconstructing the string x. This stands in contrast with the worst-case version of the problem, for which \\(\\text{exp}(\\tilde{O}(n^{1/5})) \\) is the best known time and sample complexity [Cha21b]. Our approach is based on reconstructing x from the multiset of its short subwords and is quite different from previous algorithms for either the worst-case or average-case versions of the problem. The heart of our work is a new poly( n )-time procedure for reconstructing the multiset of all O (log n )-length subwords of any source string x ∈ {0, 1} n given access to traces of x .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4293762712",
    "type": "article"
  },
  {
    "title": "Approximating ( <i>k,ℓ</i> )-Median Clustering for Polygonal Curves",
    "doi": "https://doi.org/10.1145/3559764",
    "publication_date": "2022-08-31",
    "publication_year": 2022,
    "authors": "Maike Buchin; Anne Driemel; Dennis Rohde",
    "corresponding_authors": "",
    "abstract": "In 2015, Driemel, Krivošija, and Sohler introduced the k,ℓ -median clustering problem for polygonal curves under the Fréchet distance. Given a set of input curves, the problem asks to find k median curves of at most ℓ vertices each that minimize the sum of Fréchet distances over all input curves to their closest median curve. A major shortcoming of their algorithm is that the input curves are restricted to lie on the real line. In this article, we present a randomized bicriteria-approximation algorithm that works for polygonal curves in ℝ d and achieves approximation factor (1+ɛ) with respect to the clustering costs. The algorithm has worst-case running time linear in the number of curves, polynomial in the maximum number of vertices per curve (i.e., their complexity), and exponential in d , ℓ, 1/ɛ and 1/δ (i.e., the failure probability). We achieve this result through a shortcutting lemma, which guarantees the existence of a polygonal curve with similar cost as an optimal median curve of complexity ℓ, but of complexity at most 2ℓ -2, and whose vertices can be computed efficiently. We combine this lemma with the superset sampling technique by Kumar et al. to derive our clustering result. In doing so, we describe and analyze a generalization of the algorithm by Ackermann et al., which may be of independent interest.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4293762729",
    "type": "article"
  },
  {
    "title": "Monotone Edge Flips to an Orientation of Maximum Edge-Connectivity à la Nash-Williams",
    "doi": "https://doi.org/10.1145/3561302",
    "publication_date": "2022-09-06",
    "publication_year": 2022,
    "authors": "Takehiro Ito; Yuni Iwamasa; Naonori Kakimura; Naoyuki Kamiyama; Yusuke Kobayashi; Shun‐ichi Maezawa; Yuta Nozaki; Yoshio Okamoto; Kenta Ozeki",
    "corresponding_authors": "",
    "abstract": "We initiate the study of k -edge-connected orientations of undirected graphs through edge flips for k ≥ 2. We prove that in every orientation of an undirected 2k -edge-connected graph, there exists a sequence of edges such that flipping their directions one by one does not decrease the edge connectivity, and the final orientation is k -edge connected. This yields an “edge-flip based” new proof of Nash-Williams’ theorem: A undirected graph G has a k -edge-connected orientation if and only if G is 2k -edge connected. As another consequence of the theorem, we prove that the edge-flip graph of k -edge-connected orientations of an undirected graph G is connected if G is (2k+2) -edge connected. This has been known to be true only when k=1 .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4294733420",
    "type": "article"
  },
  {
    "title": "Minimum Cut and Minimum <i>k</i> -Cut in Hypergraphs via Branching Contractions",
    "doi": "https://doi.org/10.1145/3570162",
    "publication_date": "2022-10-29",
    "publication_year": 2022,
    "authors": "Kyle Fox; Debmalya Panigrahi; Fred Zhang",
    "corresponding_authors": "",
    "abstract": "On hypergraphs with m hyperedges and n vertices, where p denotes the total size of the hyperedges, we provide the following results: We give an algorithm that runs in \\(\\widetilde{O}(mn^{2k-2})\\) time for finding a minimum k -cut in hypergraphs of arbitrary rank. This algorithm betters the previous best running time for the minimum k -cut problem, for k &gt; 2. We give an algorithm that runs in \\(\\widetilde{O}(n^{\\max \\lbrace r,2k-2\\rbrace })\\) time for finding a minimum k -cut in hypergraphs of constant rank r . This algorithm betters the previous best running times for both the minimum cut and minimum k -cut problems for dense hypergraphs. Both of our algorithms are Monte Carlo, i.e., they return a minimum k -cut (or minimum cut) with high probability. These algorithms are obtained as instantiations of a generic branching randomized contraction technique on hypergraphs, which extends the celebrated work of Karger and Stein on recursive contractions in graphs. Our techniques and results also extend to the problems of minimum hedge-cut and minimum hedge- k -cut on hedgegraphs, which generalize hypergraphs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4307592276",
    "type": "article"
  },
  {
    "title": "Dynamic Geometric Set Cover and Hitting Set",
    "doi": "https://doi.org/10.1145/3551639",
    "publication_date": "2022-08-10",
    "publication_year": 2022,
    "authors": "Pankaj K. Agarwal; Hsien-Chih Chang; Subhash Suri; Allen Xiao; Jie Xue",
    "corresponding_authors": "",
    "abstract": "We investigate dynamic versions of geometric set cover and hitting set where points and ranges may be inserted or deleted, and we want to efficiently maintain an (approximately) optimal solution for the current problem instance. While their static versions have been extensively studied in the past, surprisingly little is known about dynamic geometric set cover and hitting set. For instance, even for the most basic case of one-dimensional interval set cover and hitting set, no nontrivial results were known. The main contribution of our article are two frameworks that lead to efficient data structures for dynamically maintaining set covers and hitting sets in ℝ 1 and ℝ 2 . The first framework uses bootstrapping and gives a (1 + ε)-approximate data structure for dynamic interval set cover in ℝ 1 with O ( n α / ε) amortized update time for any constant α &gt; 0; in ℝ 2 , this method gives O (1)-approximate data structures for unit-square set cover and hitting set with O ( n 1/2+α ) amortized update time. The second framework uses local modification and leads to a (1 + ε)-approximate data structure for dynamic interval hitting set in ℝ 1 with Õ(1/ε) amortized update time; in ℝ 2 , it gives O (1)-approximate data structures for unit-square set cover and hitting set in the partially dynamic settings with Õ(1) amortized update time.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4322696849",
    "type": "article"
  },
  {
    "title": "Computing equilibria for a service provider game with (Im)perfect information",
    "doi": "https://doi.org/10.1145/1198513.1198524",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "René Beier; Artur Czumaj; Piotr Krysta; Berthold Vöcking",
    "corresponding_authors": "",
    "abstract": "We study fundamental algorithmic questions concerning the complexity of market equilibria under perfect and imperfect information by means of a basic microeconomic game. Suppose a provider offers a service to a set of potential customers. Each customer has a particular demand of service and her behavior is determined by a utility function that is nonincreasing in the sum of demands that are served by the provider.Classical game theory assumes complete information : the provider has full knowledge of the behavior of all customers. We present a complete characterization of the complexity of computing optimal pricing strategies and of computing best/worst equilibria in this model. Basically, we show that most of these problems are inapproximable in the worst case but admit an FPAS in the average case. Our average case analysis covers large classes of distributions for customer utilities. We generalize our analysis to robust equilibria in which players change their strategies only when this promises a significant utility improvement.A more realistic model considers providers with incomplete information . Following the game theoretic framework of Bayesian games introduced by Harsanyi, the provider is aware of probability distributions describing the behavior of the customers and aims at estimating its expected revenue under best/worst equilibria. Somewhat counterintuitively, we obtain an FPRAS for the equilibria problem in the model with imperfect information although the problem with perfect information is inapproximable under the worst-case measures. In particular, the worst-case complexity of the considered problems increases with the precision of the available knowledge.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2035308065",
    "type": "article"
  },
  {
    "title": "Online scheduling of splittable tasks",
    "doi": "https://doi.org/10.1145/1125994.1125999",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Leah Epstein; Rob van Stee",
    "corresponding_authors": "",
    "abstract": "We consider online scheduling of splittable tasks on parallel machines, where the goal is to minimize the last completion time (the makespan). In our model, each task can be split into a limited number of parts, that can then be scheduled independently and in parallel. We consider both the case where the machines are identical and the case where some subset of the machines have a (fixed) higher speed than the others. We design a class of algorithms that allows us to give tight bounds for a large class of cases where tasks may be split into relatively many parts. For identical machines, we also improve upon the natural greedy algorithm in other classes of cases.",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2131283467",
    "type": "article"
  },
  {
    "title": "Problems column",
    "doi": "https://doi.org/10.1145/1077464.1077475",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "Samir Khuller",
    "corresponding_authors": "Samir Khuller",
    "abstract": "article Problems column Share on Author: Samir Khuller University of Maryland, College Park, Maryland University of Maryland, College Park, MarylandView Profile Authors Info & Claims ACM Transactions on AlgorithmsVolume 1Issue 1July 2005 pp 157–159https://doi.org/10.1145/1077464.1077475Online:01 July 2005Publication History 2citation1,081DownloadsMetricsTotal Citations2Total Downloads1,081Last 12 Months8Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 4,
    "openalex_id": "https://openalex.org/W2296011403",
    "type": "article"
  },
  {
    "title": "Partial fillup and search time in LC tries",
    "doi": "https://doi.org/10.1145/1290672.1290681",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Svante Janson; Wojciech Szpankowski",
    "corresponding_authors": "",
    "abstract": "Andersson and Nilsson introduced in 1993 a level-compressed trie (for short, LC trie) in which a full subtree of a node is compressed to a single node of degree being the size of the subtree. Recent experimental results indicated a “dramatic improvement” when full subtrees are replaced by “partially filled subtrees.” In this article, we provide a theoretical justification of these experimental results, showing, among others, a rather moderate improvement in search time over the original LC tries. For such an analysis, we assume that n strings are generated independently by a binary memoryless source, with p denoting the probability of emitting a “1” (and q = 1 − p ). We first prove that the so-called α-fillup level F n (α) (i.e., the largest level in a trie with α fraction of nodes present at this level) is concentrated on two values with high probability: either F n (α) = k n or F n (α) = k n + 1, where k n = log 1/√ pq n − |ln ( p/q )|/2 ln 3/2 (1√ pq ) Φ −1 (α) √ ln n + O (1) is an integer and Φ( x ) denotes the normal distribution function. This result directly yields the typical depth (search time) D n (α) in the α-LC tries, namely, we show that with high probability D n (α) ∼ C 2 log log n , where C 2 = 1/|log(1 − h /log(1/√ pq ))| for p ≠ q and h = − p log p − q log q is the Shannon entropy rate. This should be compared with recently found typical depth in the original LC tries, which is C 1 log log n , where C 1 = 1/|log(1− h /log(1/min{ p , 1− p }))|. In conclusion, we observe that α affects only the lower term of the α-fillup level F n (α), and the search time in α-LC tries is of the same order as in the original LC tries.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2101596348",
    "type": "article"
  },
  {
    "title": "Dense subgraph problems with output-density conditions",
    "doi": "https://doi.org/10.1145/1383369.1383374",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "Akiko Suzuki; Takeshi Tokuyama",
    "corresponding_authors": "",
    "abstract": "We consider the dense subgraph problem that extracts a subgraph, with a prescribed number of vertices, having the maximum number of edges (or total edge weight, in the weighted case) in a given graph. We give approximation algorithms with improved theoretical approximation ratios assuming that the density of the optimal output subgraph is high, where density is the ratio of number of edges (or sum of edge weights) to the number of edges in the clique on the same number of vertices. Moreover, we investigate the case where the input graph is bipartite and design a randomized pseudopolynomial time approximation scheme that can become a randomized PTAS, even if the size of the optimal output graph is comparatively small. This is a significant improvement in a theoretical sense, since no constant-ratio approximation algorithm was known previously if the output graph has o ( n ) vertices.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2161922819",
    "type": "article"
  },
  {
    "title": "Approximation Algorithms for Minimum-Load <i>k</i> -Facility Location",
    "doi": "https://doi.org/10.1145/3173047",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Sara Ahmadian; Babak Behsaz; Zachary Friggstad; Amin Jorati; Mohammad R. Salavatipour; Chaitanya Swamy",
    "corresponding_authors": "",
    "abstract": "We consider a facility-location problem that abstracts settings where the cost of serving the clients assigned to a facility is incurred by the facility. Formally, we consider the minimum-load k-facility location (ML k FL) problem, which is defined as follows. We have a set F of facilities, a set C of clients, and an integer k ≥ 0. Assigning client j to a facility f incurs a connection cost d ( f , j ). The goal is to open a set F ⊆ F of k facilities and assign each client j to a facility f ( j )∈ F so as to minimize max f ∈ F ∑ j ∈ C : f ( j )= f d ( f , j ); we call ∑ j ∈ C : f ( j )= f d ( f , j ) the load of facility f . This problem was studied under the name of min-max star cover in References [3, 7], who (among other results) gave bicriteria approximation algorithms for ML k FL for when F = C . ML k FL is rather poorly understood, and only an O ( k )-approximation is currently known for ML k FL, even for line metrics . Our main result is the first polytime approximation scheme (PTAS) for ML k FL on line metrics (note that no non-trivial true approximation of any kind was known for this metric). Complementing this, we prove that ML k FL is strongly NP -hard on line metrics. We also devise a quasi-PTAS for ML k FL on tree metrics. ML k FL turns out to be surprisingly challenging even on line metrics and resilient to attack by a variety of techniques that have been successfully applied to facility-location problems. For instance, we show that (a) even a configuration-style LP-relaxation has a bad integrality gap and (b) a multi-swap k -median style local-search heuristic has a bad locality gap. Thus, we need to devise various novel techniques to attack ML k FL. Our PTAS for line metrics consists of two main ingredients. First, we prove that there always exists a near-optimal solution possessing some nice structural properties. A novel aspect of this proof is that we first move to a mixed-integer LP (MILP) encoding of the problem and argue that a MILP-solution minimizing a certain potential function possesses the desired structure and then use a rounding algorithm for the generalized-assignment problem to “transfer” this structure to the rounded integer solution. Complementing this, we show that these structural properties enable one to find such a structured solution via dynamic programming.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2802493366",
    "type": "article"
  },
  {
    "title": "Faster Carry Bit Computation for Adder Circuits with Prescribed Arrival Times",
    "doi": "https://doi.org/10.1145/3340321",
    "publication_date": "2019-07-25",
    "publication_year": 2019,
    "authors": "Ulrich Brenner; Anna Hermann",
    "corresponding_authors": "",
    "abstract": "We consider the fundamental problem of constructing fast circuits for the carry bit computation in binary addition. Up to a small additive constant, the carry bit computation reduces to computing an \\aop, i.e., a formula of type $t_0 \\land (t_1 \\lor (t_2 \\land ( \\dots t_{m-1}) \\dots )$ or $t_0 \\lor (t_1 \\land (t_2 \\lor ( \\dots t_{m-1}) \\dots )$. We present an algorithm that computes the fastest known Boolean circuit for an \\aop~ with given arrival times $a(t_0), \\dotsc, a(t_{m-1})$ for the input signals. Our objective function is delay, a natural generalization of depth with respect to arrival times. The maximum delay of the circuit we compute is $\\log_2 W + \\log_2 \\log_2 m + \\log_2 \\log_2 \\log_2 m + 4.3$, where $W := \\sum_{i = 0}^{m-1} 2^{a(t_i)}$. Note that $\\lceil \\log_2 W \\rceil$ is a lower bound on the delay of any circuit depending on inputs $t_0, \\dotsc, t_{m-1}$ with prescribed arrival times. Our method yields the fastest circuits for \\aop s, carry bit computation and adders in terms of delay known so far.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2808107703",
    "type": "article"
  },
  {
    "title": "Deterministic Parallel Algorithms for Fooling Polylogarithmic Juntas and the Lovász Local Lemma",
    "doi": "https://doi.org/10.1145/3230651",
    "publication_date": "2018-08-28",
    "publication_year": 2018,
    "authors": "David G. Harris",
    "corresponding_authors": "David G. Harris",
    "abstract": "Many randomized algorithms can be derandomized efficiently using either the method of conditional expectations or probability spaces with low (almost-) independence. A series of papers, beginning with Luby (1993) and continuing with Berger and Rompel (1991) and Chari et al. (2000), showed that these techniques can be combined to give deterministic parallel algorithms for combinatorial optimization problems involving sums of w -juntas. We improve these algorithms through derandomized variable partitioning, reducing the processor complexity to essentially independent of w and time complexity to linear in w . As a key subroutine, we give a new algorithm to generate a probability space which can fool a given set of neighborhoods. Schulman (1992) gave an NC algorithm to do so for neighborhoods of size w ≤ O (log n ). Our new algorithm is in NC 1 , with essentially optimal time and processor complexity, when w = O (log n ); it remains in NC up to w = polylog( n ). This answers an open problem of Schulman. One major application of these algorithms is an NC algorithm for the Lovász Local Lemma. Previous NC algorithms, including the seminal algorithm of Moser and Tardos (2010) and the work of Chandrasekaran et. al (2013), required that (essentially) the bad-events could span only O (log n ) variables; we relax this to polylog( n ) variables. We use this for an NC 2 algorithm for defective vertex coloring, which works for arbitrary degree graphs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2889036126",
    "type": "article"
  },
  {
    "title": "Distribution-free Junta Testing",
    "doi": "https://doi.org/10.1145/3264434",
    "publication_date": "2018-09-24",
    "publication_year": 2018,
    "authors": "Zhengyang Liu; Xi Chen; Rocco A. Servedio; Ying Sheng; Jinyu Xie",
    "corresponding_authors": "",
    "abstract": "We study the problem of testing whether an unknown n -variable Boolean function is a k -junta in the distribution-free property testing model, where the distance between functions is measured with respect to an arbitrary and unknown probability distribution over {0,1} n . Our first main result is that distribution-free k -junta testing can be performed, with one-sided error, by an adaptive algorithm that uses Õ( k 2 )/ϵ queries (independent of n ). Complementing this, our second main result is a lower bound showing that any non-adaptive distribution-free k -junta testing algorithm must make Ω(2 k /3 ) queries even to test to accuracy ϵ = 1/3. These bounds establish that while the optimal query complexity of non-adaptive k -junta testing is 2 Θ( k ) , for adaptive testing it is poly( k ), and thus show that adaptivity provides an exponential improvement in the distribution-free query complexity of testing juntas.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2892448241",
    "type": "article"
  },
  {
    "title": "A Dual Descent Algorithm for Node-capacitated Multiflow Problems and Its Applications",
    "doi": "https://doi.org/10.1145/3291531",
    "publication_date": "2018-12-20",
    "publication_year": 2018,
    "authors": "Hiroshi Hirai",
    "corresponding_authors": "Hiroshi Hirai",
    "abstract": "In this article, we develop an O (( m log k )MSF( n,m ,1))-time algorithm to find a half-integral node-capacitated multiflow of the maximum total flow-value in a network with n nodes, m edges, and k terminals, where MSF( n ′ , m ′ ,γ) denotes the time complexity of solving the maximum submodular flow problem in a network with n ′ nodes, m ′ edges, and the complexity γ of computing the exchange capacity of the submodular function describing the problem. By using Fujishige-Zhang algorithm for submodular flow, we can find a maximum half-integral multiflow in O ( m n 3 log k ) time. This is the first combinatorial strongly polynomial time algorithm for this problem. Our algorithm is built on a developing theory of discrete convex functions on certain graph structures. Applications include “ellipsoid-free” combinatorial implementations of a 2-approximation algorithm for the minimum node-multiway cut problem by Garg, Vazirani, and Yannakakis.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2962788224",
    "type": "article"
  },
  {
    "title": "Dynamic Beats Fixed",
    "doi": "https://doi.org/10.1145/3340296",
    "publication_date": "2019-07-25",
    "publication_year": 2019,
    "authors": "Marcin Bieńkowski; Jarosław Byrka; Marcin Mucha",
    "corresponding_authors": "",
    "abstract": "We construct a deterministic 4-competitive algorithm for the online file migration problem, beating the currently best 20-year-old, 4.086-competitive M ove -T o -L ocal -M in (M tlm ) algorithm by Bartal et al. (SODA 1997). Like M tlm , our algorithm also operates in phases, but it adapts their lengths dynamically depending on the geometry of requests seen so far. The improvement was obtained by carefully analyzing a linear model (factor-revealing linear program) of a single phase of the algorithm. We also show that if an online algorithm operates in phases of fixed length and the adversary is able to modify the graph between phases, then the competitive ratio is at least 4.086.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2963120404",
    "type": "article"
  },
  {
    "title": "Fully Dynamic MIS in Uniformly Sparse Graphs",
    "doi": "https://doi.org/10.1145/3378025",
    "publication_date": "2020-03-09",
    "publication_year": 2020,
    "authors": "Krzysztof Onak; Baruch Schieber; Shay Solomon; Nicole Wein",
    "corresponding_authors": "",
    "abstract": "We consider the problem of maintaining a maximal independent set in a dynamic graph subject to edge insertions and deletions. Recently, Assadi et al. (at STOC’18) showed that a maximal independent set can be maintained in sublinear (in the dynamically changing number of edges) amortized update time. In this article, we significantly improve the update time for uniformly sparse graphs . Specifically, for graphs with arboricity α, the amortized update time of our algorithm is O (α 2 ⋅ log 2 n ), where n is the number of vertices. For low arboricity graphs, which include, for example, minor-free graphs and some classes of “real-world” graphs, our update time is polylogarithmic. Our update time improves the result of Assadi et al. for all graphs with arboricity bounded by m 3/8−ϵ , for any constant ϵ &gt; 0. This covers much of the range of possible values for arboricity, as the arboricity of a general graph cannot exceed m 1/2 .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3011393812",
    "type": "article"
  },
  {
    "title": "Oblivious Resampling Oracles and Parallel Algorithms for the Lopsided Lovász Local Lemma",
    "doi": "https://doi.org/10.1145/3392035",
    "publication_date": "2020-07-07",
    "publication_year": 2020,
    "authors": "David G. Harris",
    "corresponding_authors": "David G. Harris",
    "abstract": "The Lovász Local Lemma (LLL) shows that, for a collection of “bad” events B in a probability space that are not too likely and not too interdependent, there is a positive probability that no events in B occur. Moser and Tardos (2010) gave sequential and parallel algorithms that transformed most applications of the variable-assignment LLL into efficient algorithms. A framework of Harvey and Vondrák (2015) based on “resampling oracles” extended this to sequential algorithms for other probability spaces satisfying a generalization of the LLL known as the Lopsided Lovász Local Lemma (LLLL). We describe a new structural property that holds for most known resampling oracles, which we call “obliviousness.” Essentially, it means that the interaction between two bad-events B , B ′ depends only on the randomness used to resample B and not the precise state within B itself. This property has two major consequences. First, combined with a framework of Kolmogorov (2016), it leads to a unified parallel LLLL algorithm, which is faster than previous, problem-specific algorithms of Harris (2016) for the variable-assignment LLLL and of Harris and Srinivasan (2014) for permutations. This gives the first RNC algorithms for rainbow perfect matchings and rainbow Hamiltonian cycles of K n . Second, this property allows us to build LLLL probability spaces from simpler “atomic” events. This gives the first resampling oracle for rainbow perfect matchings on the complete s -uniform hypergraph K n ( s ) and the first commutative resampling oracle for Hamiltonian cycles of K n .",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3041542062",
    "type": "article"
  },
  {
    "title": "Foreword to special issue on SODA 2002",
    "doi": "https://doi.org/10.1145/1219944.1219946",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "David Eppstein",
    "corresponding_authors": "David Eppstein",
    "abstract": "No abstract available.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W4205383648",
    "type": "article"
  },
  {
    "title": "Cheeger-Type Approximation for Sparsest <i>st</i> -Cut",
    "doi": "https://doi.org/10.1145/2996799",
    "publication_date": "2016-11-19",
    "publication_year": 2016,
    "authors": "Robert Krauthgamer; Tal Wagner",
    "corresponding_authors": "",
    "abstract": "We introduce the st -cut version of the sparsest-cut problem, where the goal is to find a cut of minimum sparsity in a graph G ( V , E ) among those separating two distinguished vertices s , t ∈ V . Clearly, this problem is at least as hard as the usual (non- st ) version. Our main result is a polynomial-time algorithm for the product-demands setting that produces a cut of sparsity O (√OPT), where OPT ⩽ 1 denotes the optimum when the total edge capacity and the total demand are assumed (by normalization) to be 1. Our result generalizes the recent work of Trevisan [arXiv, 2013] for the non- st version of the same problem (sparsest cut with product demands), which in turn generalizes the bound achieved by the discrete Cheeger inequality, a cornerstone of Spectral Graph Theory that has numerous applications. Indeed, Cheeger’s inequality handles graph conductance, the special case of product demands that are proportional to the vertex (capacitated) degrees. Along the way, we obtain an O (log | V |) approximation for the general-demands setting of sparsest st -cut.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1579163687",
    "type": "article"
  },
  {
    "title": "Corrigendum",
    "doi": "https://doi.org/10.1145/2500123",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "Rajiv Gandhi; Magnús M. Halldórsson; Guy Kortsarz; Hadas Shachnai",
    "corresponding_authors": "",
    "abstract": "In Gandhi et al. [2006], we gave an algorithm for the data migration and non-deterministic open shop scheduling problems in the minimum sum version, that was claimed to achieve a 5.06-approximation. Unfortunately, it was pointed to us by Maxim Sviridenko that the argument contained an unfounded assumption that has eluded all of its readers until now. We detail in this document how this error can be amended. A side effect is an improved approximation ratio of 4.96.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W1993025312",
    "type": "erratum"
  },
  {
    "title": "Constrained pattern matching",
    "doi": "https://doi.org/10.1145/1921659.1921671",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Yongwook Choi; Wojciech Szpankowski",
    "corresponding_authors": "",
    "abstract": "Constrained sequences are strings satisfying certain additional structural restrictions (e.g., some patterns are forbidden). They find applications in communication, digital recording, and biology. In this article, we restrict our attention to the so-called ( d , k ) constrained binary sequences in which any run of zeros must be of length at least d and at most k , where 0≤ d &lt; k . In many applications, one needs to know the number of occurrences of a given pattern w in such sequences, for which we coin the term constrained pattern matching . For a given word w , we first estimate the mean and the variance of the number of occurrences of w in a ( d , k ) sequence generated by a memoryless source. Then we present the central limit theorem and large deviations results. As a by-product, we enumerate asymptotically the number of ( d , k ) sequences with exactly r occurrences of w , and compute Shannon entropy of ( d , k ) sequences with a given number of occurrences of w . We also apply our results to detect under- and overrepresented patterns in neuronal data (spike trains), which satisfy structural constraints that match the framework of ( d , k ) binary sequences. Throughout this article we use techniques of analytic combinatorics such as combinatorial calculus, generating functions, and complex asymptotics.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2041019664",
    "type": "article"
  },
  {
    "title": "Constant factor approximations for the hotlink assignment problem",
    "doi": "https://doi.org/10.1145/1921659.1921662",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Tobias Jacobs",
    "corresponding_authors": "Tobias Jacobs",
    "abstract": "The concept of hotlink assignment aims at reducing the navigation effort for the users of a Web directory or similar structure by inserting a limited number of additional hyperlinks called hotlinks . The k -hotlink assignment problem denotes the task of adding at most k outgoing hotlinks to each page of a tree-like site, minimizing the path length , that is, the expected number of “clicks” necessary for the user to reach her destination page. Another common formulation of this problem is to maximize the gain , that is, the path length reduction achieved by the assignment. In this work we analyze the natural greedy strategy, proving that it reaches the optimal gain up to the constant factor of 2. Considering the gain, we also prove the existence of a PTAS. Finally, we give a polynomial-time 2-approximation for the 1-hotlink assignment problem, which constitutes the first constant factor approximation in terms of the path length. The algorithms' performance analyses are made possible by a set of three new basic operations for the transformation of hotlink assignments.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2046219288",
    "type": "article"
  },
  {
    "title": "Improved approximations for the hotlink assignment problem",
    "doi": "https://doi.org/10.1145/1978782.1978794",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "Eduardo Sany Laber; Marco Molinaro",
    "corresponding_authors": "",
    "abstract": "Let G =( V,E ) be a graph representing a Web site, where nodes correspond to pages and arcs to hyperlinks. In this context, hotlinks are defined as shortcuts (new arcs) added to Web pages of G in order to reduce the time spent by users to reach their desired information. In this article, we consider the problem where G is a rooted directed tree and the goal is minimizing the expected time spent by users by assigning at most k hotlinks to each node. For the most studied version of this problem where at most one hotlink can be added to each node, we prove the existence of two FPTAS's which optimize different objectives considered in the literature: one minimizes the expected user path length and the other maximizes the expected reduction in user path lengths. These results improve over a constant factor approximation for the expected length and over a PTAS for the expected reduction, both obtained recently in Jacobs [2007]. Indeed, these FPTAS's are essentially the best possible results one can achieve under the assumption that P ≠ NP . Another contribution we give here is a 16-approximation algorithm for the most general version of the problem where up to k hotlinks can be assigned from each node. This algorithm runs in O (| V | log | V |) time and it turns to be the first algorithm with constant approximation for this problem.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2059941319",
    "type": "article"
  },
  {
    "title": "Approximate Privacy",
    "doi": "https://doi.org/10.1145/2601067",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "Joan Feigenbaum; Aaron D. Jaggard; Michael Schapira",
    "corresponding_authors": "",
    "abstract": "The proliferation of online sensitive data about individuals and organizations makes concern about the privacy of these data a top priority. There have been many formulations of privacy and, unfortunately, many negative results about the feasibility of maintaining privacy of sensitive data in realistic networked environments. We formulate communication-complexity-based definitions, both worst case and average case, of a problem’s privacy-approximation ratio . We use our definitions to investigate the extent to which approximate privacy is achievable in a number of standard problems: the 2 nd -price Vickrey auction, Yao’s millionaires problem, the public-good problem, and the set-theoretic disjointness and intersection problems. For both the 2 nd -price Vickrey auction and the millionaires problem, we show that not only is perfect privacy impossible or infeasibly costly to achieve, but even close approximations of perfect privacy suffer from the same lower bounds. By contrast, if the inputs are drawn uniformly at random from { 0,…, 2 k -1}, then, for both problems, simple and natural communication protocols have privacy-approximation ratios that are linear in k (i.e., logarithmic in the size of the input space). We also demonstrate tradeoffs between privacy and communication in a family of auction protocols. We show that the privacy-approximation ratio provided by any protocol for the disjointness and intersection problems is necessarily exponential (in k ). We also use these ratios to argue that one protocol for each of these problems is significantly fairer than the others we consider (in the sense of relative effects on the privacy of the different players).",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2137912742",
    "type": "article"
  },
  {
    "title": "A Simple and Efficient Algorithm for Computing Market Equilibria",
    "doi": "https://doi.org/10.1145/2905372",
    "publication_date": "2016-05-13",
    "publication_year": 2016,
    "authors": "Lisa Fleischer; Rahul Garg; Sanjiv Kapoor; Rohit Khandekar; Amin Saberi",
    "corresponding_authors": "",
    "abstract": "We give a new mathematical formulation of market equilibria in exchange economies using an indirect utility function : the function of prices and income that gives the maximum utility achievable. The formulation is a convex program and can be solved when the indirect utility function is convex in prices. We illustrate that many economies, including: —Homogeneous utilities of degree α ∈ [0, 1] in Fisher economies—this includes Linear, Leontief, Cobb-Douglas — Resource allocation utilities like multi-commodity flows satisfy this condition and can be efficiently solved. Further, we give a natural tâtonnement type price-adjusting algorithm in these economies. Our algorithm, which is applicable to a larger class of utility functions than previously known weak gross substitutes , mimics the natural dynamics for the markets as suggested by Walras: it iteratively adjusts a good’s price upward when the demand for that good under current prices exceeds its supply; and downward when its supply exceeds its demand. The algorithm computes an approximate equilibrium in a number of iterations that is independent of the number of traders and is almost linear in the number of goods.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2402767173",
    "type": "article"
  },
  {
    "title": "Addendum to “Dominator Tree Certification and Divergent Spanning Trees”",
    "doi": "https://doi.org/10.1145/2928271",
    "publication_date": "2016-08-16",
    "publication_year": 2016,
    "authors": "Loukas Georgiadis; Robert E. Tarjan",
    "corresponding_authors": "",
    "abstract": "note Share on Addendum to \"Dominator Tree Certification and Divergent Spanning Trees\" Authors: Loukas Georgiadis University of Ioannina, Ioannina, Greece University of Ioannina, Ioannina, GreeceView Profile , Robert E. Tarjan Princeton University and Intertrust Technologies, Sunnyvale, CA Princeton University and Intertrust Technologies, Sunnyvale, CAView Profile Authors Info & Claims ACM Transactions on AlgorithmsVolume 12Issue 4September 2016 Article No.: 56pp 1–3https://doi.org/10.1145/2928271Published:16 August 2016Publication History 1citation145DownloadsMetricsTotal Citations1Total Downloads145Last 12 Months4Last 6 weeks1 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2508867560",
    "type": "article"
  },
  {
    "title": "On the bicriteria <i>k</i> -server problem",
    "doi": "https://doi.org/10.1145/1868237.1868244",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "Michele Flammini; Gaia Nicosia",
    "corresponding_authors": "",
    "abstract": "In this article we consider multicriteria formulations of classical online problems in which an algorithm must simultaneously perform well with respect to two different cost measures. Every strategy for serving a sequence of requests is characterized by a pair of costs and therefore there can be many different minimal or optimal incomparable solutions. The adversary is assumed to choose from one of these minimal strategies and the performance of the algorithm is measured with respect to the costs the adversary pays servicing the sequence according to its determined choice of strategy. We consider a parametric family of functions which includes all the possible selections for such strategies. Then, starting from a simple general method that combines any multicriteria instance into a single-criterion one, we provide a universal multicriteria algorithm that can be applied to different online problems. In the multicriteria k -server formulation with two different edge weightings, for each function class, such a universal algorithm achieves competitive ratios that are only an O (log W ) multiplicative factor away from the corresponding determined lower bounds, where W is the maximum ratio between the two weights associated to each edge. We then extend our results to two specific functions, for which nearly optimal competitive algorithms are obtained by exploiting more knowledge of the selection properties. Finally, we show how to apply our framework to other multicriteria online problems sharing similar properties.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2020813060",
    "type": "article"
  },
  {
    "title": "Two-phase greedy algorithms for some classes of combinatorial linear programs",
    "doi": "https://doi.org/10.1145/1824777.1824785",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Ulrich Faigle; Britta Peis",
    "corresponding_authors": "",
    "abstract": "We present greedy algorithms for some classes of combinatorial packing and cover problems within the general formal framework of Hoffman and Schwartz' lattice polyhedra. Our algorithms compute in a first phase Monge solutions for the associated dual cover and packing problems and then proceed to construct greedy solutions for the primal problems in a second phase. We show optimality of the algorithms under certain sub- and supermodular assumptions and monotone constraints. For supermodular lattice polyhedra with submodular constraints, our algorithms offer the farthest reaching generalization of Edmonds' polymatroid greedy algorithm currently known.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2115461308",
    "type": "article"
  },
  {
    "title": "Truthful unsplittable flow for large capacity networks",
    "doi": "https://doi.org/10.1145/1721837.1721852",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Yossi Azar; Iftah Gamzu; Shai Gutner",
    "corresponding_authors": "",
    "abstract": "The unsplittable flow problem is one of the most extensively studied optimization problems in the field of networking. An instance of it consists of an edge capacitated graph and a set of connection requests, each of which is associated with source and target vertices, a demand, and a value. The objective is to route a maximum value subset of requests subject to the edge capacities. It is a well known fact that as the capacities of the edges are larger with respect to the maximal demand among the requests, the problem can be approximated better. In particular, it is known that for sufficiently large capacities, the integrality gap of the corresponding integer linear program becomes 1 + ϵ, which can be matched by an algorithm that utilizes the randomized rounding technique. In this article, we focus our attention on the large capacities unsplittable flow problem in a game theoretic setting. In this setting, there are selfish agents, which control some of the requests characteristics, and may be dishonest about them. It is worth noting that in game theoretic settings many standard techniques, such as randomized rounding, violate certain monotonicity properties, which are imperative for truthfulness, and therefore cannot be employed. In light of this state of affairs, we design a monotone deterministic algorithm, which is based on a primal-dual machinery, which attains an approximation ratio of e / e -1, up to a disparity of ϵ away. This implies an improvement on the current best truthful mechanism, as well as an improvement on the current best combinatorial algorithm for the problem under consideration. Surprisingly, we demonstrate that any algorithm in the family of reasonable iterative path minimizing algorithms, cannot yield a better approximation ratio. Consequently, it follows that in order to achieve a monotone PTAS, if that exists, one would have to exert different techniques. We also consider the large capacities single-minded multi-unit combinatorial auction problem . This problem is closely related to the unsplittable flow problem since one can formulate it as a special case of the integer linear program of the unsplittable flow problem. Accordingly, we obtain a comparable performance guarantee by refining the algorithm suggested for the unsplittable flow problem.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2129909904",
    "type": "article"
  },
  {
    "title": "Optimally scheduling video-on-demand to minimize delay when sender and receiver bandwidth may differ",
    "doi": "https://doi.org/10.1145/1198513.1198523",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "William Evans; David Kirkpatrick",
    "corresponding_authors": "",
    "abstract": "We establish tight bounds on the intrinsic cost (either minimizing delay d for fixed sender and receiver bandwidths, or minimizing sender bandwidth for fixed delay and receiver bandwidth) of broadcasting a video of length m over a channel of bandwidth S in such a way that a receiver (with bandwidth R ), starting at an arbitrary time s , can download the video so that it can begin playback at time s + d .Our bounds are realized by a simple just-in-time protocol that partitions the video into a fixed number of segments, partitions the sender bandwidth into an equivalent number of equal bandwidth subchannels, and broadcasts each segment repeatedly on its own subchannel. The protocol is suitable for the broadcast of compressed video and it can be implemented so that video information is packaged into discrete fixed length packets incurring only a modest overhead (measured in terms of increased delay).Our primary contribution is a lower bound on the required delay that applies to all protocols. This lower bound matches the behavior of our just-in-time protocol in the limit as the number of segments approaches infinity, provided the video compression satisfies some uniform upper bound. For a fixed number of segments, our protocol is optimal within a broad class of protocols, even if the video is compressed arbitrarily.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2051835769",
    "type": "article"
  },
  {
    "title": "Sublinear Random Access Generators for Preferential Attachment Graphs",
    "doi": "https://doi.org/10.1145/3464958",
    "publication_date": "2021-10-04",
    "publication_year": 2021,
    "authors": "Guy Even; Reut Levi; Moti Medina; Adi Rosén",
    "corresponding_authors": "",
    "abstract": "We consider the problem of sampling from a distribution on graphs, specifically when the distribution is defined by an evolving graph model, and consider the time, space, and randomness complexities of such samplers. In the standard approach, the whole graph is chosen randomly according to the randomized evolving process, stored in full, and then queries on the sampled graph are answered by simply accessing the stored graph. This may require prohibitive amounts of time, space, and random bits, especially when only a small number of queries are actually issued. Instead, we propose a setting where one generates parts of the sampled graph on-the-fly, in response to queries, and therefore requires amounts of time, space, and random bits that are a function of the actual number of queries. Yet, the responses to the queries correspond to a graph sampled from the distribution in question. Within this framework, we focus on two random graph models: the Barabási-Albert Preferential Attachment model (BA-graphs) ( Science , 286 (5439):509–512) (for the special case of out-degree 1) and the random recursive tree model ( Theory of Probability and Mathematical Statistics , (51):1–28). We give on-the-fly generation algorithms for both models. With probability 1-1/poly( n ), each and every query is answered in polylog( n ) time, and the increase in space and the number of random bits consumed by any single query are both polylog( n ), where n denotes the number of vertices in the graph. Our work thus proposes a new approach for the access to huge graphs sampled from a given distribution, and our results show that, although the BA random graph model is defined by a sequential process, efficient random access to the graph’s nodes is possible. In addition to the conceptual contribution, efficient on-the-fly generation of random graphs can serve as a tool for the efficient simulation of sublinear algorithms over large BA-graphs, and the efficient estimation of their on such graphs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W2963965835",
    "type": "article"
  },
  {
    "title": "Better Distance Preservers and Additive Spanners",
    "doi": "https://doi.org/10.1145/3490147",
    "publication_date": "2021-10-05",
    "publication_year": 2021,
    "authors": "Greg Bodwin; Virginia Vassilevska Williams",
    "corresponding_authors": "",
    "abstract": "We study two popular ways to sketch the shortest path distances of an input graph. The first is distance preservers , which are sparse subgraphs that agree with the distances of the original graph on a given set of demand pairs. Prior work on distance preservers has exploited only a simple structural property of shortest paths, called consistency , stating that one can break shortest path ties such that no two paths intersect, split apart, and then intersect again later. We prove that consistency alone is not enough to understand distance preservers, by showing both a lower bound on the power of consistency and a new general upper bound that polynomially surpasses it. Specifically, our new upper bound is that any p demand pairs in an n -node undirected unweighted graph have a distance preserver on O( n 2/3 p 2/3 + np 1/3 edges. We leave a conjecture that the right bound is O ( n 2/3 p 2/3 + n ) or better. The second part of this paper leverages these distance preservers in a new construction of additive spanners , which are subgraphs that preserve all pairwise distances up to an additive error function. We give improved error bounds for spanners with relatively few edges; for example, we prove that all graphs have spanners on O(n) edges with + O ( n 3/7 + ε ) error. Our construction can be viewed as an extension of the popular path-buying framework to clusters of larger radii.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3201916240",
    "type": "article"
  },
  {
    "title": "Algorithms for Weighted Independent Transversals and Strong Colouring",
    "doi": "https://doi.org/10.1145/3474057",
    "publication_date": "2021-12-02",
    "publication_year": 2021,
    "authors": "Alessandra Graf; David G. Harris; Penny Haxell",
    "corresponding_authors": "",
    "abstract": "An independent transversal (IT) in a graph with a given vertex partition is an independent set consisting of one vertex in each partition class. Several sufficient conditions are known for the existence of an IT in a given graph and vertex partition, which have been used over the years to solve many combinatorial problems. Some of these IT existence theorems have algorithmic proofs, but there remains a gap between the best existential bounds and the bounds obtainable by efficient algorithms. Recently, Graf and Haxell (2018) described a new (deterministic) algorithm that asymptotically closes this gap, but there are limitations on its applicability. In this article, we develop a randomized algorithm that is much more widely applicable, and demonstrate its use by giving efficient algorithms for two problems concerning the strong chromatic number of graphs.",
    "cited_by_count": 3,
    "openalex_id": "https://openalex.org/W3214978406",
    "type": "article"
  },
  {
    "title": "Cache-Oblivious Buffer Heap and Cache-Efficient Computation of Shortest Paths in Graphs",
    "doi": "https://doi.org/10.1145/3147172",
    "publication_date": "2018-01-03",
    "publication_year": 2018,
    "authors": "Rezaul Chowdhury; Vijaya Ramachandran",
    "corresponding_authors": "",
    "abstract": "We present the buffer heap , a cache-oblivious priority queue that supports Delete-Min , Delete , and a hybrid Insert / Decrease-Key operation in O (1/ B log 2 N / M ) amortized block transfers from main memory, where M and B are the (unknown) cache size and block size, respectively, and N is the number of elements in the queue. We introduce the notion of a slim data structure that captures the situation when only a limited portion of the cache, which we call a slim cache , is available to the data structure to retain data between data structural operations. We show that a buffer heap automatically adapts to such an environment and supports all operations in O (1/λ + 1/ B log 2 N /λ) amortized block transfers each when the size of the slim cache is λ. Our results provide substantial improvements over known trivial cache performance bounds for cache-oblivious priority queues with Decrease-Keys . Using the buffer heap, we present cache-oblivious implementations of Dijkstra’s algorithm for undirected and directed single-source shortest path (SSSP) problems for graphs with non-negative real edge-weights. On a graph with n vertices and m edges, our algorithm for the undirected case performs O ( n + m / B log 2 n / M ) block transfers and for the directed case performs O (( n + m / B ) ċ log 2 n / B ) block transfers. These results give the first non-trivial cache-oblivious bounds for the SSSP problem on general graphs. For the all-pairs shortest path (APSP) problem on weighted undirected graphs, we incorporate slim buffer heaps into multi-buffer-buffer-heaps and use these to improve the cache-aware cache complexity. We also present a simple cache-oblivious APSP algorithm for unweighted undirected graphs that performs O ( mn / B log M / B n / B ) block transfers. This matches the cache-aware bound and is a substantial improvement over the previous cache-oblivious bound for the problem.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2782004680",
    "type": "article"
  },
  {
    "title": "Adaptive Computation of the Swap-Insert Correction Distance",
    "doi": "https://doi.org/10.1145/3232057",
    "publication_date": "2018-08-09",
    "publication_year": 2018,
    "authors": "Jérémy Barbay; Pablo Pérez-Lantero",
    "corresponding_authors": "",
    "abstract": "The Swap-Insert Correction distance from a string S of length n to another string L of length m ≥ n on the alphabet [1‥σ] is the minimum number of insertions, and swaps of pairs of adjacent symbols, converting S into L . Contrarily to other correction distances, computing it is NP-Hard in the size σ of the alphabet. We describe an algorithm computing this distance in time within O (σ 2 nmg σ−1 ), where for each α ∈ [1‥σ] there are n α occurrences of α in S , m α occurrences of α in L , and where g = max α∈[1‥σ] min{ n α , m α − n α } is a new parameter of the analysis, measuring one aspect of the difficulty of the instance. The difficulty g is bounded by above by various terms, such as the length n of the shortest string S , and by the maximum number of occurrences of a single character in S (max α ∈[1‥σ] n α ). This result illustrates how, in many cases, the correction distance between two strings can be easier to compute than in the worst case scenario.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2963814569",
    "type": "article"
  },
  {
    "title": "CoveringLSH",
    "doi": "https://doi.org/10.1145/3155300",
    "publication_date": "2018-06-16",
    "publication_year": 2018,
    "authors": "Rasmus Pagh",
    "corresponding_authors": "Rasmus Pagh",
    "abstract": "We consider a new construction of locality-sensitive hash functions for Hamming space that is covering in the sense that is it guaranteed to produce a collision for every pair of vectors within a given radius r. The construction is efficient in the sense that the expected number of hash collisions between vectors at distance cr, for a given c>1, comes close to that of the best possible data independent LSH without the covering guarantee, namely, the seminal LSH construction of Indyk and Motwani (STOC’98). The efficiency of the new construction essentially matches their bound when the search radius is not too large—e.g., when cr = o(log (n)/ log log n), where n is the number of points in the dataset, and when cr = log (n)/k, where k is an integer constant. In general, it differs by at most a factor ln (4) in the exponent of the time bounds. As a consequence, LSH-based similarity search in Hamming space can avoid the problem of false negatives at little or no cost in efficiency.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2963994525",
    "type": "article"
  },
  {
    "title": "Erratum",
    "doi": "https://doi.org/10.1145/3186991",
    "publication_date": "2018-06-16",
    "publication_year": 2018,
    "authors": "Zeev Nutov",
    "corresponding_authors": "Zeev Nutov",
    "abstract": "There are two errors in our article “Approximating Minimum-Cost Connectivity Problems via Uncrossable Bifamilies” ( ACM Transactions on Algorithms ( TALG ), 9(1), Article No. 1, 2012). In that article, we consider the (undirected) S URVIVABLE N ETWORK problem. The input consists of a graph G =( V , E ) with edge-costs, a set T ⊆ V of terminals, and connectivity demands { r st &gt; 0 : st ∈ D ⊆ T × T } . The goal is to find a minimum cost subgraph of G that for all st ∈ D contains r st pairwise internally disjoint st -paths. We claimed ratios O ( k ln k ) for rooted demands when the set D of demand pairs form a star, where k = max st ∈ D r st is the maximum demand. This ratio is correct when the requirements are r st = k for all t ∈ T \\{ s }, but for general rooted demands our article implies only ratio O ( k 2 ) (which, however, is still the currently best-known ratio for the problem). We also obtained various ratios for the node-weighted version of the problem. These results are valid, but the proof needs a correction described here.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4254450489",
    "type": "erratum"
  },
  {
    "title": "Tiling with Squares and Packing Dominos in Polynomial Time",
    "doi": "https://doi.org/10.1145/3597932",
    "publication_date": "2023-05-23",
    "publication_year": 2023,
    "authors": "Anders Aamand; Mikkel Abrahamsen; Thomas D. Ahle; Peter Rasmussen",
    "corresponding_authors": "",
    "abstract": "A polyomino is a polygonal region with axis-parallel edges and corners of integral coordinates, which may have holes. In this paper, we consider planar tiling and packing problems with polyomino pieces and a polyomino container P. We give polynomial-time algorithms for deciding if P can be tiled with k × k squares for any fixed k which can be part of the input (that is, deciding if P is the union of a set of non-overlapping k × k squares) and for packing P with a maximum number of non-overlapping and axis-parallel 2 × 1 dominos, allowing rotations by 90°. As packing is more general than tiling, the latter algorithm can also be used to decide if P can be tiled by 2 × 1 dominos.These are classical problems with important applications in VLSI design, and the related problem of finding a maximum packing of 2 × 2 squares is known to be NP-hard [6]. For our three problems there are known pseudo-polynomial-time algorithms, that is, algorithms with running times polynomial in the area or perimeter of P. However, the standard, compact way to represent a polygon is by listing the coordinates of the corners in binary. We use this representation, and thus present the first polynomial-time algorithms for the problems. Concretely, we give a simple O(n log n)-time algorithm for tiling with squares, where n is the number of corners of P. We then give a more involved algorithm that reduces the problems of packing and tiling with dominos to finding a maximum and perfect matching in a graph with O(n3) vertices. This leads to algorithms with running times and , respectively.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3106614825",
    "type": "article"
  },
  {
    "title": "Routing selfish unsplittable traffic",
    "doi": "https://doi.org/10.1145/1290672.1290689",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Vincenzo Auletta; Roberto De Prisco; Paolo Penna; Giuseppe Persiano",
    "corresponding_authors": "",
    "abstract": "We consider general resource assignment games involving selfish users/agents in which users compete for resources and try to be assigned to those which maximize their own benefits (e.g., try to route their traffic through links which minimize the latency of their own traffic). We propose and study a mechanism design approach in which an allocation mechanism assigns users to resources and charges the users for using the resources so as to induce each user to truthfully report a private piece of information he/she holds (e.g., how much traffic he/she needs to transmit). This information is crucial for computing optimal (or close to optimal) allocations and an agent could misreport his/her information to induce the underlying allocation algorithm to output a solution which he/she likes more (e.g., which assigns better resources to him/her). For our resource allocation problems, we give an algorithmic characterization of the solutions for which truth-telling is a Nash equilibrium. A natural application of these results is to a scheduling/routing problem which is the mechanism design counterpart of the selfish routing game of Koutsoupias and Papadimitriou [1999]: Each selfish user wants to route a piece of unsplittable traffic using one of m links of different speeds so as to minimize his/her own latency. Our mechanism design counterpart can be seen as the problem of scheduling selfish jobs on parallel related machines and is the dual of the problem of scheduling (unselfish) jobs on parallel selfish machines studied by Archer and Tardos [2001]. Koutsoupias and Papadimitriou studied an “anarchic” scenario in which each user chooses his/her own link, and this may produce Nash equilibria of cost Ω(log m /log log m ) times the optimum. Our mechanism design counterpart is a possible way of reducing the effect of selfish behavior via suitable incentives to the agents (i.e., taxes for using the links). We indeed show that in the resulting game, it is possible to guarantee an approximation factor of 8 for any number of links/machines (this solution also works for online settings). However, it remains impossible to guarantee arbitrarily good approximate solutions, even for 2 links/machines and even if the allocation algorithm is allowed superpolynomial time. This result shows that our scheduling problem with selfish jobs is more difficult than the scheduling problem with selfish machines by Archer and Tardos (which admits exact solutions). We also study some generalizations of this basic problem.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2148342922",
    "type": "article"
  },
  {
    "title": "A New Algorithm for Fast Generalized DFTs",
    "doi": "https://doi.org/10.1145/3301313",
    "publication_date": "2019-11-15",
    "publication_year": 2019,
    "authors": "Chloe Hsu; Chris Umans",
    "corresponding_authors": "",
    "abstract": "We give an new arithmetic algorithm to compute the generalized Discrete Fourier Transform (DFT) over finite groups G . The new algorithm uses O (∣ G ∣ ω /2 + o (1) ) operations to compute the generalized DFT over finite groups of Lie type, including the linear, orthogonal, and symplectic families and their variants, as well as all finite simple groups of Lie type. Here ω is the exponent of matrix multiplication, so the exponent ω/2 is optimal if ω = 2. Previously, “exponent one” algorithms were known for supersolvable groups and the symmetric and alternating groups. No exponent one algorithms were known, even under the assumption ω = 2, for families of linear groups of fixed dimension, and indeed the previous best-known algorithm for SL 2 (F q ) had exponent 4/3 despite being the focus of significant effort. We unconditionally achieve exponent at most 1.19 for this group and exponent one if ω = 2. Our algorithm also yields an improved exponent for computing the generalized DFT over general finite groups G , which beats the longstanding previous best upper bound for any ω. In particular, assuming ω = 2, we achieve exponent √ 2, while the previous best was 3/2.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W2989273677",
    "type": "article"
  },
  {
    "title": "Tightening Curves on Surfaces Monotonically with Applications",
    "doi": "https://doi.org/10.1145/3558097",
    "publication_date": "2022-09-09",
    "publication_year": 2022,
    "authors": "Hsien-Chih Chang; Arnaud de Mesmay",
    "corresponding_authors": "",
    "abstract": "We prove the first polynomial bound on the number of monotonic homotopy moves required to tighten a collection of closed curves on any compact orientable surface, where the number of crossings in the curve is not allowed to increase at any time during the process. The best known upper bound before was exponential, which can be obtained by combining the algorithm of De Graaf and Schrijver [ J. Comb. Theory Ser. B , 1997] together with an exponential upper bound on the number of possible surface maps. To obtain the new upper bound, we apply tools from hyperbolic geometry, as well as operations in graph drawing algorithms—the cluster and pipe expansions—to the study of curves on surfaces. As corollaries, we present two efficient algorithms for curves and graphs on surfaces. First, we provide a polynomial-time algorithm to convert any given multicurve on a surface into minimal position. Such an algorithm only existed for single closed curves, and it is known that previous techniques do not generalize to the multicurve case. Second, we provide a polynomial-time algorithm to reduce any k -terminal plane graph (and more generally, surface graph) using degree-1 reductions, series-parallel reductions, and Δ Y -transformations for arbitrary integer k . Previous algorithms only existed in the planar setting when k ≤ 4, and all of them rely on extensive case-by-case analysis based on different values of k . Our algorithm makes use of the connection between electrical transformations and homotopy moves and thus solves the problem in a unified fashion.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3006844515",
    "type": "article"
  },
  {
    "title": "Submatrix Maximum Queries in Monge and Partial Monge Matrices Are Equivalent to Predecessor Search",
    "doi": "https://doi.org/10.1145/3381416",
    "publication_date": "2020-03-09",
    "publication_year": 2020,
    "authors": "Paweł Gawrychowski; Shay Mozes; Oren Weimann",
    "corresponding_authors": "",
    "abstract": "We present an optimal data structure for submatrix maximum queries in n × n Monge matrices. Our result is a two-way reduction showing that the problem is equivalent to the classical predecessor problem in a universe of polynomial size. This gives a data structure of O ( n ) space that answers submatrix maximum queries in O (log log n ) time, as well as a matching lower bound, showing that O (log log n ) query-time is optimal for any data structure of size O ( n polylog( n )). Our result settles the problem, improving on the O (log 2 n ) query time in SODA’12, and on the O (log n ) query-time in ICALP’14. In addition, we show that partial Monge matrices can be handled in the same bounds as full Monge matrices. In both previous results, partial Monge matrices incurred additional inverse-Ackermann factors.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3012407355",
    "type": "article"
  },
  {
    "title": "Robust Algorithms for TSP and Steiner Tree",
    "doi": "https://doi.org/10.1145/3570957",
    "publication_date": "2022-12-14",
    "publication_year": 2022,
    "authors": "Arun Ganesh; Bruce M. Maggs; Debmalya Panigrahi",
    "corresponding_authors": "",
    "abstract": "Robust optimization is a widely studied area in operations research, where the algorithm takes as input a range of values and outputs a single solution that performs well for the entire range. Specifically, a robust algorithm aims to minimize regret , defined as the maximum difference between the solution’s cost and that of an optimal solution in hindsight once the input has been realized. For graph problems in P , such as shortest path and minimum spanning tree, robust polynomial-time algorithms that obtain a constant approximation on regret are known. In this paper, we study robust algorithms for minimizing regret in NP -hard graph optimization problems, and give constant approximations on regret for the classical traveling salesman and Steiner tree problems.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3024720357",
    "type": "article"
  },
  {
    "title": "Structure Learning of H-Colorings",
    "doi": "https://doi.org/10.1145/3382207",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Antonio Blanca; Zongchen Chen; Daniel Štefankoviè; Eric Vigoda",
    "corresponding_authors": "",
    "abstract": "We study the following structure learning problem for H -colorings. For a fixed (and known) constraint graph H with q colors, given access to uniformly random H -colorings of an unknown graph G=(V,E) , how many samples are required to learn the edges of G ? We give a characterization of the constraint graphs H for which the problem is identifiable for every G and show that there are identifiable constraint graphs for which one cannot hope to learn every graph G efficiently. We provide refined results for the case of proper vertex q -colorings of graphs of maximum degree d . In particular, we prove that in the tree uniqueness region (i.e., when q≤ d ), the problem is identifiable and we can learn G in poly( d,q )× O(n 2 log n ) time. In the tree non-uniqueness region (i.e., when q≤ d), we show that the problem is not identifiable and thus G cannot be learned. Moreover, when q ≤ d - √d + Θ (1), we establish that even learning an equivalent graph (any graph with the same set of H -colorings) is computationally hard—sample complexity is exponential in n in the worst case. We further explore the connection between the efficiency/hardness of the structure learning problem and the uniqueness/non-uniqueness phase transition for general H -colorings and prove that under a well-known uniqueness condition in statistical physics, we can learn G in poly( d,q )× O(n 2 log n ) time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3034032055",
    "type": "article"
  },
  {
    "title": "A Complexity Theoretical Study of Fuzzy <i>K</i> -Means",
    "doi": "https://doi.org/10.1145/3409385",
    "publication_date": "2020-09-16",
    "publication_year": 2020,
    "authors": "Johannes Blömer; Sascha Brauer; Kathrin Bujna",
    "corresponding_authors": "",
    "abstract": "The fuzzy K -means problem is a popular generalization of the well-known K -means problem to soft clusterings. In this article, we present the first algorithmic study of the problem going beyond heuristics. Our main result is that, assuming a constant number of clusters, there is a polynomial time approximation scheme for the fuzzy K -means problem. As a part of our analysis, we also prove the existence of small coresets for fuzzy K -means. At the heart of our proofs are two novel techniques developed to analyze the otherwise notoriously difficult fuzzy K -means objective function.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3087831808",
    "type": "article"
  },
  {
    "title": "Point-Width and Max-CSPs",
    "doi": "https://doi.org/10.1145/3409447",
    "publication_date": "2020-09-16",
    "publication_year": 2020,
    "authors": "Clément Carbonnel; Miguel Romero; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "The complexity of (unbounded-arity) Max-CSPs under structural restrictions is poorly understood. The two most general hypergraph properties known to ensure tractability of Max-CSPs, β -acyclicity and bounded (incidence) MIM-width, are incomparable and lead to very different algorithms. We introduce the framework of point decompositions for hypergraphs and use it to derive a new sufficient condition for the tractability of (structurally restricted) Max-CSPs, which generalises both bounded MIM-width and β -acyclicity. On the way, we give a new characterisation of bounded MIM-width and discuss other hypergraph properties which are relevant to the complexity of Max-CSPs, such as β -hypertreewidth.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3089020152",
    "type": "article"
  },
  {
    "title": "Journey to the Center of the Point Set",
    "doi": "https://doi.org/10.1145/3431285",
    "publication_date": "2020-12-31",
    "publication_year": 2020,
    "authors": "Sariel Har-Peled; Mitchell Jones",
    "corresponding_authors": "",
    "abstract": "Let P be a set of n points in R d . For a parameter α ∈ (0,1), an α-centerpoint of P is a point p ∈ R d such that all closed halfspaces containing P also contain at least α n points of P . We revisit an algorithm of Clarkson et al. [1996] that computes (roughly) a 1/(4 d 2 )-centerpoint in Õ( d 9 ) randomized time, where Õ hides polylogarithmic terms. We present an improved algorithm that can compute centerpoints with quality arbitrarily close to 1/ d 2 and runs in randomized time Õ( d 7 ). While the improvements are (arguably) mild, it is the first refinement of the algorithm by Clarkson et al. [1996] in over 20 years. The new algorithm is simpler, and the running time bound follows by a simple random walk argument, which we believe to be of independent interest. We also present several new applications of the improved centerpoint algorithm.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3114928418",
    "type": "article"
  },
  {
    "title": "A Tractable Class of Binary VCSPs via M-Convex Intersection",
    "doi": "https://doi.org/10.1145/3329862",
    "publication_date": "2019-07-16",
    "publication_year": 2019,
    "authors": "Hiroshi Hirai; Yuni Iwamasa; Kazuo Murota; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "A binary VCSP is a general framework for the minimization problem of a function represented as the sum of unary and binary cost functions. An important line of VCSP research is to investigate what functions can be solved in polynomial time. Cooper and \\v{Z}ivn\\'{y} classified the tractability of binary VCSP instances according to the concept of \"triangle,\" and showed that the only interesting tractable case is the one induced by the joint winner property (JWP). Recently, Iwamasa, Murota, and \\v{Z}ivn\\'{y} made a link between VCSP and discrete convex analysis, showing that a function satisfying the JWP can be transformed into a function represented as the sum of two quadratic M-convex functions, which can be minimized in polynomial time via an M-convex intersection algorithm if the value oracle of each M-convex function is given. In this paper, we give an algorithmic answer to a natural question: What binary finite-valued CSP instances can be represented as the sum of two quadratic M-convex functions and can be solved in polynomial time via an M-convex intersection algorithm? We solve this problem by devising a polynomial-time algorithm for obtaining a concrete form of the representation in the representable case. Our result presents a larger tractable class of binary finite-valued CSPs, which properly contains the JWP class.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3122931165",
    "type": "article"
  },
  {
    "title": "The ( <i>h,k</i> )-Server Problem on Bounded Depth Trees",
    "doi": "https://doi.org/10.1145/3301314",
    "publication_date": "2019-02-06",
    "publication_year": 2019,
    "authors": "Nikhil Bansal; Marek Eliéš; Łukasz Jeż; Grigorios Koumoutsos",
    "corresponding_authors": "",
    "abstract": "We study the k -server problem in the resource augmentation setting, i.e., when the performance of the online algorithm with k servers is compared to the offline optimal solution with h ≤ k servers. The problem is very poorly understood beyond uniform metrics. For this special case, the classic k -server algorithms are roughly (1+1/ϵ)-competitive when k =(1+ϵ) h , for any ϵ &gt; 0. Surprisingly, however, no o ( h )-competitive algorithm is known even for HSTs of depth 2 and even when k / h is arbitrarily large. We obtain several new results for the problem. First, we show that the known k -server algorithms do not work even on very simple metrics. In particular, the Double Coverage algorithm has competitive ratio Ω ( h ) irrespective of the value of k , even for depth-2 HSTs. Similarly, the Work Function Algorithm, which is believed to be optimal for all metric spaces when k = h , has competitive ratio Ω ( h ) on depth-3 HSTs even if k =2 h . Our main result is a new algorithm that is O (1)-competitive for constant depth trees, whenever k =(1+ϵ) h for any ϵ &gt; 0. Finally, we give a general lower bound that any deterministic online algorithm has competitive ratio at least 2.4 even for depth-2 HSTs and when k / h is arbitrarily large. This gives a surprising qualitative separation between uniform metrics and depth-2 HSTs for the ( h , k )-server problem.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3160943031",
    "type": "article"
  },
  {
    "title": "A Linear-Time <i>n</i> <sup>0.4</sup> -Approximation for Longest Common Subsequence",
    "doi": "https://doi.org/10.1145/3568398",
    "publication_date": "2022-10-26",
    "publication_year": 2022,
    "authors": "Karl Bringmann; Vincent Cohen-Addad; Debarati Das",
    "corresponding_authors": "",
    "abstract": "We consider the classic problem of computing the Longest Common Subsequence (LCS) of two strings of length n. The 40-year-old quadratic-time dynamic programming algorithm has recently been shown to be near-optimal by Abboud, Backurs, and Vassilevska Williams [FOCS'15] and Bringmann and Künnemann [FOCS'15] assuming the Strong Exponential Time Hypothesis. This has led the community to look for subquadratic approximation algorithms for the problem.Yet, unlike the edit distance problem for which a constant-factor approximation in almost-linear time is known, very little progress has been made on LCS, making it a notoriously difficult problem also in the realm of approximation. For the general setting, only a naive O(nI/2-approximation algorithm with running time OŠ(n2-I has been known, for any constant 0 < I ≤ 1. Recently, a breakthrough result by Hajiaghayi, Seddighin, Seddighin, and Sun [SODA'19] provided a linear-time algorithm that yields a O(n0.497956-approximation in expectation; improving upon the naive -approximation for the first time.In this paper, we provide an algorithm that in time O(n2-I) computes an OŠ(n2/5-approximation with high probability, for any 0 < I ≤ 1. Our result (1) gives an OŠ(n0.4-approximation in linear time, improving upon the bound of Hajiaghayi, Seddighin, Seddighin, and Sun, (2) provides an algorithm whose approximation scales with any subquadratic running time O(n2-I), improving upon the naive bound of O(nI/2) for any I, and (3) instead of only in expectation, succeeds with high probability.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3172736027",
    "type": "article"
  },
  {
    "title": "(最小,+)畳込みに等価な問題について【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2019-01-01",
    "publication_year": 2019,
    "authors": "Cygan Marek; Mucha Marcin; Wegrzycki Karol; Wlodarczyk Michal",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3190236558",
    "type": "article"
  },
  {
    "title": "Online Throughput Maximization on Unrelated Machines: Commitment is No Burden",
    "doi": "https://doi.org/10.1145/3569582",
    "publication_date": "2022-12-14",
    "publication_year": 2022,
    "authors": "Franziska Eberle; Nicole Megow; Kevin Schewior",
    "corresponding_authors": "",
    "abstract": "We consider a fundamental online scheduling problem in which jobs with processing times and deadlines arrive online over time at their release dates. The task is to determine a feasible preemptive schedule on a single or multiple possibly unrelated machines that maximizes the number of jobs that complete before their deadline. Due to strong impossibility results for competitive analysis on a single machine, we require that jobs contain some slack ε > 0, which means that the feasible time window for scheduling a job is at least 1 + ε times its processing time on each eligible machine. Our contribution is two-fold: (i) We give the first non-trivial online algorithms for throughput maximization on unrelated machines, and (ii), this is the main focus of our paper, we answer the question on how to handle commitment requirements which enforce that a scheduler has to guarantee at a certain point in time the completion of admitted jobs. This is very relevant, e.g., in providing cloud-computing services, and disallows last-minute rejections of critical tasks. We present an algorithm for unrelated machines that is Theta 1varepsilon -competitive when the scheduler must commit upon starting a job. Somewhat surprisingly, this is the same optimal performance bound (up to constants) as for scheduling without commitment on a single machine. If commitment decisions must be made before a job’s slack becomes less than a δ -fraction of its size, we prove a competitive ratio of O1 delta for 0 < δ < ε. This result nicely interpolates between commitment upon starting a job and commitment upon arrival. For the latter commitment model, it is known that no (randomized) online algorithm admits any bounded competitive ratio. While we mainly focus on scheduling without migration, our results also hold when comparing against a migratory optimal solution in case of identical machines.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3216068169",
    "type": "article"
  },
  {
    "title": "Improving the Dilation of a Metric Graph by Adding Edges",
    "doi": "https://doi.org/10.1145/3517807",
    "publication_date": "2022-02-23",
    "publication_year": 2022,
    "authors": "Joachim Gudmundsson; Sampson Wong",
    "corresponding_authors": "",
    "abstract": "Most of the literature on spanners focuses on building the graph from scratch. This article instead focuses on adding edges to improve an existing graph. A major open problem in this field is: Given a graph embedded in a metric space, and a budget of k edges, which k edges do we add to produce a minimum-dilation graph? The special case where k=1 has been studied in the past, but no major breakthroughs have been made for k &gt; 1 . We provide the first positive result, an O(k) -approximation algorithm that runs in O(n 3 log n ) time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4213449106",
    "type": "article"
  },
  {
    "title": "Optimal Bound on the Combinatorial Complexity of Approximating Polytopes",
    "doi": "https://doi.org/10.1145/3559106",
    "publication_date": "2022-09-10",
    "publication_year": 2022,
    "authors": "Rahul Arya; Sunil Arya; Guilherme D. da Fonseca; David M. Mount",
    "corresponding_authors": "",
    "abstract": "This paper considers the question of how to succinctly approximate a multidimensional convex body by a polytope. Given a convex body $K$ of unit diameter in Euclidean $d$-dimensional space (where $d$ is a constant) and an error parameter $\\varepsilon > 0$, the objective is to determine a convex polytope of low combinatorial complexity whose Hausdorff distance from $K$ is at most $\\varepsilon$. By combinatorial complexity we mean the total number of faces of all dimensions. Classical constructions by Dudley and Bronshteyn/Ivanov show that $O(1/\\varepsilon^{(d-1)/2})$ facets or vertices are possible, respectively, but neither achieves both bounds simultaneously. In this paper, we show that it is possible to construct a polytope with $O(1/\\varepsilon^{(d-1)/2})$ combinatorial complexity, which is optimal in the worst case. Our result is based on a new relationship between $\\varepsilon$-width caps of a convex body and its polar body. Using this relationship, we are able to obtain a volume-sensitive bound on the number of approximating caps that are \"essentially different.\" We achieve our main result by combining this with a variant of the witness-collector method and a novel variable-thickness layered construction of the economical cap covering.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4295128493",
    "type": "article"
  },
  {
    "title": "Tight Lower Bound for the Channel Assignment Problem",
    "doi": "https://doi.org/10.1145/2876505",
    "publication_date": "2016-09-02",
    "publication_year": 2016,
    "authors": "Arkadiusz Socała",
    "corresponding_authors": "Arkadiusz Socała",
    "abstract": "We study the complexity of the C hannel A ssignment problem. An open problem asks whether C hannel A ssignment admits an O ( c n ) (times a polynomial in the bit size) time algorithm, where n is a number of the vertices, for a constant c independent of the weights on the edges. We answer this question in the negative. Indeed, we show that in the standard Word RAM model, there is no 2 o ( n log n ) (times a polynomial in the bit size) time algorithm solving C hannel A ssignment unless the exponential time hypothesis fails. Note that the currently best known algorithm works in time O *( n !) = 2 O ( n log n ) , so our lower bound is tight (where the O *() notation suppresses polynomial factors).",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1533624370",
    "type": "article"
  },
  {
    "title": "Tabulating Pseudoprimes and Tabulating Liars",
    "doi": "https://doi.org/10.1145/2957759",
    "publication_date": "2016-09-14",
    "publication_year": 2016,
    "authors": "Andrew Shallue",
    "corresponding_authors": "Andrew Shallue",
    "abstract": "This article explores the asymptotic complexity of two problems related to the Miller-Rabin-Selfridge primality test. The first problem is to tabulate strong pseudoprimes to a single fixed base a . It is now proven that tabulating up to x requires O ( x ) arithmetic operations and O ( x log x ) bits of space. The second problem is to find all strong liars and witnesses, given a fixed odd composite n . This appears to be unstudied, and a randomized algorithm is presented that requires an expected O ((log n ) 2 + | S ( n )|) operations (here S ( n ) is the set of strong liars). Although interesting in their own right, a notable application is the search for sets of composites with no reliable witnesses.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2342938199",
    "type": "article"
  },
  {
    "title": "Distributed Algorithms for End-to-End Packet Scheduling in Wireless Ad Hoc Networks",
    "doi": "https://doi.org/10.1145/2812811",
    "publication_date": "2016-04-25",
    "publication_year": 2016,
    "authors": "V. S. Anil Kumar; Madhav Marathe; Srinivasan Parthasarathy; Aravind Srinivasan",
    "corresponding_authors": "",
    "abstract": "Packet scheduling is a particular challenge in wireless networks due to interference from nearby transmissions. A distance-2 interference model serves as a useful abstraction here, and we study packet routing and scheduling under this model of interference. The main focus of our work is the development of fully distributed (decentralized) protocols. We present polylogarithmic/constant factor approximation algorithms for various families of disk graphs (which capture the geometric nature of wireless-signal propagation), as well as near-optimal approximation algorithms for general graphs. A basic distributed coloring procedure, originally due to Luby [1993] ( Journal of Computer and System Sciences , 47:250--286, 1993), underlies many of our algorithms. The work of Finocchi et al. [2002] ( Proc. ACM-SIAM Symposium on Discrete Algorithms , 2002) showed that a natural modification of this algorithm leads to improved performance. A rigorous explanation of this was left as an open question, and we prove that the modified algorithm is indeed provably better in the worst case.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2344226889",
    "type": "article"
  },
  {
    "title": "Competitive Online Search Trees on Trees",
    "doi": "https://doi.org/10.1145/3595180",
    "publication_date": "2023-04-28",
    "publication_year": 2023,
    "authors": "Prosenjit Bose; Jean Cardinal; John Iacono; Grigorios Koumoutsos; Stefan Langerman",
    "corresponding_authors": "",
    "abstract": "We consider the design of adaptive data structures for searching elements of a tree-structured space. We use a natural generalization of the rotation-based online binary search tree model in which the underlying search space is the set of vertices of a tree. This model is based on a simple structure for decomposing graphs, previously known under several names including elimination trees, vertex rankings, and tubings. The model is equivalent to the classical binary search tree model exactly when the underlying tree is a path. We describe an online O (log log n )-competitive search tree data structure in this model, where n is the number of vertices. This matches the best-known competitive ratio of binary search trees. Our method is inspired by Tango trees, an online binary search tree algorithm, but critically needs several new notions including one that we call Steiner-closed search trees, which may be of independent interest. Moreover, our technique is based on a novel use of two levels of decomposition, first from search space to a set of Steiner-closed trees and, second, from these trees into paths.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2966205006",
    "type": "article"
  },
  {
    "title": "Approximating Sparsest Cut in Low-Treewidth Graphs via Combinatorial Diameter",
    "doi": "https://doi.org/10.1145/3632623",
    "publication_date": "2023-11-14",
    "publication_year": 2023,
    "authors": "Parinya Chalermsook; Matthias Kaul; Matthias Mnich; Joachim Spoerhase; Sumedha Uniyal; Daniel Vaz",
    "corresponding_authors": "",
    "abstract": "The fundamental Sparsest Cut problem takes as input a graph G together with edge capacities and demands, and seeks a cut that minimizes the ratio between the capacities and demands across the cuts. For n -vertex graphs G of treewidth k , Chlamtáč, Krauthgamer, and Raghavendra (APPROX 2010) presented an algorithm that yields a factor- \\(2^{2^k} \\) approximation in time 2 O ( k ) · n O (1) . Later, Gupta, Talwar and Witmer (STOC 2013) showed how to obtain a 2-approximation algorithm with a blown-up run time of n O ( k ) . An intriguing open question is whether one can simultaneously achieve the best out of the aforementioned results, that is, a factor-2 approximation in time 2 O ( k ) · n O (1) . In this paper, we make significant progress towards this goal, via the following results: (i) A factor- O ( k 2 ) approximation that runs in time 2 O ( k ) · n O (1) , directly improving the work of Chlamtáč et al. while keeping the run time single-exponential in k . (ii) For any ε ∈ (0, 1], a factor- O (1/ε 2 ) approximation whose run time is \\(2^{O(k^{1+\\varepsilon }/\\varepsilon)} \\cdot n^{O(1)} \\) , implying a constant-factor approximation whose run time is nearly single-exponential in k and a factor- O (log 2 k ) approximation in time k O ( k ) · n O (1) . Key to these results is a new measure of a tree decomposition that we call combinatorial diameter , which may be of independent interest.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3214284418",
    "type": "article"
  },
  {
    "title": "Width of Points in the Streaming Model",
    "doi": "https://doi.org/10.1145/2847259",
    "publication_date": "2016-02-08",
    "publication_year": 2016,
    "authors": "Alexandr Andoni; Huy Nguyen",
    "corresponding_authors": "",
    "abstract": "In this article, we show how to compute the width of a dynamic set of low-dimensional points in the streaming model. In particular, we assume that the stream contains both insertions of points and deletions of points to a set S , and the goal is to compute the width of the set S , namely the minimal distance between two parallel hyperplanes sandwiching the point set S . Our algorithm (1 + ϵ) approximates the width of the set S using space polylogarithmic in the size of S and the aspect ratio of S . This is the first such algorithm that supports both insertions and deletions of points to the set S : previous algorithms for approximating the width of a point set only supported additions [Agarwal et al. 2004; Chan 2006], or a sliding window [Chan and Sadjad 2006]. This solves an open question from the “2009 Kanpur list” of open problems in data streams, property testing, and related topics [Indyk et al. 2011].",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4244923350",
    "type": "article"
  },
  {
    "title": "Polynomial Kernel for Interval Vertex Deletion",
    "doi": "https://doi.org/10.1145/3571075",
    "publication_date": "2023-01-19",
    "publication_year": 2023,
    "authors": "Akanksha Agrawal; Daniel Lokshtanov; Pranabendu Misra; Saket Saurabh; Meirav Zehavi",
    "corresponding_authors": "",
    "abstract": "Given a graph G and an integer k , the Interval Vertex Deletion (IVD) problem asks whether there exists a subset S ⊆ V ( G ) of size at most k such that G-S is an interval graph. This problem is known to be NP -complete (according to Yannakakis at STOC 1978). Originally in 2012, Cao and Marx showed that IVD is fixed parameter tractable: they exhibited an algorithm with running time 10 k n O (1). The existence of a polynomial kernel for IVD remained a well-known open problem in parameterized complexity. In this article, we settle this problem in the affirmative.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4317504585",
    "type": "article"
  },
  {
    "title": "Collapsing the Tower - On the Complexity of Multistage Stochastic IPs",
    "doi": "https://doi.org/10.1145/3604554",
    "publication_date": "2023-06-17",
    "publication_year": 2023,
    "authors": "Kim-Manuel Klein; Janina Reuter",
    "corresponding_authors": "",
    "abstract": "In this article, we study the computational complexity of solving a class of block structured integer programs (IPs), the so-called multistage stochastic IPs. A multistage stochastic IP is an IP of the form min { c T x | Ax = b , x ≥ 0, x integral} where the constraint matrix \\({A}\\) consists of small block matrices ordered on the diagonal line, and for each stage there are larger blocks with few columns connecting the blocks in a treelike fashion. Over the past few years there was enormous progress in the area of block structured IPs. For many of the known block IP classes, such as n -fold, tree-fold, and two-stage stochastic IPs, nearly matching upper and lower bounds are known concerning their computational complexity. One of the major gaps that remained, however, was the parameter dependency in the running time for an algorithm solving multistage stochastic IPs. Previous algorithms require a tower of t exponentials, where t is the number of stages. In contrast, only a double exponential lower bound was known based on the exponential time hypothesis. In this article, we show that the tower of t exponentials is actually not necessary. We show an improved running time of \\(2^{(d\\Vert A \\Vert _\\infty)^{\\mathcal {O}(d^{3t+1})}} \\cdot rn\\log ^{\\mathcal {O}(2^d)}(rn)\\) for the algorithm solving multistage stochastic IPs, where d is the sum of columns in the connecting blocks and rn is the number of rows. Hence, we obtain the first bound by an elementary function for the running time of an algorithm solving multistage stochastic IPs. In contrast to previous works, our algorithm has only a triple exponential dependency on the parameters and only doubly exponential for every constant t . By this, we come very close to the known double exponential bound that holds already for two-stage stochastic IPs, i.e., multistage stochastic IPs with two stages. The improved running time of the algorithm is based on new bounds for the proximity of multistage stochastic IPs. The idea behind the bound is based on generalization of a structural lemma originally used for two-stage stochastic IPs. While the structural lemma requires iteration to be applied to multistage stochastic IPs, our generalization directly applies to inherent combinatorial properties of multiple stages. Already a special case of our lemma yields an improved bound for the Graver complexity of multistage stochastic IPs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4381053948",
    "type": "article"
  },
  {
    "title": "Efficient and Near-optimal Algorithms for Sampling Small Connected Subgraphs",
    "doi": "https://doi.org/10.1145/3596495",
    "publication_date": "2023-06-24",
    "publication_year": 2023,
    "authors": "Marco Bressan",
    "corresponding_authors": "Marco Bressan",
    "abstract": "We study the following problem: Given an integer k ≥ 3 and a simple graph G , sample a connected induced k -vertex subgraph of G uniformly at random. This is a fundamental graph mining primitive with applications in social network analysis, bioinformatics, and more. Surprisingly, no efficient algorithm is known for uniform sampling; the only somewhat efficient algorithms available yield samples that are only approximately uniform, with running times that are unclear or suboptimal. In this work, we provide: (i) a near-optimal mixing time bound for a well-known random walk technique, (ii) the first efficient algorithm for truly uniform graphlet sampling, and (iii) the first sublinear-time algorithm for ε-uniform graphlet sampling.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4381856690",
    "type": "article"
  },
  {
    "title": "Discovering almost any hidden motif from multiple sequences",
    "doi": "https://doi.org/10.1145/1921659.1921672",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Bin Fu; Ming‐Yang Kao; Lusheng Wang",
    "corresponding_authors": "",
    "abstract": "We study a natural probabilistic model for motif discovery. In this model, there are k background sequences, and each character in a background sequence is a random character from an alphabet Σ. A motif G = g 1 g 2 … g m is a string of m characters. Each background sequence is implanted with a probabilistically generated approximate copy of G . For a probabilistically generated approximate copy b 1 b 2 … b m of G , every character is probabilistically generated such that the probability for b i ≠ g i is at most α. In this article, we develop an efficient algorithm that can discover a hidden motif from a set of sequences for any alphabet Σ with |Σ|≥ 2 and is applicable to DNA motif discovery. We prove that for α &lt; 1/8(1- 1/|Σ|), there exist positive constants c 0 , ϵ, and δ 2 such that if there are at least c 0 log n input sequences, then in O ( n 2 / h (log n ) O (1)) time this algorithm finds the motif with probability at least 3/4 for every G ∈ Σ ρ -Ψ ρ, h ,ϵ (Σ), where n the length of longest sequences, ρ is the length of the motif, h is a parameter with ρ≥ 4 h ≥ δ 2 log n , and Ψ ρ, h ,ϵ (Σ) is a small subset of at most 2 −Θ(ϵ 2 h ) fraction of the sequences in Σ ρ .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1974404369",
    "type": "article"
  },
  {
    "title": "Computing the inverse sort transform in linear time",
    "doi": "https://doi.org/10.1145/1921659.1921673",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "Ge Nong; Sen Zhang; Wai Hong Chan",
    "corresponding_authors": "",
    "abstract": "The Sort Transform (ST) can significantly speed up the block sorting phase of the Burrows-Wheeler Transform (BWT) by sorting the limited order contexts. However, the best result obtained so far for the inverse ST has a time complexity O ( N log k ) and a space complexity O ( N ), where N and k are the text size and the context order of the transform, respectively. In this article, we present a novel algorithm that can compute the inverse ST for any k -order contexts in an O ( N ) time and space complexity, a linear result independent of k . The main idea behind the design of this linear algorithm is a set of cycle properties of k -order contexts that we explore for this work. These newly discovered cycle properties allow us to quickly compute the Longest Common Prefix (LCP) between any pair of adjacent k -order contexts that may belong to two different cycles, which eventually leads to the proposed linear-time solution.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W1994046086",
    "type": "article"
  },
  {
    "title": "Testing nilpotence of galois groups in polynomial time",
    "doi": "https://doi.org/10.1145/2229163.2229176",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "V. Arvind; Piyush P. Kurur",
    "corresponding_authors": "",
    "abstract": "We give the first polynomial-time algorithm for checking whether the Galois group Gal( f ) of an input polynomial f ( X ) ∈ Q[ X ] is nilpotent: the running time of our algorithm is bounded by a polynomial in the size of the coefficients of f and the degree of f . Additionally, we give a deterministic polynomial-time algorithm that, when given as input a polynomial f ( X ) ∈ Q[ X ] with nilpotent Galois group, computes for each prime factor p of # Gal( f ), a polynomial g p ( X )∈ Q[ X ] whose Galois group of is the p -Sylow subgroup of Gal( f ).",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2014482702",
    "type": "article"
  },
  {
    "title": "Carry propagation in multiplication by constants",
    "doi": "https://doi.org/10.1145/2000807.2000822",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "Alexander Izsak; Nicholas Pippenger",
    "corresponding_authors": "",
    "abstract": "Suppose that a random n -bit number V is multiplied by an odd constant M ≥ 3, by adding shifted versions of the number V corresponding to the 1s in the binary representation of the constant M . Suppose further that the additions are performed by carry-save adders until the number of summands is reduced to two, at which time the final addition is performed by a carry-propagate adder. We show that in this situation the distribution of the length of the longest carry-propagation chain in the final addition is the same (up to terms tending to 0 as n → ∞) as when two independent n -bit numbers are added, and in particular the mean and variance are the same (again up to terms tending to 0). This result applies to all possible orders of performing the carry-save additions.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2022248596",
    "type": "article"
  },
  {
    "title": "Bicriteria approximation tradeoff for the node-cost budget problem",
    "doi": "https://doi.org/10.1145/1497290.1497295",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "Yuval Rabani; Gabriel Scalosub",
    "corresponding_authors": "",
    "abstract": "We consider an optimization problem consisting of an undirected graph, with cost and profit functions defined on all vertices. The goal is to find a connected subset of vertices with maximum total profit, whose total cost does not exceed a given budget. The best result known prior to this work guaranteed a (2, O (log n )) bicriteria approximation, that is, the solution's profit is at least a fraction of 1/ O (log n ) of an optimum solution respecting the budget, while its cost is at most twice the given budget. We improve these results and present a bicriteria tradeoff that, given any ε ∈ (0,1], guarantees a (1 + ϵ, O (1/ε log n ))-approximation.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2015242277",
    "type": "article"
  },
  {
    "title": "Foreword to special issue SODA 2009",
    "doi": "https://doi.org/10.1145/1721837.1721839",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Claire Mathieu",
    "corresponding_authors": "Claire Mathieu",
    "abstract": "No abstract available.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2028195704",
    "type": "article"
  },
  {
    "title": "Time-dependent multi-scheduling of multicast",
    "doi": "https://doi.org/10.1145/1644015.1644029",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "Rami Cohen; Dror Rawitz; Danny Raz",
    "corresponding_authors": "",
    "abstract": "Many network applications that need to distribute content and data to a large number of clients use a hybrid scheme in which one (or more) multicast channel is used in parallel to a unicast dissemination. This way the application can distribute data using one of its available multicast channels or by sending one or more unicast transmissions. In such a model the utilization of the multicast channels is critical for the overall performance of the system. We study the scheduling algorithm of the sender in such a model. We describe this scheduling problem as an optimization problem where the objective is to maximize the utilization of the multicast channel. Our model captures the fact that it may be beneficial to multicast an object more than once (e.g., page update). Thus, the benefit depends, among other things, on the last time the object was sent, which makes the problem much more complex than previous related scheduling problems. We show that our problem is NP-hard. Then, using the local ratio technique we obtain a 4-approximation algorithm for the case where the objects are of fixed size and a 10-approximation algorithm for the general case. We also consider a special case which may be of practical interest, and prove that a simple greedy algorithm is a 3-approximation algorithm in this case.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2120585634",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1824777",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We study a generalization of the k-median problem with respect to an arbitrary dissimilarity measure D. Given a finite set P of size n, our goal is to find a set C of size k such that the sum of errors D(P,C) = ∑p ∈ P minc ∈ C {D(p,c)} is minimized. The ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4233067315",
    "type": "paratext"
  },
  {
    "title": "2-Approximating Feedback Vertex Set in Tournaments",
    "doi": "https://doi.org/10.1145/3446969",
    "publication_date": "2021-04-19",
    "publication_year": 2021,
    "authors": "Daniel Lokshtanov; Pranabendu Misra; Joydeep Mukherjee; Fahad Panolan; Geevarghese Philip; Saket Saurabh",
    "corresponding_authors": "",
    "abstract": "A tournament is a directed graph T such that every pair of vertices is connected by an arc. A feedback vertex set is a set S of vertices in T such that T − S is acyclic. We consider the Feedback Vertex Set problem in tournaments. Here, the input is a tournament T and a weight function w : V ( T ) → N, and the task is to find a feedback vertex set S in T minimizing w ( S ) = ∑ v∈S w ( v ). Rounding optimal solutions to the natural LP-relaxation of this problem yields a simple 3-approximation algorithm. This has been improved to 2.5 by Cai et al. [SICOMP 2000], and subsequently to 7/3 by Mnich et al. [ESA 2016]. In this article, we give the first polynomial time factor 2-approximation algorithm for this problem. Assuming the Unique Games Conjecture, this is the best possible approximation ratio achievable in polynomial time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3156092210",
    "type": "article"
  },
  {
    "title": "Node-weighted Network Design in Planar and Minor-closed Families of Graphs",
    "doi": "https://doi.org/10.1145/3447959",
    "publication_date": "2021-04-30",
    "publication_year": 2021,
    "authors": "Chandra Chekuri; Alina Ene; Ali Vakilian",
    "corresponding_authors": "",
    "abstract": "We consider node-weighted survivable network design (SNDP) in planar graphs and minor-closed families of graphs. The input consists of a node-weighted undirected graph G = ( V , E ) and integer connectivity requirements r ( uv ) for each unordered pair of nodes uv . The goal is to find a minimum weighted subgraph H of G such that H contains r ( uv ) disjoint paths between u and v for each node pair uv . Three versions of the problem are edge-connectivity SNDP (EC-SNDP), element-connectivity SNDP (Elem-SNDP), and vertex-connectivity SNDP (VC-SNDP), depending on whether the paths are required to be edge, element, or vertex disjoint, respectively. Our main result is an O ( k )-approximation algorithm for EC-SNDP and Elem-SNDP when the input graph is planar or more generally if it belongs to a proper minor-closed family of graphs; here, k = max uv r ( uv ) is the maximum connectivity requirement. This improves upon the O ( k log n )-approximation known for node-weighted EC-SNDP and Elem-SNDP in general graphs [31]. We also obtain an O (1) approximation for node-weighted VC-SNDP when the connectivity requirements are in {0, 1, 2}; for higher connectivity our result for Elem-SNDP can be used in a black-box fashion to obtain a logarithmic factor improvement over currently known general graph results. Our results are inspired by, and generalize, the work of Demaine, Hajiaghayi, and Klein [13], who obtained constant factor approximations for node-weighted Steiner tree and Steiner forest problems in planar graphs and proper minor-closed families of graphs via a primal-dual algorithm.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3168881589",
    "type": "article"
  },
  {
    "title": "Sparse Backbone and Optimal Distributed SINR Algorithms",
    "doi": "https://doi.org/10.1145/3452937",
    "publication_date": "2021-04-30",
    "publication_year": 2021,
    "authors": "Magnús M. Halldórsson; Tigran Tonoyan",
    "corresponding_authors": "",
    "abstract": "We develop randomized distributed algorithms for many of the most fundamental communication problems in wireless networks under the Signal to Interference and Noise Ratio (SINR) model of communication, including (multi-message) broadcast, local broadcast, coloring, Maximal Independent Set, and aggregation. The complexity of our algorithms is optimal up to polylogarithmic preprocessing time. It shows—contrary to expectation—that the plain vanilla SINR model is just as powerful and fast (modulo the preprocessing) as various extensions studied, including power control, carrier sense, collision detection, free acknowledgements, and geolocation knowledge. Central to these results is an efficient construction of a constant-density backbone structure over the network, which is of independent interest. This is achieved using an indirect sensing technique, where message non-reception is used to deduce information about relative node-distances.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3171729808",
    "type": "article"
  },
  {
    "title": "The Complexity of Approximately Counting Retractions to Square-free Graphs",
    "doi": "https://doi.org/10.1145/3458040",
    "publication_date": "2021-07-15",
    "publication_year": 2021,
    "authors": "Jacob Focke; Leslie Ann Goldberg; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "A retraction is a homomorphism from a graph G to an induced subgraph H of G that is the identity on H . In a long line of research, retractions have been studied under various algorithmic settings. Recently, the problem of approximately counting retractions was considered. We give a complete trichotomy for the complexity of approximately counting retractions to all square-free graphs (graphs that do not contain a cycle of length 4). It turns out there is a rich and interesting class of graphs for which this problem is complete in the class #BIS. As retractions generalise homomorphisms, our easiness results extend to the important problem of approximately counting homomorphisms. By giving new #BIS-easiness results, we now settle the complexity of approximately counting homomorphisms for a whole class of non-trivial graphs that were previously unresolved.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3185350268",
    "type": "article"
  },
  {
    "title": "Online Service with Delay",
    "doi": "https://doi.org/10.1145/3459925",
    "publication_date": "2021-07-15",
    "publication_year": 2021,
    "authors": "Yossi Azar; Arun Ganesh; Rong Ge; Debmalya Panigrahi",
    "corresponding_authors": "",
    "abstract": "In this article, we introduce the online service with delay problem. In this problem, there are n points in a metric space that issue service requests over time, and there is a server that serves these requests. The goal is to minimize the sum of distance traveled by the server and the total delay (or a penalty function thereof) in serving the requests. This problem models the fundamental tradeoff between batching requests to improve locality and reducing delay to improve response time, which has many applications in operations management, operating systems, logistics, supply chain management, and scheduling. Our main result is to show a poly-logarithmic competitive ratio for the online service with delay problem. This result is obtained by an algorithm that we call the preemptive service algorithm . The salient feature of this algorithm is a process called preemptive service, which uses a novel combination of (recursive) time forwarding and spatial exploration on a metric space. We also generalize our results to k &gt; 1 servers and obtain stronger results for special metrics such as uniform and star metrics that correspond to (weighted) paging problems.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W3186341792",
    "type": "article"
  },
  {
    "title": "Dynamic Distribution-Sensitive Point Location",
    "doi": "https://doi.org/10.1145/3487403",
    "publication_date": "2021-12-02",
    "publication_year": 2021,
    "authors": "Siu-Wing Cheng; Man-Kit Lau",
    "corresponding_authors": "",
    "abstract": "We propose a dynamic data structure for the distribution-sensitive point location problem in the plane. Suppose that there is a fixed query distribution within a convex subdivision S , and we are given an oracle that can return in O (1) time the probability of a query point falling into a polygonal region of constant complexity. We can maintain S such that each query is answered in O opt (S) ) expected time, where opt ( S ) is the expected time of the best linear decision tree for answering point location queries in S . The space and construction time are O(n log 2 n ), where n is the number of vertices of S . An update of S as a mixed sequence of k edge insertions and deletions takes O(k log 4 n) amortized time. As a corollary, the randomized incremental construction of the Voronoi diagram of n sites can be performed in O(n log 4 n ) expected time so that, during the incremental construction, a nearest neighbor query at any time can be answered optimally with respect to the intermediate Voronoi diagram at that time.",
    "cited_by_count": 2,
    "openalex_id": "https://openalex.org/W4205811793",
    "type": "article"
  },
  {
    "title": "Algorithmic aspects of bandwidth trading",
    "doi": "https://doi.org/10.1145/1219944.1219956",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Randeep Bhatia; Julia Chuzhoy; Ari Freund; Joseph Naor",
    "corresponding_authors": "",
    "abstract": "We study algorithmic problems that are motivated by bandwidth trading in next-generation networks. Typically, bandwidth trading involves sellers (e.g., network operators) interested in selling bandwidth pipes that offer to buyers a guaranteed level of service for a specified time interval. The buyers (e.g., bandwidth brokers) are looking to procure bandwidth pipes to satisfy the reservation requests of end-users (e.g., Internet subscribers). Depending on what is available in the bandwidth exchange, the goal of a buyer is to either spend the least amount of money so as to satisfy all the reservations made by its customers, or to maximize its revenue from whatever reservations can be satisfied.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4231342009",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1290672",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Skip graphs are a novel distributed data structure, based on skip lists, that provide the full functionality of a balanced tree in a distributed system where resources are stored in separate nodes that may fail at any time. They are designed for use in ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4235119426",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1328911",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present a new analysis of the well-known family of multiplicative hash functions, and improved deterministic algorithms for selecting “good” hash functions. The main motivation is realization of deterministic dictionaries with fast lookups and ...",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4244916840",
    "type": "paratext"
  },
  {
    "title": "Problems column",
    "doi": "https://doi.org/10.1145/1273340.1273351",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "Samir Khuller",
    "corresponding_authors": "Samir Khuller",
    "abstract": "article Problems column Share on Author: Samir Khuller University of Maryland, College Park, MD University of Maryland, College Park, MDView Profile Authors Info & Claims ACM Transactions on AlgorithmsVolume 3Issue 3August 2007 pp 35–eshttps://doi.org/10.1145/1273340.1273351Online:01 August 2007Publication History 1citation517DownloadsMetricsTotal Citations1Total Downloads517Last 12 Months3Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4249367277",
    "type": "article"
  },
  {
    "title": "Common Tangents of Two Disjoint Polygons in Linear Time and Constant Workspace",
    "doi": "https://doi.org/10.1145/3284355",
    "publication_date": "2018-12-06",
    "publication_year": 2018,
    "authors": "Mikkel Abrahamsen; Bartosz Walczak",
    "corresponding_authors": "",
    "abstract": "We provide a remarkably simple algorithm to compute all (at most four) common tangents of two disjoint simple polygons. Given each polygon as a read-only array of its corners in cyclic order, the algorithm runs in linear time and constant workspace and is the first to achieve the two complexity bounds simultaneously. The set of common tangents provides basic information about the convex hulls of the polygons—whether they are nested, overlapping, or disjoint—and our algorithm thus also decides this relationship.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2782758897",
    "type": "article"
  },
  {
    "title": "Locating Errors in Faulty Formulas",
    "doi": "https://doi.org/10.1145/3313776",
    "publication_date": "2019-06-07",
    "publication_year": 2019,
    "authors": "Sampath Kannan; Kevin Tian",
    "corresponding_authors": "",
    "abstract": "Given a drawing of a read-once formula (called the blueprint), and a blackbox implementation with the same topology as the blueprint that purports to compute the formula, can we tell if it does? Under a fault model, where the only faults in the implementation are gates that complement their outputs, we show that there is an efficient algorithm that makes a linear number of probes to the blackbox implementation and determines if the blueprint and implementation are identical. We also show a matching lower bound. We further ask whether we can diagnose where the faults are, using blackbox testing. We prove that if the implementation has a property called polynomial balance , then it is possible to do this efficiently. To complement this result, we show that even if the blueprint is polynomially balanced and there are only logarithmically many errors in the implementation, the implementation could be unbalanced and the diagnosis problem provably requires super-polynomially many tests. We point out that this problem is one instance of a general class of problems of learning deviations from a blueprint, which we call conformance learning . Conformance learning seems worthy of further investigation in a broader context.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2953097310",
    "type": "article"
  },
  {
    "title": "地形保護のための正確なアルゴリズム【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Ashok Pradeesha; V Fomin Fedor; Kolay Sudeshna; Saket Saurabh; Meirav Zehavi",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3180536692",
    "type": "article"
  },
  {
    "title": "A Mazing 2+ϵ Approximation for Unsplittable Flow on a Path.",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Aris Anagnostopoulos; Fabrizio Grandoni; Stefano Leonardi; Andreas Wiese",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3209528612",
    "type": "article"
  },
  {
    "title": "On the Two-Dimensional Knapsack Problem for Convex Polygons",
    "doi": "https://doi.org/10.1145/3644390",
    "publication_date": "2024-02-20",
    "publication_year": 2024,
    "authors": "Arturo Merino; Andreas Wiese",
    "corresponding_authors": "",
    "abstract": "We study the two-dimensional geometric knapsack problem for convex polygons. Given a set of weighted convex polygons and a square knapsack, the goal is to select the most profitable subset of the given polygons that fits non-overlappingly into the knapsack. We allow to rotate the polygons by arbitrary angles. We present a quasi-polynomial time O (1)-approximation algorithm for the general case and a pseudopolynomial time O (1)-approximation algorithm if all input polygons are triangles, both assuming polynomially bounded integral input data. Additionally, we give a quasi-polynomial time algorithm that computes a solution of optimal weight under resource augmentation—that is, we allow to increase the size of the knapsack by a factor of 1+δ for some δ &gt; 0 but compare ourselves with the optimal solution for the original knapsack. To the best of our knowledge, these are the first results for two-dimensional geometric knapsack in which the input objects are more general than axis-parallel rectangles or circles and in which the input polygons can be rotated by arbitrary angles.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3046578832",
    "type": "article"
  },
  {
    "title": "Combinatorial generation via permutation languages. IV. Elimination trees",
    "doi": "https://doi.org/10.1145/3689633",
    "publication_date": "2024-10-31",
    "publication_year": 2024,
    "authors": "Jean Cardinal; Arturo Merino; Torsten Mütze",
    "corresponding_authors": "",
    "abstract": "An elimination tree for a connected graph \\(G\\) is a rooted tree on the vertices of \\(G\\) obtained by choosing a root \\(x\\) and recursing on the connected components of \\(G-x\\) to produce the subtrees of \\(x\\) . Elimination trees appear in many guises in computer science and discrete mathematics, and they encode many interesting combinatorial objects, such as bitstrings, permutations and binary trees. We apply the recent Hartung-Hoang-Mütze-Williams combinatorial generation framework to elimination trees, and prove that all elimination trees for a chordal graph \\(G\\) can be generated by tree rotations using a simple greedy algorithm. This yields a short proof for the existence of Hamilton paths on graph associahedra of chordal graphs. Graph associahedra are a general class of high-dimensional polytopes introduced by Carr, Devadoss, and Postnikov, whose vertices correspond to elimination trees and whose edges correspond to tree rotations. As special cases of our results, we recover several classical Gray codes for bitstrings, permutations and binary trees, and we obtain a new Gray code for partial permutations. Our algorithm for generating all elimination trees for a chordal graph \\(G\\) can be implemented in time \\(cO(\\sigma)\\) on average per generated elimination tree, where \\(\\sigma=\\sigma(G)\\) denotes the maximum number of edges of an induced star in \\(G\\) . If \\(G\\) is a tree, we improve this to a loopless algorithm running in time \\(cO(1)\\) per generated elimination tree. We also prove that our algorithm produces a Hamilton cycle on the graph associahedron of \\(G\\) , rather than just Hamilton path, if the graph \\(G\\) is chordal and 2-connected. Moreover, our algorithm characterizes chordality, i.e., it computes a Hamilton path on the graph associahedron of \\(G\\) if and only if \\(G\\) is chordal.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3175320986",
    "type": "article"
  },
  {
    "title": "Width Helps and Hinders Splitting Flows",
    "doi": "https://doi.org/10.1145/3641820",
    "publication_date": "2024-01-22",
    "publication_year": 2024,
    "authors": "Manuel Cáceres; Massimo Cairo; Andreas Grigorjew; Shahbaz Khan; Brendan Mumey; Roméo Rizzi; Alexandru I. Tomescu; Lucia Williams",
    "corresponding_authors": "",
    "abstract": "Minimum flow decomposition (MFD) is the NP-hard problem of finding a smallest decomposition of a network flow/circulation X on a directed graph G into weighted source-to-sink paths whose weighted sum equals X . We show that, for acyclic graphs, considering the width of the graph (the minimum number of paths needed to cover all of its edges) yields advances in our understanding of its approximability. For the version of the problem that uses only non-negative weights, we identify and characterise a new class of width-stable graphs, for which a popular heuristic is a O (log Val ( X ))-approximation ( Val ( X ) being the total flow of X ), and strengthen its worst-case approximation ratio from \\(\\Omega (\\sqrt {m})\\) to Ω ( m /log m ) for sparse graphs, where m is the number of edges in the graph. We also study a new problem on graphs with cycles, Minimum Cost Circulation Decomposition (MCCD), and show that it generalises MFD through a simple reduction. For the version allowing also negative weights, we give a (⌈ log ‖ X ‖ ⌉ +1)-approximation (‖ X ‖ being the maximum absolute value of X on any edge) using a power-of-two approach, combined with parity fixing arguments and a decomposition of unitary circulations (‖ X ‖ ≤ 1), using a generalised notion of width for this problem. Finally, we disprove a conjecture about the linear independence of minimum (non-negative) flow decompositions posed by Kloster et al. [ 2018 ], but show that its useful implication (polynomial-time assignments of weights to a given set of paths to decompose a flow) holds for the negative version.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4391103911",
    "type": "article"
  },
  {
    "title": "The Complexity of Finding Fair Many-to-One Matchings",
    "doi": "https://doi.org/10.1145/3649220",
    "publication_date": "2024-02-24",
    "publication_year": 2024,
    "authors": "Niclas Boehmer; Tomohiro Koana",
    "corresponding_authors": "",
    "abstract": "We analyze the (parameterized) computational complexity of “fair” variants of bipartite many-to-one matching, where each vertex from the “left” side is matched to exactly one vertex and each vertex from the “right” side may be matched to multiple vertices. We want to find a “fair” matching, in which each vertex from the right side is matched to a “fair” set of vertices. Assuming that each vertex from the left side has one color modeling its “attribute”, we study two fairness criteria. For instance, in one of them, we deem a vertex set fair if for any two colors, the difference between the numbers of their occurrences does not exceed a given threshold. Fairness is, for instance, relevant when finding many-to-one matchings between students and colleges, voters and constituencies, and applicants and firms. Here colors may model sociodemographic attributes, party memberships, and qualifications, respectively. We show that finding a fair many-to-one matching is NP-hard even for three colors and maximum degree five. Our main contribution is the design of fixed-parameter tractable algorithms with respect to the number of vertices on the right side. Our algorithms make use of a variety of techniques including color coding. At the core lie integer linear programs encoding Hall like conditions. We establish the correctness of our integer programs, based on Frank’s separation theorem [Frank, Discrete Math. 1982]. We further obtain complete complexity dichotomies regarding the number of colors and the maximum degree of each side.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4392131515",
    "type": "article"
  },
  {
    "title": "On Computing the \\(k\\) -Shortcut Fréchet Distance",
    "doi": "https://doi.org/10.1145/3663762",
    "publication_date": "2024-05-23",
    "publication_year": 2024,
    "authors": "Jacobus Conradi; Anne Driemel",
    "corresponding_authors": "",
    "abstract": "The Fréchet distance is a popular measure of dissimilarity for polygonal curves. It is defined as a min-max formulation that considers all orientation-preserving bijective mappings between the two curves. Because of its susceptibility to noise, Driemel and Har-Peled introduced the shortcut Fréchet distance in 2012, where one is allowed to take shortcuts along one of the curves, similar to the edit distance for sequences. We analyse the parameterized version of this problem, where the number of shortcuts is bounded by a parameter \\(k\\) . The corresponding decision problem can be stated as follows: Given two polygonal curves \\(T\\) and \\(B\\) of at most \\(n\\) vertices, a parameter \\(k\\) and a distance threshold \\(\\delta\\) , is it possible to introduce \\(k\\) shortcuts along \\(B\\) such that the Fréchet distance of the resulting curve and the curve \\(T\\) is at most \\(\\delta\\) ? We study this problem for polygonal curves in the plane. We provide a complexity analysis for this problem with the following results: (i) there exists a decision algorithm with running time in \\(\\mathcal{O}(kn^{2k+2}\\log n)\\) ; (ii) assuming the exponential-time-hypothesis (ETH), there exists no algorithm with running time bounded by \\(n^{o(k)}\\) . In contrast, we also show that efficient approximate decider algorithms are possible, even when \\(k\\) is large. We present a \\((3+\\varepsilon)\\) -approximate decider algorithm with running time in \\(\\mathcal{O}(kn^{2}\\log^{2}n)\\) for fixed \\(\\varepsilon\\) . In addition, we can show that, if \\(k\\) is a constant and the two curves are \\(c\\) -packed for some constant \\(c\\) , then the approximate decider algorithm runs in near-linear time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4398237645",
    "type": "article"
  },
  {
    "title": "An Improved Drift Theorem for Balanced Allocations",
    "doi": "https://doi.org/10.1145/3673900",
    "publication_date": "2024-07-01",
    "publication_year": 2024,
    "authors": "Dimitrios Los; Thomas Sauerwald",
    "corresponding_authors": "",
    "abstract": "In the balanced allocations framework, there are \\(m\\) jobs (balls) to be allocated to \\(n\\) servers (bins). The goal is to minimize the gap , the difference between the maximum and the average load. In 2015, Peres, Talwar and Wieder used the hyperbolic cosine potential function to analyze the challenging case where \\(m\\gg n\\) , for a large family of processes, including the \\((1+\\beta)\\) -process and graphical balanced allocations. The key ingredient was to prove that the potential drops in every step, i.e., a drift inequality . In this work, we improve the drift inequality so that (i) it is asymptotically tight (leading to tighter gap bounds), (ii) it assumes weaker preconditions (thereby resolving an open problem regarding weighted graphical allocations), (iii) it applies not only to processes allocating to more than one bin in a single step but also (iv) to processes allocating a varying number of balls depending on the sampled bin. Our applications include the aforementioned large family of processes, and also several new processes and settings, including outdated information and memory. We hope that our techniques can be used to analyze further interesting settings and processes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400201386",
    "type": "article"
  },
  {
    "title": "Breaking the Barrier of 2 for the Competitiveness of Longest Queue Drop",
    "doi": "https://doi.org/10.1145/3676887",
    "publication_date": "2024-07-12",
    "publication_year": 2024,
    "authors": "Antonios Antoniadis; Matthias Englert; Nicolaos Matsakis; Pavel Veselý",
    "corresponding_authors": "",
    "abstract": "We consider the problem of managing the buffer of a shared-memory switch that transmits packets of unit value. A shared-memory switch consists of an input port, a number of output ports, and a buffer with a specific capacity. In each time step, an arbitrary number of packets arrive at the input port, each packet designated for one output port. Each packet is added to the queue of the respective output port. If the total number of packets exceeds the capacity of the buffer, some packets have to be irrevocably evicted. At the end of each time step, each output port transmits a packet in its queue, and the goal is to maximize the number of transmitted packets. The Longest Queue Drop ( LQD ) online algorithm accepts any arriving packet to the buffer. However, if this results in the buffer exceeding its memory capacity, then LQD drops a packet from whichever queue is currently the longest, breaking ties arbitrarily. The LQD algorithm was first introduced in 1991, and has been known to be \\(2\\) -competitive since 2001. Although LQD remains the best known online algorithm for the problem and is of practical interest, determining its true competitiveness is a long-standing open problem. We show that LQD is 1.6918-competitive, establishing the first \\((2-\\varepsilon)\\) upper bound for the competitive ratio of LQD for a constant \\(\\varepsilon{\\,\\gt\\,}0\\) .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400580852",
    "type": "article"
  },
  {
    "title": "Polynomial Integrality Gap of Flow LP for Directed Steiner Tree",
    "doi": "https://doi.org/10.1145/3681791",
    "publication_date": "2024-07-30",
    "publication_year": 2024,
    "authors": "Shi Li; Bundit Laekhanukit",
    "corresponding_authors": "",
    "abstract": "In the Directed Steiner Tree (DST) problem, we are given a directed graph \\(G=(V,E)\\) on \\(n\\) vertices with edge-costs \\(c\\in{\\mathbb{R}}_{\\geq 0}^{E}\\) , a root vertex \\(r\\in V\\) , and a set \\(K\\subseteq V\\setminus\\{r\\}\\) of \\(k\\) terminals. The goal is to find a minimum-cost subgraph of \\(G\\) that contains a path from \\(r\\) to every terminal \\(t\\in K\\) . DST has been a notorious problem for decades as there is a large gap between the best-known polynomial-time approximation ratio of \\(O(k^{\\epsilon})\\) for any constant \\(\\epsilon \\gt 0\\) , and the best quasi-polynomial-time approximation ratio of \\(O\\left(\\frac{\\log^{2}k}{\\log\\log k}\\right)\\) . Toward understanding this gap, we study the integrality gap of the standard flow linear programming relaxation for the problem. We show that the linear program (LP) has an integrality gap of \\(\\Omega(n^{0.0418})\\) . Previously, the integrality gap of the LP is only known to be \\(\\Omega\\left(\\frac{\\log^{2}n}{\\log\\log n}\\right)\\) [Halperin et al., SODA’03 &amp; SIAM J. Comput.] and \\(\\Omega(\\sqrt{k})\\) [Zosin-Khuller, SODA’02] in some instance with \\(\\sqrt{k}=O\\left(\\frac{\\log n}{\\log\\log n}\\right)\\) . Our result gives the first known lower bound on the integrality gap of this standard LP that is polynomial in \\(n\\) , the number of vertices. Consequently, we rule out the possibility of developing a poly-logarithmic approximation algorithm for the problem based on the flow LP relaxation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401122432",
    "type": "article"
  },
  {
    "title": "Automorphisms and Isomorphisms of Maps in Linear Time",
    "doi": "https://doi.org/10.1145/3686798",
    "publication_date": "2024-08-07",
    "publication_year": 2024,
    "authors": "Ken‐ichi Kawarabayashi; Bojan Mohar; Roman Nedela; Peter Zeman",
    "corresponding_authors": "",
    "abstract": "A map is a 2-cell decomposition of a closed compact surface, i.e., an embedding of a graph such that every face is homeomorphic to an open disc. An automorphism of a map can be thought of as a permutation of the vertices which preserves the vertex-edge-face incidences in the embedding. Every automorphism of a map determines an angle-preserving homeomorphism of the surface. While it is conjectured that there is no “truly subquadratic” algorithm for testing map isomorphism for unconstrained genus, we present a linear-time algorithm for computing the generators of the automorphism group of a map on an orientable surface of genus g≠0, parametrized by the genus g. A map on an orientable surface is uniform if the cyclic vector of sizes of faces incident to a vertex does not depend on the choice of v. The algorithm applies a sequence of local reductions and produces a uniform map, while preserving the automorphism group. The automorphism group of the original map can be reconstructed from the automorphism group of the associated uniform map in linear time. We also extend the algorithm to non-orientable surfaces by making use of the antipodal double-cover. The algorithm can be used to solve the map isomorphism problem between maps (orientable or non-orientable) of bounded negative Euler characteristic.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401390257",
    "type": "article"
  },
  {
    "title": "Online Euclidean Spanners",
    "doi": "https://doi.org/10.1145/3681790",
    "publication_date": "2024-08-08",
    "publication_year": 2024,
    "authors": "Sujoy Bhore; Csaba D. Tóth",
    "corresponding_authors": "",
    "abstract": "In this article, we study the online Euclidean spanners problem for points in \\(\\mathbb{R}^{d}\\) . Given a set \\(S\\) of \\(n\\) points in \\(\\mathbb{R}^{d}\\) , a \\(t\\) -spanner on \\(S\\) is a subgraph of the underlying complete graph \\(G=(S,\\binom{S}{2})\\) , that preserves the pairwise Euclidean distances between points in \\(S\\) to within a factor of \\(t\\) , that is the stretch factor . Suppose we are given a sequence of \\(n\\) points \\((s_{1},s_{2},\\ldots,s_{n})\\) in \\(\\mathbb{R}^{d}\\) , where point \\(s_{i}\\) is presented in step \\(i\\) for \\(i=1,\\ldots,n\\) . The objective of an online algorithm is to maintain a geometric \\(t\\) -spanner on \\(S_{i}=\\{s_{1},\\ldots,s_{i}\\}\\) for each step \\(i\\) . The algorithm is allowed to add new edges to the spanner when a new point is presented but cannot remove any edge from the spanner. The performance of an online algorithm is measured by its competitive ratio, which is the supremum, over all sequences of points, of the ratio between the weight of the spanner constructed by the algorithm and the weight of an optimum spanner. Here, the weight of a spanner is the sum of all edge weights. First, we establish a lower bound of \\(\\Omega(\\varepsilon^{-1}\\log n/\\log\\varepsilon^{-1})\\) for the competitive ratio of any online \\((1+\\varepsilon)\\) -spanner algorithm, for a sequence of \\(n\\) points in 1-dimension. We show that this bound is tight, and there is an online algorithm that can maintain a \\((1+\\varepsilon)\\) -spanner with competitive ratio \\(O(\\varepsilon^{-1}\\log n/\\log\\varepsilon^{-1})\\) . Next, we design online algorithms for sequences of points in \\(\\mathbb{R}^{d}\\) , for any constant \\(d\\geq 2\\) , under the \\(L_{2}\\) norm. We show that previously known incremental algorithms achieve a competitive ratio \\(O(\\varepsilon^{-(d+1)}\\log n)\\) . However, if the algorithm is allowed to use additional points (Steiner points), then it is possible to substantially improve the competitive ratio in terms of \\(\\varepsilon\\) . We describe an online Steiner \\((1+\\varepsilon)\\) -spanner algorithm with competitive ratio \\(O(\\varepsilon^{(1-d)/2}\\log n)\\) . As a counterpart, we show that the dependence on \\(n\\) cannot be eliminated in dimensions \\(d\\geq 2\\) . In particular, we prove that any online spanner algorithm for a sequence of \\(n\\) points in \\(\\mathbb{R}^{d}\\) under the \\(L_{2}\\) norm has competitive ratio \\(\\Omega(f(n))\\) , where \\(\\lim_{n\\rightarrow\\infty}f(n)=\\infty\\) . Finally, we provide improved lower bounds under the \\(L_{1}\\) norm: \\(\\Omega(\\varepsilon^{-2}/\\log\\varepsilon^{-1})\\) in the plane and \\(\\Omega(\\varepsilon^{-d})\\) in \\(\\mathbb{R}^{d}\\) for \\(d\\geq 3\\) .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401422267",
    "type": "article"
  },
  {
    "title": "Tight Bounds for Monotone Minimal Perfect Hashing",
    "doi": "https://doi.org/10.1145/3677608",
    "publication_date": "2024-08-08",
    "publication_year": 2024,
    "authors": "Sepehr Assadi; Martı́n Farach-Colton; William Kuszmaul",
    "corresponding_authors": "",
    "abstract": "The monotone minimal perfect hash function (MMPHF) problem is the following indexing problem. Given a set \\(S=\\{s_{1},\\ldots,s_{n}\\}\\) of \\(n\\) distinct keys from a universe \\(U\\) of size \\(u\\) , create a data structure \\(\\text{D}\\) that answers the following query: \\(\\begin{equation*} \\rm{R\\small{ANK}}(q) = \\begin{cases} \\text{rank of } q \\text{ in } S &amp; q\\in S\\\\ \\text{arbitrary answer} &amp; \\text{otherwise.}\\end{cases}\\end{equation*}\\) Solutions to the MMPHF problem are in widespread use in both theory and practice. The best upper bound known for the problem encodes \\(\\text{D}\\) in \\(O(n\\log\\log\\log u)\\) bits and performs queries in \\(O(\\log u)\\) time. It has been an open problem to either improve the space upper bound or to show that this somewhat odd looking bound is tight. In this paper, we show the latter: any data structure (deterministic or randomized) for monotone minimal perfect hashing of any collection of \\(n\\) elements from a universe of size \\(u\\) requires \\(\\Omega(n\\cdot\\log\\log\\log{u})\\) expected bits to answer every query correctly. We achieve our lower bound by defining a graph \\(\\mathbf{G}\\) where the nodes are the possible \\({u\\choose n}\\) inputs and where two nodes are adjacent if they cannot share the same \\(\\text{D}\\) . The size of \\(\\text{D}\\) is then lower bounded by the log of the chromatic number of \\(\\mathbf{G}\\) . Finally, we show that the fractional chromatic number (and hence the chromatic number) of \\(\\mathbf{G}\\) is lower bounded by \\(2^{\\Omega(n\\log\\log\\log u)}\\) .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401422447",
    "type": "article"
  },
  {
    "title": "Complexity of High-Dimensional Identity Testing with Coordinate Conditional Sampling",
    "doi": "https://doi.org/10.1145/3686799",
    "publication_date": "2024-08-21",
    "publication_year": 2024,
    "authors": "Antonio Blanca; Zongchen Chen; Daniel Štefankovič; Eric Vigoda",
    "corresponding_authors": "",
    "abstract": "We study the identity testing problem for high-dimensional distributions. Given as input an explicit distribution \\(\\mu\\) , an \\(\\varepsilon \\gt 0\\) , and access to sampling oracle(s) for a hidden distribution \\(\\pi\\) , the goal in identity testing is to distinguish whether the two distributions \\(\\mu\\) and \\(\\pi\\) are identical or are at least \\(\\varepsilon\\) -far apart. When there is only access to full samples from the hidden distribution \\(\\pi\\) , it is known that exponentially many samples (in the dimension) may be needed for identity testing, and hence previous works have studied identity testing with additional access to various “conditional” sampling oracles. We consider a significantly weaker conditional sampling oracle, which we call the \\(\\mathsf{Coordinate\\ Oracle}\\) , and provide a computational and statistical characterization of the identity testing problem in this new model. We prove that if an analytic property known as approximate tensorization of entropy holds for an \\(n\\) -dimensional visible distribution \\(\\mu\\) , then there is an efficient identity testing algorithm for any hidden distribution \\(\\pi\\) using \\(\\widetilde{O}(n/\\varepsilon)\\) queries to the \\(\\mathsf{Coordinate\\ Oracle}\\) . Approximate tensorization of entropy is a pertinent condition as recent works have established it for a large class of high-dimensional distributions. We also prove a computational phase transition: For a well-studied class of \\(n\\) -dimensional distributions, specifically sparse anti-ferromagnetic Ising models over \\(\\{+1,-1\\}^{n}\\) , we show that in the regime where approximate tensorization of entropy fails, there is no efficient identity testing algorithm unless \\(\\mathsf{RP}=\\mathsf{NP}\\) . We complement our results with a matching \\(\\Omega(n/\\varepsilon)\\) statistical lower bound for the sample complexity of identity testing in the \\(\\mathsf{Coordinate\\ Oracle}\\) model.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401724403",
    "type": "article"
  },
  {
    "title": "Approximately Counting Answers to Conjunctive Queries with Disequalities and Negations",
    "doi": "https://doi.org/10.1145/3689634",
    "publication_date": "2024-08-23",
    "publication_year": 2024,
    "authors": "Jacob Focke; Leslie Ann Goldberg; Marc Roth; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "We study the complexity of approximating the number of answers to a small query \\(\\varphi\\) in a large database \\(\\mathcal{D}\\) . We establish an exhaustive classification into tractable and intractable cases if \\(\\varphi\\) is a conjunctive query possibly including disequalities and negations: — If there is a constant bound on the arity of \\(\\varphi\\) , and if the randomised Exponential Time Hypothesis (rETH) holds, then the problem has a fixed-parameter tractable approximation scheme (FPTRAS) if and only if the treewidth of \\(\\varphi\\) is bounded. — If the arity is unbounded and \\(\\varphi\\) does not have negations, then the problem has an FPTRAS if and only if the adaptive width of \\(\\varphi\\) (a width measure strictly more general than treewidth) is bounded; the lower bound relies on the rETH as well. Additionally we show that our results cannot be strengthened to achieve a fully polynomial randomised approximation scheme (FPRAS): We observe that, unless \\(\\mathrm{NP}=\\mathrm{RP}\\) , there is no FPRAS even if the treewidth (and the adaptive width) is \\(1\\) . However, if there are neither disequalities nor negations, we prove the existence of an FPRAS for queries of bounded fractional hypertreewidth, strictly generalising the recently established FPRAS for conjunctive queries with bounded hypertreewidth due to Arenas, Croquevielle, Jayaram and Riveros (STOC 2021).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4401814999",
    "type": "article"
  },
  {
    "title": "Maximum Cardinality \\(f\\) -Matching in Time \\(O(n^{2/3}m)\\)",
    "doi": "https://doi.org/10.1145/3696668",
    "publication_date": "2024-09-23",
    "publication_year": 2024,
    "authors": "Harold N. Gabow",
    "corresponding_authors": "Harold N. Gabow",
    "abstract": "We present an algorithm that finds a maximum cardinality \\(f\\) -matching of a simple graph in time \\(O(n^{2/3}m)\\) . Here \\(f:V\\to\\mathbb{N}\\) is a given function and an \\(f\\) -matching is a subgraph wherein each vertex \\(v\\in V\\) has degree \\(\\leq f(v)\\) . This result generalizes a string of algorithms that concentrate on simple bipartite graphs. The bipartite case is based on the notion of level graph, introduced by Dinic for network flow. In general graphs this notion breaks down: Vertices no longer have unique levels, and there are too many levels to analyze the corresponding level graph like bipartite graphs ( \\(\\Theta(n^{2})\\) vs. \\(n\\) ). We use “natural” levels to prove properties of shortest augmenting trails (e.g., formulas for trail length). We use “shortened” levels to derive the algorithm's time bound. The algorithm, unmodified, is also efficient on multigraphs, achieving time \\(O(\\min\\{\\sqrt{f(V)},n\\} m)\\) for \\(f(V)=\\sum_{v}f(v)\\) . The special case \\(f\\equiv 1\\) shows the algorithm duplicates the classic time bound for maximum cardinality matching, \\(O(\\sqrt{n} m)\\) .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4402745972",
    "type": "article"
  },
  {
    "title": "Perfect Resolution of Strong Conflict-Free Colouring of Interval Hypergraphs",
    "doi": "https://doi.org/10.1145/3698880",
    "publication_date": "2024-10-05",
    "publication_year": 2024,
    "authors": "N. S. Narayanaswamy; S. M. Dhannya",
    "corresponding_authors": "",
    "abstract": "The \\(k\\) -Strong Conflict-Free ( \\(k\\) -SCF, in short) colouring problem seeks to find a colouring of the vertices of a hypergraph \\(H\\) using minimum number of colours so that in every hyperedge \\(e\\) of \\(H\\) , there are at least \\(\\min\\{|e|,k\\}\\) vertices whose colours are different from that of all other vertices in \\(e\\) . In the case of interval hypergraphs, we present an exact \\({\\mathsf{P}}\\) -time algorithm for the \\(k\\) -SCF problem thus solving an open problem posed by Cheilaris et al. (2014). We achieve our results by showing that for any hypergraph, a \\(k\\) -SCF colouring is a proper colouring of a related simple graph which we refer to as a co-occurrence graph . We then show that a co-occurrence graph is obtained by identifying an induced subgraph of a second simple graph that we introduce, which we refer to as the conflict graph . For interval hypergraphs, we show that each co-occurrence graph and the conflict graph are perfect graphs. This property plays a crucial role in our polynomial time algorithm. Secondly, we show that for an interval hypergraph, the \\(1\\) -SCF colouring number is the minimum partition of its intervals into sets such that each set has an exact hitting set (a hitting set in which each interval is hit exactly once).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403154786",
    "type": "article"
  },
  {
    "title": "Tiny Pointers",
    "doi": "https://doi.org/10.1145/3700594",
    "publication_date": "2024-10-21",
    "publication_year": 2024,
    "authors": "Michael A. Bender; Alex Conway; Martı́n Farach-Colton; William Kuszmaul; Guido Tagliavini",
    "corresponding_authors": "",
    "abstract": "This paper introduces a new data-structural object that we call the tiny pointer. In many applications, traditional \\(\\log n\\) -bit pointers can be replaced with \\(o(\\log n)\\) -bit tiny pointers at the cost of only a constant-factor time overhead and a small probability of failure. We develop a comprehensive theory of tiny pointers, and give optimal constructions for both fixed-size tiny pointers (i.e., settings in which all of the tiny pointers must be the same size) and variable-size tiny pointers (i.e., settings in which the average tiny-pointer size must be small, but some tiny pointers can be larger). If a tiny pointer references an item in an array filled to load factor \\(1-\\delta\\) , then the optimal tiny-pointer size is \\(\\Theta(\\log\\log\\log n+\\log\\delta^{-1})\\) bits in the fixed-size case, and \\(\\Theta(\\log\\delta^{-1})\\) expected bits in the variable-size case. Our tiny-pointer constructions also require us to revisit several classic problems having to do with balls and bins; these results may be of independent interest. Using tiny pointers, we apply tiny pointers to five classic data-structure problems. We show that: A data structure storing \\(n\\) \\(v\\) -bit values for \\(n\\) keys with constant-factor time modifications/queries can be implemented to take space \\(nv+O(n\\log^{(r)}n)\\) bits, for any constant \\(r\\gt0\\) , as long as the user stores a tiny pointer of expected size \\(O(1)\\) with each key—here, \\(\\log^{(r)}n\\) is the \\(r\\) -th iterated logarithm. Any binary search tree can be made succinct, meaning that it achieves \\((1+o(1))\\) times the optimal space, with constant-factor time overhead, and can even be made to be within \\(O(n)\\) bits of optimal if we allow for \\(O(\\log^{*}n)\\) -time modifications—this holds even for rotation-based trees such as the splay tree and the red-black tree. Any fixed-capacity key-value dictionary can be made stable (i.e., items do not move once inserted) with constant-factor time overhead and \\((1+o(1))\\) -factor space overhead. Any key-value dictionary that requires uniform-size values can be made to support arbitrary-size values with constant-factor time overhead and with an additional space consumption of \\(\\log^{(r)}n+O(\\log j)\\) bits per \\(j\\) -bit value for an arbitrary constant \\(r\\gt0\\) of our choice. Given an external-memory array \\(A\\) of size \\((1+\\varepsilon)n\\) containing a dynamic set of up to \\(n\\) key-value pairs, it is possible to maintain an internal-memory stash of size \\(O(n\\log\\varepsilon^{-1})\\) bits so that the location of any key-value pair in \\(A\\) can be computed in constant time (and with no IOs). In each case tiny pointers allow for us to take a natural space-inefficient solution that uses pointers and make it space-efficient for free.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4403601695",
    "type": "article"
  },
  {
    "title": "The Query Complexity of Searching Trees with Permanently Noisy Advice",
    "doi": "https://doi.org/10.1145/3707207",
    "publication_date": "2024-12-05",
    "publication_year": 2024,
    "authors": "Lucas Boczkowski; Uriel Feige; Amos Korman; Yoav Rodeh",
    "corresponding_authors": "",
    "abstract": "We consider a search problem on trees aiming to find a treasure that an adversary places at one of the nodes. The algorithm can query nodes and extract directional information from them. That is, each node holds a pointer, termed advice , to one of its neighbors. Ideally, this advice points to the neighbor that is closer to the treasure, however, with probability \\(q\\) this advice points to a uniformly random neighbor. Crucially, the advice is permanent , hence querying the same node again yields the same answer. Let \\(\\Delta\\) denote the maximal degree. Roughly speaking, we show that the expected number of queries incurs a phase transition when \\(q\\) is about \\(1/\\sqrt{\\Delta}\\) . In a recent paper, at TALG’21, we showed that if \\(q\\) is above the threshold then the expected number of queries is polynomial in \\(n\\) . Here, we prove that below the threshold, the expected number of queries is \\(\\mathcal{O}(\\sqrt{\\Delta}\\log\\Delta\\cdot\\log^{2}n)\\) , which is tight up to an \\(\\mathcal{O}(\\log n)\\) factor when \\(\\Delta\\) is small. We further show that this factor can be reduced to \\(\\mathcal{O}(\\log\\log n)\\) in the case of regular trees and assuming that \\(q&lt;c/\\sqrt{\\Delta}\\) for sufficiently small \\(c&gt;0\\) . In addition, we study the case that the treasure must be found with some given probability. We show that for every fixed \\(\\varepsilon,\\delta&gt;0\\) , if \\(q&lt;1/\\Delta^{\\varepsilon}\\) then there exists a search strategy that with probability \\(1-\\delta\\) finds the treasure using \\((\\delta^{-1}\\log n)^{O(\\frac{1}{\\varepsilon})}\\) queries, whereas \\((\\delta^{-1}\\log n)^{\\Omega(\\frac{1}{\\varepsilon})}\\) queries are necessary.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405075937",
    "type": "article"
  },
  {
    "title": "Faster Matroid Partition Algorithms",
    "doi": "https://doi.org/10.1145/3707208",
    "publication_date": "2024-12-05",
    "publication_year": 2024,
    "authors": "Tatsuya Terao",
    "corresponding_authors": "Tatsuya Terao",
    "abstract": "In the matroid partitioning problem, we are given \\(k\\) matroids \\(\\mathcal{M}_{1}=(V,\\mathcal{I}_{1}),\\dots,\\mathcal{M}_{k}=(V,\\mathcal{I}_{k})\\) defined over a common ground set \\(V\\) of \\(n\\) elements, and we need to find a partitionable set \\(S\\subseteq V\\) of largest possible cardinality, denoted by \\(p\\) . Here, a set \\(S\\subseteq V\\) is called partitionable if there exists a partition \\((S_{1},\\dots,S_{k})\\) of \\(S\\) with \\(S_{i}\\in\\mathcal{I}_{i}\\) for \\(i=1,\\ldots,k\\) . In 1986, Cunningham presented a matroid partition algorithm that uses \\(O(np^{3/2}+kn)\\) independence oracle queries, which was the previously known best algorithm. This query complexity is \\(O(n^{5/2})\\) when \\(k\\leq n\\) . Our main result is to present a matroid partition algorithm that uses \\(\\tilde{O}(k^{\\prime 1/3}np + kn)\\) independence oracle queries, where \\(k^{\\prime}=\\min\\{k,p\\}\\) . This query complexity is \\(\\tilde{O}(n^{7/3})\\) when \\(k\\leq n\\) , which improves upon that of Cunningham’s algorithm. To obtain our algorithm, we present a new approach edge recycling augmentation , which can be attained through new ideas: an efficient utilization of the binary search technique by Nguy \\(\\tilde{{\\hat{\\text{e}}}}\\) n and Chakrabarty et al. and a careful analysis of the independence oracle query complexity. Our analysis differs significantly from the one for matroid intersection algorithms, because of the parameter \\(k\\) . We also present a matroid partition algorithm that uses \\(\\tilde{O}((n+k)\\sqrt{p})\\) rank oracle queries.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405076280",
    "type": "article"
  },
  {
    "title": "Classification via Two-Way Comparisons",
    "doi": "https://doi.org/10.1145/3709361",
    "publication_date": "2024-12-23",
    "publication_year": 2024,
    "authors": "Marek Chrobák; Neal E. Young",
    "corresponding_authors": "",
    "abstract": "Given a weighted, ordered query set \\(Q\\) and a partition of \\(Q\\) into classes, we study the problem of computing a minimum-cost decision tree that, given any query \\(q\\in Q\\) , uses equality tests and less-than tests to determine \\(q\\) 's class. Such a tree can be faster and smaller than a conventional search tree and smaller than a lookup table (both of which must identify \\(q\\) , not just its class). We give the first polynomial-time algorithm for the problem. The algorithm extends naturally to the setting where each query has multiple allowed classes.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405705751",
    "type": "article"
  },
  {
    "title": "Finding 3-shredders efficiently",
    "doi": "https://doi.org/10.1145/1125994.1125996",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Rajneesh Hegde",
    "corresponding_authors": "Rajneesh Hegde",
    "abstract": "A shredder in an undirected graph is a set of vertices whose removal results in at least three components. A 3-shredder is a shredder of size three. We present an algorithm that, given a 3-connected graph, finds its 3-shredders in time proportional to the number of vertices and edges, when implemented on a RAM (random access machine).",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2090320427",
    "type": "article"
  },
  {
    "title": "Maintaining the Union of Unit Discs under Insertions with Near-Optimal Overhead",
    "doi": "https://doi.org/10.1145/3527614",
    "publication_date": "2022-07-31",
    "publication_year": 2022,
    "authors": "Pankaj K. Agarwal; Ravid Cohen; Dan Halperin; Wolfgang Mulzer",
    "corresponding_authors": "",
    "abstract": "We present efficient dynamic data structures for maintaining the union of unit discs and the lower envelope of pseudo-lines in the plane. More precisely, we present three main results in this paper: (i) We present a linear-size data structure to maintain the union of a set of unit discs under insertions. It can insert a disc and update the union in O (( k +1)log 2 n ) time, where n is the current number of unit discs and k is the combinatorial complexity of the structural change in the union due to the insertion of the new disc. It can also compute, within the same time bound, the area of the union after the insertion of each disc. (ii) We propose a linear-size data structure for maintaining the lower envelope of a set of x -monotone pseudo-lines. It can handle insertion/deletion of a pseudo-line in O (log 2 n ) time; for a query point x 0 ∈ ℝ, it can report, in O (log n ) time, the point on the lower envelope with x -coordinate x 0 ; and for a query point q ∈ ℝ 2 , it can return all k pseudo-lines lying below q in time O (log n + k log 2 n ). (iii) We present a linear-size data structure for storing a set of circular arcs of unit radius (not necessarily on the boundary of the union of the corresponding discs), so that for a query unit disc D , all input arcs intersecting D can be reported in O ( n 1/2+ɛ + k ) time, where k is the output size and ɛ &gt; 0 is an arbitrarily small constant. A unit-circle arc can be inserted or deleted in O (log 2 n ) time.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2950008871",
    "type": "article"
  },
  {
    "title": "Computing the Inverse Geodesic Length in Planar Graphs and Graphs of Bounded Treewidth",
    "doi": "https://doi.org/10.1145/3501303",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Sergio Cabello",
    "corresponding_authors": "Sergio Cabello",
    "abstract": "The inverse geodesic length of a graph G is the sum of the inverse of the distances between all pairs of distinct vertices of G . In some domains, it is known as the Harary index or the global efficiency of the graph. We show that, if G is planar and has n vertices, then the inverse geodesic length of G can be computed in roughly O ( n 9/5 ) time. We also show that, if G has n vertices and treewidth at most k , then the inverse geodesic length of G can be computed in O ( n log O ( k ) n ) time. In both cases, we use techniques developed for computing the sum of the distances, which does not have “inverse” component, together with batched evaluations of rational functions.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W2965517162",
    "type": "article"
  },
  {
    "title": "Clustering in Hypergraphs to Minimize Average Edge Service Time",
    "doi": "https://doi.org/10.1145/3386121",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Ori Rottenstreich; Haim Kaplan; Avinatan Hassidim",
    "corresponding_authors": "",
    "abstract": "We study the problem of clustering the vertices of a weighted hypergraph such that on average the vertices of each edge can be covered by a small number of clusters. This problem has many applications, such as for designing medical tests, clustering files on disk servers, and placing network services on servers. The edges of the hypergraph model groups of items that are likely to be needed together, and the optimization criteria that we use can be interpreted as the average delay (or cost) to serve the items of a typical edge. We describe and analyze algorithms for this problem for the case in which the clusters have to be disjoint and for the case where clusters can overlap. The analysis is often subtle and reveals interesting structure and invariants that one can utilize.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3033291176",
    "type": "article"
  },
  {
    "title": "Approximate Single-Source Fault Tolerant Shortest Path",
    "doi": "https://doi.org/10.1145/3397532",
    "publication_date": "2020-07-06",
    "publication_year": 2020,
    "authors": "Surender Baswana; Keerti Choudhary; Moazzam Hussain; Liam Roditty",
    "corresponding_authors": "",
    "abstract": "Let G=(V,E) be an n -vertices m -edges directed graph with edge weights in the range [1, W ] for some parameter W , and sϵ V be a designated source. In this article, we address several variants of the problem of maintaining the (1+ε)-approximate shortest path from s to each v ϵ V { s } in the presence of a failure of an edge or a vertex. From the graph theory perspective, we show that G has a subgraph H with Õ(ε -1 } n log W ) edges such that for any x,vϵ V , the graph H \\ x contains a path whose length is a (1+ε)-approximation of the length of the shortest path from s to v in G \\ x . We show that the size of the subgraph H is optimal (up to logarithmic factors) by proving a lower bound of Ω (ε -1 n log W ) edges. Demetrescu, Thorup, Chowdhury, and Ramachandran (SICOMP 2008) showed that the size of a fault tolerant exact shortest path subgraph in weighted directed/undirected graphs is Ω ( m ). Parter and Peleg (ESA 2013) showed that even in the restricted case of unweighted undirected graphs, the size of any subgraph for the exact shortest path is at least Ω ( n 1.5 ). Therefore, a (1+ε)-approximation is the best one can hope for. We consider also the data structure problem and show that there exists an ϕ(ε -1 n log W ) size oracle that for any vϵ V reports a (1+ε)-approximate distance of v from s on a failure of any xϵ V in O(log log 1+ε ( nW )) time. We show that the size of the oracle is optimal (up to logarithmic factors) by proving a lower bound of Ω (ε -1 n log W log -1 n ). Finally, we present two distributed algorithms . We present a single-source routing scheme that can route on a (1+ε)-approximation of the shortest path from a fixed source s to any destination t in the presence of a fault. Each vertex has a label and a routing table of ϕ(ε -1 log W ) bits. We present also a labeling scheme that assigns each vertex a label of ϕ(ε -1 log W ) bits. For any two vertices x,vϵ V , the labeling scheme outputs a (1+ε)-approximation of the distance from s to v in G \\ x using only the labels of x and v .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3039916789",
    "type": "article"
  },
  {
    "title": "Reliable Spanners for Metric Spaces",
    "doi": "https://doi.org/10.1145/3563356",
    "publication_date": "2022-09-22",
    "publication_year": 2022,
    "authors": "Sariel Har-Peled; Manor Mendel; Dániel Oláh",
    "corresponding_authors": "",
    "abstract": "A spanner is reliable if it can withstand large, catastrophic failures in the network. More precisely, any failure of some nodes can only cause a small damage in the remaining graph in terms of the dilation, that is, the spanner property is maintained for almost all nodes in the residual graph. Constructions of reliable spanners of near linear size are known in the low-dimensional Euclidean settings. Here, we present new constructions of reliable spanners for planar graphs, trees and (general) metric spaces.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3042988261",
    "type": "article"
  },
  {
    "title": "Counting Homomorphic Cycles in Degenerate Graphs",
    "doi": "https://doi.org/10.1145/3560820",
    "publication_date": "2022-09-06",
    "publication_year": 2022,
    "authors": "Lior Gishboliner; Yevgeny Levanzov; A. Shapira; Raphael Yuster",
    "corresponding_authors": "",
    "abstract": "Since counting subgraphs in general graphs is, by and large, a computationally demanding problem, it is natural to try and design fast algorithms for restricted families of graphs. One such family that has been extensively studied is that of graphs of bounded degeneracy (e.g., planar graphs). This line of work, which started in the early 80’s, culminated in a recent work of Gishboliner et al., which highlighted the importance of the task of counting homomorphic copies of cycles (i.e., cyclic walks) in graphs of bounded degeneracy. Our main result in this paper is a surprisingly tight relation between the above task and the well-studied problem of detecting (standard) copies of directed cycles in general directed graphs. More precisely, we prove the following: One can compute the number of homomorphic copies of C 2k and C 2k+1 in n -vertex graphs of bounded degeneracy in time Õ( n d k ), where the fastest known algorithm for detecting directed copies of C k in general m -edge digraphs runs in time Õ( m d k ). Conversely, one can transform any O(n b k ) algorithm for computing the number of homomorphic copies of C 2k or of C 2k+1 in n -vertex graphs of bounded degeneracy, into an Õ( m b k ) time algorithm for detecting directed copies of C k in general m -edge digraphs. We emphasize that our first result does not use a black-box reduction (as opposed to the second result which does). Instead, we design an algorithm for computing the number of C k -homomorphisms in degenerate graphs and show that one part of its analysis can be reduced to the analysis of the fastest known algorithm for detecting directed cycles in general digraphs, which was carried out in a recent breakthrough of Dalirrooyfard, Vuong and Vassilevska Williams. As a by-product of our algorithm, we obtain a new algorithm for detecting k -cycles in directed and undirected graphs of bounded degeneracy that is faster than all previously known algorithms for 7 ≤ k ≤ 11, and faster for all k ≥ 7 if the matrix multiplication exponent is 2.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3104978401",
    "type": "article"
  },
  {
    "title": "Max Flows in Planar Graphs with Vertex Capacities",
    "doi": "https://doi.org/10.1145/3504032",
    "publication_date": "2022-01-23",
    "publication_year": 2022,
    "authors": "Yipu Wang",
    "corresponding_authors": "Yipu Wang",
    "abstract": "We consider the maximum flow problem in directed planar graphs with capacities on both vertices and arcs and with multiple sources and sinks. We present three algorithms when the capacities are integers. The first algorithm runs in O ( min { k 2 n , n log 3 n + kn }) time when all capacities are bounded by a constant, where n is the number of vertices in the graph, and k is the number of terminals. This algorithm is the first to solve the vertex-disjoint paths problem in linear time when k is fixed but larger than 2. The second algorithm runs in O ( k 5 Δ n polylog ( nU )) time, where each arc capacity and finite vertex capacity is bounded by U , and Δ is the maximum degree of the graph. Finally, when k = 3, we present an algorithm that runs in O ( n log n ) time; this algorithm works even when the capacities are arbitrary reals. Our algorithms improve on the fastest previously known algorithms when k and Δ are fixed and U is bounded by a polynomial in n . Prior to this result, the fastest algorithms ran in O ( n 4/3+ o (1) ) time for unit capacities; in the smallest of O ( n 3/2 log n log U ), Õ( n 10/7 U 1/7 ), O ( n 11/8+o(1) U 1/4 ), and O ( n 4/3 + o(1) U 1/3 ) time for integer capacities; and in O ( n 2 /log n ) time for real capacities, even when k = 3.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4206982612",
    "type": "article"
  },
  {
    "title": "Optimal Las Vegas Approximate Near Neighbors in <i> ℓ <sub>p</sub> </i>",
    "doi": "https://doi.org/10.1145/3461777",
    "publication_date": "2022-01-23",
    "publication_year": 2022,
    "authors": "Alexander Wei",
    "corresponding_authors": "Alexander Wei",
    "abstract": "We show that approximate near neighbor search in high dimensions can be solved in a Las Vegas fashion (i.e., without false negatives) for ℓ p (1≤ p ≤ 2) while matching the performance of optimal locality-sensitive hashing. Specifically, we construct a data-independent Las Vegas data structure with query time O ( dn ρ ) and space usage O ( dn 1+ρ ) for ( r, c r )-approximate near neighbors in R d under the ℓ p norm, where ρ = 1/ c p + o (1). Furthermore, we give a Las Vegas locality-sensitive filter construction for the unit sphere that can be used with the data-dependent data structure of Andoni et al. (SODA 2017) to achieve optimal space-time tradeoffs in the data-dependent setting. For the symmetric case, this gives us a data-dependent Las Vegas data structure with query time O ( dn ρ ) and space usage O ( dn 1+ρ ) for ( r, c r )-approximate near neighbors in R d under the ℓ p norm, where ρ = 1/(2 c p - 1) + o (1). Our data-independent construction improves on the recent Las Vegas data structure of Ahle (FOCS 2017) for ℓ p when 1 &lt; p ≤ 2. Our data-dependent construction performs even better for ℓ p for all pε [1, 2] and is the first Las Vegas approximate near neighbors data structure to make use of data-dependent approaches. We also answer open questions of Indyk (SODA 2000), Pagh (SODA 2016), and Ahle by showing that for approximate near neighbors, Las Vegas data structures can match state-of-the-art Monte Carlo data structures in performance for both the data-independent and data-dependent settings and across space-time tradeoffs.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4207000965",
    "type": "article"
  },
  {
    "title": "Exponential Separations in Local Privacy",
    "doi": "https://doi.org/10.1145/3459095",
    "publication_date": "2022-02-08",
    "publication_year": 2022,
    "authors": "Matthew Joseph; Jieming Mao; Aaron Roth",
    "corresponding_authors": "",
    "abstract": "We prove a general connection between the communication complexity of two-player games and the sample complexity of their multi-player locally private analogues. We use this connection to prove sample complexity lower bounds for locally differentially private protocols as straightforward corollaries of results from communication complexity. In particular, we (1) use a communication lower bound for the hidden layers problem to prove an exponential sample complexity separation between sequentially and fully interactive locally private protocols, and (2) use a communication lower bound for the pointer chasing problem to prove an exponential sample complexity separation between k -round and ( k+1 )-round sequentially interactive locally private protocols, for every k .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4210856752",
    "type": "article"
  },
  {
    "title": "Quasipolynomial Multicut-mimicking Networks and Kernels for Multiway Cut Problems",
    "doi": "https://doi.org/10.1145/3501304",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Magnus Wahlström",
    "corresponding_authors": "Magnus Wahlström",
    "abstract": "We show the existence of an exact mimicking network of k O ( log k ) edges for minimum multicuts over a set of terminals in an undirected graph, where k is the total capacity of the terminals, i.e., the sum of the degrees of the terminal vertices. Furthermore, using the best available approximation algorithm for Small Set Expansion , we show that a mimicking network of k O ( log3 k ) edges can be computed in randomized polynomial time. As a consequence, we show quasipolynomial kernels for several problems, including Edge Multiway Cut , Group Feedback Edge Set for an arbitrary group, and Edge Multicut parameterized by the solution size and the number of cut requests. The result combines the matroid-based irrelevant edge approach used in the kernel for s -Multiway Cut with a recursive decomposition and sparsification of the graph along sparse cuts. This is the first progress on the kernelization of Multiway Cut problems since the kernel for s -Multiway Cut for constant value of s (Kratsch and Wahlström, FOCS 2012).",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4214824051",
    "type": "article"
  },
  {
    "title": "4 vs 7 Sparse Undirected Unweighted Diameter Is SETH-hard at Time <i>n</i> <sup>4/3</sup>",
    "doi": "https://doi.org/10.1145/3494540",
    "publication_date": "2022-03-04",
    "publication_year": 2022,
    "authors": "Édouard Bonnet",
    "corresponding_authors": "Édouard Bonnet",
    "abstract": "We show, assuming the Strong Exponential Time Hypothesis, that for every ε &gt; 0, approximating undirected unweighted Diameter on n -vertex m -edge graphs within ratio 7/4 - ε requires m 4/3 - o (1) time, even when m = Õ( n ). This is the first result that conditionally rules out a near-linear time 5/3-approximation for undirected Diameter .",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W4214852004",
    "type": "article"
  },
  {
    "title": "Deterministic Replacement Path Covering",
    "doi": "https://doi.org/10.1145/3673760",
    "publication_date": "2024-06-18",
    "publication_year": 2024,
    "authors": "C. S. Karthik; Merav Parter",
    "corresponding_authors": "",
    "abstract": "In this article, we provide a unified and simplified approach to derandomize central results in the area of fault-tolerant graph algorithms. Given a graph \\(G\\) , a vertex pair \\((s,t)\\in V(G)\\times V(G)\\) , and a set of edge faults \\(F\\subseteq E(G)\\) , a replacement path \\(P(s,t,F)\\) is an \\(s\\) - \\(t\\) shortest path in \\(G\\setminus F\\) . For integer parameters \\(L,f\\) , a replacement path covering (RPC) is a collection of subgraphs of \\(G\\) , denoted by \\(\\mathcal{G}_{L,f}=\\{G_{1},\\ldots,G_{r}\\}\\) , such that for every set \\(F\\) of at most \\(f\\) faults (i.e., \\(|F|\\leq f\\) ) and every replacement path \\(P(s,t,F)\\) of at most \\(L\\) edges, there exists a subgraph \\(G_{i}\\in\\mathcal{G}_{L,f}\\) that contains all the edges of \\(P\\) and does not contain any of the edges of \\(F\\) . The covering value of the RPC \\(\\mathcal{G}_{L,f}\\) is then defined to be the number of subgraphs in \\(\\mathcal{G}_{L,f}\\) . In the randomized setting, it is easy to build an \\((L,f)\\) -RPC with covering value of \\(O(\\max\\{L,f\\}^{\\min\\{L,f\\}}\\cdot\\min\\{L,f\\}\\cdot\\log n)\\) , but to this date, there is no efficient deterministic algorithm with matching bounds. As noted recently by Alon, Chechik, and Cohen (ICALP 2019) this poses the key barrier for derandomizing known constructions of distance sensitivity oracles and fault-tolerant spanners. We show the following: There exist efficient deterministic constructions of \\((L,f)\\) -RPCs whose covering values almost match the randomized ones, for a wide range of parameters. Our time and value bounds improve considerably over the previous construction of Parter (DISC 2019). Our algorithms are based on the introduction of a novel notion of hash families that we call Hit and Miss hash families. We then show how to construct these hash families from (algebraic) error correcting codes such as Reed-Solomon codes and Algebraic-Geometric codes. For every \\(L,f\\) , and \\(n\\) , there exists an \\(n\\) -vertex graph \\(G\\) whose \\((L,f)\\) -RPC covering value is \\(\\Omega(L^{f})\\) . This lower bound is obtained by exploiting connections to the problem of designing sparse fault-tolerant BFS structures. An application of our above deterministic constructions is the derandomization of the algebraic construction of the distance sensitivity oracle by Weimann and Yuster (FOCS 2010). The preprocessing and query time of our deterministic algorithm nearly match the randomized bounds. This resolves the open problem of Alon, Chechik and Cohen (ICALP 2019). Additionally, we show a derandomization of the randomized construction of vertex fault-tolerant spanners by Dinitz and Krauthgamer (PODC 2011) and Braunschvig et al. (Theor. Comput. Sci., 2015). The time complexity and the size bounds of the output spanners nearly match the randomized counterparts.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3048639797",
    "type": "article"
  },
  {
    "title": "Quantum Speed-ups for String Synchronizing Sets, Longest Common Substring, and \\(k\\) -mismatch Matching",
    "doi": "https://doi.org/10.1145/3672395",
    "publication_date": "2024-06-10",
    "publication_year": 2024,
    "authors": "Ce Jin; Jakob Nogler",
    "corresponding_authors": "",
    "abstract": "Longest Common Substring (LCS) is an important text processing problem, which has recently been investigated in the quantum query model. The decision version of this problem, LCS with threshold \\(d\\) , asks whether two length- \\(n\\) input strings have a common substring of length \\(d\\) . The two extreme cases, \\(d=1\\) and \\(d=n\\) , correspond respectively to Element Distinctness and Unstructured Search, two fundamental problems in quantum query complexity. However, the intermediate case \\(1\\ll d\\ll n\\) was not fully understood. We show that the complexity of LCS with threshold \\(d\\) smoothly interpolates between the two extreme cases up to \\(n^{o(1)}\\) factors: LCS with threshold \\(d\\) has a quantum algorithm in \\(n^{2/3+o(1)}/d^{1/6}\\) query complexity and time complexity, and requires at least \\(\\Omega(n^{2/3}/d^{1/6})\\) quantum query complexity. Our result improves upon previous upper bounds \\(\\tilde{O}(\\min\\{n/d^{1/2},n^{2/3}\\})\\) (Le Gall and Seddighin ITCS 2022, Akmal and Jin SODA 2022), and answers an open question of Akmal and Jin. Our main technical contribution is a quantum speed-up of the powerful String Synchronizing Set technique introduced by Kempa and Kociumaka (STOC 2019). It consistently samples \\(n/\\tau^{1-o(1)}\\) synchronizing positions in the string depending on their length- \\(\\Theta(\\tau)\\) contexts, and each synchronizing position can be reported by a quantum algorithm in \\(\\tilde{O}(\\tau^{1/2+o(1)})\\) time. Our quantum string synchronizing set also yields a near-optimal LCE data structure in the quantum setting. As another application of our quantum string synchronizing set, we study the \\(k\\) -mismatch Matching problem, which asks if the pattern has an occurrence in the text with at most \\(k\\) Hamming mismatches. Using a structural result of Charalampopoulos, Kociumaka, and Wellnitz (FOCS 2020), we obtain: \\(k\\) -mismatch matching has a quantum algorithm with \\(k^{3/4}n^{1/2+o(1)}\\) query complexity and \\(\\tilde{O}(kn^{1/2})\\) time complexity. We also observe a non-matching quantum query lower bound of \\(\\Omega(\\sqrt{kn})\\) .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4399493653",
    "type": "article"
  },
  {
    "title": "Fixed-Parameter Tractability of Maximum Colored Path and Beyond",
    "doi": "https://doi.org/10.1145/3674835",
    "publication_date": "2024-06-28",
    "publication_year": 2024,
    "authors": "Fedor V. Fomin; Petr A. Golovach; Tuukka Korhonen; Kirill Simonov; Giannos Stamoulis",
    "corresponding_authors": "",
    "abstract": "We introduce a general method for obtaining fixed-parameter algorithms for problems about finding paths in undirected graphs, where the length of the path could be unbounded in the parameter. The first application of our method is as follows. We give a randomized algorithm, that given a colored \\(n\\) -vertex undirected graph, vertices \\(s\\) and \\(t\\) , and an integer \\(k\\) , finds an \\((s,t)\\) -path containing at least \\(k\\) different colors in time \\(2^{k}n^{\\mathcal{O}(1)}\\) . This is the first FPT algorithm for this problem, and it generalizes the algorithm of Björklund, Husfeldt, and Taslaman on finding a path through \\(k\\) specified vertices. It also implies the first \\(2^{k}n^{\\mathcal{O}(1)}\\) time algorithm for finding an \\((s,t)\\) -path of length at least \\(k\\) . Our method yields FPT algorithms for even more general problems. For example, we consider the problem where the input consists of an \\(n\\) -vertex undirected graph \\(G\\) , a matroid \\(M\\) whose elements correspond to the vertices of \\(G\\) and which is represented over a finite field of order \\(q\\) , a positive integer weight function on the vertices of \\(G\\) , two sets of vertices \\(S,T\\subseteq V(G)\\) , and integers \\(p,k,w\\) , and the task is to find \\(p\\) vertex-disjoint paths from \\(S\\) to \\(T\\) so that the union of the vertices of these paths contains an independent set of \\(M\\) of cardinality \\(k\\) and weight \\(w\\) , while minimizing the sum of the lengths of the paths. We give a \\(2^{p+\\mathcal{O}(k^{2}\\log(q+k))}n^{\\mathcal{O}(1)}w\\) time randomized algorithm for this problem.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4400118168",
    "type": "article"
  },
  {
    "title": "Odd Cycle Transversal on \\(P_{5}\\) -free Graphs in Polynomial Time",
    "doi": "https://doi.org/10.1145/3708544",
    "publication_date": "2024-12-13",
    "publication_year": 2024,
    "authors": "Akanksha Agrawal; Paloma T. Lima; Daniel Lokshtanov; Paweł Rzążewski; Saket Saurabh; Roohani Sharma",
    "corresponding_authors": "",
    "abstract": "An independent set in a graph \\(G\\) is a set of pairwise non-adjacent vertices. A graph \\(G\\) is bipartite if its vertex set can be partitioned into two independent sets. In the Odd Cycle Transversal problem, the input is a graph \\(G\\) along with a weight function w associating a rational weight with each vertex, and the task is to find a minimum weight vertex subset \\(S\\) in \\(G\\) such that \\(G-S\\) is bipartite; the weight of \\(S\\) , \\(\\text{w}(S)=\\sum_{v\\in S}\\text{w}(v)\\) . We show that Odd Cycle Transversal is polynomial-time solvable on graphs excluding \\(P_{5}\\) (a path on five vertices) as an induced subgraph. The problem was previously known to be polynomial-time solvable on \\(P_{4}\\) -free graphs and NP -hard on \\(P_{6}\\) -free graphs [Dabrowski, Feghali, Johnson, Paesani, Paulusma and Rzążewski, Algorithmica 2020]. Bonamy, Dabrowski, Feghali, Johnson and Paulusma [Algorithmica 2019] posed the existence of a polynomial-time algorithm on \\(P_{5}\\) -free graphs as an open problem. This was later re-stated by Rzążewski [Dagstuhl Reports, 9(6): 2019], by Chudnovsky, King, Pilipczuk, Rzążewski, and Spirkl [SIDMA 2021] who gave an algorithm with running time \\(n^{O(\\sqrt{n})}\\) for the problem, and by Agrawal, Lima, Lokshtanov, Saurabh, and Sharma [SODA 2024] who gave a quasi-polynomial time algorithm.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4405372699",
    "type": "article"
  },
  {
    "title": "Agnostic Learning in Permutation-Invariant Domains",
    "doi": "https://doi.org/10.1145/2963169",
    "publication_date": "2016-08-03",
    "publication_year": 2016,
    "authors": "Karl Wimmer",
    "corresponding_authors": "Karl Wimmer",
    "abstract": "We generalize algorithms from computational learning theory that are successful under the uniform distribution on the Boolean hypercube {0, 1} n to algorithms successful on permutation-invariant distributions, distributions that stay invariant constant on permutating the coordinates in the instances. While the tools in our generalization mimic those used for the Boolean hypercube, the fact that permutation-invariant distributions are not product distributions presents a significant obstacle. We prove analogous results for permutation-invariant distributions; more generally, we work in the domain of the symmetric group. We define noise sensitivity in this setting and show that noise sensitivity has a nice combinatorial interpretation in terms of Young tableaux. The main technical innovations involve techniques from the representation theory of the symmetric group, especially the combinatorics of Young tableaux. We show that low noise sensitivity implies concentration on “simple” components of the Fourier spectrum and that this fact will allow us to agnostically learn halfspaces under permutation-invariant distributions to constant accuracy in roughly the same time as in the uniform distribution over the Boolean hypercube case.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2489962967",
    "type": "article"
  },
  {
    "title": "An Improved Approximation Algorithm for the Edge-Disjoint Paths Problem with Congestion Two",
    "doi": "https://doi.org/10.1145/2960410",
    "publication_date": "2016-09-21",
    "publication_year": 2016,
    "authors": "Ken‐ichi Kawarabayashi; Yusuke Kobayashi",
    "corresponding_authors": "",
    "abstract": "In the maximum edge-disjoint paths problem, we are given a graph and a collection of pairs of vertices, and the objective is to find the maximum number of pairs that can be routed by edge-disjoint paths. An r -approximation algorithm for this problem is a polynomial-time algorithm that finds at least OPT/ r edge-disjoint paths, where OPT denotes the maximum possible number of pairs that can be routed in a given instance. For a long time, an O ( n 1/2 -approximation algorithm has been best known for this problem even if a congestion of two is allowed, that is, each edge is allowed to be used in at most two of the paths. In this article, we give a randomized O ( n 3/7 ċ poly(log n ))-approximation algorithm with congestion two. This is the first result that breaks the O ( n 1/2 )-approximation algorithm. In particular, we prove the following: (1) If we have a (randomized) polynomial-time algorithm for finding Ω(OPT1/p /polylog( n )) edge-disjoint paths for some p &gt; 1, then we can give a randomized O ( n 1/2 -α)-approximation algorithm for the edge-disjoint paths problem by using Rao-Zhou’s algorithm for some α &gt; 0. (2) Based on the Chekuri-Khanna-Shepherd well-linked decomposition, we show that there is a randomized algorithm for finding Ω(OPT 1/4 /(log n ) 3/2 ) edge-disjoint paths connecting given terminal pairs with congestion two. Our framework for this algorithm is more general in the following sense. Indeed, the above two ingredients also work for the maximum edge-disjoint paths problem (with congestion one) if there is a (randomized) polynomial-time algorithm for finding Ω(OPT1/p) edge-disjoint paths connecting given terminal pairs for some p &gt; 1.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2521479096",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2620785",
    "publication_date": "2014-06-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present fast and simple algebraic algorithms for the linear matroid parity problem and its applications. For the linear matroid parity problem, we obtain a simple randomized algorithm with running time O(mrω-1), where m and r are the number of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4229724922",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2578701",
    "publication_date": "2014-01-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We consider the unsplittable flow problem on a line. In this problem, we are given a set of n tasks, each specified by a start time si, an end time ti, a demand di > 0, and a profit pi > 0. A task, if accepted, requires di units of “bandwidth” from time ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4229826086",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2685353",
    "publication_date": "2014-11-17",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The Directed Steiner Tree (DST) problem is a cornerstone problem in network design. We focus on the generalization of the problem with higher connectivity requirements. The problem with one root and two sinks is APX-hard. The problem with one root and ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231085097",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2930058",
    "publication_date": "2016-06-15",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We consider compact routing schemes in networks of low doubling dimension, where the doubling dimension is the least value α such that any ball in the network can be covered by at most 2α balls of half radius. There are two variants of routing-scheme ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231475027",
    "type": "paratext"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/2675311",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "Aravind Srinivasan",
    "corresponding_authors": "Aravind Srinivasan",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236309334",
    "type": "editorial"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2846103",
    "publication_date": "2016-02-08",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We study the k-route cut problem: given an undirected edge-weighted graph G = (V, E), a collection {(s1, t1), (s2, t2), …, (sr, tr)} of source-sink pairs, and an integer connectivity requirement k, the goal is to find a minimum-weight subset E′ of edges ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4238528143",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2578852",
    "publication_date": "2014-02-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We analyze several distributed, continuous time protocols for a fair allocation of bandwidths to flows in a network (or resources to agents). Our protocols converge to an allocation that is a logarithmic approximation, simultaneously, to all canonical ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241141494",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2660578",
    "publication_date": "2014-10-28",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A team consisting of an unknown number of mobile agents, starting from different nodes of an unknown network, have to meet at the same node. Agents move in synchronous rounds. Each agent has a different label. Up to f of the agents are Byzantine. We ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242348390",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2983296",
    "publication_date": "2016-09-02",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present three new results on one of the most basic problems in geometric data structures, 2-D orthogonal range counting. All the results are in the w-bit word RAM model.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243331083",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2756876",
    "publication_date": "2015-06-23",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We consider a single-machine scheduling problem. Given some continuous, nondecreasing cost function, we aim to compute a schedule minimizing the weighted total cost, where the cost of each job is determined by the cost function value at its completion ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243835876",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2846106",
    "publication_date": "2016-02-12",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The restricted max-min fair allocation problem (also known as the restricted Santa Claus problem) is one of few problems that enjoys the intriguing status of having a better estimation algorithm than approximation algorithm. Indeed, Asadpour et al. [...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248650924",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2997037",
    "publication_date": "2016-12-21",
    "publication_year": 2016,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we present improved inapproximability results for the k-level uncapacitated facility location problem. In particular, we show that there is no polynomial time approximation algorithm with performance guarantee better than 1.539 unless P ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4249984646",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2721890",
    "publication_date": "2015-01-13",
    "publication_year": 2015,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "For an undirected n-vertex planar graph G with nonnegative edge weights, we consider the following type of query: given two vertices s and t in G, what is the weight of a min st-cut in G? We show how to answer such queries in constant time with O(n log4 ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251429442",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2660854",
    "publication_date": "2014-08-01",
    "publication_year": 2014,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We initiate the study of testing properties of images that correspond to sparse 0/1-valued matrices of size n× n. Our study is related to but different from the study initiated by Raskhodnikova (Proceedings of RANDOM, 2003), where the images correspond ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255746481",
    "type": "paratext"
  },
  {
    "title": "On β-Plurality Points in Spatial Voting Games",
    "doi": "https://doi.org/10.1145/3459097",
    "publication_date": "2021-07-15",
    "publication_year": 2021,
    "authors": "Boris Aronov; Mark de Berg; Joachim Gudmundsson; Michael Horton",
    "corresponding_authors": "",
    "abstract": "Let V be a set of n points in mathcal R d , called voters . A point p ∈ mathcal R d is a plurality point for V when the following holds: For every q ∈ mathcal R d , the number of voters closer to p than to q is at least the number of voters closer to q than to p . Thus, in a vote where each v ∈ V votes for the nearest proposal (and voters for which the proposals are at equal distance abstain), proposal p will not lose against any alternative proposal q . For most voter sets, a plurality point does not exist. We therefore introduce the concept of β-plurality points , which are defined similarly to regular plurality points, except that the distance of each voter to p (but not to q ) is scaled by a factor β , for some constant 0&lt; β ⩽ 1. We investigate the existence and computation of β -plurality points and obtain the following results. • Define β * d := {β : any finite multiset V in mathcal R d admits a β-plurality point. We prove that β * d = √3/2, and that 1/√ d ⩽ β * d ⩽ √ 3/2 for all d ⩾ 3. • Define β ( p, V ) := sup {β : p is a β -plurality point for V }. Given a voter set V in mathcal R 2 , we provide an algorithm that runs in O ( n log n ) time and computes a point p such that β ( p , V ) ⩾ β * b . Moreover, for d ⩾ 2, we can compute a point p with β ( p , V ) ⩾ 1/√ d in O ( n ) time. • Define β ( V ) := sup { β : V admits a β -plurality point}. We present an algorithm that, given a voter set V in mathcal R d , computes an ((1-ɛ)ċ β ( V ))-plurality point in time O n 2 ɛ 3d-2 ċ log n ɛ d-1 ċ log 2 1ɛ).",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3037878906",
    "type": "article"
  },
  {
    "title": "The Combined Basic LP and Affine IP Relaxation for Promise VCSPs on Infinite Domains",
    "doi": "https://doi.org/10.1145/3458041",
    "publication_date": "2021-07-15",
    "publication_year": 2021,
    "authors": "Caterina Viola; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "Convex relaxations have been instrumental in solvability of constraint satisfaction problems (CSPs), as well as in the three different generalisations of CSPs: valued CSPs, infinite-domain CSPs, and most recently promise CSPs. In this work, we extend an existing tractability result to the three generalisations of CSPs combined: We give a sufficient condition for the combined basic linear programming and affine integer programming relaxation for exact solvability of promise valued CSPs over infinite-domains. This extends a result of Brakensiek and Guruswami (SODA’20) for promise (non-valued) CSPs (on finite domains).",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3183881142",
    "type": "article"
  },
  {
    "title": "The Infinite Server Problem",
    "doi": "https://doi.org/10.1145/3456632",
    "publication_date": "2021-07-15",
    "publication_year": 2021,
    "authors": "Christian Coester; Ηλίας Κουτσουπιάς; Philip Lazos",
    "corresponding_authors": "",
    "abstract": "We study a variant of the k -server problem, the infinite server problem, in which infinitely many servers reside initially at a particular point of the metric space and serve a sequence of requests. In the framework of competitive analysis, we show a surprisingly tight connection between this problem and the resource augmentation version of the k -server problem, also known as the (h,k) -server problem, in which an online algorithm with k servers competes against an offline algorithm with h servers. Specifically, we show that the infinite server problem has bounded competitive ratio if and only if the (h,k) -server problem has bounded competitive ratio for some k = O ( h ). We give a lower bound of 3.146 for the competitive ratio of the infinite server problem, which holds even for the line and some simple weighted stars. It implies the same lower bound for the (h,k) -server problem on the line, even when k/h → ∞, improving on the previous known bounds of 2 for the line and 2.4 for general metrics. For weighted trees and layered graphs, we obtain upper bounds, although they depend on the depth. Of particular interest is the infinite server problem on the line, which we show to be equivalent to the seemingly easier case in which all requests are in a fixed bounded interval. This is a special case of a more general reduction from arbitrary metric spaces to bounded subspaces. Unfortunately, classical approaches (double coverage and generalizations, work function algorithm, balancing algorithms) fail even for this special case.",
    "cited_by_count": 1,
    "openalex_id": "https://openalex.org/W3186059492",
    "type": "article"
  },
  {
    "title": "Foreword to the Special Issue on SODA’11",
    "doi": "https://doi.org/10.1145/2483699.2483700",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "Shuchi Chawla; Prasad Raghavendra; Dana Randall",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2067745893",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2533288",
    "publication_date": "2013-09-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We give an algorithm to morph between two planar orthogonal drawings of a graph, preserving planarity and orthogonality. The morph uses a quadratic number of steps, where each step is a linear morph (a linear interpolation between two drawings). This is ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234578374",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1978782",
    "publication_date": "2011-07-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236031059",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2483699",
    "publication_date": "2013-06-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The problems of random projections and sparse reconstruction have much in common and individually received much attention. Surprisingly, until now they progressed in parallel and remained mostly separate. Here, we employ new tools from probability in ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237143622",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1921659",
    "publication_date": "2011-03-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Motivated by an application in computational geometry, we consider a novel variant of the problem of efficiently maintaining a forest of dynamic rooted trees. This variant includes an operation that merges two tree paths. In contrast to the standard ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4237438834",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2000807",
    "publication_date": "2011-09-01",
    "publication_year": 2011,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Grötzsch's theorem states that every triangle-free planar graph is 3-colorable, and several relatively simple proofs of this fact were provided by Thomassen and other authors. It is easy to convert these proofs into quadratic-time algorithms to find a 3-...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241902969",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2438645",
    "publication_date": "2013-03-01",
    "publication_year": 2013,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A distance sensitivity oracle of an n-vertex graph G = (V,E) is a data structure that can report shortest paths when edges of the graph fail. A query (u ∈ V, v ∈ V, S ⊆ E) to this oracle returns a shortest u-to-v path in the graph G′ = (V,E ∖ S). We ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4243333837",
    "type": "paratext"
  },
  {
    "title": "A linear algorithm for computing convex hulls for random lines",
    "doi": "https://doi.org/10.1145/1597036.1597046",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "Daniel Berend; Vladimir Braverman",
    "corresponding_authors": "",
    "abstract": "Finding the convex hull of n points in the plane requires O ( n log n ) time in general. In Devroye and Toussaint [1993] and Golin et al. [2002] the problem of computing the convex hull of the intersection points of n lines was considered, where the lines are chosen randomly according to two various models. In both models, linear-time algorithms were developed. Here we improve the results of Devroye and Toussaint [1993] by giving a universal algorithm for a wider range of distributions.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1984470259",
    "type": "article"
  },
  {
    "title": "Parametric analysis for ungapped Markov models of evolution",
    "doi": "https://doi.org/10.1145/1597036.1597048",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "David Fernández‐Baca; Balaji Venkatachalam",
    "corresponding_authors": "",
    "abstract": "Efficient sensitivity analysis algorithms are presented for two problems arising in the study of Markov models of sequence evolution: ancestral reconstruction in evolutionary trees and local ungapped alignment under log-odds scoring. The algorithms generate complete descriptions of the optimum solutions for all possible values of the evolutionary distance. The running time for the parametric ancestral reconstruction problem under the Kimura 2-parameter model is O ( kn + kn 2/3 log k ), where n is the number of sequences and k is their length, assuming all edges have the same length. For the parametric gapless alignment problem under the Jukes-Cantor model, the running time is O ( mn + mn 2/3 log m ), where m and n are the sequence lengths and n ≤ m .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2058835242",
    "type": "article"
  },
  {
    "title": "Foreword to special issue on SODA 2008",
    "doi": "https://doi.org/10.1145/1824777.1824793",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Mohammad Taghi Hajiaghayi; Shang‐Hua Teng",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2061755943",
    "type": "article"
  },
  {
    "title": "Foreword to special issue on SODA 2007",
    "doi": "https://doi.org/10.1145/1541885.1541886",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "Harold Gabow",
    "corresponding_authors": "Harold Gabow",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2074609740",
    "type": "article"
  },
  {
    "title": "On the Query Complexity of Testing for Eulerian Orientations",
    "doi": null,
    "publication_date": "2009-01-01",
    "publication_year": 2009,
    "authors": "E. Fischer; Arie Matsliah; Ilan Newman; Orly Yahalom",
    "corresponding_authors": "",
    "abstract": "We consider testing directed graphs for being Eulerian in the orientation model introduced in [15]. Despite the local nature of the property of being Eulerian, it turns out to be significantly harder for testing than other properties studied in the orientation model. We show a superconstant lower bound on the query complexity of 2-sided tests and a linear lower bound on the query complexity of 1-sided tests for this property. On the positive side, we give several 1-sided and 2-sided tests, including a sub-linear 2-sided test for general graphs. For special classes of graphs, including bounded-degree graphs and expander graphs, we provide improved results. In particular, for dense graphs we give a 2-sided test with constant query complexity.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2110795391",
    "type": "article"
  },
  {
    "title": "Expansion properties of (secure) wireless networks",
    "doi": "https://doi.org/10.1145/2229163.2229165",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "Alessandro Panconesi; Jaikumar Radhakrishnan",
    "corresponding_authors": "",
    "abstract": "We show that some topologies arising naturally in the context of wireless networking are low-degree, expander graphs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2165581854",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1541885",
    "publication_date": "2009-07-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4229663451",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1721837",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We give a polynomial-time algorithm to find a shortest contractible cycle (i.e., a closed walk without repeated vertices) in a graph embedded in a surface. This answers a question posed by Hutchinson. In contrast, we show that finding a shortest ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230246834",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1497290",
    "publication_date": "2009-03-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We show how to test the bipartiteness of an intersection graph of n line segments or simple polygons in the plane, or of an intersection graph of balls in d-dimensional Euclidean space, in time O(n log n). More generally, we find subquadratic algorithms ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230982766",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2071379",
    "publication_date": "2012-01-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In several applications such as databases, planning, and sensor networks, parameters such as selectivity, load, or sensed values are known only with some associated uncertainty. The performance of such a system (as captured by some objective function ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4234505996",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2229163",
    "publication_date": "2012-07-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In a Content Distribution Network (CDN), there are m servers storing the data; each of them has a specific bandwidth. All the requests from a particular client should be assigned to one server because of the routing protocol used. The goal is to ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235318883",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1868237",
    "publication_date": "2010-11-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article we present algorithms for computing large matchings in 3-regular graphs, graphs with maximum degree 3, and 3-connected planar graphs. The algorithms give a guarantee on the size of the computed matching and take linear or slightly ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4236558410",
    "type": "paratext"
  },
  {
    "title": "Editorial note",
    "doi": "https://doi.org/10.1145/1824777.1824778",
    "publication_date": "2010-08-01",
    "publication_year": 2010,
    "authors": "Susanne Alber",
    "corresponding_authors": "Susanne Alber",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239178070",
    "type": "editorial"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2151171",
    "publication_date": "2012-04-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We introduce a generalization of interval graphs, which we call Dotted Interval Graphs (DIG). A dotted interval graph is an intersection graph of arithmetic progressions (dotted intervals). Coloring of dotted interval graphs naturally arises in the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239327054",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1597036",
    "publication_date": "2009-10-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4242059506",
    "type": "paratext"
  },
  {
    "title": "Editorial Note",
    "doi": "https://doi.org/10.1145/1721837.1721838",
    "publication_date": "2010-03-01",
    "publication_year": 2010,
    "authors": "Susanne Albers",
    "corresponding_authors": "Susanne Albers",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4244440889",
    "type": "editorial"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1798596",
    "publication_date": "2010-06-01",
    "publication_year": 2010,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "For a graph G with real weights assigned to the vertices (edges), the MAX H-SUBGRAPH problem is to find an H-subgraph of G with maximum total weight, if one exists. Our main results are new strongly polynomial algorithms for the MAX H-SUBGRAPH problem. ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246343179",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2344422",
    "publication_date": "2012-09-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Let G = (V,E) be a directed graph and let P be a shortest path from s to t in G. In the replacement paths problem, we are required to find, for every edge e on P, a shortest path from s to t in G that avoids e. The only known algorithm for solving the ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250864103",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/2390176",
    "publication_date": "2012-12-01",
    "publication_year": 2012,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We give approximation algorithms for the Survivable Network problem. The input consists of a graph G = (V,E) with edge/node-costs, a node subset S ⊆ V, and connectivity requirements {r(s,t):s,t ∈ T ⊆ V}. The goal is to find a minimum cost subgraph H of ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255174625",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1644015",
    "publication_date": "2009-12-01",
    "publication_year": 2009,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We address the problem of designing data structures in the presence of faults that may arbitrarily corrupt memory locations. More precisely, we assume that an adaptive adversary can arbitrarily overwrite the content of up to δ memory locations, that ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4256037195",
    "type": "paratext"
  },
  {
    "title": "Introduction to SODA 2002 and 2003 special issue",
    "doi": "https://doi.org/10.1145/1290672.1290673",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "Harold N. Gabow; Michael A. Bender; Martı́n Farach-Colton",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W1977259983",
    "type": "article"
  },
  {
    "title": "On the difficulty of some shortest path problems",
    "doi": "https://doi.org/10.1145/1219944.1219951",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "John Hershberger; Subhash Suri; Amit M. Bhosle",
    "corresponding_authors": "",
    "abstract": "We prove superlinear lower bounds for some shortest path problems in directed graphs, where no such bounds were previously known. The central problem in our study is the replacement paths problem: Given a directed graph G with non-negative edge weights, and a shortest path P = {e1, e2, …, ep} between two nodes s and t, compute the shortest path distances from s to t in each of the p graphs obtained from G by deleting one of the edges ei. We show that the replacement paths problem requires Ω(m √n) time in the worst case whenever m = O(n √n). Our construction also implies a similar lower bound on the k shortest simple paths problem for a broad class of algorithms that includes all known algorithms for the problem. To put our lower bound in perspective, we note that both these problems (replacement paths and k shortest simple paths) can be solved in near-linear time for undirected graphs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2565244433",
    "type": "article"
  },
  {
    "title": "Maximizing Polynomials Subject to Assignment Constraints",
    "doi": "https://doi.org/10.1145/3147137",
    "publication_date": "2017-10-31",
    "publication_year": 2017,
    "authors": "Konstantin Makarychev; Maxim Sviridenko",
    "corresponding_authors": "",
    "abstract": "We study the q -adic assignment problem. We first give an O ( n (q−1)/2) )-approximation algorithm for the Koopmans--Beckman version of the problem, improving upon the result of Barvinok. Then, we introduce a new family of instances satisfying “tensor triangle inequalities” and give a constant factor approximation algorithm for them. We show that many classical optimization problems can be modeled by q -adic assignment problems from this family. Finally, we give several integrality gap examples for the natural LP relaxations of the problem.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2769731375",
    "type": "article"
  },
  {
    "title": "String Indexing with Compressed Patterns",
    "doi": "https://doi.org/10.1145/3607141",
    "publication_date": "2023-07-21",
    "publication_year": 2023,
    "authors": "Philip Bille; Inge Li Gørtz; Teresa Anna Steiner",
    "corresponding_authors": "",
    "abstract": "Given a string S of length n, the classic string indexing problem is to preprocess S into a compact data structure that supports efficient subsequent pattern queries. In this article, we consider the basic variant where the pattern is given in compressed form and the goal is to achieve query time that is fast in terms of the compressed size of the pattern. This captures the common client-server scenario, where a client submits a query and communicates it in compressed form to a server. Instead of the server decompressing the query before processing it, we consider how to efficiently process the compressed query directly. Our main result is a novel linear space data structure that achieves near-optimal query time for patterns compressed with the classic Lempel-Ziv 1977 (LZ77) compression scheme. Along the way, we develop several data structural techniques of independent interest, including a novel data structure that compactly encodes all LZ77 compressed suffixes of a string in linear space and a general decomposition of tries that reduces the search time from logarithmic in the size of the trie to logarithmic in the length of the pattern.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2976802069",
    "type": "article"
  },
  {
    "title": "Optimal Inapproximability with Universal Factor Graphs",
    "doi": "https://doi.org/10.1145/3631119",
    "publication_date": "2023-12-15",
    "publication_year": 2023,
    "authors": "Per Austrin; Jonah Brown-Cohen; Johan Håstad",
    "corresponding_authors": "",
    "abstract": "The factor graph of an instance of a constraint satisfaction problem (CSP) is the bipartite graph indicating which variables appear in each constraint. An instance of the CSP is given by the factor graph together with a list of which predicate is applied for each constraint. We establish that many Max-CSPs remain as hard to approximate as in the general case even when the factor graph is fixed (depending only on the size of the instance) and known in advance. Examples of results obtained for this restricted setting are: (1) Optimal inapproximability for Max-3-Lin and Max-3-Sat (Håstad, J. ACM 2001). (2) Approximation resistance for predicates supporting pairwise independent subgroups (Chan, J. ACM 2016). (3) Hardness of the “(2 + ϵ)-Sat” problem and other Promise CSPs (Austrin et al., SIAM J. Comput. 2017). The main technical tool used to establish these results is a new way of folding the long code which we call “functional folding”.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2990811009",
    "type": "article"
  },
  {
    "title": "Static and Streaming Data Structures for Fréchet Distance Queries",
    "doi": "https://doi.org/10.1145/3610227",
    "publication_date": "2023-07-24",
    "publication_year": 2023,
    "authors": "Arnold Filtser; Omrit Filtser",
    "corresponding_authors": "",
    "abstract": "Given a curve P with points in ℝ d in a streaming fashion, and parameters ɛ &gt; 0 and k , we construct a distance oracle that uses \\(O(\\frac{1}{\\varepsilon })^{kd}\\log \\varepsilon ^{-1}\\) space, and given a query curve Q with k points in ℝ d returns in \\(\\tilde{O}(kd)\\) time a 1+ɛ approximation of the discrete Fréchet distance between Q and P . In addition, we construct simplifications in the streaming model, oracle for distance queries to a sub-curve (in the static setting), and introduce the zoom-in problem. Our algorithms work in any dimension d , and therefore we generalize some useful tools and algorithms for curves under the discrete Fréchet distance to work efficiently in high dimensions.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3044063909",
    "type": "article"
  },
  {
    "title": "Additive Sparsification of CSPs",
    "doi": "https://doi.org/10.1145/3625824",
    "publication_date": "2023-09-30",
    "publication_year": 2023,
    "authors": "Eden Pelleg; Stanislav Živný",
    "corresponding_authors": "",
    "abstract": "Multiplicative cut sparsifiers, introduced by Benczúr and Karger [STOC’96], have proved extremely influential and found various applications. Precise characterisations were established for sparsifiability of graphs with other 2-variable predicates on Boolean domains by Filtser and Krauthgamer [SIDMA’17] and non-Boolean domains by Butti and Živný [SIDMA’20]. Bansal, Svensson and Trevisan [FOCS’19] introduced a weaker notion of sparsification termed “additive sparsification”, which does not require weights on the edges of the graph. In particular, Bansal et al. designed algorithms for additive sparsifiers for cuts in graphs and hypergraphs. As our main result, we establish that all Boolean Constraint Satisfaction Problems (CSPs) admit an additive sparsifier; that is, for every Boolean predicate P :{ 0,1} k → { 0,1} of a fixed arity k , we show that CSP( P ) admits an additive sparsifier. Under our newly introduced notion of all-but-one sparsification for non-Boolean predicates, we show that CSP( P ) admits an additive sparsifier for any predicate P : D k → { 0,1} of a fixed arity k on an arbitrary finite domain D .",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3173284615",
    "type": "article"
  },
  {
    "title": "Fast sampling via spectral independence beyond bounded-degree graphs",
    "doi": "https://doi.org/10.1145/3631354",
    "publication_date": "2023-11-09",
    "publication_year": 2023,
    "authors": "Ivona Bezáková; Andreas Galanis; Leslie Ann Goldberg; Daniel Štefankovič",
    "corresponding_authors": "",
    "abstract": "Spectral independence is a recently-developed framework for obtaining sharp bounds on the convergence time of the classical Glauber dynamics. This new framework has yielded optimal O ( n log n ) sampling algorithms on bounded-degree graphs for a large class of problems throughout the so-called uniqueness regime, including, for example, the problems of sampling independent sets, matchings, and Ising-model configurations. Our main contribution is to relax the bounded-degree assumption that has so far been important in establishing and applying spectral independence. Previous methods for avoiding degree bounds rely on using L p -norms to analyse contraction on graphs with bounded connective constant (Sinclair, Srivastava, Yin; FOCS’13). The non-linearity of L p -norms is an obstacle to applying these results to bound spectral independence. Our solution is to capture the L p -analysis recursively by amortising over the subtrees of the recurrence used to analyse contraction. Our method generalises previous analyses that applied only to bounded-degree graphs. As a main application of our techniques, we consider the random graph G ( n , d / n ), where the previously known algorithms run in time n O (log d ) or applied only to large d . We refine these algorithmic bounds significantly, and develop fast nearly linear algorithms based on Glauber dynamics that apply to all constant d , throughout the uniqueness regime.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3214333250",
    "type": "article"
  },
  {
    "title": "Querying priced information in databases",
    "doi": "https://doi.org/10.1145/1219944.1219955",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Renato Carmo; Tomás Feder; Yoshiharu Kohayakawa; Eduardo Sany Laber; Rajeev Motwani; Liadan O'Callaghan; Rina Panigrahy‎; Dilys Thomas",
    "corresponding_authors": "",
    "abstract": "Query optimization that involves expensive predicates has received considerable attention in the database community. Typically, the output to a database query is a set of tuples that satisfy certain conditions, and, with expensive predicates, these conditions may be computationally costly to verify. In the simplest case, when the query looks for the set of tuples that simultaneously satisfy k expensive predicates, the problem reduces to ordering the evaluation of the predicates so as to minimize the time to output the set of tuples comprising the answer to the query. We study different cases of the problem: the sequential case, in which a single processor is available to evaluate the predicates, and the distributed case, in which there are k processors available, each dedicated to a different attribute (column) of the database, and there is no communication cost between the processors.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231913573",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3143522",
    "publication_date": "2017-12-21",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We show a method resulting in the improvement of several polynomial-space, exponential-time algorithms. The method capitalizes on the existence of small balanced separators for sparse graphs, which can be exploited for branching to disconnect an ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233282672",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3040971",
    "publication_date": "2017-05-29",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A fundamental result by Karger [10] states that for any λ-edge-connected graph with n nodes, independently sampling each edge with probability p = Ω(log (n)/λ) results in a graph that has edge connectivity Ω(λp), with high probability. This article ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4235601835",
    "type": "paratext"
  },
  {
    "title": "Guest editorial",
    "doi": "https://doi.org/10.1145/1361192.1361193",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "Adam L. Buchsbaum",
    "corresponding_authors": "Adam L. Buchsbaum",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4238177688",
    "type": "editorial"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1273340",
    "publication_date": "2007-08-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "In this article, we present a new data structure, called the permutation tree, to improve the running time of sorting permutation by transpositions and sorting permutation by block interchanges. The existing 1.5-approximation algorithm for sorting ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4238407261",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1361192",
    "publication_date": "2008-05-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240143741",
    "type": "paratext"
  },
  {
    "title": "Entropy-based bounds for online algorithms",
    "doi": "https://doi.org/10.1145/1219944.1219953",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Gopal Pandurangan; Eli Upfal",
    "corresponding_authors": "",
    "abstract": "We focus in this work on an aspect of online computation that is not addressed by standard competitive analysis, namely, identifying request sequences for which nontrivial online algorithms are useful versus request sequences for which all algorithms perform equally poorly. The motivations for this work are advanced system and architecture designs which allow the operating system to dynamically allocate resources to online protocols such as prefetching and caching. To utilize these features, the operating system needs to identify data streams that can benefit from more resources.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4240533605",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1186810",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The edit distance between two strings S and R is defined to be the minimum number of character inserts, deletes, and changes needed to convert R to S. Given a text string t of length n, and a pattern string p of length m, informally, the string edit ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4245295173",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1435375",
    "publication_date": "2008-11-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4247188063",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1240233",
    "publication_date": "2007-05-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "A variable can be multiplied by a given set of fixed-point constants using a multiplier block that consists exclusively of additions, subtractions, and shifts. The generation of a multiplier block from the set of constants is known as the multiple ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248042255",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3058789",
    "publication_date": "2017-08-09",
    "publication_year": 2017,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present fast algorithms for sketching valuation functions. Let N (|N| = n) be some ground set and v:2N→ R be a function. We say that v˜:2N→ R is an α-sketch of v if for every set S we have that v(S)/α ≤ v˜(S) ≤ v(S) and v˜ can be described in poly(n) ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4248676369",
    "type": "paratext"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3038922",
    "publication_date": "2017-03-21",
    "publication_year": 2017,
    "authors": "Alexandr Andoni; Debmalya Panigrahi; Marcin Pilipczuk",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250143479",
    "type": "editorial"
  },
  {
    "title": "A data structure for a sequence of string accesses in external memory",
    "doi": "https://doi.org/10.1145/1219944.1219952",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "Valentina Ciriani; Paolo Ferragina; Fabrizio Luccio; S. Muthukrishnan",
    "corresponding_authors": "",
    "abstract": "We introduce a new paradigm for querying strings in external memory, suited to the execution of sequences of operations. Formally, given a dictionary of n strings S1, …, Sn, we aim at supporting a search sequence for m not necessarily distinct strings T1, T2, …, Tm, as well as inserting and deleting individual strings. The dictionary is stored on disk, where each access to a disk page fetches B items, the cost of an operation is the number of pages accessed (I/Os), and efficiency must be attained on entire sequences of string operations rather than on individual ones.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250826546",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1383369",
    "publication_date": "2008-08-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252872003",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1367064",
    "publication_date": "2008-06-01",
    "publication_year": 2008,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We study the Bottleneck Tower of Hanoi puzzle posed by D. Wood in 1981. There, a relaxed placement rule allows a larger disk to be placed higher than a smaller one if their size difference is less than a pregiven value k. A shortest sequence of moves (...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253205057",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1219944",
    "publication_date": "2007-02-01",
    "publication_year": 2007,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The edit distance between two strings S and R is defined to be the minimum number of character inserts, deletes, and changes needed to convert R to S. Given a text string t of length n, and a pattern string p of length m, informally, the string edit ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255320467",
    "type": "paratext"
  },
  {
    "title": "Hierarchical bin buffering",
    "doi": "https://doi.org/10.1145/1328911.1328925",
    "publication_date": "2008-03-01",
    "publication_year": 2008,
    "authors": "Daniel Lemire; Owen Kaser",
    "corresponding_authors": "",
    "abstract": "For a massive I/O array of size n , we want to compute the first N local moments, for some constant N . Our simpler algorithms partition the array into consecutive ranges called bins, and apply not only to local-moment queries, but also to algebraic queries. With N buffers of size √ n , time complexity drops to O (√ n ). A more sophisticated approach uses hierarchical buffering and has a logarithmic time complexity ( O ( b log b n )), when using N hierarchical buffers of size n / b . Using overlapped bin buffering, we show that only one buffer is needed, as with wavelet-based algorithms, but using much less storage.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4300181884",
    "type": "article"
  },
  {
    "title": "Greedy Spanners in Euclidean Spaces Admit Sublinear Separators",
    "doi": "https://doi.org/10.1145/3590771",
    "publication_date": "2023-04-03",
    "publication_year": 2023,
    "authors": "Hung Le; Cuong Than",
    "corresponding_authors": "",
    "abstract": "The greedy spanner in a low-dimensional Euclidean space is a fundamental geometric construction that has been extensively studied over three decades, as it possesses the two most basic properties of a good spanner: constant maximum degree and constant lightness. Recently, Eppstein and Khodabandeh [ 28 ] showed that the greedy spanner in \\(\\mathbb {R}^2\\) admits a sublinear separator in a strong sense: Any subgraph of k vertices of the greedy spanner in \\(\\mathbb {R}^2\\) has a separator of size \\(O(\\sqrt {k})\\) . Their technique is inherently planar and is not extensible to higher dimensions. They left showing the existence of a small separator for the greedy spanner in \\(\\mathbb {R}^d\\) for any constant d ≥ 3 as an open problem. In this article, we resolve the problem of Eppstein and Khodabandeh [ 28 ] by showing that any subgraph of k vertices of the greedy spanner in \\(\\mathbb {R}^d\\) has a separator of size \\(O(k^{1-1/d})\\) . We introduce a new technique that gives a simple criterion for any geometric graph to have a sublinear separator that we dub τ-lanky : A geometric graph is τ-lanky if any ball of radius r cuts at most τ edges of length at least r in the graph. We show that any τ-lanky geometric graph of n vertices in \\(\\mathbb {R}^d\\) has a separator of size \\(O(\\tau n^{1-1/d})\\) . We then derive our main result by showing that the greedy spanner is O (1)-lanky. We indeed obtain a more general result that applies to unit ball graphs and point sets of low fractal dimensions in \\(\\mathbb {R}^d\\) . Our technique naturally extends to doubling metrics. We use the τ-lanky criterion to show that there exists a (1+ε)-spanner for doubling metrics of dimension d with a constant maximum degree and a separator of size \\(O(n^{1-\\frac{1}{d}})\\) ; this result resolves an open problem posed by Abam and Har-Peled [ 1 ] a decade ago. We then introduce another simple criterion for a graph in doubling metrics of dimension d to have a sublinear separator. We use the new criterion to show that the greedy spanner of an n -point metric space of doubling dimension d has a separator of size \\(O((n^{1-\\frac{1}{d}}) + \\log \\Delta)\\) where Δ is the spread of the metric; the factor log (Δ) is tightly connected to the fact that, unlike its Euclidean counterpart, the greedy spanner in doubling metrics has unbounded maximum degree . Finally, we discuss algorithmic implications of our results.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4362578421",
    "type": "article"
  },
  {
    "title": "Finding the <i>k</i> shortest simple paths",
    "doi": "https://doi.org/10.1145/1290672.1290682",
    "publication_date": "2007-11-01",
    "publication_year": 2007,
    "authors": "John Hershberger; Matthew Maxel; Subhash Suri",
    "corresponding_authors": "",
    "abstract": "We describe a new algorithm to enumerate the k shortest simple (loopless) paths in a directed graph and report on its implementation. Our algorithm is based on a replacement paths algorithm proposed by Hershberger and Suri [2001], and can yield a factor Θ( n ) improvement for this problem. But there is a caveat: The fast replacement paths subroutine is known to fail for some directed graphs. However, the failure is easily detected, and so our k shortest paths algorithm optimistically uses the fast subroutine, then switches to a slower but correct algorithm if a failure is detected. Thus, the algorithm achieves its Θ( n ) speed advantage only when the optimism is justified. Our empirical results show that the replacement paths failure is a rare phenomenon, and the new algorithm outperforms the current best algorithms; the improvement can be substantial in large graphs. For instance, on GIS map data with about 5,000 nodes and 12,000 edges, our algorithm is 4--8 times faster. In synthetic graphs modeling wireless ad hoc networks, our algorithm is about 20 times faster.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4376522482",
    "type": "article"
  },
  {
    "title": "Minimum+1 ( <i>s, t</i> )-cuts and Dual-edge Sensitivity Oracle",
    "doi": "https://doi.org/10.1145/3623271",
    "publication_date": "2023-09-07",
    "publication_year": 2023,
    "authors": "Surender Baswana; Koustav Bhanja; Abhyuday Pandey",
    "corresponding_authors": "",
    "abstract": "Let G be a directed multi-graph on n vertices and m edges with a designated source vertex s and a designated sink vertex t . We study the ( s,t )-cuts of capacity minimum+1 and as an important application of them, we give a solution to the dual-edge sensitivity for ( s,t )-mincuts—reporting an ( s,t )-mincut upon failure or insertion of any pair of edges. Picard and Queyranne [Mathematical Programming Studies, 13(1): 8–16 (1980)] showed that there exists a directed acyclic graph (DAG) that compactly stores all minimum ( s,t )-cuts of G . This structure also acts as an oracle for the single-edge sensitivity of minimum ( s,t )-cut. For undirected multi-graphs, Dinitz and Nutov [STOC, 509–518 (1995)] showed that there exists an 𝒪( n ) size 2-level Cactus model that stores all global cuts of capacity minimum+1. However, for minimum+1 ( s,t )-cuts, no such compact structure exists till date. We present the following structural and algorithmic results on minimum+1 ( s,t )-cuts. (1) Structure: There is an 𝒪( m ) size 2-level DAG structure that stores all minimum+1 (s,t) -cuts of G such that each minimum+1 ( s,t )-cut appears as 3-transversal cut—it intersects any path in this structure at most thrice. We also show that there is an 𝒪( mn ) size structure for storing and characterizing all minimum+1 (s,t) -cuts in terms of 1-transversal cuts. (2) Data structure: There exists an 𝒪( n 2 ) size data structure that, given a pair of vertices {u,v} that are not separated by an ( s,t )-mincut, can determine in 𝒪(1) time if there exists a minimum+1 ( s,t )-cut, say ( A,B ), such that s,u ∊ A and v,t∊ B ; the corresponding cut can be reported in 𝒪(| B |) time. (3) Sensitivity oracle: There exists an 𝒪( n 2 ) size data structure that solves the dual-edge sensitivity problem for (s,t) -mincuts. It takes 𝒪(1) time to report the capacity of a resulting (s,t) -mincut (A,B) and 𝒪(| B |) time to report the cut. (4) Lower bounds: For the data structure problems addressed in results (2) and (3) above, we also provide a matching conditional lower bound. We establish a close relationship among three seemingly unrelated problems—all-pairs directed reachability problem, the dual-edge sensitivity problem for ( s,t )-mincuts, and the problem of reporting the capacity of ({ x,y }, { u,v })-mincut for any four vertices x,y,u,v in G . Assuming the Directed Reachability Hypothesis by Patrascu [SIAM J. Computing, 827–847 (2011)] and Goldstein et al. [WADS, 421–436 (2017)], this leads to \\(\\tilde{\\Omega }(n^2)\\) lower bounds on the space for the latter two problems.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4386497988",
    "type": "article"
  },
  {
    "title": "Shortest Cycles with Monotone Submodular Costs",
    "doi": "https://doi.org/10.1145/3626824",
    "publication_date": "2023-10-05",
    "publication_year": 2023,
    "authors": "Fedor V. Fomin; Petr A. Golovach; Tuukka Korhonen; Daniel Lokshtanov; Giannos Stamoulis",
    "corresponding_authors": "",
    "abstract": "We introduce the following submodular generalization of the Shortest Cycle problem. For a nonnegative monotone submodular cost function f defined on the edges (or the vertices) of an undirected graph G , we seek for a cycle C in G of minimum cost 𝖮𝖯𝖳 = f(C) . We give an algorithm that given an n -vertex graph G , parameter ɛ &gt; 0, and the function f represented by an oracle, in time n 𝒪 (log 1/ɛ) finds a cycle C in G with f(C) ≤ (1+ɛ). 𝖮𝖯𝖳. This is in sharp contrast with the non-approximability of the closely related Monotone Submodular Shortest ( s,t -Path problem, which requires exponentially many queries to the oracle for finding an n 2/3-ɛ -approximation Goel et al. [ 7 ], FOCS 2009. We complement our algorithm with a matching lower bound. We show that for every ɛ &gt; 0, obtaining a (1+ɛ)-approximation requires at least n Ω (log 1/ ɛ) queries to the oracle. When the function f is integer-valued, our algorithm yields that a cycle of cost 𝖮𝖯𝖳 can be found in time n 𝒪(log 𝖮𝖯𝖳) . In particular, for 𝖮𝖯𝖳 = n 𝒪(1) this gives a quasipolynomial-time algorithm computing a cycle of minimum submodular cost. Interestingly, while a quasipolynomial-time algorithm often serves as a good indication that a polynomial time complexity could be achieved, we show a lower bound that n 𝒪(log n ) queries are required even when 𝖮𝖯𝖳= 𝒪( n ). We also consider special cases of monotone submodular functions, corresponding to the number of different color classes needed to cover a cycle in an edge-colored multigraph G . For special cases of the corresponding minimization problem, we obtain fixed-parameter tractable algorithms and polynomial-time algorithms, when restricted to certain classes of inputs.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4387376832",
    "type": "article"
  },
  {
    "title": "Cluster Editing Parameterized above Modification-disjoint <i>P</i> <sub>3</sub> -packings",
    "doi": "https://doi.org/10.1145/3626526",
    "publication_date": "2023-10-11",
    "publication_year": 2023,
    "authors": "Shaohua Li; Marcin Pilipczuk; Manuel Sorge",
    "corresponding_authors": "",
    "abstract": "Given a graph G =( V,E ) and an integer k , the Cluster Editing problem asks whether we can transform G into a union of vertex-disjoint cliques by at most k modifications (edge deletions or insertions). In this paper, we study the following variant of Cluster Editing . We are given a graph G = ( V,E ), a packing ℋ of modification-disjoint induced P 3 s (no pair of P 3 s in ℋ share an edge or non-edge) and an integer ℓ. The task is to decide whether G can be transformed into a union of vertex-disjoint cliques by at most ℓ +|ℋ| modifications (edge deletions or insertions). We show that this problem is NP-hard even when ℓ = 0 (in which case the problem asks to turn G into a disjoint union of cliques by performing exactly one edge deletion or insertion per element of ℋ) and when each vertex is in at most 23 P 3 s of the packing. This answers negatively a question of van Bevern, Froese, and Komusiewicz (CSR 2016, ToCS 2018), repeated by C. Komusiewicz at Shonan meeting no. 144 in March 2019. We then initiate the study to find the largest integer c such that the problem remains tractable when restricting to packings such that each vertex is in at most c packed P 3 s. Here packed P 3 s are those belonging to the packing ℋ. Van Bevern et al. showed that the case c = 1 is fixed-parameter tractable with respect to ℓ and we show that the case c = 2 is solvable in | V | 2ℓ + O (1) time.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4387540884",
    "type": "article"
  },
  {
    "title": "Approximation Guarantees for the Minimum Linear Arrangement Problem by Higher Eigenvalues",
    "doi": "https://doi.org/10.1145/3228342",
    "publication_date": "2018-08-21",
    "publication_year": 2018,
    "authors": "Suguru Tamaki; Yuichi Yoshida",
    "corresponding_authors": "",
    "abstract": "Given an n -vertex undirected graph G = ( V , E ) and positive edge weights { w e } e∈E , a linear arrangement is a permutation π : V → {1, 2, …, n }. The value of the arrangement is val ( G , π) := 1/n∑ e ={ u, v } ∈ E w e |π( u ) − π ( v )|. In the minimum linear arrangement problem, the goal is to find a linear arrangement π * that achieves val ( G , π * ) = MLA( G ) := min π val ( G , π). In this article, we show that for any ϵ &gt; 0 and positive integer r , there is an n O ( r /ϵ) -time randomized algorithm that, given a graph G , returns a linear arrangement π, such that val ( G , π) ≤ (1 + 2/(1 − ε)λ r ( L )) MLA( G ) + O (√log n / n ∑ e ∈ E w e ) with high probability, where L is the normalized Laplacian of G and λ r ( L ) is the r th smallest eigenvalue of L . Our algorithm gives a constant factor approximation for regular graphs that are weak expanders.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2270781570",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3230647",
    "publication_date": "2018-07-16",
    "publication_year": 2018,
    "authors": "Arnab Bhattacharyya; Fabrizio Grandoni; Aleksandar Nikolov; Barna Saha; Saket Saurabh; Aravindan Vijayaraghavan; Qin Zhang",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2884850827",
    "type": "editorial"
  },
  {
    "title": "Metastability of the Logit Dynamics for Asymptotically Well-Behaved Potential Games",
    "doi": "https://doi.org/10.1145/3301315",
    "publication_date": "2019-02-06",
    "publication_year": 2019,
    "authors": "Diodato Ferraioli; Carmine Ventre",
    "corresponding_authors": "",
    "abstract": "Convergence rate and stability of a solution concept are classically measured in terms of “eventually” and “forever,” respectively. In the wake of recent computational criticisms to this approach, we study whether these timeframes can be updated to have states computed “quickly” and stable for “long enough”. Logit dynamics allows irrationality in players’ behavior and may take time exponential in the number of players n to converge to a stable state (i.e., a certain distribution over pure strategy profiles). We prove that every potential game, for which the behavior of the logit dynamics is not chaotic as n increases, admits distributions stable for a super-polynomial number of steps in n no matter the players’ irrationality and the starting profile of the dynamics. The convergence rate to these metastable distributions is polynomial in n when the players are not too rational. Our proofs build upon the new concept of partitioned Markov chains , which might be of independent interest, and a number of involved technical contributions.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2912307485",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on SODA 2017",
    "doi": "https://doi.org/10.1145/3319426",
    "publication_date": "2019-04-26",
    "publication_year": 2019,
    "authors": "Dániel Marx; Virgi Vassilevska Williams; Neal E. Young",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2942640630",
    "type": "article"
  },
  {
    "title": "The Alternating Stock Size Problem and the Gasoline Puzzle",
    "doi": "https://doi.org/10.1145/3178539",
    "publication_date": "2018-04-16",
    "publication_year": 2018,
    "authors": "Alantha Newman; Heiko Röglin; Johanna Seif",
    "corresponding_authors": "",
    "abstract": "Given a set S of integers whose sum is zero, consider the problem of finding a permutation of these integers such that (i) all prefix sums of the ordering are nonnegative and (ii) the maximum value of a prefix sum is minimized. Kellerer et al. call this problem the stock size problem and showed that it can be approximated to within 3/2. They also showed that an approximation ratio of 2 can be achieved via several simple algorithms. We consider a related problem, which we call the alternating stock size problem , where the numbers of positive and negative integers in the input set S are equal. The problem is the same as that shown earlier, but we are additionally required to alternate the positive and negative numbers in the output ordering. This problem also has several simple 2-approximations. We show that it can be approximated to within 1.79. Then we show that this problem is closely related to an optimization version of the gasoline puzzle due to Lovász, in which we want to minimize the size of the gas tank necessary to go around the track. We present a 2-approximation for this problem, using a natural linear programming relaxation whose feasible solutions are doubly stochastic matrices. Our novel rounding algorithm is based on a transformation that yields another doubly stochastic matrix with special properties, from which we can extract a suitable permutation.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W2963819692",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on SODA’18",
    "doi": "https://doi.org/10.1145/3368307",
    "publication_date": "2019-12-05",
    "publication_year": 2019,
    "authors": "Yin Tat Lee; Marcin Pilipczuk; David Woodruff",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3004475106",
    "type": "article"
  },
  {
    "title": "M凸交差による2値VCSPの扱いやすいクラス【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2019-01-01",
    "publication_year": 2019,
    "authors": "Hiroshi Hirai; Iwamasa Yuni; Kazuo Murota; Zivny Stanislav",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3157222915",
    "type": "article"
  },
  {
    "title": "偶数デルタ-マトロイドと平面BooleCSPの複雑性【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2018-01-01",
    "publication_year": 2018,
    "authors": "Kazda Alexandr; Kolmogorov Vladimir; Michal Rolínek",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3175614669",
    "type": "article"
  },
  {
    "title": "高速一般化DFTSのための新しいアルゴリズム【JST・京大機械翻訳】",
    "doi": null,
    "publication_date": "2019-01-01",
    "publication_year": 2019,
    "authors": "Hsu Chloe Ching-Yun; Umans Chris",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3178013174",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3351875",
    "publication_date": "2019-10-12",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We consider the fundamental problem of constructing fast circuits for the carry bit computation in binary addition. Up to a small additive constant, the carry bit computation reduces to computing an And-Or path, i.e., a formula of type t0 ∧ (t1 ∨ (t2 ∧ (...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4230437445",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3372373",
    "publication_date": "2019-12-05",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Given a weighted planar bipartite graph G(A ∪ B, E) where each edge has an integer edge cost, we give an Õ(n4/3log nC) time algorithm to compute minimum-cost perfect matching; here C is the maximum edge cost in the graph. The previous best-known ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4231122793",
    "type": "paratext"
  },
  {
    "title": "Problems column",
    "doi": "https://doi.org/10.1145/1125994.1126002",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "Samir Khuller",
    "corresponding_authors": "Samir Khuller",
    "abstract": "article Share on Problems column Author: Samir Khuller University of Maryland, College Park, MD University of Maryland, College Park, MDView Profile Authors Info & Claims ACM Transactions on AlgorithmsVolume 2Issue 1January 2006 pp 130–134https://doi.org/10.1145/1125994.1126002Online:01 January 2006Publication History 0citation718DownloadsMetricsTotal Citations0Total Downloads718Last 12 Months3Last 6 weeks0 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteGet Access",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4233763651",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1150334",
    "publication_date": "2006-04-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4239626225",
    "type": "paratext"
  },
  {
    "title": "Foreword",
    "doi": "https://doi.org/10.1145/1198513.1198514",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "Alejandro López-Ortíz; J. Ian Munro",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4241127617",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3281277",
    "publication_date": "2019-01-25",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We study the problem of testing whether an unknown n-variable Boolean function is a k-junta in the distribution-free property testing model, where the distance between functions is measured with respect to an arbitrary and unknown probability ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246299876",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3331056",
    "publication_date": "2019-07-19",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "Submodular function maximization has been studied extensively in recent years under various constraints and models. The problem plays a major role in various disciplines. We study a natural online variant of this problem in which elements arrive one by ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4246763257",
    "type": "paratext"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3325824",
    "publication_date": "2019-04-30",
    "publication_year": 2019,
    "authors": "Aravind Srinivasan",
    "corresponding_authors": "Aravind Srinivasan",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4249583555",
    "type": "editorial"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3266298",
    "publication_date": "2018-10-13",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "How efficiently can we find an unknown graph using distance or shortest path queries between its vertices? We assume that the unknown graph G is connected, unweighted, and has bounded degree. In the reconstruction problem, the goal is to find the graph ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4250350650",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1198513",
    "publication_date": "2006-10-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We consider a class of multivariate recurrences frequently arising in the worst-case analysis of Davis-Putnam-style exponential-time backtracking algorithms for NP-hard problems. We describe a technique for proving asymptotic upper bounds on these ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252032803",
    "type": "paratext"
  },
  {
    "title": "Editor's foreword",
    "doi": "https://doi.org/10.1145/1077464.1077465",
    "publication_date": "2005-07-01",
    "publication_year": 2005,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252116665",
    "type": "article"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3233176",
    "publication_date": "2018-07-16",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "The Subtree Isomorphism problem asks whether a given tree is contained in another given tree. The problem is of fundamental importance and has been studied since the 1960s. For some variants, e.g., ordered trees, near-linear time algorithms are known, ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4252790763",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3292530",
    "publication_date": "2019-05-02",
    "publication_year": 2019,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present a simple deterministic single-pass (2+ϵ)-approximation algorithm for the maximum weight matching problem in the semi-streaming model. This improves on the currently best known approximation ratio of (4+ϵ).",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253055837",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3196491",
    "publication_date": "2018-06-04",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We consider the classical selection and sorting problems in a model where the initial permutation of the input has to be restored after completing thecomputation. Such algorithms are useful for designing space-efficient algorithms, when one encounters ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253656061",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1125994",
    "publication_date": "2006-01-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "This article has two main results. First, we develop a simple algorithm to list all nonisomorphic rooted plane trees in lexicographic order using a level sequence representation. Then, by selecting a unique centroid to act as the root of a free plane ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254053354",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/3171590",
    "publication_date": "2018-01-30",
    "publication_year": 2018,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "We present the buffer heap, a cache-oblivious priority queue that supports Delete-Min, Delete, and a hybrid Insert/Decrease-Key operation in O(1/B log2 N/M) amortized block transfers from main memory, where M and B are the (unknown) cache size and block ...",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4254414398",
    "type": "paratext"
  },
  {
    "title": null,
    "doi": "https://doi.org/10.1145/1159892",
    "publication_date": "2006-07-01",
    "publication_year": 2006,
    "authors": "No authors",
    "corresponding_authors": "",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4255835034",
    "type": "paratext"
  },
  {
    "title": "Periods of Iterations of Functions with Restricted Preimage Sizes",
    "doi": "https://doi.org/10.1145/3378570",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Rodrigo S. V. Martins; Daniel Panario; Claudio Qureshi; Eric Schmutz",
    "corresponding_authors": "",
    "abstract": "Let [ n { = {1, …, n } and let Ω n be the set of all mappings from [ n { to itself. Let f be a random uniform element of Ω n and let T( f ) and B( f ) denote, respectively, the least common multiple and the product of the length of the cycles of f . Harris proved in 1973 that T converges in distribution to a standard normal distribution and, in 2011, Schmutz obtained an asymptotic estimate on the logarithm of the expectation of T and B over all mappings on n nodes. We obtain analogous results for random uniform mappings on n = kr nodes with preimage sizes restricted to a set of the form {0,k}, where k = k ( r ) ≥ 2. This is motivated by the use of these classes of mappings as heuristic models for the statistics of polynomials of the form x k + a over the integers modulo p , with p ≡ 1 (mod k). We exhibit and discuss our numerical results on this heuristic.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3033801922",
    "type": "article"
  },
  {
    "title": "Tight Bounds on Online Checkpointing Algorithms",
    "doi": "https://doi.org/10.1145/3379543",
    "publication_date": "2020-06-06",
    "publication_year": 2020,
    "authors": "Achiya Bar-On; Itai Dinur; Orr Dunkelman; Rani Hod; Nathan Keller; Eyal Ronen; Adi Shamir",
    "corresponding_authors": "",
    "abstract": "The problem of online checkpointing is a classical problem with numerous applications that has been studied in various forms for almost 50 years. In the simplest version of this problem, a user has to maintain k memorized checkpoints during a long computation, where the only allowed operation is to move one of the checkpoints from its old time to the current time, and his goal is to keep the checkpoints as evenly spread out as possible at all times. Bringmann, Doerr, Neumann, and Sliacan studied this problem as a special case of an online/offline optimization problem in which the deviation from uniformity is measured by the natural discrepancy metric of the worst case ratio between real and ideal segment lengths. They showed this discrepancy is smaller than 1.59-o(1) for all k and smaller than ln 4-o(1)≈ 1.39 for the sparse subset of k ’s, which are powers of 2. In addition, they obtained upper bounds on the achievable discrepancy for some small values of k . In this article, we solve the main problems left open in the above-mentioned paper by proving that ln 4 is a tight upper and lower bound on the asymptotic discrepancy for all large k and by providing tight upper and lower bounds (in the form of provably optimal checkpointing algorithms, some of which are in fact better than those of Bringmann et al.) for all the small values of k ≤ 10. In the last part of the article, we describe some new applications of this online checkpointing problem.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3034127702",
    "type": "article"
  },
  {
    "title": "Test",
    "doi": "https://doi.org/10.1145/3397533",
    "publication_date": "2020-05-07",
    "publication_year": 2020,
    "authors": "Cornetto",
    "corresponding_authors": "Cornetto",
    "abstract": "",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4251862702",
    "type": "article"
  },
  {
    "title": "Deterministic Leader Election in Anonymous Radio Networks",
    "doi": "https://doi.org/10.1145/3527171",
    "publication_date": "2022-03-26",
    "publication_year": 2022,
    "authors": "Avery Miller; Andrzej Pelc; Ram Narayan Yadav",
    "corresponding_authors": "",
    "abstract": "Leader election is a fundamental task in distributed computing. It is a symmetry breaking problem, calling for one node of the network to become the leader , and for all other nodes to become non-leaders . We consider leader election in anonymous radio networks modeled as simple undirected connected graphs. Nodes communicate in synchronous rounds. In each round, a node can either transmit a message to all its neighbours, or stay silent and listen. A node v hears a message from a neighbour w in a given round if v listens in this round and if w is its only neighbour transmitting in this round. If v listens in a round in which more than one neighbour transmits, then v hears noise that is different from any message and different from silence. We assume that nodes are identical (anonymous) and execute the same deterministic algorithm. Under this scenario, symmetry can be broken only in one way: by different wake-up times of the nodes. In which situations is it possible to break symmetry and elect a leader using time as symmetry breaker? In order to answer this question, we consider configurations . A configuration is the underlying graph with nodes tagged by non-negative integers with the following meaning. A node can either wake up spontaneously in the round shown on its tag, according to some global clock, or can be woken up hearing a message sent by one of its already awoken neighbours. The local clock of a node starts at its wakeup and nodes do not have access to the global clock determining their tags. A configuration is feasible if there exists a distributed algorithm that elects a leader for this configuration. Our main result is a complete algorithmic characterization of feasible configurations. More precisely, we design a centralized decision algorithm, working in polynomial time, whose input is a configuration and which decides if the configuration is feasible. Using this algorithm we also provide a dedicated deterministic distributed leader election algorithm for each feasible configuration that elects a leader for this configuration in time O ( n 2 σ, where n is the number of nodes and σ is the difference between the largest and smallest tag of the configuration. We then ask the question whether there exists a universal deterministic distributed algorithm electing a leader for all feasible configurations. The answer turns out to be no, and we show that such a universal algorithm cannot exist even for the class of 4-node feasible configurations. We also prove that a distributed version of our decision algorithm cannot exist.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3004834866",
    "type": "article"
  },
  {
    "title": "Introduction to the ACM-SIAM Symposium on Discrete Algorithms (SODA) 2019 Special Issue",
    "doi": "https://doi.org/10.1145/3508460",
    "publication_date": "2022-01-23",
    "publication_year": 2022,
    "authors": "Martin Hoefer; Tsvi Kopelowitz",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4207036377",
    "type": "article"
  },
  {
    "title": "A Lower Bound on Cycle-Finding in Sparse Digraphs",
    "doi": "https://doi.org/10.1145/3417979",
    "publication_date": "2022-02-08",
    "publication_year": 2022,
    "authors": "Xi Chen; Tim Randolph; Rocco A. Servedio; Timothy Sun",
    "corresponding_authors": "",
    "abstract": "We consider the problem of finding a cycle in a sparse directed graph G that is promised to be far from acyclic, meaning that the smallest feedback arc set , i.e., a subset of edges whose deletion results in an acyclic graph, in G is large. We prove an information-theoretic lower bound, showing that for N -vertex graphs with constant outdegree, any algorithm for this problem must make Ω̄(N 5/9 ) queries to an adjacency list representation of G . In the language of property testing, our result is an Ω̄(N 5/9) lower bound on the query complexity of one-sided algorithms for testing whether sparse digraphs with constant outdegree are far from acyclic. This is the first improvement on the Ω (√ N ) lower bound, implicit in the work of Bender and Ron, which follows from a simple birthday paradox argument.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4210880265",
    "type": "article"
  },
  {
    "title": "The Minimum Principle of SINR: A Useful Discretization Tool for Wireless Communication",
    "doi": "https://doi.org/10.1145/3477144",
    "publication_date": "2022-02-23",
    "publication_year": 2022,
    "authors": "Erez Kantor; Zvi Lotker; Merav Parter; David Peleg",
    "corresponding_authors": "",
    "abstract": "Theoretical study of optimization problems in wireless communication often deals with tasks that concern a single point. For example, the power control problem requires computing a power assignment guaranteeing that each transmitting station s i is successfully received at a single receiver point r i . This paper aims at addressing communication applications that require handling two-dimensional tasks (e.g., guaranteeing successful transmission in entire regions rather than at specific points). The natural approach to two-dimensional optimization tasks is to discretize the optimization domain, e.g., by sampling points within the domain. The straightforward implementation of the discretization approach, however, might incur high time and memory requirements, and moreover, it cannot guarantee exact solutions. The alternative proposed and explored in this paper is based on establishing the minimum principle 1 for the signal to interference and noise ratio (SINR) function with free space path loss (i.e., when the signal decays in proportion to the square of the distance between the transmitter and receiver). Essentially, the minimum principle allows us to reduce the dimension of the optimization domain without losing anything in the accuracy or quality of the solution. More specifically, when the two-dimensional optimization domain is bounded and free from any interfering station, the minimum principle implies that it is sufficient to optimize the SINR function over the boundary of the domain, as the “hardest” points to be satisfied reside on the boundary and not in the interior. We then utilize the minimum principle as the basis for an improved discretization technique for solving two-dimensional problems in the SINR model. This approach is shown to be useful for handling optimization problems over two dimensions (e.g., power control, energy minimization); in providing tight bounds on the number of null cells in the reception map; and in approximating geometric and topological properties of the wireless reception map (e.g., maximum inscribed sphere). The minimum principle, as well as the interplay between continuous and discrete analysis presented in this paper, are expected to pave the way to future study of algorithmic SINR in higher dimensions.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4226238092",
    "type": "article"
  },
  {
    "title": "Ranked Document Retrieval in External Memory",
    "doi": "https://doi.org/10.1145/3559763",
    "publication_date": "2022-09-22",
    "publication_year": 2022,
    "authors": "Rahul Shah; Cheng Sheng; Sharma V. Thankachan; Jeffrey Scott Vitter",
    "corresponding_authors": "",
    "abstract": "The ranked (or top- k ) document retrieval problem is defined as follows: preprocess a collection {T 1 ,T 2 ,… ,T d } of d strings (called documents) of total length n into a data structure, such that for any given query (P,k) , where P is a string (called pattern) of length p ≥ 1 and k ∈ [1,d] is an integer, the identifiers of those k documents that are most relevant to P can be reported, ideally in the sorted order of their relevance. The seminal work by Hon et al. [FOCS 2009 and Journal of the ACM 2014] presented an O(n) -space (in words) data structure with O(p+k log k) query time. The query time was later improved to O(p+k) [SODA 2012] and further to O(p/ log σn+k ) [SIAM Journal on Computing 2017] by Navarro and Nekrich, where σ is the alphabet size. We revisit this problem in the external memory model and present three data structures. The first one takes O(n) -space and answer queries in O(p/B + log B n + k/B+ log * (n/B) ) I/Os, where B is the block size. The second one takes O(n log * (n/B) ) space and answer queries in optimal O(p/B + log B n + k/B) I/Os. In both cases, the answers are reported in the unsorted order of relevance. To handle sorted top- k document retrieval, we present an O(n log (d/B)) space data structure with optimal query cost.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4296613559",
    "type": "article"
  },
  {
    "title": "Generic Techniques for Building Top- <i>k</i> Structures",
    "doi": "https://doi.org/10.1145/3546074",
    "publication_date": "2022-06-29",
    "publication_year": 2022,
    "authors": "Saladi Rahul; Yufei Tao",
    "corresponding_authors": "",
    "abstract": "A reporting query returns the objects satisfying a predicate q from an input set. In prioritized reporting , each object carries a real-valued weight (which can be query dependent), and a query returns the objects that satisfy q and have weights at least a threshold τ. A top- k query finds, among all the objects satisfying q , the k ones of the largest weights; a max query is a special instance with k = 1. We want to design data structures of small space to support queries (and possibly updates) efficiently. Previous work has shown that a top- k structure can also support max and prioritized queries with no performance deterioration. This article explores the opposite direction: do prioritized queries, possibly combined with max queries, imply top- k search? Subject to mild conditions, we provide affirmative answers with two reduction techniques. The first converts a prioritized structure into a static top- k structure with the same space complexity and only a logarithmic blowup in query time. If a max structure is available in addition, our second reduction yields a top- k structure with no degradation in expected performance (this holds for the space, query, and update complexities). Our techniques significantly simplify the design of top- k structures because structures for max and prioritized queries are often easier to obtain. We demonstrate this by developing top- k structures for interval stabbing, 3D dominance, halfspace reporting, linear ranking, and L ∞ nearest neighbor search in the RAM and the external memory computation models.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4300915185",
    "type": "article"
  },
  {
    "title": "A Generalization of Self-Improving Algorithms",
    "doi": "https://doi.org/10.1145/3531227",
    "publication_date": "2022-04-27",
    "publication_year": 2022,
    "authors": "Kai Jin; Siu-Wing Cheng; Man-Kwun Chiu; Man Ting Wong",
    "corresponding_authors": "",
    "abstract": "Ailon et al. [SICOMP’11] proposed self-improving algorithms for sorting and Delaunay triangulation (DT) when the input instances x 1 , ... , x n follow some unknown product distribution . That is, x i is drawn independently from a fixed unknown distribution 𝒟 i . After spending O ( n 1+ε ) time in a learning phase, the subsequent expected running time is O (( n + H )/ε), where H ∊ { H S , H DT }, and H S and H DT are the entropies of the distributions of the sorting and DT output, respectively. In this article, we allow dependence among the x i ’s under the group product distribution . There is a hidden partition of [1, n ] into groups; the x i ’s in the k th group are fixed unknown functions of the same hidden variable u k ; and the u k ’s are drawn from an unknown product distribution. We describe self-improving algorithms for sorting and DT under this model when the functions that map u k to x i ’s are well-behaved. After an O (poly( n ))-time training phase, we achieve O ( n + H S ) and O ( n α ( n ) + H DT ) expected running times for sorting and DT, respectively, where α (⋅) is the inverse Ackermann function.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4301418388",
    "type": "article"
  },
  {
    "title": "Introduction to the Special Issue on ACM-SIAM Symposium on Discrete Algorithms (SODA) 2020",
    "doi": "https://doi.org/10.1145/3561912",
    "publication_date": "2022-10-31",
    "publication_year": 2022,
    "authors": "Gautam Kamath; Sepehr Assadi; Anne Driemel; Janardhan Kulkarni",
    "corresponding_authors": "",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4308915930",
    "type": "article"
  },
  {
    "title": "<i>r</i> -Simple <i>k</i> -Path and Related Problems Parameterized by <i>k</i> / <i>r</i>",
    "doi": "https://doi.org/10.1145/3439721",
    "publication_date": "2021-01-21",
    "publication_year": 2021,
    "authors": "Gregory Gutin; Magnus Wahlström; Meirav Zehavi",
    "corresponding_authors": "",
    "abstract": "Abasi et al. (2014) introduced the following two problems. In the r -S imple k -P ath problem, given a digraph G on n vertices and positive integers r , k , decide whether G has an r -simple k -path, which is a walk where every vertex occurs at most r times and the total number of vertex occurrences is k . In the ( r , k )-M onomial D etection problem, given an arithmetic circuit that succinctly encodes some polynomial P on n variables and positive integers k , r , decide whether P has a monomial of total degree k where the degree of each variable is at most r . Abasi et al. obtained randomized algorithms of running time 4 ( k / r )log r ⋅ n O (1) for both problems. Gabizon et al. (2015) designed deterministic 2 O (( k / r )log r ) ⋅ n O (1) -time algorithms for both problems (however, for the ( r , k )-M onomial D etection problem the input circuit is restricted to be non-canceling). Gabizon et al. also studied the following problem. In the P -S et ( r , q )-P acking P roblem , given a universe V , positive integers ( p , q , r ), and a collection H of sets of size P whose elements belong to V , decide whether there exists a subcollection H ′ of H of size q where each element occurs in at most r sets of H ′ . Gabizon et al. obtained a deterministic 2 O (( pq / r )log r ) ⋅ n O (1) -time algorithm for P -S et ( r , q )-P acking . The above results prove that the three problems are single-exponentially fixed-parameter tractable (FPT) parameterized by the product of two parameters, that is, k / r and log r , where k = pq for P -S et ( r , q )-P acking . Abasi et al. and Gabizon et al. asked whether the log r factor in the exponent can be avoided. Bonamy et al. (2017) answered the question for ( r , k )-M onomial D etection by proving that unless the Exponential Time Hypothesis (ETH) fails there is no 2 o (( k / r ) log r ) ⋅ ( n + log k ) O (1) -time algorithm for ( r , k )-M onomial D etection , i.e., ( r , k )-M onomial D etection is unlikely to be single-exponentially FPT when parameterized by k / r alone. The question remains open for r -S imple k -P ath and P -S et ( r , q )-P acking . We consider the question from a wider perspective: are the above problems FPT when parameterized by k / r only, i.e., whether there exists a computable function f such that the problems admit a f ( k / r )( n +log k ) O (1) -time algorithm? Since r can be substantially larger than the input size, the algorithms of Abasi et al. and Gabizon et al. do not even show that any of these three problems is in XP parameterized by k / r alone. We resolve the wider question by (a) obtaining a 2 O (( k / r ) 2 log( k / r )) ⋅ ( n + log k ) O (1) -time algorithm for r -S imple k -P ath on digraphs and a 2 O ( k / r ) &amp;sdot ( n + log k ) O (1) -time algorithm for r -S imple k -P ath on undirected graphs (i.e., for undirected graphs, we answer the original question in affirmative), (b) showing that P -S et ( r , q )-P acking is FPT (in contrast, we prove that P -M ultiset ( r , q )-P acking is W[1]-hard), and (c) proving that ( r , k )-M onomial D etection is para-NP-hard even if only two distinct variables are in polynomial P and the circuit is non-canceling. For the special case of ( r , k )-M onomial D etection where k is polynomially bounded by the input size (which is in XP), we show W[1]-hardness. Along the way to solve P -S et ( r , q )-P acking , we obtain a polynomial kernel for any fixed P , which resolves a question posed by Gabizon et al. regarding the existence of polynomial kernels for problems with relaxed disjointness constraints. All our algorithms are deterministic.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3123868149",
    "type": "article"
  },
  {
    "title": "Memory-Adjustable Navigation Piles with Applications to Sorting and Convex Hulls",
    "doi": "https://doi.org/10.1145/3452938",
    "publication_date": "2021-04-30",
    "publication_year": 2021,
    "authors": "Omar Darwish; Amr Elmasry; Jyrki Katajainen",
    "corresponding_authors": "",
    "abstract": "We consider space-bounded computations on a random-access machine, where the input is given on a read-only random-access medium, the output is to be produced to a write-only sequential-access medium, and the available workspace allows random reads and writes but is of limited capacity. The length of the input is N elements, the length of the output is limited by the computation, and the capacity of the workspace is O(S) bits for some predetermined parameter S ≥ lg N. We present a state-of-the-art priority queue - called an adjustable navigation pile - for this restricted model. This priority queue supports Minimum in O(1) time, Construct in O(N) time, and Extract-min in O(N/S + lg S) time for any S ≥ lg N. The priority queue can be further augmented in O(N) time to deal with a batch of at most S elements in a specified range of values at a time, and allow to Insert (activate) or Extract (deactivate) an element among these elements, such that Insert and Extract take O(N/S + lg S) time for any S ≥ lg N. We show how to use our data structure to sort N elements and to compute the convex hull of N points in the Euclidean plane in O(N2/S + N lg S) time for any S ≥ lg N. Following a known lower bound for the space-time product of any branching program for finding unique elements, both our sorting and convex-hull algorithms are optimal. The adjustable navigation pile has turned out to be useful when designing other space-efficient algorithms, and we expect that it will find its way to yet other applications.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W3170513281",
    "type": "article"
  },
  {
    "title": "Editorial",
    "doi": "https://doi.org/10.1145/3462270",
    "publication_date": "2021-07-15",
    "publication_year": 2021,
    "authors": "Edith Cohen",
    "corresponding_authors": "Edith Cohen",
    "abstract": "No abstract available.",
    "cited_by_count": 0,
    "openalex_id": "https://openalex.org/W4253598343",
    "type": "editorial"
  }
]